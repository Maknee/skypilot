[33mTailing logs of the last job on cluster 'dd'...[0m
Job ID not provided. Streaming the logs of the latest job.
[2m├── [0m[2mWaiting for task resources on 2 nodes.[0m
[2m└── [0mJob started. Streaming logs... [2m(Ctrl-C to exit log streaming; job will not be killed)[0m
[36m(setup pid=3472)[0m Channels:
[36m(setup pid=3472)[0m  - nvidia
[36m(setup pid=3472)[0m  - defaults
[36m(setup pid=3472)[0m Platform: linux-64
[36m(setup pid=2535, ip=10.102.30.168)[0m Channels:
[36m(setup pid=2535, ip=10.102.30.168)[0m  - nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m  - defaults
[36m(setup pid=2535, ip=10.102.30.168)[0m Platform: linux-64
[36m(setup pid=3472)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=3472)[0m Solving environment: ...working... done
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m ## Package Plan ##
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m   environment location: /root/miniconda3
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m   added / updated specs:
[36m(setup pid=3472)[0m     - cuda
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m The following packages will be downloaded:
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m     package                    |            build
[36m(setup pid=3472)[0m     ---------------------------|-----------------
[36m(setup pid=3472)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=3472)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=3472)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=3472)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=3472)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=3472)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=3472)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=3472)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=3472)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=3472)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=3472)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=3472)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=3472)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=3472)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=3472)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=3472)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=3472)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=3472)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=3472)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=3472)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=3472)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=3472)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=3472)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=3472)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=3472)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=3472)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=3472)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=3472)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=3472)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=3472)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=3472)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=3472)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=3472)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=3472)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=3472)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=3472)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=3472)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=3472)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=3472)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=3472)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=3472)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=3472)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=3472)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=3472)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=3472)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=3472)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=3472)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=3472)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=3472)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=3472)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=3472)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=3472)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=3472)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=3472)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=3472)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=3472)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=3472)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=3472)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=3472)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=3472)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=3472)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=3472)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=3472)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=3472)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=3472)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=3472)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=3472)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=3472)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=3472)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=3472)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=3472)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=3472)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=3472)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=3472)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=3472)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=3472)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=3472)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=3472)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=3472)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=3472)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=3472)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=3472)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=3472)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=3472)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=3472)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=3472)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=3472)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=3472)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=3472)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=3472)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=3472)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=3472)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=3472)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=3472)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=3472)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=3472)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=3472)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=3472)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=3472)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=3472)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=3472)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=3472)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=3472)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=3472)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=3472)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=3472)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=3472)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=3472)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=3472)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=3472)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=3472)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=3472)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=3472)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=3472)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=3472)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=3472)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=3472)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=3472)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=3472)[0m     ------------------------------------------------------------
[36m(setup pid=3472)[0m                                            Total:        2.06 GB
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=3472)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=3472)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=3472)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=3472)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=3472)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=3472)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=3472)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=3472)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=3472)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=3472)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=3472)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=3472)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=3472)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=3472)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=3472)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=3472)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=3472)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=3472)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=3472)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=3472)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=3472)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=3472)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=3472)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=3472)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=3472)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=3472)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=3472)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=3472)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=3472)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=3472)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=3472)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=3472)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=3472)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=3472)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=3472)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=3472)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=3472)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=3472)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=3472)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=3472)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=3472)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=3472)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=3472)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=3472)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=3472)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=3472)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=3472)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=3472)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=3472)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=3472)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=3472)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=3472)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=3472)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=3472)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=3472)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=3472)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3472)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=3472)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=3472)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=3472)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=3472)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=3472)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3472)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=3472)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=3472)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=3472)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=3472)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=3472)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=3472)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=3472)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=3472)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=3472)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=3472)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=3472)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=3472)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=3472)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=3472)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=3472)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3472)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=3472)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=3472)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=3472)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=3472)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=3472)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=3472)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=3472)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=3472)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=3472)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=3472)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=3472)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3472)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=3472)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=3472)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=3472)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=3472)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=3472)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=3472)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=3472)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=3472)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=3472)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=3472)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=3472)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=3472)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=3472)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=3472)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=3472)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m The following packages will be UPDATED:
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=3472)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=3472)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=3472)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=3472)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=3472)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=3472)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=3472)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=3472)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=3472)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=3472)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m Proceed ([y]/n)? 
[36m(setup pid=3472)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=2535, ip=10.102.30.168)[0m Solving environment: ...working... done
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m ## Package Plan ##
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m   environment location: /root/miniconda3
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m   added / updated specs:
[36m(setup pid=2535, ip=10.102.30.168)[0m     - cuda
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m The following packages will be downloaded:
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m     package                    |            build
[36m(setup pid=2535, ip=10.102.30.168)[0m     ---------------------------|-----------------
[36m(setup pid=2535, ip=10.102.30.168)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=2535, ip=10.102.30.168)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=2535, ip=10.102.30.168)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=2535, ip=10.102.30.168)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=2535, ip=10.102.30.168)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=2535, ip=10.102.30.168)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=2535, ip=10.102.30.168)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=2535, ip=10.102.30.168)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=2535, ip=10.102.30.168)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=2535, ip=10.102.30.168)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=2535, ip=10.102.30.168)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=2535, ip=10.102.30.168)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=2535, ip=10.102.30.168)[0m     ------------------------------------------------------------
[36m(setup pid=2535, ip=10.102.30.168)[0m                                            Total:        2.06 GB
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=2535, ip=10.102.30.168)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=2535, ip=10.102.30.168)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=2535, ip=10.102.30.168)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=2535, ip=10.102.30.168)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=2535, ip=10.102.30.168)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m The following packages will be UPDATED:
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=2535, ip=10.102.30.168)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=2535, ip=10.102.30.168)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m Proceed ([y]/n)? 
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=3472)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=3472)[0m Preparing transaction: ...working... done
[36m(setup pid=3472)[0m Verifying transaction: ...working... done
[36m(setup pid=3472)[0m Executing transaction: ...working... done
[36m(setup pid=3472)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=3472)[0m Using CPython 3.10.12 interpreter at: /usr/bin/python3.10
[36m(setup pid=3472)[0m Creating virtual environment with seed packages at: /root/training
[36m(setup pid=3472)[0m  + pip==25.2
[36m(setup pid=3472)[0m  + setuptools==80.9.0
[36m(setup pid=3472)[0m  + wheel==0.45.1
[36m(setup pid=3472)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3472)[0m Resolved 29 packages in 110ms
[36m(setup pid=3472)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=3472)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=3472)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=3472)[0m Downloading sympy (6.0MiB)
[36m(setup pid=3472)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=3472)[0m Downloading pillow (6.3MiB)
[36m(setup pid=3472)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=3472)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=3472)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=3472)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=3472)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=3472)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=3472)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=3472)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=3472)[0m Downloading torch (783.1MiB)
[36m(setup pid=3472)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=3472)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=3472)[0m Downloading triton (148.4MiB)
[36m(setup pid=3472)[0m  Downloading nvidia-cufile-cu12
[36m(setup pid=3472)[0m  Downloading torchaudio
[36m(setup pid=3472)[0m  Downloading torchvision
[36m(setup pid=3472)[0m  Downloading pillow
[36m(setup pid=3472)[0m  Downloading nvidia-cuda-cupti-cu12
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing transaction: ...working... done
[36m(setup pid=3472)[0m  Downloading nvidia-nvjitlink-cu12
[36m(setup pid=3472)[0m  Downloading nvidia-cuda-nvrtc-cu12
[36m(setup pid=2535, ip=10.102.30.168)[0m Verifying transaction: ...working... done
[36m(setup pid=2535, ip=10.102.30.168)[0m Executing transaction: ...working... done
[36m(setup pid=2535, ip=10.102.30.168)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=2535, ip=10.102.30.168)[0m Using CPython 3.10.12 interpreter at: /usr/bin/python3.10
[36m(setup pid=2535, ip=10.102.30.168)[0m Creating virtual environment with seed packages at: /root/training
[36m(setup pid=3472)[0m  Downloading nvidia-curand-cu12
[36m(setup pid=2535, ip=10.102.30.168)[0m  + pip==25.2
[36m(setup pid=2535, ip=10.102.30.168)[0m  + setuptools==80.9.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + wheel==0.45.1
[36m(setup pid=2535, ip=10.102.30.168)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2535, ip=10.102.30.168)[0m Resolved 29 packages in 155ms
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading pillow (6.3MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading sympy (6.0MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading triton (148.4MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading torch (783.1MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading nvidia-cufile-cu12
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading torchaudio
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading torchvision
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading pillow
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading nvidia-cuda-cupti-cu12
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading nvidia-nvjitlink-cu12
[36m(setup pid=3472)[0m  Downloading sympy
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading nvidia-cuda-nvrtc-cu12
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading nvidia-curand-cu12
[36m(setup pid=3472)[0m  Downloading nvidia-cusolver-cu12
[36m(setup pid=3472)[0m  Downloading nvidia-cusparselt-cu12
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading sympy
[36m(setup pid=3472)[0m  Downloading triton
[36m(setup pid=3472)[0m  Downloading nvidia-nccl-cu12
[36m(setup pid=3472)[0m  Downloading nvidia-cufft-cu12
[36m(setup pid=3472)[0m  Downloading nvidia-cusparse-cu12
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading nvidia-cusparselt-cu12
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading nvidia-cusolver-cu12
[36m(setup pid=3472)[0m  Downloading nvidia-cublas-cu12
[36m(setup pid=3472)[0m  Downloading nvidia-cudnn-cu12
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading triton
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading nvidia-cufft-cu12
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading nvidia-nccl-cu12
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading nvidia-cusparse-cu12
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading nvidia-cublas-cu12
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading nvidia-cudnn-cu12
[36m(setup pid=3472)[0m  Downloading torch
[36m(setup pid=3472)[0m Prepared 22 packages in 22.76s
[36m(setup pid=3472)[0m Installed 28 packages in 174ms
[36m(setup pid=3472)[0m  + filelock==3.18.0
[36m(setup pid=3472)[0m  + fsspec==2025.7.0
[36m(setup pid=3472)[0m  + jinja2==3.1.6
[36m(setup pid=3472)[0m  + markupsafe==3.0.2
[36m(setup pid=3472)[0m  + mpmath==1.3.0
[36m(setup pid=3472)[0m  + networkx==3.4.2
[36m(setup pid=3472)[0m  + numpy==2.2.6
[36m(setup pid=3472)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=3472)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=3472)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=3472)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=3472)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=3472)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=3472)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=3472)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=3472)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=3472)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=3472)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=3472)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=3472)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=3472)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=3472)[0m  + pillow==11.3.0
[36m(setup pid=3472)[0m  + sympy==1.14.0
[36m(setup pid=3472)[0m  + torch==2.7.1
[36m(setup pid=3472)[0m  + torchaudio==2.7.1
[36m(setup pid=3472)[0m  + torchvision==0.22.1
[36m(setup pid=3472)[0m  + triton==3.3.1
[36m(setup pid=3472)[0m  + typing-extensions==4.14.1
[36m(setup pid=3472)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3472)[0m Resolved 73 packages in 403ms
[36m(setup pid=3472)[0m    Building deepspeed==0.17.4
[36m(setup pid=3472)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=3472)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=3472)[0m Downloading transformers (10.7MiB)
[36m(setup pid=3472)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=3472)[0m  Downloading tokenizers
[36m(setup pid=3472)[0m  Downloading hf-xet
[36m(setup pid=3472)[0m  Downloading pyarrow
[36m(setup pid=3472)[0m  Downloading transformers
[36m(setup pid=3472)[0m       Built deepspeed==0.17.4
[36m(setup pid=3472)[0m Prepared 21 packages in 1.44s
[36m(setup pid=3472)[0m Uninstalled 1 package in 1ms
[36m(setup pid=3472)[0m Installed 48 packages in 54ms
[36m(setup pid=3472)[0m  + accelerate==1.9.0
[36m(setup pid=3472)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=3472)[0m  + aiohttp==3.12.15
[36m(setup pid=3472)[0m  + aiosignal==1.4.0
[36m(setup pid=3472)[0m  + annotated-types==0.7.0
[36m(setup pid=3472)[0m  + async-timeout==5.0.1
[36m(setup pid=3472)[0m  + attrs==25.3.0
[36m(setup pid=3472)[0m  + certifi==2025.8.3
[36m(setup pid=3472)[0m  + charset-normalizer==3.4.2
[36m(setup pid=3472)[0m  + datasets==4.0.0
[36m(setup pid=3472)[0m  + deepspeed==0.17.4
[36m(setup pid=3472)[0m  + dill==0.3.8
[36m(setup pid=3472)[0m  + einops==0.8.1
[36m(setup pid=3472)[0m  + frozenlist==1.7.0
[36m(setup pid=3472)[0m  - fsspec==2025.7.0
[36m(setup pid=3472)[0m  + fsspec==2025.3.0
[36m(setup pid=3472)[0m  + hf-xet==1.1.5
[36m(setup pid=3472)[0m  + hjson==3.1.0
[36m(setup pid=3472)[0m  + huggingface-hub==0.34.3
[36m(setup pid=3472)[0m  + idna==3.10
[36m(setup pid=3472)[0m  + liger-kernel==0.6.1
[36m(setup pid=3472)[0m  + msgpack==1.1.1
[36m(setup pid=3472)[0m  + multidict==6.6.3
[36m(setup pid=3472)[0m  + multiprocess==0.70.16
[36m(setup pid=3472)[0m  + ninja==1.11.1.4
[36m(setup pid=3472)[0m  + packaging==25.0
[36m(setup pid=3472)[0m  + pandas==2.3.1
[36m(setup pid=3472)[0m  + propcache==0.3.2
[36m(setup pid=3472)[0m  + psutil==7.0.0
[36m(setup pid=3472)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=3472)[0m  + pyarrow==21.0.0
[36m(setup pid=3472)[0m  + pydantic==2.11.7
[36m(setup pid=3472)[0m  + pydantic-core==2.33.2
[36m(setup pid=3472)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=3472)[0m  + pytz==2025.2
[36m(setup pid=3472)[0m  + pyyaml==6.0.2
[36m(setup pid=3472)[0m  + regex==2025.7.34
[36m(setup pid=3472)[0m  + requests==2.32.4
[36m(setup pid=3472)[0m  + safetensors==0.5.3
[36m(setup pid=3472)[0m  + six==1.17.0
[36m(setup pid=3472)[0m  + tokenizers==0.21.4
[36m(setup pid=3472)[0m  + tqdm==4.67.1
[36m(setup pid=3472)[0m  + transformers==4.54.1
[36m(setup pid=3472)[0m  + trl==0.20.0
[36m(setup pid=3472)[0m  + typing-inspection==0.4.1
[36m(setup pid=3472)[0m  + tzdata==2025.2
[36m(setup pid=3472)[0m  + urllib3==2.5.0
[36m(setup pid=3472)[0m  + xxhash==3.5.0
[36m(setup pid=3472)[0m  + yarl==1.20.1
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m Reading package lists...
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading torch
[36m(setup pid=2535, ip=10.102.30.168)[0m Prepared 22 packages in 21.09s
[36m(setup pid=3472)[0m Building dependency tree...
[36m(setup pid=3472)[0m Reading state information...
[36m(setup pid=2535, ip=10.102.30.168)[0m Installed 28 packages in 154ms
[36m(setup pid=2535, ip=10.102.30.168)[0m  + filelock==3.18.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + fsspec==2025.7.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + jinja2==3.1.6
[36m(setup pid=2535, ip=10.102.30.168)[0m  + markupsafe==3.0.2
[36m(setup pid=2535, ip=10.102.30.168)[0m  + mpmath==1.3.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + networkx==3.4.2
[36m(setup pid=2535, ip=10.102.30.168)[0m  + numpy==2.2.6
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=2535, ip=10.102.30.168)[0m  + pillow==11.3.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + sympy==1.14.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + torch==2.7.1
[36m(setup pid=2535, ip=10.102.30.168)[0m  + torchaudio==2.7.1
[36m(setup pid=2535, ip=10.102.30.168)[0m  + torchvision==0.22.1
[36m(setup pid=2535, ip=10.102.30.168)[0m  + triton==3.3.1
[36m(setup pid=2535, ip=10.102.30.168)[0m  + typing-extensions==4.14.1
[36m(setup pid=2535, ip=10.102.30.168)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3472)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3472)[0m   libfuse2
[36m(setup pid=3472)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3472)[0m The following additional packages will be installed:
[36m(setup pid=3472)[0m   vim-common vim-runtime
[36m(setup pid=3472)[0m Suggested packages:
[36m(setup pid=3472)[0m   ctags vim-doc vim-scripts
[36m(setup pid=3472)[0m The following NEW packages will be installed:
[36m(setup pid=3472)[0m   vmtouch
[36m(setup pid=3472)[0m The following packages will be upgraded:
[36m(setup pid=3472)[0m   vim vim-common vim-runtime
[36m(setup pid=2535, ip=10.102.30.168)[0m Resolved 73 packages in 292ms
[36m(setup pid=2535, ip=10.102.30.168)[0m    Building deepspeed==0.17.4
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading transformers (10.7MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=2535, ip=10.102.30.168)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=3472)[0m 3 upgraded, 1 newly installed, 0 to remove and 84 not upgraded.
[36m(setup pid=3472)[0m Need to get 8664 kB of archives.
[36m(setup pid=3472)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=3472)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 vmtouch amd64 1.3.1-2 [21.5 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading tokenizers
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading hf-xet
[36m(setup pid=3472)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim amd64 2:8.2.3995-1ubuntu2.24 [1728 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading pyarrow
[36m(setup pid=2535, ip=10.102.30.168)[0m  Downloading transformers
[36m(setup pid=3472)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-runtime all 2:8.2.3995-1ubuntu2.24 [6833 kB]
[36m(setup pid=3472)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-common all 2:8.2.3995-1ubuntu2.24 [81.5 kB]
[36m(setup pid=3472)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3472)[0m Fetched 8664 kB in 1s (6589 kB/s)
[36m(setup pid=3472)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=3472)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23408 files and directories currently installed.)
[36m(setup pid=3472)[0m Preparing to unpack .../vmtouch_1.3.1-2_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking vmtouch (1.3.1-2) ...
[36m(setup pid=3472)[0m Preparing to unpack .../vim_2%3a8.2.3995-1ubuntu2.24_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking vim (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m       Built deepspeed==0.17.4
[36m(setup pid=2535, ip=10.102.30.168)[0m Prepared 21 packages in 1.40s
[36m(setup pid=2535, ip=10.102.30.168)[0m Uninstalled 1 package in 1ms
[36m(setup pid=3472)[0m Preparing to unpack .../vim-runtime_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=3472)[0m Unpacking vim-runtime (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Installed 48 packages in 98ms
[36m(setup pid=2535, ip=10.102.30.168)[0m  + accelerate==1.9.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=2535, ip=10.102.30.168)[0m  + aiohttp==3.12.15
[36m(setup pid=2535, ip=10.102.30.168)[0m  + aiosignal==1.4.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + annotated-types==0.7.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + async-timeout==5.0.1
[36m(setup pid=2535, ip=10.102.30.168)[0m  + attrs==25.3.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + certifi==2025.8.3
[36m(setup pid=2535, ip=10.102.30.168)[0m  + charset-normalizer==3.4.2
[36m(setup pid=2535, ip=10.102.30.168)[0m  + datasets==4.0.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + deepspeed==0.17.4
[36m(setup pid=2535, ip=10.102.30.168)[0m  + dill==0.3.8
[36m(setup pid=2535, ip=10.102.30.168)[0m  + einops==0.8.1
[36m(setup pid=2535, ip=10.102.30.168)[0m  + frozenlist==1.7.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  - fsspec==2025.7.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + fsspec==2025.3.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + hf-xet==1.1.5
[36m(setup pid=2535, ip=10.102.30.168)[0m  + hjson==3.1.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + huggingface-hub==0.34.3
[36m(setup pid=2535, ip=10.102.30.168)[0m  + idna==3.10
[36m(setup pid=2535, ip=10.102.30.168)[0m  + liger-kernel==0.6.1
[36m(setup pid=2535, ip=10.102.30.168)[0m  + msgpack==1.1.1
[36m(setup pid=2535, ip=10.102.30.168)[0m  + multidict==6.6.3
[36m(setup pid=2535, ip=10.102.30.168)[0m  + multiprocess==0.70.16
[36m(setup pid=2535, ip=10.102.30.168)[0m  + ninja==1.11.1.4
[36m(setup pid=2535, ip=10.102.30.168)[0m  + packaging==25.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + pandas==2.3.1
[36m(setup pid=2535, ip=10.102.30.168)[0m  + propcache==0.3.2
[36m(setup pid=2535, ip=10.102.30.168)[0m  + psutil==7.0.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + pyarrow==21.0.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + pydantic==2.11.7
[36m(setup pid=2535, ip=10.102.30.168)[0m  + pydantic-core==2.33.2
[36m(setup pid=2535, ip=10.102.30.168)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + pytz==2025.2
[36m(setup pid=2535, ip=10.102.30.168)[0m  + pyyaml==6.0.2
[36m(setup pid=2535, ip=10.102.30.168)[0m  + regex==2025.7.34
[36m(setup pid=2535, ip=10.102.30.168)[0m  + requests==2.32.4
[36m(setup pid=2535, ip=10.102.30.168)[0m  + safetensors==0.5.3
[36m(setup pid=2535, ip=10.102.30.168)[0m  + six==1.17.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + tokenizers==0.21.4
[36m(setup pid=2535, ip=10.102.30.168)[0m  + tqdm==4.67.1
[36m(setup pid=2535, ip=10.102.30.168)[0m  + transformers==4.54.1
[36m(setup pid=2535, ip=10.102.30.168)[0m  + trl==0.20.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + typing-inspection==0.4.1
[36m(setup pid=2535, ip=10.102.30.168)[0m  + tzdata==2025.2
[36m(setup pid=2535, ip=10.102.30.168)[0m  + urllib3==2.5.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + xxhash==3.5.0
[36m(setup pid=2535, ip=10.102.30.168)[0m  + yarl==1.20.1
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m Reading package lists...
[36m(setup pid=2535, ip=10.102.30.168)[0m Building dependency tree...
[36m(setup pid=2535, ip=10.102.30.168)[0m Reading state information...
[36m(setup pid=2535, ip=10.102.30.168)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2535, ip=10.102.30.168)[0m   libfuse2
[36m(setup pid=2535, ip=10.102.30.168)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2535, ip=10.102.30.168)[0m The following additional packages will be installed:
[36m(setup pid=2535, ip=10.102.30.168)[0m   vim-common vim-runtime
[36m(setup pid=2535, ip=10.102.30.168)[0m Suggested packages:
[36m(setup pid=2535, ip=10.102.30.168)[0m   ctags vim-doc vim-scripts
[36m(setup pid=2535, ip=10.102.30.168)[0m The following NEW packages will be installed:
[36m(setup pid=2535, ip=10.102.30.168)[0m   vmtouch
[36m(setup pid=2535, ip=10.102.30.168)[0m The following packages will be upgraded:
[36m(setup pid=2535, ip=10.102.30.168)[0m   vim vim-common vim-runtime
[36m(setup pid=2535, ip=10.102.30.168)[0m 3 upgraded, 1 newly installed, 0 to remove and 84 not upgraded.
[36m(setup pid=2535, ip=10.102.30.168)[0m Need to get 8664 kB of archives.
[36m(setup pid=2535, ip=10.102.30.168)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 vmtouch amd64 1.3.1-2 [21.5 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim amd64 2:8.2.3995-1ubuntu2.24 [1728 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-runtime all 2:8.2.3995-1ubuntu2.24 [6833 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-common all 2:8.2.3995-1ubuntu2.24 [81.5 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2535, ip=10.102.30.168)[0m Fetched 8664 kB in 0s (18.6 MB/s)
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=2535, ip=10.102.30.168)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23408 files and directories currently installed.)
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../vmtouch_1.3.1-2_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking vmtouch (1.3.1-2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../vim_2%3a8.2.3995-1ubuntu2.24_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking vim (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3472)[0m Preparing to unpack .../vim-common_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=3472)[0m Unpacking vim-common (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3472)[0m Setting up vmtouch (1.3.1-2) ...
[36m(setup pid=3472)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=3472)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=3472)[0m Setting up vim-common (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../vim-runtime_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking vim-runtime (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3472)[0m Setting up vim-runtime (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3472)[0m Setting up vim (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m Reading package lists...
[36m(setup pid=3472)[0m Building dependency tree...
[36m(setup pid=3472)[0m Reading state information...
[36m(setup pid=3472)[0m build-essential is already the newest version (12.9ubuntu3).
[36m(setup pid=3472)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3472)[0m   libfuse2
[36m(setup pid=3472)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3472)[0m The following additional packages will be installed:
[36m(setup pid=3472)[0m   javascript-common libexpat1 libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=3472)[0m   libjs-underscore libpython3-dev libpython3.10 libpython3.10-dev
[36m(setup pid=3472)[0m   libpython3.10-minimal libpython3.10-stdlib python3-distutils python3-lib2to3
[36m(setup pid=3472)[0m   python3.10 python3.10-minimal
[36m(setup pid=3472)[0m Suggested packages:
[36m(setup pid=3472)[0m   apache2 | lighttpd | httpd python3.10-venv python3.10-doc binfmt-support
[36m(setup pid=3472)[0m The following NEW packages will be installed:
[36m(setup pid=3472)[0m   javascript-common libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=3472)[0m   libjs-underscore libpython3-dev libpython3.10-dev python3-dev
[36m(setup pid=3472)[0m   python3-distutils python3-lib2to3 python3.10-dev
[36m(setup pid=3472)[0m The following packages will be upgraded:
[36m(setup pid=3472)[0m   libexpat1 libpython3.10 libpython3.10-minimal libpython3.10-stdlib
[36m(setup pid=3472)[0m   python3.10 python3.10-minimal
[36m(setup pid=3472)[0m 6 upgraded, 11 newly installed, 0 to remove and 78 not upgraded.
[36m(setup pid=3472)[0m Need to get 13.7 MB of archives.
[36m(setup pid=3472)[0m After this operation, 25.1 MB of additional disk space will be used.
[36m(setup pid=3472)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1 amd64 2.4.7-1ubuntu0.6 [92.1 kB]
[36m(setup pid=3472)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.10 [1950 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../vim-common_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking vim-common (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3472)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=3472)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.10 [1850 kB]
[36m(setup pid=3472)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.10 [2277 kB]
[36m(setup pid=3472)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.10 [815 kB]
[36m(setup pid=3472)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5936 B]
[36m(setup pid=3472)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1-dev amd64 2.4.7-1ubuntu0.6 [148 kB]
[36m(setup pid=3472)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-jquery all 3.6.0+dfsg+~3.5.13-1 [321 kB]
[36m(setup pid=3472)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]
[36m(setup pid=3472)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]
[36m(setup pid=3472)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.10 [4763 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up vmtouch (1.3.1-2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=2535, ip=10.102.30.168)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up vim-common (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up vim-runtime (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up vim (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3472)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3-dev amd64 3.10.6-1~22.04.1 [7064 B]
[36m(setup pid=3472)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=3472)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-lib2to3 all 3.10.8-1~22.04 [77.6 kB]
[36m(setup pid=3472)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-distutils all 3.10.8-1~22.04 [139 kB]
[36m(setup pid=3472)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=3472)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3472)[0m Fetched 13.7 MB in 1s (23.4 MB/s)
[36m(setup pid=3472)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23418 files and directories currently installed.)
[36m(setup pid=3472)[0m Preparing to unpack .../00-libexpat1_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libexpat1:amd64 (2.4.7-1ubuntu0.6) over (2.4.7-1ubuntu0.4) ...
[36m(setup pid=3472)[0m Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libpython3.10:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3472)[0m Preparing to unpack .../02-python3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking python3.10 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3472)[0m Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3472)[0m Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking python3.10-minimal (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3472)[0m Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Reading package lists...
[36m(setup pid=2535, ip=10.102.30.168)[0m Building dependency tree...
[36m(setup pid=2535, ip=10.102.30.168)[0m Reading state information...
[36m(setup pid=2535, ip=10.102.30.168)[0m build-essential is already the newest version (12.9ubuntu3).
[36m(setup pid=2535, ip=10.102.30.168)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2535, ip=10.102.30.168)[0m   libfuse2
[36m(setup pid=2535, ip=10.102.30.168)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2535, ip=10.102.30.168)[0m The following additional packages will be installed:
[36m(setup pid=2535, ip=10.102.30.168)[0m   javascript-common libexpat1 libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=2535, ip=10.102.30.168)[0m   libjs-underscore libpython3-dev libpython3.10 libpython3.10-dev
[36m(setup pid=2535, ip=10.102.30.168)[0m   libpython3.10-minimal libpython3.10-stdlib python3-distutils python3-lib2to3
[36m(setup pid=2535, ip=10.102.30.168)[0m   python3.10 python3.10-minimal
[36m(setup pid=2535, ip=10.102.30.168)[0m Suggested packages:
[36m(setup pid=2535, ip=10.102.30.168)[0m   apache2 | lighttpd | httpd python3.10-venv python3.10-doc binfmt-support
[36m(setup pid=2535, ip=10.102.30.168)[0m The following NEW packages will be installed:
[36m(setup pid=2535, ip=10.102.30.168)[0m   javascript-common libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=2535, ip=10.102.30.168)[0m   libjs-underscore libpython3-dev libpython3.10-dev python3-dev
[36m(setup pid=2535, ip=10.102.30.168)[0m   python3-distutils python3-lib2to3 python3.10-dev
[36m(setup pid=2535, ip=10.102.30.168)[0m The following packages will be upgraded:
[36m(setup pid=2535, ip=10.102.30.168)[0m   libexpat1 libpython3.10 libpython3.10-minimal libpython3.10-stdlib
[36m(setup pid=2535, ip=10.102.30.168)[0m   python3.10 python3.10-minimal
[36m(setup pid=2535, ip=10.102.30.168)[0m 6 upgraded, 11 newly installed, 0 to remove and 78 not upgraded.
[36m(setup pid=2535, ip=10.102.30.168)[0m Need to get 13.7 MB of archives.
[36m(setup pid=2535, ip=10.102.30.168)[0m After this operation, 25.1 MB of additional disk space will be used.
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1 amd64 2.4.7-1ubuntu0.6 [92.1 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.10 [1950 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.10 [1850 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.10 [2277 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.10 [815 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5936 B]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1-dev amd64 2.4.7-1ubuntu0.6 [148 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-jquery all 3.6.0+dfsg+~3.5.13-1 [321 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.10 [4763 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3-dev amd64 3.10.6-1~22.04.1 [7064 B]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-lib2to3 all 3.10.8-1~22.04 [77.6 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-distutils all 3.10.8-1~22.04 [139 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2535, ip=10.102.30.168)[0m Fetched 13.7 MB in 1s (23.3 MB/s)
[36m(setup pid=2535, ip=10.102.30.168)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
[36m(setup pid=2535, ip=10.102.30.168)[0m (Reading database ... 70%
[36m(setup pid=2535, ip=10.102.30.168)[0m (Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23418 files and directories currently installed.)
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../00-libexpat1_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libexpat1:amd64 (2.4.7-1ubuntu0.6) over (2.4.7-1ubuntu0.4) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libpython3.10:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../02-python3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking python3.10 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3472)[0m Selecting previously unselected package javascript-common.
[36m(setup pid=3472)[0m Preparing to unpack .../06-javascript-common_11+nmu1_all.deb ...
[36m(setup pid=3472)[0m Unpacking javascript-common (11+nmu1) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libexpat1-dev:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../07-libexpat1-dev_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libjs-jquery.
[36m(setup pid=3472)[0m Preparing to unpack .../08-libjs-jquery_3.6.0+dfsg+~3.5.13-1_all.deb ...
[36m(setup pid=3472)[0m Unpacking libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libjs-underscore.
[36m(setup pid=3472)[0m Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...
[36m(setup pid=3472)[0m Unpacking libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libjs-sphinxdoc.
[36m(setup pid=3472)[0m Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...
[36m(setup pid=3472)[0m Unpacking libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libpython3.10-dev:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../11-libpython3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking python3.10-minimal (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3472)[0m Selecting previously unselected package libpython3-dev:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../12-libpython3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=3472)[0m Selecting previously unselected package python3.10-dev.
[36m(setup pid=3472)[0m Preparing to unpack .../13-python3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3472)[0m Selecting previously unselected package python3-lib2to3.
[36m(setup pid=3472)[0m Preparing to unpack .../14-python3-lib2to3_3.10.8-1~22.04_all.deb ...
[36m(setup pid=3472)[0m Unpacking python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=3472)[0m Selecting previously unselected package python3-distutils.
[36m(setup pid=3472)[0m Preparing to unpack .../15-python3-distutils_3.10.8-1~22.04_all.deb ...
[36m(setup pid=3472)[0m Unpacking python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3472)[0m Selecting previously unselected package python3-dev.
[36m(setup pid=3472)[0m Preparing to unpack .../16-python3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=3472)[0m Setting up libexpat1:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3472)[0m Setting up javascript-common (11+nmu1) ...
[36m(setup pid=3472)[0m Setting up libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3472)[0m Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3472)[0m Setting up libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=3472)[0m Setting up python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=3472)[0m Setting up libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=3472)[0m Setting up python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package javascript-common.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../06-javascript-common_11+nmu1_all.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking javascript-common (11+nmu1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libexpat1-dev:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../07-libexpat1-dev_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libjs-jquery.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../08-libjs-jquery_3.6.0+dfsg+~3.5.13-1_all.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libjs-underscore.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=3472)[0m Setting up python3.10-minimal (3.10.12-1~22.04.10) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libjs-sphinxdoc.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libpython3.10-dev:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../11-libpython3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libpython3-dev:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../12-libpython3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package python3.10-dev.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../13-python3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package python3-lib2to3.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../14-python3-lib2to3_3.10.8-1~22.04_all.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package python3-distutils.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../15-python3-distutils_3.10.8-1~22.04_all.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package python3-dev.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../16-python3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libexpat1:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up javascript-common (11+nmu1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3472)[0m Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3472)[0m Setting up libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=3472)[0m Setting up libpython3.10:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3472)[0m Setting up python3.10 (3.10.12-1~22.04.10) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up python3.10-minimal (3.10.12-1~22.04.10) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libpython3.10:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up python3.10 (3.10.12-1~22.04.10) ...
[36m(setup pid=3472)[0m Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3472)[0m Setting up python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=3472)[0m Setting up libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=3472)[0m Setting up python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=3472)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3472)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=3472)[0m Reading package lists...
[36m(setup pid=3472)[0m Building dependency tree...
[36m(setup pid=3472)[0m Reading state information...
[36m(setup pid=2535, ip=10.102.30.168)[0m Reading package lists...
[36m(setup pid=3472)[0m infiniband-diags is already the newest version (2410mlnx54-1.2410068).
[36m(setup pid=3472)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3472)[0m   libfuse2
[36m(setup pid=3472)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3472)[0m The following additional packages will be installed:
[36m(setup pid=3472)[0m   dbus dmsetup gir1.2-glib-2.0 libapparmor1 libargon2-1 libatm1 libbpf0
[36m(setup pid=3472)[0m   libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1 libgirepository-1.0-1
[36m(setup pid=3472)[0m   libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5 libmnl0 libnl-genl-3-200
[36m(setup pid=3472)[0m   libsensors-config libsensors5 libsystemd0 libxtables12 networkd-dispatcher
[36m(setup pid=3472)[0m   python3-dbus python3-gi shared-mime-info systemd systemd-timesyncd
[36m(setup pid=3472)[0m   xdg-user-dirs
[36m(setup pid=3472)[0m Suggested packages:
[36m(setup pid=3472)[0m   default-dbus-session-bus | dbus-session-bus lm-sensors lsof strace
[36m(setup pid=3472)[0m   iproute2-doc iw | wireless-tools python-dbus-doc isag systemd-container
[36m(setup pid=3472)[0m   libtss2-esys-3.0.2-0 libtss2-mu0 libtss2-rc0 policykit-1
[36m(setup pid=3472)[0m The following NEW packages will be installed:
[36m(setup pid=3472)[0m   dbus dmsetup gir1.2-glib-2.0 htop iproute2 libapparmor1 libargon2-1 libatm1
[36m(setup pid=3472)[0m   libbpf0 libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1
[36m(setup pid=3472)[0m   libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5
[36m(setup pid=3472)[0m   libmnl0 libnl-genl-3-200 libsensors-config libsensors5 libxtables12
[36m(setup pid=3472)[0m   networkd-dispatcher python3-dbus python3-gi shared-mime-info sysstat systemd
[36m(setup pid=3472)[0m   systemd-timesyncd xdg-user-dirs
[36m(setup pid=3472)[0m The following packages will be upgraded:
[36m(setup pid=3472)[0m   libsystemd0 net-tools
[36m(setup pid=2535, ip=10.102.30.168)[0m Building dependency tree...
[36m(setup pid=2535, ip=10.102.30.168)[0m Reading state information...
[36m(setup pid=2535, ip=10.102.30.168)[0m infiniband-diags is already the newest version (2410mlnx54-1.2410068).
[36m(setup pid=2535, ip=10.102.30.168)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2535, ip=10.102.30.168)[0m   libfuse2
[36m(setup pid=2535, ip=10.102.30.168)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2535, ip=10.102.30.168)[0m The following additional packages will be installed:
[36m(setup pid=2535, ip=10.102.30.168)[0m   dbus dmsetup gir1.2-glib-2.0 libapparmor1 libargon2-1 libatm1 libbpf0
[36m(setup pid=2535, ip=10.102.30.168)[0m   libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1 libgirepository-1.0-1
[36m(setup pid=2535, ip=10.102.30.168)[0m   libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5 libmnl0 libnl-genl-3-200
[36m(setup pid=2535, ip=10.102.30.168)[0m   libsensors-config libsensors5 libsystemd0 libxtables12 networkd-dispatcher
[36m(setup pid=2535, ip=10.102.30.168)[0m   python3-dbus python3-gi shared-mime-info systemd systemd-timesyncd
[36m(setup pid=2535, ip=10.102.30.168)[0m   xdg-user-dirs
[36m(setup pid=2535, ip=10.102.30.168)[0m Suggested packages:
[36m(setup pid=2535, ip=10.102.30.168)[0m   default-dbus-session-bus | dbus-session-bus lm-sensors lsof strace
[36m(setup pid=2535, ip=10.102.30.168)[0m   iproute2-doc iw | wireless-tools python-dbus-doc isag systemd-container
[36m(setup pid=2535, ip=10.102.30.168)[0m   libtss2-esys-3.0.2-0 libtss2-mu0 libtss2-rc0 policykit-1
[36m(setup pid=3472)[0m 2 upgraded, 31 newly installed, 0 to remove and 76 not upgraded.
[36m(setup pid=3472)[0m Need to get 10.6 MB of archives.
[36m(setup pid=3472)[0m After this operation, 35.4 MB of additional disk space will be used.
[36m(setup pid=3472)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsystemd0 amd64 249.11-0ubuntu3.16 [317 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m The following NEW packages will be installed:
[36m(setup pid=2535, ip=10.102.30.168)[0m   dbus dmsetup gir1.2-glib-2.0 htop iproute2 libapparmor1 libargon2-1 libatm1
[36m(setup pid=2535, ip=10.102.30.168)[0m   libbpf0 libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1
[36m(setup pid=2535, ip=10.102.30.168)[0m   libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5
[36m(setup pid=2535, ip=10.102.30.168)[0m   libmnl0 libnl-genl-3-200 libsensors-config libsensors5 libxtables12
[36m(setup pid=2535, ip=10.102.30.168)[0m   networkd-dispatcher python3-dbus python3-gi shared-mime-info sysstat systemd
[36m(setup pid=2535, ip=10.102.30.168)[0m   systemd-timesyncd xdg-user-dirs
[36m(setup pid=2535, ip=10.102.30.168)[0m The following packages will be upgraded:
[36m(setup pid=2535, ip=10.102.30.168)[0m   libsystemd0 net-tools
[36m(setup pid=2535, ip=10.102.30.168)[0m 2 upgraded, 31 newly installed, 0 to remove and 76 not upgraded.
[36m(setup pid=2535, ip=10.102.30.168)[0m Need to get 10.6 MB of archives.
[36m(setup pid=2535, ip=10.102.30.168)[0m After this operation, 35.4 MB of additional disk space will be used.
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsystemd0 amd64 249.11-0ubuntu3.16 [317 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapparmor1 amd64 3.0.4-2ubuntu2.4 [39.7 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libargon2-1 amd64 0~20171227-0.3 [19.5 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdevmapper1.02.1 amd64 2:1.02.175-2.1ubuntu5 [139 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjson-c5 amd64 0.15-3~ubuntu1.22.04.2 [33.5 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcryptsetup12 amd64 2:2.4.3-1ubuntu1.3 [211 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip4tc2 amd64 1.8.7-1ubuntu5.2 [19.9 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd amd64 249.11-0ubuntu3.16 [4581 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-3 amd64 1.12.20-2ubuntu4.1 [189 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dbus amd64 1.12.20-2ubuntu4.1 [158 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dmsetup amd64 2:1.02.175-2.1ubuntu5 [81.7 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.5 [1466 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgirepository-1.0-1 amd64 1.72.0-1 [55.6 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-glib-2.0 amd64 1.72.0-1 [164 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libelf1 amd64 0.186-1ubuntu0.1 [51.1 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbpf0 amd64 1:0.5.0-1ubuntu22.04.1 [140 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmnl0 amd64 1.0.4-3build2 [13.2 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxtables12 amd64 1.8.7-1ubuntu5.2 [31.3 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 iproute2 amd64 5.15.0-1ubuntu2 [1070 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatm1 amd64 1:2.5.1-4build2 [22.8 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.5 [4656 B]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-dbus amd64 1.2.18-3build1 [99.5 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-gi amd64 3.42.1-0ubuntu1 [229 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 networkd-dispatcher all 2.1-2ubuntu0.22.04.2 [15.8 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-timesyncd amd64 249.11-0ubuntu3.16 [31.2 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]
[36m(setup pid=3472)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapparmor1 amd64 3.0.4-2ubuntu2.4 [39.7 kB]
[36m(setup pid=3472)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libargon2-1 amd64 0~20171227-0.3 [19.5 kB]
[36m(setup pid=3472)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdevmapper1.02.1 amd64 2:1.02.175-2.1ubuntu5 [139 kB]
[36m(setup pid=3472)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjson-c5 amd64 0.15-3~ubuntu1.22.04.2 [33.5 kB]
[36m(setup pid=3472)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcryptsetup12 amd64 2:2.4.3-1ubuntu1.3 [211 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 htop amd64 3.0.5-7build2 [128 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 net-tools amd64 1.60+git20181103.0eebece-1ubuntu5.4 [204 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]
[36m(setup pid=3472)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip4tc2 amd64 1.8.7-1ubuntu5.2 [19.9 kB]
[36m(setup pid=3472)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd amd64 249.11-0ubuntu3.16 [4581 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2535, ip=10.102.30.168)[0m Fetched 10.6 MB in 1s (17.8 MB/s)
[36m(setup pid=2535, ip=10.102.30.168)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../libsystemd0_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libsystemd0:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libsystemd0:amd64 (249.11-0ubuntu3.16) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libapparmor1:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../00-libapparmor1_3.0.4-2ubuntu2.4_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libargon2-1:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../01-libargon2-1_0~20171227-0.3_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libdevmapper1.02.1:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../02-libdevmapper1.02.1_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libjson-c5:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../03-libjson-c5_0.15-3~ubuntu1.22.04.2_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libcryptsetup12:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../04-libcryptsetup12_2%3a2.4.3-1ubuntu1.3_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libip4tc2:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../05-libip4tc2_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package systemd.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../06-systemd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3472)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-3 amd64 1.12.20-2ubuntu4.1 [189 kB]
[36m(setup pid=3472)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dbus amd64 1.12.20-2ubuntu4.1 [158 kB]
[36m(setup pid=3472)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dmsetup amd64 2:1.02.175-2.1ubuntu5 [81.7 kB]
[36m(setup pid=3472)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.5 [1466 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libdbus-1-3:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../07-libdbus-1-3_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package dbus.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../08-dbus_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3472)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgirepository-1.0-1 amd64 1.72.0-1 [55.6 kB]
[36m(setup pid=3472)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-glib-2.0 amd64 1.72.0-1 [164 kB]
[36m(setup pid=3472)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libelf1 amd64 0.186-1ubuntu0.1 [51.1 kB]
[36m(setup pid=3472)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbpf0 amd64 1:0.5.0-1ubuntu22.04.1 [140 kB]
[36m(setup pid=3472)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmnl0 amd64 1.0.4-3build2 [13.2 kB]
[36m(setup pid=3472)[0m Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxtables12 amd64 1.8.7-1ubuntu5.2 [31.3 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package dmsetup.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../09-dmsetup_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libglib2.0-0:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../10-libglib2.0-0_2.72.4-0ubuntu2.5_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libgirepository-1.0-1:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../11-libgirepository-1.0-1_1.72.0-1_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package gir1.2-glib-2.0:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../12-gir1.2-glib-2.0_1.72.0-1_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=3472)[0m Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 iproute2 amd64 5.15.0-1ubuntu2 [1070 kB]
[36m(setup pid=3472)[0m Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatm1 amd64 1:2.5.1-4build2 [22.8 kB]
[36m(setup pid=3472)[0m Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.5 [4656 B]
[36m(setup pid=3472)[0m Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-dbus amd64 1.2.18-3build1 [99.5 kB]
[36m(setup pid=3472)[0m Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-gi amd64 3.42.1-0ubuntu1 [229 kB]
[36m(setup pid=3472)[0m Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 networkd-dispatcher all 2.1-2ubuntu0.22.04.2 [15.8 kB]
[36m(setup pid=3472)[0m Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]
[36m(setup pid=3472)[0m Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-timesyncd amd64 249.11-0ubuntu3.16 [31.2 kB]
[36m(setup pid=3472)[0m Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../13-libelf1_0.186-1ubuntu0.1_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libbpf0:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../14-libbpf0_1%3a0.5.0-1ubuntu22.04.1_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../15-libmnl0_1.0.4-3build2_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../16-libxtables12_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package iproute2.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../17-iproute2_5.15.0-1ubuntu2_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=3472)[0m Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../18-libatm1_1%3a2.5.1-4build2_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libglib2.0-data.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../19-libglib2.0-data_2.72.4-0ubuntu2.5_all.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package python3-dbus.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../20-python3-dbus_1.2.18-3build1_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package python3-gi.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../21-python3-gi_3.42.1-0ubuntu1_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package networkd-dispatcher.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../22-networkd-dispatcher_2.1-2ubuntu0.22.04.2_all.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=3472)[0m Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 htop amd64 3.0.5-7build2 [128 kB]
[36m(setup pid=3472)[0m Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]
[36m(setup pid=3472)[0m Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]
[36m(setup pid=3472)[0m Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 net-tools amd64 1.60+git20181103.0eebece-1ubuntu5.4 [204 kB]
[36m(setup pid=3472)[0m Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package shared-mime-info.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../23-shared-mime-info_2.1-2_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking shared-mime-info (2.1-2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package systemd-timesyncd.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../24-systemd-timesyncd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking systemd-timesyncd (249.11-0ubuntu3.16) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package xdg-user-dirs.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../25-xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3472)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libnl-genl-3-200:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../26-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package htop.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../27-htop_3.0.5-7build2_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking htop (3.0.5-7build2) ...
[36m(setup pid=3472)[0m Fetched 10.6 MB in 2s (6387 kB/s)
[36m(setup pid=3472)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=3472)[0m Preparing to unpack .../libsystemd0_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libsystemd0:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...
[36m(setup pid=3472)[0m Setting up libsystemd0:amd64 (249.11-0ubuntu3.16) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../28-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libapparmor1:amd64.
[36m(setup pid=3472)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=3472)[0m Preparing to unpack .../00-libapparmor1_3.0.4-2ubuntu2.4_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libargon2-1:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../01-libargon2-1_0~20171227-0.3_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libdevmapper1.02.1:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../02-libdevmapper1.02.1_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libjson-c5:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../03-libjson-c5_0.15-3~ubuntu1.22.04.2_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libcryptsetup12:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../04-libcryptsetup12_2%3a2.4.3-1ubuntu1.3_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../29-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...
[36m(setup pid=3472)[0m Selecting previously unselected package libip4tc2:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../05-libip4tc2_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3472)[0m Selecting previously unselected package systemd.
[36m(setup pid=3472)[0m Preparing to unpack .../06-systemd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libdbus-1-3:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../07-libdbus-1-3_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3472)[0m Selecting previously unselected package dbus.
[36m(setup pid=3472)[0m Preparing to unpack .../08-dbus_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../30-net-tools_1.60+git20181103.0eebece-1ubuntu5.4_amd64.deb ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking net-tools (1.60+git20181103.0eebece-1ubuntu5.4) over (1.60+git20181103.0eebece-1ubuntu5) ...
[36m(setup pid=3472)[0m Selecting previously unselected package dmsetup.
[36m(setup pid=3472)[0m Preparing to unpack .../09-dmsetup_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libglib2.0-0:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../10-libglib2.0-0_2.72.4-0ubuntu2.5_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libgirepository-1.0-1:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../11-libgirepository-1.0-1_1.72.0-1_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=3472)[0m Selecting previously unselected package gir1.2-glib-2.0:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../12-gir1.2-glib-2.0_1.72.0-1_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Selecting previously unselected package sysstat.
[36m(setup pid=2535, ip=10.102.30.168)[0m Preparing to unpack .../31-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...
[36m(setup pid=3472)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../13-libelf1_0.186-1ubuntu0.1_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Unpacking sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libbpf0:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../14-libbpf0_1%3a0.5.0-1ubuntu22.04.1_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../15-libmnl0_1.0.4-3build2_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../16-libxtables12_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3472)[0m Selecting previously unselected package iproute2.
[36m(setup pid=3472)[0m Preparing to unpack .../17-iproute2_5.15.0-1ubuntu2_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../18-libatm1_1%3a2.5.1-4build2_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libglib2.0-data.
[36m(setup pid=3472)[0m Preparing to unpack .../19-libglib2.0-data_2.72.4-0ubuntu2.5_all.deb ...
[36m(setup pid=3472)[0m Unpacking libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3472)[0m Selecting previously unselected package python3-dbus.
[36m(setup pid=3472)[0m Preparing to unpack .../20-python3-dbus_1.2.18-3build1_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking python3-dbus (1.2.18-3build1) ...
[36m(setup pid=3472)[0m Selecting previously unselected package python3-gi.
[36m(setup pid=3472)[0m Preparing to unpack .../21-python3-gi_3.42.1-0ubuntu1_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=3472)[0m Selecting previously unselected package networkd-dispatcher.
[36m(setup pid=3472)[0m Preparing to unpack .../22-networkd-dispatcher_2.1-2ubuntu0.22.04.2_all.deb ...
[36m(setup pid=3472)[0m Unpacking networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5.4) ...
[36m(setup pid=3472)[0m Selecting previously unselected package shared-mime-info.
[36m(setup pid=3472)[0m Preparing to unpack .../23-shared-mime-info_2.1-2_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking shared-mime-info (2.1-2) ...
[36m(setup pid=3472)[0m Selecting previously unselected package systemd-timesyncd.
[36m(setup pid=3472)[0m Preparing to unpack .../24-systemd-timesyncd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking systemd-timesyncd (249.11-0ubuntu3.16) ...
[36m(setup pid=3472)[0m Selecting previously unselected package xdg-user-dirs.
[36m(setup pid=3472)[0m Preparing to unpack .../25-xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libnl-genl-3-200:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../26-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=3472)[0m Selecting previously unselected package htop.
[36m(setup pid=3472)[0m Preparing to unpack .../27-htop_3.0.5-7build2_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking htop (3.0.5-7build2) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=3472)[0m Preparing to unpack .../28-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...
[36m(setup pid=3472)[0m Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3472)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=3472)[0m Preparing to unpack .../29-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m No schema files found: doing nothing.
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3472)[0m Preparing to unpack .../30-net-tools_1.60+git20181103.0eebece-1ubuntu5.4_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking net-tools (1.60+git20181103.0eebece-1ubuntu5.4) over (1.60+git20181103.0eebece-1ubuntu5) ...
[36m(setup pid=3472)[0m Selecting previously unselected package sysstat.
[36m(setup pid=3472)[0m Preparing to unpack .../31-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...
[36m(setup pid=3472)[0m Unpacking sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=3472)[0m Setting up libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3472)[0m Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5.4) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up shared-mime-info (2.1-2) ...
[36m(setup pid=3472)[0m Setting up libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3472)[0m Setting up xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3472)[0m Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3472)[0m No schema files found: doing nothing.
[36m(setup pid=3472)[0m Setting up libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=3472)[0m Setting up libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3472)[0m Setting up libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=3472)[0m Setting up libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3472)[0m Setting up libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3472)[0m Setting up dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3472)[0m Setting up shared-mime-info (2.1-2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=2535, ip=10.102.30.168)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=2535, ip=10.102.30.168)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=3472)[0m Setting up libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=3472)[0m Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3472)[0m Setting up libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3472)[0m Setting up libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3472)[0m Setting up dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3472)[0m Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=3472)[0m Setting up libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=3472)[0m Setting up libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=3472)[0m Setting up libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=3472)[0m Setting up sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /lib/systemd/system/sysstat-collect.timer.
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=3472)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=3472)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=2535, ip=10.102.30.168)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /lib/systemd/system/sysstat-summary.timer.
[36m(setup pid=3472)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /lib/systemd/system/sysstat-collect.timer.
[36m(setup pid=2535, ip=10.102.30.168)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up python3-dbus (1.2.18-3build1) ...
[36m(setup pid=3472)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /lib/systemd/system/sysstat-summary.timer.
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up htop (3.0.5-7build2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=3472)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.
[36m(setup pid=3472)[0m Setting up python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m Configuration file '/etc/systemd/system.conf'
[36m(setup pid=2535, ip=10.102.30.168)[0m  ==> File on system created by you or by a script.
[36m(setup pid=2535, ip=10.102.30.168)[0m  ==> File also in package provided by package maintainer.
[36m(setup pid=2535, ip=10.102.30.168)[0m    What would you like to do about it ?  Your options are:
[36m(setup pid=2535, ip=10.102.30.168)[0m     Y or I  : install the package maintainer's version
[36m(setup pid=2535, ip=10.102.30.168)[0m     N or O  : keep your currently-installed version
[36m(setup pid=2535, ip=10.102.30.168)[0m       D     : show the differences between the versions
[36m(setup pid=2535, ip=10.102.30.168)[0m       Z     : start a shell to examine the situation
[36m(setup pid=2535, ip=10.102.30.168)[0m  The default action is to keep your current version.
[36m(setup pid=2535, ip=10.102.30.168)[0m *** system.conf (Y/I/N/O/D/Z) [default=N] ? dpkg: error processing package systemd (--configure):
[36m(setup pid=2535, ip=10.102.30.168)[0m  end of file on stdin at conffile prompt
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=3472)[0m Setting up htop (3.0.5-7build2) ...
[36m(setup pid=3472)[0m Setting up gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=3472)[0m Setting up libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=3472)[0m Setting up libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3472)[0m Setting up iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m dpkg: dependency problems prevent configuration of systemd-timesyncd:
[36m(setup pid=2535, ip=10.102.30.168)[0m  systemd-timesyncd depends on systemd (= 249.11-0ubuntu3.16); however:
[36m(setup pid=2535, ip=10.102.30.168)[0m   Package systemd is not configured yet.
[36m(setup pid=2535, ip=10.102.30.168)[0m 
[36m(setup pid=2535, ip=10.102.30.168)[0m dpkg: error processing package systemd-timesyncd (--configure):
[36m(setup pid=2535, ip=10.102.30.168)[0m  dependency problems - leaving unconfigured
[36m(setup pid=2535, ip=10.102.30.168)[0m Setting up networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=3472)[0m Setting up systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m Configuration file '/etc/systemd/system.conf'
[36m(setup pid=3472)[0m  ==> File on system created by you or by a script.
[36m(setup pid=3472)[0m  ==> File also in package provided by package maintainer.
[36m(setup pid=3472)[0m    What would you like to do about it ?  Your options are:
[36m(setup pid=3472)[0m     Y or I  : install the package maintainer's version
[36m(setup pid=3472)[0m     N or O  : keep your currently-installed version
[36m(setup pid=3472)[0m       D     : show the differences between the versions
[36m(setup pid=3472)[0m       Z     : start a shell to examine the situation
[36m(setup pid=3472)[0m  The default action is to keep your current version.
[36m(setup pid=3472)[0m *** system.conf (Y/I/N/O/D/Z) [default=N] ? dpkg: error processing package systemd (--configure):
[36m(setup pid=3472)[0m  end of file on stdin at conffile prompt
[36m(setup pid=3472)[0m Setting up python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Created symlink /etc/systemd/system/multi-user.target.wants/networkd-dispatcher.service → /lib/systemd/system/networkd-dispatcher.service.
[36m(setup pid=2535, ip=10.102.30.168)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Errors were encountered while processing:
[36m(setup pid=2535, ip=10.102.30.168)[0m  systemd
[36m(setup pid=2535, ip=10.102.30.168)[0m  systemd-timesyncd
[36m(setup pid=2535, ip=10.102.30.168)[0m E: Sub-process /usr/bin/dpkg returned an error code (1)
[36m(setup pid=3472)[0m dpkg: dependency problems prevent configuration of systemd-timesyncd:
[36m(setup pid=3472)[0m  systemd-timesyncd depends on systemd (= 249.11-0ubuntu3.16); however:
[36m(setup pid=3472)[0m   Package systemd is not configured yet.
[36m(setup pid=3472)[0m 
[36m(setup pid=3472)[0m dpkg: error processing package systemd-timesyncd (--configure):
[36m(setup pid=3472)[0m  dependency problems - leaving unconfigured
[36m(setup pid=3472)[0m Setting up networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2535, ip=10.102.30.168)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3472)[0m Created symlink /etc/systemd/system/multi-user.target.wants/networkd-dispatcher.service → /lib/systemd/system/networkd-dispatcher.service.
[36m(setup pid=3472)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=3472)[0m Errors were encountered while processing:
[36m(setup pid=3472)[0m  systemd
[36m(setup pid=3472)[0m  systemd-timesyncd
[36m(setup pid=3472)[0m E: Sub-process /usr/bin/dpkg returned an error code (1)
[36m(setup pid=2535, ip=10.102.30.168)[0m Resolved 3 packages in 139ms
[36m(setup pid=2535, ip=10.102.30.168)[0m Prepared 1 package in 9ms
[36m(setup pid=2535, ip=10.102.30.168)[0m Installed 2 packages in 17ms
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=2535, ip=10.102.30.168)[0m  + nvitop==1.5.2
[36m(setup pid=3472)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3472)[0m Resolved 3 packages in 23ms
[36m(setup pid=3472)[0m Prepared 1 package in 9ms
[36m(setup pid=3472)[0m Installed 2 packages in 17ms
[36m(setup pid=3472)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=3472)[0m  + nvitop==1.5.2
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Processing directory 1/2: /tmp/checkpoint ===
[36m(head, rank=0, pid=3472)[0m Preserving existing cache directories...
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Downloading and caching dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Processing directory 1/2: /tmp/checkpoint ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Preserving existing cache directories...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Downloading and caching dataset...
[36m(head, rank=0, pid=3472)[0m Setting num_proc from 128 to 10 for the train split as it only contains 10 shards.
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3472)[0m Generating train split:   2%|▏         | 1000/47780 [00:00<00:24, 1903.15 examples/s]
[36m(head, rank=0, pid=3472)[0m Generating train split:  10%|█         | 5000/47780 [00:00<00:04, 10019.76 examples/s]
[36m(head, rank=0, pid=3472)[0m Generating train split:  23%|██▎       | 11000/47780 [00:00<00:01, 21207.91 examples/s]
[36m(head, rank=0, pid=3472)[0m Generating train split:  36%|███▌      | 17000/47780 [00:00<00:01, 30385.37 examples/s]
[36m(head, rank=0, pid=3472)[0m Generating train split:  46%|████▌     | 22000/47780 [00:00<00:00, 31491.71 examples/s]
[36m(head, rank=0, pid=3472)[0m Generating train split:  63%|██████▎   | 30000/47780 [00:01<00:00, 40331.50 examples/s]
[36m(head, rank=0, pid=3472)[0m Generating train split:  80%|████████  | 38334/47780 [00:01<00:00, 50440.81 examples/s]
[36m(head, rank=0, pid=3472)[0m Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 60735.95 examples/s]
Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 33966.47 examples/s]
[36m(head, rank=0, pid=3472)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(head, rank=0, pid=3472)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Setting num_proc from 128 to 10 for the train split as it only contains 10 shards.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Generating train split:   2%|▏         | 1000/47780 [00:00<00:24, 1913.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Generating train split:  13%|█▎        | 6000/47780 [00:00<00:03, 12044.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Generating train split:  23%|██▎       | 11000/47780 [00:00<00:01, 20305.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Generating train split:  38%|███▊      | 18000/47780 [00:00<00:00, 31564.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Generating train split:  48%|████▊     | 23000/47780 [00:01<00:00, 31366.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Generating train split:  63%|██████▎   | 30000/47780 [00:01<00:00, 40295.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Generating train split:  81%|████████  | 38556/47780 [00:01<00:00, 51476.55 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Generating train split:  98%|█████████▊| 47002/47780 [00:01<00:00, 59418.75 examples/s]
Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 33604.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3472)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3472)[0m vmtouch output: Files: 14
[36m(head, rank=0, pid=3472)[0m      Directories: 5
[36m(head, rank=0, pid=3472)[0m    Evicted Pages: 1212952 (4G)
[36m(head, rank=0, pid=3472)[0m          Elapsed: 3.6588 seconds
[36m(head, rank=0, pid=3472)[0m Downloading and caching model...
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m vmtouch output: Files: 14
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m      Directories: 5
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m    Evicted Pages: 1212952 (4G)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m          Elapsed: 3.7393 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Downloading and caching model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Fetching 5 files:  20%|██        | 1/5 [00:18<01:15, 18.94s/it]
Fetching 5 files:  80%|████████  | 4/5 [00:20<00:04,  4.01s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:20<00:00,  4.11s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(head, rank=0, pid=3472)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3472)[0m Fetching 5 files:  20%|██        | 1/5 [00:27<01:48, 27.21s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3472)[0m Fetching 5 files:  40%|████      | 2/5 [00:27<00:33, 11.27s/it]
Fetching 5 files:  80%|████████  | 4/5 [00:28<00:04,  4.55s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:28<00:00,  5.69s/it]
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:16,  4.17s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:08<00:12,  4.02s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:16,  4.15s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:12<00:07,  3.98s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:08<00:12,  4.13s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:15<00:03,  3.96s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.87s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.93s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model downloaded and cached at: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Flushing filesystem cache for: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:12<00:08,  4.27s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:17<00:04,  4.31s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:21<00:00,  4.20s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:21<00:00,  4.22s/it]
[36m(head, rank=0, pid=3472)[0m Model downloaded and cached at: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Flushing filesystem cache for: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3472)[0m vmtouch output: Files: 18
[36m(head, rank=0, pid=3472)[0m      Directories: 10
[36m(head, rank=0, pid=3472)[0m    Evicted Pages: 5950909 (22G)
[36m(head, rank=0, pid=3472)[0m          Elapsed: 17.741 seconds
[36m(head, rank=0, pid=3472)[0m Completed processing directory 1/2
[36m(head, rank=0, pid=3472)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache, /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3472)[0m vmtouch output: Files: 32
[36m(head, rank=0, pid=3472)[0m      Directories: 15
[36m(head, rank=0, pid=3472)[0m    Evicted Pages: 7163861 (27G)
[36m(head, rank=0, pid=3472)[0m          Elapsed: 0.003314 seconds
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Processing directory 2/2: /mnt/data ===
[36m(head, rank=0, pid=3472)[0m Preserving existing cache directories...
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Downloading and caching dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m vmtouch output: Files: 18
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m      Directories: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m    Evicted Pages: 5950909 (22G)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m          Elapsed: 25.452 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed processing directory 1/2
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache, /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m vmtouch output: Files: 32
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m      Directories: 15
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m    Evicted Pages: 7163861 (27G)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m          Elapsed: 0.003167 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Processing directory 2/2: /mnt/data ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Preserving existing cache directories...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Downloading and caching dataset...
[36m(head, rank=0, pid=3472)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(head, rank=0, pid=3472)[0m Flushing filesystem cache for: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3472)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3472)[0m vmtouch output: Files: 78
[36m(head, rank=0, pid=3472)[0m      Directories: 5
[36m(head, rank=0, pid=3472)[0m    Evicted Pages: 4617819 (17G)
[36m(head, rank=0, pid=3472)[0m          Elapsed: 0.28926 seconds
[36m(head, rank=0, pid=3472)[0m Downloading and caching model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Flushing filesystem cache for: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m vmtouch output: Files: 78
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m      Directories: 5
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m    Evicted Pages: 4617819 (17G)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m          Elapsed: 0.2987 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Downloading and caching model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:06<00:24,  6.20s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:06<00:24,  6.13s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:11<00:17,  5.86s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:12<00:19,  6.54s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:17<00:11,  5.61s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:18<00:12,  6.06s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:22<00:05,  5.45s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:27<00:00,  5.18s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:27<00:00,  5.41s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model downloaded and cached at: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Flushing filesystem cache for: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:24<00:05,  5.91s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:29<00:00,  5.78s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:29<00:00,  5.94s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m vmtouch output: Files: 18
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m      Directories: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m    Evicted Pages: 5950909 (22G)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m          Elapsed: 1.2075 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed processing directory 2/2
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Flushing filesystem cache for: /mnt/data/dataset_cache, /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m vmtouch output: Files: 96
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m      Directories: 15
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m    Evicted Pages: 10568728 (40G)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m          Elapsed: 0.11779 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Copying cached data to S3 directories ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Copying to S3 directory 1/2: /checkpoints_s3
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model downloaded and cached at: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Flushing filesystem cache for: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3472)[0m vmtouch output: Files: 18
[36m(head, rank=0, pid=3472)[0m      Directories: 10
[36m(head, rank=0, pid=3472)[0m    Evicted Pages: 5950909 (22G)
[36m(head, rank=0, pid=3472)[0m          Elapsed: 1.3003 seconds
[36m(head, rank=0, pid=3472)[0m Completed processing directory 2/2
[36m(head, rank=0, pid=3472)[0m Flushing filesystem cache for: /mnt/data/dataset_cache, /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3472)[0m vmtouch output: Files: 96
[36m(head, rank=0, pid=3472)[0m      Directories: 15
[36m(head, rank=0, pid=3472)[0m    Evicted Pages: 10568728 (40G)
[36m(head, rank=0, pid=3472)[0m          Elapsed: 0.1132 seconds
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Copying cached data to S3 directories ===
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Copying to S3 directory 1/2: /checkpoints_s3
[36m(head, rank=0, pid=3472)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3472)[0m Dataset cache copied successfully
[36m(head, rank=0, pid=3472)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache copied successfully
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Model cache copied successfully
[36m(head, rank=0, pid=3472)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3472)[0m Checkpoints copied successfully
[36m(head, rank=0, pid=3472)[0m Completed copying to S3 directory 1/2
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Copying to S3 directory 2/2: /checkpoints_s3_mount_cached
[36m(head, rank=0, pid=3472)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3472)[0m Dataset cache copied successfully
[36m(head, rank=0, pid=3472)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache copied successfully
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoints copied successfully
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed copying to S3 directory 1/2
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Copying to S3 directory 2/2: /checkpoints_s3_mount_cached
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache copied successfully
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Model cache copied successfully
[36m(head, rank=0, pid=3472)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3472)[0m Checkpoints copied successfully
[36m(head, rank=0, pid=3472)[0m Completed copying to S3 directory 2/2
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Download and caching completed ===
[36m(head, rank=0, pid=3472)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache copied successfully
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoints copied successfully
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed copying to S3 directory 2/2
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Download and caching completed ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.06 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.07 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.08 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.08 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.10 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.11 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.07 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.10 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.27 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.30 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.31 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.32 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.34 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.34 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.34 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.49 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 123.49it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 130.32it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 128.55it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 127.90it/s]
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 128.15it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 128.25it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 0.97 seconds
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 135.09it/s]
[36m(head, rank=0, pid=3472)[0m Completed Load model in 0.97 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 0.96 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 1.02 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 132.51it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 129.24it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 127.70it/s]
[36m(head, rank=0, pid=3472)[0m Completed Load model in 0.95 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.02 seconds
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 1.06 seconds
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 139.90it/s]
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 131.78it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 130.74it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 0.97 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.01 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.00 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.03 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.04 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 127.78it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.09 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.04 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:18,  4.62s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:19,  4.81s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:08<00:13,  4.39s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.53s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.28s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.33s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:17<00:04,  4.22s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:21<00:00,  4.12s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:21<00:00,  4.21s/it]
[36m(head, rank=0, pid=3472)[0m Completed Load model in 22.09 seconds
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:17<00:04,  4.22s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:21<00:00,  4.11s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:21<00:00,  4.24s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 22.10 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   0%|          | 2/47780 [00:10<72:17:58,  5.45s/ examples]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   0%|          | 8/47780 [00:11<14:08:26,  1.07s/ examples]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   0%|          | 33/47780 [00:11<2:33:53,  5.17 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   0%|          | 65/47780 [00:11<1:05:59, 12.05 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   0%|          | 125/47780 [00:12<28:21, 28.00 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   0%|          | 213/47780 [00:12<14:18, 55.40 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   1%|          | 296/47780 [00:12<09:45, 81.16 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   1%|          | 418/47780 [00:13<06:22, 123.74 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   1%|          | 579/47780 [00:13<04:07, 191.08 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 730/47780 [00:14<03:13, 243.48 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 889/47780 [00:14<02:36, 298.89 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1030/47780 [00:14<02:21, 330.35 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1184/47780 [00:15<02:06, 366.95 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1371/47780 [00:15<01:49, 421.98 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1552/47780 [00:15<01:41, 456.24 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1765/47780 [00:16<01:30, 511.03 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1975/47780 [00:16<01:24, 543.69 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2217/47780 [00:16<01:16, 597.61 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2467/47780 [00:17<01:10, 640.13 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2722/47780 [00:17<01:06, 674.52 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2976/47780 [00:17<01:04, 696.90 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3231/47780 [00:18<01:02, 711.89 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3532/47780 [00:18<00:59, 744.22 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3850/47780 [00:18<00:55, 785.81 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4156/47780 [00:19<00:54, 803.95 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4467/47780 [00:19<00:52, 819.03 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4814/47780 [00:19<00:50, 855.40 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5175/47780 [00:20<00:47, 905.25 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5547/47780 [00:20<00:35, 1205.46 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5724/47780 [00:20<00:35, 1171.71 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5879/47780 [00:20<00:35, 1166.85 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6021/47780 [00:20<00:37, 1116.39 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6149/47780 [00:20<00:37, 1098.61 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6272/47780 [00:21<00:37, 1093.56 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6390/47780 [00:21<00:38, 1065.38 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6502/47780 [00:21<00:38, 1077.04 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6615/47780 [00:21<00:38, 1065.40 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6724/47780 [00:21<00:39, 1038.02 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6833/47780 [00:21<00:39, 1033.84 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6968/47780 [00:21<00:36, 1116.86 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7082/47780 [00:21<00:36, 1107.98 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7206/47780 [00:21<00:35, 1135.33 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7340/47780 [00:21<00:34, 1180.49 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7460/47780 [00:22<00:35, 1148.06 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7598/47780 [00:22<00:33, 1212.29 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7723/47780 [00:22<00:33, 1185.08 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7843/47780 [00:22<00:34, 1170.98 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7965/47780 [00:22<00:33, 1176.99 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8084/47780 [00:22<00:35, 1126.78 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8209/47780 [00:22<00:34, 1151.75 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8326/47780 [00:22<00:34, 1139.02 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8450/47780 [00:22<00:33, 1160.47 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8585/47780 [00:23<00:32, 1203.35 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8708/47780 [00:23<00:32, 1191.05 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8829/47780 [00:23<00:33, 1152.99 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8946/47780 [00:23<00:34, 1136.91 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9062/47780 [00:23<00:34, 1137.46 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9176/47780 [00:23<00:34, 1129.41 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9291/47780 [00:23<00:34, 1131.28 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9407/47780 [00:23<00:33, 1139.67 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9534/47780 [00:23<00:33, 1151.96 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9672/47780 [00:23<00:31, 1218.00 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9795/47780 [00:24<00:32, 1186.42 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9916/47780 [00:24<00:31, 1188.86 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10036/47780 [00:24<00:32, 1151.57 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10153/47780 [00:24<00:33, 1139.63 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10276/47780 [00:24<00:32, 1164.01 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10394/47780 [00:24<00:32, 1147.46 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10511/47780 [00:24<00:32, 1152.35 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10629/47780 [00:24<00:32, 1130.97 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10746/47780 [00:24<00:32, 1134.31 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10860/47780 [00:25<00:33, 1094.97 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10972/47780 [00:25<00:34, 1069.45 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11098/47780 [00:25<00:33, 1102.94 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11233/47780 [00:25<00:31, 1168.83 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11378/47780 [00:25<00:29, 1217.92 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11519/47780 [00:25<00:28, 1267.77 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11649/47780 [00:25<00:29, 1221.69 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11774/47780 [00:25<00:29, 1206.21 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11895/47780 [00:25<00:29, 1197.24 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12015/47780 [00:26<00:30, 1179.83 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12134/47780 [00:26<00:30, 1173.78 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12258/47780 [00:26<00:30, 1179.03 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12378/47780 [00:26<00:30, 1157.24 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12503/47780 [00:26<00:29, 1181.53 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12642/47780 [00:26<00:28, 1242.16 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12769/47780 [00:26<00:29, 1178.53 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12890/47780 [00:26<00:30, 1159.50 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13011/47780 [00:26<00:29, 1165.45 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13129/47780 [00:26<00:29, 1161.53 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13256/47780 [00:27<00:29, 1182.76 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13375/47780 [00:27<00:29, 1170.27 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13493/47780 [00:27<00:30, 1118.37 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13606/47780 [00:27<00:30, 1109.64 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13734/47780 [00:27<00:29, 1158.20 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13858/47780 [00:27<00:28, 1178.96 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13978/47780 [00:27<00:30, 1111.82 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14092/47780 [00:27<00:30, 1116.01 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14225/47780 [00:27<00:28, 1176.46 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14345/47780 [00:28<00:28, 1158.06 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14464/47780 [00:28<00:28, 1159.15 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14582/47780 [00:28<00:28, 1159.46 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14701/47780 [00:28<00:28, 1154.97 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14817/47780 [00:28<00:30, 1095.46 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14970/47780 [00:28<00:27, 1214.47 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15094/47780 [00:28<00:29, 1119.54 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15208/47780 [00:28<00:29, 1095.94 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15327/47780 [00:28<00:28, 1120.03 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15441/47780 [00:28<00:28, 1125.52 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15561/47780 [00:29<00:28, 1135.20 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15682/47780 [00:29<00:29, 1101.33 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15814/47780 [00:29<00:27, 1155.01 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15932/47780 [00:29<00:29, 1093.45 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16062/47780 [00:29<00:27, 1145.36 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16180/47780 [00:29<00:27, 1138.39 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16296/47780 [00:29<00:28, 1123.44 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16425/47780 [00:29<00:27, 1150.31 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16543/47780 [00:29<00:27, 1156.16 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16661/47780 [00:30<00:26, 1158.02 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16782/47780 [00:30<00:26, 1160.55 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16907/47780 [00:30<00:26, 1178.84 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17041/47780 [00:30<00:25, 1223.71 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17165/47780 [00:30<00:27, 1118.43 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17297/47780 [00:30<00:25, 1174.19 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17437/47780 [00:30<00:24, 1224.11 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17569/47780 [00:30<00:24, 1248.80 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17705/47780 [00:30<00:23, 1275.82 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17835/47780 [00:31<00:24, 1201.94 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17970/47780 [00:31<00:24, 1238.42 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18097/47780 [00:31<00:24, 1211.22 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18222/47780 [00:31<00:25, 1175.40 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18346/47780 [00:31<00:24, 1192.64 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18468/47780 [00:31<00:25, 1169.09 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18586/47780 [00:31<00:25, 1158.40 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18703/47780 [00:31<00:25, 1125.11 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18831/47780 [00:31<00:25, 1129.39 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18947/47780 [00:31<00:25, 1137.36 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19061/47780 [00:32<00:25, 1137.42 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19175/47780 [00:32<00:25, 1123.86 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19288/47780 [00:32<00:25, 1107.36 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19400/47780 [00:32<00:25, 1108.30 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19513/47780 [00:32<00:25, 1090.56 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19627/47780 [00:32<00:26, 1080.47 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19748/47780 [00:32<00:25, 1106.86 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19859/47780 [00:32<00:25, 1098.13 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19970/47780 [00:32<00:25, 1090.33 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20087/47780 [00:33<00:25, 1095.32 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20226/47780 [00:33<00:23, 1170.02 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20360/47780 [00:33<00:22, 1218.71 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20484/47780 [00:33<00:23, 1161.45 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20607/47780 [00:33<00:23, 1178.23 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20729/47780 [00:33<00:22, 1179.47 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20849/47780 [00:33<00:23, 1139.01 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20976/47780 [00:33<00:22, 1176.24 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21126/47780 [00:33<00:21, 1265.60 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21254/47780 [00:34<00:22, 1167.14 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21374/47780 [00:34<00:23, 1125.21 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21490/47780 [00:34<00:23, 1133.93 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21617/47780 [00:34<00:22, 1168.70 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21753/47780 [00:34<00:21, 1222.97 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21878/47780 [00:34<00:22, 1174.36 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21999/47780 [00:34<00:22, 1125.32 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22115/47780 [00:34<00:22, 1129.39 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22231/47780 [00:34<00:22, 1131.01 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22351/47780 [00:34<00:22, 1143.36 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22470/47780 [00:35<00:21, 1155.38 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22588/47780 [00:35<00:21, 1149.34 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22714/47780 [00:35<00:21, 1179.93 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22833/47780 [00:35<00:21, 1170.58 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22959/47780 [00:35<00:20, 1196.11 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23085/47780 [00:35<00:20, 1214.57 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23223/47780 [00:35<00:19, 1262.30 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23351/47780 [00:35<00:19, 1241.03 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23481/47780 [00:35<00:20, 1193.02 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23603/47780 [00:36<00:20, 1179.25 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23739/47780 [00:36<00:19, 1226.95 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23864/47780 [00:36<00:20, 1150.74 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23993/47780 [00:36<00:20, 1173.42 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24113/47780 [00:36<00:20, 1151.59 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24230/47780 [00:36<00:20, 1142.52 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24365/47780 [00:36<00:19, 1198.89 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24501/47780 [00:36<00:19, 1219.58 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24625/47780 [00:36<00:19, 1196.75 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24750/47780 [00:36<00:19, 1195.35 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24873/47780 [00:37<00:19, 1167.05 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24991/47780 [00:37<00:20, 1112.14 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25111/47780 [00:37<00:20, 1130.75 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25227/47780 [00:37<00:19, 1128.21 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25344/47780 [00:37<00:20, 1110.29 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25457/47780 [00:37<00:20, 1070.28 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25568/47780 [00:37<00:20, 1069.75 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25676/47780 [00:37<00:21, 1050.00 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25795/47780 [00:37<00:20, 1081.45 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25908/47780 [00:38<00:20, 1088.76 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26018/47780 [00:38<00:20, 1065.02 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26130/47780 [00:38<00:20, 1075.82 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26244/47780 [00:38<00:19, 1093.66 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26356/47780 [00:38<00:19, 1098.30 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26466/47780 [00:38<00:19, 1089.59 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26581/47780 [00:38<00:19, 1073.63 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26700/47780 [00:38<00:19, 1091.99 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26811/47780 [00:38<00:19, 1088.51 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26921/47780 [00:38<00:19, 1050.22 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27033/47780 [00:39<00:19, 1069.85 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27161/47780 [00:39<00:18, 1124.31 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27289/47780 [00:39<00:17, 1167.64 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27413/47780 [00:39<00:17, 1166.08 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27530/47780 [00:39<00:17, 1153.04 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27648/47780 [00:39<00:18, 1108.05 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27761/47780 [00:39<00:18, 1078.74 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27884/47780 [00:39<00:17, 1114.59 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28014/47780 [00:39<00:17, 1144.95 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28137/47780 [00:40<00:17, 1136.47 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28252/47780 [00:40<00:17, 1113.91 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28384/47780 [00:40<00:16, 1165.86 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28504/47780 [00:40<00:16, 1174.56 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28622/47780 [00:40<00:16, 1137.90 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28743/47780 [00:40<00:16, 1128.59 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28857/47780 [00:40<00:16, 1122.28 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28972/47780 [00:40<00:17, 1104.54 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29083/47780 [00:40<00:17, 1069.24 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29195/47780 [00:41<00:17, 1051.62 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29302/47780 [00:41<00:18, 1013.35 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29407/47780 [00:41<00:17, 1023.42 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29512/47780 [00:41<00:18, 1007.67 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29622/47780 [00:41<00:17, 1033.60 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29727/47780 [00:41<00:17, 1004.17 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29834/47780 [00:41<00:17, 1019.74 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29947/47780 [00:41<00:17, 1045.55 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30052/47780 [00:41<00:16, 1046.14 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30159/47780 [00:41<00:17, 1030.46 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30265/47780 [00:42<00:17, 1027.31 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30371/47780 [00:42<00:17, 1003.18 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30473/47780 [00:42<00:17, 993.73 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30574/47780 [00:42<00:17, 961.95 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30683/47780 [00:42<00:17, 996.31 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30789/47780 [00:42<00:16, 1014.31 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30892/47780 [00:42<00:16, 1006.96 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30995/47780 [00:42<00:17, 976.56 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31102/47780 [00:42<00:16, 999.23 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31228/47780 [00:43<00:15, 1064.11 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31346/47780 [00:43<00:15, 1093.90 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31486/47780 [00:43<00:13, 1176.09 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31606/47780 [00:43<00:14, 1131.35 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31720/47780 [00:43<00:14, 1075.80 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31830/47780 [00:43<00:14, 1070.80 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31939/47780 [00:43<00:15, 1024.79 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32074/47780 [00:43<00:14, 1114.40 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32190/47780 [00:43<00:13, 1116.60 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32312/47780 [00:43<00:13, 1137.83 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32430/47780 [00:44<00:13, 1127.84 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32555/47780 [00:44<00:13, 1155.12 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32671/47780 [00:44<00:13, 1102.63 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32784/47780 [00:44<00:14, 1057.12 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32894/47780 [00:44<00:14, 1033.44 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32999/47780 [00:44<00:14, 1008.35 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33103/47780 [00:44<00:14, 988.98 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33206/47780 [00:44<00:14, 996.91 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33318/47780 [00:44<00:14, 1016.92 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33420/47780 [00:45<00:15, 950.26 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33526/47780 [00:45<00:14, 969.10 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33635/47780 [00:45<00:14, 996.34 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33736/47780 [00:45<00:14, 955.86 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33841/47780 [00:45<00:14, 976.33 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33947/47780 [00:45<00:14, 984.16 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34054/47780 [00:45<00:13, 1007.85 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34157/47780 [00:45<00:13, 993.38 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34262/47780 [00:45<00:13, 1005.68 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34363/47780 [00:46<00:13, 973.69 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34484/47780 [00:46<00:12, 1027.42 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34607/47780 [00:46<00:12, 1066.32 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34720/47780 [00:46<00:12, 1083.33 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34829/47780 [00:46<00:12, 1040.57 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34937/47780 [00:46<00:12, 1051.51 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35043/47780 [00:46<00:12, 1040.83 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35163/47780 [00:46<00:11, 1086.52 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35273/47780 [00:46<00:11, 1071.72 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35381/47780 [00:47<00:12, 1013.03 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35498/47780 [00:47<00:11, 1054.93 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35611/47780 [00:47<00:11, 1072.48 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35719/47780 [00:47<00:11, 1058.58 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35847/47780 [00:47<00:10, 1108.33 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35960/47780 [00:47<00:10, 1111.84 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36073/47780 [00:47<00:11, 1046.82 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36179/47780 [00:47<00:11, 1028.88 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36284/47780 [00:47<00:11, 1012.82 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36398/47780 [00:47<00:10, 1046.18 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36505/47780 [00:48<00:11, 1016.71 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36609/47780 [00:48<00:10, 1016.07 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36713/47780 [00:48<00:10, 1006.52 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36814/47780 [00:48<00:11, 972.12 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36912/47780 [00:48<00:11, 945.39 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37008/47780 [00:48<00:11, 928.08 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37113/47780 [00:48<00:11, 957.18 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37221/47780 [00:48<00:10, 990.84 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37327/47780 [00:48<00:10, 1002.35 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37430/47780 [00:49<00:10, 987.59 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37531/47780 [00:49<00:10, 968.66 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37629/47780 [00:49<00:11, 899.93 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37721/47780 [00:49<00:11, 886.15 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37823/47780 [00:49<00:10, 922.29 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37932/47780 [00:49<00:10, 967.18 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38032/47780 [00:49<00:10, 949.19 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38135/47780 [00:49<00:09, 964.80 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38245/47780 [00:49<00:09, 996.84 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38349/47780 [00:49<00:09, 988.55 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38449/47780 [00:50<00:09, 989.66 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38560/47780 [00:50<00:09, 1023.36 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38665/47780 [00:50<00:08, 1031.14 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38775/47780 [00:50<00:08, 1046.90 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38881/47780 [00:50<00:08, 1038.14 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38997/47780 [00:50<00:08, 1064.21 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39105/47780 [00:50<00:08, 1032.12 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39209/47780 [00:50<00:08, 1017.26 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39314/47780 [00:50<00:08, 979.63 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39414/47780 [00:51<00:08, 980.19 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39524/47780 [00:51<00:08, 1012.22 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39626/47780 [00:51<00:08, 981.73 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39725/47780 [00:51<00:08, 981.41 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39828/47780 [00:51<00:08, 993.66 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39929/47780 [00:51<00:07, 994.69 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40036/47780 [00:51<00:07, 1013.19 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40139/47780 [00:51<00:07, 1004.81 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40240/47780 [00:51<00:07, 957.01 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40363/47780 [00:51<00:07, 1021.48 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40468/47780 [00:52<00:07, 1028.18 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40573/47780 [00:52<00:07, 1001.16 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40674/47780 [00:52<00:07, 990.14 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40787/47780 [00:52<00:06, 1016.79 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40891/47780 [00:52<00:06, 994.93 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40993/47780 [00:52<00:06, 1000.25 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41098/47780 [00:52<00:06, 1005.22 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41200/47780 [00:52<00:06, 991.45 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41326/47780 [00:52<00:06, 1065.98 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41436/47780 [00:53<00:05, 1070.52 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41545/47780 [00:53<00:05, 1053.02 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41651/47780 [00:53<00:05, 1029.76 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41767/47780 [00:53<00:05, 1055.04 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41873/47780 [00:53<00:05, 1053.63 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41984/47780 [00:53<00:05, 1066.80 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42097/47780 [00:53<00:05, 1071.74 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42205/47780 [00:53<00:05, 1033.13 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42315/47780 [00:53<00:05, 989.89 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42420/47780 [00:53<00:05, 993.68 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42521/47780 [00:54<00:05, 965.53 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42649/47780 [00:54<00:04, 1051.69 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42755/47780 [00:54<00:04, 1047.03 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42862/47780 [00:54<00:04, 1000.81 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42965/47780 [00:54<00:04, 971.81 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43063/47780 [00:54<00:05, 939.72 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43158/47780 [00:54<00:04, 940.90 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43254/47780 [00:54<00:05, 895.74 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43349/47780 [00:54<00:04, 910.37 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43442/47780 [00:55<00:04, 903.72 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43536/47780 [00:55<00:04, 890.51 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43629/47780 [00:55<00:04, 900.47 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43720/47780 [00:55<00:04, 900.51 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43812/47780 [00:55<00:04, 846.44 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43898/47780 [00:55<00:04, 819.23 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43981/47780 [00:55<00:04, 772.66 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44061/47780 [00:55<00:05, 721.11 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44141/47780 [00:55<00:04, 737.80 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44219/47780 [00:56<00:04, 732.93 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44299/47780 [00:56<00:04, 741.82 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44394/47780 [00:56<00:04, 790.60 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44474/47780 [00:56<00:04, 769.07 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44552/47780 [00:56<00:04, 730.54 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44627/47780 [00:56<00:04, 735.84 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44712/47780 [00:56<00:04, 752.28 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44807/47780 [00:56<00:03, 804.49 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44890/47780 [00:56<00:03, 778.37 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44971/47780 [00:57<00:03, 756.95 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45050/47780 [00:57<00:03, 738.55 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45125/47780 [00:57<00:03, 726.61 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45198/47780 [00:57<00:03, 683.93 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45267/47780 [00:57<00:04, 623.48 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45333/47780 [00:57<00:04, 601.77 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45396/47780 [00:57<00:04, 579.20 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45455/47780 [00:57<00:04, 550.02 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45519/47780 [00:58<00:04, 559.90 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45576/47780 [00:58<00:04, 496.26 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45628/47780 [00:58<00:04, 501.11 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45681/47780 [00:58<00:04, 482.43 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45731/47780 [00:58<00:04, 464.61 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45782/47780 [00:58<00:04, 463.95 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45829/47780 [00:58<00:04, 450.57 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45876/47780 [00:58<00:04, 438.97 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45924/47780 [00:58<00:04, 444.64 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45969/47780 [00:59<00:04, 427.10 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46012/47780 [00:59<00:04, 413.61 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46055/47780 [00:59<00:04, 408.74 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46105/47780 [00:59<00:03, 421.48 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46157/47780 [00:59<00:03, 435.00 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46201/47780 [00:59<00:03, 426.23 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46246/47780 [00:59<00:03, 427.67 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46289/47780 [00:59<00:03, 427.75 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46336/47780 [00:59<00:03, 437.24 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46383/47780 [01:00<00:03, 405.98 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46433/47780 [01:00<00:03, 416.84 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46481/47780 [01:00<00:03, 428.99 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46526/47780 [01:00<00:03, 401.53 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46568/47780 [01:00<00:03, 403.51 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46610/47780 [01:00<00:02, 404.57 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46654/47780 [01:00<00:02, 413.41 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46701/47780 [01:00<00:02, 404.36 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46744/47780 [01:00<00:02, 379.34 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46784/47780 [01:01<00:02, 381.12 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46824/47780 [01:01<00:02, 364.26 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46862/47780 [01:01<00:02, 364.08 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46904/47780 [01:01<00:02, 366.50 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46946/47780 [01:01<00:02, 380.99 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46986/47780 [01:01<00:02, 352.81 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47022/47780 [01:01<00:02, 332.58 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47058/47780 [01:01<00:02, 325.88 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47092/47780 [01:02<00:02, 318.42 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47126/47780 [01:02<00:02, 307.17 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47158/47780 [01:02<00:02, 288.14 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47189/47780 [01:02<00:02, 264.54 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47218/47780 [01:02<00:02, 253.60 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47252/47780 [01:02<00:01, 268.31 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47282/47780 [01:02<00:01, 273.10 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47311/47780 [01:02<00:01, 274.34 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47340/47780 [01:02<00:01, 263.83 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47367/47780 [01:03<00:01, 262.90 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47395/47780 [01:03<00:01, 243.92 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47425/47780 [01:03<00:01, 252.05 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47452/47780 [01:03<00:01, 235.13 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47477/47780 [01:03<00:01, 193.17 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47498/47780 [01:03<00:01, 164.38 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47517/47780 [01:03<00:01, 154.91 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47535/47780 [01:04<00:01, 147.05 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47551/47780 [01:04<00:01, 138.48 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47569/47780 [01:04<00:01, 139.87 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47587/47780 [01:04<00:01, 133.75 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47602/47780 [01:04<00:01, 111.71 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47615/47780 [01:04<00:01, 103.72 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47627/47780 [01:05<00:01, 98.83 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47639/47780 [01:05<00:01, 97.34 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47649/47780 [01:05<00:01, 96.69 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47663/47780 [01:05<00:01, 104.92 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47676/47780 [01:05<00:00, 110.91 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47690/47780 [01:05<00:00, 116.02 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47703/47780 [01:05<00:00, 115.17 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47715/47780 [01:05<00:00, 88.84 examples/s] 
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47726/47780 [01:06<00:00, 68.23 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47735/47780 [01:06<00:00, 63.97 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47743/47780 [01:06<00:00, 50.42 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47750/47780 [01:06<00:00, 49.58 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [01:06<00:00, 41.51 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47761/47780 [01:07<00:00, 40.21 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47768/47780 [01:07<00:00, 39.30 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [01:07<00:00, 38.58 examples/s]
[36m(head, rank=0, pid=3472)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [01:08<00:00, 13.43 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [01:10<00:00, 678.07 examples/s]
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3472)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:09<07:03, 110.55 examples/s]
[36m(head, rank=0, pid=3472)[0m Truncating train dataset (num_proc=32):  17%|█▋        | 8000/47780 [00:09<00:33, 1196.06 examples/s]
[36m(head, rank=0, pid=3472)[0m Truncating train dataset (num_proc=32):  41%|████      | 19482/47780 [00:09<00:07, 3651.25 examples/s]
[36m(head, rank=0, pid=3472)[0m Truncating train dataset (num_proc=32):  80%|████████  | 38385/47780 [00:09<00:01, 9196.48 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:15<00:00, 3001.61 examples/s]
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:15,771] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3472)[0m df: /root/.triton/autotune: No such file or directory
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:16,407] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:16,440] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:16,443] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:16,471] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:16,484] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:16,499] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:16,504] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:18,092] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:18,092] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:18,092] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:18,092] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:18,092] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:18,092] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:18,093] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:23:18,093] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<4:28:04,  2.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 24/47780 [00:02<1:04:26, 12.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:17:00,  2.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:47:11,  2.29 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 52/47780 [00:02<30:02, 26.49 examples/s]  
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:54:02,  2.25 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 24/47780 [00:02<1:14:15, 10.72 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<6:10:47,  2.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 1/47780 [00:02<37:22:22,  2.82s/ examples]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 1/47780 [00:02<38:51:17,  2.93s/ examples]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 20/47780 [00:03<1:37:22,  8.17 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 88/47780 [00:03<18:27, 43.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 29/47780 [00:03<1:06:49, 11.91 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 47/47780 [00:03<38:05, 20.89 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 29/47780 [00:03<1:08:22, 11.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 7/47780 [00:03<4:35:40,  2.89 examples/s] 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 35/47780 [00:03<57:05, 13.94 examples/s]  
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 39/47780 [00:03<49:07, 16.20 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 158/47780 [00:03<10:02, 79.05 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 42/47780 [00:03<50:05, 15.89 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 61/47780 [00:03<31:55, 24.91 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 95/47780 [00:03<18:21, 43.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 49/47780 [00:03<35:04, 22.68 examples/s] 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 78/47780 [00:03<25:18, 31.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 64/47780 [00:03<29:53, 26.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 219/47780 [00:03<08:04, 98.19 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 101/47780 [00:03<19:22, 41.01 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 92/47780 [00:04<19:27, 40.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 77/47780 [00:04<26:15, 30.28 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 161/47780 [00:04<11:21, 69.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 123/47780 [00:04<16:40, 47.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 124/47780 [00:04<14:05, 56.37 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 154/47780 [00:04<11:38, 68.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 163/47780 [00:04<10:53, 72.87 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 302/47780 [00:04<07:00, 112.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   1%|          | 251/47780 [00:04<07:28, 105.99 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 168/47780 [00:04<12:52, 61.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 206/47780 [00:04<08:33, 92.67 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 207/47780 [00:04<10:39, 74.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   1%|          | 242/47780 [00:04<07:39, 103.42 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 217/47780 [00:05<09:54, 79.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   1%|          | 415/47780 [00:05<05:34, 141.40 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 340/47780 [00:05<06:34, 120.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   1%|          | 284/47780 [00:05<07:27, 106.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   1%|          | 286/47780 [00:05<07:33, 104.80 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 313/47780 [00:05<07:32, 104.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   1%|          | 323/47780 [00:05<06:59, 113.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   1%|          | 386/47780 [00:05<05:42, 138.43 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 334/47780 [00:05<06:49, 115.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   1%|          | 540/47780 [00:05<04:51, 161.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   1%|          | 479/47780 [00:05<05:07, 153.66 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 440/47780 [00:05<05:02, 156.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   1%|          | 456/47780 [00:05<04:51, 162.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   1%|          | 492/47780 [00:06<04:56, 159.56 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 664/47780 [00:06<03:34, 219.98 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 465/47780 [00:06<06:00, 131.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   1%|          | 456/47780 [00:06<05:31, 142.80 examples/s]
Tokenizing train dataset (num_proc=32):   1%|▏         | 714/47780 [00:06<03:57, 197.81 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 571/47780 [00:06<04:09, 189.45 examples/s]
Tokenizing train dataset (num_proc=32):   1%|▏         | 620/47780 [00:06<03:25, 229.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 612/47780 [00:06<03:43, 210.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 751/47780 [00:06<02:37, 299.15 examples/s]
Tokenizing train dataset (num_proc=32):   1%|▏         | 609/47780 [00:06<04:08, 190.11 examples/s]
Tokenizing train dataset (num_proc=32):   1%|▏         | 701/47780 [00:06<03:46, 207.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 697/47780 [00:06<03:36, 217.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 830/47780 [00:06<03:22, 232.41 examples/s]
Tokenizing train dataset (num_proc=32):   1%|▏         | 678/47780 [00:06<04:25, 177.40 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 869/47780 [00:07<03:41, 211.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 809/47780 [00:07<03:36, 216.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 897/47780 [00:07<03:05, 252.08 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 744/47780 [00:07<04:01, 194.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 796/47780 [00:07<04:02, 193.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 894/47780 [00:07<02:45, 283.81 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1025/47780 [00:07<03:07, 249.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1039/47780 [00:07<03:26, 226.04 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 963/47780 [00:07<03:16, 237.75 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 819/47780 [00:07<04:13, 184.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1025/47780 [00:07<03:02, 256.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1029/47780 [00:07<02:25, 321.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 963/47780 [00:08<03:31, 220.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 953/47780 [00:08<03:35, 217.38 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1206/47780 [00:08<03:03, 254.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1149/47780 [00:08<03:06, 250.65 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1104/47780 [00:08<03:23, 229.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1240/47780 [00:08<03:06, 249.98 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1116/47780 [00:08<03:04, 253.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1202/47780 [00:08<02:35, 299.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1121/47780 [00:08<03:25, 227.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1390/47780 [00:08<02:54, 266.50 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1077/47780 [00:08<04:04, 190.73 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1295/47780 [00:08<03:14, 238.83 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1446/47780 [00:09<02:51, 269.42 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1582/47780 [00:09<02:04, 370.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1264/47780 [00:08<03:20, 232.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1275/47780 [00:08<02:28, 313.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1489/47780 [00:09<02:05, 368.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1296/47780 [00:09<03:15, 238.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1270/47780 [00:09<04:11, 184.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1493/47780 [00:09<02:17, 335.48 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1487/47780 [00:09<03:04, 250.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1654/47780 [00:09<02:52, 267.81 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1573/47780 [00:09<02:44, 280.66 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▎         | 1679/47780 [00:09<02:43, 281.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1674/47780 [00:09<02:10, 354.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1359/47780 [00:09<03:32, 218.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1511/47780 [00:10<02:58, 259.05 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1738/47780 [00:10<01:59, 384.22 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1588/47780 [00:10<03:05, 249.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1729/47780 [00:10<03:31, 217.45 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▎         | 1748/47780 [00:10<02:53, 265.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1700/47780 [00:10<03:08, 244.71 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1938/47780 [00:10<02:30, 304.14 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1915/47780 [00:10<02:03, 371.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1940/47780 [00:10<01:55, 396.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2086/47780 [00:10<02:02, 371.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2219/47780 [00:10<01:42, 442.34 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1822/47780 [00:10<02:38, 290.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2302/47780 [00:10<01:45, 431.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1511/47780 [00:10<04:19, 178.26 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▎         | 1709/47780 [00:11<02:45, 277.76 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▎         | 1721/47780 [00:11<03:36, 213.05 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2017/47780 [00:11<02:47, 273.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1973/47780 [00:11<02:04, 367.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2057/47780 [00:11<02:51, 266.95 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2040/47780 [00:11<02:58, 256.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2002/47780 [00:11<03:21, 227.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2264/47780 [00:11<01:56, 392.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1979/47780 [00:11<02:53, 264.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2217/47780 [00:11<01:51, 408.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2373/47780 [00:12<03:29, 217.06 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2503/47780 [00:12<02:34, 292.52 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2085/47780 [00:12<03:05, 246.28 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1801/47780 [00:12<04:03, 188.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2264/47780 [00:12<02:43, 278.61 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2299/47780 [00:12<02:02, 372.00 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2223/47780 [00:12<01:48, 420.05 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2469/47780 [00:12<01:55, 393.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2578/47780 [00:12<02:24, 313.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2420/47780 [00:12<02:05, 361.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2324/47780 [00:12<02:57, 255.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2377/47780 [00:12<03:37, 208.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2532/47780 [00:13<02:39, 283.06 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2092/47780 [00:13<06:40, 114.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2565/47780 [00:13<02:50, 265.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2542/47780 [00:13<02:25, 311.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2710/47780 [00:13<01:54, 392.49 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2495/47780 [00:13<03:27, 218.10 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2398/47780 [00:13<02:59, 252.94 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2643/47780 [00:13<05:22, 139.83 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2557/47780 [00:13<03:08, 239.87 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2636/47780 [00:13<03:18, 227.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2789/47780 [00:13<01:44, 431.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2798/47780 [00:14<02:52, 261.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2515/47780 [00:14<04:20, 174.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2809/47780 [00:14<02:22, 316.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2859/47780 [00:14<03:04, 244.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2658/47780 [00:14<04:03, 185.06 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2826/47780 [00:14<02:43, 274.53 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2919/47780 [00:14<03:05, 241.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2748/47780 [00:15<06:27, 116.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2860/47780 [00:15<04:34, 163.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2981/47780 [00:15<03:08, 237.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2855/47780 [00:15<04:28, 167.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3136/47780 [00:15<02:18, 321.82 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2941/47780 [00:15<03:13, 232.13 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3223/47780 [00:15<02:13, 334.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 2991/47780 [00:15<03:19, 224.54 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3264/47780 [00:15<01:51, 398.87 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3578/47780 [00:15<01:22, 537.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 3072/47780 [00:15<02:56, 252.89 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2974/47780 [00:15<02:55, 254.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3220/47780 [00:15<02:22, 313.06 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3326/47780 [00:15<01:51, 397.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2918/47780 [00:16<05:44, 130.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3427/47780 [00:15<01:57, 378.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3148/47780 [00:16<03:46, 197.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3362/47780 [00:16<02:18, 319.85 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3765/47780 [00:16<01:56, 378.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2905/47780 [00:16<05:18, 140.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3926/47780 [00:16<01:36, 456.20 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3284/47780 [00:16<04:44, 156.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3265/47780 [00:17<03:34, 207.08 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3523/47780 [00:17<02:40, 275.93 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3719/47780 [00:17<01:50, 398.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3504/47780 [00:17<02:19, 316.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3456/47780 [00:17<03:16, 225.77 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2963/47780 [00:17<06:04, 123.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3550/47780 [00:17<03:13, 228.40 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3884/47780 [00:17<01:51, 392.08 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3601/47780 [00:18<03:15, 226.24 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3543/47780 [00:18<04:13, 174.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3791/47780 [00:18<02:22, 309.59 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3197/47780 [00:18<04:41, 158.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4148/47780 [00:18<01:17, 560.87 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3446/47780 [00:18<02:47, 265.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4611/47780 [00:18<00:45, 958.41 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▊         | 4069/47780 [00:18<03:27, 210.29 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▊         | 4141/47780 [00:18<02:07, 343.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3665/47780 [00:18<03:36, 203.38 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4451/47780 [00:18<01:56, 371.89 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4557/47780 [00:18<01:20, 536.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4302/47780 [00:18<01:38, 440.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4865/47780 [00:18<00:45, 951.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 4046/47780 [00:19<03:08, 232.55 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4364/47780 [00:19<01:57, 368.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3546/47780 [00:19<03:36, 204.30 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3672/47780 [00:19<04:58, 147.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3764/47780 [00:19<02:22, 309.13 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▊         | 4154/47780 [00:19<02:01, 358.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4756/47780 [00:19<01:48, 397.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5127/47780 [00:19<01:12, 586.89 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5072/47780 [00:19<01:23, 510.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4559/47780 [00:19<02:01, 355.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4535/47780 [00:20<02:33, 281.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3870/47780 [00:20<03:18, 221.08 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4440/47780 [00:20<01:19, 542.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4456/47780 [00:20<02:10, 331.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4879/47780 [00:20<01:20, 535.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5338/47780 [00:21<02:11, 323.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4710/47780 [00:21<03:15, 220.74 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4663/47780 [00:21<01:48, 397.90 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5222/47780 [00:21<02:51, 248.24 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5106/47780 [00:21<01:50, 384.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5139/47780 [00:21<01:39, 426.47 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4630/47780 [00:21<04:24, 163.42 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4747/47780 [00:21<03:04, 232.91 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5588/47780 [00:21<01:45, 401.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5330/47780 [00:21<01:22, 513.37 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5185/47780 [00:21<01:53, 376.32 examples/s]
Tokenizing train dataset (num_proc=32):  10%|█         | 4984/47780 [00:21<02:42, 263.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5896/47780 [00:21<01:14, 563.05 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5284/47780 [00:22<02:16, 311.94 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5417/47780 [00:22<01:56, 365.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6117/47780 [00:22<01:44, 398.25 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█▏        | 5491/47780 [00:22<03:09, 223.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6290/47780 [00:22<01:26, 478.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5850/47780 [00:23<01:59, 351.97 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5546/47780 [00:23<02:00, 350.80 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5502/47780 [00:23<02:16, 309.99 examples/s]
Tokenizing train dataset (num_proc=32):  10%|█         | 4872/47780 [00:23<02:40, 267.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5171/47780 [00:23<03:16, 217.33 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5922/47780 [00:23<01:20, 517.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5227/47780 [00:23<01:43, 409.85 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5500/47780 [00:23<02:08, 328.35 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5516/47780 [00:23<01:16, 555.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5410/47780 [00:23<02:33, 275.86 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5761/47780 [00:23<00:59, 703.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5727/47780 [00:23<01:48, 386.10 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6067/47780 [00:23<00:44, 939.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6309/47780 [00:23<00:46, 890.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6452/47780 [00:24<02:14, 307.64 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5646/47780 [00:24<03:06, 225.55 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6712/47780 [00:24<01:33, 440.88 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5926/47780 [00:24<01:52, 373.07 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6132/47780 [00:24<01:54, 364.36 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6504/47780 [00:24<01:00, 679.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6035/47780 [00:24<02:38, 262.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6370/47780 [00:24<01:44, 395.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6663/47780 [00:24<01:15, 541.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6874/47780 [00:24<01:38, 416.34 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5674/47780 [00:24<02:55, 240.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6651/47780 [00:24<01:13, 556.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6058/47780 [00:24<01:47, 388.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5930/47780 [00:24<02:32, 275.18 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6997/47780 [00:25<01:42, 396.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6192/47780 [00:25<01:52, 370.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6765/47780 [00:25<01:21, 501.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7093/47780 [00:25<01:45, 385.41 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6881/47780 [00:25<01:38, 414.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6855/47780 [00:25<01:37, 419.58 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6059/47780 [00:25<02:55, 237.74 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7171/47780 [00:25<01:50, 368.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6306/47780 [00:25<02:35, 265.90 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6927/47780 [00:25<01:37, 420.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6502/47780 [00:25<02:00, 343.07 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7235/47780 [00:25<01:53, 357.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6974/47780 [00:25<01:06, 609.25 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6989/47780 [00:25<01:42, 398.59 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6259/47780 [00:25<02:13, 311.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7314/47780 [00:26<00:48, 832.75 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7289/47780 [00:25<01:55, 350.94 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6528/47780 [00:26<01:36, 427.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7042/47780 [00:26<01:45, 385.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7339/47780 [00:26<01:53, 355.53 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7089/47780 [00:26<01:47, 377.41 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7384/47780 [00:26<01:53, 355.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7042/47780 [00:26<01:57, 347.73 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7426/47780 [00:26<01:50, 366.07 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7244/47780 [00:26<01:30, 448.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7133/47780 [00:26<01:56, 348.05 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7469/47780 [00:26<01:47, 376.55 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7183/47780 [00:26<01:50, 367.44 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7580/47780 [00:26<00:59, 677.99 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7511/47780 [00:26<01:48, 369.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7231/47780 [00:26<01:44, 389.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7552/47780 [00:26<01:46, 378.75 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7274/47780 [00:26<01:52, 360.68 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6710/47780 [00:26<01:51, 367.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7594/47780 [00:26<01:50, 364.00 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7313/47780 [00:26<01:53, 357.32 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6991/47780 [00:26<01:18, 517.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7634/47780 [00:26<01:47, 373.00 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7351/47780 [00:26<01:52, 359.59 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7292/47780 [00:26<00:56, 719.36 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6277/47780 [00:26<03:26, 201.07 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7779/47780 [00:27<01:06, 600.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7673/47780 [00:26<01:49, 365.52 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7391/47780 [00:27<01:49, 369.71 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7572/47780 [00:27<00:43, 920.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6495/47780 [00:27<02:23, 286.98 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7719/47780 [00:27<01:43, 387.01 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7387/47780 [00:27<01:59, 339.37 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7429/47780 [00:27<01:52, 357.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6613/47780 [00:27<02:01, 338.58 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7759/47780 [00:27<02:05, 320.13 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7493/47780 [00:27<01:47, 376.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7466/47780 [00:27<02:00, 335.87 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7799/47780 [00:27<01:57, 339.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7501/47780 [00:27<01:59, 336.38 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7931/47780 [00:27<01:15, 524.60 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7845/47780 [00:27<01:49, 366.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7538/47780 [00:27<01:59, 337.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7589/47780 [00:27<01:44, 385.56 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7884/47780 [00:27<01:51, 358.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7573/47780 [00:27<01:59, 336.42 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6366/47780 [00:27<03:40, 187.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7611/47780 [00:27<01:56, 345.38 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8049/47780 [00:27<01:20, 490.69 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7669/47780 [00:27<01:46, 377.54 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7922/47780 [00:27<02:04, 319.51 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6906/47780 [00:27<01:54, 355.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7647/47780 [00:27<01:55, 348.76 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7793/47780 [00:27<01:09, 578.03 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7959/47780 [00:27<01:59, 332.17 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7687/47780 [00:27<01:51, 358.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7736/47780 [00:27<01:45, 377.91 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7994/47780 [00:27<02:09, 307.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8143/47780 [00:28<01:25, 465.15 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7724/47780 [00:28<01:59, 336.60 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7795/47780 [00:28<01:47, 370.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8031/47780 [00:28<02:03, 320.56 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7758/47780 [00:28<02:02, 326.68 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6726/47780 [00:28<02:55, 234.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8065/47780 [00:28<02:09, 306.19 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8220/47780 [00:28<01:31, 432.26 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7848/47780 [00:28<01:50, 360.74 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7802/47780 [00:28<01:52, 354.11 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7078/47780 [00:28<01:33, 433.44 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8097/47780 [00:28<02:10, 303.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7956/47780 [00:28<01:19, 502.27 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7843/47780 [00:28<01:51, 357.65 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7894/47780 [00:28<01:51, 358.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8283/47780 [00:28<01:33, 420.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8145/47780 [00:28<01:55, 343.57 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7891/47780 [00:28<01:41, 391.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7937/47780 [00:28<01:49, 363.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8182/47780 [00:28<01:54, 346.44 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8342/47780 [00:28<01:34, 415.89 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7932/47780 [00:28<01:46, 375.59 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8083/47780 [00:28<01:21, 486.07 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7978/47780 [00:28<01:55, 344.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8222/47780 [00:28<01:49, 361.30 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8393/47780 [00:28<01:37, 403.79 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7970/47780 [00:28<01:58, 334.86 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8272/47780 [00:28<01:41, 387.65 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8016/47780 [00:28<02:05, 317.93 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8439/47780 [00:28<01:37, 402.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8017/47780 [00:28<01:47, 368.24 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8311/47780 [00:28<01:42, 384.35 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8183/47780 [00:28<01:24, 470.46 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8051/47780 [00:28<02:03, 322.10 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8055/47780 [00:28<01:47, 370.69 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8350/47780 [00:28<01:42, 385.67 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8484/47780 [00:29<01:45, 374.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8087/47780 [00:28<02:01, 327.88 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8093/47780 [00:29<01:52, 354.18 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8266/47780 [00:29<01:25, 464.10 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8389/47780 [00:29<01:45, 373.89 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8525/47780 [00:29<01:43, 378.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8124/47780 [00:29<01:58, 334.92 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8130/47780 [00:29<01:54, 344.98 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8427/47780 [00:29<01:47, 367.64 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8565/47780 [00:29<01:44, 376.67 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8161/47780 [00:29<01:55, 343.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8337/47780 [00:29<01:28, 447.27 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8165/47780 [00:29<01:56, 340.40 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8604/47780 [00:29<01:46, 369.31 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8464/47780 [00:29<01:52, 348.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8206/47780 [00:29<01:46, 372.20 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8200/47780 [00:29<01:59, 332.08 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8655/47780 [00:29<01:38, 396.18 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8246/47780 [00:29<01:49, 359.70 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8501/47780 [00:29<01:59, 328.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8398/47780 [00:29<01:33, 421.43 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8236/47780 [00:29<01:56, 339.80 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8696/47780 [00:29<01:37, 398.94 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8290/47780 [00:29<01:44, 377.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8535/47780 [00:29<02:08, 305.82 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8272/47780 [00:29<01:54, 345.14 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8451/47780 [00:29<01:40, 390.81 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8737/47780 [00:29<01:43, 378.50 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7151/47780 [00:29<02:41, 252.04 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8330/47780 [00:29<01:42, 383.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8578/47780 [00:29<01:55, 338.27 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8307/47780 [00:29<01:59, 331.60 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8369/47780 [00:29<01:43, 381.29 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8777/47780 [00:29<01:43, 377.22 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8497/47780 [00:29<01:42, 384.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8623/47780 [00:29<01:46, 368.63 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8343/47780 [00:29<01:57, 335.95 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8817/47780 [00:29<01:46, 366.18 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8410/47780 [00:29<01:45, 372.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8661/47780 [00:29<01:47, 363.10 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8540/47780 [00:29<01:47, 366.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7242/47780 [00:29<02:46, 243.97 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8381/47780 [00:29<01:54, 344.87 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8856/47780 [00:30<01:45, 368.93 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8453/47780 [00:29<01:43, 380.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8698/47780 [00:29<01:51, 349.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7642/47780 [00:29<01:33, 430.48 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8580/47780 [00:30<01:49, 356.60 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8421/47780 [00:29<01:49, 360.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8895/47780 [00:30<01:49, 354.78 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8492/47780 [00:30<01:51, 351.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8734/47780 [00:30<01:53, 345.14 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8618/47780 [00:30<01:50, 355.42 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8459/47780 [00:30<01:52, 349.36 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8943/47780 [00:30<01:40, 385.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8769/47780 [00:30<01:53, 344.61 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8528/47780 [00:30<01:54, 343.61 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8496/47780 [00:30<01:51, 351.76 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8655/47780 [00:30<01:58, 328.92 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8809/47780 [00:30<01:48, 358.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 8986/47780 [00:30<01:41, 380.54 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8563/47780 [00:30<01:58, 329.93 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8532/47780 [00:30<01:54, 342.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8689/47780 [00:30<01:58, 328.51 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9027/47780 [00:30<01:42, 376.26 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8850/47780 [00:30<01:47, 360.70 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8606/47780 [00:30<01:50, 353.33 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8567/47780 [00:30<01:58, 329.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8723/47780 [00:30<02:03, 315.56 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9066/47780 [00:30<01:41, 380.00 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8887/47780 [00:30<01:48, 359.27 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8642/47780 [00:30<02:01, 323.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8601/47780 [00:30<01:58, 331.90 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8755/47780 [00:30<02:12, 293.54 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8924/47780 [00:30<01:47, 361.98 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8683/47780 [00:30<01:52, 346.01 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8638/47780 [00:30<01:56, 335.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9105/47780 [00:30<02:03, 311.95 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8961/47780 [00:30<01:51, 348.50 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8785/47780 [00:30<02:21, 276.04 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8719/47780 [00:30<01:55, 337.52 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8675/47780 [00:30<01:58, 330.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9166/47780 [00:30<01:41, 382.24 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8819/47780 [00:30<02:13, 291.89 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9003/47780 [00:30<01:48, 356.53 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8760/47780 [00:30<01:51, 350.88 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9207/47780 [00:30<01:39, 388.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8709/47780 [00:30<02:00, 325.00 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8849/47780 [00:30<02:19, 278.91 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9039/47780 [00:30<01:55, 334.80 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8796/47780 [00:30<01:55, 338.47 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9253/47780 [00:31<01:36, 400.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8742/47780 [00:30<02:00, 323.54 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8883/47780 [00:31<02:13, 292.37 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9073/47780 [00:31<02:02, 315.62 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8831/47780 [00:31<01:57, 331.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9296/47780 [00:31<01:37, 395.24 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8775/47780 [00:31<02:14, 289.18 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8927/47780 [00:31<01:56, 332.36 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9111/47780 [00:31<01:58, 325.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8867/47780 [00:31<01:57, 331.24 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9337/47780 [00:31<01:44, 367.22 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8811/47780 [00:31<02:09, 301.62 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8967/47780 [00:31<01:52, 345.20 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9147/47780 [00:31<01:56, 331.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8906/47780 [00:31<01:54, 338.62 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9377/47780 [00:31<01:44, 367.88 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8856/47780 [00:31<01:55, 338.00 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9007/47780 [00:31<01:48, 358.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9181/47780 [00:31<01:56, 332.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8946/47780 [00:31<01:49, 353.41 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9415/47780 [00:31<01:43, 370.68 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7841/47780 [00:31<02:23, 278.85 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9058/47780 [00:31<01:36, 402.00 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8898/47780 [00:31<01:54, 338.17 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7327/47780 [00:31<03:34, 188.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9215/47780 [00:31<02:02, 314.68 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8982/47780 [00:31<01:53, 343.25 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9453/47780 [00:31<01:44, 365.37 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8126/47780 [00:31<01:39, 399.86 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9100/47780 [00:31<01:35, 406.75 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8935/47780 [00:31<01:52, 346.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9250/47780 [00:31<02:00, 320.85 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9022/47780 [00:31<01:50, 351.68 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9494/47780 [00:31<01:42, 374.13 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9143/47780 [00:31<01:36, 402.40 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 8972/47780 [00:31<01:57, 331.22 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9283/47780 [00:31<02:03, 312.88 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9061/47780 [00:31<01:46, 362.48 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9538/47780 [00:31<01:39, 384.05 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9006/47780 [00:31<01:56, 331.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9185/47780 [00:31<01:45, 366.85 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9315/47780 [00:31<02:03, 310.52 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9098/47780 [00:31<01:58, 326.85 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9578/47780 [00:31<01:43, 367.50 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9040/47780 [00:31<02:01, 318.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9224/47780 [00:31<01:45, 365.41 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9349/47780 [00:31<02:01, 316.16 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9616/47780 [00:32<01:44, 366.12 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8311/47780 [00:31<01:37, 404.51 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9132/47780 [00:31<02:06, 304.99 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9080/47780 [00:31<01:53, 340.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9269/47780 [00:32<01:40, 384.46 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9382/47780 [00:32<02:00, 319.32 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9653/47780 [00:32<01:49, 348.58 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9183/47780 [00:32<01:48, 354.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9116/47780 [00:32<01:52, 343.11 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9309/47780 [00:32<01:44, 367.98 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9415/47780 [00:32<02:06, 302.18 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9691/47780 [00:32<01:47, 353.39 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9220/47780 [00:32<01:47, 358.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9153/47780 [00:32<01:50, 350.07 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9347/47780 [00:32<01:46, 359.24 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9446/47780 [00:32<02:08, 297.77 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9201/47780 [00:32<01:39, 387.51 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9257/47780 [00:32<01:50, 349.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9727/47780 [00:32<01:54, 332.78 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9384/47780 [00:32<01:48, 354.28 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9478/47780 [00:32<02:06, 303.89 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9242/47780 [00:32<01:38, 389.45 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9293/47780 [00:32<01:52, 341.39 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9762/47780 [00:32<02:01, 313.28 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9425/47780 [00:32<01:44, 366.21 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8453/47780 [00:32<01:44, 376.80 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9509/47780 [00:32<02:13, 285.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9282/47780 [00:32<01:40, 382.87 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9329/47780 [00:32<01:57, 328.53 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9794/47780 [00:32<02:01, 312.02 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9462/47780 [00:32<01:44, 366.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9539/47780 [00:32<02:14, 283.56 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9321/47780 [00:32<01:44, 368.43 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9363/47780 [00:32<01:55, 331.38 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9829/47780 [00:32<02:02, 308.91 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9499/47780 [00:32<01:53, 337.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9571/47780 [00:32<02:11, 291.28 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9359/47780 [00:32<01:48, 353.96 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9397/47780 [00:32<01:58, 323.21 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9871/47780 [00:32<01:52, 335.51 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9601/47780 [00:32<02:11, 289.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9534/47780 [00:32<01:59, 319.44 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9906/47780 [00:32<01:55, 328.56 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9395/47780 [00:32<01:57, 327.92 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9430/47780 [00:32<02:08, 299.60 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9640/47780 [00:32<02:01, 314.36 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9570/47780 [00:32<01:58, 323.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8561/47780 [00:32<01:56, 336.94 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9943/47780 [00:33<01:51, 339.79 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9430/47780 [00:32<01:58, 323.77 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9462/47780 [00:32<02:10, 294.19 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9676/47780 [00:33<01:56, 327.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9608/47780 [00:33<01:52, 338.89 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8644/47780 [00:33<01:47, 364.01 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9980/47780 [00:33<01:49, 344.75 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9474/47780 [00:33<01:47, 355.10 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9492/47780 [00:33<02:09, 295.55 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9709/47780 [00:33<01:57, 324.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9644/47780 [00:33<01:54, 333.58 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 3/47780 [00:33<146:43:27, 11.06s/ examples]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9523/47780 [00:33<02:08, 296.67 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10015/47780 [00:33<01:55, 327.35 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9512/47780 [00:33<01:50, 346.55 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9744/47780 [00:33<01:58, 321.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9684/47780 [00:33<01:50, 344.55 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8720/47780 [00:33<01:46, 367.91 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9779/47780 [00:33<01:56, 325.65 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10051/47780 [00:33<01:55, 325.71 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9553/47780 [00:33<02:15, 283.10 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 16/47780 [00:33<20:32:14,  1.55s/ examples]
Tokenizing train dataset (num_proc=32):  20%|██        | 9719/47780 [00:33<01:50, 345.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9548/47780 [00:33<01:59, 318.66 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9585/47780 [00:33<02:10, 291.76 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10085/47780 [00:33<01:58, 319.09 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9762/47780 [00:33<01:43, 366.10 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9812/47780 [00:33<02:04, 305.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9595/47780 [00:33<01:47, 354.81 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8785/47780 [00:33<01:50, 352.81 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9622/47780 [00:33<02:01, 313.49 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10120/47780 [00:33<01:54, 327.58 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9845/47780 [00:33<02:01, 312.26 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9799/47780 [00:33<01:49, 347.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9634/47780 [00:33<01:47, 356.36 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9654/47780 [00:33<02:04, 305.28 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9881/47780 [00:33<01:58, 318.74 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10154/47780 [00:33<02:03, 305.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9674/47780 [00:33<01:43, 366.83 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9686/47780 [00:33<02:03, 309.46 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8841/47780 [00:33<02:02, 318.85 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9923/47780 [00:33<01:48, 347.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10199/47780 [00:33<01:49, 343.94 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9712/47780 [00:33<01:55, 330.85 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9834/47780 [00:33<02:37, 240.36 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9724/47780 [00:33<01:56, 326.32 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8920/47780 [00:33<01:42, 377.44 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9965/47780 [00:33<01:42, 368.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10234/47780 [00:33<01:50, 338.88 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9748/47780 [00:33<01:55, 328.67 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9757/47780 [00:33<02:00, 316.22 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10005/47780 [00:33<01:42, 369.22 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9863/47780 [00:33<02:44, 230.77 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8974/47780 [00:33<01:39, 388.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10281/47780 [00:34<01:40, 373.21 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9782/47780 [00:33<01:54, 331.62 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9792/47780 [00:34<01:57, 322.12 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9982/47780 [00:34<01:26, 435.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10043/47780 [00:34<01:45, 358.84 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10319/47780 [00:34<01:46, 351.02 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9029/47780 [00:34<01:39, 389.26 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9817/47780 [00:34<01:52, 336.46 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9832/47780 [00:34<01:55, 329.40 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10081/47780 [00:34<01:47, 350.73 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10360/47780 [00:34<01:42, 365.07 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10034/47780 [00:34<01:29, 419.95 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9857/47780 [00:34<01:48, 350.74 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9077/47780 [00:34<01:42, 376.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9865/47780 [00:34<01:59, 318.52 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10117/47780 [00:34<01:49, 344.48 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10403/47780 [00:34<01:39, 377.18 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10082/47780 [00:34<01:33, 403.53 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7453/47780 [00:34<05:32, 121.38 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9121/47780 [00:34<01:43, 372.71 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9893/47780 [00:34<02:04, 304.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9897/47780 [00:34<02:01, 311.95 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10442/47780 [00:34<01:42, 364.26 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10152/47780 [00:34<01:56, 324.08 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10127/47780 [00:34<01:34, 398.82 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7774/47780 [00:34<03:29, 191.34 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9164/47780 [00:34<01:44, 369.12 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9942/47780 [00:34<01:51, 338.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9929/47780 [00:34<02:01, 311.01 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10185/47780 [00:34<01:57, 319.08 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10479/47780 [00:34<01:53, 329.24 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10170/47780 [00:34<01:36, 391.67 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7977/47780 [00:34<02:40, 247.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9970/47780 [00:34<01:52, 336.46 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9978/47780 [00:34<01:55, 327.29 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9205/47780 [00:34<01:47, 357.92 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10218/47780 [00:34<01:59, 315.14 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8182/47780 [00:34<02:01, 324.85 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10515/47780 [00:34<01:55, 323.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10211/47780 [00:34<01:39, 377.12 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10013/47780 [00:34<01:54, 328.63 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9243/47780 [00:34<01:49, 350.70 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10005/47780 [00:34<02:05, 301.30 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8463/47780 [00:34<01:24, 465.27 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10250/47780 [00:34<02:14, 278.87 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10257/47780 [00:34<01:34, 398.39 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10548/47780 [00:34<01:59, 312.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   0%|          | 26/47780 [00:34<11:30:12,  1.15 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10049/47780 [00:34<01:56, 324.26 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10047/47780 [00:34<01:53, 332.84 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9280/47780 [00:34<01:54, 335.62 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10584/47780 [00:34<01:54, 324.92 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10295/47780 [00:34<01:58, 316.84 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10299/47780 [00:34<01:34, 395.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8758/47780 [00:34<01:00, 643.10 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10082/47780 [00:34<01:56, 322.85 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 72/47780 [00:34<2:46:11,  4.78 examples/s] 
Tokenizing train dataset (num_proc=32):  21%|██        | 10085/47780 [00:34<01:49, 345.70 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9316/47780 [00:34<01:54, 335.17 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10334/47780 [00:35<01:51, 336.12 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9203/47780 [00:34<00:38, 1008.74 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10341/47780 [00:35<01:36, 389.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10617/47780 [00:35<02:01, 305.99 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10120/47780 [00:35<01:52, 334.51 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10126/47780 [00:35<01:45, 355.96 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9363/47780 [00:35<01:44, 366.39 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10371/47780 [00:35<01:48, 345.42 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10656/47780 [00:35<01:53, 328.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10382/47780 [00:35<01:37, 382.74 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10154/47780 [00:35<01:52, 335.95 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10164/47780 [00:35<01:46, 354.55 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9401/47780 [00:35<01:43, 369.28 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10407/47780 [00:35<01:47, 346.19 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9486/47780 [00:35<00:35, 1068.98 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10422/47780 [00:35<01:37, 383.22 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10690/47780 [00:35<01:56, 317.72 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10189/47780 [00:35<01:53, 332.31 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9440/47780 [00:35<01:43, 371.56 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10207/47780 [00:35<01:42, 367.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10444/47780 [00:35<01:45, 352.99 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10731/47780 [00:35<01:49, 339.49 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10461/47780 [00:35<01:42, 364.35 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10223/47780 [00:35<01:57, 319.86 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9479/47780 [00:35<01:45, 364.46 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10249/47780 [00:35<01:43, 363.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10480/47780 [00:35<01:51, 335.22 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10766/47780 [00:35<01:48, 342.13 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10501/47780 [00:35<01:42, 362.65 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10256/47780 [00:35<02:00, 312.22 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9516/47780 [00:35<01:44, 365.57 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10286/47780 [00:35<01:45, 355.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10517/47780 [00:35<01:48, 344.91 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10801/47780 [00:35<01:48, 340.33 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10544/47780 [00:35<01:38, 377.05 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10296/47780 [00:35<01:52, 332.99 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9553/47780 [00:35<01:45, 363.17 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10323/47780 [00:35<01:46, 352.10 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10554/47780 [00:35<01:45, 352.05 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 91/47780 [00:35<2:03:46,  6.42 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10836/47780 [00:35<01:49, 338.04 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10582/47780 [00:35<01:39, 372.66 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10333/47780 [00:35<01:49, 343.38 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9591/47780 [00:35<01:44, 363.87 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10359/47780 [00:35<01:46, 350.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10590/47780 [00:35<01:49, 338.60 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10877/47780 [00:35<01:44, 352.18 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10621/47780 [00:35<01:41, 366.10 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10372/47780 [00:35<01:47, 348.92 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9636/47780 [00:35<01:39, 384.05 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10412/47780 [00:35<01:38, 379.84 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10625/47780 [00:35<01:52, 330.27 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10917/47780 [00:35<01:41, 363.43 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10658/47780 [00:35<01:43, 357.15 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10409/47780 [00:35<01:47, 347.45 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9680/47780 [00:35<01:37, 389.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10451/47780 [00:35<01:38, 377.54 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10660/47780 [00:35<01:50, 334.68 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10954/47780 [00:36<01:41, 363.43 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9723/47780 [00:35<00:56, 676.85 examples/s] 
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10694/47780 [00:36<01:47, 344.56 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9731/47780 [00:35<01:29, 424.21 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10444/47780 [00:35<01:53, 328.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10489/47780 [00:36<01:40, 370.87 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10695/47780 [00:36<01:49, 337.16 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10991/47780 [00:36<01:44, 353.14 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10736/47780 [00:36<01:41, 365.46 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10478/47780 [00:36<01:52, 331.94 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9774/47780 [00:36<01:39, 383.05 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10526/47780 [00:36<01:47, 346.06 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10730/47780 [00:36<01:54, 322.30 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11029/47780 [00:36<01:41, 360.72 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10515/47780 [00:36<01:49, 339.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10773/47780 [00:36<01:50, 335.52 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9815/47780 [00:36<01:41, 374.20 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10763/47780 [00:36<01:54, 324.39 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10564/47780 [00:36<01:45, 352.47 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11066/47780 [00:36<01:43, 355.29 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 112/47780 [00:36<1:31:01,  8.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10825/47780 [00:36<01:36, 382.15 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10604/47780 [00:36<01:42, 361.83 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9854/47780 [00:36<01:44, 362.31 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10796/47780 [00:36<01:58, 311.48 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11102/47780 [00:36<01:53, 322.97 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10551/47780 [00:36<02:18, 268.18 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9899/47780 [00:36<01:05, 578.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10864/47780 [00:36<01:40, 368.03 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9891/47780 [00:36<01:49, 346.06 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10641/47780 [00:36<01:48, 341.10 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10828/47780 [00:36<02:02, 300.68 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11136/47780 [00:36<01:54, 320.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10581/47780 [00:36<02:20, 264.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10902/47780 [00:36<01:42, 359.43 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10678/47780 [00:36<01:46, 348.83 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9926/47780 [00:36<01:50, 343.02 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10859/47780 [00:36<02:07, 288.85 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11169/47780 [00:36<01:54, 319.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10647/47780 [00:36<01:43, 357.24 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10951/47780 [00:36<01:34, 391.14 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9973/47780 [00:36<01:41, 374.30 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10714/47780 [00:36<01:48, 340.55 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10899/47780 [00:36<01:58, 311.94 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11202/47780 [00:36<01:58, 308.85 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10992/47780 [00:36<01:34, 387.56 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10686/47780 [00:36<01:53, 328.03 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10034/47780 [00:36<01:12, 519.09 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10011/47780 [00:36<01:44, 363.06 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10749/47780 [00:36<01:52, 328.04 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10931/47780 [00:36<02:00, 305.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11242/47780 [00:36<01:51, 326.74 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11033/47780 [00:36<01:35, 385.30 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10721/47780 [00:36<01:54, 323.92 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10048/47780 [00:36<01:47, 349.97 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10783/47780 [00:36<01:55, 320.16 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10963/47780 [00:36<02:01, 303.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11284/47780 [00:37<01:43, 352.70 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11074/47780 [00:37<01:33, 392.09 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10086/47780 [00:36<01:45, 358.16 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10755/47780 [00:37<02:03, 300.45 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10822/47780 [00:37<01:49, 336.60 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10995/47780 [00:37<02:00, 304.86 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11320/47780 [00:37<01:46, 342.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10142/47780 [00:37<01:16, 494.24 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11115/47780 [00:37<01:37, 375.95 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10791/47780 [00:37<01:57, 315.22 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10857/47780 [00:37<01:49, 337.82 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11031/47780 [00:37<01:54, 320.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11361/47780 [00:37<01:42, 354.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10123/47780 [00:37<01:58, 317.45 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11157/47780 [00:37<01:35, 383.90 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10824/47780 [00:37<01:59, 309.12 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10891/47780 [00:37<01:52, 327.14 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10228/47780 [00:37<01:16, 489.47 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11064/47780 [00:37<01:57, 312.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11399/47780 [00:37<01:41, 357.54 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10156/47780 [00:37<02:04, 302.76 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11196/47780 [00:37<01:37, 376.38 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 134/47780 [00:37<1:13:43, 10.77 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11100/47780 [00:37<01:52, 325.10 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10926/47780 [00:37<01:53, 325.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11443/47780 [00:37<01:35, 380.79 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10856/47780 [00:37<02:12, 279.60 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10221/47780 [00:37<01:39, 377.28 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11234/47780 [00:37<01:37, 373.64 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10302/47780 [00:37<01:17, 484.42 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10962/47780 [00:37<01:51, 331.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11486/47780 [00:37<01:31, 394.93 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 186/47780 [00:37<35:54, 22.09 examples/s]  
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11133/47780 [00:37<02:01, 302.75 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10898/47780 [00:37<01:56, 315.35 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11272/47780 [00:37<01:37, 374.42 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10261/47780 [00:37<01:40, 371.57 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10368/47780 [00:37<01:17, 484.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11528/47780 [00:37<01:31, 396.83 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10996/47780 [00:37<01:59, 307.87 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10931/47780 [00:37<02:01, 303.00 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11310/47780 [00:37<01:37, 372.98 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11164/47780 [00:37<02:14, 272.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10300/47780 [00:37<01:41, 368.64 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10429/47780 [00:37<01:19, 471.84 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11046/47780 [00:37<01:45, 346.58 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10963/47780 [00:37<02:02, 300.62 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11568/47780 [00:37<01:42, 352.79 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11210/47780 [00:37<01:56, 314.37 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11349/47780 [00:37<01:41, 359.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10341/47780 [00:37<01:43, 360.32 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11088/47780 [00:37<01:42, 358.87 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10994/47780 [00:37<02:02, 300.38 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11243/47780 [00:37<01:54, 318.24 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11386/47780 [00:37<01:41, 359.30 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11606/47780 [00:37<01:49, 331.79 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10484/47780 [00:37<01:24, 439.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10384/47780 [00:37<01:39, 375.19 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11128/47780 [00:37<01:40, 366.21 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11029/47780 [00:37<01:57, 311.57 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11277/47780 [00:37<01:54, 317.90 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11423/47780 [00:37<01:43, 350.59 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11641/47780 [00:38<01:49, 329.97 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10422/47780 [00:37<01:42, 363.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10533/47780 [00:37<01:28, 420.90 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11168/47780 [00:38<01:38, 371.54 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11062/47780 [00:38<01:58, 308.92 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11459/47780 [00:38<01:45, 345.84 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11675/47780 [00:38<01:50, 325.72 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10469/47780 [00:38<01:35, 389.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11310/47780 [00:38<02:08, 283.19 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10578/47780 [00:38<01:32, 404.26 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11207/47780 [00:38<01:38, 372.03 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11098/47780 [00:38<01:54, 319.84 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11506/47780 [00:38<01:36, 376.82 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10512/47780 [00:38<01:35, 392.05 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11709/47780 [00:38<01:57, 306.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11346/47780 [00:38<02:02, 296.86 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10620/47780 [00:38<01:31, 407.47 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11247/47780 [00:38<01:36, 379.95 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11131/47780 [00:38<01:53, 321.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11741/47780 [00:38<01:58, 303.35 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11386/47780 [00:38<01:53, 320.80 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11544/47780 [00:38<01:48, 335.43 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10553/47780 [00:38<01:42, 364.25 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11164/47780 [00:38<01:53, 321.26 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10663/47780 [00:38<01:36, 384.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11286/47780 [00:38<01:44, 350.84 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11783/47780 [00:38<01:50, 324.45 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10593/47780 [00:38<01:41, 365.94 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11204/47780 [00:38<01:47, 340.21 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10704/47780 [00:38<01:35, 386.87 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11579/47780 [00:38<02:07, 284.83 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11322/47780 [00:38<01:50, 329.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11420/47780 [00:38<02:22, 255.57 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11819/47780 [00:38<01:47, 334.15 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10643/47780 [00:38<01:32, 402.62 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11246/47780 [00:38<01:41, 361.40 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10745/47780 [00:38<01:35, 388.82 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11652/47780 [00:38<01:33, 384.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11357/47780 [00:38<01:50, 329.87 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11859/47780 [00:38<01:42, 349.57 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11449/47780 [00:38<02:21, 256.39 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10684/47780 [00:38<01:37, 380.39 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11290/47780 [00:38<01:39, 367.79 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10786/47780 [00:38<01:35, 386.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11694/47780 [00:38<01:32, 389.98 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11391/47780 [00:38<01:55, 315.02 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11895/47780 [00:38<01:42, 351.71 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 204/47780 [00:38<39:44, 19.96 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11533/47780 [00:38<01:32, 393.03 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10723/47780 [00:38<01:39, 373.33 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11336/47780 [00:38<01:33, 391.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10825/47780 [00:38<01:41, 363.58 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11424/47780 [00:38<01:55, 315.80 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 261/47780 [00:38<21:13, 37.32 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11736/47780 [00:38<01:41, 356.50 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11576/47780 [00:38<01:33, 386.20 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11932/47780 [00:38<01:47, 333.11 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10762/47780 [00:38<01:41, 366.13 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11382/47780 [00:38<01:30, 401.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10862/47780 [00:38<01:42, 361.54 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11778/47780 [00:38<01:37, 371.04 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11456/47780 [00:38<02:02, 297.42 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11969/47780 [00:39<01:45, 340.32 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11617/47780 [00:38<01:38, 365.84 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10800/47780 [00:38<01:46, 346.58 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10900/47780 [00:39<01:42, 358.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11423/47780 [00:38<01:40, 361.94 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12010/47780 [00:39<01:40, 355.96 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11492/47780 [00:39<02:02, 295.04 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11656/47780 [00:39<01:39, 361.31 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11818/47780 [00:39<01:45, 340.57 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10847/47780 [00:39<01:38, 376.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10936/47780 [00:39<01:45, 347.88 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11460/47780 [00:39<01:53, 319.69 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11526/47780 [00:39<01:58, 305.05 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12046/47780 [00:39<01:49, 327.00 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10886/47780 [00:39<01:39, 371.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11695/47780 [00:39<01:44, 346.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10977/47780 [00:39<01:43, 357.09 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11856/47780 [00:39<01:55, 312.33 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11500/47780 [00:39<01:47, 336.81 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11561/47780 [00:39<01:57, 309.35 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12080/47780 [00:39<01:52, 317.13 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11732/47780 [00:39<01:43, 348.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10924/47780 [00:39<01:41, 361.83 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11889/47780 [00:39<01:54, 313.81 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11018/47780 [00:39<01:42, 357.64 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11597/47780 [00:39<01:53, 319.87 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11536/47780 [00:39<01:54, 316.35 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12113/47780 [00:39<01:52, 316.64 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11768/47780 [00:39<01:44, 345.06 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10963/47780 [00:39<01:40, 365.96 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11058/47780 [00:39<01:42, 359.61 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11922/47780 [00:39<01:59, 300.40 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11636/47780 [00:39<01:52, 321.48 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11573/47780 [00:39<01:49, 329.90 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12149/47780 [00:39<01:49, 325.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11811/47780 [00:39<01:37, 368.01 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11002/47780 [00:39<01:44, 351.21 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11096/47780 [00:39<01:41, 360.62 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11953/47780 [00:39<02:01, 295.82 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12185/47780 [00:39<01:46, 335.01 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11676/47780 [00:39<01:47, 335.69 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11849/47780 [00:39<01:38, 363.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11607/47780 [00:39<01:58, 306.06 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11043/47780 [00:39<01:40, 365.12 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11133/47780 [00:39<01:41, 359.88 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11985/47780 [00:39<02:02, 292.92 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12219/47780 [00:39<01:48, 329.07 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11715/47780 [00:39<01:45, 342.44 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11647/47780 [00:39<01:50, 327.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11886/47780 [00:39<01:42, 351.41 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11081/47780 [00:39<01:41, 361.11 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11171/47780 [00:39<01:42, 357.31 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12015/47780 [00:39<02:02, 292.20 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12259/47780 [00:39<01:41, 349.12 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11755/47780 [00:39<01:42, 351.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11928/47780 [00:39<01:37, 368.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11683/47780 [00:39<01:49, 328.49 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11123/47780 [00:39<01:38, 373.44 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11217/47780 [00:39<01:35, 382.36 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12060/47780 [00:39<01:47, 331.35 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12298/47780 [00:40<01:39, 356.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11793/47780 [00:39<01:41, 355.38 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11720/47780 [00:39<01:48, 333.18 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11161/47780 [00:39<01:37, 374.96 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11967/47780 [00:39<01:43, 346.90 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11257/47780 [00:39<01:35, 382.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12334/47780 [00:40<01:43, 341.88 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12095/47780 [00:40<02:05, 283.45 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11200/47780 [00:40<01:37, 375.35 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11829/47780 [00:40<01:50, 326.69 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12008/47780 [00:40<01:42, 348.83 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11754/47780 [00:40<01:58, 304.77 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11296/47780 [00:40<01:44, 348.97 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12372/47780 [00:40<01:42, 344.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12140/47780 [00:40<01:49, 324.63 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11238/47780 [00:40<01:40, 364.15 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11873/47780 [00:40<01:43, 346.51 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11786/47780 [00:40<02:00, 299.35 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12044/47780 [00:40<01:48, 330.39 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11332/47780 [00:40<01:44, 348.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12419/47780 [00:40<01:34, 372.26 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12175/47780 [00:40<01:49, 324.49 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11275/47780 [00:40<01:41, 361.12 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11908/47780 [00:40<01:45, 339.60 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 287/47780 [00:40<26:49, 29.51 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11825/47780 [00:40<01:53, 316.87 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11369/47780 [00:40<01:43, 350.35 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12078/47780 [00:40<01:53, 314.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12457/47780 [00:40<01:36, 365.72 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12209/47780 [00:40<01:50, 321.71 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11316/47780 [00:40<01:39, 367.18 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11944/47780 [00:40<01:44, 341.76 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 370/47780 [00:40<13:19, 59.27 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11858/47780 [00:40<01:52, 320.43 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11414/47780 [00:40<01:37, 372.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12110/47780 [00:40<01:54, 311.08 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12494/47780 [00:40<01:39, 354.81 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11358/47780 [00:40<01:35, 382.22 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12243/47780 [00:40<01:54, 309.37 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11979/47780 [00:40<01:52, 319.49 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11894/47780 [00:40<01:49, 327.99 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11452/47780 [00:40<01:37, 372.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12151/47780 [00:40<01:47, 330.76 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12530/47780 [00:40<01:42, 344.83 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11397/47780 [00:40<01:37, 373.63 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12281/47780 [00:40<01:51, 318.51 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11928/47780 [00:40<01:49, 327.56 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12019/47780 [00:40<01:47, 333.71 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11491/47780 [00:40<01:38, 368.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12185/47780 [00:40<01:47, 330.68 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12567/47780 [00:40<01:41, 348.33 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12317/47780 [00:40<01:48, 326.13 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11435/47780 [00:40<01:40, 360.82 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11961/47780 [00:40<01:50, 324.48 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11530/47780 [00:40<01:38, 366.46 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12054/47780 [00:40<01:56, 307.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12219/47780 [00:40<01:51, 318.05 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12603/47780 [00:40<01:40, 351.31 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12352/47780 [00:40<01:46, 331.75 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11472/47780 [00:40<01:40, 359.61 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11994/47780 [00:40<01:51, 322.31 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12088/47780 [00:40<01:53, 314.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12251/47780 [00:40<01:53, 312.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11567/47780 [00:40<01:48, 334.04 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11513/47780 [00:40<01:37, 373.84 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12639/47780 [00:41<01:47, 326.61 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12387/47780 [00:40<01:49, 323.38 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12030/47780 [00:40<01:48, 329.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12122/47780 [00:40<01:51, 321.03 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11602/47780 [00:40<01:47, 337.56 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12283/47780 [00:41<01:55, 306.54 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12420/47780 [00:41<01:51, 318.51 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12673/47780 [00:41<01:52, 310.74 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12064/47780 [00:41<01:54, 310.98 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12155/47780 [00:41<01:54, 311.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11637/47780 [00:41<01:46, 340.74 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12314/47780 [00:41<01:56, 304.14 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11551/47780 [00:41<02:00, 299.55 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12456/47780 [00:41<01:47, 329.87 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12705/47780 [00:41<01:56, 299.95 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12101/47780 [00:41<01:50, 323.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12193/47780 [00:41<01:48, 327.17 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11673/47780 [00:41<01:45, 342.60 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12349/47780 [00:41<01:51, 317.08 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11627/47780 [00:41<01:27, 413.68 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12490/47780 [00:41<01:47, 328.28 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12751/47780 [00:41<01:42, 342.94 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12134/47780 [00:41<01:55, 308.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12226/47780 [00:41<01:49, 324.27 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11718/47780 [00:41<01:37, 369.16 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12381/47780 [00:41<01:53, 310.69 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11673/47780 [00:41<01:28, 408.34 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12523/47780 [00:41<01:52, 314.56 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12787/47780 [00:41<01:42, 340.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12169/47780 [00:41<01:51, 319.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12259/47780 [00:41<01:50, 321.80 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12422/47780 [00:41<01:44, 339.18 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11756/47780 [00:41<01:45, 340.46 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11717/47780 [00:41<01:35, 377.22 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12555/47780 [00:41<01:52, 312.86 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12823/47780 [00:41<01:44, 333.91 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12209/47780 [00:41<01:44, 340.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12297/47780 [00:41<01:45, 335.04 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12457/47780 [00:41<01:45, 334.62 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11791/47780 [00:41<01:48, 331.87 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12587/47780 [00:41<01:54, 307.54 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11758/47780 [00:41<01:37, 370.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12867/47780 [00:41<01:36, 360.55 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12342/47780 [00:41<01:38, 359.84 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12246/47780 [00:41<01:48, 328.23 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12491/47780 [00:41<01:47, 328.40 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11834/47780 [00:41<01:42, 351.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12618/47780 [00:41<02:00, 291.63 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12283/47780 [00:41<01:44, 339.83 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11797/47780 [00:41<01:43, 346.48 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12379/47780 [00:41<01:38, 358.24 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12904/47780 [00:41<01:43, 335.84 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12525/47780 [00:41<01:49, 321.74 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11876/47780 [00:41<01:37, 366.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12655/47780 [00:41<01:53, 310.41 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12415/47780 [00:41<01:39, 354.76 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12318/47780 [00:41<01:45, 335.12 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12563/47780 [00:41<01:44, 337.78 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12939/47780 [00:41<01:50, 316.31 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11918/47780 [00:41<01:33, 381.56 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12688/47780 [00:41<01:52, 312.39 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12352/47780 [00:41<01:46, 332.47 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12455/47780 [00:41<01:39, 355.87 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12598/47780 [00:41<01:49, 322.77 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11833/47780 [00:41<02:20, 256.35 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11958/47780 [00:41<01:33, 381.81 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12972/47780 [00:42<02:03, 282.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12721/47780 [00:42<01:51, 313.80 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12495/47780 [00:42<01:37, 362.95 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12387/47780 [00:42<01:49, 322.42 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 407/47780 [00:42<18:41, 42.25 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11913/47780 [00:42<01:36, 370.56 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12001/47780 [00:42<01:31, 392.00 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13010/47780 [00:42<01:53, 305.22 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12631/47780 [00:42<02:04, 281.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12757/47780 [00:42<01:48, 323.35 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12537/47780 [00:42<01:33, 375.23 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12422/47780 [00:42<01:50, 319.92 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 577/47780 [00:42<07:24, 106.09 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12041/47780 [00:42<01:34, 376.75 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11959/47780 [00:42<01:42, 348.93 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13042/47780 [00:42<01:57, 296.41 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12711/47780 [00:42<01:25, 409.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12791/47780 [00:42<01:49, 320.73 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12455/47780 [00:42<01:53, 312.35 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12575/47780 [00:42<01:41, 345.61 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12080/47780 [00:42<01:43, 344.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12831/47780 [00:42<01:41, 343.21 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13073/47780 [00:42<02:01, 285.17 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12000/47780 [00:42<01:44, 341.45 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12755/47780 [00:42<01:29, 390.23 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12498/47780 [00:42<01:42, 345.09 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12610/47780 [00:42<01:49, 322.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12120/47780 [00:42<01:40, 356.45 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12866/47780 [00:42<01:45, 330.11 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13102/47780 [00:42<02:07, 271.64 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12535/47780 [00:42<01:41, 348.33 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12038/47780 [00:42<01:52, 317.49 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12801/47780 [00:42<01:35, 368.06 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12650/47780 [00:42<01:46, 328.98 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12910/47780 [00:42<01:39, 349.46 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12157/47780 [00:42<01:48, 326.88 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13148/47780 [00:42<01:51, 311.90 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12573/47780 [00:42<01:38, 357.22 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12840/47780 [00:42<01:39, 352.23 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12073/47780 [00:42<01:57, 304.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12684/47780 [00:42<01:46, 328.05 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12949/47780 [00:42<01:37, 356.86 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12203/47780 [00:42<01:39, 358.99 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12617/47780 [00:42<01:33, 377.03 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12877/47780 [00:42<01:37, 356.45 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12118/47780 [00:42<01:46, 333.68 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12719/47780 [00:42<01:45, 330.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13180/47780 [00:42<02:07, 270.68 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12987/47780 [00:42<01:37, 355.36 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12240/47780 [00:42<01:41, 350.15 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12655/47780 [00:42<01:40, 348.99 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12759/47780 [00:42<01:40, 349.94 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13220/47780 [00:42<01:54, 302.62 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12914/47780 [00:42<01:41, 342.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12156/47780 [00:42<01:46, 335.20 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13024/47780 [00:42<01:37, 355.48 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12280/47780 [00:42<01:38, 360.32 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12691/47780 [00:42<01:45, 333.63 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12795/47780 [00:42<01:41, 345.24 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12949/47780 [00:42<01:42, 340.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13252/47780 [00:43<01:55, 297.83 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12191/47780 [00:42<01:49, 325.31 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13060/47780 [00:42<01:38, 351.45 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12318/47780 [00:42<01:42, 346.22 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12725/47780 [00:43<01:46, 328.46 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12988/47780 [00:43<01:40, 346.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13285/47780 [00:43<01:53, 303.15 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12229/47780 [00:43<01:46, 332.97 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12830/47780 [00:43<01:53, 307.96 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13101/47780 [00:43<01:35, 361.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12354/47780 [00:43<01:46, 332.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13024/47780 [00:43<01:41, 342.88 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12759/47780 [00:43<01:52, 310.97 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13317/47780 [00:43<01:55, 297.79 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12266/47780 [00:43<01:45, 335.63 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12863/47780 [00:43<01:52, 310.49 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13138/47780 [00:43<01:41, 340.39 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12388/47780 [00:43<01:48, 327.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13066/47780 [00:43<01:36, 360.30 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12793/47780 [00:43<01:50, 315.24 examples/s]
Tokenizing train dataset (num_proc=32):   1%|▏         | 637/47780 [00:43<09:02, 86.87 examples/s] 
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12302/47780 [00:43<01:44, 338.62 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13348/47780 [00:43<01:59, 288.61 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12904/47780 [00:43<01:44, 333.98 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13173/47780 [00:43<01:41, 339.33 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12424/47780 [00:43<01:46, 332.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13108/47780 [00:43<01:32, 373.25 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12827/47780 [00:43<01:52, 311.82 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13383/47780 [00:43<01:53, 302.09 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12942/47780 [00:43<01:40, 346.51 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12338/47780 [00:43<01:48, 326.74 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 773/47780 [00:43<05:24, 144.96 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13209/47780 [00:43<01:44, 329.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12461/47780 [00:43<01:46, 331.86 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13146/47780 [00:43<01:33, 370.20 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12861/47780 [00:43<01:49, 319.39 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13417/47780 [00:43<01:49, 312.53 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12980/47780 [00:43<01:37, 355.94 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12371/47780 [00:43<01:50, 320.28 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13243/47780 [00:43<01:45, 325.85 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12495/47780 [00:43<01:50, 319.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13184/47780 [00:43<01:32, 372.76 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13454/47780 [00:43<01:44, 328.77 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12405/47780 [00:43<01:49, 322.20 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13016/47780 [00:43<01:43, 337.49 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12894/47780 [00:43<02:00, 289.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13276/47780 [00:43<01:53, 302.93 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12528/47780 [00:43<01:54, 308.80 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13488/47780 [00:43<01:47, 317.58 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13222/47780 [00:43<01:42, 336.29 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13051/47780 [00:43<01:42, 337.36 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12439/47780 [00:43<01:51, 316.24 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12926/47780 [00:43<01:57, 296.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13312/47780 [00:43<01:49, 315.30 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12562/47780 [00:43<01:54, 307.44 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13523/47780 [00:43<01:46, 322.96 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13089/47780 [00:43<01:40, 345.94 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13263/47780 [00:43<01:40, 344.96 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12961/47780 [00:43<01:53, 305.94 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12471/47780 [00:43<02:02, 289.02 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13344/47780 [00:43<01:55, 296.91 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12597/47780 [00:43<01:51, 315.88 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13556/47780 [00:43<01:46, 321.27 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13124/47780 [00:43<01:39, 346.74 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13311/47780 [00:43<01:32, 373.87 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12994/47780 [00:43<01:52, 310.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12501/47780 [00:43<02:02, 288.38 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12629/47780 [00:43<01:50, 316.96 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13375/47780 [00:44<01:59, 287.54 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13589/47780 [00:44<01:50, 309.48 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13160/47780 [00:43<01:43, 335.36 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13027/47780 [00:43<01:51, 310.97 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13349/47780 [00:44<01:37, 352.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12531/47780 [00:44<02:02, 288.43 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12668/47780 [00:44<01:47, 326.57 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13404/47780 [00:44<02:01, 282.07 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13621/47780 [00:44<01:52, 302.55 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13059/47780 [00:44<01:53, 306.48 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13391/47780 [00:44<01:32, 370.20 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12561/47780 [00:44<02:01, 289.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13195/47780 [00:44<01:51, 310.80 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13433/47780 [00:44<02:03, 278.70 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12709/47780 [00:44<01:45, 331.43 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13664/47780 [00:44<01:43, 330.85 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13090/47780 [00:44<01:54, 304.28 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13229/47780 [00:44<01:48, 318.69 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12593/47780 [00:44<01:59, 293.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13429/47780 [00:44<01:38, 349.55 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13464/47780 [00:44<01:59, 287.33 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13699/47780 [00:44<01:41, 336.23 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12744/47780 [00:44<01:48, 322.28 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13121/47780 [00:44<01:57, 295.72 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12633/47780 [00:44<01:49, 320.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13262/47780 [00:44<01:49, 315.00 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13465/47780 [00:44<01:45, 324.57 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12780/47780 [00:44<01:46, 329.09 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13493/47780 [00:44<02:07, 269.67 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13733/47780 [00:44<01:45, 322.06 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13156/47780 [00:44<01:53, 304.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13296/47780 [00:44<01:47, 322.01 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12666/47780 [00:44<01:56, 302.35 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13505/47780 [00:44<01:40, 340.85 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12813/47780 [00:44<01:47, 325.26 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13771/47780 [00:44<01:42, 331.41 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13197/47780 [00:44<01:43, 334.22 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13521/47780 [00:44<02:16, 250.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13329/47780 [00:44<01:51, 307.82 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12699/47780 [00:44<01:53, 309.96 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 836/47780 [00:44<07:36, 102.75 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13549/47780 [00:44<01:38, 348.72 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12851/47780 [00:44<01:42, 340.63 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13553/47780 [00:44<02:08, 266.07 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13231/47780 [00:44<01:49, 316.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13805/47780 [00:44<01:49, 309.40 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13366/47780 [00:44<01:46, 324.23 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12731/47780 [00:44<02:01, 289.60 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13591/47780 [00:44<01:32, 367.80 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1004/47780 [00:44<04:20, 179.83 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12886/47780 [00:44<01:50, 314.65 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13581/47780 [00:44<02:08, 267.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13837/47780 [00:44<01:49, 309.40 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13404/47780 [00:44<01:41, 339.78 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13266/47780 [00:44<01:50, 312.88 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13629/47780 [00:44<01:35, 359.37 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12761/47780 [00:44<02:04, 280.44 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12928/47780 [00:44<01:43, 336.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13877/47780 [00:44<01:41, 334.02 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13609/47780 [00:44<02:13, 256.22 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13439/47780 [00:44<01:47, 320.28 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13298/47780 [00:44<01:55, 298.30 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13666/47780 [00:44<01:36, 354.03 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12790/47780 [00:44<02:07, 273.92 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12973/47780 [00:44<01:36, 359.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13911/47780 [00:45<01:42, 331.99 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13636/47780 [00:45<02:11, 259.74 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13333/47780 [00:44<01:50, 312.36 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13472/47780 [00:44<01:47, 319.87 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13702/47780 [00:45<01:38, 344.30 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12819/47780 [00:45<02:11, 266.85 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13017/47780 [00:45<01:30, 382.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13946/47780 [00:45<01:40, 336.96 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13507/47780 [00:45<01:45, 326.06 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13668/47780 [00:45<02:08, 265.12 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13365/47780 [00:45<01:54, 300.78 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12846/47780 [00:45<02:10, 267.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13738/47780 [00:45<01:41, 334.13 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13981/47780 [00:45<01:41, 333.15 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13703/47780 [00:45<01:59, 285.60 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13056/47780 [00:45<01:37, 355.58 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13545/47780 [00:45<01:44, 328.43 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13402/47780 [00:45<01:48, 317.27 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12876/47780 [00:45<02:06, 276.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13772/47780 [00:45<01:50, 308.61 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14015/47780 [00:45<01:44, 323.37 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13735/47780 [00:45<01:56, 291.90 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13585/47780 [00:45<01:39, 345.38 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13093/47780 [00:45<01:40, 344.89 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12911/47780 [00:45<01:58, 294.36 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13435/47780 [00:45<02:00, 284.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13809/47780 [00:45<01:44, 324.81 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13771/47780 [00:45<01:50, 307.91 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14048/47780 [00:45<01:51, 301.42 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13620/47780 [00:45<01:40, 338.47 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12942/47780 [00:45<01:57, 295.80 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13128/47780 [00:45<01:49, 315.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13479/47780 [00:45<01:46, 322.64 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13842/47780 [00:45<01:48, 312.19 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13802/47780 [00:45<01:54, 298.03 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13658/47780 [00:45<01:39, 342.98 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14082/47780 [00:45<01:53, 296.15 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12977/47780 [00:45<01:55, 300.66 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13513/47780 [00:45<01:45, 323.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13161/47780 [00:45<01:52, 308.73 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13874/47780 [00:45<01:53, 298.35 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13832/47780 [00:45<01:53, 298.45 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13695/47780 [00:45<01:37, 350.66 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14113/47780 [00:45<01:52, 299.87 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13013/47780 [00:45<01:49, 317.29 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13193/47780 [00:45<01:51, 310.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13547/47780 [00:45<01:51, 307.51 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13731/47780 [00:45<01:36, 353.15 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13862/47780 [00:45<01:58, 285.98 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13905/47780 [00:45<01:58, 285.99 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14144/47780 [00:45<01:52, 299.11 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13226/47780 [00:45<01:49, 314.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13045/47780 [00:45<01:51, 310.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13580/47780 [00:45<01:51, 307.40 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13905/47780 [00:45<01:46, 319.45 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13937/47780 [00:45<01:55, 291.86 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13767/47780 [00:45<01:40, 339.58 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14180/47780 [00:45<01:46, 314.77 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13259/47780 [00:45<01:48, 317.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13090/47780 [00:45<01:44, 332.19 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13612/47780 [00:45<01:52, 304.21 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13967/47780 [00:45<01:56, 291.10 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14214/47780 [00:46<01:47, 313.00 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13938/47780 [00:45<01:51, 304.75 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13292/47780 [00:45<01:49, 315.29 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13802/47780 [00:45<01:47, 317.18 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1081/47780 [00:46<06:19, 123.10 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13125/47780 [00:45<01:44, 333.02 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13645/47780 [00:46<01:54, 298.16 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14250/47780 [00:46<01:45, 319.15 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13969/47780 [00:46<01:51, 303.34 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13835/47780 [00:46<01:49, 310.45 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13324/47780 [00:46<01:52, 305.72 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13997/47780 [00:46<02:08, 263.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1219/47780 [00:46<04:10, 185.59 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13159/47780 [00:46<01:49, 317.49 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13686/47780 [00:46<01:45, 321.75 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14283/47780 [00:46<01:49, 305.00 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13873/47780 [00:46<01:43, 329.17 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14048/47780 [00:46<01:43, 326.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14000/47780 [00:46<02:04, 271.64 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13355/47780 [00:46<02:00, 284.70 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13192/47780 [00:46<01:57, 293.80 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13719/47780 [00:46<01:49, 310.15 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13911/47780 [00:46<01:40, 336.36 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14314/47780 [00:46<01:51, 299.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14040/47780 [00:46<01:50, 305.42 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13384/47780 [00:46<02:02, 280.11 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14082/47780 [00:46<01:52, 300.11 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13234/47780 [00:46<01:46, 325.03 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13756/47780 [00:46<01:45, 323.16 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14355/47780 [00:46<01:41, 330.22 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13945/47780 [00:46<01:44, 322.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14072/47780 [00:46<01:50, 306.03 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13416/47780 [00:46<02:01, 283.08 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14114/47780 [00:46<01:57, 287.12 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13273/47780 [00:46<01:43, 331.94 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13789/47780 [00:46<01:58, 285.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14389/47780 [00:46<01:43, 322.05 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13980/47780 [00:46<01:44, 323.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14104/47780 [00:46<01:49, 306.19 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13450/47780 [00:46<01:55, 297.45 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14147/47780 [00:46<01:56, 289.39 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13316/47780 [00:46<01:37, 355.03 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13833/47780 [00:46<01:44, 323.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14425/47780 [00:46<01:41, 329.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14136/47780 [00:46<01:51, 303.09 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14014/47780 [00:46<01:48, 310.50 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13486/47780 [00:46<01:51, 308.20 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14188/47780 [00:46<01:44, 321.19 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13353/47780 [00:46<01:36, 355.23 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13875/47780 [00:46<01:37, 349.35 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1297/47780 [00:46<04:35, 168.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14470/47780 [00:46<01:33, 355.55 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14172/47780 [00:46<01:46, 315.97 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14051/47780 [00:46<01:45, 319.81 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14222/47780 [00:46<01:43, 322.77 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13397/47780 [00:46<01:33, 366.76 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13914/47780 [00:46<01:34, 356.83 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13517/47780 [00:46<02:13, 257.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14506/47780 [00:46<01:33, 355.81 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14206/47780 [00:46<01:47, 312.16 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14092/47780 [00:46<01:40, 333.71 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14259/47780 [00:46<01:40, 332.48 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13445/47780 [00:46<01:26, 398.49 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13957/47780 [00:46<01:29, 377.21 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13588/47780 [00:46<01:34, 362.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14542/47780 [00:47<01:34, 350.06 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14238/47780 [00:46<01:46, 314.20 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14126/47780 [00:46<01:42, 328.26 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14296/47780 [00:47<01:38, 339.30 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14003/47780 [00:46<01:24, 400.86 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13486/47780 [00:46<01:34, 363.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13627/47780 [00:47<01:35, 358.60 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14578/47780 [00:47<01:38, 337.31 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14271/47780 [00:47<01:47, 311.70 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14159/47780 [00:47<01:43, 325.10 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14331/47780 [00:47<01:37, 342.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14044/47780 [00:47<01:26, 389.83 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14303/47780 [00:47<01:46, 313.52 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14612/47780 [00:47<01:42, 323.53 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13525/47780 [00:47<01:43, 331.95 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13665/47780 [00:47<01:40, 338.82 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14375/47780 [00:47<01:30, 370.37 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14192/47780 [00:47<01:44, 320.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14085/47780 [00:47<01:26, 391.53 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14337/47780 [00:47<01:45, 318.14 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14645/47780 [00:47<01:47, 307.90 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13560/47780 [00:47<01:46, 321.22 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14413/47780 [00:47<01:31, 365.29 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13701/47780 [00:47<01:45, 324.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14225/47780 [00:47<01:46, 314.37 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14125/47780 [00:47<01:33, 359.96 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14370/47780 [00:47<01:48, 307.35 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14461/47780 [00:47<01:23, 398.28 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13593/47780 [00:47<01:46, 320.35 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14678/47780 [00:47<01:47, 307.37 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14262/47780 [00:47<01:42, 326.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13735/47780 [00:47<01:45, 321.73 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14401/47780 [00:47<01:48, 307.81 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14711/47780 [00:47<01:46, 310.30 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14296/47780 [00:47<01:41, 329.74 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14162/47780 [00:47<01:42, 326.59 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13771/47780 [00:47<01:43, 328.45 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13627/47780 [00:47<01:49, 310.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14502/47780 [00:47<01:28, 375.85 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14330/47780 [00:47<01:41, 329.74 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14198/47780 [00:47<01:40, 333.80 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13805/47780 [00:47<01:42, 331.58 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14432/47780 [00:47<01:58, 281.13 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14545/47780 [00:47<01:26, 386.13 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13661/47780 [00:47<01:49, 312.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14743/47780 [00:47<01:51, 296.09 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14367/47780 [00:47<01:39, 337.44 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14244/47780 [00:47<01:31, 366.77 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13839/47780 [00:47<01:45, 323.16 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14780/47780 [00:47<01:45, 313.32 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14461/47780 [00:47<02:00, 276.02 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13693/47780 [00:47<01:55, 295.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14584/47780 [00:47<01:34, 351.12 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14403/47780 [00:47<01:37, 343.73 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14282/47780 [00:47<01:33, 358.51 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14495/47780 [00:47<01:54, 290.35 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13874/47780 [00:47<01:44, 323.15 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14812/47780 [00:47<01:50, 299.58 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13727/47780 [00:47<01:50, 307.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14621/47780 [00:47<01:33, 355.90 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14449/47780 [00:47<01:29, 373.73 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14535/47780 [00:47<01:43, 320.05 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13907/47780 [00:47<01:49, 308.08 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13759/47780 [00:47<01:50, 307.13 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14319/47780 [00:47<01:40, 331.97 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14843/47780 [00:48<01:54, 288.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14658/47780 [00:47<01:34, 351.96 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14489/47780 [00:48<01:32, 360.19 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14568/47780 [00:48<01:44, 316.69 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13944/47780 [00:48<01:44, 324.96 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13802/47780 [00:48<01:39, 341.22 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14353/47780 [00:48<01:43, 324.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14874/47780 [00:48<01:55, 285.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14694/47780 [00:48<01:37, 339.13 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14526/47780 [00:48<01:34, 350.73 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14601/47780 [00:48<01:47, 309.81 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13837/47780 [00:48<01:38, 343.09 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13977/47780 [00:48<01:47, 314.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14395/47780 [00:48<01:35, 349.59 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14732/47780 [00:48<01:35, 347.01 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14903/47780 [00:48<01:59, 274.41 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14633/47780 [00:48<01:46, 312.42 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13884/47780 [00:48<01:29, 376.88 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14564/47780 [00:48<01:38, 336.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14431/47780 [00:48<01:37, 341.50 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14009/47780 [00:48<01:56, 291.06 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1356/47780 [00:48<07:49, 98.96 examples/s] 
Tokenizing train dataset (num_proc=32):  31%|███       | 14767/47780 [00:48<01:39, 332.91 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14931/47780 [00:48<02:03, 266.95 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14665/47780 [00:48<01:46, 310.96 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13928/47780 [00:48<01:25, 393.87 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14603/47780 [00:48<01:35, 347.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14471/47780 [00:48<01:33, 357.65 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14044/47780 [00:48<01:52, 300.71 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14958/47780 [00:48<02:03, 266.02 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14801/47780 [00:48<01:47, 307.57 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13968/47780 [00:48<01:26, 392.33 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14699/47780 [00:48<01:44, 316.16 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14649/47780 [00:48<01:28, 374.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14508/47780 [00:48<01:32, 360.51 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14991/47780 [00:48<01:57, 279.82 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14083/47780 [00:48<01:47, 314.73 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14833/47780 [00:48<01:49, 300.94 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14009/47780 [00:48<01:25, 395.70 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14733/47780 [00:48<01:43, 319.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14546/47780 [00:48<01:33, 354.56 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14688/47780 [00:48<01:34, 351.23 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15022/47780 [00:48<01:53, 288.13 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14115/47780 [00:48<01:48, 309.44 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14864/47780 [00:48<01:53, 291.12 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14049/47780 [00:48<01:25, 394.05 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14767/47780 [00:48<01:41, 325.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14582/47780 [00:48<01:33, 356.11 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14724/47780 [00:48<01:36, 342.67 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14164/47780 [00:48<01:34, 355.43 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15051/47780 [00:48<01:59, 273.27 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14800/47780 [00:48<01:41, 326.16 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14894/47780 [00:48<01:54, 287.01 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14089/47780 [00:48<01:31, 366.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14618/47780 [00:48<01:35, 347.98 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15093/47780 [00:48<01:45, 310.76 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14759/47780 [00:48<01:41, 326.59 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14201/47780 [00:48<01:36, 347.33 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14924/47780 [00:48<01:54, 287.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14833/47780 [00:48<01:47, 305.97 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14653/47780 [00:48<01:37, 338.16 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14127/47780 [00:48<01:40, 335.77 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14793/47780 [00:48<01:40, 326.69 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14237/47780 [00:48<01:38, 339.81 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15125/47780 [00:49<01:50, 296.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14953/47780 [00:49<02:01, 269.52 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14687/47780 [00:48<01:39, 333.97 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14864/47780 [00:49<01:56, 281.86 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14826/47780 [00:49<01:42, 320.09 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15155/47780 [00:49<01:49, 297.54 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14272/47780 [00:49<01:40, 334.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14162/47780 [00:49<01:52, 297.92 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14981/47780 [00:49<02:04, 264.47 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14723/47780 [00:49<01:38, 335.70 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14893/47780 [00:49<01:58, 276.70 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14875/47780 [00:49<01:29, 367.28 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15191/47780 [00:49<01:43, 315.03 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14309/47780 [00:49<01:38, 339.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14195/47780 [00:49<01:50, 303.25 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14759/47780 [00:49<01:36, 341.51 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15008/47780 [00:49<02:07, 256.94 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14925/47780 [00:49<01:54, 286.87 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14913/47780 [00:49<01:34, 347.23 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15223/47780 [00:49<01:49, 296.28 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14344/47780 [00:49<01:43, 324.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14234/47780 [00:49<01:43, 323.88 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15042/47780 [00:49<01:58, 277.29 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14794/47780 [00:49<01:40, 328.72 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14954/47780 [00:49<02:00, 272.53 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15253/47780 [00:49<01:49, 296.17 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14268/47780 [00:49<01:43, 322.91 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14949/47780 [00:49<01:39, 329.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14377/47780 [00:49<01:46, 312.59 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15077/47780 [00:49<01:49, 297.62 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14834/47780 [00:49<01:36, 341.23 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14983/47780 [00:49<01:58, 277.27 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15302/47780 [00:49<01:34, 344.50 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14302/47780 [00:49<01:42, 327.53 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14991/47780 [00:49<01:33, 350.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14417/47780 [00:49<01:42, 326.78 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15110/47780 [00:49<01:47, 303.43 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14877/47780 [00:49<01:29, 366.27 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15016/47780 [00:49<01:52, 292.07 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14336/47780 [00:49<01:41, 327.89 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15337/47780 [00:49<01:41, 320.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14451/47780 [00:49<01:42, 324.08 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15027/47780 [00:49<01:40, 327.45 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1527/47780 [00:49<06:59, 110.24 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15141/47780 [00:49<01:50, 294.83 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15046/47780 [00:49<01:51, 293.98 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14915/47780 [00:49<01:31, 361.06 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14373/47780 [00:49<01:39, 336.12 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15378/47780 [00:49<01:33, 345.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14488/47780 [00:49<01:39, 336.08 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15061/47780 [00:49<01:39, 327.42 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▎         | 1772/47780 [00:49<03:46, 203.51 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15083/47780 [00:49<01:44, 312.89 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15172/47780 [00:49<02:02, 266.13 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14407/47780 [00:49<01:42, 324.63 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14522/47780 [00:49<01:39, 333.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14952/47780 [00:49<01:48, 301.19 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15095/47780 [00:49<01:38, 330.28 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15414/47780 [00:49<01:45, 307.75 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15115/47780 [00:49<01:50, 294.37 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15202/47780 [00:49<01:58, 274.96 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14441/47780 [00:49<01:42, 326.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14563/47780 [00:49<01:33, 355.04 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15006/47780 [00:49<01:32, 355.70 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15129/47780 [00:49<01:43, 315.85 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15446/47780 [00:50<01:46, 304.06 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15145/47780 [00:49<01:50, 295.91 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15231/47780 [00:50<02:00, 270.42 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14483/47780 [00:49<01:35, 349.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14600/47780 [00:50<01:34, 351.55 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15044/47780 [00:50<01:30, 361.40 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15166/47780 [00:50<01:39, 327.30 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15178/47780 [00:50<01:47, 302.24 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15479/47780 [00:50<01:48, 298.60 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15265/47780 [00:50<01:53, 286.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14528/47780 [00:50<01:28, 374.10 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15082/47780 [00:50<01:30, 361.50 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15202/47780 [00:50<01:36, 336.35 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14636/47780 [00:50<01:47, 307.85 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15523/47780 [00:50<01:35, 336.50 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15209/47780 [00:50<01:49, 297.28 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15294/47780 [00:50<01:55, 280.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14573/47780 [00:50<01:25, 387.10 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15237/47780 [00:50<01:36, 336.44 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15120/47780 [00:50<01:37, 334.55 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15560/47780 [00:50<01:33, 345.77 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15245/47780 [00:50<01:44, 312.06 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14668/47780 [00:50<01:52, 294.17 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15323/47780 [00:50<01:59, 271.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14625/47780 [00:50<01:18, 420.51 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15272/47780 [00:50<01:36, 336.43 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15277/47780 [00:50<01:44, 310.45 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15155/47780 [00:50<01:43, 315.43 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14707/47780 [00:50<01:44, 317.43 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15596/47780 [00:50<01:39, 324.04 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15354/47780 [00:50<01:57, 276.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14668/47780 [00:50<01:19, 418.66 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15310/47780 [00:50<01:43, 312.54 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15306/47780 [00:50<01:47, 302.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15188/47780 [00:50<01:47, 302.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14744/47780 [00:50<01:50, 299.28 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15631/47780 [00:50<01:45, 304.48 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15382/47780 [00:50<02:03, 261.71 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14710/47780 [00:50<01:23, 395.57 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15344/47780 [00:50<01:41, 318.25 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15349/47780 [00:50<01:36, 336.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15222/47780 [00:50<01:44, 310.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14792/47780 [00:50<01:36, 343.13 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15667/47780 [00:50<01:42, 312.82 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15409/47780 [00:50<02:03, 261.94 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14750/47780 [00:50<01:27, 375.69 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15382/47780 [00:50<01:36, 334.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15384/47780 [00:50<01:43, 312.74 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15254/47780 [00:50<01:52, 287.89 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15699/47780 [00:50<01:43, 311.26 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14828/47780 [00:50<01:38, 335.73 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15438/47780 [00:50<02:01, 266.55 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14791/47780 [00:50<01:25, 384.78 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15420/47780 [00:50<01:32, 348.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15418/47780 [00:50<01:41, 319.98 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15290/47780 [00:50<01:48, 300.42 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15731/47780 [00:50<01:46, 299.95 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15465/47780 [00:50<02:04, 258.90 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14864/47780 [00:50<01:41, 324.87 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1866/47780 [00:50<04:55, 155.57 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14830/47780 [00:50<01:32, 354.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15456/47780 [00:50<01:41, 317.04 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15451/47780 [00:50<01:44, 309.11 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15321/47780 [00:50<01:48, 299.48 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15492/47780 [00:50<02:03, 261.93 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15762/47780 [00:51<01:47, 296.69 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2013/47780 [00:50<03:30, 217.02 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14898/47780 [00:50<01:44, 315.37 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14867/47780 [00:50<01:34, 347.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15505/47780 [00:51<01:30, 357.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15485/47780 [00:51<01:42, 314.05 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15520/47780 [00:51<02:00, 266.90 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15355/47780 [00:51<01:46, 304.39 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15797/47780 [00:51<01:42, 311.31 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14930/47780 [00:51<01:45, 310.24 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14909/47780 [00:51<01:30, 363.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15522/47780 [00:51<01:38, 326.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15542/47780 [00:51<01:33, 345.89 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15548/47780 [00:51<02:00, 267.56 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15386/47780 [00:51<01:47, 302.46 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14963/47780 [00:51<01:45, 312.21 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15829/47780 [00:51<01:54, 278.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14953/47780 [00:51<01:26, 380.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15555/47780 [00:51<01:39, 323.13 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15578/47780 [00:51<01:35, 338.52 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15594/47780 [00:51<01:40, 320.29 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15425/47780 [00:51<01:38, 326.82 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15005/47780 [00:51<01:35, 341.98 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15862/47780 [00:51<01:49, 292.40 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14992/47780 [00:51<01:27, 372.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15588/47780 [00:51<01:39, 322.91 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15635/47780 [00:51<01:32, 346.26 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15458/47780 [00:51<01:44, 309.02 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15613/47780 [00:51<01:43, 310.63 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15040/47780 [00:51<01:42, 320.42 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15030/47780 [00:51<01:27, 373.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15892/47780 [00:51<01:52, 282.43 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15671/47780 [00:51<01:32, 346.36 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15621/47780 [00:51<01:48, 296.21 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15648/47780 [00:51<01:41, 317.99 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15490/47780 [00:51<01:52, 287.65 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15082/47780 [00:51<01:35, 342.46 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15925/47780 [00:51<01:52, 283.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15068/47780 [00:51<01:34, 346.85 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15657/47780 [00:51<01:43, 310.53 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15706/47780 [00:51<01:40, 320.23 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15681/47780 [00:51<01:45, 304.31 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15520/47780 [00:51<01:53, 284.20 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15119/47780 [00:51<01:35, 342.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15956/47780 [00:51<01:54, 277.56 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15104/47780 [00:51<01:36, 339.23 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15692/47780 [00:51<01:40, 318.15 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15741/47780 [00:51<01:38, 325.82 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15714/47780 [00:51<01:45, 305.04 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15155/47780 [00:51<01:36, 339.58 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15549/47780 [00:51<01:58, 271.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15986/47780 [00:51<01:53, 281.25 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15144/47780 [00:51<01:31, 355.69 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15777/47780 [00:51<01:35, 333.51 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15725/47780 [00:51<01:45, 304.10 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15749/47780 [00:51<01:41, 317.07 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15192/47780 [00:51<01:34, 344.46 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15583/47780 [00:51<01:52, 286.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16019/47780 [00:51<01:48, 291.68 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15185/47780 [00:51<01:29, 365.10 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2104/47780 [00:51<04:24, 172.50 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15762/47780 [00:51<01:39, 322.19 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15814/47780 [00:51<01:36, 330.69 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15227/47780 [00:51<01:36, 338.25 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15620/47780 [00:51<01:44, 306.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15782/47780 [00:51<01:48, 294.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16051/47780 [00:52<01:47, 296.33 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15222/47780 [00:51<01:35, 341.39 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15795/47780 [00:52<01:39, 321.04 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15849/47780 [00:52<01:39, 321.38 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15655/47780 [00:52<01:41, 315.45 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15816/47780 [00:52<01:44, 306.60 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15261/47780 [00:52<01:38, 330.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16086/47780 [00:52<01:42, 308.10 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15257/47780 [00:52<01:36, 336.18 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15828/47780 [00:52<01:43, 309.31 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15884/47780 [00:52<01:37, 326.02 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15302/47780 [00:52<01:32, 352.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15688/47780 [00:52<01:43, 308.98 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16122/47780 [00:52<01:40, 315.70 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15849/47780 [00:52<01:50, 287.68 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15291/47780 [00:52<01:37, 333.79 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15917/47780 [00:52<01:41, 312.98 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15860/47780 [00:52<01:49, 292.34 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15721/47780 [00:52<01:42, 311.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15339/47780 [00:52<01:34, 343.17 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15880/47780 [00:52<01:48, 293.13 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16154/47780 [00:52<01:44, 302.53 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15328/47780 [00:52<01:34, 343.93 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15894/47780 [00:52<01:45, 302.48 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15754/47780 [00:52<01:41, 316.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15949/47780 [00:52<01:48, 294.63 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15374/47780 [00:52<01:34, 341.15 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15915/47780 [00:52<01:44, 305.92 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16185/47780 [00:52<01:48, 291.59 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15363/47780 [00:52<01:37, 334.15 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15925/47780 [00:52<01:45, 300.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15979/47780 [00:52<01:48, 293.64 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15786/47780 [00:52<01:44, 307.19 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15412/47780 [00:52<01:34, 340.74 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15946/47780 [00:52<01:47, 296.97 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16217/47780 [00:52<01:46, 296.72 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15403/47780 [00:52<01:31, 352.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15960/47780 [00:52<01:45, 301.51 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16009/47780 [00:52<01:51, 285.73 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15447/47780 [00:52<01:34, 343.10 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15818/47780 [00:52<01:47, 297.39 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15980/47780 [00:52<01:45, 302.44 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16247/47780 [00:52<01:48, 291.01 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15439/47780 [00:52<01:33, 346.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15997/47780 [00:52<01:40, 317.13 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15484/47780 [00:52<01:33, 347.15 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16042/47780 [00:52<01:47, 294.75 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15858/47780 [00:52<01:39, 322.29 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16025/47780 [00:52<01:32, 343.86 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16279/47780 [00:52<01:45, 299.20 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15481/47780 [00:52<01:28, 363.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2199/47780 [00:52<05:02, 150.84 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16077/47780 [00:52<01:42, 310.04 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15525/47780 [00:52<01:29, 361.21 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16030/47780 [00:52<01:43, 306.76 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15891/47780 [00:52<01:42, 310.47 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16311/47780 [00:52<01:43, 305.10 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16060/47780 [00:52<01:36, 329.95 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15518/47780 [00:52<01:31, 353.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2326/47780 [00:52<03:36, 210.08 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16118/47780 [00:52<01:34, 335.22 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16061/47780 [00:52<01:44, 304.21 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15562/47780 [00:52<01:30, 355.02 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15923/47780 [00:52<01:43, 306.78 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16342/47780 [00:53<01:46, 295.78 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15555/47780 [00:52<01:30, 358.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16095/47780 [00:52<01:39, 317.85 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16158/47780 [00:53<01:30, 349.76 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15598/47780 [00:53<01:33, 344.96 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16092/47780 [00:53<01:49, 289.40 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15954/47780 [00:53<01:44, 303.49 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16375/47780 [00:53<01:45, 299.02 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15603/47780 [00:53<01:22, 388.77 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16128/47780 [00:53<01:48, 292.46 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16196/47780 [00:53<01:33, 338.59 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15639/47780 [00:53<01:31, 351.43 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15999/47780 [00:53<01:33, 341.73 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16122/47780 [00:53<01:51, 283.21 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16406/47780 [00:53<01:46, 295.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15642/47780 [00:53<01:26, 371.80 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16158/47780 [00:53<01:55, 274.24 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15679/47780 [00:53<01:28, 363.64 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16034/47780 [00:53<01:32, 343.28 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16159/47780 [00:53<01:44, 303.91 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16231/47780 [00:53<01:36, 327.43 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16438/47780 [00:53<01:44, 299.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15680/47780 [00:53<01:27, 365.68 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16191/47780 [00:53<01:50, 285.68 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15716/47780 [00:53<01:32, 346.79 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16264/47780 [00:53<01:39, 316.58 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16468/47780 [00:53<01:45, 296.08 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16069/47780 [00:53<01:40, 316.61 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16190/47780 [00:53<01:52, 280.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15717/47780 [00:53<01:30, 355.11 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16297/47780 [00:53<01:40, 314.51 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16221/47780 [00:53<02:00, 261.23 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16231/47780 [00:53<01:40, 315.22 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16109/47780 [00:53<01:34, 335.69 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16498/47780 [00:53<01:50, 284.07 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15751/47780 [00:53<01:40, 319.45 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15760/47780 [00:53<01:27, 367.86 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16336/47780 [00:53<01:34, 334.03 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16259/47780 [00:53<01:49, 289.17 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16530/47780 [00:53<01:46, 294.07 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16267/47780 [00:53<01:38, 320.40 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15784/47780 [00:53<01:39, 322.16 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16146/47780 [00:53<01:34, 334.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15798/47780 [00:53<01:27, 367.24 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16374/47780 [00:53<01:30, 346.34 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16290/47780 [00:53<01:50, 285.35 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16560/47780 [00:53<01:46, 292.59 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16311/47780 [00:53<01:28, 353.59 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16186/47780 [00:53<01:30, 348.62 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15817/47780 [00:53<01:39, 320.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15835/47780 [00:53<01:30, 351.89 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16409/47780 [00:53<01:34, 333.64 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16330/47780 [00:53<01:39, 315.53 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16590/47780 [00:53<01:48, 287.93 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16227/47780 [00:53<01:27, 361.81 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15856/47780 [00:53<01:36, 329.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16347/47780 [00:53<01:33, 335.89 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15871/47780 [00:53<01:34, 338.72 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16367/47780 [00:53<01:35, 328.06 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16447/47780 [00:53<01:32, 339.53 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16267/47780 [00:53<01:25, 368.55 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15891/47780 [00:53<01:35, 335.08 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16628/47780 [00:54<01:43, 302.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16390/47780 [00:53<01:27, 358.87 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15909/47780 [00:53<01:31, 346.58 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16401/47780 [00:54<01:36, 325.03 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16305/47780 [00:53<01:25, 367.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16482/47780 [00:54<01:37, 320.72 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16427/47780 [00:54<01:34, 331.80 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15926/47780 [00:54<01:44, 304.01 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15948/47780 [00:54<01:31, 347.04 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16661/47780 [00:54<02:04, 249.57 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16437/47780 [00:54<01:33, 333.96 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2400/47780 [00:54<05:32, 136.58 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16342/47780 [00:54<01:30, 347.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16515/47780 [00:54<01:41, 308.73 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16464/47780 [00:54<01:31, 341.98 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15987/47780 [00:54<01:29, 355.19 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15964/47780 [00:54<01:41, 314.70 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16711/47780 [00:54<01:39, 310.93 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2598/47780 [00:54<03:13, 233.18 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16471/47780 [00:54<01:38, 317.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16384/47780 [00:54<01:26, 364.44 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16547/47780 [00:54<01:45, 296.63 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 16003/47780 [00:54<01:35, 331.60 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16500/47780 [00:54<01:35, 328.92 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16023/47780 [00:54<01:33, 339.01 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16745/47780 [00:54<01:39, 312.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16509/47780 [00:54<01:33, 334.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16422/47780 [00:54<01:27, 360.15 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16539/47780 [00:54<01:30, 345.59 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16577/47780 [00:54<01:49, 285.15 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16058/47780 [00:54<01:34, 336.52 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16038/47780 [00:54<01:40, 315.84 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16778/47780 [00:54<01:38, 313.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16543/47780 [00:54<01:35, 326.98 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16463/47780 [00:54<01:24, 370.68 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16607/47780 [00:54<01:47, 288.65 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16575/47780 [00:54<01:31, 341.57 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16092/47780 [00:54<01:39, 319.13 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16811/47780 [00:54<01:41, 305.22 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16578/47780 [00:54<01:33, 332.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16071/47780 [00:54<01:50, 287.38 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16501/47780 [00:54<01:25, 364.63 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16620/47780 [00:54<01:24, 368.32 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16636/47780 [00:54<01:53, 274.31 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16128/47780 [00:54<01:37, 323.85 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16849/47780 [00:54<01:36, 321.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16113/47780 [00:54<01:40, 316.15 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16541/47780 [00:54<01:23, 374.68 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16612/47780 [00:54<01:45, 296.76 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16670/47780 [00:54<01:48, 285.97 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16658/47780 [00:54<01:31, 341.95 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16162/47780 [00:54<01:39, 317.42 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16883/47780 [00:54<01:34, 325.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16147/47780 [00:54<01:39, 319.27 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16653/47780 [00:54<01:35, 326.50 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16579/47780 [00:54<01:31, 341.23 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16707/47780 [00:54<01:40, 308.92 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16694/47780 [00:54<01:31, 338.19 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16196/47780 [00:54<01:38, 322.05 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16180/47780 [00:54<01:39, 318.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16918/47780 [00:54<01:37, 315.30 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16616/47780 [00:54<01:30, 345.09 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16740/47780 [00:54<01:38, 314.85 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16729/47780 [00:54<01:31, 337.81 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16687/47780 [00:54<01:46, 291.42 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16231/47780 [00:54<01:37, 324.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16954/47780 [00:55<01:36, 321.00 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16213/47780 [00:54<01:47, 292.49 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16651/47780 [00:54<01:30, 342.56 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16777/47780 [00:55<01:35, 323.65 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16737/47780 [00:55<01:30, 342.11 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16773/47780 [00:55<01:25, 362.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16267/47780 [00:54<01:35, 330.91 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16991/47780 [00:55<01:35, 323.80 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16247/47780 [00:55<01:44, 301.91 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16810/47780 [00:55<01:36, 321.81 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16686/47780 [00:55<01:35, 326.37 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16811/47780 [00:55<01:25, 362.81 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16301/47780 [00:55<01:37, 322.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16773/47780 [00:55<01:35, 325.92 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17030/47780 [00:55<01:30, 339.20 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16278/47780 [00:55<01:50, 285.51 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16843/47780 [00:55<01:42, 303.17 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16719/47780 [00:55<01:42, 303.82 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16848/47780 [00:55<01:28, 347.80 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16810/47780 [00:55<01:32, 333.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16334/47780 [00:55<01:41, 310.63 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17066/47780 [00:55<01:31, 336.90 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16314/47780 [00:55<01:44, 302.06 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16874/47780 [00:55<01:44, 295.20 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16758/47780 [00:55<01:36, 320.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16383/47780 [00:55<01:27, 360.63 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16884/47780 [00:55<01:37, 317.00 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17100/47780 [00:55<01:32, 331.76 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16846/47780 [00:55<01:39, 310.16 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16350/47780 [00:55<01:42, 307.91 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16904/47780 [00:55<01:45, 293.32 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16791/47780 [00:55<01:39, 312.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16420/47780 [00:55<01:28, 354.91 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17156/47780 [00:55<01:17, 394.61 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16925/47780 [00:55<01:32, 334.77 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2693/47780 [00:55<04:49, 155.47 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16390/47780 [00:55<01:35, 330.04 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16878/47780 [00:55<01:53, 273.24 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16943/47780 [00:55<01:38, 313.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16823/47780 [00:55<01:39, 311.18 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17200/47780 [00:55<01:15, 403.09 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2882/47780 [00:55<03:03, 244.61 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16460/47780 [00:55<01:32, 337.30 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16960/47780 [00:55<01:36, 317.74 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16425/47780 [00:55<01:33, 335.19 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16921/47780 [00:55<01:39, 308.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 16977/47780 [00:55<01:35, 320.89 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16855/47780 [00:55<01:41, 306.16 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16497/47780 [00:55<01:30, 346.15 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17241/47780 [00:55<01:20, 378.41 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16993/47780 [00:55<01:38, 311.58 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16468/47780 [00:55<01:27, 358.22 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17012/47780 [00:55<01:33, 329.24 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16954/47780 [00:55<01:41, 304.52 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16889/47780 [00:55<01:40, 306.03 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16539/47780 [00:55<01:26, 362.78 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17282/47780 [00:55<01:21, 372.97 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16505/47780 [00:55<01:28, 353.35 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17026/47780 [00:55<01:40, 306.42 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17046/47780 [00:55<01:33, 328.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 16991/47780 [00:55<01:36, 318.55 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16576/47780 [00:55<01:27, 356.76 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16920/47780 [00:55<01:49, 281.36 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16553/47780 [00:55<01:21, 385.37 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17057/47780 [00:55<01:44, 294.74 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17086/47780 [00:55<01:27, 349.45 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17320/47780 [00:56<01:28, 342.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17028/47780 [00:55<01:32, 332.29 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16612/47780 [00:55<01:30, 345.52 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16950/47780 [00:56<01:50, 278.00 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16593/47780 [00:56<01:23, 372.54 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17088/47780 [00:56<01:45, 289.59 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17067/47780 [00:56<01:29, 344.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17122/47780 [00:56<01:32, 332.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17355/47780 [00:56<01:32, 327.23 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16649/47780 [00:56<01:31, 341.27 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16984/47780 [00:56<01:46, 288.52 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16631/47780 [00:56<01:24, 370.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17118/47780 [00:56<01:48, 283.05 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17104/47780 [00:56<01:30, 338.60 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17156/47780 [00:56<01:35, 320.51 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17389/47780 [00:56<01:39, 304.81 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17023/47780 [00:56<01:38, 313.01 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16684/47780 [00:56<01:36, 322.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16669/47780 [00:56<01:29, 349.24 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17140/47780 [00:56<01:31, 335.28 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17154/47780 [00:56<01:44, 294.32 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17189/47780 [00:56<01:41, 302.61 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17420/47780 [00:56<01:42, 296.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17055/47780 [00:56<01:37, 314.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17180/47780 [00:56<01:26, 353.37 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16717/47780 [00:56<01:46, 292.01 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17184/47780 [00:56<01:46, 286.62 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16705/47780 [00:56<01:37, 320.33 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17454/47780 [00:56<01:38, 307.70 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17221/47780 [00:56<01:42, 297.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17087/47780 [00:56<01:43, 295.92 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17218/47780 [00:56<01:41, 301.22 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16753/47780 [00:56<01:43, 300.62 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16743/47780 [00:56<01:33, 332.62 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17489/47780 [00:56<01:35, 316.45 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17251/47780 [00:56<01:43, 295.22 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17216/47780 [00:56<01:36, 315.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17121/47780 [00:56<01:42, 300.02 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17249/47780 [00:56<01:45, 289.91 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16794/47780 [00:56<01:36, 319.46 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17531/47780 [00:56<01:29, 337.84 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17253/47780 [00:56<01:34, 324.73 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17284/47780 [00:56<01:43, 295.04 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16777/47780 [00:56<01:42, 301.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17153/47780 [00:56<01:40, 303.49 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17281/47780 [00:56<01:44, 292.44 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16827/47780 [00:56<01:38, 315.50 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17314/47780 [00:56<01:48, 280.39 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17568/47780 [00:56<01:36, 311.94 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17185/47780 [00:56<01:40, 305.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17287/47780 [00:56<01:43, 295.39 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16860/47780 [00:56<01:37, 317.57 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17311/47780 [00:56<01:50, 276.02 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16809/47780 [00:56<02:03, 251.73 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17349/47780 [00:56<01:44, 290.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17321/47780 [00:56<01:40, 303.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17600/47780 [00:57<01:43, 292.05 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17216/47780 [00:56<01:47, 283.75 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16892/47780 [00:56<01:39, 309.73 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16871/47780 [00:56<01:32, 334.44 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17343/47780 [00:56<01:47, 281.86 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17379/47780 [00:57<01:44, 291.16 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17354/47780 [00:57<01:38, 310.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2984/47780 [00:57<04:44, 157.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17653/47780 [00:57<01:26, 347.05 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17245/47780 [00:57<01:53, 267.89 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16926/47780 [00:57<01:20, 384.21 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17383/47780 [00:57<01:36, 314.30 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16924/47780 [00:57<01:43, 298.94 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17418/47780 [00:57<01:35, 317.00 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3199/47780 [00:57<02:54, 255.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17386/47780 [00:57<01:41, 297.99 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17273/47780 [00:57<01:53, 268.22 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17689/47780 [00:57<01:32, 325.60 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16960/47780 [00:57<01:38, 312.78 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17416/47780 [00:57<01:37, 310.60 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16968/47780 [00:57<01:23, 369.61 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17460/47780 [00:57<01:28, 342.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17417/47780 [00:57<01:42, 297.07 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17301/47780 [00:57<01:55, 262.92 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17727/47780 [00:57<01:30, 333.36 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16996/47780 [00:57<01:36, 318.78 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17451/47780 [00:57<01:36, 315.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17497/47780 [00:57<01:26, 350.54 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17459/47780 [00:57<01:34, 320.47 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17010/47780 [00:57<01:33, 328.87 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17334/47780 [00:57<01:49, 278.37 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17761/47780 [00:57<01:32, 324.76 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17033/47780 [00:57<01:33, 329.53 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17483/47780 [00:57<01:37, 309.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17533/47780 [00:57<01:29, 337.61 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17492/47780 [00:57<01:34, 319.69 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17046/47780 [00:57<01:32, 333.15 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17370/47780 [00:57<01:42, 297.81 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17797/47780 [00:57<01:30, 331.37 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17069/47780 [00:57<01:32, 330.59 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17515/47780 [00:57<01:41, 299.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17572/47780 [00:57<01:28, 340.85 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17525/47780 [00:57<01:34, 321.11 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17404/47780 [00:57<01:39, 306.27 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17081/47780 [00:57<01:37, 314.99 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17831/47780 [00:57<01:33, 319.02 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17111/47780 [00:57<01:27, 352.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17546/47780 [00:57<01:43, 292.61 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17558/47780 [00:57<01:35, 317.54 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17607/47780 [00:57<01:35, 315.29 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17435/47780 [00:57<01:39, 303.87 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17867/47780 [00:57<01:32, 323.22 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17114/47780 [00:57<01:40, 306.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17147/47780 [00:57<01:31, 333.70 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17576/47780 [00:57<01:52, 267.79 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17643/47780 [00:57<01:34, 320.21 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17591/47780 [00:57<01:40, 300.74 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17470/47780 [00:57<01:38, 306.58 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17904/47780 [00:57<01:28, 335.86 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17155/47780 [00:57<01:32, 329.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17181/47780 [00:57<01:34, 322.62 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17608/47780 [00:57<01:48, 278.69 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17676/47780 [00:57<01:34, 317.78 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17622/47780 [00:57<01:44, 289.96 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17501/47780 [00:57<01:40, 300.52 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17938/47780 [00:58<01:31, 326.18 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3314/47780 [00:57<03:27, 214.00 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17189/47780 [00:57<01:37, 314.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17215/47780 [00:57<01:33, 327.37 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17637/47780 [00:57<01:49, 275.73 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17656/47780 [00:58<01:41, 297.64 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17713/47780 [00:58<01:36, 312.91 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17533/47780 [00:57<01:39, 302.82 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17983/47780 [00:58<01:23, 357.04 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3485/47780 [00:58<02:26, 302.45 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17251/47780 [00:57<01:31, 332.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17230/47780 [00:58<01:32, 330.53 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17666/47780 [00:58<01:47, 279.54 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17686/47780 [00:58<01:41, 295.13 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17753/47780 [00:58<01:30, 333.17 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18022/47780 [00:58<01:21, 366.24 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17565/47780 [00:58<01:44, 287.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17285/47780 [00:58<01:34, 323.87 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17265/47780 [00:58<01:33, 325.22 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17695/47780 [00:58<01:51, 270.47 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17787/47780 [00:58<01:30, 331.40 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17717/47780 [00:58<01:41, 295.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17594/47780 [00:58<01:45, 285.01 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17320/47780 [00:58<01:33, 327.50 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18059/47780 [00:58<01:30, 329.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17298/47780 [00:58<01:34, 322.55 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17730/47780 [00:58<01:46, 283.19 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17747/47780 [00:58<01:42, 293.84 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17821/47780 [00:58<01:33, 318.99 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17626/47780 [00:58<01:45, 285.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18093/47780 [00:58<01:29, 330.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17331/47780 [00:58<01:34, 321.65 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17353/47780 [00:58<01:43, 294.11 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17759/47780 [00:58<01:46, 281.97 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17777/47780 [00:58<01:42, 291.87 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17854/47780 [00:58<01:33, 318.59 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17659/47780 [00:58<01:42, 294.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17364/47780 [00:58<01:36, 316.61 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18127/47780 [00:58<01:33, 317.21 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17386/47780 [00:58<01:40, 300.96 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17800/47780 [00:58<01:34, 318.07 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17809/47780 [00:58<01:40, 296.86 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17886/47780 [00:58<01:37, 305.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17689/47780 [00:58<01:42, 292.54 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17396/47780 [00:58<01:38, 307.40 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18160/47780 [00:58<01:37, 303.79 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17833/47780 [00:58<01:33, 321.49 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17417/47780 [00:58<01:44, 290.22 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17839/47780 [00:58<01:41, 293.87 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17923/47780 [00:58<01:32, 323.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17720/47780 [00:58<01:43, 291.18 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17428/47780 [00:58<01:37, 310.90 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17867/47780 [00:58<01:35, 312.39 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18193/47780 [00:58<01:40, 295.10 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17455/47780 [00:58<01:37, 311.15 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17870/47780 [00:58<01:42, 292.25 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17956/47780 [00:58<01:33, 317.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17756/47780 [00:58<01:39, 300.55 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17469/47780 [00:58<01:30, 335.48 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17913/47780 [00:58<01:24, 354.32 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18226/47780 [00:58<01:37, 302.82 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17900/47780 [00:58<01:42, 291.20 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17487/47780 [00:58<01:40, 300.85 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17988/47780 [00:58<01:35, 311.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17788/47780 [00:58<01:39, 301.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17503/47780 [00:58<01:30, 332.95 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17936/47780 [00:58<01:37, 307.53 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17949/47780 [00:58<01:27, 339.94 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17522/47780 [00:58<01:36, 314.40 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18257/47780 [00:59<01:44, 281.60 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18020/47780 [00:58<01:35, 310.37 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17819/47780 [00:58<01:39, 301.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17543/47780 [00:58<01:25, 352.19 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17985/47780 [00:59<01:27, 342.13 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17971/47780 [00:59<01:35, 312.52 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18287/47780 [00:59<01:44, 283.35 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18053/47780 [00:59<01:36, 309.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17853/47780 [00:59<01:36, 309.24 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17579/47780 [00:59<01:28, 342.56 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18020/47780 [00:59<01:28, 336.71 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18003/47780 [00:59<01:35, 311.09 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17554/47780 [00:59<02:11, 229.73 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18086/47780 [00:59<01:35, 311.20 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18316/47780 [00:59<01:52, 262.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17884/47780 [00:59<01:38, 302.55 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17618/47780 [00:59<01:25, 352.11 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18054/47780 [00:59<01:30, 330.06 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18035/47780 [00:59<01:38, 303.03 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18120/47780 [00:59<01:33, 316.07 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17616/47780 [00:59<01:37, 310.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18344/47780 [00:59<01:50, 266.86 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17915/47780 [00:59<01:43, 287.81 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17654/47780 [00:59<01:27, 345.60 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3592/47780 [00:59<03:56, 186.70 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18067/47780 [00:59<01:37, 304.63 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18088/47780 [00:59<01:34, 314.59 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18153/47780 [00:59<01:34, 312.85 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17652/47780 [00:59<01:35, 316.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18372/47780 [00:59<01:51, 264.86 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17694/47780 [00:59<01:23, 361.06 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3669/47780 [00:59<03:22, 218.24 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17944/47780 [00:59<01:51, 267.20 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18105/47780 [00:59<01:30, 326.29 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18128/47780 [00:59<01:27, 338.21 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18188/47780 [00:59<01:32, 319.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18403/47780 [00:59<01:45, 277.37 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17687/47780 [00:59<01:38, 304.47 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17740/47780 [00:59<01:17, 386.22 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17982/47780 [00:59<01:41, 294.98 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18138/47780 [00:59<01:34, 312.47 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18230/47780 [00:59<01:25, 345.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18432/47780 [00:59<01:46, 274.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18163/47780 [00:59<01:35, 310.26 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17720/47780 [00:59<01:40, 300.55 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17781/47780 [00:59<01:18, 384.32 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18012/47780 [00:59<01:44, 283.53 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18172/47780 [00:59<01:33, 317.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18203/47780 [00:59<01:29, 330.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18265/47780 [00:59<01:31, 320.96 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18461/47780 [00:59<01:49, 266.84 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17822/47780 [00:59<01:16, 391.52 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17762/47780 [00:59<01:32, 324.71 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18042/47780 [00:59<01:44, 284.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18206/47780 [00:59<01:37, 302.60 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18238/47780 [00:59<01:28, 332.33 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18489/47780 [00:59<01:48, 270.49 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18298/47780 [00:59<01:36, 306.07 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17862/47780 [00:59<01:20, 371.97 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17796/47780 [00:59<01:37, 308.63 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18071/47780 [00:59<01:46, 280.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18240/47780 [00:59<01:35, 309.59 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18272/47780 [00:59<01:32, 319.90 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18334/47780 [00:59<01:31, 320.54 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18517/47780 [01:00<01:54, 255.86 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17900/47780 [00:59<01:25, 350.96 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17828/47780 [00:59<01:41, 296.47 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18100/47780 [00:59<01:51, 265.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18284/47780 [01:00<01:27, 338.72 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18315/47780 [01:00<01:24, 347.03 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18550/47780 [01:00<01:45, 276.26 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18367/47780 [01:00<01:33, 315.94 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17936/47780 [01:00<01:26, 344.42 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18131/47780 [01:00<01:46, 277.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17859/47780 [01:00<01:44, 285.07 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18319/47780 [01:00<01:30, 326.58 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18353/47780 [01:00<01:22, 356.31 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18578/47780 [01:00<01:45, 275.72 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18402/47780 [01:00<01:31, 322.19 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17972/47780 [01:00<01:27, 342.61 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17890/47780 [01:00<01:43, 288.55 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18162/47780 [01:00<01:46, 277.21 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18397/47780 [01:00<01:17, 380.05 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18606/47780 [01:00<01:49, 266.12 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18435/47780 [01:00<01:32, 316.97 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18352/47780 [01:00<01:35, 307.25 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18007/47780 [01:00<01:30, 329.91 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18191/47780 [01:00<01:45, 280.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17924/47780 [01:00<01:41, 292.96 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18442/47780 [01:00<01:14, 396.11 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18469/47780 [01:00<01:30, 323.46 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18641/47780 [01:00<01:41, 286.82 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18384/47780 [01:00<01:35, 307.65 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17962/47780 [01:00<01:35, 313.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18220/47780 [01:00<01:53, 259.86 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18482/47780 [01:00<01:17, 379.54 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18041/47780 [01:00<01:44, 285.32 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18674/47780 [01:00<01:37, 299.06 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18415/47780 [01:00<01:35, 307.88 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18503/47780 [01:00<01:39, 294.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17994/47780 [01:00<01:35, 311.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18247/47780 [01:00<01:53, 259.52 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18521/47780 [01:00<01:16, 382.22 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18450/47780 [01:00<01:32, 316.73 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18705/47780 [01:00<01:37, 297.52 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18071/47780 [01:00<01:49, 272.19 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18534/47780 [01:00<01:42, 286.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18280/47780 [01:00<01:46, 276.31 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18026/47780 [01:00<01:42, 291.01 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18560/47780 [01:00<01:16, 384.20 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18742/47780 [01:00<01:31, 316.98 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18483/47780 [01:00<01:32, 316.71 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18564/47780 [01:00<01:44, 280.77 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3836/47780 [01:00<04:14, 172.94 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18313/47780 [01:00<01:41, 291.18 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18056/47780 [01:00<01:42, 290.14 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18099/47780 [01:00<02:10, 228.15 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18520/47780 [01:00<01:30, 324.71 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18776/47780 [01:00<01:32, 312.12 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18599/47780 [01:00<01:20, 360.55 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▊         | 4107/47780 [01:00<02:22, 305.85 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18594/47780 [01:00<01:44, 279.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18343/47780 [01:00<01:41, 290.70 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18086/47780 [01:00<01:45, 280.69 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18556/47780 [01:00<01:27, 334.59 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18808/47780 [01:00<01:33, 310.45 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18636/47780 [01:00<01:22, 351.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18124/47780 [01:00<02:31, 195.19 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18378/47780 [01:00<01:37, 300.84 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18623/47780 [01:00<01:52, 260.12 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18123/47780 [01:00<01:38, 301.99 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18591/47780 [01:01<01:29, 327.69 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18840/47780 [01:01<01:34, 306.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18672/47780 [01:00<01:24, 342.70 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18410/47780 [01:01<01:36, 302.81 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18156/47780 [01:01<01:38, 299.65 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18650/47780 [01:01<01:58, 246.13 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18872/47780 [01:01<01:33, 310.12 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18146/47780 [01:01<02:43, 181.42 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18636/47780 [01:01<01:24, 343.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18707/47780 [01:01<01:26, 337.09 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18446/47780 [01:01<01:31, 319.05 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18198/47780 [01:01<01:28, 332.82 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18697/47780 [01:01<01:37, 299.54 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18249/47780 [01:01<01:21, 361.31 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18904/47780 [01:01<01:36, 299.28 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18742/47780 [01:01<01:26, 337.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18671/47780 [01:01<01:28, 330.34 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18480/47780 [01:01<01:34, 310.29 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18729/47780 [01:01<01:35, 305.04 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18935/47780 [01:01<01:37, 295.58 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18292/47780 [01:01<01:21, 360.31 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18232/47780 [01:01<01:38, 300.64 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18777/47780 [01:01<01:28, 329.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18706/47780 [01:01<01:28, 328.54 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18512/47780 [01:01<01:37, 299.79 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18965/47780 [01:01<01:38, 293.17 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18812/47780 [01:01<01:27, 331.67 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18761/47780 [01:01<01:43, 280.64 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18263/47780 [01:01<01:40, 294.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18739/47780 [01:01<01:31, 316.06 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18544/47780 [01:01<01:38, 295.67 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18333/47780 [01:01<01:40, 294.44 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18796/47780 [01:01<01:38, 293.32 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18995/47780 [01:01<01:43, 279.42 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18846/47780 [01:01<01:29, 322.51 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18771/47780 [01:01<01:31, 315.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18293/47780 [01:01<01:47, 274.90 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18575/47780 [01:01<01:38, 296.46 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18396/47780 [01:01<01:20, 364.63 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18827/47780 [01:01<01:38, 294.69 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18879/47780 [01:01<01:30, 318.06 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19024/47780 [01:01<01:45, 273.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18331/47780 [01:01<01:38, 299.46 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18605/47780 [01:01<01:44, 278.57 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18804/47780 [01:01<01:56, 249.64 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18920/47780 [01:01<01:23, 343.90 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19054/47780 [01:01<01:43, 277.50 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18439/47780 [01:01<01:22, 356.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18858/47780 [01:01<01:43, 280.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18363/47780 [01:01<01:37, 301.80 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18634/47780 [01:01<01:45, 275.51 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18832/47780 [01:01<01:56, 249.15 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19082/47780 [01:01<01:45, 273.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18955/47780 [01:01<01:27, 330.01 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18394/47780 [01:01<01:41, 290.25 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18887/47780 [01:01<01:51, 258.14 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4231/47780 [01:01<03:17, 220.73 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18481/47780 [01:01<01:31, 319.79 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18663/47780 [01:01<01:46, 273.57 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18889/47780 [01:01<01:29, 322.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19110/47780 [01:02<01:48, 263.05 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18989/47780 [01:01<01:31, 315.37 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18426/47780 [01:01<01:39, 296.11 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18922/47780 [01:02<01:47, 267.75 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4330/47780 [01:02<02:46, 261.00 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18517/47780 [01:02<01:30, 324.98 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18691/47780 [01:02<01:53, 256.37 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19137/47780 [01:02<01:52, 255.63 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19024/47780 [01:02<01:29, 321.41 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18456/47780 [01:02<01:40, 290.35 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18924/47780 [01:02<01:39, 290.21 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18562/47780 [01:02<01:23, 349.55 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18950/47780 [01:02<01:53, 254.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18719/47780 [01:02<01:51, 261.76 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19166/47780 [01:02<01:49, 262.17 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19057/47780 [01:02<01:30, 316.86 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18486/47780 [01:02<01:41, 289.73 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18972/47780 [01:02<01:26, 334.84 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18976/47780 [01:02<01:55, 250.43 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18600/47780 [01:02<01:27, 333.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18753/47780 [01:02<01:43, 280.34 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18516/47780 [01:02<01:41, 289.16 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19193/47780 [01:02<01:52, 254.64 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19008/47780 [01:02<01:27, 327.47 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19089/47780 [01:02<01:44, 274.19 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19009/47780 [01:02<01:46, 269.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18792/47780 [01:02<01:34, 307.84 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19220/47780 [01:02<01:51, 257.25 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18548/47780 [01:02<01:39, 295.23 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18635/47780 [01:02<01:35, 306.06 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19141/47780 [01:02<01:25, 335.77 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19038/47780 [01:02<01:45, 272.13 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19044/47780 [01:02<01:30, 315.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18829/47780 [01:02<01:28, 325.55 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19247/47780 [01:02<01:49, 260.83 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18591/47780 [01:02<01:28, 330.36 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18667/47780 [01:02<01:37, 298.30 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19082/47780 [01:02<01:27, 329.54 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19177/47780 [01:02<01:27, 328.06 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19068/47780 [01:02<01:46, 270.77 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18862/47780 [01:02<01:32, 312.41 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19274/47780 [01:02<01:49, 259.68 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18625/47780 [01:02<01:30, 321.52 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18698/47780 [01:02<01:38, 295.18 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19213/47780 [01:02<01:25, 335.18 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19116/47780 [01:02<01:28, 325.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19101/47780 [01:02<01:42, 281.03 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18894/47780 [01:02<01:34, 304.28 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18659/47780 [01:02<01:31, 316.59 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18729/47780 [01:02<01:39, 290.67 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19301/47780 [01:02<01:59, 238.55 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19150/47780 [01:02<01:28, 322.07 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19133/47780 [01:02<01:39, 288.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19248/47780 [01:02<01:27, 324.71 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18925/47780 [01:02<01:42, 280.58 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19338/47780 [01:02<01:43, 274.26 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18691/47780 [01:02<01:35, 303.63 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18759/47780 [01:02<01:41, 285.63 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19163/47780 [01:02<01:38, 291.69 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19285/47780 [01:02<01:24, 337.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19183/47780 [01:02<01:30, 317.13 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18956/47780 [01:02<01:39, 288.29 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18722/47780 [01:02<01:35, 305.17 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18796/47780 [01:02<01:38, 293.53 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19368/47780 [01:03<01:48, 260.97 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19215/47780 [01:03<01:29, 317.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19193/47780 [01:03<01:39, 287.37 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4417/47780 [01:03<03:53, 185.62 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19320/47780 [01:03<01:29, 316.24 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18753/47780 [01:03<01:38, 293.26 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18986/47780 [01:03<01:47, 268.07 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18827/47780 [01:03<01:37, 297.77 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19403/47780 [01:03<01:40, 282.26 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19247/47780 [01:03<01:31, 312.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19226/47780 [01:03<01:36, 295.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4582/47780 [01:03<02:38, 272.86 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18783/47780 [01:03<01:39, 291.80 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19021/47780 [01:03<01:39, 288.91 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19353/47780 [01:03<01:43, 274.81 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18857/47780 [01:03<01:40, 288.96 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19432/47780 [01:03<01:43, 275.10 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19279/47780 [01:03<01:31, 310.19 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19256/47780 [01:03<01:44, 272.72 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19392/47780 [01:03<01:35, 297.86 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18888/47780 [01:03<01:39, 291.57 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18815/47780 [01:03<01:40, 286.97 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19311/47780 [01:03<01:33, 305.79 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19051/47780 [01:03<01:48, 263.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19460/47780 [01:03<01:50, 256.53 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19284/47780 [01:03<01:44, 273.70 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19423/47780 [01:03<01:35, 297.73 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18848/47780 [01:03<01:37, 295.77 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18918/47780 [01:03<01:39, 289.77 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19079/47780 [01:03<01:49, 262.60 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19350/47780 [01:03<01:29, 316.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19487/47780 [01:03<01:49, 257.56 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19312/47780 [01:03<01:48, 261.39 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18881/47780 [01:03<01:35, 302.04 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19454/47780 [01:03<01:36, 294.87 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18949/47780 [01:03<01:41, 283.28 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19117/47780 [01:03<01:38, 291.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19382/47780 [01:03<01:29, 316.69 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19515/47780 [01:03<01:51, 252.62 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19341/47780 [01:03<01:46, 266.71 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18913/47780 [01:03<01:33, 307.16 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19490/47780 [01:03<01:33, 302.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18981/47780 [01:03<01:38, 293.55 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19420/47780 [01:03<01:25, 331.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19152/47780 [01:03<01:35, 300.59 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19545/47780 [01:03<01:46, 265.39 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19375/47780 [01:03<01:41, 280.93 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18944/47780 [01:03<01:34, 304.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19521/47780 [01:03<01:32, 304.79 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19011/47780 [01:03<01:44, 276.36 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19469/47780 [01:03<01:16, 368.80 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19183/47780 [01:03<01:36, 296.50 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19406/47780 [01:03<01:40, 282.75 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19573/47780 [01:03<02:02, 230.62 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18975/47780 [01:03<01:35, 302.59 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19555/47780 [01:03<01:30, 311.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19055/47780 [01:03<01:30, 318.44 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19506/47780 [01:03<01:19, 356.88 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19214/47780 [01:03<01:42, 277.94 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19437/47780 [01:03<01:38, 287.21 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19601/47780 [01:04<01:58, 238.63 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19011/47780 [01:03<01:31, 315.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19587/47780 [01:03<01:31, 309.79 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19542/47780 [01:03<01:19, 353.72 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19088/47780 [01:03<01:36, 298.14 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19247/47780 [01:03<01:38, 290.03 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19472/47780 [01:03<01:33, 301.60 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19657/47780 [01:04<01:27, 323.16 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19621/47780 [01:04<01:29, 315.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19047/47780 [01:03<01:30, 317.44 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19580/47780 [01:04<01:18, 357.11 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19278/47780 [01:04<01:38, 288.62 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19121/47780 [01:04<01:37, 292.95 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19503/47780 [01:04<01:38, 287.48 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19660/47780 [01:04<01:23, 336.84 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19084/47780 [01:04<01:27, 328.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19691/47780 [01:04<01:31, 307.56 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19616/47780 [01:04<01:24, 334.81 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19151/47780 [01:04<01:37, 292.47 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19543/47780 [01:04<01:29, 315.58 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19308/47780 [01:04<01:44, 272.74 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19694/47780 [01:04<01:25, 330.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19117/47780 [01:04<01:30, 317.84 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19184/47780 [01:04<01:35, 300.11 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19650/47780 [01:04<01:26, 325.11 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19724/47780 [01:04<01:44, 267.82 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19575/47780 [01:04<01:32, 306.43 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19738/47780 [01:04<01:18, 357.77 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19149/47780 [01:04<01:31, 311.70 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19336/47780 [01:04<01:56, 243.14 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19767/47780 [01:04<01:31, 307.66 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19683/47780 [01:04<01:32, 303.05 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19606/47780 [01:04<01:33, 300.02 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19774/47780 [01:04<01:18, 357.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19181/47780 [01:04<01:31, 314.06 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19361/47780 [01:04<01:56, 243.02 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19216/47780 [01:04<01:52, 253.68 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4676/47780 [01:04<04:23, 163.60 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19800/47780 [01:04<01:29, 313.26 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19810/47780 [01:04<01:18, 356.35 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19714/47780 [01:04<01:37, 289.07 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19637/47780 [01:04<01:39, 284.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19214/47780 [01:04<01:30, 315.01 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5125/47780 [01:04<01:48, 394.77 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19386/47780 [01:04<01:58, 239.17 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19271/47780 [01:04<01:30, 315.72 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19833/47780 [01:04<01:33, 298.66 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19745/47780 [01:04<01:37, 288.99 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19248/47780 [01:04<01:30, 314.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19667/47780 [01:04<01:42, 273.57 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19847/47780 [01:04<01:25, 328.26 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19414/47780 [01:04<01:54, 248.11 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19865/47780 [01:04<01:32, 301.09 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19305/47780 [01:04<01:40, 282.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19695/47780 [01:04<01:42, 275.28 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19294/47780 [01:04<01:22, 344.79 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19444/47780 [01:04<01:47, 262.47 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19884/47780 [01:04<01:23, 332.26 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19775/47780 [01:04<01:44, 268.21 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19348/47780 [01:04<01:29, 317.03 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19896/47780 [01:04<01:36, 287.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19727/47780 [01:04<01:37, 287.64 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19920/47780 [01:04<01:22, 336.35 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19471/47780 [01:04<01:51, 253.29 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19329/47780 [01:04<01:27, 324.19 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19803/47780 [01:04<01:51, 250.56 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19926/47780 [01:05<01:35, 291.09 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19382/47780 [01:04<01:34, 301.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19759/47780 [01:04<01:35, 293.74 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19501/47780 [01:04<01:46, 266.22 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19954/47780 [01:04<01:23, 333.36 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19367/47780 [01:04<01:24, 335.89 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19830/47780 [01:05<01:50, 253.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19962/47780 [01:05<01:30, 306.75 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19414/47780 [01:05<01:37, 290.90 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19790/47780 [01:05<01:38, 285.24 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19529/47780 [01:05<01:46, 264.10 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19989/47780 [01:05<01:27, 316.74 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19401/47780 [01:05<01:27, 325.87 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19856/47780 [01:05<02:01, 230.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20000/47780 [01:05<01:27, 316.79 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19448/47780 [01:05<01:33, 301.42 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19819/47780 [01:05<01:38, 283.30 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19563/47780 [01:05<01:39, 282.51 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20022/47780 [01:05<01:26, 320.33 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19438/47780 [01:05<01:25, 331.01 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19880/47780 [01:05<02:01, 230.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20037/47780 [01:05<01:24, 328.01 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19848/47780 [01:05<01:38, 284.63 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19479/47780 [01:05<01:36, 294.51 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19592/47780 [01:05<01:41, 279.05 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19472/47780 [01:05<01:27, 322.16 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20055/47780 [01:05<01:36, 287.09 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20071/47780 [01:05<01:25, 324.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19915/47780 [01:05<01:49, 254.16 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19514/47780 [01:05<01:31, 309.09 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19884/47780 [01:05<01:33, 299.59 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19621/47780 [01:05<01:46, 263.34 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19507/47780 [01:05<01:26, 326.66 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20089/47780 [01:05<01:33, 294.88 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20107/47780 [01:05<01:22, 334.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19941/47780 [01:05<01:49, 253.09 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19918/47780 [01:05<01:29, 310.03 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19546/47780 [01:05<01:33, 301.47 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19544/47780 [01:05<01:24, 335.25 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19648/47780 [01:05<01:49, 256.71 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20122/47780 [01:05<01:32, 298.10 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20141/47780 [01:05<01:23, 332.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19977/47780 [01:05<01:38, 280.99 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19950/47780 [01:05<01:32, 300.63 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19577/47780 [01:05<01:36, 293.70 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19578/47780 [01:05<01:23, 335.91 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19674/47780 [01:05<01:50, 254.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20176/47780 [01:05<01:22, 333.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20154/47780 [01:05<01:35, 287.86 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20015/47780 [01:05<01:35, 290.82 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19981/47780 [01:05<01:33, 296.59 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19609/47780 [01:05<01:34, 298.12 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19705/47780 [01:05<01:45, 267.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19615/47780 [01:05<01:24, 334.73 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20210/47780 [01:05<01:25, 323.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20184/47780 [01:05<01:35, 288.23 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20045/47780 [01:05<01:37, 284.00 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19640/47780 [01:05<01:33, 299.83 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20013/47780 [01:05<01:33, 296.57 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19732/47780 [01:05<01:46, 262.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19650/47780 [01:05<01:29, 314.05 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20214/47780 [01:05<01:38, 279.09 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20082/47780 [01:05<01:30, 307.34 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20243/47780 [01:06<01:30, 304.96 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20044/47780 [01:05<01:32, 300.38 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19672/47780 [01:05<01:38, 284.00 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19760/47780 [01:05<01:44, 267.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19690/47780 [01:05<01:23, 337.35 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20245/47780 [01:05<01:36, 284.75 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20116/47780 [01:06<01:28, 313.43 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20075/47780 [01:06<01:35, 289.83 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19708/47780 [01:06<01:32, 302.07 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19787/47780 [01:06<01:50, 253.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19725/47780 [01:06<01:23, 334.08 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20275/47780 [01:06<01:35, 289.01 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20148/47780 [01:06<01:27, 314.48 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20274/47780 [01:06<01:55, 237.53 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20107/47780 [01:06<01:32, 298.21 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19739/47780 [01:06<01:38, 284.81 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19759/47780 [01:06<01:25, 327.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19813/47780 [01:06<01:55, 241.71 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20305/47780 [01:06<01:35, 288.94 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20182/47780 [01:06<01:28, 311.38 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20141/47780 [01:06<01:29, 310.07 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5307/47780 [01:06<03:03, 231.31 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19771/47780 [01:06<01:37, 288.41 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19838/47780 [01:06<01:55, 241.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19792/47780 [01:06<01:28, 314.49 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20301/47780 [01:06<02:18, 198.88 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20337/47780 [01:06<01:33, 292.89 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20214/47780 [01:06<01:31, 300.22 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20175/47780 [01:06<01:28, 311.79 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19801/47780 [01:06<01:38, 285.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5492/47780 [01:06<02:20, 301.45 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20404/47780 [01:06<01:12, 376.45 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19863/47780 [01:06<02:00, 230.90 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19824/47780 [01:06<01:35, 293.10 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20367/47780 [01:06<01:39, 274.25 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20213/47780 [01:06<01:25, 324.04 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20245/47780 [01:06<01:36, 284.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19834/47780 [01:06<01:34, 294.43 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19888/47780 [01:06<01:58, 236.14 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5629/47780 [01:06<01:57, 359.98 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19855/47780 [01:06<01:34, 294.43 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20401/47780 [01:06<01:33, 292.40 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20451/47780 [01:06<01:15, 361.20 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20275/47780 [01:06<01:36, 285.35 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20246/47780 [01:06<01:29, 308.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19866/47780 [01:06<01:34, 294.97 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19918/47780 [01:06<01:53, 245.75 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19885/47780 [01:06<01:36, 289.56 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20435/47780 [01:06<01:29, 305.67 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20304/47780 [01:06<01:35, 286.35 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20277/47780 [01:06<01:34, 291.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19897/47780 [01:06<01:33, 299.13 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20494/47780 [01:06<01:24, 323.12 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19946/47780 [01:06<01:51, 249.82 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19917/47780 [01:06<01:34, 294.69 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20466/47780 [01:06<01:35, 286.92 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20333/47780 [01:06<01:42, 267.45 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19928/47780 [01:06<01:35, 292.35 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20307/47780 [01:06<01:41, 270.69 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20541/47780 [01:06<01:16, 355.10 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19972/47780 [01:06<01:50, 252.61 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19952/47780 [01:06<01:31, 305.56 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20496/47780 [01:06<01:36, 282.43 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20361/47780 [01:06<01:46, 258.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19960/47780 [01:06<01:32, 300.04 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19999/47780 [01:06<01:47, 257.41 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20335/47780 [01:06<01:45, 260.86 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19983/47780 [01:06<01:34, 293.47 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20581/47780 [01:07<01:22, 330.96 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20526/47780 [01:06<01:38, 277.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20388/47780 [01:07<01:48, 253.51 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19992/47780 [01:07<01:37, 285.76 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20025/47780 [01:07<01:48, 254.71 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20362/47780 [01:07<01:54, 239.01 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20013/47780 [01:07<01:38, 280.62 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20560/47780 [01:07<01:32, 294.43 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20618/47780 [01:07<01:28, 305.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20416/47780 [01:07<01:47, 255.15 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20053/47780 [01:07<01:46, 259.88 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20022/47780 [01:07<01:36, 286.87 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20392/47780 [01:07<01:49, 251.02 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20042/47780 [01:07<01:42, 271.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20658/47780 [01:07<01:24, 321.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20444/47780 [01:07<01:45, 259.15 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20080/47780 [01:07<01:45, 262.65 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20062/47780 [01:07<01:26, 318.64 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20419/47780 [01:07<01:47, 254.48 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20590/47780 [01:07<02:03, 221.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20070/47780 [01:07<01:44, 265.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20477/47780 [01:07<01:39, 275.73 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20112/47780 [01:07<01:40, 276.34 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20095/47780 [01:07<01:27, 314.92 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20693/47780 [01:07<01:31, 296.21 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20445/47780 [01:07<01:49, 250.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20097/47780 [01:07<01:49, 252.62 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20505/47780 [01:07<01:41, 267.99 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20141/47780 [01:07<01:41, 270.98 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20130/47780 [01:07<01:27, 317.67 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20615/47780 [01:07<02:15, 199.90 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20725/47780 [01:07<01:30, 298.97 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20475/47780 [01:07<01:44, 261.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5759/47780 [01:07<02:45, 253.41 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20123/47780 [01:07<01:55, 239.13 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20543/47780 [01:07<01:33, 292.85 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20171/47780 [01:07<01:22, 336.38 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20169/47780 [01:07<01:48, 254.73 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20515/47780 [01:07<01:31, 296.84 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20757/47780 [01:07<01:35, 282.24 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6104/47780 [01:07<01:33, 446.78 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20638/47780 [01:07<02:35, 175.09 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20161/47780 [01:07<01:39, 276.56 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20209/47780 [01:07<01:19, 348.55 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20573/47780 [01:07<01:37, 280.40 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20226/47780 [01:07<01:21, 339.88 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20801/47780 [01:07<01:23, 321.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20556/47780 [01:07<01:23, 325.34 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20659/47780 [01:07<02:29, 181.02 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20194/47780 [01:07<01:35, 288.19 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20244/47780 [01:07<01:19, 344.99 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20264/47780 [01:07<01:18, 351.20 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20605/47780 [01:07<01:35, 283.74 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20589/47780 [01:07<01:25, 319.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20835/47780 [01:07<01:25, 316.55 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20782/47780 [01:07<01:03, 425.31 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20225/47780 [01:07<01:34, 290.97 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20286/47780 [01:07<01:14, 366.60 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20634/47780 [01:07<01:35, 285.18 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20300/47780 [01:07<01:21, 338.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20622/47780 [01:07<01:25, 318.37 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20868/47780 [01:08<01:33, 289.15 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20261/47780 [01:07<01:29, 307.04 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20326/47780 [01:07<01:15, 364.05 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20663/47780 [01:08<01:35, 283.72 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20337/47780 [01:07<01:19, 343.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20654/47780 [01:08<01:32, 291.78 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20900/47780 [01:08<01:31, 293.97 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20833/47780 [01:08<01:18, 345.21 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20292/47780 [01:08<01:30, 302.24 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20366/47780 [01:08<01:14, 370.15 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20373/47780 [01:08<01:23, 329.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20692/47780 [01:08<01:45, 255.95 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20711/47780 [01:08<01:14, 364.47 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20931/47780 [01:08<01:32, 288.79 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20327/47780 [01:08<01:27, 312.17 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20878/47780 [01:08<01:16, 351.99 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20405/47780 [01:08<01:15, 363.01 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20408/47780 [01:08<01:27, 313.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20719/47780 [01:08<01:52, 241.28 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20749/47780 [01:08<01:16, 353.06 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20359/47780 [01:08<01:32, 295.28 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20443/47780 [01:08<01:16, 359.43 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20961/47780 [01:08<01:40, 266.21 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20919/47780 [01:08<01:19, 336.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20440/47780 [01:08<01:28, 310.66 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20744/47780 [01:08<01:53, 238.62 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20786/47780 [01:08<01:15, 357.44 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20389/47780 [01:08<01:33, 294.19 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20996/47780 [01:08<01:33, 287.78 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20957/47780 [01:08<01:21, 327.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20472/47780 [01:08<01:28, 309.79 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20481/47780 [01:08<01:27, 312.40 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20771/47780 [01:08<01:50, 244.85 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6267/47780 [01:08<02:01, 341.43 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20823/47780 [01:08<01:20, 334.80 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20421/47780 [01:08<01:32, 295.03 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21026/47780 [01:08<01:35, 278.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20523/47780 [01:08<01:20, 339.39 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20800/47780 [01:08<01:44, 257.27 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20504/47780 [01:08<01:30, 300.67 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20993/47780 [01:08<01:25, 312.14 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20451/47780 [01:08<01:33, 290.92 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20858/47780 [01:08<01:22, 327.68 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21057/47780 [01:08<01:34, 281.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6387/47780 [01:08<01:48, 379.86 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20539/47780 [01:08<01:27, 311.29 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20827/47780 [01:08<01:45, 254.75 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20560/47780 [01:08<01:21, 334.09 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21028/47780 [01:08<01:26, 308.83 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20892/47780 [01:08<01:23, 321.12 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20481/47780 [01:08<01:35, 285.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21095/47780 [01:08<01:27, 305.34 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20855/47780 [01:08<01:43, 259.22 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20571/47780 [01:08<01:29, 303.44 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20598/47780 [01:08<01:20, 338.90 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21062/47780 [01:08<01:25, 314.12 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20511/47780 [01:08<01:34, 287.62 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20926/47780 [01:08<01:24, 319.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21129/47780 [01:08<01:26, 309.29 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20885/47780 [01:08<01:40, 267.81 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20633/47780 [01:08<01:21, 334.59 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20602/47780 [01:08<01:31, 298.21 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21096/47780 [01:08<01:24, 314.38 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6493/47780 [01:08<01:47, 382.90 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20961/47780 [01:08<01:21, 327.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20540/47780 [01:08<01:36, 280.91 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20634/47780 [01:08<01:31, 297.30 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20913/47780 [01:09<01:45, 253.73 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21130/47780 [01:09<01:23, 320.90 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20667/47780 [01:09<01:23, 325.36 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21161/47780 [01:09<01:41, 261.06 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20995/47780 [01:09<01:21, 327.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20572/47780 [01:09<01:34, 288.81 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20702/47780 [01:09<01:22, 328.62 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20668/47780 [01:09<01:29, 303.13 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20941/47780 [01:09<01:45, 255.46 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21207/47780 [01:09<01:25, 310.97 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21029/47780 [01:09<01:22, 323.85 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21163/47780 [01:09<01:31, 291.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20607/47780 [01:09<01:30, 299.45 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6578/47780 [01:09<01:55, 356.84 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21253/47780 [01:09<01:16, 347.10 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20968/47780 [01:09<01:44, 256.73 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20736/47780 [01:09<01:24, 321.04 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20699/47780 [01:09<01:31, 295.12 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21062/47780 [01:09<01:23, 318.82 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20639/47780 [01:09<01:30, 301.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21199/47780 [01:09<01:27, 303.18 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21000/47780 [01:09<01:37, 274.60 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20769/47780 [01:09<01:24, 319.71 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20740/47780 [01:09<01:25, 316.70 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21290/47780 [01:09<01:21, 324.58 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20670/47780 [01:09<01:30, 300.63 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21094/47780 [01:09<01:26, 307.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21230/47780 [01:09<01:28, 301.17 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20802/47780 [01:09<01:24, 318.92 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20773/47780 [01:09<01:24, 320.19 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21030/47780 [01:09<01:40, 266.51 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20702/47780 [01:09<01:28, 306.12 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21324/47780 [01:09<01:24, 314.26 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21125/47780 [01:09<01:31, 292.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6646/47780 [01:09<02:03, 332.02 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21261/47780 [01:09<01:35, 276.51 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20834/47780 [01:09<01:24, 319.21 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20806/47780 [01:09<01:25, 314.81 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21057/47780 [01:09<01:42, 261.76 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20734/47780 [01:09<01:28, 307.07 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21357/47780 [01:09<01:25, 309.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21165/47780 [01:09<01:23, 318.59 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21296/47780 [01:09<01:30, 292.90 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20870/47780 [01:09<01:25, 316.52 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20839/47780 [01:09<01:25, 313.27 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21087/47780 [01:09<01:41, 264.17 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20768/47780 [01:09<01:25, 316.60 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6702/47780 [01:09<02:06, 325.17 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21198/47780 [01:09<01:23, 317.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21389/47780 [01:09<01:27, 302.55 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21327/47780 [01:09<01:30, 291.24 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20907/47780 [01:09<01:21, 328.13 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20871/47780 [01:09<01:27, 308.17 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21114/47780 [01:09<01:45, 253.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20800/47780 [01:09<01:28, 303.41 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21420/47780 [01:09<01:33, 283.29 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21357/47780 [01:09<01:36, 272.71 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20950/47780 [01:09<01:15, 353.28 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20910/47780 [01:09<01:21, 331.47 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6750/47780 [01:09<02:12, 310.24 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21230/47780 [01:09<01:44, 252.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21147/47780 [01:09<01:39, 268.95 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20831/47780 [01:09<01:37, 276.71 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21391/47780 [01:09<01:32, 284.62 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21449/47780 [01:10<01:39, 265.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20992/47780 [01:09<01:12, 368.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20944/47780 [01:09<01:27, 305.37 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21176/47780 [01:10<01:40, 265.95 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20860/47780 [01:09<01:37, 277.23 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21258/47780 [01:10<01:51, 237.70 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6792/47780 [01:10<02:15, 301.99 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21425/47780 [01:10<01:29, 293.29 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21481/47780 [01:10<01:36, 271.44 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21030/47780 [01:10<01:12, 370.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20979/47780 [01:10<01:24, 317.47 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21203/47780 [01:10<01:44, 255.49 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20892/47780 [01:10<01:34, 285.95 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21316/47780 [01:10<01:24, 313.27 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6829/47780 [01:10<02:16, 299.51 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21513/47780 [01:10<01:32, 284.32 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21455/47780 [01:10<01:31, 288.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21068/47780 [01:10<01:12, 368.28 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21013/47780 [01:10<01:27, 306.61 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21230/47780 [01:10<01:44, 254.09 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20921/47780 [01:10<01:34, 283.91 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21350/47780 [01:10<01:23, 316.85 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6865/47780 [01:10<02:14, 304.51 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21542/47780 [01:10<01:32, 283.39 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21485/47780 [01:10<01:34, 279.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21105/47780 [01:10<01:17, 345.83 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21257/47780 [01:10<01:42, 258.13 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21045/47780 [01:10<01:30, 294.47 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20950/47780 [01:10<01:41, 264.58 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21572/47780 [01:10<01:33, 281.12 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6902/47780 [01:10<02:13, 305.39 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21522/47780 [01:10<01:28, 297.73 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21384/47780 [01:10<01:33, 280.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21140/47780 [01:10<01:20, 332.45 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21283/47780 [01:10<01:43, 256.11 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21075/47780 [01:10<01:31, 292.73 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20981/47780 [01:10<01:38, 271.03 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21601/47780 [01:10<01:35, 274.46 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21560/47780 [01:10<01:21, 320.51 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21426/47780 [01:10<01:23, 314.94 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6935/47780 [01:10<02:15, 301.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21174/47780 [01:10<01:21, 327.32 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21316/47780 [01:10<01:35, 277.28 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21108/47780 [01:10<01:28, 299.73 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21014/47780 [01:10<01:33, 285.84 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21629/47780 [01:10<01:34, 275.53 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21596/47780 [01:10<01:18, 331.55 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21207/47780 [01:10<01:22, 323.91 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21460/47780 [01:10<01:26, 305.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6967/47780 [01:10<02:20, 290.54 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21350/47780 [01:10<01:31, 287.33 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21139/47780 [01:10<01:38, 269.32 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21043/47780 [01:10<01:39, 267.44 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21630/47780 [01:10<01:19, 330.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21657/47780 [01:10<01:43, 253.49 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21243/47780 [01:10<01:22, 320.09 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6998/47780 [01:10<02:24, 281.83 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21388/47780 [01:10<01:25, 308.35 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21492/47780 [01:10<01:38, 267.06 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21176/47780 [01:10<01:30, 295.43 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21664/47780 [01:10<01:19, 329.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21075/47780 [01:10<01:35, 278.74 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21693/47780 [01:10<01:36, 271.23 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21280/47780 [01:10<01:20, 327.31 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7028/47780 [01:10<02:22, 286.26 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21419/47780 [01:10<01:28, 298.46 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21525/47780 [01:10<01:35, 274.74 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21698/47780 [01:10<01:19, 328.85 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21110/47780 [01:10<01:30, 295.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21207/47780 [01:10<01:32, 287.25 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21722/47780 [01:11<01:35, 273.81 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21313/47780 [01:10<01:20, 327.51 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7065/47780 [01:10<02:12, 307.85 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21449/47780 [01:11<01:38, 268.62 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21560/47780 [01:11<01:31, 288.02 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21245/47780 [01:10<01:26, 307.90 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21146/47780 [01:10<01:26, 308.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21731/47780 [01:10<01:20, 323.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21753/47780 [01:11<01:31, 283.37 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21346/47780 [01:11<01:22, 321.33 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7100/47780 [01:11<02:10, 312.48 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21590/47780 [01:11<01:30, 288.15 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21477/47780 [01:11<01:39, 263.18 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21765/47780 [01:11<01:19, 326.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21277/47780 [01:11<01:26, 305.65 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21382/47780 [01:11<01:19, 331.91 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21782/47780 [01:11<01:36, 269.94 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21178/47780 [01:11<01:37, 272.25 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7139/47780 [01:11<02:05, 323.08 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21621/47780 [01:11<01:29, 290.83 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21505/47780 [01:11<01:38, 267.63 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21798/47780 [01:11<01:20, 323.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21308/47780 [01:11<01:30, 293.94 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21416/47780 [01:11<01:19, 330.75 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21812/47780 [01:11<01:35, 272.35 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21215/47780 [01:11<01:31, 289.34 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7172/47780 [01:11<02:07, 317.78 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21538/47780 [01:11<01:33, 281.29 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21652/47780 [01:11<01:31, 286.70 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21831/47780 [01:11<01:20, 324.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21343/47780 [01:11<01:26, 306.00 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21450/47780 [01:11<01:20, 325.14 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21249/47780 [01:11<01:27, 302.72 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7205/47780 [01:11<02:09, 314.45 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21840/47780 [01:11<01:42, 253.79 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21568/47780 [01:11<01:31, 286.52 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21685/47780 [01:11<01:28, 295.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21375/47780 [01:11<01:26, 306.06 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21864/47780 [01:11<01:29, 289.63 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21483/47780 [01:11<01:20, 326.12 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7243/47780 [01:11<02:01, 332.49 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21882/47780 [01:11<01:28, 293.11 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21601/47780 [01:11<01:31, 286.72 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21282/47780 [01:11<01:43, 256.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21406/47780 [01:11<01:29, 294.16 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21897/47780 [01:11<01:26, 300.57 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21715/47780 [01:11<01:39, 261.55 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21517/47780 [01:11<01:20, 327.23 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7278/47780 [01:11<02:06, 319.26 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21912/47780 [01:11<01:29, 288.61 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21633/47780 [01:11<01:29, 292.77 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21436/47780 [01:11<01:29, 295.36 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21931/47780 [01:11<01:23, 308.50 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21759/47780 [01:11<01:25, 304.84 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21550/47780 [01:11<01:22, 316.05 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7321/47780 [01:11<01:56, 346.51 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21942/47780 [01:11<01:36, 267.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21663/47780 [01:11<01:35, 272.78 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21310/47780 [01:11<02:11, 201.41 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21798/47780 [01:11<01:19, 327.59 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21466/47780 [01:11<01:33, 280.94 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21964/47780 [01:11<01:25, 300.86 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21583/47780 [01:11<01:27, 300.83 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7356/47780 [01:11<01:56, 347.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21692/47780 [01:11<01:34, 274.65 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21970/47780 [01:11<01:40, 257.58 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21383/47780 [01:11<01:24, 313.03 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21995/47780 [01:11<01:25, 300.12 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21836/47780 [01:11<01:18, 331.31 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21495/47780 [01:11<01:39, 263.09 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7392/47780 [01:11<01:55, 350.70 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21614/47780 [01:11<01:29, 292.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21725/47780 [01:11<01:29, 290.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22001/47780 [01:12<01:35, 268.87 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21875/47780 [01:12<01:14, 347.23 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7428/47780 [01:12<01:56, 347.05 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22026/47780 [01:12<01:31, 280.47 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21421/47780 [01:11<01:29, 292.96 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21645/47780 [01:12<01:30, 287.77 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21522/47780 [01:12<01:47, 243.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22031/47780 [01:12<01:32, 277.36 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21755/47780 [01:12<01:34, 274.21 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21911/47780 [01:12<01:14, 347.32 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7463/47780 [01:12<01:56, 346.41 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22056/47780 [01:12<01:33, 273.85 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21456/47780 [01:12<01:28, 297.96 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21554/47780 [01:12<01:40, 261.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22068/47780 [01:12<01:26, 296.67 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21674/47780 [01:12<01:47, 243.11 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21947/47780 [01:12<01:15, 342.90 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21791/47780 [01:12<01:32, 282.30 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7498/47780 [01:12<02:00, 334.19 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22084/47780 [01:12<01:34, 272.79 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21490/47780 [01:12<01:28, 298.59 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22099/47780 [01:12<01:26, 297.13 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21581/47780 [01:12<01:51, 235.50 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21716/47780 [01:12<01:30, 287.18 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21824/47780 [01:12<01:28, 292.08 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21982/47780 [01:12<01:20, 319.74 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7532/47780 [01:12<02:00, 333.55 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22115/47780 [01:12<01:30, 283.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21523/47780 [01:12<01:31, 287.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22129/47780 [01:12<01:26, 295.34 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21618/47780 [01:12<01:37, 267.41 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21757/47780 [01:12<01:23, 312.98 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21854/47780 [01:12<01:28, 293.91 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22015/47780 [01:12<01:20, 318.81 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7575/47780 [01:12<01:52, 357.59 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22144/47780 [01:12<01:29, 285.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21555/47780 [01:12<01:28, 295.28 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21646/47780 [01:12<01:38, 265.03 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22173/47780 [01:12<01:19, 321.27 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21793/47780 [01:12<01:20, 322.14 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21884/47780 [01:12<01:28, 292.77 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22181/47780 [01:12<01:23, 308.34 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7611/47780 [01:12<02:00, 334.68 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22048/47780 [01:12<01:28, 292.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21586/47780 [01:12<01:28, 295.97 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21676/47780 [01:12<01:37, 268.25 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22206/47780 [01:12<01:23, 306.47 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21827/47780 [01:12<01:24, 308.93 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21914/47780 [01:12<01:32, 278.86 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22219/47780 [01:12<01:19, 322.75 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7646/47780 [01:12<01:59, 335.52 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22078/47780 [01:12<01:27, 294.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21619/47780 [01:12<01:25, 305.09 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22237/47780 [01:12<01:25, 297.65 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21704/47780 [01:12<01:43, 252.35 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21943/47780 [01:12<01:31, 281.94 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22262/47780 [01:12<01:12, 349.89 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21859/47780 [01:12<01:29, 290.93 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7681/47780 [01:12<01:59, 335.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22110/47780 [01:12<01:26, 298.48 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21651/47780 [01:12<01:30, 287.17 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21738/47780 [01:12<01:34, 275.61 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21973/47780 [01:12<01:35, 271.61 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22267/47780 [01:12<01:33, 273.88 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22142/47780 [01:12<01:24, 304.22 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7719/47780 [01:12<01:57, 341.43 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22298/47780 [01:12<01:19, 321.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21889/47780 [01:12<01:34, 272.63 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21691/47780 [01:12<01:23, 314.18 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21768/47780 [01:12<01:34, 276.24 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7755/47780 [01:12<01:55, 345.46 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22296/47780 [01:13<01:36, 264.13 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21917/47780 [01:12<01:35, 272.04 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22331/47780 [01:12<01:21, 311.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22001/47780 [01:13<01:44, 247.41 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22174/47780 [01:13<01:30, 283.27 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21724/47780 [01:12<01:21, 318.40 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21797/47780 [01:13<01:32, 279.99 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7798/47780 [01:13<01:48, 369.79 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22324/47780 [01:13<01:35, 265.69 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21945/47780 [01:13<01:34, 274.08 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22036/47780 [01:13<01:34, 273.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22203/47780 [01:13<01:29, 284.97 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21758/47780 [01:13<01:20, 322.21 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22363/47780 [01:13<01:29, 282.93 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21826/47780 [01:13<01:36, 268.98 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7836/47780 [01:13<01:50, 360.53 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21973/47780 [01:13<01:34, 272.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22351/47780 [01:13<01:36, 262.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22065/47780 [01:13<01:34, 271.93 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22237/47780 [01:13<01:28, 287.47 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21791/47780 [01:13<01:21, 319.25 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22392/47780 [01:13<01:30, 281.85 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21861/47780 [01:13<01:30, 287.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22383/47780 [01:13<01:31, 276.83 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7873/47780 [01:13<01:58, 336.23 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22101/47780 [01:13<01:28, 289.79 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22003/47780 [01:13<01:38, 262.88 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22272/47780 [01:13<01:24, 301.39 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21824/47780 [01:13<01:25, 302.07 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21890/47780 [01:13<01:29, 287.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22421/47780 [01:13<01:37, 258.92 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7912/47780 [01:13<01:56, 343.64 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22037/47780 [01:13<01:31, 280.96 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22303/47780 [01:13<01:24, 303.09 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22411/47780 [01:13<01:39, 254.82 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22131/47780 [01:13<01:34, 271.64 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21856/47780 [01:13<01:24, 307.04 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21919/47780 [01:13<01:31, 282.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22448/47780 [01:13<01:39, 253.84 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22066/47780 [01:13<01:32, 277.29 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22440/47780 [01:13<01:36, 261.41 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7947/47780 [01:13<02:00, 330.74 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22334/47780 [01:13<01:28, 286.18 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22160/47780 [01:13<01:33, 273.40 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21893/47780 [01:13<01:20, 321.34 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21948/47780 [01:13<01:34, 274.77 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22482/47780 [01:13<01:31, 275.77 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22099/47780 [01:13<01:28, 288.77 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22468/47780 [01:13<01:35, 266.32 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7981/47780 [01:13<02:00, 329.58 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22368/47780 [01:13<01:27, 291.04 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22192/47780 [01:13<01:33, 274.37 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21926/47780 [01:13<01:25, 304.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21976/47780 [01:13<01:42, 250.67 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22511/47780 [01:13<01:42, 247.52 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22500/47780 [01:13<01:30, 279.16 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22129/47780 [01:13<01:30, 282.12 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8015/47780 [01:13<02:04, 318.24 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22400/47780 [01:13<01:25, 296.16 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22222/47780 [01:13<01:30, 281.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21957/47780 [01:13<01:25, 300.57 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22005/47780 [01:13<01:40, 255.99 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22553/47780 [01:13<01:27, 288.33 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22529/47780 [01:13<01:32, 272.38 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22164/47780 [01:13<01:27, 291.69 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8048/47780 [01:13<02:05, 317.52 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22261/47780 [01:13<01:22, 308.55 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22433/47780 [01:13<01:23, 302.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21988/47780 [01:13<01:27, 296.43 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22032/47780 [01:13<01:45, 243.62 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22202/47780 [01:13<01:20, 316.41 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22557/47780 [01:14<01:34, 268.09 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22295/47780 [01:13<01:20, 317.40 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22465/47780 [01:13<01:22, 306.05 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22583/47780 [01:13<01:33, 269.17 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8081/47780 [01:13<02:10, 304.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22019/47780 [01:13<01:30, 284.92 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22069/47780 [01:14<01:33, 274.80 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22237/47780 [01:14<01:19, 322.28 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22587/47780 [01:14<01:31, 274.34 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22327/47780 [01:14<01:21, 311.04 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22622/47780 [01:14<01:25, 294.82 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8113/47780 [01:14<02:14, 295.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22049/47780 [01:14<01:29, 289.05 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22099/47780 [01:14<01:32, 278.70 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22278/47780 [01:14<01:14, 343.62 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22622/47780 [01:14<01:27, 287.53 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22498/47780 [01:14<01:45, 239.55 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22363/47780 [01:14<01:18, 324.80 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22654/47780 [01:14<01:23, 301.34 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8143/47780 [01:14<02:16, 290.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22079/47780 [01:14<01:30, 282.62 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22315/47780 [01:14<01:13, 347.26 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22687/47780 [01:14<01:21, 306.10 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22654/47780 [01:14<01:27, 285.55 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22128/47780 [01:14<01:38, 261.00 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22396/47780 [01:14<01:25, 298.46 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8177/47780 [01:14<02:14, 294.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22113/47780 [01:14<01:25, 298.72 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22527/47780 [01:14<01:57, 214.63 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22351/47780 [01:14<01:15, 338.82 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22155/47780 [01:14<01:38, 260.99 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22683/47780 [01:14<01:30, 277.45 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22435/47780 [01:14<01:18, 322.94 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22719/47780 [01:14<01:27, 287.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8217/47780 [01:14<02:03, 320.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22144/47780 [01:14<01:30, 282.42 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22588/47780 [01:14<01:22, 303.78 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22386/47780 [01:14<01:15, 334.51 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22712/47780 [01:14<01:31, 273.90 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22750/47780 [01:14<01:27, 287.23 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22182/47780 [01:14<01:44, 244.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22468/47780 [01:14<01:22, 305.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22176/47780 [01:14<01:28, 288.16 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22625/47780 [01:14<01:20, 310.72 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8253/47780 [01:14<02:12, 297.71 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22420/47780 [01:14<01:19, 318.16 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22740/47780 [01:14<01:31, 273.28 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22780/47780 [01:14<01:26, 287.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22210/47780 [01:14<01:40, 253.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22209/47780 [01:14<01:25, 298.23 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8284/47780 [01:14<02:16, 288.70 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22500/47780 [01:14<01:33, 270.64 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22660/47780 [01:14<01:28, 283.64 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22453/47780 [01:14<01:19, 317.16 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22814/47780 [01:14<01:23, 299.00 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22768/47780 [01:14<01:35, 260.65 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22239/47780 [01:14<01:40, 252.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22249/47780 [01:14<01:18, 327.00 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22547/47780 [01:14<01:19, 318.32 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8314/47780 [01:14<02:21, 279.49 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22698/47780 [01:14<01:21, 306.81 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22490/47780 [01:14<01:16, 329.20 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22855/47780 [01:14<01:16, 326.65 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22804/47780 [01:14<01:27, 285.06 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22274/47780 [01:14<01:32, 276.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22287/47780 [01:14<01:15, 338.64 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22581/47780 [01:14<01:20, 314.21 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8343/47780 [01:14<02:31, 260.23 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22732/47780 [01:14<01:23, 299.98 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22524/47780 [01:14<01:18, 320.80 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22892/47780 [01:14<01:13, 338.33 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22835/47780 [01:15<01:25, 290.39 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22302/47780 [01:14<01:32, 274.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22323/47780 [01:14<01:13, 344.71 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22620/47780 [01:15<01:18, 320.60 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22557/47780 [01:15<01:18, 323.32 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22865/47780 [01:15<01:27, 284.94 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22330/47780 [01:15<01:32, 275.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8370/47780 [01:15<02:40, 244.94 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22764/47780 [01:15<01:28, 281.84 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22358/47780 [01:15<01:16, 334.28 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22927/47780 [01:15<01:21, 306.67 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22654/47780 [01:15<01:17, 325.61 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22593/47780 [01:15<01:15, 333.74 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22901/47780 [01:15<01:21, 306.05 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22359/47780 [01:15<01:32, 273.55 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8395/47780 [01:15<02:42, 241.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22794/47780 [01:15<01:27, 285.80 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22394/47780 [01:15<01:14, 340.38 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22962/47780 [01:15<01:19, 311.73 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22630/47780 [01:15<01:13, 341.01 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22688/47780 [01:15<01:22, 303.04 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22932/47780 [01:15<01:21, 303.56 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22395/47780 [01:15<01:25, 295.45 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8420/47780 [01:15<02:41, 243.47 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22432/47780 [01:15<01:14, 341.68 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22825/47780 [01:15<01:30, 275.25 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22994/47780 [01:15<01:21, 304.27 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22720/47780 [01:15<01:21, 307.24 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22665/47780 [01:15<01:16, 327.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22963/47780 [01:15<01:24, 292.33 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8445/47780 [01:15<02:45, 237.15 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22425/47780 [01:15<01:29, 282.34 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23029/47780 [01:15<01:19, 313.10 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22854/47780 [01:15<01:35, 262.30 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22467/47780 [01:15<01:21, 311.58 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22752/47780 [01:15<01:20, 310.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22698/47780 [01:15<01:18, 318.16 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22454/47780 [01:15<01:29, 282.45 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22993/47780 [01:15<01:27, 284.49 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8478/47780 [01:15<02:34, 254.55 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23061/47780 [01:15<01:18, 314.97 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22889/47780 [01:15<01:28, 282.64 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22501/47780 [01:15<01:19, 316.28 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22789/47780 [01:15<01:17, 324.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22735/47780 [01:15<01:16, 329.12 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23024/47780 [01:15<01:25, 288.79 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8510/47780 [01:15<02:27, 266.63 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23099/47780 [01:15<01:14, 333.49 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22483/47780 [01:15<01:36, 263.45 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22534/47780 [01:15<01:21, 311.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22919/47780 [01:15<01:32, 269.78 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22822/47780 [01:15<01:22, 301.89 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23053/47780 [01:15<01:28, 278.49 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22769/47780 [01:15<01:23, 300.95 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23140/47780 [01:15<01:11, 344.03 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22513/47780 [01:15<01:32, 272.10 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22567/47780 [01:15<01:20, 311.28 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8537/47780 [01:15<02:46, 236.24 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22948/47780 [01:15<01:32, 269.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22857/47780 [01:15<01:19, 311.57 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23083/47780 [01:15<01:28, 279.40 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23178/47780 [01:15<01:09, 354.30 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22803/47780 [01:15<01:21, 307.33 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22541/47780 [01:15<01:39, 253.18 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22609/47780 [01:15<01:14, 337.92 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8586/47780 [01:15<02:12, 295.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22976/47780 [01:15<01:36, 255.72 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22889/47780 [01:15<01:21, 307.12 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23115/47780 [01:16<01:25, 290.00 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22835/47780 [01:15<01:21, 304.69 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23214/47780 [01:15<01:11, 344.11 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22567/47780 [01:15<01:38, 254.99 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22650/47780 [01:15<01:10, 354.51 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8617/47780 [01:15<02:15, 290.05 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23002/47780 [01:15<01:36, 256.55 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22933/47780 [01:16<01:14, 333.27 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23145/47780 [01:16<01:26, 283.89 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23255/47780 [01:16<01:07, 362.76 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22866/47780 [01:16<01:23, 299.68 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22686/47780 [01:16<01:13, 340.50 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22593/47780 [01:16<01:44, 241.77 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8648/47780 [01:16<02:13, 292.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23033/47780 [01:16<01:32, 268.72 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22967/47780 [01:16<01:15, 327.67 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23178/47780 [01:16<01:24, 290.91 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23293/47780 [01:16<01:08, 359.37 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22897/47780 [01:16<01:28, 280.91 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8678/47780 [01:16<02:14, 291.51 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22721/47780 [01:16<01:16, 328.12 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23065/47780 [01:16<01:28, 279.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22618/47780 [01:16<01:51, 224.94 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23331/47780 [01:16<01:07, 360.74 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23209/47780 [01:16<01:25, 286.21 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23000/47780 [01:16<01:23, 298.27 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22932/47780 [01:16<01:24, 293.39 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8714/47780 [01:16<02:05, 310.69 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22755/47780 [01:16<01:17, 320.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23094/47780 [01:16<01:29, 276.51 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22650/47780 [01:16<01:41, 248.06 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23238/47780 [01:16<01:26, 283.63 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23368/47780 [01:16<01:12, 336.55 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22967/47780 [01:16<01:20, 308.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8748/47780 [01:16<02:05, 311.85 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23122/47780 [01:16<01:30, 271.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22788/47780 [01:16<01:19, 316.05 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22677/47780 [01:16<01:40, 248.57 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23269/47780 [01:16<01:27, 278.82 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23031/47780 [01:16<01:46, 231.81 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23403/47780 [01:16<01:13, 329.53 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23004/47780 [01:16<01:19, 312.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8780/47780 [01:16<02:04, 314.06 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22820/47780 [01:16<01:19, 314.06 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23152/47780 [01:16<01:30, 273.18 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22707/47780 [01:16<01:36, 259.89 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23117/47780 [01:16<01:05, 374.29 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23297/47780 [01:16<01:29, 272.49 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23042/47780 [01:16<01:15, 327.42 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8822/47780 [01:16<01:53, 343.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23437/47780 [01:16<01:15, 321.04 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23183/47780 [01:16<01:27, 280.60 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22741/47780 [01:16<01:29, 279.25 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22852/47780 [01:16<01:21, 305.22 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23075/47780 [01:16<01:16, 320.86 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8857/47780 [01:16<01:57, 330.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23325/47780 [01:16<01:37, 249.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23470/47780 [01:16<01:20, 303.33 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23212/47780 [01:16<01:27, 280.02 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22884/47780 [01:16<01:22, 302.78 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22771/47780 [01:16<01:29, 278.81 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23161/47780 [01:16<01:12, 337.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8893/47780 [01:16<01:57, 332.08 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23353/47780 [01:16<01:36, 252.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23247/47780 [01:16<01:21, 300.04 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23501/47780 [01:16<01:20, 301.40 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23109/47780 [01:16<01:21, 301.97 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22806/47780 [01:16<01:23, 298.97 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22915/47780 [01:16<01:25, 291.62 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23201/47780 [01:16<01:20, 304.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8930/47780 [01:16<01:54, 339.05 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23279/47780 [01:16<01:21, 302.48 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23379/47780 [01:17<01:40, 242.38 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23140/47780 [01:16<01:23, 294.91 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22952/47780 [01:16<01:19, 313.40 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22837/47780 [01:16<01:31, 273.71 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23532/47780 [01:16<01:32, 261.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23239/47780 [01:17<01:17, 318.31 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23313/47780 [01:17<01:18, 309.78 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8965/47780 [01:17<01:58, 326.62 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23411/47780 [01:17<01:32, 262.30 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23174/47780 [01:17<01:20, 303.90 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22984/47780 [01:17<01:19, 311.29 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22877/47780 [01:17<01:21, 304.78 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23561/47780 [01:17<01:31, 263.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23275/47780 [01:17<01:15, 325.23 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23349/47780 [01:17<01:17, 313.48 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23438/47780 [01:17<01:34, 258.03 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23016/47780 [01:17<01:20, 307.12 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23205/47780 [01:17<01:25, 286.37 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8998/47780 [01:17<02:08, 300.79 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22910/47780 [01:17<01:19, 311.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23590/47780 [01:17<01:30, 267.26 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23310/47780 [01:17<01:16, 321.35 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23383/47780 [01:17<01:16, 317.33 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23466/47780 [01:17<01:33, 259.37 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23050/47780 [01:17<01:18, 313.07 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23234/47780 [01:17<01:26, 284.28 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9029/47780 [01:17<02:09, 299.95 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22944/47780 [01:17<01:18, 316.41 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23625/47780 [01:17<01:25, 280.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23345/47780 [01:17<01:15, 322.37 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23497/47780 [01:17<01:30, 267.18 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23415/47780 [01:17<01:21, 297.73 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23264/47780 [01:17<01:24, 288.43 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23082/47780 [01:17<01:22, 301.04 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9062/47780 [01:17<02:17, 280.72 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22977/47780 [01:17<01:26, 287.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23654/47780 [01:17<01:27, 277.02 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23381/47780 [01:17<01:16, 318.09 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23524/47780 [01:17<01:31, 264.82 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23300/47780 [01:17<01:19, 308.70 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23445/47780 [01:17<01:23, 291.42 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23114/47780 [01:17<01:23, 295.94 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9107/47780 [01:17<02:00, 321.85 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23682/47780 [01:17<01:27, 275.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23007/47780 [01:17<01:29, 276.00 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23421/47780 [01:17<01:12, 333.72 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23559/47780 [01:17<01:25, 282.87 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23334/47780 [01:17<01:17, 314.35 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23490/47780 [01:17<01:12, 335.21 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23144/47780 [01:17<01:25, 287.47 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23710/47780 [01:17<01:28, 272.97 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9140/47780 [01:17<02:04, 310.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23046/47780 [01:17<01:20, 306.36 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23456/47780 [01:17<01:13, 330.64 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23371/47780 [01:17<01:14, 326.76 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23588/47780 [01:17<01:26, 278.54 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23524/47780 [01:17<01:12, 333.21 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23180/47780 [01:17<01:20, 304.87 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9172/47780 [01:17<02:04, 309.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23738/47780 [01:17<01:32, 258.60 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23078/47780 [01:17<01:28, 279.42 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23411/47780 [01:17<01:10, 347.88 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23559/47780 [01:17<01:12, 334.30 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23623/47780 [01:17<01:22, 292.23 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23490/47780 [01:17<01:20, 303.37 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23211/47780 [01:17<01:23, 293.06 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23765/47780 [01:17<01:32, 261.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9205/47780 [01:17<02:07, 301.99 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23107/47780 [01:17<01:28, 279.22 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23446/47780 [01:17<01:10, 344.49 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23661/47780 [01:17<01:16, 313.47 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23593/47780 [01:17<01:15, 321.52 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23521/47780 [01:17<01:21, 296.93 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23248/47780 [01:17<01:20, 304.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23798/47780 [01:17<01:25, 280.28 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9237/47780 [01:17<02:09, 296.94 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23139/47780 [01:17<01:24, 290.05 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23486/47780 [01:17<01:07, 360.71 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23703/47780 [01:18<01:10, 340.97 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23626/47780 [01:18<01:16, 316.35 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23553/47780 [01:18<01:21, 295.61 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23289/47780 [01:17<01:15, 326.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23827/47780 [01:18<01:25, 280.08 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9269/47780 [01:18<02:06, 303.24 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23523/47780 [01:18<01:08, 354.56 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23169/47780 [01:18<01:30, 270.81 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23584/47780 [01:18<01:20, 299.49 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23738/47780 [01:18<01:14, 323.87 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23659/47780 [01:18<01:19, 302.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23857/47780 [01:18<01:24, 282.52 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23322/47780 [01:18<01:19, 307.37 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9301/47780 [01:18<02:09, 298.12 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23772/47780 [01:18<01:13, 324.96 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23560/47780 [01:18<01:13, 328.68 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23197/47780 [01:18<01:34, 260.02 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23615/47780 [01:18<01:25, 283.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23690/47780 [01:18<01:23, 288.87 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9333/47780 [01:18<02:06, 303.94 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23886/47780 [01:18<01:28, 269.08 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23353/47780 [01:18<01:22, 296.53 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23224/47780 [01:18<01:34, 259.79 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23805/47780 [01:18<01:16, 312.06 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23594/47780 [01:18<01:18, 308.36 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23721/47780 [01:18<01:22, 291.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23644/47780 [01:18<01:28, 273.16 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23384/47780 [01:18<01:21, 297.87 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23917/47780 [01:18<01:28, 268.47 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9364/47780 [01:18<02:14, 286.40 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23251/47780 [01:18<01:36, 254.51 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23837/47780 [01:18<01:17, 307.67 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23676/47780 [01:18<01:24, 285.61 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23626/47780 [01:18<01:20, 301.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23753/47780 [01:18<01:21, 293.28 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23414/47780 [01:18<01:23, 292.22 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23945/47780 [01:18<01:28, 268.67 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9398/47780 [01:18<02:08, 297.83 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23876/47780 [01:18<01:13, 327.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23284/47780 [01:18<01:34, 258.27 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23706/47780 [01:18<01:25, 280.61 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23783/47780 [01:18<01:24, 283.83 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23660/47780 [01:18<01:23, 290.00 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23452/47780 [01:18<01:17, 313.47 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23979/47780 [01:18<01:23, 285.65 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9430/47780 [01:18<02:08, 297.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23910/47780 [01:18<01:13, 326.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23313/47780 [01:18<01:33, 261.14 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23735/47780 [01:18<01:26, 277.94 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23812/47780 [01:18<01:25, 281.09 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23485/47780 [01:18<01:19, 307.47 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24008/47780 [01:18<01:24, 280.01 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23690/47780 [01:18<01:29, 269.37 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9460/47780 [01:18<02:21, 270.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23944/47780 [01:18<01:13, 325.04 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23340/47780 [01:18<01:35, 255.29 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23771/47780 [01:18<01:21, 293.44 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23842/47780 [01:18<01:24, 283.14 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24043/47780 [01:18<01:19, 297.02 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23516/47780 [01:18<01:20, 301.62 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9489/47780 [01:18<02:20, 273.02 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23718/47780 [01:18<01:34, 254.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23977/47780 [01:18<01:13, 324.78 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23804/47780 [01:18<01:18, 303.71 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23872/47780 [01:18<01:23, 287.49 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24078/47780 [01:18<01:16, 308.51 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23547/47780 [01:18<01:20, 300.59 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23366/47780 [01:18<01:43, 235.14 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9520/47780 [01:18<02:15, 283.15 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23744/47780 [01:18<01:36, 247.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24010/47780 [01:19<01:14, 318.96 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23901/47780 [01:19<01:27, 273.40 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23835/47780 [01:19<01:24, 282.01 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23394/47780 [01:18<01:39, 245.15 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23578/47780 [01:18<01:20, 299.68 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24109/47780 [01:19<01:20, 295.52 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23771/47780 [01:19<01:34, 253.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9549/47780 [01:19<02:26, 261.20 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23930/47780 [01:19<01:26, 274.51 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23872/47780 [01:19<01:18, 303.81 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24043/47780 [01:19<01:23, 285.64 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23419/47780 [01:19<01:38, 246.25 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24141/47780 [01:19<01:19, 295.77 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23608/47780 [01:19<01:25, 284.14 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23799/47780 [01:19<01:34, 252.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9580/47780 [01:19<02:22, 268.87 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23966/47780 [01:19<01:20, 295.46 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23903/47780 [01:19<01:18, 305.25 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23444/47780 [01:19<01:39, 244.26 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24171/47780 [01:19<01:19, 296.42 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23641/47780 [01:19<01:21, 296.29 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24073/47780 [01:19<01:31, 258.86 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23826/47780 [01:19<01:33, 257.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9610/47780 [01:19<02:17, 277.24 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23996/47780 [01:19<01:21, 293.45 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23938/47780 [01:19<01:14, 317.95 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23474/47780 [01:19<01:34, 257.74 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23672/47780 [01:19<01:21, 297.04 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24207/47780 [01:19<01:18, 301.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24106/47780 [01:19<01:26, 274.61 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9641/47780 [01:19<02:14, 283.36 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23852/47780 [01:19<01:37, 244.57 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24031/47780 [01:19<01:16, 309.67 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23972/47780 [01:19<01:14, 320.96 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23502/47780 [01:19<01:31, 264.08 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23702/47780 [01:19<01:21, 294.46 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24254/47780 [01:19<01:08, 341.27 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24135/47780 [01:19<01:31, 258.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9674/47780 [01:19<02:09, 293.35 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23877/47780 [01:19<01:42, 233.24 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24063/47780 [01:19<01:15, 312.32 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24005/47780 [01:19<01:14, 319.85 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23530/47780 [01:19<01:33, 259.16 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24289/47780 [01:19<01:08, 343.47 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23732/47780 [01:19<01:24, 285.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9707/47780 [01:19<02:06, 300.26 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24162/47780 [01:19<01:38, 239.71 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23908/47780 [01:19<01:37, 246.03 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24038/47780 [01:19<01:15, 313.14 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23563/47780 [01:19<01:27, 276.82 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24325/47780 [01:19<01:08, 344.59 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23761/47780 [01:19<01:25, 280.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24095/47780 [01:19<01:28, 267.80 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24196/47780 [01:19<01:29, 262.78 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23933/47780 [01:19<01:37, 244.53 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24073/47780 [01:19<01:14, 318.87 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9738/47780 [01:19<02:21, 268.78 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23594/47780 [01:19<01:25, 283.00 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24360/47780 [01:19<01:07, 345.85 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23796/47780 [01:19<01:20, 297.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24138/47780 [01:19<01:16, 309.93 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23963/47780 [01:19<01:31, 259.84 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24229/47780 [01:19<01:25, 274.68 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9770/47780 [01:19<02:15, 279.93 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24105/47780 [01:19<01:17, 305.03 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23623/47780 [01:19<01:30, 266.21 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24171/47780 [01:19<01:15, 312.27 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23828/47780 [01:19<01:21, 293.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24395/47780 [01:19<01:15, 308.91 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23990/47780 [01:19<01:31, 259.75 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24262/47780 [01:20<01:22, 283.53 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9800/47780 [01:19<02:14, 282.18 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24144/47780 [01:19<01:12, 325.41 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23651/47780 [01:19<01:30, 267.54 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24204/47780 [01:20<01:15, 310.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23859/47780 [01:19<01:22, 288.52 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24427/47780 [01:19<01:16, 303.66 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24017/47780 [01:20<01:31, 259.71 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24298/47780 [01:20<01:17, 304.48 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9831/47780 [01:20<02:16, 277.73 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24177/47780 [01:20<01:13, 322.73 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23681/47780 [01:20<01:28, 273.48 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24246/47780 [01:20<01:09, 337.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23888/47780 [01:20<01:25, 279.51 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24458/47780 [01:20<01:20, 289.96 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24045/47780 [01:20<01:30, 262.76 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24330/47780 [01:20<01:17, 302.00 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24214/47780 [01:20<01:11, 330.97 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23714/47780 [01:20<01:24, 286.38 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24283/47780 [01:20<01:08, 342.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23917/47780 [01:20<01:25, 279.32 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9860/47780 [01:20<02:41, 235.40 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24488/47780 [01:20<01:25, 272.15 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24361/47780 [01:20<01:19, 294.34 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24072/47780 [01:20<01:36, 244.60 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23744/47780 [01:20<01:23, 286.90 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24319/47780 [01:20<01:08, 343.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24249/47780 [01:20<01:18, 300.15 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23954/47780 [01:20<01:19, 298.28 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9925/47780 [01:20<01:52, 337.01 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24108/47780 [01:20<01:27, 270.92 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24516/47780 [01:20<01:29, 260.49 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24391/47780 [01:20<01:26, 271.18 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23773/47780 [01:20<01:26, 278.30 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24354/47780 [01:20<01:10, 330.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23984/47780 [01:20<01:19, 298.67 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24286/47780 [01:20<01:16, 308.87 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9962/47780 [01:20<01:50, 341.84 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24136/47780 [01:20<01:26, 273.44 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24551/47780 [01:20<01:22, 279.87 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24425/47780 [01:20<01:25, 272.45 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24388/47780 [01:20<01:11, 329.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24018/47780 [01:20<01:17, 307.44 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24318/47780 [01:20<01:16, 307.63 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23801/47780 [01:20<01:34, 252.56 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24168/47780 [01:20<01:23, 283.52 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9999/47780 [01:20<02:01, 312.20 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24580/47780 [01:20<01:26, 269.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24457/47780 [01:20<01:22, 282.10 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24350/47780 [01:20<01:16, 305.15 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24422/47780 [01:20<01:15, 311.08 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23827/47780 [01:20<01:37, 246.83 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24049/47780 [01:20<01:25, 275.97 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10035/47780 [01:20<01:57, 321.32 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24197/47780 [01:20<01:28, 266.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24613/47780 [01:20<01:21, 285.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24488/47780 [01:20<01:22, 283.52 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24385/47780 [01:20<01:13, 317.51 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23854/47780 [01:20<01:34, 253.12 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24454/47780 [01:20<01:17, 299.92 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24078/47780 [01:20<01:25, 276.11 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24224/47780 [01:20<01:28, 264.88 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10070/47780 [01:20<02:01, 309.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24652/47780 [01:20<01:14, 311.19 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24417/47780 [01:20<01:16, 304.67 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24485/47780 [01:20<01:18, 296.03 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24518/47780 [01:20<01:30, 256.96 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23880/47780 [01:20<01:41, 236.55 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24111/47780 [01:20<01:23, 282.22 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24254/47780 [01:20<01:26, 271.86 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10112/47780 [01:20<01:52, 334.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24687/47780 [01:20<01:12, 318.61 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24448/47780 [01:20<01:19, 292.53 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23908/47780 [01:20<01:37, 245.66 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24549/47780 [01:21<01:26, 267.28 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24515/47780 [01:21<01:22, 283.58 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24140/47780 [01:20<01:32, 256.18 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24725/47780 [01:20<01:09, 332.27 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24282/47780 [01:21<01:28, 264.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10148/47780 [01:21<01:53, 330.92 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24483/47780 [01:21<01:17, 298.96 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24592/47780 [01:21<01:15, 305.23 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24184/47780 [01:21<01:17, 304.23 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24761/47780 [01:21<01:08, 336.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10188/47780 [01:21<01:48, 345.94 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23933/47780 [01:21<01:53, 209.51 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24309/47780 [01:21<01:36, 244.48 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24544/47780 [01:21<01:38, 235.19 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24625/47780 [01:21<01:16, 302.02 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24514/47780 [01:21<01:22, 282.96 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24797/47780 [01:21<01:07, 342.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24216/47780 [01:21<01:18, 301.69 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23961/47780 [01:21<01:46, 222.99 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10224/47780 [01:21<01:54, 327.97 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24338/47780 [01:21<01:31, 256.49 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24589/47780 [01:21<01:21, 284.65 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24657/47780 [01:21<01:16, 303.32 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24550/47780 [01:21<01:19, 291.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24833/47780 [01:21<01:07, 339.78 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24247/47780 [01:21<01:21, 287.82 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23985/47780 [01:21<01:47, 222.20 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24365/47780 [01:21<01:36, 241.84 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24620/47780 [01:21<01:23, 276.82 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24689/47780 [01:21<01:15, 304.72 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10258/47780 [01:21<02:10, 287.64 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24876/47780 [01:21<01:03, 362.24 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24580/47780 [01:21<01:23, 278.49 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24286/47780 [01:21<01:15, 309.57 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24014/47780 [01:21<01:39, 238.40 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24404/47780 [01:21<01:23, 278.73 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24651/47780 [01:21<01:21, 285.28 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24730/47780 [01:21<01:09, 330.76 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24921/47780 [01:21<00:58, 387.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24609/47780 [01:21<01:24, 273.02 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24322/47780 [01:21<01:13, 319.89 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24039/47780 [01:21<01:39, 238.94 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24436/47780 [01:21<01:20, 290.11 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24681/47780 [01:21<01:20, 285.87 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10288/47780 [01:21<02:36, 239.98 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24769/47780 [01:21<01:06, 347.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24960/47780 [01:21<01:00, 375.17 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24637/47780 [01:21<01:26, 266.23 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24355/47780 [01:21<01:14, 315.62 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24068/47780 [01:21<01:34, 250.91 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24467/47780 [01:21<01:18, 295.72 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24723/47780 [01:21<01:12, 320.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10314/47780 [01:21<02:48, 222.18 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24998/47780 [01:21<01:01, 367.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24805/47780 [01:21<01:13, 311.38 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24100/47780 [01:21<01:27, 269.91 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24387/47780 [01:21<01:14, 313.06 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24503/47780 [01:21<01:14, 310.65 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24757/47780 [01:21<01:10, 325.29 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24666/47780 [01:21<01:33, 248.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25036/47780 [01:21<01:01, 367.16 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24838/47780 [01:21<01:17, 296.53 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10339/47780 [01:21<03:03, 204.23 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24419/47780 [01:21<01:18, 298.39 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24536/47780 [01:21<01:15, 309.08 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24128/47780 [01:21<01:34, 250.34 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24694/47780 [01:21<01:30, 254.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24791/47780 [01:21<01:16, 302.11 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25073/47780 [01:21<01:05, 344.53 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24452/47780 [01:21<01:16, 306.93 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24869/47780 [01:22<01:21, 280.32 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24158/47780 [01:21<01:30, 260.52 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24722/47780 [01:22<01:31, 252.80 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10361/47780 [01:22<03:14, 192.14 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24569/47780 [01:22<01:20, 288.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24826/47780 [01:22<01:16, 298.88 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25111/47780 [01:22<01:05, 346.28 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24483/47780 [01:22<01:16, 304.41 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24900/47780 [01:22<01:20, 285.13 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24185/47780 [01:22<01:30, 259.85 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24748/47780 [01:22<01:31, 252.21 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24599/47780 [01:22<01:23, 276.30 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10381/47780 [01:22<03:25, 182.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24863/47780 [01:22<01:14, 308.08 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24516/47780 [01:22<01:15, 308.38 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24931/47780 [01:22<01:20, 282.64 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24212/47780 [01:22<01:32, 254.07 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25146/47780 [01:22<01:11, 318.38 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24774/47780 [01:22<01:32, 248.70 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24631/47780 [01:22<01:22, 279.66 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10589/47780 [01:22<01:00, 618.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24895/47780 [01:22<01:16, 298.41 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24557/47780 [01:22<01:08, 337.37 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24963/47780 [01:22<01:18, 289.67 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24238/47780 [01:22<01:33, 252.97 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24800/47780 [01:22<01:33, 246.49 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25179/47780 [01:22<01:13, 308.71 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24660/47780 [01:22<01:23, 276.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24930/47780 [01:22<01:13, 312.23 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24592/47780 [01:22<01:10, 329.72 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10660/47780 [01:22<01:05, 562.79 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24993/47780 [01:22<01:17, 292.49 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24829/47780 [01:22<01:29, 255.75 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24265/47780 [01:22<01:38, 239.16 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24694/47780 [01:22<01:19, 290.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24964/47780 [01:22<01:12, 316.74 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25211/47780 [01:22<01:22, 273.66 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24633/47780 [01:22<01:06, 348.87 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25023/47780 [01:22<01:18, 288.15 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24860/47780 [01:22<01:25, 268.14 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10724/47780 [01:22<01:09, 534.81 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24292/47780 [01:22<01:36, 242.28 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24996/47780 [01:22<01:11, 317.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24727/47780 [01:22<01:18, 295.00 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25244/47780 [01:22<01:19, 282.19 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24671/47780 [01:22<01:04, 357.80 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25052/47780 [01:22<01:18, 287.98 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24887/47780 [01:22<01:26, 265.56 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24317/47780 [01:22<01:38, 237.13 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24757/47780 [01:22<01:20, 285.81 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25029/47780 [01:22<01:15, 300.52 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25274/47780 [01:22<01:20, 280.91 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24715/47780 [01:22<01:01, 377.41 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10783/47780 [01:22<01:17, 475.59 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25081/47780 [01:22<01:21, 279.58 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24915/47780 [01:22<01:26, 263.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24344/47780 [01:22<01:38, 237.73 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24790/47780 [01:22<01:18, 292.70 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25066/47780 [01:22<01:11, 316.19 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25303/47780 [01:22<01:24, 266.07 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24753/47780 [01:22<01:04, 358.46 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10835/47780 [01:22<01:20, 456.88 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25110/47780 [01:22<01:21, 279.23 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24945/47780 [01:22<01:24, 270.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24370/47780 [01:22<01:37, 241.27 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24821/47780 [01:22<01:17, 297.16 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25098/47780 [01:22<01:13, 310.39 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25330/47780 [01:22<01:25, 261.58 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24797/47780 [01:22<01:01, 371.38 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25138/47780 [01:23<01:21, 279.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24978/47780 [01:22<01:21, 281.40 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24395/47780 [01:22<01:38, 238.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10884/47780 [01:22<01:29, 413.78 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24851/47780 [01:23<01:17, 294.67 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25130/47780 [01:23<01:17, 293.16 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25357/47780 [01:23<01:26, 258.00 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25166/47780 [01:23<01:22, 274.18 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25012/47780 [01:23<01:17, 295.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24835/47780 [01:23<01:06, 342.89 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24419/47780 [01:23<01:39, 233.63 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10928/47780 [01:23<01:35, 384.57 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25383/47780 [01:23<01:28, 253.06 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25195/47780 [01:23<01:21, 277.93 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25160/47780 [01:23<01:21, 276.60 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25042/47780 [01:23<01:17, 292.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24870/47780 [01:23<01:08, 334.33 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24444/47780 [01:23<01:37, 238.14 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24882/47780 [01:23<01:41, 226.32 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25413/47780 [01:23<01:24, 263.63 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10968/47780 [01:23<01:40, 367.72 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25226/47780 [01:23<01:19, 283.23 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25188/47780 [01:23<01:22, 274.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25072/47780 [01:23<01:19, 285.17 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24472/47780 [01:23<01:34, 247.40 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24904/47780 [01:23<01:12, 313.45 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24946/47780 [01:23<01:10, 322.93 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25441/47780 [01:23<01:23, 266.06 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11007/47780 [01:23<01:39, 369.82 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25259/47780 [01:23<01:17, 290.82 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25216/47780 [01:23<01:27, 256.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25101/47780 [01:23<01:21, 277.10 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24505/47780 [01:23<01:25, 271.22 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24936/47780 [01:23<01:13, 310.56 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24983/47780 [01:23<01:12, 314.19 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11045/47780 [01:23<01:41, 361.38 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25468/47780 [01:23<01:30, 246.70 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25289/47780 [01:23<01:21, 274.41 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25245/47780 [01:23<01:25, 264.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25129/47780 [01:23<01:22, 274.02 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24536/47780 [01:23<01:23, 279.31 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24968/47780 [01:23<01:15, 301.76 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25020/47780 [01:23<01:10, 325.03 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25275/47780 [01:23<01:22, 272.49 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25496/47780 [01:23<01:29, 250.30 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11082/47780 [01:23<01:46, 345.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25317/47780 [01:23<01:25, 261.25 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24569/47780 [01:23<01:19, 290.58 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25157/47780 [01:23<01:26, 261.63 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24999/47780 [01:23<01:17, 295.69 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25055/47780 [01:23<01:12, 314.67 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11122/47780 [01:23<01:42, 356.22 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25303/47780 [01:23<01:22, 270.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25522/47780 [01:23<01:32, 241.90 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25185/47780 [01:23<01:25, 263.81 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25356/47780 [01:23<01:18, 284.21 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24599/47780 [01:23<01:21, 283.07 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25030/47780 [01:23<01:21, 277.72 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11158/47780 [01:23<01:42, 355.85 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25088/47780 [01:23<01:17, 291.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25331/47780 [01:23<01:23, 267.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25547/47780 [01:23<01:33, 236.79 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24629/47780 [01:23<01:22, 282.02 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25387/47780 [01:23<01:19, 282.06 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25213/47780 [01:23<01:33, 241.12 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25060/47780 [01:23<01:21, 278.19 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25365/47780 [01:23<01:17, 288.30 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11194/47780 [01:23<01:44, 349.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25571/47780 [01:23<01:33, 237.63 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25119/47780 [01:23<01:21, 278.87 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25422/47780 [01:24<01:15, 295.80 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24659/47780 [01:23<01:25, 271.51 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25245/47780 [01:23<01:26, 260.69 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25093/47780 [01:23<01:19, 286.10 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25395/47780 [01:24<01:17, 288.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11231/47780 [01:24<01:44, 348.97 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25600/47780 [01:24<01:29, 246.83 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25149/47780 [01:24<01:22, 273.26 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25452/47780 [01:24<01:15, 295.34 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24688/47780 [01:24<01:27, 263.21 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25272/47780 [01:24<01:30, 248.21 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25122/47780 [01:24<01:22, 274.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25429/47780 [01:24<01:16, 293.19 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25625/47780 [01:24<01:30, 244.97 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25484/47780 [01:24<01:14, 298.98 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11266/47780 [01:24<01:55, 316.63 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25177/47780 [01:24<01:25, 263.86 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24721/47780 [01:24<01:24, 274.24 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25312/47780 [01:24<01:19, 283.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25151/47780 [01:24<01:21, 278.98 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25650/47780 [01:24<01:32, 238.06 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11309/47780 [01:24<01:46, 343.66 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25459/47780 [01:24<01:24, 264.96 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25212/47780 [01:24<01:19, 283.70 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25514/47780 [01:24<01:22, 271.28 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24749/47780 [01:24<01:24, 272.91 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25342/47780 [01:24<01:17, 287.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25185/47780 [01:24<01:17, 293.11 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25675/47780 [01:24<01:33, 236.25 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25241/47780 [01:24<01:20, 278.75 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11349/47780 [01:24<01:47, 340.38 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25554/47780 [01:24<01:13, 302.85 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25487/47780 [01:24<01:30, 247.64 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24777/47780 [01:24<01:25, 268.35 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25376/47780 [01:24<01:14, 299.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25215/47780 [01:24<01:23, 271.83 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25699/47780 [01:24<01:35, 231.89 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25288/47780 [01:24<01:08, 328.48 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11391/47780 [01:24<01:43, 350.31 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25586/47780 [01:24<01:13, 300.65 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25516/47780 [01:24<01:27, 253.39 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25407/47780 [01:24<01:16, 291.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24804/47780 [01:24<01:29, 257.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25244/47780 [01:24<01:23, 269.46 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25729/47780 [01:24<01:27, 251.03 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25326/47780 [01:24<01:05, 342.60 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11428/47780 [01:24<01:44, 348.33 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25542/47780 [01:24<01:28, 251.11 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25618/47780 [01:24<01:14, 296.38 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24833/47780 [01:24<01:26, 266.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25438/47780 [01:24<01:15, 294.10 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25272/47780 [01:24<01:26, 260.79 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25361/47780 [01:24<01:05, 340.68 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25756/47780 [01:24<01:29, 245.22 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25654/47780 [01:24<01:11, 310.59 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25568/47780 [01:24<01:29, 246.86 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11464/47780 [01:24<01:50, 329.68 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25470/47780 [01:24<01:14, 297.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24860/47780 [01:24<01:29, 255.67 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25304/47780 [01:24<01:21, 274.58 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25784/47780 [01:24<01:28, 249.66 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25396/47780 [01:24<01:08, 328.71 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25686/47780 [01:24<01:10, 312.10 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25593/47780 [01:24<01:29, 247.39 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11506/47780 [01:24<01:44, 348.31 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24886/47780 [01:24<01:31, 248.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25500/47780 [01:24<01:19, 280.91 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25341/47780 [01:24<01:15, 299.15 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25818/47780 [01:24<01:21, 269.12 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25430/47780 [01:24<01:12, 307.36 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25623/47780 [01:24<01:25, 258.26 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25719/47780 [01:25<01:12, 304.45 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24917/47780 [01:24<01:26, 262.98 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11543/47780 [01:24<01:48, 333.88 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25383/47780 [01:24<01:07, 331.44 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25531/47780 [01:25<01:25, 258.82 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25855/47780 [01:24<01:13, 297.61 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25463/47780 [01:25<01:11, 312.97 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25657/47780 [01:25<01:19, 279.86 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25750/47780 [01:25<01:12, 305.81 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24946/47780 [01:25<01:25, 267.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11577/47780 [01:25<01:49, 332.00 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25417/47780 [01:25<01:09, 322.75 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25558/47780 [01:25<01:25, 258.97 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25885/47780 [01:25<01:13, 298.15 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25495/47780 [01:25<01:11, 312.15 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25781/47780 [01:25<01:11, 306.10 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24975/47780 [01:25<01:23, 273.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11611/47780 [01:25<01:53, 319.86 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25686/47780 [01:25<01:32, 238.77 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25586/47780 [01:25<01:24, 261.78 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25450/47780 [01:25<01:14, 300.47 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25915/47780 [01:25<01:19, 273.53 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25527/47780 [01:25<01:12, 307.57 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25812/47780 [01:25<01:15, 291.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25011/47780 [01:25<01:18, 288.85 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11644/47780 [01:25<01:56, 309.07 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25712/47780 [01:25<01:32, 239.30 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25613/47780 [01:25<01:30, 244.88 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25946/47780 [01:25<01:16, 283.59 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25482/47780 [01:25<01:21, 273.13 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25558/47780 [01:25<01:16, 290.67 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25049/47780 [01:25<01:12, 314.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25842/47780 [01:25<01:17, 284.01 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25738/47780 [01:25<01:30, 242.31 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11676/47780 [01:25<02:06, 284.36 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25638/47780 [01:25<01:32, 240.60 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25975/47780 [01:25<01:21, 267.09 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25592/47780 [01:25<01:14, 298.70 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25872/47780 [01:25<01:16, 285.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25512/47780 [01:25<01:21, 271.85 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25082/47780 [01:25<01:17, 292.20 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25765/47780 [01:25<01:29, 247.13 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11706/47780 [01:25<02:05, 288.12 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25663/47780 [01:25<01:33, 236.23 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26005/47780 [01:25<01:19, 273.27 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25541/47780 [01:25<01:20, 276.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25901/47780 [01:25<01:18, 280.37 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25623/47780 [01:25<01:17, 285.96 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25117/47780 [01:25<01:15, 301.52 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25798/47780 [01:25<01:21, 269.94 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11736/47780 [01:25<02:07, 282.65 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25688/47780 [01:25<01:32, 239.89 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26045/47780 [01:25<01:10, 308.66 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25580/47780 [01:25<01:13, 301.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25933/47780 [01:25<01:15, 288.44 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25150/47780 [01:25<01:13, 309.38 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25653/47780 [01:25<01:21, 271.90 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25828/47780 [01:25<01:19, 275.53 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11769/47780 [01:25<02:03, 292.34 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25716/47780 [01:25<01:28, 248.45 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26087/47780 [01:25<01:05, 332.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25616/47780 [01:25<01:10, 313.90 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25962/47780 [01:25<01:17, 281.84 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25684/47780 [01:25<01:18, 282.00 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25182/47780 [01:25<01:14, 301.73 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25856/47780 [01:25<01:20, 270.69 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11799/47780 [01:25<02:03, 291.37 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25748/47780 [01:25<01:22, 265.80 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26133/47780 [01:25<00:58, 368.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25656/47780 [01:25<01:06, 334.41 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25991/47780 [01:25<01:18, 278.10 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25714/47780 [01:25<01:18, 280.92 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25213/47780 [01:25<01:17, 291.38 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25884/47780 [01:25<01:22, 266.93 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11829/47780 [01:25<02:06, 285.07 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25779/47780 [01:25<01:20, 272.15 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26175/47780 [01:25<00:56, 379.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25690/47780 [01:25<01:05, 335.94 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26019/47780 [01:26<01:18, 275.58 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25746/47780 [01:26<01:15, 291.79 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25917/47780 [01:26<01:17, 282.00 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25249/47780 [01:26<01:14, 303.68 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25812/47780 [01:26<01:16, 288.58 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11858/47780 [01:26<02:13, 269.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26224/47780 [01:26<00:53, 402.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25724/47780 [01:26<01:06, 332.91 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26048/47780 [01:26<01:18, 276.76 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25780/47780 [01:26<01:12, 302.23 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25947/47780 [01:26<01:16, 287.05 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25280/47780 [01:26<01:16, 295.28 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25847/47780 [01:26<01:12, 303.13 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11891/47780 [01:26<02:06, 283.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26271/47780 [01:26<00:51, 421.40 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25759/47780 [01:26<01:07, 326.95 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26087/47780 [01:26<01:12, 298.96 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25976/47780 [01:26<01:18, 278.27 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25310/47780 [01:26<01:18, 287.27 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25879/47780 [01:26<01:12, 304.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11920/47780 [01:26<02:07, 281.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26314/47780 [01:26<00:54, 396.16 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25792/47780 [01:26<01:10, 309.83 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26118/47780 [01:26<01:13, 295.08 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25811/47780 [01:26<01:34, 232.37 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25342/47780 [01:26<01:16, 293.14 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25915/47780 [01:26<01:08, 320.20 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26004/47780 [01:26<01:27, 247.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 11950/47780 [01:26<02:07, 281.17 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25827/47780 [01:26<01:08, 320.53 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26355/47780 [01:26<00:57, 375.54 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26148/47780 [01:26<01:15, 287.01 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26036/47780 [01:26<01:21, 266.84 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25372/47780 [01:26<01:22, 270.30 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25837/47780 [01:26<01:47, 203.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 11979/47780 [01:26<02:10, 274.22 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25948/47780 [01:26<01:16, 283.55 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26180/47780 [01:26<01:14, 289.57 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25860/47780 [01:26<01:16, 287.95 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26066/47780 [01:26<01:18, 275.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25400/47780 [01:26<01:24, 264.59 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12007/47780 [01:26<02:15, 264.05 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26393/47780 [01:26<01:12, 295.72 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25860/47780 [01:26<01:50, 198.48 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26209/47780 [01:26<01:16, 283.52 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25978/47780 [01:26<01:27, 250.06 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25890/47780 [01:26<01:18, 279.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26095/47780 [01:26<01:21, 264.78 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25427/47780 [01:26<01:25, 260.09 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12046/47780 [01:26<02:00, 295.61 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26431/47780 [01:26<01:07, 315.47 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25982/47780 [01:26<00:50, 430.11 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26239/47780 [01:26<01:16, 279.75 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25928/47780 [01:26<01:12, 302.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26012/47780 [01:26<01:22, 262.37 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26122/47780 [01:26<01:24, 257.55 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25458/47780 [01:26<01:23, 268.33 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12080/47780 [01:26<01:58, 301.42 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26466/47780 [01:26<01:11, 300.03 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26267/47780 [01:26<01:18, 275.28 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26041/47780 [01:26<01:21, 266.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25959/47780 [01:26<01:12, 301.46 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26032/47780 [01:26<00:59, 364.31 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25490/47780 [01:26<01:19, 282.06 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12111/47780 [01:26<02:00, 297.20 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26149/47780 [01:26<01:28, 245.16 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26498/47780 [01:26<01:12, 293.33 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26297/47780 [01:27<01:17, 277.65 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25990/47780 [01:26<01:12, 300.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26070/47780 [01:27<01:24, 256.28 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25523/47780 [01:27<01:16, 289.85 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12150/47780 [01:27<01:53, 312.82 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26174/47780 [01:27<01:29, 241.24 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26327/47780 [01:27<01:15, 282.84 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26529/47780 [01:27<01:14, 286.59 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26075/47780 [01:27<01:08, 316.79 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26097/47780 [01:27<01:25, 254.79 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25553/47780 [01:27<01:16, 292.31 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26199/47780 [01:27<01:28, 243.60 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12182/47780 [01:27<01:59, 298.14 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26358/47780 [01:27<01:13, 290.66 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26021/47780 [01:27<01:29, 242.91 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26559/47780 [01:27<01:13, 288.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26123/47780 [01:27<01:24, 255.90 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26112/47780 [01:27<01:08, 316.30 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26227/47780 [01:27<01:24, 253.61 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25583/47780 [01:27<01:21, 272.65 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26077/47780 [01:27<01:07, 320.35 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12218/47780 [01:27<01:57, 301.77 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26388/47780 [01:27<01:15, 283.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26589/47780 [01:27<01:18, 269.37 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26166/47780 [01:27<01:12, 297.96 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26158/47780 [01:27<01:02, 346.89 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26254/47780 [01:27<01:24, 255.63 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25619/47780 [01:27<01:15, 293.64 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12259/47780 [01:27<01:49, 324.32 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26422/47780 [01:27<01:12, 292.96 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26618/47780 [01:27<01:17, 271.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26113/47780 [01:27<01:13, 296.76 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26196/47780 [01:27<01:03, 338.46 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26280/47780 [01:27<01:24, 254.04 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26197/47780 [01:27<01:18, 273.81 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25656/47780 [01:27<01:10, 314.90 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12292/47780 [01:27<01:50, 322.45 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26460/47780 [01:27<01:07, 315.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26146/47780 [01:27<01:11, 304.70 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26646/47780 [01:27<01:21, 259.88 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26315/47780 [01:27<01:16, 281.82 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26233/47780 [01:27<01:04, 333.24 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26228/47780 [01:27<01:19, 271.85 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25688/47780 [01:27<01:14, 296.01 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12325/47780 [01:27<01:52, 313.97 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26492/47780 [01:27<01:10, 301.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26184/47780 [01:27<01:07, 321.58 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26675/47780 [01:27<01:19, 265.24 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26349/47780 [01:27<01:11, 298.83 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26259/47780 [01:27<01:16, 281.91 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26268/47780 [01:27<01:06, 323.74 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12360/47780 [01:27<01:51, 316.90 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26523/47780 [01:27<01:11, 296.90 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25719/47780 [01:27<01:21, 272.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26219/47780 [01:27<01:06, 325.70 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26715/47780 [01:27<01:10, 298.88 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26383/47780 [01:27<01:13, 290.39 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26288/47780 [01:27<01:19, 269.47 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26303/47780 [01:27<01:11, 300.01 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12393/47780 [01:27<01:54, 310.10 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25749/47780 [01:27<01:20, 274.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26255/47780 [01:27<01:04, 334.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26554/47780 [01:27<01:13, 288.09 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26747/47780 [01:27<01:11, 294.86 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26413/47780 [01:27<01:16, 280.34 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26316/47780 [01:27<01:19, 270.25 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26588/47780 [01:28<01:10, 299.21 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12425/47780 [01:27<01:58, 299.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25777/47780 [01:27<01:22, 267.10 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26290/47780 [01:27<01:09, 307.61 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26778/47780 [01:27<01:13, 286.08 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26347/47780 [01:28<01:16, 280.30 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26447/47780 [01:28<01:13, 290.77 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26334/47780 [01:28<01:26, 247.78 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26619/47780 [01:28<01:10, 302.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25808/47780 [01:28<01:19, 276.05 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12456/47780 [01:28<02:05, 280.50 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26322/47780 [01:28<01:10, 304.46 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26807/47780 [01:28<01:15, 277.82 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26477/47780 [01:28<01:14, 286.58 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26361/47780 [01:28<01:27, 245.41 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26377/47780 [01:28<01:21, 263.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26653/47780 [01:28<01:07, 312.25 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25842/47780 [01:28<01:15, 290.55 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12485/47780 [01:28<02:04, 282.94 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26354/47780 [01:28<01:09, 306.11 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26843/47780 [01:28<01:11, 293.31 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26439/47780 [01:28<00:57, 370.80 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26506/47780 [01:28<01:18, 272.40 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26408/47780 [01:28<01:17, 274.79 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26692/47780 [01:28<01:04, 324.50 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25872/47780 [01:28<01:17, 283.20 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12520/47780 [01:28<01:58, 298.57 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26386/47780 [01:28<01:09, 305.92 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26534/47780 [01:28<01:19, 265.65 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26873/47780 [01:28<01:20, 261.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26480/47780 [01:28<00:59, 355.60 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26727/47780 [01:28<01:04, 326.60 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25901/47780 [01:28<01:17, 282.27 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26436/47780 [01:28<01:25, 251.05 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26418/47780 [01:28<01:09, 306.66 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12552/47780 [01:28<02:04, 282.14 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26916/47780 [01:28<01:09, 302.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26563/47780 [01:28<01:18, 269.45 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26764/47780 [01:28<01:02, 336.74 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26519/47780 [01:28<01:01, 346.79 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26469/47780 [01:28<01:19, 269.14 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25930/47780 [01:28<01:20, 272.25 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26451/47780 [01:28<01:08, 309.89 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12581/47780 [01:28<02:09, 272.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26592/47780 [01:28<01:17, 274.18 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26948/47780 [01:28<01:10, 294.25 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26557/47780 [01:28<00:59, 355.28 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26508/47780 [01:28<01:11, 298.89 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26798/47780 [01:28<01:06, 315.74 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25958/47780 [01:28<01:21, 268.39 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26483/47780 [01:28<01:09, 305.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12609/47780 [01:28<02:10, 268.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26620/47780 [01:28<01:20, 264.42 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26539/47780 [01:28<01:10, 301.95 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26594/47780 [01:28<01:00, 351.45 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26979/47780 [01:28<01:15, 274.80 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26515/47780 [01:28<01:09, 306.38 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26830/47780 [01:28<01:09, 300.17 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25985/47780 [01:28<01:27, 249.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12637/47780 [01:28<02:18, 254.37 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26570/47780 [01:28<01:11, 297.59 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26647/47780 [01:28<01:26, 244.31 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27008/47780 [01:28<01:14, 278.63 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26866/47780 [01:28<01:06, 316.34 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26546/47780 [01:28<01:11, 296.99 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26631/47780 [01:28<01:05, 324.82 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26023/47780 [01:28<01:18, 278.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12665/47780 [01:28<02:15, 259.32 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26681/47780 [01:28<01:18, 269.94 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27038/47780 [01:28<01:14, 278.53 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26901/47780 [01:29<01:04, 325.67 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26601/47780 [01:28<01:15, 278.78 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26576/47780 [01:28<01:11, 297.19 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26053/47780 [01:28<01:20, 269.71 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26665/47780 [01:28<01:12, 292.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12692/47780 [01:28<02:19, 251.28 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27069/47780 [01:28<01:12, 284.07 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26630/47780 [01:29<01:15, 279.96 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26709/47780 [01:29<01:21, 258.59 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26939/47780 [01:29<01:03, 326.61 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26606/47780 [01:28<01:13, 288.89 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26091/47780 [01:29<01:13, 293.25 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12725/47780 [01:29<02:09, 269.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26696/47780 [01:29<01:13, 287.94 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26736/47780 [01:29<01:20, 261.39 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27098/47780 [01:29<01:14, 279.17 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26975/47780 [01:29<01:02, 334.52 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26641/47780 [01:29<01:09, 302.94 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26659/47780 [01:29<01:21, 260.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26121/47780 [01:29<01:14, 291.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12753/47780 [01:29<02:12, 264.85 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26727/47780 [01:29<01:13, 284.57 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27127/47780 [01:29<01:13, 279.39 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26768/47780 [01:29<01:17, 271.98 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26675/47780 [01:29<01:07, 313.55 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27009/47780 [01:29<01:06, 312.56 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26690/47780 [01:29<01:18, 267.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26151/47780 [01:29<01:17, 278.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12783/47780 [01:29<02:07, 273.56 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26756/47780 [01:29<01:14, 280.35 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27156/47780 [01:29<01:15, 272.87 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27041/47780 [01:29<01:05, 314.55 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26708/47780 [01:29<01:11, 294.42 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26724/47780 [01:29<01:13, 285.78 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26796/47780 [01:29<01:23, 251.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26183/47780 [01:29<01:16, 280.75 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12811/47780 [01:29<02:11, 266.36 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26785/47780 [01:29<01:16, 273.83 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27184/47780 [01:29<01:15, 271.97 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26827/47780 [01:29<01:18, 267.40 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26743/47780 [01:29<01:08, 306.36 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26754/47780 [01:29<01:13, 286.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27073/47780 [01:29<01:08, 302.35 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12841/47780 [01:29<02:08, 272.71 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26212/47780 [01:29<01:19, 269.63 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26813/47780 [01:29<01:19, 264.00 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27212/47780 [01:29<01:15, 271.20 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26860/47780 [01:29<01:15, 278.56 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26785/47780 [01:29<01:13, 286.72 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27109/47780 [01:29<01:05, 314.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26774/47780 [01:29<01:11, 293.77 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12870/47780 [01:29<02:07, 274.58 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27247/47780 [01:29<01:09, 293.50 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26240/47780 [01:29<01:29, 240.06 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26840/47780 [01:29<01:28, 235.49 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27141/47780 [01:29<01:06, 312.26 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26814/47780 [01:29<01:15, 278.17 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26807/47780 [01:29<01:10, 297.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26889/47780 [01:29<01:20, 258.65 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12905/47780 [01:29<02:01, 286.27 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27277/47780 [01:29<01:13, 279.16 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26265/47780 [01:29<01:30, 237.84 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26865/47780 [01:29<01:29, 234.06 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26842/47780 [01:29<01:15, 277.68 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26917/47780 [01:29<01:18, 264.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26837/47780 [01:29<01:12, 288.12 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27173/47780 [01:29<01:12, 282.84 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12935/47780 [01:29<02:03, 281.03 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26294/47780 [01:29<01:25, 251.56 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27306/47780 [01:29<01:16, 267.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26897/47780 [01:29<01:22, 254.38 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26866/47780 [01:29<01:13, 283.01 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26870/47780 [01:29<01:20, 258.58 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27202/47780 [01:30<01:12, 284.50 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26944/47780 [01:29<01:23, 249.31 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12964/47780 [01:29<02:05, 276.49 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27334/47780 [01:29<01:15, 270.68 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26925/47780 [01:29<01:20, 260.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26320/47780 [01:29<01:32, 233.19 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26900/47780 [01:30<01:17, 268.38 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26901/47780 [01:29<01:10, 295.03 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26974/47780 [01:30<01:19, 262.95 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12993/47780 [01:30<02:06, 274.47 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27231/47780 [01:30<01:24, 243.17 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27370/47780 [01:30<01:10, 289.62 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26952/47780 [01:30<01:22, 252.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26344/47780 [01:30<01:32, 232.78 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26929/47780 [01:30<01:16, 273.17 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26939/47780 [01:30<01:06, 315.34 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27001/47780 [01:30<01:21, 253.59 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13024/47780 [01:30<02:03, 281.35 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27265/47780 [01:30<01:16, 267.22 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27400/47780 [01:30<01:11, 285.83 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26986/47780 [01:30<01:15, 276.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26374/47780 [01:30<01:26, 248.40 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26957/47780 [01:30<01:19, 262.92 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26971/47780 [01:30<01:08, 304.45 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27031/47780 [01:30<01:18, 263.50 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13057/47780 [01:30<01:57, 295.22 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27023/47780 [01:30<01:08, 302.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27294/47780 [01:30<01:22, 249.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27429/47780 [01:30<01:14, 271.87 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26400/47780 [01:30<01:30, 235.88 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26984/47780 [01:30<01:19, 262.19 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27006/47780 [01:30<01:06, 311.99 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27058/47780 [01:30<01:18, 265.08 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13087/47780 [01:30<02:01, 286.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27327/47780 [01:30<01:16, 267.83 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27457/47780 [01:30<01:14, 271.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27054/47780 [01:30<01:12, 286.22 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26431/47780 [01:30<01:24, 253.25 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27011/47780 [01:30<01:19, 261.09 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13119/47780 [01:30<01:57, 295.99 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27085/47780 [01:30<01:23, 249.23 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27038/47780 [01:30<01:12, 287.98 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27357/47780 [01:30<01:13, 276.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27493/47780 [01:30<01:09, 292.92 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26457/47780 [01:30<01:26, 246.89 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27038/47780 [01:30<01:21, 255.25 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27085/47780 [01:30<01:15, 273.68 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13149/47780 [01:30<01:59, 290.72 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27070/47780 [01:30<01:10, 293.86 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27111/47780 [01:30<01:26, 239.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27524/47780 [01:30<01:08, 297.54 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27387/47780 [01:30<01:17, 262.33 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27113/47780 [01:30<01:16, 269.74 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26482/47780 [01:30<01:29, 237.16 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13179/47780 [01:30<01:59, 289.55 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27100/47780 [01:30<01:10, 291.68 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27136/47780 [01:30<01:34, 218.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27555/47780 [01:30<01:07, 297.94 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27064/47780 [01:30<01:39, 207.26 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27141/47780 [01:30<01:15, 272.33 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27414/47780 [01:30<01:20, 253.88 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26510/47780 [01:30<01:28, 241.13 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27130/47780 [01:30<01:11, 287.74 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13209/47780 [01:30<02:08, 268.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27594/47780 [01:30<01:02, 324.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27162/47780 [01:30<01:31, 224.80 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27169/47780 [01:30<01:16, 268.87 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26535/47780 [01:30<01:29, 238.27 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27440/47780 [01:30<01:26, 235.31 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27171/47780 [01:30<01:05, 315.56 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27087/47780 [01:30<01:53, 182.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13239/47780 [01:30<02:06, 273.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27189/47780 [01:30<01:28, 232.97 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27203/47780 [01:30<01:11, 288.79 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27627/47780 [01:30<01:09, 291.62 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26564/47780 [01:30<01:24, 249.90 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27472/47780 [01:31<01:19, 254.72 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27149/47780 [01:31<01:12, 283.59 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27203/47780 [01:30<01:09, 296.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13267/47780 [01:31<02:10, 263.93 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27213/47780 [01:31<01:34, 217.15 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27234/47780 [01:31<01:12, 285.23 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27657/47780 [01:31<01:09, 287.54 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27506/47780 [01:31<01:13, 276.55 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26590/47780 [01:31<01:28, 239.32 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13298/47780 [01:31<02:06, 273.56 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27240/47780 [01:31<01:06, 306.74 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27250/47780 [01:31<01:21, 252.29 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27182/47780 [01:31<01:24, 244.20 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27687/47780 [01:31<01:10, 285.19 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27264/47780 [01:31<01:14, 276.74 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26622/47780 [01:31<01:20, 261.39 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27537/47780 [01:31<01:12, 277.79 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13333/47780 [01:31<01:56, 294.79 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27271/47780 [01:31<01:11, 288.41 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27279/47780 [01:31<01:21, 251.75 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27292/47780 [01:31<01:14, 274.70 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27716/47780 [01:31<01:13, 271.30 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26662/47780 [01:31<01:10, 300.46 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27566/47780 [01:31<01:12, 277.86 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27210/47780 [01:31<01:29, 231.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13363/47780 [01:31<01:57, 293.23 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27301/47780 [01:31<01:11, 285.44 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27307/47780 [01:31<01:18, 259.26 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27320/47780 [01:31<01:15, 269.99 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27595/47780 [01:31<01:13, 275.23 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26693/47780 [01:31<01:15, 278.17 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13393/47780 [01:31<02:01, 282.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27236/47780 [01:31<01:31, 223.56 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27744/47780 [01:31<01:25, 235.10 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27330/47780 [01:31<01:13, 277.68 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27334/47780 [01:31<01:20, 253.75 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27348/47780 [01:31<01:16, 266.83 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27623/47780 [01:31<01:13, 273.63 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26723/47780 [01:31<01:15, 280.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27263/47780 [01:31<01:28, 232.34 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27770/47780 [01:31<01:23, 239.07 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27358/47780 [01:31<01:15, 269.54 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13422/47780 [01:31<02:17, 250.51 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27384/47780 [01:31<01:09, 293.26 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27360/47780 [01:31<01:23, 244.35 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27655/47780 [01:31<01:10, 283.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26753/47780 [01:31<01:15, 279.94 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27799/47780 [01:31<01:19, 252.30 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27394/47780 [01:31<01:10, 291.17 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27288/47780 [01:31<01:34, 217.19 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13475/47780 [01:31<01:45, 323.70 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27392/47780 [01:31<01:17, 262.59 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27684/47780 [01:31<01:11, 281.98 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27414/47780 [01:31<01:14, 273.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26782/47780 [01:31<01:15, 277.51 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27425/47780 [01:31<01:09, 293.12 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27322/47780 [01:31<01:22, 247.47 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13509/47780 [01:31<01:52, 304.73 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27720/47780 [01:31<01:05, 304.38 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27419/47780 [01:31<01:20, 253.17 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27442/47780 [01:31<01:14, 274.51 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27825/47780 [01:31<01:36, 207.10 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26810/47780 [01:31<01:16, 274.06 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27457/47780 [01:31<01:09, 294.04 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27349/47780 [01:31<01:25, 238.10 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13541/47780 [01:31<01:53, 302.16 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27472/47780 [01:31<01:12, 279.04 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27752/47780 [01:32<01:07, 298.69 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27445/47780 [01:31<01:24, 239.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26844/47780 [01:31<01:12, 289.47 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27848/47780 [01:31<01:40, 199.20 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27493/47780 [01:31<01:04, 312.52 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27377/47780 [01:32<01:22, 246.87 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13573/47780 [01:32<01:54, 297.68 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27501/47780 [01:32<01:12, 279.04 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27782/47780 [01:32<01:07, 295.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27473/47780 [01:32<01:21, 250.24 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27906/47780 [01:32<01:08, 291.06 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26874/47780 [01:32<01:17, 270.63 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27527/47780 [01:32<01:03, 317.06 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27405/47780 [01:32<01:20, 252.91 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27538/47780 [01:32<01:06, 305.10 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13608/47780 [01:32<01:51, 305.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27818/47780 [01:32<01:04, 307.17 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27500/47780 [01:32<01:22, 244.70 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27940/47780 [01:32<01:05, 301.35 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26902/47780 [01:32<01:22, 253.56 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27559/47780 [01:32<01:08, 296.49 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27431/47780 [01:32<01:25, 239.00 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27573/47780 [01:32<01:05, 310.87 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27858/47780 [01:32<00:59, 332.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13639/47780 [01:32<01:54, 299.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27525/47780 [01:32<01:22, 245.48 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27974/47780 [01:32<01:04, 305.23 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26928/47780 [01:32<01:27, 237.63 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27459/47780 [01:32<01:22, 247.55 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27589/47780 [01:32<01:13, 276.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27892/47780 [01:32<01:03, 314.21 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27605/47780 [01:32<01:10, 285.09 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13670/47780 [01:32<02:02, 278.18 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27550/47780 [01:32<01:27, 231.97 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28007/47780 [01:32<01:08, 289.51 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26955/47780 [01:32<01:25, 243.73 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27485/47780 [01:32<01:25, 237.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27618/47780 [01:32<01:15, 267.81 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13700/47780 [01:32<01:59, 284.00 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27924/47780 [01:32<01:05, 305.45 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27634/47780 [01:32<01:15, 267.69 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27580/47780 [01:32<01:23, 242.50 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28038/47780 [01:32<01:11, 277.70 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26980/47780 [01:32<01:26, 240.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27511/47780 [01:32<01:24, 238.62 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27955/47780 [01:32<01:05, 302.02 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13736/47780 [01:32<01:55, 295.24 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27662/47780 [01:32<01:16, 262.22 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27606/47780 [01:32<01:25, 236.68 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27646/47780 [01:32<01:27, 229.93 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28067/47780 [01:32<01:13, 266.70 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27536/47780 [01:32<01:24, 239.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27005/47780 [01:32<01:31, 227.93 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13773/47780 [01:32<01:47, 315.72 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27987/47780 [01:32<01:07, 291.82 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27631/47780 [01:32<01:24, 239.06 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27689/47780 [01:32<01:18, 256.60 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27680/47780 [01:32<01:19, 251.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28100/47780 [01:32<01:11, 276.11 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27029/47780 [01:32<01:33, 221.70 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27562/47780 [01:32<01:28, 229.53 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28020/47780 [01:32<01:06, 299.07 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13806/47780 [01:32<01:51, 304.90 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27656/47780 [01:32<01:26, 232.59 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27716/47780 [01:32<01:12, 276.79 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27716/47780 [01:32<01:21, 247.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28129/47780 [01:32<01:12, 269.58 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27060/47780 [01:32<01:27, 237.52 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27586/47780 [01:32<01:28, 227.29 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28056/47780 [01:33<01:03, 312.36 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13837/47780 [01:32<01:54, 297.63 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27753/47780 [01:32<01:06, 301.26 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27685/47780 [01:32<01:23, 241.21 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27746/47780 [01:32<01:17, 258.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28161/47780 [01:32<01:09, 280.40 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27615/47780 [01:33<01:22, 244.51 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28099/47780 [01:33<00:57, 342.57 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13867/47780 [01:33<01:56, 291.50 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27084/47780 [01:33<01:32, 223.59 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27788/47780 [01:33<01:04, 308.17 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27711/47780 [01:33<01:22, 243.79 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27774/47780 [01:33<01:18, 255.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28191/47780 [01:33<01:09, 282.72 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27640/47780 [01:33<01:22, 243.45 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27107/47780 [01:33<01:33, 222.13 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13901/47780 [01:33<01:52, 301.80 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28134/47780 [01:33<01:03, 309.22 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27839/47780 [01:33<00:55, 356.29 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27737/47780 [01:33<01:21, 245.25 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27803/47780 [01:33<01:17, 256.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28223/47780 [01:33<01:08, 286.79 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27671/47780 [01:33<01:17, 259.64 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13933/47780 [01:33<01:52, 300.28 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27130/47780 [01:33<01:35, 215.55 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27876/47780 [01:33<00:55, 359.70 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27762/47780 [01:33<01:23, 238.69 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28166/47780 [01:33<01:07, 290.05 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27830/47780 [01:33<01:19, 249.39 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28252/47780 [01:33<01:12, 268.59 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27698/47780 [01:33<01:20, 248.44 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13971/47780 [01:33<01:44, 322.63 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27163/47780 [01:33<01:25, 241.86 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27788/47780 [01:33<01:22, 242.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27913/47780 [01:33<01:00, 329.42 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27856/47780 [01:33<01:22, 241.46 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28197/47780 [01:33<01:13, 267.45 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27731/47780 [01:33<01:14, 268.07 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28280/47780 [01:33<01:17, 253.20 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27198/47780 [01:33<01:16, 269.14 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14005/47780 [01:33<01:49, 309.58 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27821/47780 [01:33<01:14, 267.06 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27947/47780 [01:33<01:00, 328.61 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27883/47780 [01:33<01:19, 249.10 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28228/47780 [01:33<01:11, 275.27 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27760/47780 [01:33<01:14, 267.65 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28306/47780 [01:33<01:19, 244.37 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27227/47780 [01:33<01:18, 262.65 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27853/47780 [01:33<01:12, 276.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14037/47780 [01:33<01:56, 289.91 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27915/47780 [01:33<01:16, 260.60 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27981/47780 [01:33<01:03, 310.71 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28259/47780 [01:33<01:10, 278.67 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28331/47780 [01:33<01:22, 235.93 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27883/47780 [01:33<01:11, 279.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27787/47780 [01:33<01:22, 241.32 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27254/47780 [01:33<01:26, 238.33 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14067/47780 [01:33<02:03, 272.12 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27948/47780 [01:33<01:11, 276.69 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28293/47780 [01:33<01:06, 292.05 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28014/47780 [01:33<01:08, 288.43 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28356/47780 [01:33<01:21, 239.67 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27915/47780 [01:33<01:09, 284.77 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27812/47780 [01:33<01:23, 238.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27281/47780 [01:33<01:23, 246.54 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14095/47780 [01:33<02:05, 268.33 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27979/47780 [01:33<01:09, 283.10 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28336/47780 [01:33<01:00, 322.92 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28382/47780 [01:33<01:20, 242.41 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28044/47780 [01:33<01:14, 263.93 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27944/47780 [01:33<01:11, 276.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27837/47780 [01:33<01:26, 229.36 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14130/47780 [01:33<01:58, 284.77 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28011/47780 [01:33<01:08, 290.22 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27307/47780 [01:33<01:27, 234.98 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28370/47780 [01:34<01:04, 302.01 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28407/47780 [01:33<01:23, 231.85 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28072/47780 [01:33<01:17, 255.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27972/47780 [01:34<01:13, 268.61 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27861/47780 [01:34<01:29, 222.66 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14169/47780 [01:34<01:47, 313.54 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28044/47780 [01:34<01:06, 298.39 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27331/47780 [01:34<01:32, 220.50 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28437/47780 [01:34<01:18, 246.45 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28401/47780 [01:34<01:08, 281.39 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28098/47780 [01:34<01:20, 245.91 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27884/47780 [01:34<01:30, 219.92 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28074/47780 [01:34<01:05, 298.68 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14204/47780 [01:34<01:46, 316.59 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28000/47780 [01:34<01:17, 254.55 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27356/47780 [01:34<01:30, 225.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28462/47780 [01:34<01:21, 237.22 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27908/47780 [01:34<01:29, 222.98 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28104/47780 [01:34<01:06, 295.65 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14252/47780 [01:34<01:32, 362.46 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28026/47780 [01:34<01:17, 253.32 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28430/47780 [01:34<01:14, 259.43 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28124/47780 [01:34<01:26, 228.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27379/47780 [01:34<01:30, 224.24 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27933/47780 [01:34<01:26, 230.32 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28134/47780 [01:34<01:07, 293.11 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28457/47780 [01:34<01:14, 259.78 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28486/47780 [01:34<01:28, 219.08 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28052/47780 [01:34<01:22, 239.09 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14289/47780 [01:34<01:40, 333.43 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28148/47780 [01:34<01:27, 224.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27404/47780 [01:34<01:33, 219.05 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28484/47780 [01:34<01:15, 256.46 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27958/47780 [01:34<01:31, 216.38 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28077/47780 [01:34<01:24, 234.20 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28509/47780 [01:34<01:34, 204.99 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28164/47780 [01:34<01:14, 264.41 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27434/47780 [01:34<01:24, 240.96 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28171/47780 [01:34<01:32, 210.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14326/47780 [01:34<01:50, 301.52 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28510/47780 [01:34<01:17, 247.33 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27984/47780 [01:34<01:26, 228.23 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28101/47780 [01:34<01:23, 235.44 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27460/47780 [01:34<01:23, 242.08 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28195/47780 [01:34<01:13, 265.53 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28198/47780 [01:34<01:28, 221.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28530/47780 [01:34<01:44, 183.94 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14358/47780 [01:34<01:54, 291.00 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28010/47780 [01:34<01:23, 237.01 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28543/47780 [01:34<01:13, 261.20 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28128/47780 [01:34<01:22, 238.29 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28222/47780 [01:34<01:14, 261.13 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27493/47780 [01:34<01:18, 259.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28228/47780 [01:34<01:21, 238.81 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14388/47780 [01:34<01:58, 281.55 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28549/47780 [01:34<01:52, 171.68 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28037/47780 [01:34<01:21, 243.63 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28573/47780 [01:34<01:11, 268.83 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28153/47780 [01:34<01:21, 241.05 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27528/47780 [01:34<01:13, 275.98 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28256/47780 [01:34<01:18, 248.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28249/47780 [01:34<01:19, 247.21 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28602/47780 [01:34<01:13, 259.57 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14418/47780 [01:34<01:58, 280.96 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28064/47780 [01:34<01:20, 245.64 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28605/47780 [01:34<01:07, 282.82 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28178/47780 [01:34<01:24, 232.89 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27559/47780 [01:34<01:11, 282.41 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28282/47780 [01:34<01:18, 248.24 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28279/47780 [01:34<01:15, 258.57 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14449/47780 [01:34<01:55, 288.54 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28630/47780 [01:34<01:15, 254.18 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28102/47780 [01:35<01:10, 277.83 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28634/47780 [01:35<01:08, 281.45 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28209/47780 [01:35<01:18, 249.91 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28309/47780 [01:35<01:12, 267.20 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28317/47780 [01:35<01:12, 268.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27589/47780 [01:35<01:14, 269.38 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14486/47780 [01:35<01:48, 307.87 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28657/47780 [01:35<01:16, 250.64 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28663/47780 [01:35<01:09, 274.93 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28241/47780 [01:35<01:12, 268.69 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28132/47780 [01:35<01:13, 265.92 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28338/47780 [01:35<01:11, 273.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28349/47780 [01:35<01:10, 275.39 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14522/47780 [01:35<01:45, 315.40 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27617/47780 [01:35<01:20, 249.52 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28686/47780 [01:35<01:14, 255.66 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28691/47780 [01:35<01:10, 269.97 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28269/47780 [01:35<01:12, 268.91 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28164/47780 [01:35<01:09, 280.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28369/47780 [01:35<01:08, 283.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28380/47780 [01:35<01:09, 279.90 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27654/47780 [01:35<01:12, 277.73 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14554/47780 [01:35<01:49, 303.15 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28195/47780 [01:35<01:07, 288.92 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28302/47780 [01:35<01:07, 286.46 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28719/47780 [01:35<01:13, 258.42 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28713/47780 [01:35<01:19, 238.46 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28398/47780 [01:35<01:08, 282.56 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28411/47780 [01:35<01:07, 286.97 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14585/47780 [01:35<01:54, 288.99 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28225/47780 [01:35<01:08, 285.67 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27684/47780 [01:35<01:18, 256.38 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28751/47780 [01:35<01:10, 270.39 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28331/47780 [01:35<01:11, 271.59 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28427/47780 [01:35<01:08, 283.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28746/47780 [01:35<01:17, 246.26 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28440/47780 [01:35<01:11, 270.30 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27715/47780 [01:35<01:16, 263.77 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28254/47780 [01:35<01:10, 278.24 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14616/47780 [01:35<02:01, 273.68 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28782/47780 [01:35<01:09, 274.87 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28461/47780 [01:35<01:06, 290.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28774/47780 [01:35<01:14, 254.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28359/47780 [01:35<01:16, 253.95 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28468/47780 [01:35<01:17, 248.66 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28282/47780 [01:35<01:11, 274.53 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27742/47780 [01:35<01:19, 253.33 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28820/47780 [01:35<01:03, 300.63 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28492/47780 [01:35<01:05, 293.01 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14644/47780 [01:35<02:05, 263.04 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28800/47780 [01:35<01:15, 249.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28392/47780 [01:35<01:10, 274.56 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28495/47780 [01:35<01:21, 236.65 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28851/47780 [01:35<01:03, 299.93 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28310/47780 [01:35<01:14, 260.94 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14671/47780 [01:35<02:07, 260.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28826/47780 [01:35<01:15, 250.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28522/47780 [01:35<01:07, 285.09 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28420/47780 [01:35<01:11, 269.97 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27768/47780 [01:35<01:25, 235.33 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28529/47780 [01:35<01:13, 263.48 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28556/47780 [01:35<01:03, 300.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14700/47780 [01:35<02:04, 265.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28340/47780 [01:35<01:14, 260.64 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28852/47780 [01:36<01:19, 237.35 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28882/47780 [01:35<01:08, 274.80 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28448/47780 [01:35<01:15, 255.35 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27792/47780 [01:35<01:31, 218.04 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28368/47780 [01:36<01:13, 263.02 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28556/47780 [01:35<01:20, 238.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14727/47780 [01:35<02:07, 259.29 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28587/47780 [01:36<01:06, 290.22 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28876/47780 [01:36<01:20, 235.24 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28913/47780 [01:35<01:07, 278.27 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28475/47780 [01:36<01:15, 257.00 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27822/47780 [01:36<01:24, 237.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28395/47780 [01:36<01:14, 259.03 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28586/47780 [01:36<01:17, 247.65 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28900/47780 [01:36<01:20, 233.94 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14756/47780 [01:36<02:09, 255.38 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28942/47780 [01:36<01:07, 278.49 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28506/47780 [01:36<01:11, 267.93 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27847/47780 [01:36<01:25, 232.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28617/47780 [01:36<01:17, 248.16 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28613/47780 [01:36<01:15, 253.32 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14788/47780 [01:36<02:02, 270.15 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28926/47780 [01:36<01:20, 233.34 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28421/47780 [01:36<01:19, 243.16 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28534/47780 [01:36<01:15, 254.89 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27871/47780 [01:36<01:24, 234.80 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28971/47780 [01:36<01:13, 255.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28678/47780 [01:36<00:56, 340.19 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14817/47780 [01:36<01:59, 275.63 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28639/47780 [01:36<01:18, 244.74 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28447/47780 [01:36<01:19, 242.46 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28950/47780 [01:36<01:23, 225.11 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27895/47780 [01:36<01:26, 231.03 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29002/47780 [01:36<01:12, 259.41 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28560/47780 [01:36<01:20, 237.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28717/47780 [01:36<00:59, 322.29 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14852/47780 [01:36<01:50, 296.76 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28666/47780 [01:36<01:16, 248.94 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28476/47780 [01:36<01:15, 255.58 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28980/47780 [01:36<01:16, 245.91 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27920/47780 [01:36<01:24, 234.36 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29032/47780 [01:36<01:10, 264.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28585/47780 [01:36<01:22, 232.25 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14885/47780 [01:36<01:47, 306.21 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28692/47780 [01:36<01:16, 249.84 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28502/47780 [01:36<01:15, 254.00 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28752/47780 [01:36<01:03, 301.36 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27952/47780 [01:36<01:16, 257.99 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29005/47780 [01:36<01:19, 236.23 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29067/47780 [01:36<01:05, 284.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28609/47780 [01:36<01:22, 232.59 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14917/47780 [01:36<01:50, 296.76 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28721/47780 [01:36<01:14, 257.49 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28529/47780 [01:36<01:15, 255.60 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29033/47780 [01:36<01:16, 245.80 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28785/47780 [01:36<01:07, 283.18 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27979/47780 [01:36<01:20, 247.24 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29097/47780 [01:36<01:06, 282.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28633/47780 [01:36<01:24, 227.86 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14950/47780 [01:36<01:48, 302.65 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28747/47780 [01:36<01:13, 258.10 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28561/47780 [01:36<01:10, 271.08 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29068/47780 [01:36<01:11, 263.40 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28005/47780 [01:36<01:19, 248.93 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29126/47780 [01:36<01:06, 281.64 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28816/47780 [01:36<01:09, 270.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28656/47780 [01:36<01:28, 216.40 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14985/47780 [01:36<01:44, 312.88 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28774/47780 [01:36<01:15, 253.06 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29100/47780 [01:36<01:07, 276.12 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28591/47780 [01:36<01:15, 252.90 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28033/47780 [01:36<01:18, 251.99 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29165/47780 [01:36<01:00, 309.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28844/47780 [01:36<01:11, 265.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28688/47780 [01:36<01:18, 241.95 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15017/47780 [01:36<01:45, 310.95 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28800/47780 [01:36<01:18, 240.98 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29134/47780 [01:37<01:04, 290.91 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28064/47780 [01:36<01:13, 268.26 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28617/47780 [01:37<01:16, 249.59 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29202/47780 [01:36<00:58, 314.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28714/47780 [01:37<01:17, 246.88 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28872/47780 [01:37<01:14, 253.06 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15049/47780 [01:37<01:51, 293.39 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28829/47780 [01:37<01:15, 252.11 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28095/47780 [01:37<01:11, 276.22 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29164/47780 [01:37<01:07, 277.23 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28643/47780 [01:37<01:20, 239.08 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29235/47780 [01:37<01:00, 308.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28745/47780 [01:37<01:12, 262.04 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28900/47780 [01:37<01:16, 247.60 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28857/47780 [01:37<01:12, 259.89 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15079/47780 [01:37<01:59, 273.99 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28129/47780 [01:37<01:08, 288.10 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28668/47780 [01:37<01:19, 239.66 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29192/47780 [01:37<01:08, 272.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29267/47780 [01:37<01:01, 301.85 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28778/47780 [01:37<01:08, 276.17 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28926/47780 [01:37<01:16, 246.72 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28887/47780 [01:37<01:09, 270.26 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28165/47780 [01:37<01:03, 308.54 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29222/47780 [01:37<01:07, 275.38 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28695/47780 [01:37<01:18, 242.68 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29299/47780 [01:37<01:00, 306.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15107/47780 [01:37<02:11, 249.00 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28806/47780 [01:37<01:09, 272.24 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28916/47780 [01:37<01:08, 274.03 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28958/47780 [01:37<01:13, 254.36 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28196/47780 [01:37<01:04, 301.44 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28725/47780 [01:37<01:13, 258.53 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29254/47780 [01:37<01:05, 283.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15155/47780 [01:37<01:45, 308.35 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28834/47780 [01:37<01:16, 249.08 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29330/47780 [01:37<01:08, 270.77 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28986/47780 [01:37<01:14, 253.07 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28944/47780 [01:37<01:12, 260.63 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28230/47780 [01:37<01:03, 306.28 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28752/47780 [01:37<01:14, 256.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15188/47780 [01:37<01:43, 313.92 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29283/47780 [01:37<01:09, 267.05 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28860/47780 [01:37<01:15, 249.86 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29361/47780 [01:37<01:06, 275.28 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28979/47780 [01:37<01:05, 285.62 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29012/47780 [01:37<01:15, 249.29 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28261/47780 [01:37<01:03, 307.19 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28780/47780 [01:37<01:13, 259.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15229/47780 [01:37<01:37, 334.19 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29312/47780 [01:37<01:08, 271.53 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28886/47780 [01:37<01:18, 241.94 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29009/47780 [01:37<01:06, 283.18 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28299/47780 [01:37<00:59, 328.36 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29390/47780 [01:37<01:10, 259.71 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29037/47780 [01:37<01:19, 234.38 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28807/47780 [01:37<01:12, 262.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15265/47780 [01:37<01:36, 336.81 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29343/47780 [01:37<01:06, 275.68 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28915/47780 [01:37<01:14, 252.41 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28332/47780 [01:37<01:00, 321.52 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29061/47780 [01:37<01:21, 230.87 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29038/47780 [01:37<01:11, 261.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29417/47780 [01:37<01:16, 239.64 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15305/47780 [01:37<01:33, 346.94 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29371/47780 [01:37<01:08, 270.10 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28834/47780 [01:37<01:22, 230.26 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28943/47780 [01:37<01:12, 260.10 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28366/47780 [01:37<01:00, 318.91 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29070/47780 [01:37<01:07, 277.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29085/47780 [01:37<01:21, 228.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29454/47780 [01:37<01:07, 270.45 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29399/47780 [01:38<01:08, 269.68 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15341/47780 [01:37<01:37, 332.83 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28861/47780 [01:38<01:20, 235.69 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28976/47780 [01:38<01:07, 276.84 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29099/47780 [01:37<01:06, 280.66 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29111/47780 [01:38<01:19, 234.57 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28399/47780 [01:38<01:04, 301.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29483/47780 [01:38<01:06, 275.50 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15377/47780 [01:38<01:36, 335.74 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29431/47780 [01:38<01:07, 271.67 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28886/47780 [01:38<01:20, 234.26 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29005/47780 [01:38<01:13, 254.36 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29129/47780 [01:38<01:05, 283.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29136/47780 [01:38<01:18, 236.11 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29512/47780 [01:38<01:09, 262.05 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15411/47780 [01:38<01:38, 329.44 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28430/47780 [01:38<01:09, 279.00 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28910/47780 [01:38<01:25, 220.99 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29459/47780 [01:38<01:14, 246.52 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29160/47780 [01:38<01:19, 234.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29031/47780 [01:38<01:18, 239.73 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29158/47780 [01:38<01:11, 261.22 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28465/47780 [01:38<01:04, 297.99 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15446/47780 [01:38<01:39, 323.78 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29541/47780 [01:38<01:11, 253.38 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28935/47780 [01:38<01:23, 226.61 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29191/47780 [01:38<01:13, 253.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29485/47780 [01:38<01:19, 230.65 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29056/47780 [01:38<01:21, 228.37 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29185/47780 [01:38<01:13, 252.90 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28496/47780 [01:38<01:05, 295.07 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29571/47780 [01:38<01:09, 260.19 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15479/47780 [01:38<01:43, 310.79 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28958/47780 [01:38<01:25, 219.85 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29222/47780 [01:38<01:08, 269.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29526/47780 [01:38<01:06, 274.55 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29211/47780 [01:38<01:15, 246.44 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29087/47780 [01:38<01:17, 242.16 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28528/47780 [01:38<01:05, 292.20 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29601/47780 [01:38<01:07, 270.93 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15512/47780 [01:38<01:46, 303.06 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28982/47780 [01:38<01:28, 212.11 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29250/47780 [01:38<01:10, 261.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29557/47780 [01:38<01:06, 274.71 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29236/47780 [01:38<01:15, 244.85 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29112/47780 [01:38<01:18, 236.75 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29642/47780 [01:38<00:59, 307.05 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28559/47780 [01:38<01:06, 290.68 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15543/47780 [01:38<01:46, 302.49 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29279/47780 [01:38<01:08, 268.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29009/47780 [01:38<01:25, 220.53 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29261/47780 [01:38<01:16, 243.14 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29675/47780 [01:38<00:57, 312.79 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29136/47780 [01:38<01:19, 234.76 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28597/47780 [01:38<01:01, 312.22 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15581/47780 [01:38<01:39, 324.01 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29588/47780 [01:38<01:15, 242.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29041/47780 [01:38<01:15, 247.47 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29311/47780 [01:38<01:08, 267.85 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29297/47780 [01:38<01:07, 273.43 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29707/47780 [01:38<00:58, 310.69 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29160/47780 [01:38<01:22, 226.10 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28629/47780 [01:38<01:04, 297.12 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15615/47780 [01:38<01:39, 324.12 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29616/47780 [01:38<01:12, 249.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29068/47780 [01:38<01:13, 253.59 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29340/47780 [01:38<01:09, 265.27 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29333/47780 [01:38<01:02, 294.76 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29183/47780 [01:38<01:24, 220.43 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29739/47780 [01:38<01:01, 293.73 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15648/47780 [01:38<01:39, 323.02 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28668/47780 [01:38<00:59, 319.78 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29642/47780 [01:39<01:14, 244.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29096/47780 [01:39<01:11, 259.68 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29371/47780 [01:38<00:58, 315.56 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29367/47780 [01:39<01:14, 247.27 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29209/47780 [01:39<01:20, 231.15 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15687/47780 [01:39<01:34, 338.32 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29671/47780 [01:39<01:12, 251.04 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29770/47780 [01:39<01:04, 279.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28701/47780 [01:39<01:07, 284.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29124/47780 [01:39<01:13, 255.30 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29413/47780 [01:39<00:54, 337.98 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29392/47780 [01:39<01:16, 240.20 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29241/47780 [01:39<01:13, 252.62 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15724/47780 [01:39<01:33, 343.70 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29703/47780 [01:39<01:07, 269.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29799/47780 [01:39<01:08, 262.11 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29150/47780 [01:39<01:19, 235.07 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29419/47780 [01:39<01:14, 246.12 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29447/47780 [01:39<00:57, 319.84 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28731/47780 [01:39<01:17, 247.10 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15768/47780 [01:39<01:27, 367.16 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29267/47780 [01:39<01:15, 244.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29731/47780 [01:39<01:09, 258.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29827/47780 [01:39<01:08, 261.64 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29184/47780 [01:39<01:11, 258.42 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29447/47780 [01:39<01:12, 252.23 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29480/47780 [01:39<00:57, 318.75 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15812/47780 [01:39<01:23, 384.16 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29293/47780 [01:39<01:15, 243.29 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29859/47780 [01:39<01:04, 277.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29758/47780 [01:39<01:13, 245.86 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28757/47780 [01:39<01:29, 213.03 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29212/47780 [01:39<01:13, 254.28 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29513/47780 [01:39<00:58, 312.97 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29484/47780 [01:39<01:06, 276.00 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15851/47780 [01:39<01:24, 377.05 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29319/47780 [01:39<01:15, 245.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29889/47780 [01:39<01:03, 282.92 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29783/47780 [01:39<01:14, 241.03 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29239/47780 [01:39<01:12, 257.12 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29514/47780 [01:39<01:04, 282.66 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15897/47780 [01:39<01:20, 396.75 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28780/47780 [01:39<01:37, 195.52 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29346/47780 [01:39<01:13, 252.05 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29545/47780 [01:39<01:02, 293.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29923/47780 [01:39<00:59, 297.81 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29808/47780 [01:39<01:17, 233.04 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29270/47780 [01:39<01:08, 269.31 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28876/47780 [01:39<00:51, 368.14 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29373/47780 [01:39<01:12, 254.64 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29544/47780 [01:39<01:07, 269.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15937/47780 [01:39<01:24, 375.45 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29575/47780 [01:39<01:07, 269.28 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29955/47780 [01:39<01:03, 280.53 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29841/47780 [01:39<01:11, 251.69 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29298/47780 [01:39<01:12, 254.21 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29578/47780 [01:39<01:03, 287.38 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15976/47780 [01:39<01:24, 375.51 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29399/47780 [01:39<01:15, 244.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28919/47780 [01:39<00:53, 352.62 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29984/47780 [01:39<01:03, 281.42 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29870/47780 [01:39<01:08, 261.98 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29603/47780 [01:39<01:11, 253.47 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29324/47780 [01:39<01:12, 252.83 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29612/47780 [01:39<01:00, 300.38 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29424/47780 [01:39<01:15, 241.98 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16015/47780 [01:39<01:25, 370.90 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28960/47780 [01:39<00:53, 349.78 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30013/47780 [01:39<01:03, 279.28 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29901/47780 [01:40<01:06, 269.52 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29636/47780 [01:39<01:06, 273.01 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29644/47780 [01:39<01:00, 301.81 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29350/47780 [01:40<01:17, 237.21 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29449/47780 [01:40<01:17, 237.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16053/47780 [01:40<01:30, 350.94 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28998/47780 [01:40<00:54, 341.92 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30042/47780 [01:40<01:04, 275.97 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29666/47780 [01:40<01:05, 275.99 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29929/47780 [01:40<01:14, 239.99 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29477/47780 [01:40<01:14, 244.22 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29675/47780 [01:40<01:03, 284.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29375/47780 [01:40<01:19, 230.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16089/47780 [01:40<01:32, 344.38 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29035/47780 [01:40<00:55, 340.09 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30072/47780 [01:40<01:04, 273.45 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29696/47780 [01:40<01:07, 269.37 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29959/47780 [01:40<01:10, 253.85 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29712/47780 [01:40<00:58, 308.41 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29408/47780 [01:40<01:11, 256.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29504/47780 [01:40<01:14, 245.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16125/47780 [01:40<01:31, 344.99 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30105/47780 [01:40<01:01, 287.25 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29724/47780 [01:40<01:10, 257.27 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29071/47780 [01:40<01:03, 296.18 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29748/47780 [01:40<00:56, 316.41 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29435/47780 [01:40<01:11, 255.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29533/47780 [01:40<01:12, 252.60 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16162/47780 [01:40<01:30, 349.10 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29986/47780 [01:40<01:17, 230.00 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30134/47780 [01:40<01:01, 287.14 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29750/47780 [01:40<01:12, 248.36 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29103/47780 [01:40<01:03, 296.20 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29466/47780 [01:40<01:07, 270.53 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29780/47780 [01:40<00:58, 307.03 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29559/47780 [01:40<01:12, 251.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16198/47780 [01:40<01:30, 350.00 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30019/47780 [01:40<01:10, 250.42 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30170/47780 [01:40<00:57, 308.05 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29776/47780 [01:40<01:15, 238.33 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29820/47780 [01:40<00:53, 333.25 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29585/47780 [01:40<01:12, 252.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29494/47780 [01:40<01:08, 267.33 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16234/47780 [01:40<01:34, 334.95 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29134/47780 [01:40<01:07, 274.82 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30045/47780 [01:40<01:13, 242.84 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30201/47780 [01:40<01:01, 285.14 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29805/47780 [01:40<01:12, 247.17 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29857/47780 [01:40<00:52, 339.76 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29521/47780 [01:40<01:09, 263.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29611/47780 [01:40<01:12, 251.40 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29163/47780 [01:40<01:07, 277.85 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16275/47780 [01:40<01:30, 348.40 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30071/47780 [01:40<01:12, 244.56 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30231/47780 [01:40<01:02, 280.11 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29836/47780 [01:40<01:09, 258.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29903/47780 [01:40<00:48, 366.06 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29637/47780 [01:40<01:13, 245.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29562/47780 [01:40<01:01, 294.07 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16318/47780 [01:40<01:25, 367.15 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30099/47780 [01:40<01:10, 251.80 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29192/47780 [01:40<01:11, 260.77 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30260/47780 [01:40<01:04, 270.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29863/47780 [01:40<01:10, 255.80 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29594/47780 [01:40<01:01, 298.11 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29662/47780 [01:40<01:16, 237.76 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29940/47780 [01:40<00:51, 343.24 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16363/47780 [01:40<01:20, 387.87 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30129/47780 [01:40<01:07, 262.63 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29219/47780 [01:40<01:12, 256.87 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30288/47780 [01:40<01:08, 253.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29890/47780 [01:40<01:09, 257.16 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29625/47780 [01:40<01:00, 299.83 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29687/47780 [01:40<01:15, 238.56 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29975/47780 [01:40<00:53, 330.67 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16402/47780 [01:40<01:24, 370.04 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30156/47780 [01:41<01:09, 252.91 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29246/47780 [01:41<01:15, 244.49 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30327/47780 [01:41<01:01, 284.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29918/47780 [01:41<01:08, 260.80 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29658/47780 [01:41<00:59, 303.31 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16441/47780 [01:41<01:23, 375.65 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30009/47780 [01:41<00:53, 329.60 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29711/47780 [01:41<01:19, 226.09 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30194/47780 [01:41<01:02, 282.05 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29281/47780 [01:41<01:08, 269.58 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30357/47780 [01:41<01:00, 288.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29946/47780 [01:41<01:06, 266.24 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29689/47780 [01:41<01:00, 298.44 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30054/47780 [01:41<00:49, 359.42 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16479/47780 [01:41<01:28, 352.64 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30230/47780 [01:41<00:59, 293.98 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29735/47780 [01:41<01:23, 215.48 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29314/47780 [01:41<01:04, 285.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30387/47780 [01:41<00:59, 290.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29979/47780 [01:41<01:03, 278.18 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30091/47780 [01:41<00:49, 358.30 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29719/47780 [01:41<01:05, 275.98 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29762/47780 [01:41<01:18, 229.58 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30265/47780 [01:41<00:58, 299.57 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30421/47780 [01:41<00:57, 302.57 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29344/47780 [01:41<01:10, 263.06 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30009/47780 [01:41<01:02, 282.75 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16515/47780 [01:41<01:46, 292.82 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29750/47780 [01:41<01:04, 279.84 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30128/47780 [01:41<00:51, 345.37 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29788/47780 [01:41<01:16, 236.16 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30301/47780 [01:41<00:55, 315.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30453/47780 [01:41<00:56, 307.55 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29377/47780 [01:41<01:06, 275.39 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30038/47780 [01:41<01:04, 273.62 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16565/47780 [01:41<01:31, 340.59 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29783/47780 [01:41<01:01, 290.35 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29816/47780 [01:41<01:13, 245.81 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30177/47780 [01:41<00:46, 377.89 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30486/47780 [01:41<00:55, 314.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30333/47780 [01:41<00:59, 291.06 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30066/47780 [01:41<01:08, 258.05 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16602/47780 [01:41<01:35, 327.93 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29406/47780 [01:41<01:13, 249.42 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29813/47780 [01:41<01:04, 280.18 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29846/47780 [01:41<01:10, 253.33 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30217/47780 [01:41<00:47, 369.37 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30518/47780 [01:41<00:55, 308.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30363/47780 [01:41<01:00, 285.58 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30094/47780 [01:41<01:07, 263.87 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29432/47780 [01:41<01:14, 246.82 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29844/47780 [01:41<01:02, 285.47 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29885/47780 [01:41<01:02, 288.03 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16637/47780 [01:41<01:38, 316.89 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30257/47780 [01:41<00:47, 371.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30549/47780 [01:41<00:57, 302.09 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30392/47780 [01:41<01:04, 269.33 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30121/47780 [01:41<01:09, 254.10 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29881/47780 [01:41<00:58, 306.98 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16677/47780 [01:41<01:32, 335.38 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30300/47780 [01:41<00:45, 384.02 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29924/47780 [01:41<00:58, 306.66 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29458/47780 [01:41<01:20, 228.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30580/47780 [01:41<00:56, 304.02 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30148/47780 [01:41<01:08, 258.38 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30420/47780 [01:42<01:09, 249.31 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29912/47780 [01:41<00:58, 306.46 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29962/47780 [01:41<00:54, 325.81 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16712/47780 [01:41<01:34, 328.23 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29486/47780 [01:41<01:15, 241.85 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30339/47780 [01:41<00:48, 360.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30615/47780 [01:41<00:54, 314.13 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30454/47780 [01:42<01:04, 270.16 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30180/47780 [01:41<01:05, 270.17 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29943/47780 [01:42<01:00, 293.88 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16749/47780 [01:42<01:32, 336.40 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29517/47780 [01:42<01:12, 252.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30376/47780 [01:42<00:49, 348.30 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30647/47780 [01:42<00:56, 301.48 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29995/47780 [01:42<01:01, 288.68 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30482/47780 [01:42<01:05, 264.12 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29973/47780 [01:42<01:02, 286.18 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30208/47780 [01:42<01:11, 245.11 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16786/47780 [01:42<01:32, 334.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29549/47780 [01:42<01:07, 268.87 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30678/47780 [01:42<00:59, 287.74 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30025/47780 [01:42<01:04, 274.25 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30412/47780 [01:42<00:54, 319.73 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30509/47780 [01:42<01:07, 254.66 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30002/47780 [01:42<01:02, 284.17 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16821/47780 [01:42<01:31, 338.54 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29581/47780 [01:42<01:04, 281.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30237/47780 [01:42<01:11, 244.67 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30720/47780 [01:42<00:52, 324.50 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30058/47780 [01:42<01:02, 285.56 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30448/47780 [01:42<00:53, 323.83 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30536/47780 [01:42<01:08, 250.51 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16856/47780 [01:42<01:31, 339.13 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30032/47780 [01:42<01:02, 285.48 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30262/47780 [01:42<01:11, 245.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29611/47780 [01:42<01:05, 277.53 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30088/47780 [01:42<01:02, 283.68 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30753/47780 [01:42<00:55, 308.26 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30481/47780 [01:42<00:54, 314.97 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30566/47780 [01:42<01:05, 263.36 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16891/47780 [01:42<01:30, 341.37 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30065/47780 [01:42<00:59, 298.16 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29640/47780 [01:42<01:05, 277.79 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30296/47780 [01:42<01:05, 265.56 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30789/47780 [01:42<00:53, 319.43 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30513/47780 [01:42<00:54, 316.04 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30117/47780 [01:42<01:04, 273.24 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16926/47780 [01:42<01:30, 341.61 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30596/47780 [01:42<01:03, 269.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30095/47780 [01:42<00:59, 295.89 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29668/47780 [01:42<01:11, 252.72 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30822/47780 [01:42<00:53, 318.78 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30323/47780 [01:42<01:14, 233.14 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30146/47780 [01:42<01:04, 275.02 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30545/47780 [01:42<00:57, 298.71 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16965/47780 [01:42<01:27, 352.56 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30128/47780 [01:42<00:58, 301.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30628/47780 [01:42<01:02, 272.74 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30860/47780 [01:42<00:50, 336.17 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29694/47780 [01:42<01:15, 238.88 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30175/47780 [01:42<01:04, 273.06 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30576/47780 [01:42<00:58, 294.31 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30348/47780 [01:42<01:21, 215.18 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30159/47780 [01:42<01:00, 290.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30656/47780 [01:42<01:04, 266.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17001/47780 [01:42<01:35, 322.81 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30894/47780 [01:42<00:51, 326.05 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30213/47780 [01:42<00:58, 299.58 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29722/47780 [01:42<01:16, 237.51 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30606/47780 [01:42<00:59, 286.29 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30195/47780 [01:42<00:57, 306.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30685/47780 [01:43<01:03, 270.38 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30371/47780 [01:42<01:25, 202.67 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17034/47780 [01:42<01:40, 307.33 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30927/47780 [01:42<00:53, 316.30 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30247/47780 [01:42<00:56, 310.87 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29750/47780 [01:42<01:13, 246.10 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30642/47780 [01:42<00:56, 301.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30714/47780 [01:43<01:02, 272.74 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30396/47780 [01:42<01:21, 212.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30226/47780 [01:43<01:01, 287.60 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17068/47780 [01:43<01:39, 309.30 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30959/47780 [01:43<00:53, 313.79 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30279/47780 [01:43<00:57, 306.18 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29779/47780 [01:43<01:12, 249.94 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30674/47780 [01:43<00:56, 302.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30742/47780 [01:43<01:03, 268.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30418/47780 [01:43<01:22, 209.33 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17108/47780 [01:43<01:31, 333.98 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30257/47780 [01:43<01:02, 278.67 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30992/47780 [01:43<00:52, 318.30 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30310/47780 [01:43<00:58, 300.91 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30706/47780 [01:43<00:57, 296.68 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29806/47780 [01:43<01:17, 232.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30769/47780 [01:43<01:04, 263.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30442/47780 [01:43<01:20, 215.86 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17145/47780 [01:43<01:29, 343.08 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30290/47780 [01:43<01:02, 279.48 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31024/47780 [01:43<00:54, 308.20 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30346/47780 [01:43<00:55, 314.24 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30741/47780 [01:43<00:54, 310.82 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30797/47780 [01:43<01:04, 264.62 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29832/47780 [01:43<01:17, 232.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30469/47780 [01:43<01:15, 228.25 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17181/47780 [01:43<01:29, 341.50 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30323/47780 [01:43<01:00, 286.77 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30379/47780 [01:43<00:54, 318.41 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31055/47780 [01:43<00:56, 295.23 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30773/47780 [01:43<00:55, 307.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30825/47780 [01:43<01:03, 268.90 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30493/47780 [01:43<01:16, 226.42 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29857/47780 [01:43<01:18, 229.43 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17216/47780 [01:43<01:31, 332.30 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30352/47780 [01:43<01:02, 279.18 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30414/47780 [01:43<00:54, 320.47 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31086/47780 [01:43<00:57, 289.58 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30811/47780 [01:43<00:52, 321.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30855/47780 [01:43<01:01, 275.12 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30521/47780 [01:43<01:12, 238.80 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29886/47780 [01:43<01:15, 238.36 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30387/47780 [01:43<00:58, 296.02 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17250/47780 [01:43<01:37, 313.29 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30447/47780 [01:43<00:54, 315.71 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31116/47780 [01:43<00:58, 284.62 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30847/47780 [01:43<00:51, 328.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30885/47780 [01:43<00:59, 282.30 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30549/47780 [01:43<01:09, 247.61 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29910/47780 [01:43<01:20, 221.94 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30420/47780 [01:43<00:57, 302.11 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17282/47780 [01:43<01:39, 305.17 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30479/47780 [01:43<00:56, 306.59 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30915/47780 [01:43<00:58, 287.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30880/47780 [01:43<00:52, 320.96 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31145/47780 [01:43<01:04, 258.31 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30581/47780 [01:43<01:04, 265.51 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17318/47780 [01:43<01:35, 318.10 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30452/47780 [01:43<00:58, 296.58 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29933/47780 [01:43<01:25, 208.69 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30510/47780 [01:43<00:57, 300.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30923/47780 [01:43<00:48, 348.84 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30610/47780 [01:43<01:03, 272.53 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30944/47780 [01:43<01:04, 262.14 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31172/47780 [01:43<01:06, 250.82 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30494/47780 [01:43<00:53, 321.05 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17351/47780 [01:43<01:40, 303.14 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29960/47780 [01:43<01:20, 222.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30544/47780 [01:43<00:55, 308.17 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30974/47780 [01:44<01:01, 272.57 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30958/47780 [01:43<00:53, 317.06 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31198/47780 [01:43<01:07, 245.64 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30638/47780 [01:43<01:11, 240.72 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29984/47780 [01:44<01:18, 226.85 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30577/47780 [01:44<00:55, 311.04 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17382/47780 [01:44<01:41, 298.05 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30528/47780 [01:44<00:55, 309.14 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31002/47780 [01:44<01:02, 267.06 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30991/47780 [01:44<00:52, 319.35 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31228/47780 [01:44<01:06, 249.56 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30663/47780 [01:44<01:11, 240.62 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17418/47780 [01:44<01:36, 315.07 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30612/47780 [01:44<00:53, 320.92 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30017/47780 [01:44<01:11, 248.79 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30560/47780 [01:44<00:55, 308.12 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31024/47780 [01:44<00:54, 308.99 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31256/47780 [01:44<01:05, 252.27 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31029/47780 [01:44<01:11, 235.93 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30690/47780 [01:44<01:10, 241.04 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17450/47780 [01:44<01:37, 312.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30645/47780 [01:44<00:56, 303.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30043/47780 [01:44<01:17, 230.14 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30591/47780 [01:44<01:03, 272.56 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31293/47780 [01:44<00:58, 281.42 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31056/47780 [01:44<01:09, 242.19 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31056/47780 [01:44<00:58, 283.54 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30720/47780 [01:44<01:07, 254.18 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17489/47780 [01:44<01:31, 331.87 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30676/47780 [01:44<00:57, 295.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30073/47780 [01:44<01:11, 248.75 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30619/47780 [01:44<01:05, 260.92 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31324/47780 [01:44<00:57, 286.22 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31092/47780 [01:44<01:00, 274.00 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31091/47780 [01:44<00:56, 295.13 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17524/47780 [01:44<01:30, 334.97 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30754/47780 [01:44<01:03, 269.48 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30707/47780 [01:44<00:56, 299.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30105/47780 [01:44<01:06, 265.51 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30646/47780 [01:44<01:08, 250.10 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31121/47780 [01:44<00:56, 296.07 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30782/47780 [01:44<01:03, 269.43 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31121/47780 [01:44<01:02, 266.70 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31353/47780 [01:44<01:01, 266.15 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17559/47780 [01:44<01:33, 322.66 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30137/47780 [01:44<01:03, 277.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30739/47780 [01:44<00:57, 298.67 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17596/47780 [01:44<01:30, 332.31 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31380/47780 [01:44<01:05, 250.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31151/47780 [01:44<01:01, 270.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30810/47780 [01:44<01:07, 249.57 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30166/47780 [01:44<01:04, 272.79 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31149/47780 [01:44<01:09, 238.95 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30769/47780 [01:44<01:01, 276.94 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30672/47780 [01:44<01:21, 210.89 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17634/47780 [01:44<01:28, 341.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31406/47780 [01:44<01:05, 250.67 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30842/47780 [01:44<01:04, 263.19 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31190/47780 [01:44<00:56, 292.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30197/47780 [01:44<01:02, 279.23 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31181/47780 [01:44<01:03, 259.75 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30713/47780 [01:44<01:06, 257.60 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30800/47780 [01:44<01:00, 279.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17669/47780 [01:44<01:27, 344.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31433/47780 [01:44<01:06, 247.39 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30873/47780 [01:44<01:02, 269.85 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31220/47780 [01:44<00:58, 282.41 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30829/47780 [01:44<01:01, 276.55 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30226/47780 [01:44<01:07, 258.79 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30741/47780 [01:44<01:07, 251.15 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17708/47780 [01:44<01:24, 354.74 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31208/47780 [01:45<01:17, 214.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31468/47780 [01:44<01:00, 270.06 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30901/47780 [01:44<01:03, 263.84 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31250/47780 [01:45<00:59, 278.42 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30858/47780 [01:45<01:01, 277.22 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30253/47780 [01:45<01:10, 248.10 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30768/47780 [01:45<01:11, 238.58 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17758/47780 [01:45<01:15, 395.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31269/47780 [01:45<00:54, 305.57 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31496/47780 [01:45<01:01, 266.95 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30931/47780 [01:45<01:02, 268.16 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31279/47780 [01:45<01:01, 267.10 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30888/47780 [01:45<01:02, 268.41 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30280/47780 [01:45<01:11, 245.98 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30794/47780 [01:45<01:10, 240.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17798/47780 [01:45<01:21, 366.62 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31523/47780 [01:45<01:02, 261.44 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30966/47780 [01:45<00:57, 290.72 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31303/47780 [01:45<00:57, 285.41 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31307/47780 [01:45<01:00, 270.52 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30915/47780 [01:45<01:04, 262.95 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30309/47780 [01:45<01:08, 254.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30819/47780 [01:45<01:10, 239.43 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17837/47780 [01:45<01:24, 353.65 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31334/47780 [01:45<00:56, 291.28 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31550/47780 [01:45<01:04, 249.96 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30996/47780 [01:45<01:00, 277.66 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31339/47780 [01:45<00:58, 281.11 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30943/47780 [01:45<01:04, 261.99 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30844/47780 [01:45<01:11, 237.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30336/47780 [01:45<01:09, 251.26 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17873/47780 [01:45<01:24, 353.37 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31025/47780 [01:45<01:00, 276.29 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31576/47780 [01:45<01:06, 245.11 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31369/47780 [01:45<00:58, 280.09 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31365/47780 [01:45<00:59, 276.03 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30869/47780 [01:45<01:12, 232.29 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30362/47780 [01:45<01:12, 240.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30970/47780 [01:45<01:09, 241.21 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17909/47780 [01:45<01:26, 345.11 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31602/47780 [01:45<01:05, 247.66 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31400/47780 [01:45<00:56, 288.49 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31053/47780 [01:45<01:05, 257.19 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31394/47780 [01:45<01:01, 266.22 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30389/47780 [01:45<01:09, 248.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30903/47780 [01:45<01:07, 248.94 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30995/47780 [01:45<01:14, 225.49 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17944/47780 [01:45<01:28, 335.62 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31627/47780 [01:45<01:09, 233.83 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31422/47780 [01:45<01:01, 264.31 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31429/47780 [01:45<01:01, 264.59 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31080/47780 [01:45<01:08, 245.15 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30415/47780 [01:45<01:09, 248.98 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30945/47780 [01:45<00:57, 292.18 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31020/47780 [01:45<01:13, 229.43 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17983/47780 [01:45<01:25, 347.06 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31653/47780 [01:45<01:08, 236.67 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31460/47780 [01:45<00:58, 276.91 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31450/47780 [01:45<01:02, 260.63 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31105/47780 [01:45<01:07, 245.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30441/47780 [01:45<01:13, 237.12 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31053/47780 [01:45<01:06, 251.20 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30976/47780 [01:45<01:01, 272.84 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18018/47780 [01:45<01:27, 338.84 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31678/47780 [01:45<01:07, 239.50 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31489/47780 [01:45<01:02, 260.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31477/47780 [01:46<01:06, 246.73 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30465/47780 [01:45<01:13, 234.11 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31130/47780 [01:45<01:12, 228.34 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31079/47780 [01:45<01:07, 248.16 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31009/47780 [01:45<00:58, 285.10 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18052/47780 [01:45<01:33, 318.59 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31704/47780 [01:45<01:06, 242.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31505/47780 [01:46<01:03, 255.47 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30489/47780 [01:46<01:14, 230.70 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31155/47780 [01:45<01:12, 229.42 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31516/47780 [01:46<01:07, 241.96 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31107/47780 [01:46<01:04, 256.86 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31043/47780 [01:46<00:56, 294.40 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18086/47780 [01:46<01:31, 324.33 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31737/47780 [01:46<01:02, 258.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31532/47780 [01:46<01:03, 253.96 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31183/47780 [01:46<01:08, 240.58 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31543/47780 [01:46<01:05, 249.09 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30515/47780 [01:46<01:14, 232.80 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31133/47780 [01:46<01:04, 256.56 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31074/47780 [01:46<00:56, 295.83 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18126/47780 [01:46<01:26, 342.24 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31767/47780 [01:46<00:59, 267.89 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31558/47780 [01:46<01:05, 247.12 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31208/47780 [01:46<01:08, 240.28 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31575/47780 [01:46<01:00, 265.68 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30539/47780 [01:46<01:14, 230.52 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31164/47780 [01:46<01:02, 267.18 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31104/47780 [01:46<00:58, 283.22 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31798/47780 [01:46<00:57, 279.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18167/47780 [01:46<01:25, 345.80 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31604/47780 [01:46<00:59, 272.40 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31238/47780 [01:46<01:06, 248.98 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31583/47780 [01:46<01:11, 227.96 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30563/47780 [01:46<01:18, 218.17 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31191/47780 [01:46<01:08, 242.77 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31831/47780 [01:46<00:54, 294.01 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18219/47780 [01:46<01:15, 390.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31133/47780 [01:46<01:04, 259.21 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31632/47780 [01:46<01:00, 268.37 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31268/47780 [01:46<01:04, 257.47 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30592/47780 [01:46<01:13, 232.88 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31618/47780 [01:46<01:04, 250.41 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31216/47780 [01:46<01:08, 242.19 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31160/47780 [01:46<01:06, 250.77 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18259/47780 [01:46<01:20, 367.45 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31861/47780 [01:46<00:58, 269.92 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31660/47780 [01:46<01:01, 263.01 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31296/47780 [01:46<01:03, 260.89 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31648/47780 [01:46<01:01, 260.36 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30616/47780 [01:46<01:15, 225.92 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31242/47780 [01:46<01:09, 236.72 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31895/47780 [01:46<00:55, 286.81 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18297/47780 [01:46<01:21, 363.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31186/47780 [01:46<01:07, 245.77 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31692/47780 [01:46<00:58, 275.82 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31325/47780 [01:46<01:02, 264.27 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30639/47780 [01:46<01:15, 225.76 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31676/47780 [01:46<01:02, 258.92 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31266/47780 [01:46<01:11, 229.84 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31939/47780 [01:46<00:48, 326.06 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31221/47780 [01:46<01:01, 271.06 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18334/47780 [01:46<01:22, 357.10 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31720/47780 [01:46<00:59, 270.44 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31352/47780 [01:46<01:04, 255.91 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30664/47780 [01:46<01:14, 230.25 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31710/47780 [01:46<01:01, 262.17 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31291/47780 [01:46<01:13, 225.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18372/47780 [01:46<01:21, 362.70 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31974/47780 [01:46<00:50, 313.03 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31249/47780 [01:46<01:03, 259.46 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31748/47780 [01:46<00:59, 270.29 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31380/47780 [01:46<01:03, 259.98 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31743/47780 [01:47<00:57, 280.27 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30688/47780 [01:46<01:17, 220.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31314/47780 [01:46<01:12, 226.54 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31279/47780 [01:46<01:01, 267.51 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32006/47780 [01:46<00:51, 306.57 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18409/47780 [01:46<01:28, 331.08 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31779/47780 [01:46<00:58, 275.72 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31414/47780 [01:46<00:59, 277.29 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30715/47780 [01:47<01:14, 229.16 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31772/47780 [01:47<00:57, 277.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31340/47780 [01:47<01:10, 233.65 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31307/47780 [01:47<01:01, 268.06 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32038/47780 [01:47<00:51, 303.79 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18451/47780 [01:47<01:26, 341.00 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31442/47780 [01:47<00:58, 277.08 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31807/47780 [01:47<01:01, 258.86 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31802/47780 [01:47<00:56, 283.37 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30739/47780 [01:47<01:14, 229.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31366/47780 [01:47<01:08, 238.34 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31340/47780 [01:47<00:58, 282.12 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32069/47780 [01:47<00:52, 301.99 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18486/47780 [01:47<01:27, 336.27 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31470/47780 [01:47<01:00, 269.06 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31834/47780 [01:47<01:01, 259.87 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31831/47780 [01:47<00:56, 283.11 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30771/47780 [01:47<01:07, 252.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31394/47780 [01:47<01:06, 247.48 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31369/47780 [01:47<00:59, 275.06 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18520/47780 [01:47<01:27, 333.32 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32100/47780 [01:47<00:55, 281.87 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31861/47780 [01:47<01:02, 253.61 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30799/47780 [01:47<01:05, 260.09 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31497/47780 [01:47<01:07, 241.64 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31860/47780 [01:47<00:58, 272.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31420/47780 [01:47<01:05, 248.16 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31400/47780 [01:47<00:57, 284.73 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32129/47780 [01:47<00:55, 280.94 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18554/47780 [01:47<01:30, 324.37 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31893/47780 [01:47<00:59, 266.22 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31522/47780 [01:47<01:08, 238.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31450/47780 [01:47<01:02, 260.01 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31888/47780 [01:47<01:00, 264.79 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30826/47780 [01:47<01:09, 243.44 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31436/47780 [01:47<00:53, 306.34 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32158/47780 [01:47<00:56, 276.73 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18592/47780 [01:47<01:26, 336.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31920/47780 [01:47<01:00, 264.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31915/47780 [01:47<01:00, 263.29 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30857/47780 [01:47<01:06, 255.79 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31547/47780 [01:47<01:14, 218.03 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31478/47780 [01:47<01:11, 226.61 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32192/47780 [01:47<00:53, 292.10 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18633/47780 [01:47<01:22, 353.15 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31467/47780 [01:47<01:00, 269.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31947/47780 [01:47<01:04, 246.24 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31947/47780 [01:47<00:58, 271.94 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30884/47780 [01:47<01:06, 254.45 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31571/47780 [01:47<01:12, 223.60 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31510/47780 [01:47<01:06, 243.34 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32223/47780 [01:47<00:54, 287.31 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18678/47780 [01:47<01:18, 372.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31495/47780 [01:47<01:04, 251.11 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31978/47780 [01:47<01:02, 253.96 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31976/47780 [01:47<00:58, 272.11 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30920/47780 [01:47<01:00, 277.86 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31596/47780 [01:47<01:10, 230.51 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18720/47780 [01:47<01:15, 385.72 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32256/47780 [01:47<00:52, 297.95 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31536/47780 [01:47<01:08, 237.56 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31522/47780 [01:47<01:03, 255.88 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32009/47780 [01:47<00:58, 267.88 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30957/47780 [01:47<00:55, 303.68 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32004/47780 [01:47<00:59, 265.39 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31628/47780 [01:47<01:04, 249.99 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31561/47780 [01:47<01:08, 235.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18759/47780 [01:47<01:20, 361.72 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32286/47780 [01:47<00:59, 261.12 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31549/47780 [01:48<01:06, 244.07 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32040/47780 [01:47<00:57, 273.61 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32031/47780 [01:48<01:00, 260.78 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30988/47780 [01:47<00:58, 288.80 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31658/47780 [01:47<01:02, 258.38 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31586/47780 [01:48<01:08, 237.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18798/47780 [01:48<01:19, 365.81 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32323/47780 [01:48<00:53, 289.50 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32068/47780 [01:48<00:57, 275.38 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31580/47780 [01:48<01:02, 258.90 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31693/47780 [01:48<00:56, 282.45 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32058/47780 [01:48<01:01, 254.20 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31019/47780 [01:48<00:58, 285.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31614/47780 [01:48<01:06, 242.69 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18835/47780 [01:48<01:25, 340.12 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31611/47780 [01:48<00:59, 269.95 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32353/47780 [01:48<00:55, 276.76 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32096/47780 [01:48<01:00, 258.87 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32090/47780 [01:48<00:58, 270.02 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31725/47780 [01:48<00:56, 285.07 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31048/47780 [01:48<01:02, 265.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31644/47780 [01:48<01:03, 253.39 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18875/47780 [01:48<01:21, 352.72 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32384/47780 [01:48<00:54, 282.88 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32127/47780 [01:48<00:57, 270.11 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31639/47780 [01:48<01:03, 252.67 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32118/47780 [01:48<00:58, 266.78 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31754/47780 [01:48<00:58, 274.25 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31080/47780 [01:48<01:00, 277.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31681/47780 [01:48<00:58, 277.44 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18911/47780 [01:48<01:22, 349.66 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32155/47780 [01:48<00:57, 269.83 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31666/47780 [01:48<01:03, 254.89 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32413/47780 [01:48<00:56, 272.99 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32146/47780 [01:48<00:59, 261.76 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31788/47780 [01:48<00:56, 283.14 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31109/47780 [01:48<01:01, 269.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31709/47780 [01:48<00:59, 269.25 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18948/47780 [01:48<01:21, 352.43 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32183/47780 [01:48<00:57, 272.19 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32441/47780 [01:48<00:57, 266.25 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32176/47780 [01:48<00:57, 269.54 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31700/47780 [01:48<01:00, 266.96 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31137/47780 [01:48<01:01, 272.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31817/47780 [01:48<01:00, 264.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31737/47780 [01:48<01:00, 266.22 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18985/47780 [01:48<01:21, 354.56 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32211/47780 [01:48<00:57, 271.62 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32473/47780 [01:48<00:54, 279.55 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31733/47780 [01:48<00:57, 280.82 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32204/47780 [01:48<00:59, 263.64 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31170/47780 [01:48<00:58, 282.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31846/47780 [01:48<01:00, 265.45 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19021/47780 [01:48<01:21, 354.93 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31773/47780 [01:48<00:56, 285.58 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32253/47780 [01:48<00:49, 311.35 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32231/47780 [01:48<00:58, 265.02 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32503/47780 [01:48<00:56, 271.57 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31762/47780 [01:48<01:00, 262.91 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31204/47780 [01:48<00:56, 295.24 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31877/47780 [01:48<00:58, 271.44 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19057/47780 [01:48<01:22, 348.19 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31803/47780 [01:48<00:56, 284.94 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32258/47780 [01:48<00:58, 263.19 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32531/47780 [01:48<00:56, 270.93 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32286/47780 [01:48<00:55, 277.97 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31240/47780 [01:48<00:53, 310.03 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31793/47780 [01:48<00:59, 269.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31914/47780 [01:48<00:54, 292.63 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31832/47780 [01:48<00:55, 285.27 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19100/47780 [01:48<01:18, 367.66 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32287/47780 [01:49<00:59, 262.44 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32559/47780 [01:48<00:57, 266.54 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31821/47780 [01:49<00:58, 272.40 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31272/47780 [01:48<00:53, 308.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32315/47780 [01:49<00:59, 258.72 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19141/47780 [01:49<01:17, 371.52 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31862/47780 [01:49<00:58, 273.71 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31945/47780 [01:49<01:00, 262.41 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32319/47780 [01:49<00:56, 272.58 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31849/47780 [01:49<00:58, 274.07 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31303/47780 [01:49<00:54, 302.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32586/47780 [01:49<01:01, 246.84 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32342/47780 [01:49<01:00, 256.61 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19185/47780 [01:49<01:13, 391.21 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31974/47780 [01:49<00:59, 266.55 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31890/47780 [01:49<01:00, 262.83 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31878/47780 [01:49<00:58, 273.09 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31334/47780 [01:49<00:55, 297.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32347/47780 [01:49<01:01, 251.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32618/47780 [01:49<00:59, 254.94 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19227/47780 [01:49<01:12, 394.92 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32369/47780 [01:49<01:01, 249.55 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32011/47780 [01:49<00:53, 294.24 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31917/47780 [01:49<01:03, 251.64 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31908/47780 [01:49<00:56, 280.79 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31365/47780 [01:49<00:55, 298.19 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32651/47780 [01:49<00:55, 272.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32384/47780 [01:49<00:55, 274.95 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32399/47780 [01:49<01:00, 254.82 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19267/47780 [01:49<01:16, 374.30 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32042/47780 [01:49<00:55, 283.26 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31948/47780 [01:49<00:59, 264.82 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31940/47780 [01:49<00:54, 292.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31395/47780 [01:49<00:56, 288.20 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32684/47780 [01:49<00:52, 285.09 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32413/47780 [01:49<00:55, 275.91 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32434/47780 [01:49<00:54, 280.43 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19308/47780 [01:49<01:14, 380.25 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31975/47780 [01:49<00:59, 266.21 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32072/47780 [01:49<00:55, 284.56 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31971/47780 [01:49<00:54, 289.10 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32713/47780 [01:49<00:53, 283.16 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32446/47780 [01:49<00:53, 284.84 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31424/47780 [01:49<01:02, 263.39 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32463/47780 [01:49<00:55, 277.08 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19347/47780 [01:49<01:18, 362.51 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32103/47780 [01:49<00:54, 288.56 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32006/47780 [01:49<00:58, 270.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32007/47780 [01:49<00:52, 302.29 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32744/47780 [01:49<00:52, 285.67 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32479/47780 [01:49<00:51, 294.28 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31451/47780 [01:49<01:02, 261.07 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32502/47780 [01:49<00:51, 298.71 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19385/47780 [01:49<01:18, 362.38 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32034/47780 [01:49<00:57, 271.76 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32038/47780 [01:49<00:51, 303.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32134/47780 [01:49<00:58, 267.53 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32775/47780 [01:49<00:51, 291.37 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32526/47780 [01:49<00:44, 340.28 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32535/47780 [01:49<00:50, 303.97 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31478/47780 [01:49<01:05, 249.97 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19423/47780 [01:49<01:23, 341.33 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32062/47780 [01:49<00:59, 262.38 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32189/47780 [01:49<00:45, 343.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32069/47780 [01:49<00:52, 297.35 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32809/47780 [01:49<00:49, 301.92 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32561/47780 [01:49<00:47, 317.70 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32572/47780 [01:49<00:47, 322.50 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31505/47780 [01:49<01:03, 255.18 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19460/47780 [01:49<01:22, 345.34 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32093/47780 [01:49<00:57, 272.68 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32225/47780 [01:49<00:46, 332.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32099/47780 [01:49<00:55, 283.11 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32840/47780 [01:49<00:51, 287.55 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32605/47780 [01:49<00:47, 317.27 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32600/47780 [01:50<00:46, 326.62 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31531/47780 [01:49<01:05, 247.11 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19496/47780 [01:50<01:22, 341.84 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32122/47780 [01:50<01:00, 259.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32132/47780 [01:50<00:53, 292.15 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32875/47780 [01:50<00:49, 298.38 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32639/47780 [01:50<00:44, 343.87 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32637/47780 [01:50<00:48, 314.53 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32260/47780 [01:50<00:53, 292.57 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31563/47780 [01:50<01:01, 265.71 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19532/47780 [01:50<01:26, 325.14 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32163/47780 [01:50<00:52, 297.06 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32152/47780 [01:50<00:59, 262.33 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32905/47780 [01:50<00:50, 295.60 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32291/47780 [01:50<00:52, 296.82 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32675/47780 [01:50<00:45, 330.14 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31591/47780 [01:50<01:03, 256.10 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32669/47780 [01:50<00:52, 289.61 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19566/47780 [01:50<01:25, 329.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32179/47780 [01:50<00:59, 263.99 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32193/47780 [01:50<00:56, 275.93 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32935/47780 [01:50<00:51, 287.00 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32322/47780 [01:50<00:52, 294.23 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32709/47780 [01:50<00:45, 332.78 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32700/47780 [01:50<00:51, 292.00 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31617/47780 [01:50<01:05, 245.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32208/47780 [01:50<00:57, 269.45 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19601/47780 [01:50<01:28, 316.97 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32967/47780 [01:50<00:50, 293.00 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32355/47780 [01:50<00:50, 303.80 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32750/47780 [01:50<00:42, 350.62 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32221/47780 [01:50<01:03, 246.65 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32733/47780 [01:50<00:50, 299.91 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31642/47780 [01:50<01:06, 243.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32238/47780 [01:50<00:56, 277.51 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19642/47780 [01:50<01:23, 335.37 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33001/47780 [01:50<00:48, 302.93 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32391/47780 [01:50<00:48, 319.47 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32786/47780 [01:50<00:44, 336.78 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32264/47780 [01:50<00:53, 287.64 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32764/47780 [01:50<00:50, 295.26 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31669/47780 [01:50<01:04, 248.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32271/47780 [01:50<00:53, 289.41 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19681/47780 [01:50<01:21, 342.98 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33035/47780 [01:50<00:47, 310.00 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32424/47780 [01:50<00:48, 315.28 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32294/47780 [01:50<00:55, 279.99 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32794/47780 [01:50<00:52, 283.94 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31694/47780 [01:50<01:08, 233.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32301/47780 [01:50<00:54, 285.58 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32820/47780 [01:50<00:49, 301.55 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19720/47780 [01:50<01:20, 348.32 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32457/47780 [01:50<00:49, 311.67 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33068/47780 [01:50<00:49, 298.52 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32823/47780 [01:50<00:52, 285.59 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32854/47780 [01:50<00:47, 311.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32323/47780 [01:50<00:58, 262.71 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31723/47780 [01:50<01:06, 240.92 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32331/47780 [01:50<00:55, 276.65 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19755/47780 [01:50<01:20, 348.22 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32492/47780 [01:50<00:47, 320.11 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33102/47780 [01:50<00:47, 308.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32865/47780 [01:50<00:46, 320.28 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32358/47780 [01:50<00:55, 280.07 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32886/47780 [01:50<00:48, 307.19 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31760/47780 [01:50<00:58, 273.44 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19793/47780 [01:50<01:19, 349.89 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32528/47780 [01:50<00:47, 324.25 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32359/47780 [01:50<01:03, 242.56 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33135/47780 [01:50<00:48, 300.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32898/47780 [01:50<00:46, 319.06 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32389/47780 [01:51<00:53, 288.08 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32918/47780 [01:51<00:49, 302.78 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31791/47780 [01:50<00:57, 277.44 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19833/47780 [01:51<01:17, 359.96 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32561/47780 [01:50<00:46, 325.15 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32392/47780 [01:51<00:58, 262.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33168/47780 [01:51<00:48, 300.50 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32931/47780 [01:51<00:49, 301.36 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32949/47780 [01:51<00:49, 299.55 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32421/47780 [01:51<00:54, 284.25 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31822/47780 [01:51<00:58, 274.53 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19871/47780 [01:51<01:19, 349.80 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32602/47780 [01:51<00:43, 346.61 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32420/47780 [01:51<00:59, 258.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33200/47780 [01:51<00:49, 297.23 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32963/47780 [01:51<00:50, 293.71 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32455/47780 [01:51<00:51, 296.39 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31859/47780 [01:51<00:53, 297.49 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32981/47780 [01:51<00:52, 282.44 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19907/47780 [01:51<01:20, 344.90 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32637/47780 [01:51<00:43, 344.80 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33230/47780 [01:51<00:50, 289.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32447/47780 [01:51<01:03, 240.80 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32487/47780 [01:51<00:50, 302.78 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32993/47780 [01:51<00:52, 279.99 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31889/47780 [01:51<00:55, 288.38 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33012/47780 [01:51<00:51, 284.36 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19942/47780 [01:51<01:27, 317.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32672/47780 [01:51<00:46, 325.71 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32472/47780 [01:51<01:05, 233.68 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32521/47780 [01:51<00:49, 310.17 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33260/47780 [01:51<00:54, 266.19 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33022/47780 [01:51<00:52, 279.65 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33045/47780 [01:51<00:49, 296.85 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31926/47780 [01:51<00:52, 304.51 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19977/47780 [01:51<01:25, 326.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32707/47780 [01:51<00:46, 325.40 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32511/47780 [01:51<00:55, 274.98 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31958/47780 [01:51<00:51, 308.25 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32554/47780 [01:51<00:52, 289.23 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33075/47780 [01:51<00:50, 292.67 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33051/47780 [01:51<00:56, 261.88 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20010/47780 [01:51<01:28, 313.47 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32740/47780 [01:51<00:47, 319.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33287/47780 [01:51<01:05, 220.33 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32540/47780 [01:51<00:58, 259.06 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33105/47780 [01:51<00:50, 289.87 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33079/47780 [01:51<00:55, 264.45 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31989/47780 [01:51<00:54, 289.63 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32584/47780 [01:51<00:55, 275.20 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20042/47780 [01:51<01:29, 311.63 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33328/47780 [01:51<00:54, 265.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32773/47780 [01:51<00:48, 308.48 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32567/47780 [01:51<00:58, 259.00 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32019/47780 [01:51<00:54, 289.07 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33136/47780 [01:51<00:52, 276.68 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33113/47780 [01:51<00:53, 275.91 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32614/47780 [01:51<00:57, 263.92 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20074/47780 [01:51<01:29, 310.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32804/47780 [01:51<00:49, 302.10 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33357/47780 [01:51<00:56, 256.17 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32594/47780 [01:51<01:01, 246.21 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32052/47780 [01:51<00:52, 300.35 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33143/47780 [01:51<00:52, 279.56 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33164/47780 [01:51<00:53, 271.13 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32650/47780 [01:51<00:52, 286.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20106/47780 [01:51<01:30, 306.47 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32848/47780 [01:51<00:45, 328.88 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33388/47780 [01:51<00:53, 267.24 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32620/47780 [01:51<01:00, 249.87 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32086/47780 [01:51<00:51, 304.98 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33172/47780 [01:51<00:52, 280.43 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20139/47780 [01:51<01:29, 309.49 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33192/47780 [01:52<00:56, 256.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32681/47780 [01:52<00:54, 274.61 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32884/47780 [01:51<00:44, 334.76 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33416/47780 [01:52<00:56, 254.40 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32646/47780 [01:52<00:59, 252.58 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33207/47780 [01:52<00:49, 295.67 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32117/47780 [01:52<00:51, 302.21 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20177/47780 [01:52<01:25, 322.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33218/47780 [01:52<00:58, 249.73 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32710/47780 [01:52<00:56, 267.43 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32918/47780 [01:52<00:49, 299.04 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33443/47780 [01:52<00:58, 243.16 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32684/47780 [01:52<00:53, 282.37 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32157/47780 [01:52<00:47, 327.36 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33240/47780 [01:52<00:47, 305.26 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20218/47780 [01:52<01:20, 343.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33245/47780 [01:52<00:56, 255.25 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32746/47780 [01:52<00:52, 289.11 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33468/47780 [01:52<00:59, 239.92 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32194/47780 [01:52<00:46, 333.95 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32713/47780 [01:52<00:56, 266.43 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33272/47780 [01:52<00:48, 298.37 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32949/47780 [01:52<00:55, 265.37 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20256/47780 [01:52<01:18, 349.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33276/47780 [01:52<00:54, 267.61 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32776/47780 [01:52<00:51, 288.94 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32228/47780 [01:52<00:47, 329.92 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33494/47780 [01:52<01:01, 232.45 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32740/47780 [01:52<00:57, 261.33 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33303/47780 [01:52<00:50, 288.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33309/47780 [01:52<00:50, 285.26 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32977/47780 [01:52<01:00, 244.66 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32806/47780 [01:52<00:54, 273.80 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20292/47780 [01:52<01:33, 295.05 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33527/47780 [01:52<00:55, 256.02 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32262/47780 [01:52<00:48, 321.75 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32772/47780 [01:52<00:55, 271.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33346/47780 [01:52<00:47, 306.31 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33332/47780 [01:52<00:53, 271.52 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33004/47780 [01:52<00:58, 250.80 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32840/47780 [01:52<00:52, 285.64 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20339/47780 [01:52<01:20, 339.86 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33554/47780 [01:52<00:56, 251.60 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32296/47780 [01:52<00:48, 316.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32800/47780 [01:52<00:58, 256.87 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33378/47780 [01:52<00:48, 299.73 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33361/47780 [01:52<00:52, 276.26 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33030/47780 [01:52<00:58, 250.23 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32869/47780 [01:52<00:55, 270.36 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20375/47780 [01:52<01:25, 320.93 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33588/47780 [01:52<00:53, 263.12 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32332/47780 [01:52<00:48, 315.81 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33411/47780 [01:52<00:46, 308.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33391/47780 [01:52<00:50, 282.82 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32827/47780 [01:52<00:58, 254.49 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33065/47780 [01:52<00:53, 276.94 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32897/47780 [01:52<00:56, 265.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20409/47780 [01:52<01:28, 309.96 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32859/47780 [01:52<00:55, 270.07 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33420/47780 [01:52<00:51, 276.79 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32364/47780 [01:52<00:51, 301.97 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33615/47780 [01:52<00:57, 244.74 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33094/47780 [01:52<00:52, 277.99 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33442/47780 [01:52<00:50, 282.74 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32924/47780 [01:52<00:58, 252.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20445/47780 [01:52<01:25, 319.60 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32396/47780 [01:52<00:51, 297.11 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33123/47780 [01:52<00:52, 281.31 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33643/47780 [01:52<00:56, 249.01 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32887/47780 [01:52<00:58, 255.47 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33472/47780 [01:53<00:51, 277.72 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33448/47780 [01:52<00:58, 244.14 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32951/47780 [01:53<00:57, 257.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20488/47780 [01:53<01:20, 338.86 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33674/47780 [01:53<00:54, 259.78 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33152/47780 [01:53<00:53, 271.42 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32426/47780 [01:53<00:56, 270.84 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33479/47780 [01:53<00:54, 260.41 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32913/47780 [01:53<01:02, 236.33 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33501/47780 [01:53<00:53, 266.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32979/47780 [01:53<00:56, 263.66 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20523/47780 [01:53<01:21, 334.01 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33183/47780 [01:53<00:51, 282.23 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33707/47780 [01:53<00:51, 274.29 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32455/47780 [01:53<00:55, 274.63 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32949/47780 [01:53<00:55, 268.95 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33510/47780 [01:53<00:52, 271.47 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33014/47780 [01:53<00:51, 288.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33528/47780 [01:53<00:57, 246.28 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20559/47780 [01:53<01:20, 337.72 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33212/47780 [01:53<00:53, 272.00 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32489/47780 [01:53<00:52, 291.97 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33542/47780 [01:53<00:50, 281.86 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32981/47780 [01:53<00:53, 276.83 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33736/47780 [01:53<00:55, 254.02 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33052/47780 [01:53<00:47, 313.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33553/47780 [01:53<00:58, 244.91 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20599/47780 [01:53<01:16, 355.17 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33242/47780 [01:53<00:53, 273.63 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32519/47780 [01:53<00:53, 286.69 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33762/47780 [01:53<00:55, 253.43 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33010/47780 [01:53<00:55, 265.41 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33578/47780 [01:53<00:57, 245.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33571/47780 [01:53<00:56, 252.86 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33084/47780 [01:53<00:51, 286.94 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20635/47780 [01:53<01:19, 340.94 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33270/47780 [01:53<00:53, 272.09 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32548/47780 [01:53<00:54, 281.31 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33795/47780 [01:53<00:52, 266.03 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33041/47780 [01:53<00:53, 274.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33603/47780 [01:53<00:59, 236.83 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33114/47780 [01:53<00:51, 286.16 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20670/47780 [01:53<01:20, 335.97 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33598/47780 [01:53<01:03, 222.18 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32577/47780 [01:53<00:53, 283.73 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33304/47780 [01:53<00:52, 277.93 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33077/47780 [01:53<00:49, 295.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33832/47780 [01:53<00:47, 291.28 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33629/47780 [01:53<01:00, 235.49 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33144/47780 [01:53<00:55, 262.94 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20705/47780 [01:53<01:27, 310.29 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32606/47780 [01:53<00:53, 282.07 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33340/47780 [01:53<00:48, 298.78 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33622/47780 [01:53<01:06, 211.98 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33866/47780 [01:53<00:45, 304.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33109/47780 [01:53<00:49, 298.66 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33664/47780 [01:53<00:54, 261.35 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33171/47780 [01:53<00:56, 257.33 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20761/47780 [01:53<01:13, 367.43 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33372/47780 [01:53<00:47, 304.77 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32635/47780 [01:53<00:55, 271.51 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33140/47780 [01:53<00:49, 298.38 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33897/47780 [01:53<00:46, 295.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33644/47780 [01:53<01:09, 203.88 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33694/47780 [01:53<00:52, 269.06 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33198/47780 [01:53<00:58, 250.88 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20799/47780 [01:53<01:13, 364.97 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32674/47780 [01:53<00:49, 304.17 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33174/47780 [01:53<00:47, 307.00 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33404/47780 [01:53<00:49, 291.90 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33931/47780 [01:53<00:45, 305.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33723/47780 [01:53<00:40, 351.40 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33733/47780 [01:54<00:46, 300.02 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33225/47780 [01:54<00:57, 253.31 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20843/47780 [01:54<01:10, 383.53 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33435/47780 [01:54<00:48, 294.10 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33963/47780 [01:54<00:44, 309.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33205/47780 [01:54<00:49, 297.00 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32710/47780 [01:54<00:52, 285.28 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33762/47780 [01:54<00:42, 333.31 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33764/47780 [01:54<00:49, 283.38 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20883/47780 [01:54<01:09, 387.95 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33251/47780 [01:54<00:58, 249.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33465/47780 [01:54<00:49, 291.92 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33995/47780 [01:54<00:48, 282.88 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33235/47780 [01:54<00:53, 273.42 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32740/47780 [01:54<00:54, 277.14 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33798/47780 [01:54<00:42, 326.54 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33793/47780 [01:54<00:51, 272.92 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20923/47780 [01:54<01:10, 380.29 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33277/47780 [01:54<00:58, 247.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33495/47780 [01:54<00:49, 287.52 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34026/47780 [01:54<00:48, 284.34 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33263/47780 [01:54<00:53, 272.37 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32769/47780 [01:54<00:55, 271.00 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33821/47780 [01:54<00:55, 251.30 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33302/47780 [01:54<00:59, 242.26 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20962/47780 [01:54<01:13, 364.75 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33833/47780 [01:54<00:48, 284.77 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33525/47780 [01:54<00:50, 282.07 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33291/47780 [01:54<00:52, 274.05 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34055/47780 [01:54<00:49, 279.71 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32799/47780 [01:54<00:55, 271.36 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33327/47780 [01:54<01:00, 238.58 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33557/47780 [01:54<00:49, 289.55 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33847/47780 [01:54<00:59, 234.94 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20999/47780 [01:54<01:19, 336.35 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33321/47780 [01:54<00:51, 281.32 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33864/47780 [01:54<00:52, 263.11 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34084/47780 [01:54<00:51, 264.91 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32827/47780 [01:54<00:56, 263.05 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33354/47780 [01:54<00:58, 245.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33594/47780 [01:54<00:45, 309.00 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21039/47780 [01:54<01:15, 353.24 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33871/47780 [01:54<01:01, 226.73 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33359/47780 [01:54<00:49, 293.37 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33893/47780 [01:54<00:52, 264.51 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34111/47780 [01:54<00:52, 261.79 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32854/47780 [01:54<01:02, 238.23 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33379/47780 [01:54<01:01, 232.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33629/47780 [01:54<00:44, 317.74 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21076/47780 [01:54<01:14, 357.65 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33899/47780 [01:54<00:58, 238.50 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33389/47780 [01:54<00:49, 288.68 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34139/47780 [01:54<00:51, 264.43 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33921/47780 [01:54<00:54, 253.21 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32882/47780 [01:54<00:59, 248.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33416/47780 [01:54<00:53, 268.56 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33661/47780 [01:54<00:45, 307.10 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33924/47780 [01:54<00:59, 233.96 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21113/47780 [01:54<01:24, 314.95 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33419/47780 [01:54<00:53, 267.82 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33948/47780 [01:54<00:56, 245.07 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34166/47780 [01:54<00:54, 247.60 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32913/47780 [01:54<00:57, 257.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33447/47780 [01:54<00:51, 280.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33693/47780 [01:54<00:45, 310.55 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33950/47780 [01:55<00:58, 236.21 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21153/47780 [01:54<01:19, 333.67 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34207/47780 [01:54<00:46, 291.74 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33447/47780 [01:54<00:54, 261.28 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33987/47780 [01:54<00:50, 273.79 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33476/47780 [01:55<00:50, 282.78 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33730/47780 [01:54<00:43, 324.36 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32950/47780 [01:54<00:53, 275.67 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33978/47780 [01:55<00:56, 242.93 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21192/47780 [01:55<01:20, 331.10 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34237/47780 [01:55<00:47, 287.69 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34016/47780 [01:55<00:50, 275.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33480/47780 [01:55<00:53, 266.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33505/47780 [01:55<00:52, 272.47 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32979/47780 [01:55<00:54, 272.88 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33763/47780 [01:55<00:45, 307.97 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34003/47780 [01:55<00:56, 244.86 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21235/47780 [01:55<01:14, 357.47 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34046/47780 [01:55<00:50, 272.98 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34267/47780 [01:55<00:49, 272.48 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33517/47780 [01:55<00:49, 286.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33534/47780 [01:55<00:51, 274.42 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33008/47780 [01:55<00:53, 275.43 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34040/47780 [01:55<00:49, 277.38 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33794/47780 [01:55<00:47, 295.71 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21273/47780 [01:55<01:16, 347.60 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34076/47780 [01:55<00:49, 277.14 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33550/47780 [01:55<00:47, 297.12 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34295/47780 [01:55<00:49, 271.44 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33564/47780 [01:55<00:51, 278.55 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33039/47780 [01:55<00:51, 284.11 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34068/47780 [01:55<00:49, 274.91 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33824/47780 [01:55<00:50, 277.79 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21317/47780 [01:55<01:12, 365.61 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33581/47780 [01:55<00:47, 297.46 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34324/47780 [01:55<00:49, 273.97 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34105/47780 [01:55<00:50, 271.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33594/47780 [01:55<00:50, 282.52 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33076/47780 [01:55<00:48, 302.75 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34096/47780 [01:55<00:50, 273.17 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33855/47780 [01:55<00:48, 286.48 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21355/47780 [01:55<01:13, 361.56 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33613/47780 [01:55<00:46, 303.75 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34352/47780 [01:55<00:49, 272.55 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34133/47780 [01:55<00:49, 273.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33626/47780 [01:55<00:48, 292.28 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33107/47780 [01:55<00:52, 279.29 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34124/47780 [01:55<00:51, 263.02 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33898/47780 [01:55<00:43, 319.65 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34380/47780 [01:55<00:48, 274.53 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34161/47780 [01:55<00:49, 272.73 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33644/47780 [01:55<00:47, 295.10 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21392/47780 [01:55<01:16, 344.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33658/47780 [01:55<00:47, 296.89 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34154/47780 [01:55<00:50, 272.10 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33934/47780 [01:55<00:41, 330.83 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33136/47780 [01:55<00:54, 267.70 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34410/47780 [01:55<00:47, 281.79 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34191/47780 [01:55<00:49, 273.28 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33694/47780 [01:55<00:44, 315.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21430/47780 [01:55<01:14, 354.09 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33674/47780 [01:55<00:50, 279.44 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34182/47780 [01:55<00:52, 257.26 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33968/47780 [01:55<00:43, 318.34 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33164/47780 [01:55<00:56, 259.75 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34439/47780 [01:55<00:47, 278.08 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34222/47780 [01:55<00:48, 278.40 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21468/47780 [01:55<01:13, 357.27 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33727/47780 [01:55<00:46, 305.22 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33709/47780 [01:55<00:47, 293.95 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33198/47780 [01:55<00:52, 277.99 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34001/47780 [01:55<00:46, 295.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34467/47780 [01:55<00:48, 272.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34208/47780 [01:56<00:58, 230.50 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21507/47780 [01:55<01:13, 358.68 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34255/47780 [01:55<00:47, 283.39 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33740/47780 [01:55<00:47, 298.35 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33772/47780 [01:55<00:42, 332.12 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33234/47780 [01:55<00:49, 294.54 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34032/47780 [01:55<00:45, 299.24 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34501/47780 [01:56<00:45, 291.77 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34232/47780 [01:56<00:59, 228.02 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33771/47780 [01:56<00:46, 298.37 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21544/47780 [01:56<01:15, 346.22 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34284/47780 [01:56<00:50, 269.62 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33807/47780 [01:56<00:42, 329.06 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33264/47780 [01:56<00:50, 289.65 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34537/47780 [01:56<00:42, 311.65 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34064/47780 [01:56<00:46, 292.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34263/47780 [01:56<00:54, 247.55 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33804/47780 [01:56<00:45, 306.15 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21579/47780 [01:56<01:18, 331.78 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34315/47780 [01:56<00:50, 266.46 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33840/47780 [01:56<00:44, 311.88 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33303/47780 [01:56<00:46, 314.23 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34098/47780 [01:56<00:44, 305.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34298/47780 [01:56<00:48, 275.70 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33839/47780 [01:56<00:44, 316.57 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34569/47780 [01:56<00:46, 285.38 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21613/47780 [01:56<01:22, 317.20 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34343/47780 [01:56<00:51, 261.13 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33335/47780 [01:56<00:46, 312.34 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33872/47780 [01:56<00:50, 274.68 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34132/47780 [01:56<00:43, 312.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34333/47780 [01:56<00:45, 296.49 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34611/47780 [01:56<00:41, 317.46 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33872/47780 [01:56<00:47, 290.04 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34372/47780 [01:56<00:50, 264.97 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21645/47780 [01:56<01:24, 307.91 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33367/47780 [01:56<00:46, 310.96 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34171/47780 [01:56<00:40, 333.56 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33902/47780 [01:56<00:49, 278.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34374/47780 [01:56<00:42, 318.28 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34644/47780 [01:56<00:43, 303.51 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33902/47780 [01:56<00:48, 289.08 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21676/47780 [01:56<01:25, 305.17 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34399/47780 [01:56<00:51, 258.86 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33399/47780 [01:56<00:47, 299.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33937/47780 [01:56<00:47, 293.10 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34408/47780 [01:56<00:42, 312.60 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34676/47780 [01:56<00:42, 305.16 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33933/47780 [01:56<00:47, 288.78 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34205/47780 [01:56<00:47, 283.11 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34430/47780 [01:56<00:49, 270.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21708/47780 [01:56<01:30, 287.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33430/47780 [01:56<00:49, 289.61 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33967/47780 [01:56<00:49, 280.18 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34445/47780 [01:56<00:41, 322.75 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34707/47780 [01:56<00:43, 303.11 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34235/47780 [01:56<00:47, 284.13 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34461/47780 [01:56<00:47, 281.76 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33963/47780 [01:56<00:50, 273.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21744/47780 [01:56<01:25, 306.27 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33998/47780 [01:56<00:48, 285.89 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34478/47780 [01:56<00:43, 307.13 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33460/47780 [01:56<00:55, 258.93 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34286/47780 [01:56<00:39, 344.46 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34739/47780 [01:56<00:44, 291.44 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34001/47780 [01:56<00:46, 299.50 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21784/47780 [01:56<01:19, 328.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34490/47780 [01:56<00:50, 265.68 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34027/47780 [01:56<00:52, 263.35 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33492/47780 [01:56<00:54, 262.90 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34322/47780 [01:56<00:39, 337.92 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34509/47780 [01:57<00:46, 285.89 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34771/47780 [01:56<00:44, 289.70 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34035/47780 [01:56<00:44, 310.64 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21820/47780 [01:56<01:16, 337.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34521/47780 [01:56<00:48, 275.06 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34056/47780 [01:57<00:50, 269.75 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33524/47780 [01:57<00:51, 277.62 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34538/47780 [01:57<00:46, 282.52 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34805/47780 [01:57<00:43, 297.08 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21855/47780 [01:57<01:18, 329.85 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34549/47780 [01:57<00:49, 267.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34067/47780 [01:57<00:47, 290.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34358/47780 [01:57<00:44, 304.75 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33565/47780 [01:57<00:46, 304.02 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34567/47780 [01:57<00:49, 268.46 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34084/47780 [01:57<00:57, 239.38 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21893/47780 [01:57<01:17, 335.52 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34576/47780 [01:57<00:50, 262.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34097/47780 [01:57<00:47, 286.66 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34835/47780 [01:57<00:49, 259.48 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34390/47780 [01:57<00:46, 288.94 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33597/47780 [01:57<00:47, 301.32 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34596/47780 [01:57<00:48, 271.28 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34112/47780 [01:57<00:55, 247.17 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21931/47780 [01:57<01:14, 347.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34606/47780 [01:57<00:48, 272.58 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34870/47780 [01:57<00:45, 282.01 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34127/47780 [01:57<00:50, 269.48 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34429/47780 [01:57<00:42, 311.41 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33633/47780 [01:57<00:44, 314.66 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34139/47780 [01:57<00:53, 252.93 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34640/47780 [01:57<00:45, 288.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21966/47780 [01:57<01:15, 342.15 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34625/47780 [01:57<00:52, 251.55 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34902/47780 [01:57<00:45, 284.97 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34164/47780 [01:57<00:46, 291.33 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34473/47780 [01:57<00:39, 336.28 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33666/47780 [01:57<00:45, 311.95 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34165/47780 [01:57<00:56, 241.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22002/47780 [01:57<01:17, 331.94 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34670/47780 [01:57<00:47, 275.78 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34508/47780 [01:57<00:39, 332.42 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34651/47780 [01:57<00:56, 233.01 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34194/47780 [01:57<00:49, 271.77 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34932/47780 [01:57<00:49, 260.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33698/47780 [01:57<00:47, 297.44 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34699/47780 [01:57<00:47, 277.39 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22038/47780 [01:57<01:19, 325.23 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34190/47780 [01:57<00:59, 229.14 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34545/47780 [01:57<00:38, 339.45 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34677/47780 [01:57<00:54, 238.64 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34959/47780 [01:57<00:52, 244.89 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34222/47780 [01:57<00:56, 241.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33728/47780 [01:57<00:48, 291.63 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34731/47780 [01:57<00:45, 289.09 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22076/47780 [01:57<01:15, 340.46 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34227/47780 [01:57<00:52, 258.46 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34708/47780 [01:57<00:50, 257.70 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34580/47780 [01:57<00:42, 307.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34985/47780 [01:57<00:53, 238.88 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34762/47780 [01:57<00:44, 295.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33759/47780 [01:57<00:48, 290.28 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34247/47780 [01:57<00:57, 235.41 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22112/47780 [01:57<01:15, 341.62 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34258/47780 [01:57<00:49, 272.34 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34735/47780 [01:57<00:49, 261.09 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34615/47780 [01:57<00:41, 315.80 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35017/47780 [01:57<00:49, 257.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34792/47780 [01:57<00:44, 293.64 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33789/47780 [01:57<00:48, 285.94 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22147/47780 [01:57<01:19, 323.59 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34292/47780 [01:57<00:47, 282.56 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34272/47780 [01:57<01:01, 221.31 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34763/47780 [01:58<00:49, 260.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34651/47780 [01:57<00:40, 327.76 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34825/47780 [01:57<00:43, 300.23 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35045/47780 [01:57<00:50, 252.76 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33818/47780 [01:57<00:51, 272.57 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34303/47780 [01:58<00:55, 243.74 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22181/47780 [01:58<01:19, 323.28 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34791/47780 [01:58<00:48, 266.01 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34321/47780 [01:58<00:50, 268.64 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34699/47780 [01:58<00:35, 366.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34866/47780 [01:58<00:38, 331.92 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35072/47780 [01:58<00:49, 254.66 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33858/47780 [01:58<00:45, 307.35 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34330/47780 [01:58<00:54, 246.26 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22218/47780 [01:58<01:16, 332.16 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34824/47780 [01:58<00:45, 283.19 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34351/47780 [01:58<00:48, 274.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34737/47780 [01:58<00:36, 358.03 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34901/47780 [01:58<00:39, 326.08 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35099/47780 [01:58<00:50, 250.67 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33890/47780 [01:58<00:44, 310.10 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34356/47780 [01:58<00:53, 249.22 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22259/47780 [01:58<01:12, 350.40 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34379/47780 [01:58<00:48, 275.53 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34853/47780 [01:58<00:48, 264.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34774/47780 [01:58<00:36, 360.19 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34934/47780 [01:58<00:40, 314.26 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35133/47780 [01:58<00:46, 270.79 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34386/47780 [01:58<00:52, 257.55 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22295/47780 [01:58<01:13, 346.15 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33922/47780 [01:58<00:51, 270.24 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34880/47780 [01:58<00:50, 257.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34811/47780 [01:58<00:37, 344.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34407/47780 [01:58<00:56, 234.62 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35164/47780 [01:58<00:45, 277.01 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34966/47780 [01:58<00:41, 310.15 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34416/47780 [01:58<00:49, 269.28 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22330/47780 [01:58<01:16, 331.63 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33951/47780 [01:58<00:50, 272.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34906/47780 [01:58<00:52, 244.46 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35201/47780 [01:58<00:41, 302.96 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34846/47780 [01:58<00:41, 311.11 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34433/47780 [01:58<00:59, 222.53 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34445/47780 [01:58<00:49, 268.90 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34998/47780 [01:58<00:44, 290.44 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22365/47780 [01:58<01:18, 324.74 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34931/47780 [01:58<00:52, 243.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33980/47780 [01:58<00:56, 246.40 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34474/47780 [01:58<00:49, 268.16 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35233/47780 [01:58<00:43, 285.35 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34473/47780 [01:58<00:51, 260.23 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35028/47780 [01:58<00:44, 283.73 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22399/47780 [01:58<01:18, 322.86 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34878/47780 [01:58<00:46, 277.99 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34961/47780 [01:58<00:50, 255.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 34008/47780 [01:58<00:54, 254.60 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34503/47780 [01:58<00:48, 272.89 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35263/47780 [01:58<00:43, 286.04 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35057/47780 [01:58<00:45, 279.35 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22433/47780 [01:58<01:18, 324.10 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34501/47780 [01:58<00:53, 249.33 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34989/47780 [01:58<00:50, 254.72 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34907/47780 [01:58<00:49, 258.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 34036/47780 [01:58<00:52, 260.52 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34536/47780 [01:58<00:46, 285.66 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35292/47780 [01:58<00:43, 287.01 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22469/47780 [01:58<01:15, 334.22 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35090/47780 [01:58<00:45, 277.94 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34527/47780 [01:58<00:55, 240.59 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34935/47780 [01:58<00:48, 263.41 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35015/47780 [01:59<00:52, 245.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34063/47780 [01:58<00:52, 260.60 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34568/47780 [01:58<00:45, 291.84 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22505/47780 [01:58<01:14, 337.80 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35321/47780 [01:58<00:47, 261.00 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35118/47780 [01:58<00:45, 275.48 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34098/47780 [01:59<00:47, 285.48 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34552/47780 [01:59<00:58, 225.38 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34963/47780 [01:58<00:49, 259.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35047/47780 [01:59<00:48, 260.22 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34598/47780 [01:59<00:46, 284.71 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22540/47780 [01:59<01:13, 341.29 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35348/47780 [01:59<00:47, 261.45 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35146/47780 [01:59<00:47, 267.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34128/47780 [01:59<00:47, 286.18 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34990/47780 [01:59<00:49, 259.22 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35074/47780 [01:59<00:49, 257.95 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34575/47780 [01:59<01:00, 219.04 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34635/47780 [01:59<00:42, 308.57 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22582/47780 [01:59<01:10, 356.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35375/47780 [01:59<00:48, 257.55 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35017/47780 [01:59<00:49, 259.77 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34157/47780 [01:59<00:49, 276.48 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34598/47780 [01:59<00:59, 221.74 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35102/47780 [01:59<00:49, 257.47 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35173/47780 [01:59<00:53, 234.93 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34667/47780 [01:59<00:43, 304.93 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22621/47780 [01:59<01:09, 361.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35402/47780 [01:59<00:49, 252.58 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35047/47780 [01:59<00:47, 267.99 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34192/47780 [01:59<00:45, 295.73 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35128/47780 [01:59<00:49, 255.39 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35200/47780 [01:59<00:53, 233.91 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34621/47780 [01:59<01:04, 203.83 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34698/47780 [01:59<00:44, 292.99 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22658/47780 [01:59<01:09, 364.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35433/47780 [01:59<00:46, 265.63 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35154/47780 [01:59<00:49, 253.64 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35074/47780 [01:59<00:50, 251.93 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34223/47780 [01:59<00:49, 274.47 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34644/47780 [01:59<01:02, 210.58 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35224/47780 [01:59<00:55, 228.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22695/47780 [01:59<01:11, 349.48 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34728/47780 [01:59<00:48, 267.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35460/47780 [01:59<00:49, 249.66 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35107/47780 [01:59<00:46, 269.93 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34671/47780 [01:59<00:58, 224.69 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35180/47780 [01:59<00:53, 236.65 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35248/47780 [01:59<00:54, 228.59 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34251/47780 [01:59<00:54, 248.96 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22731/47780 [01:59<01:13, 341.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34756/47780 [01:59<00:49, 265.08 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35493/47780 [01:59<00:46, 263.32 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34700/47780 [01:59<00:53, 242.79 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35210/47780 [01:59<00:50, 251.30 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35135/47780 [01:59<00:49, 255.61 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35272/47780 [01:59<00:54, 229.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22767/47780 [01:59<01:13, 341.90 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35520/47780 [01:59<00:46, 265.04 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34277/47780 [01:59<00:59, 228.06 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34783/47780 [01:59<00:51, 250.07 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35237/47780 [01:59<00:49, 250.96 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35167/47780 [01:59<00:46, 270.15 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35302/47780 [01:59<00:52, 238.70 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34725/47780 [01:59<00:57, 226.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22803/47780 [01:59<01:15, 332.03 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34303/47780 [01:59<00:58, 231.41 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34821/47780 [01:59<00:46, 276.41 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35547/47780 [01:59<00:48, 252.25 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35263/47780 [01:59<00:49, 251.72 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35340/47780 [01:59<00:45, 275.52 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34750/47780 [01:59<00:56, 230.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35196/47780 [01:59<00:47, 263.83 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34327/47780 [01:59<00:58, 231.21 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35573/47780 [01:59<00:48, 251.62 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22838/47780 [01:59<01:22, 303.78 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34849/47780 [02:00<00:48, 268.61 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35291/47780 [02:00<00:49, 252.88 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35370/47780 [02:00<00:44, 281.47 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34782/47780 [02:00<00:50, 255.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35223/47780 [02:00<00:50, 246.81 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34353/47780 [02:00<00:56, 238.18 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34883/47780 [02:00<00:44, 287.80 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22885/47780 [02:00<01:11, 347.48 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35599/47780 [02:00<00:51, 235.49 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35318/47780 [02:00<00:49, 251.32 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35255/47780 [02:00<00:47, 263.34 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35399/47780 [02:00<00:47, 259.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34808/47780 [02:00<00:56, 228.30 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34382/47780 [02:00<00:54, 247.93 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34920/47780 [02:00<00:41, 307.75 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22921/47780 [02:00<01:12, 344.87 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35632/47780 [02:00<00:47, 258.26 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35349/47780 [02:00<00:48, 257.03 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35432/47780 [02:00<00:44, 276.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35291/47780 [02:00<00:44, 283.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34840/47780 [02:00<00:52, 247.30 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34953/47780 [02:00<00:41, 310.51 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34416/47780 [02:00<00:50, 264.78 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22957/47780 [02:00<01:14, 332.09 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35659/47780 [02:00<00:47, 255.45 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35378/47780 [02:00<00:46, 264.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35462/47780 [02:00<00:43, 282.75 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34867/47780 [02:00<00:53, 240.62 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35320/47780 [02:00<00:48, 258.31 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34989/47780 [02:00<00:40, 317.41 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34444/47780 [02:00<00:51, 257.49 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22991/47780 [02:00<01:16, 323.56 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35695/47780 [02:00<00:44, 272.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35493/47780 [02:00<00:43, 284.14 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35405/47780 [02:00<00:52, 235.64 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35348/47780 [02:00<00:47, 259.80 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34475/47780 [02:00<00:48, 271.90 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35023/47780 [02:00<00:40, 316.01 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34892/47780 [02:00<00:57, 223.93 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23025/47780 [02:00<01:18, 313.87 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35729/47780 [02:00<00:42, 285.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35530/47780 [02:00<00:39, 306.26 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35430/47780 [02:00<00:52, 234.19 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35380/47780 [02:00<00:44, 275.95 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34509/47780 [02:00<00:46, 287.84 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35055/47780 [02:00<00:40, 310.70 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34917/47780 [02:00<00:55, 230.65 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23057/47780 [02:00<01:22, 299.57 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35759/47780 [02:00<00:43, 277.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35561/47780 [02:00<00:39, 305.97 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35411/47780 [02:00<00:44, 278.32 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34542/47780 [02:00<00:44, 296.79 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34946/47780 [02:00<00:52, 244.09 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35454/47780 [02:00<00:57, 213.06 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35087/47780 [02:00<00:42, 297.23 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35791/47780 [02:00<00:41, 285.62 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23088/47780 [02:00<01:24, 292.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35611/47780 [02:00<00:34, 354.29 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34572/47780 [02:00<00:45, 287.71 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35440/47780 [02:00<00:46, 264.89 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35483/47780 [02:00<00:53, 228.07 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34971/47780 [02:00<00:54, 232.91 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35826/47780 [02:00<00:39, 303.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23118/47780 [02:00<01:26, 285.99 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35117/47780 [02:00<00:48, 260.75 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35648/47780 [02:00<00:35, 342.94 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34603/47780 [02:00<00:44, 293.81 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35467/47780 [02:00<00:46, 266.26 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35512/47780 [02:01<00:50, 241.39 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34997/47780 [02:00<00:53, 240.17 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35868/47780 [02:00<00:35, 336.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23150/47780 [02:00<01:23, 293.42 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35684/47780 [02:00<00:35, 344.67 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35144/47780 [02:01<00:49, 256.32 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35494/47780 [02:00<00:46, 264.33 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34637/47780 [02:01<00:44, 297.06 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35546/47780 [02:01<00:45, 266.08 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35027/47780 [02:01<00:50, 251.37 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35902/47780 [02:01<00:35, 330.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23186/47780 [02:01<01:19, 310.66 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35719/47780 [02:01<00:36, 333.46 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35171/47780 [02:01<00:50, 250.46 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34667/47780 [02:01<00:44, 294.12 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35053/47780 [02:01<00:51, 248.33 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35521/47780 [02:01<00:49, 246.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35574/47780 [02:01<00:48, 250.41 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23218/47780 [02:01<01:21, 302.79 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35936/47780 [02:01<00:38, 311.12 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35202/47780 [02:01<00:47, 262.72 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35753/47780 [02:01<00:37, 317.65 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34697/47780 [02:01<00:46, 283.42 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35080/47780 [02:01<00:50, 251.48 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35600/47780 [02:01<00:48, 250.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35555/47780 [02:01<00:46, 260.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23250/47780 [02:01<01:19, 307.52 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35232/47780 [02:01<00:46, 269.34 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35969/47780 [02:01<00:39, 296.99 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35785/47780 [02:01<00:39, 301.93 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35107/47780 [02:01<00:49, 253.88 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34726/47780 [02:01<00:49, 261.56 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35582/47780 [02:01<00:47, 257.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35626/47780 [02:01<00:50, 239.54 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23285/47780 [02:01<01:18, 312.82 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35274/47780 [02:01<00:40, 307.25 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36002/47780 [02:01<00:39, 299.24 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35817/47780 [02:01<00:40, 297.03 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35134/47780 [02:01<00:48, 258.51 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35610/47780 [02:01<00:46, 260.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34753/47780 [02:01<00:49, 260.66 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35651/47780 [02:01<00:51, 234.67 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23318/47780 [02:01<01:17, 313.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36033/47780 [02:01<00:39, 299.19 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35306/47780 [02:01<00:41, 301.56 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35847/47780 [02:01<00:40, 291.38 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35160/47780 [02:01<00:50, 249.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34781/47780 [02:01<00:49, 261.13 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23363/47780 [02:01<01:11, 341.63 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35637/47780 [02:01<00:52, 230.04 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35675/47780 [02:01<00:56, 212.60 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35337/47780 [02:01<00:43, 285.10 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35880/47780 [02:01<00:39, 298.95 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35186/47780 [02:01<00:52, 241.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34808/47780 [02:01<00:49, 262.89 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23398/47780 [02:01<01:14, 325.45 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35668/47780 [02:01<00:48, 250.65 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36064/47780 [02:01<00:51, 228.15 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35709/47780 [02:01<00:49, 245.72 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35911/47780 [02:01<00:41, 287.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35366/47780 [02:01<00:48, 258.39 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34835/47780 [02:01<00:52, 248.23 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35211/47780 [02:01<00:56, 221.90 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23431/47780 [02:01<01:16, 319.70 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35741/47780 [02:01<00:46, 260.83 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35699/47780 [02:01<00:48, 248.02 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36090/47780 [02:01<00:53, 218.95 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35940/47780 [02:01<00:41, 286.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35398/47780 [02:01<00:45, 274.33 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34861/47780 [02:01<00:53, 243.50 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23467/47780 [02:01<01:13, 330.93 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35234/47780 [02:01<00:58, 214.84 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35770/47780 [02:02<00:45, 265.99 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35734/47780 [02:01<00:44, 272.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36147/47780 [02:01<00:38, 298.98 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35427/47780 [02:02<00:48, 253.76 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34887/47780 [02:02<00:53, 242.14 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23501/47780 [02:02<01:12, 333.31 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35256/47780 [02:02<00:59, 211.56 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35799/47780 [02:02<00:44, 269.71 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35969/47780 [02:02<00:53, 222.34 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35762/47780 [02:02<00:45, 262.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36181/47780 [02:02<00:40, 288.55 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35454/47780 [02:02<00:49, 247.69 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34912/47780 [02:02<00:54, 236.88 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35279/47780 [02:02<00:57, 216.56 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23535/47780 [02:02<01:15, 320.58 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35827/47780 [02:02<00:43, 272.55 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36016/47780 [02:02<00:42, 275.89 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35791/47780 [02:02<00:45, 264.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36215/47780 [02:02<00:39, 296.16 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35480/47780 [02:02<00:49, 246.40 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34936/47780 [02:02<00:54, 235.11 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35855/47780 [02:02<00:43, 271.60 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35307/47780 [02:02<00:54, 226.90 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23569/47780 [02:02<01:15, 322.40 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35818/47780 [02:02<00:46, 257.10 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36247/47780 [02:02<00:38, 300.54 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36047/47780 [02:02<00:45, 260.50 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35505/47780 [02:02<00:49, 246.52 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23603/47780 [02:02<01:13, 327.22 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35330/47780 [02:02<00:55, 222.52 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35884/47780 [02:02<00:44, 268.50 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34961/47780 [02:02<00:58, 218.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35847/47780 [02:02<00:45, 263.60 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36280/47780 [02:02<00:38, 296.80 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36081/47780 [02:02<00:41, 279.78 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35534/47780 [02:02<00:48, 253.10 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23636/47780 [02:02<01:14, 323.94 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35912/47780 [02:02<00:43, 270.80 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35357/47780 [02:02<00:54, 229.04 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34984/47780 [02:02<01:01, 209.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35874/47780 [02:02<00:44, 265.16 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36120/47780 [02:02<00:38, 303.03 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36311/47780 [02:02<00:39, 292.15 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35563/47780 [02:02<00:46, 260.55 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35940/47780 [02:02<00:43, 270.22 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35386/47780 [02:02<00:50, 244.03 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23669/47780 [02:02<01:23, 290.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35006/47780 [02:02<01:02, 205.27 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35902/47780 [02:02<00:47, 249.60 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36159/47780 [02:02<00:35, 322.82 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36346/47780 [02:02<00:37, 307.43 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35591/47780 [02:02<00:46, 260.87 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35968/47780 [02:02<00:43, 269.88 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35415/47780 [02:02<00:48, 252.88 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23700/47780 [02:02<01:24, 285.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35031/47780 [02:02<00:59, 215.28 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35932/47780 [02:02<00:45, 260.62 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36200/47780 [02:02<00:33, 343.00 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36378/47780 [02:02<00:38, 297.49 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35618/47780 [02:02<00:46, 261.98 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35998/47780 [02:02<00:42, 275.65 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35441/47780 [02:02<00:51, 240.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35055/47780 [02:02<00:57, 219.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23732/47780 [02:02<01:24, 285.43 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35959/47780 [02:02<00:46, 256.46 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35648/47780 [02:02<00:44, 270.61 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36409/47780 [02:02<00:40, 279.39 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36236/47780 [02:02<00:36, 312.52 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36026/47780 [02:03<00:45, 256.09 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35467/47780 [02:02<00:50, 241.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35078/47780 [02:02<00:57, 220.03 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23767/47780 [02:02<01:20, 299.87 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35986/47780 [02:02<00:45, 258.35 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36438/47780 [02:02<00:41, 276.15 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35676/47780 [02:03<00:48, 247.22 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35497/47780 [02:03<00:48, 254.59 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36052/47780 [02:03<00:46, 251.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36269/47780 [02:03<00:41, 278.64 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35101/47780 [02:03<00:59, 212.74 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36013/47780 [02:03<00:45, 255.89 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36466/47780 [02:03<00:43, 262.99 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35708/47780 [02:03<00:45, 264.53 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35524/47780 [02:03<00:47, 255.89 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23798/47780 [02:03<01:38, 242.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36305/47780 [02:03<00:38, 296.40 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36078/47780 [02:03<00:49, 238.80 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35127/47780 [02:03<00:56, 223.27 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36049/47780 [02:03<00:41, 282.25 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35736/47780 [02:03<00:45, 262.96 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36494/47780 [02:03<00:43, 261.51 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35554/47780 [02:03<00:45, 268.24 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23844/47780 [02:03<01:21, 291.94 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36104/47780 [02:03<00:47, 243.61 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36336/47780 [02:03<00:40, 284.68 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35150/47780 [02:03<00:57, 218.45 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36080/47780 [02:03<00:40, 285.83 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35764/47780 [02:03<00:45, 264.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35583/47780 [02:03<00:45, 265.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23876/47780 [02:03<01:23, 285.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36129/47780 [02:03<00:47, 243.24 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36521/47780 [02:03<00:46, 240.28 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35172/47780 [02:03<00:59, 211.72 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36109/47780 [02:03<00:45, 255.82 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36366/47780 [02:03<00:44, 254.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35791/47780 [02:03<00:48, 249.28 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35610/47780 [02:03<00:48, 252.26 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36551/47780 [02:03<00:44, 253.60 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35198/47780 [02:03<00:56, 222.52 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23907/47780 [02:03<01:29, 266.70 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36155/47780 [02:03<00:52, 221.68 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36393/47780 [02:03<00:44, 258.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36136/47780 [02:03<00:45, 256.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35817/47780 [02:03<00:48, 245.36 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36579/47780 [02:03<00:43, 257.98 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35639/47780 [02:03<00:47, 257.35 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35221/47780 [02:03<00:57, 219.54 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23943/47780 [02:03<01:23, 285.11 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36183/47780 [02:03<00:49, 234.08 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36420/47780 [02:03<00:44, 255.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36163/47780 [02:03<00:48, 241.78 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35842/47780 [02:03<00:50, 237.58 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35669/47780 [02:03<00:46, 257.73 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23974/47780 [02:03<01:22, 288.41 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36606/47780 [02:03<00:47, 237.59 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35248/47780 [02:03<00:55, 224.06 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36212/47780 [02:03<00:49, 235.33 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36447/47780 [02:03<00:43, 259.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36194/47780 [02:03<00:44, 259.73 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35869/47780 [02:03<00:48, 243.76 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35696/47780 [02:03<00:47, 255.17 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24014/47780 [02:03<01:16, 310.79 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36634/47780 [02:03<00:46, 241.15 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36242/47780 [02:03<00:45, 252.61 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35273/47780 [02:03<00:56, 223.24 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36223/47780 [02:03<00:43, 263.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36474/47780 [02:03<00:46, 241.64 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35894/47780 [02:03<00:50, 234.86 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35722/47780 [02:03<00:49, 245.46 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24050/47780 [02:03<01:13, 321.95 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36659/47780 [02:03<00:46, 241.31 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35302/47780 [02:03<00:53, 232.05 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36268/47780 [02:04<00:47, 241.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36499/47780 [02:03<00:46, 241.17 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36251/47780 [02:03<00:47, 240.28 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35918/47780 [02:04<00:51, 231.12 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24084/47780 [02:04<01:13, 323.39 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35752/47780 [02:04<00:47, 255.05 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35327/47780 [02:04<00:54, 229.50 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36293/47780 [02:04<00:48, 236.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36684/47780 [02:04<00:50, 221.20 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36525/47780 [02:04<00:50, 224.32 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35945/47780 [02:04<00:49, 239.44 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36276/47780 [02:04<00:52, 220.02 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24117/47780 [02:04<01:19, 297.74 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35778/47780 [02:04<00:52, 228.54 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36707/47780 [02:04<00:51, 216.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35350/47780 [02:04<00:57, 217.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36318/47780 [02:04<00:50, 225.00 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36549/47780 [02:04<00:52, 214.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35970/47780 [02:04<00:50, 233.65 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36300/47780 [02:04<00:52, 220.68 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24149/47780 [02:04<01:20, 294.74 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35802/47780 [02:04<00:52, 228.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36731/47780 [02:04<00:50, 218.51 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36341/47780 [02:04<00:53, 214.62 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35372/47780 [02:04<01:03, 196.91 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35995/47780 [02:04<00:49, 236.55 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36329/47780 [02:04<00:48, 236.24 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36571/47780 [02:04<00:55, 203.56 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24179/47780 [02:04<01:19, 295.84 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36754/47780 [02:04<00:52, 210.15 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35826/47780 [02:04<00:55, 213.78 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36367/47780 [02:04<00:51, 222.22 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35395/47780 [02:04<01:02, 199.29 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36354/47780 [02:04<00:47, 239.80 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36019/47780 [02:04<00:53, 219.82 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36593/47780 [02:04<00:55, 201.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24211/47780 [02:04<01:19, 296.19 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35848/47780 [02:04<00:56, 210.01 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36391/47780 [02:04<00:50, 224.62 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36776/47780 [02:04<00:53, 206.05 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35416/47780 [02:04<01:02, 197.67 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36619/47780 [02:04<00:51, 216.86 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36379/47780 [02:04<00:49, 232.55 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24244/47780 [02:04<01:19, 295.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36042/47780 [02:04<00:57, 203.33 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35875/47780 [02:04<00:52, 225.70 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36414/47780 [02:04<00:52, 216.07 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35436/47780 [02:04<01:02, 197.20 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36797/47780 [02:04<00:57, 192.44 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36643/47780 [02:04<00:50, 218.72 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36408/47780 [02:04<00:46, 245.68 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24276/47780 [02:04<01:18, 299.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36071/47780 [02:04<00:53, 220.83 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35902/47780 [02:04<00:50, 234.33 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36817/47780 [02:04<00:56, 194.36 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35456/47780 [02:04<01:06, 185.03 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36436/47780 [02:04<00:57, 197.94 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36438/47780 [02:04<00:43, 260.72 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24309/47780 [02:04<01:17, 304.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36666/47780 [02:04<00:54, 205.48 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36097/47780 [02:04<00:51, 228.88 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35936/47780 [02:04<00:45, 258.13 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36837/47780 [02:04<00:58, 185.95 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35476/47780 [02:04<01:06, 185.91 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36457/47780 [02:04<00:59, 188.98 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24349/47780 [02:04<01:10, 331.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36465/47780 [02:04<00:45, 247.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36687/47780 [02:04<00:54, 202.61 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36124/47780 [02:04<00:49, 235.01 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35963/47780 [02:04<00:45, 258.68 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35500/47780 [02:04<01:01, 199.71 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36857/47780 [02:04<00:58, 185.66 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36486/47780 [02:05<00:53, 211.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24383/47780 [02:05<01:11, 326.61 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36491/47780 [02:04<00:47, 239.33 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36710/47780 [02:05<00:53, 205.55 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36148/47780 [02:05<00:50, 231.34 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35990/47780 [02:05<00:48, 242.16 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36876/47780 [02:05<00:58, 184.91 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35526/47780 [02:05<00:59, 205.17 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24418/47780 [02:05<01:10, 329.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36517/47780 [02:05<00:48, 230.28 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36735/47780 [02:05<00:51, 213.19 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36172/47780 [02:05<00:49, 232.45 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36516/47780 [02:05<00:49, 229.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36020/47780 [02:05<00:45, 256.81 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36895/47780 [02:05<00:59, 182.27 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35552/47780 [02:05<00:55, 220.23 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24452/47780 [02:05<01:10, 328.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36541/47780 [02:05<00:49, 228.32 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36758/47780 [02:05<00:51, 215.52 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36196/47780 [02:05<00:50, 230.71 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36540/47780 [02:05<00:53, 209.74 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36047/47780 [02:05<00:47, 247.97 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36914/47780 [02:05<00:58, 184.37 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35575/47780 [02:05<00:55, 220.67 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24495/47780 [02:05<01:05, 353.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36566/47780 [02:05<00:47, 233.92 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36785/47780 [02:05<00:47, 230.71 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36220/47780 [02:05<00:50, 227.87 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36083/47780 [02:05<00:41, 278.73 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36937/47780 [02:05<00:54, 197.25 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35602/47780 [02:05<00:51, 234.65 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36563/47780 [02:05<00:57, 194.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24539/47780 [02:05<01:02, 374.72 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36590/47780 [02:05<00:48, 230.28 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36243/47780 [02:05<00:52, 218.51 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36809/47780 [02:05<00:51, 211.47 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36964/47780 [02:05<00:49, 217.27 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36112/47780 [02:05<00:45, 256.13 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24583/47780 [02:05<00:59, 391.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36586/47780 [02:05<00:56, 199.59 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35626/47780 [02:05<00:57, 211.74 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36617/47780 [02:05<00:47, 236.35 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36265/47780 [02:05<00:52, 218.76 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36831/47780 [02:05<00:53, 206.49 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36986/47780 [02:05<00:52, 207.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36139/47780 [02:05<00:46, 251.75 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36607/47780 [02:05<00:56, 196.30 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35648/47780 [02:05<00:59, 205.11 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24623/47780 [02:05<01:03, 362.18 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36641/47780 [02:05<00:49, 224.65 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36287/47780 [02:05<00:54, 209.96 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36853/47780 [02:05<00:52, 206.44 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37009/47780 [02:05<00:50, 211.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36165/47780 [02:05<00:46, 251.30 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24661/47780 [02:05<01:03, 363.11 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36665/47780 [02:05<00:48, 228.80 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36627/47780 [02:05<01:00, 185.21 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35670/47780 [02:05<00:59, 202.23 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36311/47780 [02:05<00:53, 213.55 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36874/47780 [02:05<00:55, 195.93 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36192/47780 [02:05<00:46, 250.87 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37031/47780 [02:05<00:56, 191.92 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35696/47780 [02:05<00:55, 217.42 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24698/47780 [02:05<01:05, 353.28 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36656/47780 [02:05<00:53, 206.47 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36337/47780 [02:05<00:51, 224.06 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36689/47780 [02:06<00:54, 202.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36902/47780 [02:05<00:50, 215.89 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37052/47780 [02:05<00:55, 194.86 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36218/47780 [02:05<00:47, 245.08 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36682/47780 [02:05<00:50, 220.62 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24734/47780 [02:05<01:08, 335.02 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36363/47780 [02:06<00:50, 226.62 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35719/47780 [02:05<00:59, 203.28 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36716/47780 [02:06<00:50, 219.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36924/47780 [02:06<00:51, 209.16 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37073/47780 [02:06<00:56, 188.38 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36243/47780 [02:06<00:50, 226.41 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36387/47780 [02:06<00:49, 229.13 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36705/47780 [02:06<00:53, 205.34 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24783/47780 [02:06<01:03, 362.83 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35740/47780 [02:06<01:00, 198.92 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36739/47780 [02:06<00:52, 210.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36946/47780 [02:06<00:52, 207.27 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37097/47780 [02:06<00:53, 198.12 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36268/47780 [02:06<00:51, 225.50 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24829/47780 [02:06<01:00, 381.92 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35764/47780 [02:06<00:58, 205.70 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36728/47780 [02:06<00:53, 205.23 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36410/47780 [02:06<00:52, 217.49 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36761/47780 [02:06<00:52, 209.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36967/47780 [02:06<00:52, 205.07 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37120/47780 [02:06<00:51, 206.83 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36291/47780 [02:06<00:51, 224.24 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35793/47780 [02:06<00:52, 228.77 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24868/47780 [02:06<01:01, 375.05 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36432/47780 [02:06<00:52, 216.44 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36749/47780 [02:06<00:55, 200.07 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36783/47780 [02:06<00:52, 207.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36988/47780 [02:06<00:54, 198.37 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37143/47780 [02:06<00:51, 206.19 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36316/47780 [02:06<00:50, 228.95 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35819/47780 [02:06<00:50, 234.90 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24915/47780 [02:06<00:58, 392.75 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36460/47780 [02:06<00:49, 226.71 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36770/47780 [02:06<00:54, 200.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37008/47780 [02:06<00:54, 198.81 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36805/47780 [02:06<00:54, 202.31 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37164/47780 [02:06<00:53, 198.45 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36340/47780 [02:06<00:51, 224.15 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35844/47780 [02:06<00:49, 239.18 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24955/47780 [02:06<00:59, 386.10 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36484/47780 [02:06<00:49, 227.92 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36792/47780 [02:06<00:55, 199.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37030/47780 [02:06<00:53, 200.34 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36828/47780 [02:06<00:53, 205.40 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37184/47780 [02:06<00:53, 198.81 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36363/47780 [02:06<00:52, 218.71 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24995/47780 [02:06<00:59, 385.56 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36510/47780 [02:06<00:48, 234.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36817/47780 [02:06<00:51, 211.08 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37051/47780 [02:06<00:53, 200.43 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35869/47780 [02:06<00:55, 212.78 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36849/47780 [02:06<00:54, 202.18 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37210/47780 [02:06<00:49, 214.02 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36390/47780 [02:06<00:50, 225.48 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25041/47780 [02:06<00:56, 402.25 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36844/47780 [02:06<00:49, 220.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36534/47780 [02:06<00:50, 220.92 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37075/47780 [02:06<00:51, 207.35 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35891/47780 [02:06<00:57, 208.17 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36871/47780 [02:06<00:53, 202.70 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37234/47780 [02:06<00:50, 209.35 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36417/47780 [02:06<00:47, 237.75 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25082/47780 [02:06<00:58, 386.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36868/47780 [02:06<00:48, 225.74 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36567/47780 [02:06<00:45, 245.58 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37099/47780 [02:06<00:49, 214.21 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35916/47780 [02:06<00:54, 218.32 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36900/47780 [02:06<00:48, 224.67 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36444/47780 [02:06<00:46, 244.22 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36891/47780 [02:06<00:48, 224.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37256/47780 [02:06<00:54, 192.98 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36602/47780 [02:06<00:40, 274.59 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37122/47780 [02:06<00:49, 216.26 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35939/47780 [02:06<00:54, 219.27 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25121/47780 [02:06<01:03, 355.65 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36923/47780 [02:07<00:50, 213.74 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36914/47780 [02:07<00:49, 221.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36469/47780 [02:07<00:50, 225.36 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37276/47780 [02:07<00:56, 186.89 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35962/47780 [02:07<00:54, 218.37 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36630/47780 [02:07<00:42, 261.39 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37144/47780 [02:07<00:51, 207.50 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36948/47780 [02:07<00:48, 223.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25158/47780 [02:07<01:08, 331.08 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37295/47780 [02:07<00:55, 187.58 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36939/47780 [02:07<00:50, 214.60 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35987/47780 [02:07<00:52, 224.67 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36659/47780 [02:07<00:42, 260.94 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36972/47780 [02:07<00:48, 223.59 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36492/47780 [02:07<00:55, 204.26 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37165/47780 [02:07<00:53, 197.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25193/47780 [02:07<01:07, 332.42 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37315/47780 [02:07<00:55, 189.09 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36961/47780 [02:07<00:52, 206.82 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36010/47780 [02:07<00:55, 211.30 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36513/47780 [02:07<00:56, 200.96 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36995/47780 [02:07<00:51, 210.75 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37186/47780 [02:07<00:58, 180.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36686/47780 [02:07<00:51, 217.24 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37335/47780 [02:07<00:55, 189.89 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25227/47780 [02:07<01:22, 274.44 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36984/47780 [02:07<00:51, 211.14 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36537/47780 [02:07<00:53, 211.05 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36033/47780 [02:07<00:55, 212.21 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37026/47780 [02:07<00:46, 230.73 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37205/47780 [02:07<00:58, 181.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36712/47780 [02:07<00:49, 223.53 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37360/47780 [02:07<00:52, 200.28 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25296/47780 [02:07<01:01, 368.15 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37012/47780 [02:07<00:47, 227.38 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36058/47780 [02:07<00:52, 222.60 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36564/47780 [02:07<00:50, 223.36 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37051/47780 [02:07<00:45, 233.24 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37224/47780 [02:07<00:58, 179.77 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36742/47780 [02:07<00:45, 242.39 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37385/47780 [02:07<00:50, 205.05 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37039/47780 [02:07<00:45, 234.37 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36086/47780 [02:07<00:49, 236.41 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25336/47780 [02:07<01:03, 354.39 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36587/47780 [02:07<00:51, 217.47 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37075/47780 [02:07<00:47, 227.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37247/47780 [02:07<00:55, 189.40 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36768/47780 [02:07<00:45, 242.64 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37409/47780 [02:07<00:48, 214.51 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36111/47780 [02:07<00:49, 237.40 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37063/47780 [02:07<00:46, 228.21 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36609/47780 [02:07<00:51, 217.52 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37102/47780 [02:07<00:44, 239.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37273/47780 [02:07<00:50, 206.78 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36794/47780 [02:07<00:45, 242.07 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25374/47780 [02:07<01:13, 304.78 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37436/47780 [02:07<00:45, 226.79 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37088/47780 [02:07<00:46, 229.12 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36136/47780 [02:07<00:49, 233.07 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36636/47780 [02:07<00:49, 223.41 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37294/47780 [02:07<00:51, 205.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37127/47780 [02:07<00:46, 226.72 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25419/47780 [02:07<01:06, 336.46 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37462/47780 [02:07<00:43, 234.87 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36822/47780 [02:07<00:47, 232.01 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37112/47780 [02:07<00:46, 227.84 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36162/47780 [02:07<00:49, 232.79 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36665/47780 [02:07<00:45, 242.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37325/47780 [02:07<00:44, 233.27 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37150/47780 [02:08<00:51, 207.28 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36850/47780 [02:08<00:44, 244.64 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25456/47780 [02:08<01:09, 319.07 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37486/47780 [02:08<00:47, 218.68 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37138/47780 [02:08<00:45, 236.17 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36186/47780 [02:08<00:50, 229.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36692/47780 [02:08<00:45, 244.02 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37172/47780 [02:08<00:51, 206.27 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37350/47780 [02:08<00:50, 208.29 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36875/47780 [02:08<00:45, 240.82 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37162/47780 [02:08<00:44, 237.11 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25491/47780 [02:08<01:10, 317.50 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37509/47780 [02:08<00:46, 219.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36717/47780 [02:08<00:45, 241.41 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36210/47780 [02:08<00:55, 208.73 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37380/47780 [02:08<00:44, 232.36 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37195/47780 [02:08<00:50, 210.39 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36904/47780 [02:08<00:42, 254.42 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37186/47780 [02:08<00:45, 235.24 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25526/47780 [02:08<01:08, 325.60 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36746/47780 [02:08<00:44, 246.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37532/47780 [02:08<00:50, 201.56 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36232/47780 [02:08<00:55, 209.70 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25581/47780 [02:08<00:58, 381.98 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37217/47780 [02:08<00:52, 200.57 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36930/47780 [02:08<00:47, 230.09 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37210/47780 [02:08<00:48, 218.84 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37405/47780 [02:08<00:50, 206.79 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37553/47780 [02:08<00:51, 200.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36258/47780 [02:08<00:52, 221.11 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36771/47780 [02:08<00:50, 219.89 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37239/47780 [02:08<00:51, 205.13 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25621/47780 [02:08<00:59, 370.30 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36956/47780 [02:08<00:45, 235.51 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37236/47780 [02:08<00:46, 227.83 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37430/47780 [02:08<00:47, 216.94 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37574/47780 [02:08<00:52, 195.99 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36282/47780 [02:08<00:55, 207.37 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36794/47780 [02:08<00:52, 209.28 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25659/47780 [02:08<00:59, 369.21 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37453/47780 [02:08<00:47, 218.08 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37260/47780 [02:08<00:56, 187.69 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36991/47780 [02:08<00:42, 255.71 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37608/47780 [02:08<00:43, 233.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37259/47780 [02:08<00:49, 210.71 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36816/47780 [02:08<00:51, 212.02 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36307/47780 [02:08<00:54, 212.40 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25697/47780 [02:08<01:00, 367.79 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37476/47780 [02:08<00:46, 219.70 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37288/47780 [02:08<00:50, 209.79 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37030/47780 [02:08<00:37, 286.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37635/47780 [02:08<00:42, 238.08 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37284/47780 [02:08<00:50, 206.80 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36849/47780 [02:08<00:45, 241.67 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36329/47780 [02:08<00:54, 209.96 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25736/47780 [02:08<01:00, 366.16 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37500/47780 [02:08<00:46, 219.58 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37310/47780 [02:08<00:51, 205.25 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37660/47780 [02:08<00:43, 233.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37059/47780 [02:08<00:40, 266.05 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37328/47780 [02:08<00:39, 265.72 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36351/47780 [02:08<00:53, 212.71 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36875/47780 [02:08<00:46, 236.87 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37526/47780 [02:08<00:44, 228.44 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37331/47780 [02:09<00:52, 200.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25773/47780 [02:08<01:06, 333.06 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37684/47780 [02:08<00:44, 227.69 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37088/47780 [02:08<00:42, 253.62 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36375/47780 [02:08<00:52, 218.95 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37356/47780 [02:08<00:41, 250.32 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36899/47780 [02:09<00:47, 227.03 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37551/47780 [02:09<00:45, 224.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37357/47780 [02:09<00:48, 214.63 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25808/47780 [02:09<01:07, 323.83 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37710/47780 [02:09<00:43, 229.21 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37114/47780 [02:09<00:42, 253.05 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37383/47780 [02:09<00:41, 253.05 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36398/47780 [02:09<00:53, 211.42 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36922/47780 [02:09<00:49, 218.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37382/47780 [02:09<00:46, 221.88 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25841/47780 [02:09<01:07, 325.26 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37574/47780 [02:09<00:50, 201.29 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37143/47780 [02:09<00:40, 263.06 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37412/47780 [02:09<00:39, 262.02 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36423/47780 [02:09<00:52, 217.40 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37734/47780 [02:09<00:47, 211.07 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36945/47780 [02:09<00:50, 216.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37405/47780 [02:09<00:47, 219.17 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25879/47780 [02:09<01:05, 333.36 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37170/47780 [02:09<00:41, 255.26 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37595/47780 [02:09<00:53, 191.33 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36452/47780 [02:09<00:49, 230.12 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36968/47780 [02:09<00:49, 218.19 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37439/47780 [02:09<00:43, 239.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37757/47780 [02:09<00:50, 199.02 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25918/47780 [02:09<01:03, 345.29 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37428/47780 [02:09<00:49, 210.26 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37201/47780 [02:09<00:39, 270.40 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37616/47780 [02:09<00:52, 192.45 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36990/47780 [02:09<00:49, 218.57 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36477/47780 [02:09<00:51, 220.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37778/47780 [02:09<00:51, 192.67 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25957/47780 [02:09<01:00, 357.76 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37464/47780 [02:09<00:47, 219.43 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37453/47780 [02:09<00:47, 219.13 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37230/47780 [02:09<00:38, 274.17 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37639/47780 [02:09<00:51, 197.31 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37012/47780 [02:09<00:49, 216.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36500/47780 [02:09<00:52, 216.16 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25995/47780 [02:09<01:00, 360.31 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37490/47780 [02:09<00:45, 223.76 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37799/47780 [02:09<00:54, 183.23 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37476/47780 [02:09<00:49, 208.10 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37259/47780 [02:09<00:38, 272.43 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37667/47780 [02:09<00:46, 218.27 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37035/47780 [02:09<00:49, 217.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36523/47780 [02:09<00:51, 216.62 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26033/47780 [02:09<00:59, 362.59 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37820/47780 [02:09<00:53, 186.90 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37514/47780 [02:09<00:47, 217.90 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37289/47780 [02:09<00:37, 279.83 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37499/47780 [02:09<00:49, 207.32 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37690/47780 [02:09<00:48, 209.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37057/47780 [02:09<00:50, 211.05 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26072/47780 [02:09<00:59, 365.47 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36545/47780 [02:09<00:55, 203.65 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37841/47780 [02:09<00:51, 192.44 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37537/47780 [02:09<00:46, 219.46 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37320/47780 [02:09<00:38, 269.92 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37520/47780 [02:09<00:52, 197.22 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37712/47780 [02:09<00:48, 207.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37079/47780 [02:09<00:53, 200.82 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26111/47780 [02:09<00:58, 368.31 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36566/47780 [02:09<00:56, 199.85 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37866/47780 [02:09<00:47, 208.14 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37561/47780 [02:09<00:45, 222.59 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37545/47780 [02:10<00:48, 211.51 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37733/47780 [02:09<00:49, 201.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37348/47780 [02:09<00:42, 243.07 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37100/47780 [02:09<00:53, 198.30 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26148/47780 [02:09<00:58, 368.68 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36589/47780 [02:09<00:54, 206.14 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37890/47780 [02:09<00:45, 216.97 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37567/47780 [02:10<00:49, 206.96 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37585/47780 [02:09<00:50, 202.79 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37755/47780 [02:10<00:49, 202.77 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37122/47780 [02:10<00:52, 201.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37373/47780 [02:10<00:44, 235.02 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26188/47780 [02:10<00:58, 369.36 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37917/47780 [02:10<00:42, 229.69 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36610/47780 [02:10<00:56, 196.24 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37613/47780 [02:10<00:46, 220.89 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37592/47780 [02:10<00:47, 213.98 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37776/47780 [02:10<00:51, 195.93 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37397/47780 [02:10<00:44, 231.56 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26234/47780 [02:10<00:55, 387.36 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37143/47780 [02:10<00:54, 196.25 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37944/47780 [02:10<00:41, 235.17 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36630/47780 [02:10<00:56, 196.99 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37636/47780 [02:10<00:46, 218.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37614/47780 [02:10<00:50, 199.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37798/47780 [02:10<00:49, 200.46 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37163/47780 [02:10<00:54, 196.53 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37427/47780 [02:10<00:42, 243.91 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37968/47780 [02:10<00:42, 232.03 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36650/47780 [02:10<00:58, 188.95 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26274/47780 [02:10<01:02, 342.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37665/47780 [02:10<00:42, 235.49 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37184/47780 [02:10<00:53, 198.35 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37636/47780 [02:10<00:52, 193.22 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37819/47780 [02:10<00:50, 196.40 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37457/47780 [02:10<00:40, 254.59 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37996/47780 [02:10<00:39, 245.53 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36674/47780 [02:10<00:55, 201.89 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26322/47780 [02:10<00:57, 371.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37689/47780 [02:10<00:43, 231.59 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37483/47780 [02:10<00:40, 253.38 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37659/47780 [02:10<00:52, 192.72 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37839/47780 [02:10<00:53, 186.96 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37204/47780 [02:10<00:56, 185.85 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36695/47780 [02:10<00:54, 203.06 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26362/47780 [02:10<00:57, 375.25 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38021/47780 [02:10<00:44, 217.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37716/47780 [02:10<00:42, 237.06 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37515/47780 [02:10<00:37, 271.04 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37862/47780 [02:10<00:49, 198.67 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37689/47780 [02:10<00:46, 219.25 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37224/47780 [02:10<00:56, 187.69 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36716/47780 [02:10<00:54, 203.64 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26418/47780 [02:10<00:50, 421.63 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38044/47780 [02:10<00:45, 211.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37747/47780 [02:10<00:39, 252.01 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37543/47780 [02:10<00:38, 262.60 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37250/47780 [02:10<00:50, 206.83 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37886/47780 [02:10<00:47, 206.70 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37712/47780 [02:10<00:46, 214.73 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36741/47780 [02:10<00:50, 216.89 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26461/47780 [02:10<00:50, 423.97 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38066/47780 [02:10<00:46, 208.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37773/47780 [02:10<00:40, 245.92 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37273/47780 [02:10<00:50, 209.45 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37570/47780 [02:10<00:39, 256.13 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36767/47780 [02:10<00:48, 226.91 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37907/47780 [02:10<00:50, 193.69 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37734/47780 [02:10<00:49, 202.62 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26504/47780 [02:10<00:53, 394.19 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38091/47780 [02:10<00:44, 217.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37799/47780 [02:10<00:40, 247.17 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37295/47780 [02:10<00:49, 210.56 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36791/47780 [02:10<00:48, 228.02 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37936/47780 [02:10<00:45, 217.63 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37755/47780 [02:11<00:49, 200.52 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37596/47780 [02:10<00:43, 233.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38117/47780 [02:10<00:44, 219.55 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26545/47780 [02:11<00:56, 373.66 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37824/47780 [02:10<00:43, 229.62 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37322/47780 [02:11<00:45, 227.61 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36822/47780 [02:11<00:44, 249.02 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37959/47780 [02:11<00:46, 210.51 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37623/47780 [02:11<00:42, 240.71 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37777/47780 [02:11<00:50, 197.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38142/47780 [02:11<00:42, 225.53 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37850/47780 [02:11<00:42, 232.81 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37348/47780 [02:11<00:44, 235.16 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26583/47780 [02:11<01:02, 341.65 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36849/47780 [02:11<00:43, 252.26 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37799/47780 [02:11<00:49, 203.34 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37648/47780 [02:11<00:43, 235.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37981/47780 [02:11<00:48, 200.80 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38165/47780 [02:11<00:44, 217.13 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37875/47780 [02:11<00:42, 234.93 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37380/47780 [02:11<00:41, 253.18 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36875/47780 [02:11<00:43, 251.50 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26618/47780 [02:11<01:04, 330.37 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37820/47780 [02:11<00:50, 198.60 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38022/47780 [02:11<00:37, 256.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37673/47780 [02:11<00:44, 227.05 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38195/47780 [02:11<00:42, 225.00 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37906/47780 [02:11<00:39, 250.40 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37412/47780 [02:11<00:38, 270.95 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36905/47780 [02:11<00:41, 262.66 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26661/47780 [02:11<01:01, 345.96 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38051/47780 [02:11<00:37, 262.06 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37849/47780 [02:11<00:45, 216.80 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37704/47780 [02:11<00:41, 244.63 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37939/47780 [02:11<00:36, 269.89 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37441/47780 [02:11<00:38, 268.75 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36933/47780 [02:11<00:41, 261.71 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38228/47780 [02:11<00:40, 237.90 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26697/47780 [02:11<01:04, 328.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38078/47780 [02:11<00:37, 260.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37730/47780 [02:11<00:40, 245.82 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37872/47780 [02:11<00:47, 208.79 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37980/47780 [02:11<00:31, 306.27 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36962/47780 [02:11<00:40, 269.80 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38253/47780 [02:11<00:39, 238.44 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37468/47780 [02:11<00:42, 243.63 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26744/47780 [02:11<00:58, 362.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37759/47780 [02:11<00:39, 255.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37896/47780 [02:11<00:46, 213.39 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38105/47780 [02:11<00:40, 241.34 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38015/47780 [02:11<00:31, 311.62 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36990/47780 [02:11<00:40, 266.49 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38279/47780 [02:11<00:39, 241.86 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26793/47780 [02:11<00:53, 392.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37493/47780 [02:11<00:43, 234.64 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37785/47780 [02:11<00:40, 248.00 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37923/47780 [02:11<00:43, 224.32 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38133/47780 [02:11<00:39, 246.49 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38049/47780 [02:11<00:31, 308.54 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26840/47780 [02:11<00:51, 409.64 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37017/47780 [02:11<00:44, 242.15 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38304/47780 [02:11<00:42, 223.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37517/47780 [02:11<00:44, 229.08 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37949/47780 [02:11<00:42, 233.38 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37812/47780 [02:11<00:39, 251.61 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38160/47780 [02:11<00:38, 252.84 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38080/47780 [02:11<00:32, 300.42 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37044/47780 [02:11<00:43, 249.02 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38336/47780 [02:11<00:38, 247.40 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26882/47780 [02:11<00:53, 387.54 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37541/47780 [02:11<00:45, 224.24 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37976/47780 [02:12<00:40, 243.79 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37848/47780 [02:11<00:35, 279.23 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38191/47780 [02:11<00:36, 266.07 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38363/47780 [02:11<00:37, 253.53 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26924/47780 [02:12<00:52, 396.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37070/47780 [02:12<00:46, 229.52 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37565/47780 [02:12<00:46, 221.89 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38219/47780 [02:12<00:35, 267.00 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38111/47780 [02:12<00:38, 253.40 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37877/47780 [02:12<00:36, 273.02 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38001/47780 [02:12<00:43, 224.53 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38390/47780 [02:12<00:36, 257.94 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26965/47780 [02:12<00:52, 398.98 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37101/47780 [02:12<00:43, 248.30 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37588/47780 [02:12<00:46, 219.01 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38150/47780 [02:12<00:34, 279.61 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38246/47780 [02:12<00:38, 245.08 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38024/47780 [02:12<00:44, 218.80 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37905/47780 [02:12<00:38, 253.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38417/47780 [02:12<00:39, 237.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37137/47780 [02:12<00:38, 274.56 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37610/47780 [02:12<00:47, 212.63 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27006/47780 [02:12<00:57, 363.62 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38180/47780 [02:12<00:35, 268.35 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38271/47780 [02:12<00:39, 243.57 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38047/47780 [02:12<00:45, 212.55 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37931/47780 [02:12<00:40, 240.70 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38449/47780 [02:12<00:36, 258.10 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37165/47780 [02:12<00:38, 274.22 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37632/47780 [02:12<00:47, 212.34 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27053/47780 [02:12<00:53, 389.22 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38296/47780 [02:12<00:39, 237.86 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38208/47780 [02:12<00:36, 260.60 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38069/47780 [02:12<00:48, 201.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37956/47780 [02:12<00:44, 220.04 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37196/47780 [02:12<00:38, 272.50 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37658/47780 [02:12<00:45, 223.19 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27093/47780 [02:12<00:54, 382.95 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38320/47780 [02:12<00:40, 235.12 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38476/47780 [02:12<00:41, 226.60 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38237/47780 [02:12<00:35, 265.40 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38090/47780 [02:12<00:48, 201.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37979/47780 [02:12<00:44, 220.45 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37224/47780 [02:12<00:39, 268.61 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27135/47780 [02:12<00:54, 381.21 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37684/47780 [02:12<00:45, 222.24 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38349/47780 [02:12<00:37, 248.48 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38264/47780 [02:12<00:36, 263.43 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38501/47780 [02:12<00:40, 228.06 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38113/47780 [02:12<00:47, 204.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38008/47780 [02:12<00:40, 238.82 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37252/47780 [02:12<00:39, 265.93 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27174/47780 [02:12<00:54, 381.31 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37709/47780 [02:12<00:44, 226.22 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38384/47780 [02:12<00:33, 277.27 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38531/47780 [02:12<00:37, 245.25 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38291/47780 [02:12<00:36, 257.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38139/47780 [02:12<00:44, 218.29 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38033/47780 [02:12<00:42, 230.98 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27222/47780 [02:12<00:51, 402.78 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37279/47780 [02:12<00:41, 255.45 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38416/47780 [02:12<00:32, 286.55 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37741/47780 [02:12<00:41, 244.36 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38557/47780 [02:12<00:37, 247.57 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38321/47780 [02:12<00:35, 263.10 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38161/47780 [02:12<00:44, 216.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38057/47780 [02:12<00:41, 233.19 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37307/47780 [02:12<00:40, 259.31 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38445/47780 [02:12<00:32, 284.33 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27263/47780 [02:12<00:53, 387.09 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38594/47780 [02:12<00:32, 280.60 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37775/47780 [02:12<00:38, 262.41 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38351/47780 [02:12<00:34, 273.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38202/47780 [02:13<00:35, 269.95 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38081/47780 [02:13<00:43, 223.77 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37334/47780 [02:12<00:39, 261.80 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38475/47780 [02:13<00:32, 288.83 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27314/47780 [02:13<00:49, 417.53 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37802/47780 [02:13<00:38, 261.39 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38623/47780 [02:13<00:33, 273.82 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38381/47780 [02:12<00:33, 280.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38230/47780 [02:13<00:35, 268.20 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38113/47780 [02:13<00:39, 244.16 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37362/47780 [02:13<00:40, 258.77 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27365/47780 [02:13<00:46, 443.14 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38504/47780 [02:13<00:32, 285.41 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38411/47780 [02:13<00:32, 284.85 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37829/47780 [02:13<00:38, 258.14 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38655/47780 [02:13<00:32, 282.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38258/47780 [02:13<00:35, 267.58 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38139/47780 [02:13<00:40, 239.66 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27411/47780 [02:13<00:45, 442.93 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37390/47780 [02:13<00:39, 261.85 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38538/47780 [02:13<00:31, 294.91 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37864/47780 [02:13<00:35, 281.02 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38448/47780 [02:13<00:30, 304.39 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38684/47780 [02:13<00:32, 276.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38286/47780 [02:13<00:36, 260.17 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37421/47780 [02:13<00:37, 275.57 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38568/47780 [02:13<00:32, 286.05 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38479/47780 [02:13<00:31, 292.49 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38712/47780 [02:13<00:33, 267.98 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38164/47780 [02:13<00:46, 208.06 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37893/47780 [02:13<00:37, 260.58 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27456/47780 [02:13<00:52, 386.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38313/47780 [02:13<00:36, 256.97 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38597/47780 [02:13<00:32, 280.59 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38741/47780 [02:13<00:33, 271.51 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38513/47780 [02:13<00:31, 295.75 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37449/47780 [02:13<00:42, 243.09 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38192/47780 [02:13<00:42, 223.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27511/47780 [02:13<00:47, 425.41 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37921/47780 [02:13<00:40, 243.55 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38340/47780 [02:13<00:39, 241.11 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38628/47780 [02:13<00:32, 279.87 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38769/47780 [02:13<00:33, 267.88 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38546/47780 [02:13<00:30, 302.10 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37490/47780 [02:13<00:35, 287.55 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27555/47780 [02:13<00:47, 428.69 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37946/47780 [02:13<00:41, 235.66 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38369/47780 [02:13<00:38, 246.93 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38216/47780 [02:13<00:47, 201.26 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38657/47780 [02:13<00:33, 270.53 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37520/47780 [02:13<00:35, 287.87 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38577/47780 [02:13<00:31, 294.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38796/47780 [02:13<00:34, 256.82 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27599/47780 [02:13<00:51, 392.69 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38395/47780 [02:13<00:37, 250.36 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37972/47780 [02:13<00:41, 236.88 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38237/47780 [02:13<00:47, 201.43 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38685/47780 [02:13<00:34, 267.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38822/47780 [02:13<00:35, 254.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38607/47780 [02:13<00:32, 284.12 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37550/47780 [02:13<00:39, 256.48 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38260/47780 [02:13<00:46, 206.92 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38423/47780 [02:13<00:37, 250.29 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27640/47780 [02:13<00:54, 369.89 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37999/47780 [02:13<00:42, 230.92 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38848/47780 [02:13<00:35, 253.27 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38636/47780 [02:13<00:32, 284.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38713/47780 [02:13<00:35, 253.73 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38454/47780 [02:14<00:35, 266.08 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37577/47780 [02:13<00:41, 246.88 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38282/47780 [02:13<00:47, 199.67 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27678/47780 [02:13<00:56, 357.74 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38028/47780 [02:13<00:40, 239.11 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38669/47780 [02:13<00:30, 294.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38741/47780 [02:14<00:35, 258.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38874/47780 [02:13<00:36, 244.07 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37603/47780 [02:14<00:41, 248.03 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38307/47780 [02:14<00:44, 210.79 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27715/47780 [02:14<00:56, 357.05 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38055/47780 [02:14<00:40, 242.21 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38481/47780 [02:14<00:38, 240.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38701/47780 [02:14<00:30, 298.03 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38767/47780 [02:14<00:36, 250.19 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38899/47780 [02:14<00:39, 225.58 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37632/47780 [02:14<00:39, 256.75 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38329/47780 [02:14<00:46, 204.52 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38082/47780 [02:14<00:39, 247.12 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38506/47780 [02:14<00:39, 233.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27752/47780 [02:14<00:59, 335.15 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38795/47780 [02:14<00:34, 258.26 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38731/47780 [02:14<00:32, 282.11 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38923/47780 [02:14<00:38, 229.06 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37662/47780 [02:14<00:37, 268.61 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38357/47780 [02:14<00:42, 222.55 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38108/47780 [02:14<00:39, 247.92 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38532/47780 [02:14<00:39, 232.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27787/47780 [02:14<01:01, 324.80 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38823/47780 [02:14<00:34, 261.74 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38769/47780 [02:14<00:30, 299.84 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38959/47780 [02:14<00:33, 263.05 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37704/47780 [02:14<00:32, 308.03 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38385/47780 [02:14<00:39, 238.54 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38140/47780 [02:14<00:35, 268.05 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38561/47780 [02:14<00:37, 248.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27821/47780 [02:14<01:01, 325.85 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38865/47780 [02:14<00:29, 301.14 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38805/47780 [02:14<00:28, 309.66 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38986/47780 [02:14<00:34, 252.94 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37743/47780 [02:14<00:31, 320.42 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38410/47780 [02:14<00:39, 234.69 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38167/47780 [02:14<00:36, 260.04 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38587/47780 [02:14<00:36, 248.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27855/47780 [02:14<01:01, 322.55 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38896/47780 [02:14<00:29, 302.30 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38837/47780 [02:14<00:30, 295.42 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39033/47780 [02:14<00:28, 308.35 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38437/47780 [02:14<00:38, 241.11 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37776/47780 [02:14<00:33, 300.85 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38198/47780 [02:14<00:35, 271.54 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38613/47780 [02:14<00:37, 243.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27891/47780 [02:14<01:00, 329.40 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38927/47780 [02:14<00:30, 294.70 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38867/47780 [02:14<00:30, 291.91 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39067/47780 [02:14<00:29, 292.90 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38462/47780 [02:14<00:39, 237.74 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37807/47780 [02:14<00:34, 292.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38227/47780 [02:14<00:37, 253.22 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38638/47780 [02:14<00:39, 229.85 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38961/47780 [02:14<00:28, 307.46 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27926/47780 [02:14<01:03, 313.46 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38897/47780 [02:14<00:31, 283.60 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38491/47780 [02:14<00:36, 252.24 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39100/47780 [02:14<00:29, 293.46 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37837/47780 [02:14<00:35, 282.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38263/47780 [02:14<00:34, 279.10 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38662/47780 [02:14<00:39, 230.38 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38992/47780 [02:14<00:28, 308.15 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27965/47780 [02:14<00:59, 331.32 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38926/47780 [02:14<00:31, 280.79 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39130/47780 [02:14<00:30, 282.93 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38518/47780 [02:14<00:38, 238.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37869/47780 [02:14<00:34, 289.22 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38294/47780 [02:14<00:33, 281.10 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38692/47780 [02:15<00:36, 249.67 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39023/47780 [02:14<00:29, 294.52 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27999/47780 [02:14<01:04, 306.42 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38959/47780 [02:14<00:30, 291.33 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37899/47780 [02:15<00:33, 292.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38547/47780 [02:15<00:37, 247.63 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38329/47780 [02:15<00:31, 297.49 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39159/47780 [02:15<00:32, 266.94 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39054/47780 [02:15<00:29, 298.85 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38718/47780 [02:15<00:38, 234.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38991/47780 [02:15<00:29, 294.43 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38573/47780 [02:15<00:37, 245.59 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37929/47780 [02:15<00:35, 275.80 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38361/47780 [02:15<00:31, 297.14 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39189/47780 [02:15<00:32, 264.36 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39085/47780 [02:15<00:29, 292.61 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38743/47780 [02:15<00:38, 234.99 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28031/47780 [02:15<01:20, 246.72 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39021/47780 [02:15<00:31, 274.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38598/47780 [02:15<00:37, 246.72 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39216/47780 [02:15<00:32, 260.83 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38392/47780 [02:15<00:33, 280.91 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37957/47780 [02:15<00:38, 256.90 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28086/47780 [02:15<01:03, 311.51 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38767/47780 [02:15<00:39, 227.10 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39116/47780 [02:15<00:32, 268.36 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39056/47780 [02:15<00:29, 291.77 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38628/47780 [02:15<00:35, 259.11 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39243/47780 [02:15<00:32, 262.99 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38422/47780 [02:15<00:33, 280.71 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28122/47780 [02:15<01:00, 323.33 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37986/47780 [02:15<00:38, 255.12 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38790/47780 [02:15<00:40, 222.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39144/47780 [02:15<00:32, 267.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38661/47780 [02:15<00:33, 274.32 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39086/47780 [02:15<00:33, 261.80 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38813/47780 [02:15<00:40, 223.67 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38023/47780 [02:15<00:34, 279.83 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38451/47780 [02:15<00:35, 262.32 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39270/47780 [02:15<00:35, 238.38 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39172/47780 [02:15<00:32, 264.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28158/47780 [02:15<01:06, 296.17 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38695/47780 [02:15<00:31, 288.76 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39113/47780 [02:15<00:34, 248.39 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38836/47780 [02:15<00:41, 216.94 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38054/47780 [02:15<00:35, 276.04 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38478/47780 [02:15<00:36, 256.60 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39297/47780 [02:15<00:35, 237.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39204/47780 [02:15<00:30, 277.24 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38726/47780 [02:15<00:31, 291.57 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39142/47780 [02:15<00:34, 251.35 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28190/47780 [02:15<01:19, 245.86 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38509/47780 [02:15<00:34, 268.24 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38088/47780 [02:15<00:33, 287.16 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39324/47780 [02:15<00:34, 245.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38859/47780 [02:15<00:42, 210.88 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39232/47780 [02:15<00:34, 249.57 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38756/47780 [02:15<00:34, 263.31 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39168/47780 [02:15<00:34, 250.96 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28297/47780 [02:15<00:45, 430.47 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38120/47780 [02:15<00:32, 292.99 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39353/47780 [02:15<00:33, 252.24 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38881/47780 [02:15<00:43, 204.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38537/47780 [02:15<00:37, 249.32 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39262/47780 [02:15<00:32, 260.48 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38783/47780 [02:15<00:34, 257.94 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39194/47780 [02:15<00:34, 248.05 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38152/47780 [02:15<00:32, 293.84 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28348/47780 [02:15<00:45, 425.21 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38905/47780 [02:16<00:41, 212.09 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39379/47780 [02:15<00:34, 241.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38563/47780 [02:15<00:36, 249.55 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39289/47780 [02:16<00:34, 244.07 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38810/47780 [02:16<00:35, 249.27 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38928/47780 [02:16<00:41, 212.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38182/47780 [02:16<00:34, 277.09 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28398/47780 [02:16<00:45, 422.10 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39405/47780 [02:16<00:36, 231.10 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39219/47780 [02:16<00:40, 213.36 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38589/47780 [02:16<00:39, 232.06 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38836/47780 [02:16<00:35, 252.13 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39314/47780 [02:16<00:37, 224.59 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38955/47780 [02:16<00:38, 228.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38216/47780 [02:16<00:33, 287.61 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39432/47780 [02:16<00:36, 231.52 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39256/47780 [02:16<00:34, 245.42 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38614/47780 [02:16<00:40, 227.05 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28445/47780 [02:16<00:50, 383.90 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38863/47780 [02:16<00:35, 254.46 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39350/47780 [02:16<00:33, 253.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38979/47780 [02:16<00:38, 229.09 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38246/47780 [02:16<00:33, 281.97 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39464/47780 [02:16<00:32, 254.54 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39282/47780 [02:16<00:34, 244.25 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38644/47780 [02:16<00:37, 244.14 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38891/47780 [02:16<00:33, 261.50 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28487/47780 [02:16<00:50, 378.62 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39377/47780 [02:16<00:32, 255.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39008/47780 [02:16<00:35, 246.13 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38275/47780 [02:16<00:34, 278.00 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39490/47780 [02:16<00:32, 253.94 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38688/47780 [02:16<00:30, 297.60 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39308/47780 [02:16<00:37, 223.99 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38918/47780 [02:16<00:36, 245.89 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28527/47780 [02:16<00:53, 362.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39036/47780 [02:16<00:34, 250.70 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38303/47780 [02:16<00:35, 266.74 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39404/47780 [02:16<00:37, 223.25 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39516/47780 [02:16<00:35, 233.19 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38719/47780 [02:16<00:33, 272.98 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28565/47780 [02:16<00:52, 366.35 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38943/47780 [02:16<00:36, 242.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39065/47780 [02:16<00:33, 259.29 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39430/47780 [02:16<00:36, 227.63 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38330/47780 [02:16<00:36, 256.31 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39554/47780 [02:16<00:30, 268.52 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39332/47780 [02:16<00:46, 182.03 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38748/47780 [02:16<00:33, 266.62 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28603/47780 [02:16<00:54, 351.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38968/47780 [02:16<00:37, 234.07 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39091/47780 [02:16<00:35, 244.90 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38356/47780 [02:16<00:37, 249.14 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39454/47780 [02:16<00:37, 221.87 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39582/47780 [02:16<00:31, 263.01 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39352/47780 [02:16<00:47, 178.05 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28641/47780 [02:16<00:53, 359.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38776/47780 [02:16<00:35, 256.34 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39116/47780 [02:16<00:35, 243.85 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38992/47780 [02:16<00:40, 215.02 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38383/47780 [02:16<00:36, 254.81 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39477/47780 [02:16<00:38, 217.92 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39609/47780 [02:16<00:31, 259.22 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39425/47780 [02:16<00:27, 302.39 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28679/47780 [02:16<00:53, 358.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38810/47780 [02:16<00:32, 275.63 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39141/47780 [02:17<00:35, 240.17 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38412/47780 [02:16<00:35, 264.70 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39015/47780 [02:16<00:41, 211.60 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39503/47780 [02:16<00:36, 228.28 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39636/47780 [02:16<00:31, 261.21 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39459/47780 [02:16<00:27, 299.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28721/47780 [02:16<00:51, 373.00 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38839/47780 [02:17<00:33, 270.64 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39166/47780 [02:17<00:37, 232.03 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39039/47780 [02:17<00:40, 217.16 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38441/47780 [02:17<00:34, 271.89 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39527/47780 [02:17<00:36, 226.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39663/47780 [02:17<00:31, 257.69 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28771/47780 [02:17<00:47, 400.81 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38867/47780 [02:17<00:33, 264.71 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39493/47780 [02:17<00:28, 286.81 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39191/47780 [02:17<00:37, 226.28 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39061/47780 [02:17<00:41, 210.75 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38470/47780 [02:17<00:34, 267.75 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39553/47780 [02:17<00:36, 227.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39689/47780 [02:17<00:32, 248.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28817/47780 [02:17<00:45, 417.30 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39524/47780 [02:17<00:28, 286.92 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39216/47780 [02:17<00:37, 231.32 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38894/47780 [02:17<00:36, 246.72 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39088/47780 [02:17<00:39, 221.10 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38497/47780 [02:17<00:36, 251.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39715/47780 [02:17<00:32, 248.73 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39576/47780 [02:17<00:40, 201.73 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39243/47780 [02:17<00:35, 242.12 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38922/47780 [02:17<00:34, 253.38 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39554/47780 [02:17<00:30, 273.22 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39118/47780 [02:17<00:35, 241.77 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28861/47780 [02:17<00:52, 361.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38523/47780 [02:17<00:38, 240.39 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39616/47780 [02:17<00:33, 245.79 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39740/47780 [02:17<00:35, 223.54 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39270/47780 [02:17<00:34, 244.37 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28917/47780 [02:17<00:46, 405.01 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39583/47780 [02:17<00:30, 268.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38551/47780 [02:17<00:37, 249.16 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39143/47780 [02:17<00:41, 210.61 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38948/47780 [02:17<00:41, 213.11 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39771/47780 [02:17<00:33, 241.66 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39300/47780 [02:17<00:32, 260.27 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39642/47780 [02:17<00:36, 225.93 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28962/47780 [02:17<00:46, 408.37 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38580/47780 [02:17<00:35, 259.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39611/47780 [02:17<00:32, 253.33 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39169/47780 [02:17<00:38, 220.97 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38981/47780 [02:17<00:37, 234.87 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39803/47780 [02:17<00:30, 262.91 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39328/47780 [02:17<00:32, 263.14 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39672/47780 [02:17<00:33, 241.76 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38608/47780 [02:17<00:34, 263.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39637/47780 [02:17<00:32, 252.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29004/47780 [02:17<00:50, 369.56 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39199/47780 [02:17<00:36, 234.91 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39013/47780 [02:17<00:34, 256.34 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39364/47780 [02:17<00:29, 287.88 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39830/47780 [02:17<00:31, 250.65 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39697/47780 [02:17<00:34, 236.59 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38641/47780 [02:17<00:32, 281.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39671/47780 [02:17<00:29, 273.02 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29044/47780 [02:17<00:50, 371.07 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39226/47780 [02:17<00:35, 244.34 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39044/47780 [02:17<00:32, 268.12 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39865/47780 [02:17<00:29, 272.22 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39394/47780 [02:17<00:30, 278.49 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39722/47780 [02:17<00:34, 230.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38676/47780 [02:17<00:30, 297.95 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39699/47780 [02:17<00:31, 255.28 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39072/47780 [02:17<00:32, 270.84 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39252/47780 [02:17<00:35, 243.33 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29083/47780 [02:17<00:53, 346.66 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39893/47780 [02:17<00:29, 268.23 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39429/47780 [02:18<00:28, 295.40 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38706/47780 [02:17<00:30, 297.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39755/47780 [02:18<00:32, 246.70 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39725/47780 [02:17<00:31, 256.53 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39277/47780 [02:18<00:34, 245.17 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39100/47780 [02:18<00:33, 259.46 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29132/47780 [02:18<00:49, 380.18 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39928/47780 [02:18<00:27, 288.07 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39461/47780 [02:18<00:28, 292.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39780/47780 [02:18<00:32, 245.05 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38736/47780 [02:18<00:33, 272.96 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39751/47780 [02:18<00:32, 246.04 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39304/47780 [02:18<00:34, 243.77 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29177/47780 [02:18<00:46, 398.63 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39958/47780 [02:18<00:27, 281.80 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39127/47780 [02:18<00:36, 235.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39503/47780 [02:18<00:26, 317.82 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39806/47780 [02:18<00:34, 233.64 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38764/47780 [02:18<00:34, 264.96 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39778/47780 [02:18<00:31, 250.42 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29218/47780 [02:18<00:46, 396.69 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39329/47780 [02:18<00:37, 225.29 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39156/47780 [02:18<00:34, 247.78 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39535/47780 [02:18<00:26, 307.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39988/47780 [02:18<00:29, 263.33 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38794/47780 [02:18<00:32, 273.29 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39830/47780 [02:18<00:34, 228.04 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39804/47780 [02:18<00:31, 250.14 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29270/47780 [02:18<00:43, 426.42 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39355/47780 [02:18<00:35, 234.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40015/47780 [02:18<00:29, 262.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39567/47780 [02:18<00:27, 298.02 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39854/47780 [02:18<00:34, 231.21 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39830/47780 [02:18<00:31, 250.27 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39182/47780 [02:18<00:40, 214.16 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38822/47780 [02:18<00:33, 265.78 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29318/47780 [02:18<00:42, 437.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39385/47780 [02:18<00:34, 244.70 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40042/47780 [02:18<00:30, 252.08 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39597/47780 [02:18<00:29, 279.96 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39856/47780 [02:18<00:31, 249.35 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39878/47780 [02:18<00:34, 226.14 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39224/47780 [02:18<00:32, 262.40 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29364/47780 [02:18<00:41, 439.47 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38849/47780 [02:18<00:34, 258.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39410/47780 [02:18<00:34, 245.70 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40068/47780 [02:18<00:30, 249.85 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39626/47780 [02:18<00:29, 277.79 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39903/47780 [02:18<00:33, 232.67 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39252/47780 [02:18<00:32, 264.34 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39882/47780 [02:18<00:31, 247.36 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38875/47780 [02:18<00:38, 232.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39435/47780 [02:18<00:35, 232.24 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29409/47780 [02:18<00:51, 358.92 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40096/47780 [02:18<00:30, 249.98 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39280/47780 [02:18<00:32, 262.75 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39654/47780 [02:18<00:31, 260.18 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39927/47780 [02:18<00:36, 217.46 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39907/47780 [02:18<00:34, 229.92 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38901/47780 [02:18<00:37, 235.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39459/47780 [02:18<00:37, 219.04 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29501/47780 [02:18<00:36, 499.32 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40124/47780 [02:18<00:29, 255.29 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39310/47780 [02:18<00:31, 272.90 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39682/47780 [02:18<00:30, 265.48 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39938/47780 [02:18<00:31, 251.93 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39949/47780 [02:18<00:37, 208.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38929/47780 [02:18<00:35, 247.48 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39486/47780 [02:18<00:36, 225.61 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40151/47780 [02:18<00:30, 253.82 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29556/47780 [02:18<00:37, 479.71 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39338/47780 [02:19<00:32, 263.51 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39964/47780 [02:18<00:31, 250.75 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39709/47780 [02:19<00:32, 250.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39971/47780 [02:19<00:39, 199.07 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38955/47780 [02:19<00:38, 230.06 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39510/47780 [02:19<00:37, 218.00 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29609/47780 [02:19<00:36, 491.29 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40177/47780 [02:19<00:31, 239.16 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39371/47780 [02:19<00:30, 275.40 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39991/47780 [02:19<00:30, 253.07 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39737/47780 [02:19<00:31, 256.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39996/47780 [02:19<00:36, 210.51 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38981/47780 [02:19<00:37, 236.26 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39535/47780 [02:19<00:37, 221.46 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40205/47780 [02:19<00:30, 247.98 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29662/47780 [02:19<00:38, 471.27 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39399/47780 [02:19<00:30, 270.39 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40017/47780 [02:19<00:32, 236.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39763/47780 [02:19<00:34, 232.95 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40018/47780 [02:19<00:38, 199.97 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39007/47780 [02:19<00:36, 239.76 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39558/47780 [02:19<00:37, 221.08 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29712/47780 [02:19<00:38, 473.99 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39427/47780 [02:19<00:30, 272.65 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40230/47780 [02:19<00:31, 240.01 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40041/47780 [02:19<00:32, 235.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39788/47780 [02:19<00:34, 235.01 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39037/47780 [02:19<00:34, 256.54 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40039/47780 [02:19<00:38, 200.56 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39585/47780 [02:19<00:35, 232.49 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40262/47780 [02:19<00:28, 260.21 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29787/47780 [02:19<00:33, 533.66 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39455/47780 [02:19<00:31, 266.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40065/47780 [02:19<00:34, 223.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39813/47780 [02:19<00:34, 231.60 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39063/47780 [02:19<00:37, 233.72 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39610/47780 [02:19<00:36, 226.74 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40061/47780 [02:19<00:43, 176.76 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29853/47780 [02:19<00:31, 560.32 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39482/47780 [02:19<00:31, 262.59 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40289/47780 [02:19<00:31, 240.89 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40104/47780 [02:19<00:28, 266.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39843/47780 [02:19<00:31, 250.14 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39100/47780 [02:19<00:32, 264.69 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39639/47780 [02:19<00:34, 238.14 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29910/47780 [02:19<00:32, 556.83 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39509/47780 [02:19<00:32, 254.91 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40080/47780 [02:19<00:45, 168.21 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40318/47780 [02:19<00:29, 250.56 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39874/47780 [02:19<00:29, 265.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40133/47780 [02:19<00:28, 268.73 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39663/47780 [02:19<00:34, 237.43 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39128/47780 [02:19<00:34, 247.34 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29968/47780 [02:19<00:32, 542.29 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40119/47780 [02:19<00:34, 224.00 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39535/47780 [02:19<00:34, 241.98 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39904/47780 [02:19<00:28, 274.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40161/47780 [02:19<00:28, 267.51 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40345/47780 [02:19<00:32, 231.77 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39697/47780 [02:19<00:31, 254.96 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39154/47780 [02:19<00:35, 245.13 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30026/47780 [02:19<00:33, 537.37 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39941/47780 [02:19<00:26, 294.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39560/47780 [02:19<00:35, 234.58 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40143/47780 [02:19<00:36, 212.12 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40192/47780 [02:19<00:28, 267.39 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40381/47780 [02:19<00:28, 262.56 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30095/47780 [02:19<00:30, 580.08 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39723/47780 [02:19<00:33, 240.38 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39179/47780 [02:19<00:36, 233.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39591/47780 [02:19<00:32, 255.13 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40170/47780 [02:19<00:33, 225.28 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40221/47780 [02:19<00:27, 270.74 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39976/47780 [02:20<00:26, 297.05 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40409/47780 [02:19<00:28, 261.09 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30155/47780 [02:20<00:30, 572.89 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39203/47780 [02:20<00:37, 228.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39617/47780 [02:20<00:32, 253.86 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39748/47780 [02:20<00:35, 223.40 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40194/47780 [02:20<00:33, 226.72 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40008/47780 [02:20<00:25, 300.14 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40253/47780 [02:20<00:27, 278.41 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40436/47780 [02:20<00:29, 249.81 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39649/47780 [02:20<00:29, 272.64 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39231/47780 [02:20<00:36, 237.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39771/47780 [02:20<00:35, 224.11 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40221/47780 [02:20<00:32, 236.10 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30213/47780 [02:20<00:34, 508.24 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40039/47780 [02:20<00:26, 292.64 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40281/47780 [02:20<00:29, 258.32 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40462/47780 [02:20<00:31, 232.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39677/47780 [02:20<00:30, 265.54 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39255/47780 [02:20<00:37, 228.06 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40075/47780 [02:20<00:24, 311.60 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30266/47780 [02:20<00:34, 500.53 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40246/47780 [02:20<00:34, 218.13 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39795/47780 [02:20<00:38, 204.85 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40308/47780 [02:20<00:30, 242.88 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40486/47780 [02:20<00:34, 214.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39704/47780 [02:20<00:30, 266.54 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39279/47780 [02:20<00:37, 226.06 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40107/47780 [02:20<00:24, 313.89 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40272/47780 [02:20<00:32, 229.12 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30318/47780 [02:20<00:37, 469.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39817/47780 [02:20<00:40, 194.58 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40333/47780 [02:20<00:34, 218.01 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39731/47780 [02:20<00:31, 258.44 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39312/47780 [02:20<00:33, 251.21 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40508/47780 [02:20<00:35, 203.30 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40296/47780 [02:20<00:32, 228.65 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30368/47780 [02:20<00:36, 475.83 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40139/47780 [02:20<00:28, 269.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39844/47780 [02:20<00:37, 209.71 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39761/47780 [02:20<00:29, 267.84 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40356/47780 [02:20<00:34, 217.63 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39338/47780 [02:20<00:33, 248.72 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40529/47780 [02:20<00:36, 200.84 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30417/47780 [02:20<00:36, 474.38 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40320/47780 [02:20<00:34, 215.67 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40169/47780 [02:20<00:27, 277.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39866/47780 [02:20<00:37, 212.34 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39788/47780 [02:20<00:30, 265.23 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40380/47780 [02:20<00:34, 216.38 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39363/47780 [02:20<00:34, 243.94 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40551/47780 [02:20<00:35, 201.44 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30465/47780 [02:20<00:38, 454.25 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40342/47780 [02:20<00:35, 211.48 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39888/47780 [02:20<00:37, 209.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40198/47780 [02:20<00:28, 265.70 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39815/47780 [02:20<00:30, 258.62 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40412/47780 [02:20<00:30, 239.48 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39388/47780 [02:20<00:34, 242.92 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40576/47780 [02:20<00:33, 212.47 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30512/47780 [02:20<00:38, 447.01 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40369/47780 [02:20<00:33, 218.60 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40226/47780 [02:20<00:28, 261.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39916/47780 [02:20<00:36, 215.24 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40447/47780 [02:20<00:27, 263.81 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40601/47780 [02:20<00:32, 222.76 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39414/47780 [02:20<00:33, 247.61 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40392/47780 [02:20<00:33, 219.72 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39841/47780 [02:21<00:36, 218.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30557/47780 [02:20<00:40, 429.12 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40254/47780 [02:21<00:29, 257.92 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39942/47780 [02:21<00:36, 215.75 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40633/47780 [02:21<00:28, 249.93 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39439/47780 [02:21<00:34, 244.89 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40475/47780 [02:21<00:27, 262.41 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40425/47780 [02:21<00:29, 247.68 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30602/47780 [02:21<00:41, 417.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39864/47780 [02:21<00:37, 208.44 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40285/47780 [02:21<00:28, 266.21 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40663/47780 [02:21<00:27, 261.72 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40508/47780 [02:21<00:26, 278.17 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39464/47780 [02:21<00:36, 228.57 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39964/47780 [02:21<00:41, 187.45 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40454/47780 [02:21<00:28, 256.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30651/47780 [02:21<00:39, 436.80 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40312/47780 [02:21<00:28, 264.43 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39886/47780 [02:21<00:38, 204.93 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40695/47780 [02:21<00:25, 278.56 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40539/47780 [02:21<00:25, 283.99 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39492/47780 [02:21<00:34, 242.62 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40014/47780 [02:21<00:29, 264.23 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40480/47780 [02:21<00:28, 255.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30704/47780 [02:21<00:37, 458.03 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40339/47780 [02:21<00:28, 263.01 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40724/47780 [02:21<00:25, 281.78 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39907/47780 [02:21<00:40, 196.15 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40571/47780 [02:21<00:25, 287.79 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39517/47780 [02:21<00:36, 225.62 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40043/47780 [02:21<00:30, 252.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30751/47780 [02:21<00:37, 456.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40506/47780 [02:21<00:30, 239.62 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40755/47780 [02:21<00:24, 290.03 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40368/47780 [02:21<00:28, 258.92 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39934/47780 [02:21<00:37, 211.62 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40605/47780 [02:21<00:24, 295.70 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39540/47780 [02:21<00:37, 218.58 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40070/47780 [02:21<00:30, 249.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30803/47780 [02:21<00:36, 462.49 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40531/47780 [02:21<00:30, 237.29 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40785/47780 [02:21<00:24, 286.27 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39960/47780 [02:21<00:34, 224.12 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40394/47780 [02:21<00:29, 253.35 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40637/47780 [02:21<00:23, 302.38 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39566/47780 [02:21<00:36, 227.52 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30853/47780 [02:21<00:36, 464.07 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40096/47780 [02:21<00:31, 240.29 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40555/47780 [02:21<00:31, 230.28 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40420/47780 [02:21<00:28, 255.15 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39983/47780 [02:21<00:36, 216.12 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40668/47780 [02:21<00:24, 287.99 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40814/47780 [02:21<00:27, 253.40 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39591/47780 [02:21<00:36, 222.77 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30910/47780 [02:21<00:35, 479.15 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40121/47780 [02:21<00:32, 232.12 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40580/47780 [02:21<00:32, 223.42 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40007/47780 [02:21<00:35, 217.92 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40446/47780 [02:21<00:30, 240.36 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40846/47780 [02:21<00:25, 267.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40697/47780 [02:21<00:26, 262.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39637/47780 [02:21<00:28, 284.07 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30961/47780 [02:21<00:34, 486.61 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40148/47780 [02:21<00:32, 234.82 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40611/47780 [02:21<00:30, 236.60 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40030/47780 [02:21<00:35, 218.59 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40471/47780 [02:22<00:33, 221.00 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40874/47780 [02:21<00:26, 259.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40726/47780 [02:21<00:26, 266.55 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31010/47780 [02:21<00:35, 473.83 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40178/47780 [02:21<00:30, 247.03 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40640/47780 [02:21<00:29, 245.74 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39666/47780 [02:21<00:32, 246.31 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40053/47780 [02:22<00:37, 205.11 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40494/47780 [02:22<00:33, 220.39 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40910/47780 [02:22<00:24, 280.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40757/47780 [02:21<00:25, 275.70 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40203/47780 [02:22<00:30, 246.95 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40670/47780 [02:22<00:27, 260.60 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39714/47780 [02:22<00:26, 302.80 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31058/47780 [02:22<00:39, 420.55 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40077/47780 [02:22<00:36, 213.00 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40518/47780 [02:22<00:33, 219.15 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40942/47780 [02:22<00:24, 282.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40785/47780 [02:22<00:25, 270.98 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40240/47780 [02:22<00:26, 281.26 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40699/47780 [02:22<00:26, 263.33 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40099/47780 [02:22<00:36, 210.65 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39746/47780 [02:22<00:27, 286.94 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31102/47780 [02:22<00:41, 399.82 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40544/47780 [02:22<00:31, 227.89 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40984/47780 [02:22<00:21, 320.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40813/47780 [02:22<00:25, 270.42 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40276/47780 [02:22<00:24, 301.57 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40727/47780 [02:22<00:26, 267.91 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40124/47780 [02:22<00:35, 215.35 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31143/47780 [02:22<00:42, 394.70 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40567/47780 [02:22<00:31, 228.45 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39776/47780 [02:22<00:28, 277.89 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41017/47780 [02:22<00:21, 319.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40850/47780 [02:22<00:23, 298.47 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40307/47780 [02:22<00:25, 290.75 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40754/47780 [02:22<00:26, 262.23 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31184/47780 [02:22<00:41, 398.74 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40148/47780 [02:22<00:34, 218.48 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40600/47780 [02:22<00:28, 254.30 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41052/47780 [02:22<00:20, 324.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40886/47780 [02:22<00:22, 312.79 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39805/47780 [02:22<00:31, 256.82 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40341/47780 [02:22<00:24, 297.77 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40784/47780 [02:22<00:25, 270.16 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40171/47780 [02:22<00:34, 219.27 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40631/47780 [02:22<00:27, 261.47 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40918/47780 [02:22<00:22, 311.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31225/47780 [02:22<00:43, 380.19 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41085/47780 [02:22<00:21, 308.28 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39833/47780 [02:22<00:30, 260.38 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40375/47780 [02:22<00:24, 306.27 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40812/47780 [02:22<00:26, 266.95 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40193/47780 [02:22<00:35, 212.26 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40668/47780 [02:22<00:24, 288.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31272/47780 [02:22<00:40, 404.67 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40950/47780 [02:22<00:23, 296.67 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41117/47780 [02:22<00:22, 301.51 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39861/47780 [02:22<00:30, 257.02 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40410/47780 [02:22<00:23, 315.16 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40839/47780 [02:22<00:28, 240.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40216/47780 [02:22<00:35, 214.74 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31324/47780 [02:22<00:38, 428.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40699/47780 [02:22<00:24, 285.19 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40980/47780 [02:22<00:23, 294.29 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41148/47780 [02:22<00:22, 290.66 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39888/47780 [02:22<00:30, 260.47 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40443/47780 [02:22<00:23, 308.40 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40864/47780 [02:22<00:28, 240.24 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40238/47780 [02:22<00:35, 213.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31372/47780 [02:22<00:37, 437.87 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41011/47780 [02:22<00:23, 291.89 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40728/47780 [02:22<00:26, 268.14 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39916/47780 [02:22<00:29, 263.06 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41178/47780 [02:22<00:23, 280.83 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40474/47780 [02:22<00:25, 286.50 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40896/47780 [02:22<00:26, 262.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40260/47780 [02:22<00:34, 215.40 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31418/47780 [02:22<00:37, 434.20 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41041/47780 [02:22<00:23, 291.21 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40756/47780 [02:23<00:26, 263.07 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39944/47780 [02:22<00:30, 258.41 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41210/47780 [02:22<00:22, 288.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40503/47780 [02:23<00:25, 284.01 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40289/47780 [02:23<00:33, 224.26 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31462/47780 [02:23<00:38, 425.31 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41071/47780 [02:23<00:24, 278.32 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40923/47780 [02:23<00:29, 232.61 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40783/47780 [02:23<00:27, 250.97 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41240/47780 [02:23<00:23, 281.83 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39971/47780 [02:23<00:32, 238.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40532/47780 [02:23<00:26, 275.24 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31509/47780 [02:23<00:37, 434.02 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40312/47780 [02:23<00:33, 223.37 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41103/47780 [02:23<00:23, 286.08 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40954/47780 [02:23<00:27, 245.36 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40809/47780 [02:23<00:27, 252.55 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41269/47780 [02:23<00:23, 278.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40006/47780 [02:23<00:29, 265.30 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40335/47780 [02:23<00:33, 222.48 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31556/47780 [02:23<00:37, 434.47 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40561/47780 [02:23<00:28, 257.57 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41135/47780 [02:23<00:22, 289.07 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40980/47780 [02:23<00:27, 245.87 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40839/47780 [02:23<00:26, 260.72 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41299/47780 [02:23<00:23, 278.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40034/47780 [02:23<00:30, 255.44 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31603/47780 [02:23<00:36, 439.60 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40369/47780 [02:23<00:29, 249.42 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40611/47780 [02:23<00:22, 319.46 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41176/47780 [02:23<00:20, 319.83 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41332/47780 [02:23<00:22, 286.36 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40866/47780 [02:23<00:28, 246.82 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41006/47780 [02:23<00:29, 225.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40060/47780 [02:23<00:30, 256.08 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40644/47780 [02:23<00:22, 318.84 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40394/47780 [02:23<00:32, 229.80 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31648/47780 [02:23<00:41, 388.80 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41361/47780 [02:23<00:22, 281.19 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41209/47780 [02:23<00:22, 295.52 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40894/47780 [02:23<00:27, 247.92 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41038/47780 [02:23<00:27, 242.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40086/47780 [02:23<00:31, 247.57 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40687/47780 [02:23<00:21, 334.84 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40420/47780 [02:23<00:30, 238.00 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31713/47780 [02:23<00:35, 457.96 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41392/47780 [02:23<00:22, 289.17 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41243/47780 [02:23<00:21, 307.35 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40919/47780 [02:23<00:27, 248.02 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41067/47780 [02:23<00:26, 252.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40113/47780 [02:23<00:30, 253.62 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40721/47780 [02:23<00:22, 318.65 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40445/47780 [02:23<00:34, 212.50 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41276/47780 [02:23<00:21, 295.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41421/47780 [02:23<00:23, 267.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41100/47780 [02:23<00:25, 265.00 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40139/47780 [02:23<00:31, 243.62 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31761/47780 [02:23<00:42, 377.18 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40944/47780 [02:23<00:32, 209.09 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40755/47780 [02:23<00:22, 314.21 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41308/47780 [02:23<00:21, 300.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40469/47780 [02:23<00:33, 215.49 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41129/47780 [02:23<00:24, 268.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41449/47780 [02:23<00:24, 261.50 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40164/47780 [02:23<00:32, 232.44 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40979/47780 [02:24<00:27, 244.58 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31847/47780 [02:23<00:32, 484.60 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40796/47780 [02:23<00:20, 336.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40492/47780 [02:24<00:33, 217.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41476/47780 [02:23<00:24, 257.67 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41157/47780 [02:24<00:25, 263.29 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41339/47780 [02:23<00:23, 278.38 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31900/47780 [02:24<00:32, 494.36 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41009/47780 [02:24<00:26, 253.84 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40189/47780 [02:24<00:34, 220.28 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40515/47780 [02:24<00:33, 216.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40830/47780 [02:24<00:22, 306.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41186/47780 [02:24<00:24, 270.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41509/47780 [02:24<00:22, 273.37 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41369/47780 [02:24<00:23, 272.60 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40225/47780 [02:24<00:29, 255.33 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41036/47780 [02:24<00:27, 247.32 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31953/47780 [02:24<00:33, 469.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40537/47780 [02:24<00:34, 212.13 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40862/47780 [02:24<00:23, 291.69 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41542/47780 [02:24<00:22, 278.76 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41401/47780 [02:24<00:22, 282.06 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41065/47780 [02:24<00:26, 256.35 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41216/47780 [02:24<00:27, 238.45 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32008/47780 [02:24<00:32, 486.15 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40253/47780 [02:24<00:30, 250.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40564/47780 [02:24<00:31, 225.80 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40892/47780 [02:24<00:23, 287.89 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41572/47780 [02:24<00:22, 279.54 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41432/47780 [02:24<00:22, 286.87 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41094/47780 [02:24<00:25, 265.49 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41260/47780 [02:24<00:22, 290.30 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32063/47780 [02:24<00:31, 498.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40279/47780 [02:24<00:32, 232.26 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40587/47780 [02:24<00:33, 217.18 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40929/47780 [02:24<00:22, 306.70 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41601/47780 [02:24<00:22, 273.31 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41461/47780 [02:24<00:23, 264.05 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41130/47780 [02:24<00:23, 279.67 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40309/47780 [02:24<00:30, 245.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32115/47780 [02:24<00:34, 454.23 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41291/47780 [02:24<00:26, 247.58 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41629/47780 [02:24<00:22, 271.84 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40610/47780 [02:24<00:35, 204.47 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41489/47780 [02:24<00:23, 265.59 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40961/47780 [02:24<00:24, 276.12 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41162/47780 [02:24<00:22, 287.77 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40335/47780 [02:24<00:29, 249.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32183/47780 [02:24<00:30, 513.33 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41657/47780 [02:24<00:22, 270.37 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40632/47780 [02:24<00:35, 200.31 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41318/47780 [02:24<00:27, 234.81 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41008/47780 [02:24<00:20, 323.85 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41193/47780 [02:24<00:23, 284.41 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41516/47780 [02:24<00:24, 252.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32237/47780 [02:24<00:30, 507.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40361/47780 [02:24<00:30, 241.57 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41691/47780 [02:24<00:21, 288.11 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40658/47780 [02:24<00:32, 216.40 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41348/47780 [02:24<00:25, 250.70 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41542/47780 [02:24<00:24, 251.99 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41222/47780 [02:24<00:23, 276.70 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41042/47780 [02:24<00:21, 308.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32290/47780 [02:24<00:30, 503.63 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40391/47780 [02:24<00:29, 252.13 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41730/47780 [02:24<00:19, 317.18 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40684/47780 [02:24<00:31, 226.08 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41375/47780 [02:24<00:25, 247.94 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41568/47780 [02:24<00:24, 251.64 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41074/47780 [02:24<00:21, 308.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41252/47780 [02:25<00:23, 277.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40417/47780 [02:24<00:29, 253.69 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32342/47780 [02:24<00:32, 472.62 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41762/47780 [02:24<00:19, 311.12 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40707/47780 [02:25<00:32, 219.44 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41404/47780 [02:25<00:25, 248.67 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41595/47780 [02:24<00:24, 253.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41106/47780 [02:25<00:22, 301.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40448/47780 [02:25<00:27, 264.30 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41280/47780 [02:25<00:25, 254.78 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41794/47780 [02:25<00:20, 292.76 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40730/47780 [02:25<00:32, 220.15 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32391/47780 [02:25<00:35, 433.34 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41430/47780 [02:25<00:27, 232.63 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41137/47780 [02:25<00:22, 294.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41621/47780 [02:25<00:26, 233.56 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40475/47780 [02:25<00:28, 256.90 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41306/47780 [02:25<00:25, 253.22 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32484/47780 [02:25<00:27, 552.89 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40753/47780 [02:25<00:32, 213.32 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41824/47780 [02:25<00:21, 273.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41656/47780 [02:25<00:23, 263.26 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40502/47780 [02:25<00:28, 258.03 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41332/47780 [02:25<00:26, 240.43 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41456/47780 [02:25<00:30, 204.29 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32542/47780 [02:25<00:28, 531.66 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40775/47780 [02:25<00:34, 206.01 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41878/47780 [02:25<00:17, 334.72 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41687/47780 [02:25<00:22, 276.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41167/47780 [02:25<00:29, 226.29 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40529/47780 [02:25<00:28, 258.51 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41357/47780 [02:25<00:26, 240.37 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41505/47780 [02:25<00:24, 261.28 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40796/47780 [02:25<00:34, 204.88 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41912/47780 [02:25<00:17, 329.00 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41718/47780 [02:25<00:21, 284.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32597/47780 [02:25<00:30, 504.23 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40558/47780 [02:25<00:26, 267.50 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41193/47780 [02:25<00:31, 212.39 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41382/47780 [02:25<00:27, 229.17 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41546/47780 [02:25<00:20, 297.86 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40821/47780 [02:25<00:32, 215.08 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41946/47780 [02:25<00:17, 324.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32650/47780 [02:25<00:29, 505.10 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41748/47780 [02:25<00:22, 273.63 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40585/47780 [02:25<00:27, 261.85 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41266/47780 [02:25<00:20, 325.66 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41407/47780 [02:25<00:27, 232.76 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40843/47780 [02:25<00:33, 209.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32709/47780 [02:25<00:28, 523.21 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41578/47780 [02:25<00:22, 270.06 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40612/47780 [02:25<00:27, 261.16 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41979/47780 [02:25<00:19, 300.25 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41776/47780 [02:25<00:22, 264.74 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41307/47780 [02:25<00:18, 344.52 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41431/47780 [02:25<00:28, 221.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40866/47780 [02:25<00:32, 212.79 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32764/47780 [02:25<00:29, 514.56 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41609/47780 [02:25<00:22, 279.82 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40639/47780 [02:25<00:27, 255.20 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41806/47780 [02:25<00:22, 265.28 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42011/47780 [02:25<00:20, 286.54 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41454/47780 [02:25<00:28, 222.37 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41350/47780 [02:25<00:18, 340.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40892/47780 [02:25<00:30, 226.04 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41642/47780 [02:25<00:21, 287.10 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41833/47780 [02:25<00:23, 258.07 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32816/47780 [02:25<00:32, 466.04 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42040/47780 [02:25<00:20, 284.08 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40665/47780 [02:25<00:29, 239.77 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41478/47780 [02:26<00:27, 227.21 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40915/47780 [02:25<00:32, 210.32 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41387/47780 [02:25<00:20, 313.99 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32870/47780 [02:26<00:30, 483.07 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41674/47780 [02:26<00:22, 272.25 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42069/47780 [02:25<00:20, 279.69 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40693/47780 [02:25<00:28, 248.37 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41860/47780 [02:25<00:23, 250.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41501/47780 [02:26<00:27, 225.13 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41426/47780 [02:26<00:19, 324.98 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40946/47780 [02:26<00:31, 218.12 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32936/47780 [02:26<00:28, 529.45 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41886/47780 [02:26<00:23, 250.97 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40723/47780 [02:26<00:27, 257.10 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41703/47780 [02:26<00:23, 260.57 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42099/47780 [02:26<00:20, 270.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41533/47780 [02:26<00:25, 246.45 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41460/47780 [02:26<00:20, 312.83 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40968/47780 [02:26<00:31, 216.64 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41915/47780 [02:26<00:22, 261.05 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32991/47780 [02:26<00:28, 511.25 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40750/47780 [02:26<00:27, 251.41 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41731/47780 [02:26<00:23, 252.52 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42132/47780 [02:26<00:20, 274.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41560/47780 [02:26<00:26, 237.43 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40994/47780 [02:26<00:30, 223.57 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40782/47780 [02:26<00:26, 265.81 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33044/47780 [02:26<00:30, 481.91 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41757/47780 [02:26<00:23, 252.11 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41493/47780 [02:26<00:22, 279.58 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41585/47780 [02:26<00:25, 240.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41942/47780 [02:26<00:24, 236.60 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42160/47780 [02:26<00:22, 251.87 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41017/47780 [02:26<00:30, 220.49 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33104/47780 [02:26<00:28, 513.28 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40809/47780 [02:26<00:26, 260.85 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41523/47780 [02:26<00:22, 278.88 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41613/47780 [02:26<00:25, 246.48 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41784/47780 [02:26<00:24, 246.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41968/47780 [02:26<00:24, 237.79 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42186/47780 [02:26<00:22, 253.76 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40846/47780 [02:26<00:23, 290.77 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41040/47780 [02:26<00:32, 206.74 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41996/47780 [02:26<00:23, 243.96 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33158/47780 [02:26<00:30, 480.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41638/47780 [02:26<00:25, 239.37 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41809/47780 [02:26<00:26, 229.62 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42212/47780 [02:26<00:22, 247.44 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41552/47780 [02:26<00:25, 242.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40886/47780 [02:26<00:21, 319.58 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33210/47780 [02:26<00:30, 483.56 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41663/47780 [02:26<00:25, 239.07 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41061/47780 [02:26<00:35, 191.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42021/47780 [02:26<00:24, 237.24 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42238/47780 [02:26<00:23, 235.75 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41833/47780 [02:26<00:27, 216.73 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41578/47780 [02:26<00:27, 229.07 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40920/47780 [02:26<00:22, 300.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41081/47780 [02:26<00:34, 191.74 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41687/47780 [02:26<00:25, 234.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33260/47780 [02:26<00:30, 477.22 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42046/47780 [02:26<00:24, 235.24 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41855/47780 [02:26<00:28, 210.84 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42262/47780 [02:26<00:24, 222.50 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41603/47780 [02:26<00:26, 231.98 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41102/47780 [02:26<00:33, 196.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33314/47780 [02:26<00:29, 489.60 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41712/47780 [02:27<00:26, 226.91 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40951/47780 [02:26<00:24, 275.72 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42070/47780 [02:26<00:25, 221.36 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41878/47780 [02:26<00:27, 213.74 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42285/47780 [02:26<00:25, 219.61 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41631/47780 [02:26<00:25, 243.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41122/47780 [02:27<00:34, 195.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33365/47780 [02:27<00:29, 489.28 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41735/47780 [02:27<00:26, 226.18 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42093/47780 [02:26<00:25, 222.57 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40980/47780 [02:27<00:25, 271.18 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41911/47780 [02:27<00:24, 243.20 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42318/47780 [02:27<00:22, 247.82 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41661/47780 [02:27<00:23, 256.30 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33427/47780 [02:27<00:27, 521.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41145/47780 [02:27<00:33, 198.60 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41765/47780 [02:27<00:24, 245.10 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42116/47780 [02:27<00:26, 217.13 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41939/47780 [02:27<00:23, 252.00 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41008/47780 [02:27<00:26, 259.85 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42348/47780 [02:27<00:20, 261.36 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41695/47780 [02:27<00:22, 273.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41167/47780 [02:27<00:32, 204.61 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33488/47780 [02:27<00:26, 541.74 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41799/47780 [02:27<00:22, 269.19 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42139/47780 [02:27<00:26, 213.77 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42376/47780 [02:27<00:20, 264.79 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41725/47780 [02:27<00:21, 280.69 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41045/47780 [02:27<00:24, 269.88 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41966/47780 [02:27<00:24, 233.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41194/47780 [02:27<00:29, 220.78 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33544/47780 [02:27<00:26, 533.35 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41827/47780 [02:27<00:23, 254.33 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42407/47780 [02:27<00:19, 273.32 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42165/47780 [02:27<00:26, 210.43 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41082/47780 [02:27<00:22, 292.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41991/47780 [02:27<00:25, 231.09 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41217/47780 [02:27<00:30, 215.81 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33599/47780 [02:27<00:27, 514.54 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41754/47780 [02:27<00:25, 234.83 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41853/47780 [02:27<00:24, 243.84 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42435/47780 [02:27<00:19, 270.57 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42190/47780 [02:27<00:25, 219.65 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41115/47780 [02:27<00:22, 302.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42015/47780 [02:27<00:25, 228.56 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41246/47780 [02:27<00:28, 231.50 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33657/47780 [02:27<00:26, 532.70 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41797/47780 [02:27<00:21, 281.61 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41878/47780 [02:27<00:24, 239.24 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42463/47780 [02:27<00:20, 265.74 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42213/47780 [02:27<00:25, 214.34 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42044/47780 [02:27<00:23, 245.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41147/47780 [02:27<00:23, 284.35 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41277/47780 [02:27<00:26, 248.91 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33716/47780 [02:27<00:25, 543.17 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41827/47780 [02:27<00:22, 269.49 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41911/47780 [02:27<00:22, 259.41 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42235/47780 [02:27<00:25, 215.78 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42490/47780 [02:27<00:20, 256.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41176/47780 [02:27<00:23, 277.58 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42069/47780 [02:27<00:25, 228.39 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41308/47780 [02:27<00:25, 256.99 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33771/47780 [02:27<00:27, 515.76 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41940/47780 [02:27<00:21, 267.52 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42516/47780 [02:27<00:21, 250.58 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42257/47780 [02:27<00:26, 207.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41205/47780 [02:27<00:23, 275.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42098/47780 [02:27<00:23, 242.89 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41856/47780 [02:27<00:25, 230.51 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41334/47780 [02:27<00:25, 253.62 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33823/47780 [02:27<00:27, 508.37 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41970/47780 [02:27<00:21, 273.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42278/47780 [02:27<00:28, 193.27 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41233/47780 [02:27<00:24, 265.57 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42123/47780 [02:27<00:23, 236.97 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42542/47780 [02:27<00:23, 225.07 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41360/47780 [02:27<00:26, 240.39 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41881/47780 [02:27<00:26, 219.20 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41998/47780 [02:28<00:21, 268.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33875/47780 [02:27<00:29, 470.73 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41260/47780 [02:28<00:24, 262.64 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42304/47780 [02:28<00:26, 203.71 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42147/47780 [02:28<00:24, 230.51 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42565/47780 [02:28<00:23, 219.63 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41908/47780 [02:28<00:25, 229.56 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42027/47780 [02:28<00:21, 271.88 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33929/47780 [02:28<00:28, 479.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41387/47780 [02:28<00:27, 230.54 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42328/47780 [02:28<00:25, 212.34 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42594/47780 [02:28<00:21, 237.48 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42171/47780 [02:28<00:24, 227.55 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41288/47780 [02:28<00:25, 250.92 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41932/47780 [02:28<00:25, 232.07 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33987/47780 [02:28<00:27, 505.58 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42055/47780 [02:28<00:21, 268.98 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41421/47780 [02:28<00:24, 258.26 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42620/47780 [02:28<00:21, 237.94 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41963/47780 [02:28<00:23, 252.83 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42194/47780 [02:28<00:25, 216.62 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42350/47780 [02:28<00:27, 196.89 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41314/47780 [02:28<00:26, 244.35 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42082/47780 [02:28<00:21, 262.90 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34040/47780 [02:28<00:28, 485.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41448/47780 [02:28<00:26, 239.37 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42649/47780 [02:28<00:20, 252.32 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42372/47780 [02:28<00:26, 202.98 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42217/47780 [02:28<00:25, 217.50 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41339/47780 [02:28<00:27, 236.63 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41990/47780 [02:28<00:24, 239.07 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42114/47780 [02:28<00:20, 277.45 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34093/47780 [02:28<00:27, 497.86 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41474/47780 [02:28<00:27, 230.34 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42675/47780 [02:28<00:20, 250.63 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42394/47780 [02:28<00:26, 206.43 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41379/47780 [02:28<00:23, 275.57 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42239/47780 [02:28<00:26, 206.60 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42015/47780 [02:28<00:23, 241.82 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34144/47780 [02:28<00:27, 497.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42142/47780 [02:28<00:22, 255.35 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41499/47780 [02:28<00:26, 232.83 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42705/47780 [02:28<00:19, 261.77 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42420/47780 [02:28<00:24, 220.52 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41415/47780 [02:28<00:21, 298.32 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42042/47780 [02:28<00:23, 245.05 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42260/47780 [02:28<00:27, 199.83 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34198/47780 [02:28<00:26, 509.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42172/47780 [02:28<00:21, 262.29 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41529/47780 [02:28<00:25, 245.88 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42734/47780 [02:28<00:18, 266.22 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42447/47780 [02:28<00:22, 231.96 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42068/47780 [02:28<00:23, 245.92 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41447/47780 [02:28<00:21, 291.32 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34254/47780 [02:28<00:26, 517.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42281/47780 [02:28<00:29, 187.22 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41556/47780 [02:28<00:25, 247.29 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42199/47780 [02:28<00:24, 228.54 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42471/47780 [02:28<00:23, 224.02 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42762/47780 [02:28<00:20, 244.84 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42093/47780 [02:28<00:23, 243.56 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34313/47780 [02:28<00:25, 538.32 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41478/47780 [02:28<00:22, 277.98 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42300/47780 [02:28<00:29, 187.11 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41583/47780 [02:28<00:24, 253.48 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42234/47780 [02:29<00:21, 258.41 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42494/47780 [02:28<00:23, 222.88 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42123/47780 [02:28<00:22, 254.47 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34370/47780 [02:28<00:25, 529.48 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41511/47780 [02:28<00:21, 288.99 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42793/47780 [02:28<00:20, 241.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42328/47780 [02:28<00:26, 206.97 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41617/47780 [02:29<00:22, 277.90 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42522/47780 [02:28<00:22, 236.79 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42261/47780 [02:29<00:21, 252.12 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42150/47780 [02:29<00:21, 255.97 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42825/47780 [02:29<00:18, 262.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34425/47780 [02:29<00:26, 500.73 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42349/47780 [02:29<00:27, 194.89 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41542/47780 [02:29<00:23, 267.98 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41646/47780 [02:29<00:22, 269.91 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42547/47780 [02:29<00:21, 240.40 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42289/47780 [02:29<00:21, 257.07 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42177/47780 [02:29<00:22, 248.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34478/47780 [02:29<00:26, 508.39 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42382/47780 [02:29<00:23, 228.80 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42852/47780 [02:29<00:20, 236.18 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41570/47780 [02:29<00:23, 265.53 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41676/47780 [02:29<00:22, 274.49 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42321/47780 [02:29<00:19, 274.27 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42578/47780 [02:29<00:20, 251.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42202/47780 [02:29<00:22, 246.16 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34530/47780 [02:29<00:27, 474.54 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42406/47780 [02:29<00:23, 229.37 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42877/47780 [02:29<00:20, 239.58 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41604/47780 [02:29<00:21, 282.66 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41704/47780 [02:29<00:23, 258.75 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42350/47780 [02:29<00:19, 275.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42228/47780 [02:29<00:22, 247.51 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42605/47780 [02:29<00:24, 215.10 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41633/47780 [02:29<00:21, 284.17 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42902/47780 [02:29<00:20, 232.58 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42430/47780 [02:29<00:24, 219.45 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41737/47780 [02:29<00:21, 275.00 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42381/47780 [02:29<00:19, 279.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42258/47780 [02:29<00:21, 259.36 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41668/47780 [02:29<00:20, 300.01 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42926/47780 [02:29<00:20, 232.06 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34580/47780 [02:29<00:37, 353.50 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42628/47780 [02:29<00:25, 204.31 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42453/47780 [02:29<00:25, 208.83 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41766/47780 [02:29<00:22, 272.57 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42289/47780 [02:29<00:20, 271.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42411/47780 [02:29<00:21, 253.32 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41702/47780 [02:29<00:19, 307.74 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42953/47780 [02:29<00:19, 241.92 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42654/47780 [02:29<00:23, 218.41 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34690/47780 [02:29<00:25, 511.24 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41798/47780 [02:29<00:21, 284.37 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42475/47780 [02:29<00:25, 209.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42319/47780 [02:29<00:19, 279.42 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42438/47780 [02:29<00:20, 255.06 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42978/47780 [02:29<00:19, 243.10 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41733/47780 [02:29<00:20, 298.26 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42677/47780 [02:29<00:23, 216.65 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41833/47780 [02:29<00:19, 301.91 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34750/47780 [02:29<00:25, 509.11 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42509/47780 [02:29<00:22, 237.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42348/47780 [02:29<00:19, 281.90 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42466/47780 [02:29<00:20, 253.40 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41768/47780 [02:29<00:19, 309.48 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43008/47780 [02:29<00:19, 250.91 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42700/47780 [02:29<00:23, 215.74 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34849/47780 [02:29<00:20, 626.06 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41864/47780 [02:29<00:20, 292.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42537/47780 [02:29<00:21, 244.18 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42493/47780 [02:30<00:20, 252.47 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42377/47780 [02:29<00:21, 251.76 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43034/47780 [02:29<00:19, 246.69 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42722/47780 [02:29<00:23, 215.43 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42570/47780 [02:29<00:19, 267.86 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41906/47780 [02:29<00:18, 316.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34918/47780 [02:29<00:21, 604.82 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41800/47780 [02:29<00:23, 256.70 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42519/47780 [02:30<00:21, 243.74 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42403/47780 [02:30<00:22, 236.40 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43067/47780 [02:30<00:17, 265.96 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42752/47780 [02:30<00:21, 235.66 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42598/47780 [02:30<00:19, 265.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41938/47780 [02:30<00:18, 309.88 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41837/47780 [02:30<00:21, 282.25 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34983/47780 [02:30<00:23, 553.00 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42428/47780 [02:30<00:22, 238.30 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42782/47780 [02:30<00:19, 252.54 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43101/47780 [02:30<00:16, 282.04 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42544/47780 [02:30<00:23, 220.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42626/47780 [02:30<00:19, 260.94 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41972/47780 [02:30<00:19, 301.26 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35047/47780 [02:30<00:22, 569.55 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41867/47780 [02:30<00:21, 274.90 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42455/47780 [02:30<00:21, 246.15 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43139/47780 [02:30<00:14, 309.77 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42574/47780 [02:30<00:21, 236.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42809/47780 [02:30<00:20, 239.78 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42654/47780 [02:30<00:20, 247.77 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42003/47780 [02:30<00:20, 285.31 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35107/47780 [02:30<00:22, 564.99 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41896/47780 [02:30<00:22, 265.22 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43171/47780 [02:30<00:15, 295.77 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42481/47780 [02:30<00:23, 229.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42601/47780 [02:30<00:21, 240.68 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42834/47780 [02:30<00:22, 220.67 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42680/47780 [02:30<00:21, 236.96 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41926/47780 [02:30<00:21, 268.78 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42032/47780 [02:30<00:21, 271.09 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35166/47780 [02:30<00:24, 517.07 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42508/47780 [02:30<00:22, 235.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43201/47780 [02:30<00:16, 278.22 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42626/47780 [02:30<00:22, 225.76 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42860/47780 [02:30<00:21, 228.62 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42709/47780 [02:30<00:20, 243.48 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41957/47780 [02:30<00:20, 279.89 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42061/47780 [02:30<00:21, 262.84 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43236/47780 [02:30<00:15, 297.59 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35222/47780 [02:30<00:25, 486.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42532/47780 [02:30<00:23, 219.75 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42649/47780 [02:30<00:23, 217.98 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42884/47780 [02:30<00:22, 219.73 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41988/47780 [02:30<00:20, 287.04 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42741/47780 [02:30<00:19, 258.65 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42092/47780 [02:30<00:21, 269.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35303/47780 [02:30<00:22, 564.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43267/47780 [02:30<00:15, 284.90 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42555/47780 [02:30<00:24, 210.40 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42909/47780 [02:30<00:21, 223.05 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42672/47780 [02:30<00:24, 209.87 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42018/47780 [02:30<00:20, 282.44 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42769/47780 [02:30<00:19, 256.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42120/47780 [02:30<00:21, 263.63 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35362/47780 [02:30<00:22, 547.63 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43298/47780 [02:30<00:16, 276.54 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42699/47780 [02:30<00:22, 224.91 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42932/47780 [02:30<00:22, 219.35 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42577/47780 [02:30<00:25, 201.09 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42798/47780 [02:30<00:18, 265.42 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42055/47780 [02:30<00:18, 301.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42155/47780 [02:30<00:19, 284.39 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35419/47780 [02:30<00:23, 525.90 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43331/47780 [02:30<00:15, 285.29 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42727/47780 [02:31<00:21, 239.27 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42957/47780 [02:30<00:21, 226.07 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42598/47780 [02:30<00:26, 199.20 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42827/47780 [02:30<00:18, 266.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42184/47780 [02:31<00:19, 282.54 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42086/47780 [02:31<00:22, 256.21 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43364/47780 [02:31<00:14, 295.14 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42762/47780 [02:31<00:18, 269.48 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35474/47780 [02:31<00:24, 510.31 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42986/47780 [02:31<00:20, 238.46 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42623/47780 [02:31<00:24, 210.63 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42866/47780 [02:31<00:16, 294.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42233/47780 [02:31<00:16, 333.83 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42114/47780 [02:31<00:21, 259.70 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43396/47780 [02:31<00:14, 298.00 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35526/47780 [02:31<00:24, 497.57 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42652/47780 [02:31<00:22, 229.92 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43010/47780 [02:31<00:20, 233.69 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42898/47780 [02:31<00:16, 298.51 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42790/47780 [02:31<00:20, 247.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42268/47780 [02:31<00:16, 330.43 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42142/47780 [02:31<00:21, 260.47 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43429/47780 [02:31<00:14, 297.00 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35580/47780 [02:31<00:23, 508.46 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43042/47780 [02:31<00:18, 252.70 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42824/47780 [02:31<00:18, 270.41 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42677/47780 [02:31<00:22, 223.07 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42313/47780 [02:31<00:15, 360.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42929/47780 [02:31<00:18, 262.73 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42170/47780 [02:31<00:21, 261.65 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43459/47780 [02:31<00:14, 297.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35635/47780 [02:31<00:23, 515.77 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42707/47780 [02:31<00:20, 242.80 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43068/47780 [02:31<00:19, 237.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42852/47780 [02:31<00:19, 257.75 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42198/47780 [02:31<00:21, 265.56 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42351/47780 [02:31<00:16, 325.31 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43492/47780 [02:31<00:14, 303.66 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42957/47780 [02:31<00:20, 240.75 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35687/47780 [02:31<00:24, 487.91 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42735/47780 [02:31<00:20, 248.94 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42882/47780 [02:31<00:18, 263.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43092/47780 [02:31<00:20, 226.52 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42385/47780 [02:31<00:16, 325.81 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42225/47780 [02:31<00:21, 255.65 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43526/47780 [02:31<00:13, 310.54 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42982/47780 [02:31<00:20, 232.93 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42761/47780 [02:31<00:20, 246.60 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35737/47780 [02:31<00:25, 474.06 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42909/47780 [02:31<00:18, 262.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43116/47780 [02:31<00:20, 227.19 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43574/47780 [02:31<00:11, 359.56 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42419/47780 [02:31<00:16, 315.91 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42260/47780 [02:31<00:21, 254.62 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35793/47780 [02:31<00:24, 494.40 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42786/47780 [02:31<00:20, 239.52 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42936/47780 [02:31<00:18, 264.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43006/47780 [02:31<00:22, 210.63 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43139/47780 [02:31<00:21, 216.60 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43611/47780 [02:31<00:12, 321.25 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42452/47780 [02:31<00:18, 285.44 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42286/47780 [02:31<00:23, 236.07 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42965/47780 [02:31<00:18, 256.85 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42811/47780 [02:31<00:21, 227.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43035/47780 [02:31<00:21, 225.75 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43161/47780 [02:31<00:22, 208.50 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35843/47780 [02:31<00:27, 431.63 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42482/47780 [02:31<00:19, 277.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43645/47780 [02:31<00:13, 300.41 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42316/47780 [02:31<00:22, 242.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43069/47780 [02:31<00:18, 252.58 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42991/47780 [02:32<00:19, 241.58 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43184/47780 [02:31<00:21, 212.05 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42834/47780 [02:31<00:23, 213.68 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35899/47780 [02:31<00:27, 438.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42359/47780 [02:32<00:18, 291.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43676/47780 [02:32<00:13, 296.69 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43097/47780 [02:32<00:18, 254.45 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42511/47780 [02:32<00:20, 261.98 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42859/47780 [02:32<00:22, 221.22 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43206/47780 [02:32<00:22, 203.02 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43016/47780 [02:32<00:20, 226.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35945/47780 [02:32<00:27, 435.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43124/47780 [02:32<00:18, 256.67 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43710/47780 [02:32<00:13, 301.81 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42391/47780 [02:32<00:18, 289.83 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42554/47780 [02:32<00:17, 302.11 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42884/47780 [02:32<00:21, 224.22 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43227/47780 [02:32<00:22, 204.89 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43049/47780 [02:32<00:19, 248.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35991/47780 [02:32<00:27, 432.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43151/47780 [02:32<00:17, 259.61 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42422/47780 [02:32<00:18, 295.32 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43741/47780 [02:32<00:13, 300.92 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42590/47780 [02:32<00:16, 317.56 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42907/47780 [02:32<00:21, 223.38 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43087/47780 [02:32<00:16, 283.34 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43258/47780 [02:32<00:20, 224.40 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36035/47780 [02:32<00:28, 411.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43181/47780 [02:32<00:17, 268.00 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42453/47780 [02:32<00:18, 284.38 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42930/47780 [02:32<00:21, 225.09 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42625/47780 [02:32<00:17, 302.75 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43772/47780 [02:32<00:14, 280.90 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43289/47780 [02:32<00:18, 242.61 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43116/47780 [02:32<00:17, 274.05 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36077/47780 [02:32<00:28, 410.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43210/47780 [02:32<00:16, 274.29 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42483/47780 [02:32<00:18, 287.32 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42954/47780 [02:32<00:22, 217.04 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43823/47780 [02:32<00:11, 332.25 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43318/47780 [02:32<00:17, 253.10 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42657/47780 [02:32<00:17, 289.27 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43148/47780 [02:32<00:16, 280.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36128/47780 [02:32<00:26, 433.17 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43239/47780 [02:32<00:17, 260.72 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42513/47780 [02:32<00:18, 285.03 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42977/47780 [02:32<00:21, 220.63 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36173/47780 [02:32<00:26, 433.04 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43177/47780 [02:32<00:16, 276.64 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43859/47780 [02:32<00:12, 303.12 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43344/47780 [02:32<00:19, 228.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42687/47780 [02:32<00:19, 261.57 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42542/47780 [02:32<00:18, 278.80 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43267/47780 [02:32<00:17, 257.34 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 43000/47780 [02:32<00:21, 220.79 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43205/47780 [02:32<00:17, 268.66 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43368/47780 [02:32<00:19, 222.71 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42715/47780 [02:32<00:19, 258.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36218/47780 [02:32<00:29, 390.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43891/47780 [02:32<00:13, 284.37 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43026/47780 [02:32<00:21, 225.34 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43293/47780 [02:32<00:18, 247.07 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42571/47780 [02:32<00:19, 265.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43237/47780 [02:32<00:16, 273.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36264/47780 [02:32<00:28, 399.81 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43922/47780 [02:32<00:13, 276.70 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43392/47780 [02:32<00:21, 207.29 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42742/47780 [02:32<00:21, 234.31 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43318/47780 [02:32<00:18, 247.73 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43053/47780 [02:32<00:20, 231.81 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42609/47780 [02:32<00:18, 281.24 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43265/47780 [02:33<00:17, 255.87 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36307/47780 [02:32<00:28, 407.41 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43953/47780 [02:32<00:13, 279.83 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43415/47780 [02:32<00:21, 204.72 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43345/47780 [02:33<00:17, 248.61 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43077/47780 [02:33<00:20, 228.57 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42767/47780 [02:33<00:22, 227.07 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42645/47780 [02:33<00:17, 296.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43294/47780 [02:33<00:16, 264.87 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36359/47780 [02:33<00:26, 429.38 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43986/47780 [02:33<00:13, 287.07 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43442/47780 [02:33<00:19, 219.43 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43375/47780 [02:33<00:16, 260.31 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42791/47780 [02:33<00:21, 229.29 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42683/47780 [02:33<00:16, 315.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43100/47780 [02:33<00:21, 214.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36419/47780 [02:33<00:23, 474.27 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43321/47780 [02:33<00:18, 239.92 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44015/47780 [02:33<00:13, 281.89 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43403/47780 [02:33<00:16, 265.85 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43465/47780 [02:33<00:20, 210.78 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43122/47780 [02:33<00:22, 211.49 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42715/47780 [02:33<00:16, 303.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42815/47780 [02:33<00:23, 206.90 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36467/47780 [02:33<00:25, 448.18 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43348/47780 [02:33<00:17, 247.28 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44045/47780 [02:33<00:13, 286.84 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43442/47780 [02:33<00:14, 297.34 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43487/47780 [02:33<00:21, 200.73 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42748/47780 [02:33<00:16, 310.52 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43148/47780 [02:33<00:21, 216.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42841/47780 [02:33<00:22, 217.95 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36518/47780 [02:33<00:24, 459.84 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43475/47780 [02:33<00:14, 300.96 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43374/47780 [02:33<00:19, 230.95 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44075/47780 [02:33<00:14, 258.49 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43508/47780 [02:33<00:22, 192.81 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42780/47780 [02:33<00:17, 290.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42868/47780 [02:33<00:21, 227.00 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43170/47780 [02:33<00:23, 194.75 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43512/47780 [02:33<00:13, 319.80 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36565/47780 [02:33<00:26, 428.92 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43412/47780 [02:33<00:16, 259.40 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43531/47780 [02:33<00:20, 202.58 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42896/47780 [02:33<00:20, 241.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44102/47780 [02:33<00:15, 241.15 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42811/47780 [02:33<00:17, 283.37 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43190/47780 [02:33<00:23, 193.73 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36612/47780 [02:33<00:25, 435.32 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43546/47780 [02:33<00:13, 308.82 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43439/47780 [02:33<00:17, 254.19 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42921/47780 [02:33<00:19, 243.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43556/47780 [02:33<00:20, 208.74 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44127/47780 [02:33<00:15, 231.28 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42847/47780 [02:33<00:16, 294.99 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43210/47780 [02:33<00:23, 191.10 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36657/47780 [02:33<00:25, 434.43 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43467/47780 [02:33<00:16, 258.38 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43578/47780 [02:33<00:14, 289.19 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42946/47780 [02:33<00:19, 242.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43586/47780 [02:33<00:17, 233.69 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44152/47780 [02:33<00:15, 226.94 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43230/47780 [02:33<00:24, 184.20 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36701/47780 [02:33<00:25, 430.87 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42877/47780 [02:33<00:19, 252.04 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43609/47780 [02:33<00:14, 291.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43611/47780 [02:33<00:18, 231.09 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42971/47780 [02:33<00:20, 233.73 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43494/47780 [02:34<00:18, 237.61 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44177/47780 [02:33<00:15, 232.12 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43251/47780 [02:33<00:23, 189.62 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36751/47780 [02:33<00:24, 445.91 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42920/47780 [02:33<00:16, 293.41 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43639/47780 [02:34<00:14, 284.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43636/47780 [02:33<00:17, 235.92 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42998/47780 [02:34<00:20, 236.79 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43520/47780 [02:34<00:18, 236.24 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44210/47780 [02:34<00:14, 253.34 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43272/47780 [02:34<00:23, 195.09 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36800/47780 [02:34<00:24, 453.31 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42952/47780 [02:34<00:16, 294.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43669/47780 [02:34<00:14, 282.47 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43022/47780 [02:34<00:20, 234.14 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43544/47780 [02:34<00:18, 234.86 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43661/47780 [02:34<00:18, 219.91 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44236/47780 [02:34<00:14, 245.32 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43292/47780 [02:34<00:23, 191.45 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36846/47780 [02:34<00:24, 440.25 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42983/47780 [02:34<00:16, 291.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43705/47780 [02:34<00:13, 294.13 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43569/47780 [02:34<00:17, 233.95 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43046/47780 [02:34<00:21, 222.23 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43685/47780 [02:34<00:18, 215.71 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44261/47780 [02:34<00:14, 243.80 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43313/47780 [02:34<00:23, 192.78 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36896/47780 [02:34<00:24, 452.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43018/47780 [02:34<00:15, 298.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43736/47780 [02:34<00:13, 295.63 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43593/47780 [02:34<00:19, 218.64 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44289/47780 [02:34<00:14, 248.00 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43333/47780 [02:34<00:23, 190.27 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36961/47780 [02:34<00:21, 507.36 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43070/47780 [02:34<00:22, 209.16 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43707/47780 [02:34<00:20, 203.10 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43055/47780 [02:34<00:15, 311.11 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43767/47780 [02:34<00:13, 296.07 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44317/47780 [02:34<00:13, 252.35 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43616/47780 [02:34<00:19, 214.58 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43353/47780 [02:34<00:23, 186.32 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37013/47780 [02:34<00:21, 497.17 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43728/47780 [02:34<00:20, 195.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43092/47780 [02:34<00:24, 195.06 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43090/47780 [02:34<00:14, 318.24 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43798/47780 [02:34<00:14, 281.99 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44343/47780 [02:34<00:13, 253.68 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43373/47780 [02:34<00:23, 186.57 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43638/47780 [02:34<00:20, 206.24 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37063/47780 [02:34<00:22, 474.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43129/47780 [02:34<00:13, 334.78 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43114/47780 [02:34<00:24, 192.17 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43748/47780 [02:34<00:22, 177.69 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43833/47780 [02:34<00:13, 299.97 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44370/47780 [02:34<00:13, 246.00 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43402/47780 [02:34<00:20, 214.89 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43660/47780 [02:34<00:20, 204.37 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37117/47780 [02:34<00:21, 487.26 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43165/47780 [02:34<00:13, 340.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43139/47780 [02:34<00:22, 206.81 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43771/47780 [02:34<00:22, 179.93 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43866/47780 [02:34<00:13, 297.80 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44397/47780 [02:34<00:13, 249.41 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43428/47780 [02:34<00:19, 224.20 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43693/47780 [02:34<00:17, 231.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37168/47780 [02:34<00:22, 475.85 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43200/47780 [02:34<00:13, 330.65 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43162/47780 [02:34<00:22, 203.73 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43794/47780 [02:34<00:20, 190.79 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43902/47780 [02:34<00:12, 305.32 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43451/47780 [02:34<00:19, 222.81 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44423/47780 [02:34<00:13, 241.76 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37222/47780 [02:34<00:21, 486.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43717/47780 [02:35<00:17, 226.80 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43183/47780 [02:34<00:22, 205.15 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43234/47780 [02:34<00:13, 328.24 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43817/47780 [02:34<00:20, 189.93 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43474/47780 [02:35<00:19, 224.45 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37271/47780 [02:35<00:21, 485.62 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43740/47780 [02:35<00:17, 226.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43933/47780 [02:35<00:14, 262.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44448/47780 [02:35<00:14, 225.23 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43205/47780 [02:35<00:21, 208.83 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43267/47780 [02:35<00:14, 311.09 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43837/47780 [02:35<00:20, 191.85 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43497/47780 [02:35<00:19, 224.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43961/47780 [02:35<00:14, 263.64 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43763/47780 [02:35<00:18, 218.98 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37321/47780 [02:35<00:22, 468.29 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44473/47780 [02:35<00:14, 223.82 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43232/47780 [02:35<00:20, 219.76 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43299/47780 [02:35<00:14, 306.35 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43857/47780 [02:35<00:21, 182.07 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43520/47780 [02:35<00:19, 215.07 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43989/47780 [02:35<00:14, 265.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37384/47780 [02:35<00:20, 513.37 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44496/47780 [02:35<00:14, 225.13 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43786/47780 [02:35<00:18, 211.64 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43258/47780 [02:35<00:19, 227.53 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43330/47780 [02:35<00:15, 293.83 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43877/47780 [02:35<00:22, 177.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43552/47780 [02:35<00:17, 236.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37438/47780 [02:35<00:20, 511.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44017/47780 [02:35<00:14, 259.36 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44520/47780 [02:35<00:14, 225.41 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43811/47780 [02:35<00:18, 219.73 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43285/47780 [02:35<00:19, 234.37 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43360/47780 [02:35<00:16, 275.01 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43901/47780 [02:35<00:20, 188.02 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43585/47780 [02:35<00:16, 257.10 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44049/47780 [02:35<00:13, 274.89 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44548/47780 [02:35<00:13, 237.77 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43835/47780 [02:35<00:17, 222.98 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37490/47780 [02:35<00:21, 488.98 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43309/47780 [02:35<00:19, 230.70 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43388/47780 [02:35<00:16, 267.48 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43927/47780 [02:35<00:18, 206.06 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43611/47780 [02:35<00:16, 245.65 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37543/47780 [02:35<00:20, 499.93 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43860/47780 [02:35<00:17, 225.52 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44573/47780 [02:35<00:13, 232.91 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44077/47780 [02:35<00:14, 257.18 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43336/47780 [02:35<00:18, 237.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43948/47780 [02:35<00:18, 206.75 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43416/47780 [02:35<00:17, 244.39 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43636/47780 [02:35<00:17, 235.91 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44597/47780 [02:35<00:13, 232.47 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44110/47780 [02:35<00:13, 276.46 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37594/47780 [02:35<00:21, 477.95 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43883/47780 [02:35<00:17, 219.37 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43364/47780 [02:35<00:18, 235.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43969/47780 [02:35<00:19, 194.01 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43445/47780 [02:35<00:17, 251.50 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43661/47780 [02:35<00:17, 233.75 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37650/47780 [02:35<00:20, 498.02 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44621/47780 [02:35<00:13, 228.75 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43906/47780 [02:35<00:17, 216.59 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44139/47780 [02:35<00:13, 266.11 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43392/47780 [02:35<00:17, 247.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43993/47780 [02:35<00:18, 205.16 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43478/47780 [02:35<00:15, 270.56 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43685/47780 [02:35<00:17, 231.71 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44654/47780 [02:35<00:12, 249.29 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43935/47780 [02:36<00:16, 232.95 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44169/47780 [02:35<00:13, 268.13 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37701/47780 [02:35<00:21, 470.50 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43418/47780 [02:35<00:18, 232.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44019/47780 [02:35<00:17, 219.08 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43709/47780 [02:36<00:17, 233.07 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43508/47780 [02:35<00:16, 265.23 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43959/47780 [02:36<00:16, 229.71 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44199/47780 [02:36<00:12, 276.93 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37755/47780 [02:36<00:20, 485.00 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44688/47780 [02:36<00:12, 253.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43447/47780 [02:36<00:17, 243.30 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44042/47780 [02:36<00:17, 213.89 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43733/47780 [02:36<00:18, 224.65 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44229/47780 [02:36<00:12, 280.59 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37806/47780 [02:36<00:20, 487.51 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43535/47780 [02:36<00:16, 253.26 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44718/47780 [02:36<00:11, 265.02 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43983/47780 [02:36<00:17, 217.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43473/47780 [02:36<00:17, 244.97 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44073/47780 [02:36<00:15, 240.06 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37865/47780 [02:36<00:19, 515.80 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43758/47780 [02:36<00:17, 226.64 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43562/47780 [02:36<00:16, 257.32 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44258/47780 [02:36<00:12, 279.40 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44745/47780 [02:36<00:11, 265.45 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44005/47780 [02:36<00:17, 213.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43502/47780 [02:36<00:16, 254.71 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44099/47780 [02:36<00:15, 240.19 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44287/47780 [02:36<00:12, 278.79 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43783/47780 [02:36<00:17, 228.41 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37917/47780 [02:36<00:19, 502.18 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43588/47780 [02:36<00:17, 240.25 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43534/47780 [02:36<00:15, 270.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44028/47780 [02:36<00:18, 208.18 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44772/47780 [02:36<00:13, 220.77 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44125/47780 [02:36<00:15, 234.41 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44320/47780 [02:36<00:11, 289.58 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37978/47780 [02:36<00:18, 532.19 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43806/47780 [02:36<00:17, 225.96 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43572/47780 [02:36<00:14, 298.12 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43614/47780 [02:36<00:17, 237.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44050/47780 [02:36<00:18, 203.31 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44796/47780 [02:36<00:13, 218.92 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44150/47780 [02:36<00:15, 236.32 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44350/47780 [02:36<00:11, 286.91 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38033/47780 [02:36<00:19, 511.69 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43829/47780 [02:36<00:18, 217.08 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43602/47780 [02:36<00:14, 298.43 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44071/47780 [02:36<00:18, 200.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43638/47780 [02:36<00:18, 219.21 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44178/47780 [02:36<00:14, 243.72 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44827/47780 [02:36<00:12, 235.14 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44381/47780 [02:36<00:11, 283.62 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38085/47780 [02:36<00:19, 502.79 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43851/47780 [02:36<00:19, 204.30 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43632/47780 [02:36<00:14, 280.55 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43663/47780 [02:36<00:18, 224.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44097/47780 [02:36<00:17, 207.91 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44203/47780 [02:36<00:14, 242.74 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44411/47780 [02:36<00:11, 287.79 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44859/47780 [02:36<00:12, 235.28 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38136/47780 [02:36<00:19, 487.77 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43883/47780 [02:36<00:16, 235.75 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43664/47780 [02:36<00:14, 287.46 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44127/47780 [02:36<00:15, 232.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43686/47780 [02:36<00:18, 221.61 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44229/47780 [02:36<00:14, 239.50 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44440/47780 [02:36<00:12, 273.55 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44897/47780 [02:36<00:10, 266.76 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43911/47780 [02:36<00:15, 242.87 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38187/47780 [02:36<00:20, 472.82 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43693/47780 [02:36<00:14, 281.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43714/47780 [02:36<00:17, 236.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44151/47780 [02:37<00:16, 225.30 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44254/47780 [02:36<00:15, 228.72 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43938/47780 [02:37<00:15, 249.82 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44926/47780 [02:36<00:10, 267.22 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38235/47780 [02:37<00:20, 469.86 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44468/47780 [02:37<00:13, 252.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43738/47780 [02:37<00:17, 230.83 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44177/47780 [02:37<00:15, 227.11 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43722/47780 [02:37<00:16, 250.02 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44288/47780 [02:37<00:13, 257.91 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43973/47780 [02:37<00:13, 276.72 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44958/47780 [02:37<00:10, 277.56 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38283/47780 [02:37<00:20, 459.66 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44499/47780 [02:37<00:12, 266.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43766/47780 [02:37<00:16, 243.34 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44200/47780 [02:37<00:15, 225.31 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43748/47780 [02:37<00:16, 246.33 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44006/47780 [02:37<00:13, 288.03 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38338/47780 [02:37<00:19, 483.35 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44527/47780 [02:37<00:12, 269.16 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44315/47780 [02:37<00:14, 232.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43792/47780 [02:37<00:16, 247.65 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44987/47780 [02:37<00:10, 254.45 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44224/47780 [02:37<00:15, 226.66 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43783/47780 [02:37<00:14, 272.52 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38398/47780 [02:37<00:18, 509.97 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44555/47780 [02:37<00:11, 272.03 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44035/47780 [02:37<00:14, 267.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43821/47780 [02:37<00:15, 258.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44340/47780 [02:37<00:15, 227.23 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45015/47780 [02:37<00:10, 251.94 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44252/47780 [02:37<00:15, 234.21 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43812/47780 [02:37<00:14, 274.42 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38450/47780 [02:37<00:18, 500.57 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44583/47780 [02:37<00:12, 255.98 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44365/47780 [02:37<00:14, 232.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43848/47780 [02:37<00:15, 251.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44063/47780 [02:37<00:14, 255.28 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44278/47780 [02:37<00:14, 234.47 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43855/47780 [02:37<00:12, 315.70 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45041/47780 [02:37<00:11, 232.08 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38502/47780 [02:37<00:18, 491.71 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44611/47780 [02:37<00:12, 261.89 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44390/47780 [02:37<00:14, 235.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43880/47780 [02:37<00:14, 269.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44089/47780 [02:37<00:14, 253.57 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43894/47780 [02:37<00:11, 336.50 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44313/47780 [02:37<00:13, 260.07 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45065/47780 [02:37<00:12, 214.34 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44414/47780 [02:37<00:14, 236.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38552/47780 [02:37<00:19, 472.30 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44639/47780 [02:37<00:12, 250.01 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43908/47780 [02:37<00:15, 247.49 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44340/47780 [02:37<00:13, 260.16 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44115/47780 [02:37<00:15, 233.96 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43929/47780 [02:37<00:12, 317.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45087/47780 [02:37<00:12, 213.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44449/47780 [02:37<00:12, 257.46 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38600/47780 [02:37<00:20, 453.34 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44668/47780 [02:37<00:12, 254.07 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44367/47780 [02:37<00:13, 260.61 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44139/47780 [02:37<00:15, 229.34 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43963/47780 [02:37<00:12, 315.68 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43937/47780 [02:37<00:16, 235.56 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45111/47780 [02:37<00:12, 215.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44479/47780 [02:37<00:12, 267.06 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38655/47780 [02:37<00:19, 479.80 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44694/47780 [02:37<00:12, 250.14 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44163/47780 [02:37<00:16, 222.93 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43997/47780 [02:37<00:11, 318.88 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44394/47780 [02:38<00:13, 247.44 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43962/47780 [02:37<00:16, 230.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45142/47780 [02:37<00:11, 239.46 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44506/47780 [02:37<00:12, 261.37 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38704/47780 [02:37<00:19, 462.90 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44723/47780 [02:37<00:11, 261.13 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44030/47780 [02:38<00:11, 318.75 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44424/47780 [02:38<00:13, 255.01 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44186/47780 [02:38<00:16, 221.54 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43986/47780 [02:38<00:16, 231.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45168/47780 [02:38<00:10, 240.39 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44542/47780 [02:38<00:11, 283.84 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38770/47780 [02:38<00:17, 517.02 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44756/47780 [02:38<00:11, 274.65 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44209/47780 [02:38<00:16, 220.32 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44453/47780 [02:38<00:12, 258.60 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44063/47780 [02:38<00:12, 309.25 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45205/47780 [02:38<00:09, 275.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44014/47780 [02:38<00:15, 237.20 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44578/47780 [02:38<00:10, 297.79 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38823/47780 [02:38<00:17, 500.03 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44790/47780 [02:38<00:10, 284.10 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44234/47780 [02:38<00:15, 228.36 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45239/47780 [02:38<00:08, 293.56 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44046/47780 [02:38<00:14, 256.87 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44095/47780 [02:38<00:12, 291.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44479/47780 [02:38<00:13, 240.65 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44615/47780 [02:38<00:10, 316.21 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38874/47780 [02:38<00:17, 495.40 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44821/47780 [02:38<00:10, 283.92 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44257/47780 [02:38<00:15, 221.64 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45270/47780 [02:38<00:08, 291.64 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44078/47780 [02:38<00:14, 263.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44125/47780 [02:38<00:13, 277.04 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44504/47780 [02:38<00:14, 224.94 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38925/47780 [02:38<00:18, 487.25 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44647/47780 [02:38<00:10, 287.07 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44850/47780 [02:38<00:11, 262.46 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44284/47780 [02:38<00:15, 229.89 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45300/47780 [02:38<00:08, 289.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44109/47780 [02:38<00:13, 272.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44155/47780 [02:38<00:13, 277.73 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44527/47780 [02:38<00:15, 210.89 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38975/47780 [02:38<00:18, 488.94 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44678/47780 [02:38<00:11, 271.89 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44314/47780 [02:38<00:14, 239.01 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45336/47780 [02:38<00:07, 308.48 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44877/47780 [02:38<00:11, 249.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44137/47780 [02:38<00:13, 269.07 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39025/47780 [02:38<00:18, 485.30 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44553/47780 [02:38<00:14, 217.24 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44183/47780 [02:38<00:14, 249.73 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44338/47780 [02:38<00:14, 236.64 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44710/47780 [02:38<00:11, 272.99 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44167/47780 [02:38<00:13, 277.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45368/47780 [02:38<00:08, 287.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44903/47780 [02:38<00:12, 235.50 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39079/47780 [02:38<00:17, 499.07 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44213/47780 [02:38<00:13, 258.96 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44587/47780 [02:38<00:13, 240.08 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44364/47780 [02:38<00:14, 239.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44739/47780 [02:38<00:11, 268.85 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44927/47780 [02:38<00:12, 232.46 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44196/47780 [02:38<00:13, 266.62 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45398/47780 [02:38<00:08, 284.49 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39130/47780 [02:38<00:17, 484.18 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44624/47780 [02:38<00:11, 272.71 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44246/47780 [02:38<00:13, 267.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44392/47780 [02:38<00:13, 243.87 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45432/47780 [02:38<00:07, 298.75 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44960/47780 [02:38<00:11, 254.64 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44223/47780 [02:38<00:13, 255.76 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39185/47780 [02:38<00:17, 484.61 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44655/47780 [02:39<00:11, 278.53 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44275/47780 [02:38<00:13, 267.94 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44767/47780 [02:38<00:13, 218.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44426/47780 [02:39<00:12, 265.75 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44993/47780 [02:39<00:10, 273.80 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44252/47780 [02:39<00:13, 264.64 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45463/47780 [02:39<00:08, 271.63 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39234/47780 [02:39<00:18, 468.02 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44684/47780 [02:39<00:11, 272.48 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44306/47780 [02:39<00:12, 274.13 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44792/47780 [02:39<00:13, 221.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44456/47780 [02:39<00:12, 271.51 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45025/47780 [02:39<00:09, 280.60 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44279/47780 [02:39<00:13, 256.34 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39304/47780 [02:39<00:15, 529.92 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44339/47780 [02:39<00:11, 288.94 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45492/47780 [02:39<00:08, 260.00 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44712/47780 [02:39<00:11, 257.49 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44816/47780 [02:39<00:13, 217.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44486/47780 [02:39<00:12, 272.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45054/47780 [02:39<00:09, 279.87 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44312/47780 [02:39<00:12, 273.05 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44370/47780 [02:39<00:12, 273.89 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44839/47780 [02:39<00:13, 220.50 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45519/47780 [02:39<00:09, 235.50 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39359/47780 [02:39<00:18, 463.72 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45083/47780 [02:39<00:09, 280.19 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44516/47780 [02:39<00:12, 259.15 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44739/47780 [02:39<00:13, 229.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44341/47780 [02:39<00:12, 271.72 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45546/47780 [02:39<00:09, 242.45 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44398/47780 [02:39<00:13, 258.40 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44862/47780 [02:39<00:14, 206.04 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45112/47780 [02:39<00:09, 271.79 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44372/47780 [02:39<00:12, 279.82 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44763/47780 [02:39<00:13, 219.98 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39408/47780 [02:39<00:20, 412.78 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44543/47780 [02:39<00:14, 230.22 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45571/47780 [02:39<00:09, 239.76 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44429/47780 [02:39<00:12, 261.99 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44889/47780 [02:39<00:13, 219.80 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45141/47780 [02:39<00:09, 275.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44403/47780 [02:39<00:11, 288.31 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44786/47780 [02:39<00:13, 218.05 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39452/47780 [02:39<00:20, 409.60 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44567/47780 [02:39<00:14, 219.31 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45600/47780 [02:39<00:08, 248.20 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45175/47780 [02:39<00:08, 293.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44456/47780 [02:39<00:13, 251.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44441/47780 [02:39<00:10, 309.59 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44912/47780 [02:39<00:13, 208.49 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44809/47780 [02:39<00:13, 218.98 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39502/47780 [02:39<00:19, 425.11 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45628/47780 [02:39<00:08, 255.69 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44590/47780 [02:39<00:15, 205.81 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45205/47780 [02:39<00:08, 290.46 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44486/47780 [02:39<00:12, 263.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44477/47780 [02:39<00:10, 322.62 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44938/47780 [02:39<00:13, 215.87 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44832/47780 [02:39<00:13, 214.85 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39547/47780 [02:39<00:20, 403.06 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45657/47780 [02:39<00:08, 265.01 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44611/47780 [02:39<00:15, 203.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44516/47780 [02:39<00:12, 266.36 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44514/47780 [02:39<00:09, 327.97 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45235/47780 [02:39<00:09, 272.43 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44968/47780 [02:39<00:12, 233.48 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44856/47780 [02:39<00:13, 217.11 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39589/47780 [02:39<00:20, 404.21 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45686/47780 [02:39<00:07, 272.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44632/47780 [02:39<00:15, 203.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44545/47780 [02:39<00:11, 269.88 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44550/47780 [02:39<00:09, 336.13 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45263/47780 [02:39<00:09, 269.82 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44992/47780 [02:39<00:12, 229.58 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44883/47780 [02:40<00:12, 226.72 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39636/47780 [02:40<00:19, 418.80 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44659/47780 [02:40<00:14, 219.30 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44580/47780 [02:40<00:10, 292.26 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44586/47780 [02:40<00:09, 336.58 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45716/47780 [02:40<00:08, 246.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45291/47780 [02:40<00:09, 271.62 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44909/47780 [02:40<00:12, 235.79 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45016/47780 [02:40<00:13, 205.86 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39679/47780 [02:40<00:20, 392.36 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44689/47780 [02:40<00:13, 231.31 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44610/47780 [02:40<00:10, 288.88 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44620/47780 [02:40<00:09, 337.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45742/47780 [02:40<00:08, 249.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45319/47780 [02:40<00:09, 261.00 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44937/47780 [02:40<00:11, 244.25 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45038/47780 [02:40<00:13, 205.20 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39724/47780 [02:40<00:19, 406.56 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44644/47780 [02:40<00:10, 302.81 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44654/47780 [02:40<00:09, 332.33 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44719/47780 [02:40<00:12, 240.91 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45772/47780 [02:40<00:07, 260.48 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44964/47780 [02:40<00:11, 249.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45346/47780 [02:40<00:09, 249.81 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39769/47780 [02:40<00:19, 416.48 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45060/47780 [02:40<00:13, 202.21 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44679/47780 [02:40<00:09, 314.77 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44689/47780 [02:40<00:09, 335.20 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45799/47780 [02:40<00:07, 253.15 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44744/47780 [02:40<00:13, 227.45 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44990/47780 [02:40<00:11, 239.43 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45372/47780 [02:40<00:10, 237.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39818/47780 [02:40<00:18, 434.60 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45082/47780 [02:40<00:13, 198.86 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44771/47780 [02:40<00:12, 237.72 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44711/47780 [02:40<00:10, 287.47 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44723/47780 [02:40<00:09, 307.57 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45825/47780 [02:40<00:08, 242.94 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45016/47780 [02:40<00:11, 239.82 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45397/47780 [02:40<00:10, 235.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39868/47780 [02:40<00:17, 450.12 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45103/47780 [02:40<00:13, 195.00 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44811/47780 [02:40<00:10, 278.29 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44758/47780 [02:40<00:09, 317.54 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44741/47780 [02:40<00:10, 282.56 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45046/47780 [02:40<00:10, 256.25 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45851/47780 [02:40<00:08, 230.40 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45424/47780 [02:40<00:09, 242.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39916/47780 [02:40<00:17, 454.09 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45124/47780 [02:40<00:13, 193.27 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44779/47780 [02:40<00:09, 308.49 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44840/47780 [02:40<00:10, 275.54 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45072/47780 [02:40<00:10, 251.28 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44792/47780 [02:40<00:10, 296.87 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39972/47780 [02:40<00:16, 483.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45449/47780 [02:40<00:09, 238.55 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45878/47780 [02:40<00:08, 224.47 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45147/47780 [02:40<00:13, 199.11 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44815/47780 [02:40<00:09, 312.46 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44823/47780 [02:40<00:09, 299.63 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44868/47780 [02:40<00:11, 250.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45106/47780 [02:40<00:10, 263.87 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40021/47780 [02:40<00:16, 472.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45903/47780 [02:40<00:08, 230.68 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45473/47780 [02:40<00:10, 223.59 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45172/47780 [02:40<00:12, 210.99 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44859/47780 [02:40<00:09, 316.21 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44847/47780 [02:40<00:09, 300.40 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45134/47780 [02:41<00:09, 264.62 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44900/47780 [02:40<00:11, 261.77 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45927/47780 [02:40<00:08, 221.94 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45496/47780 [02:40<00:10, 222.62 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40070/47780 [02:41<00:18, 427.16 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45194/47780 [02:40<00:12, 201.84 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44880/47780 [02:41<00:09, 307.80 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44900/47780 [02:41<00:08, 339.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44928/47780 [02:41<00:10, 266.43 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45161/47780 [02:41<00:10, 256.71 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45520/47780 [02:41<00:10, 221.35 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40119/47780 [02:41<00:17, 444.07 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45952/47780 [02:41<00:08, 211.16 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45216/47780 [02:41<00:12, 206.02 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44912/47780 [02:41<00:09, 306.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44938/47780 [02:41<00:08, 344.83 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45194/47780 [02:41<00:09, 260.43 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45550/47780 [02:41<00:09, 240.65 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44955/47780 [02:41<00:11, 242.64 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40166/47780 [02:41<00:17, 447.88 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45237/47780 [02:41<00:12, 198.82 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44943/47780 [02:41<00:09, 307.22 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44977/47780 [02:41<00:07, 352.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45974/47780 [02:41<00:09, 185.76 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45221/47780 [02:41<00:09, 261.55 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45581/47780 [02:41<00:08, 250.54 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40213/47780 [02:41<00:17, 425.06 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45259/47780 [02:41<00:12, 204.01 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44980/47780 [02:41<00:12, 216.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44977/47780 [02:41<00:08, 312.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45999/47780 [02:41<00:09, 196.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45013/47780 [02:41<00:08, 330.18 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45248/47780 [02:41<00:09, 259.47 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45612/47780 [02:41<00:08, 267.08 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40263/47780 [02:41<00:17, 434.34 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45005/47780 [02:41<00:12, 223.72 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45280/47780 [02:41<00:12, 198.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45009/47780 [02:41<00:08, 314.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45047/47780 [02:41<00:08, 329.91 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46020/47780 [02:41<00:09, 194.26 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45274/47780 [02:41<00:09, 255.85 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45639/47780 [02:41<00:08, 263.50 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40313/47780 [02:41<00:16, 441.72 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45032/47780 [02:41<00:11, 233.35 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45302/47780 [02:41<00:12, 198.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45058/47780 [02:41<00:07, 353.29 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46040/47780 [02:41<00:09, 183.14 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45300/47780 [02:41<00:09, 248.18 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45081/47780 [02:41<00:08, 300.78 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45666/47780 [02:41<00:08, 243.48 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40368/47780 [02:41<00:16, 451.37 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45323/47780 [02:41<00:12, 199.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45095/47780 [02:41<00:07, 339.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45056/47780 [02:41<00:12, 212.97 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45325/47780 [02:41<00:09, 248.32 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46069/47780 [02:41<00:08, 208.90 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45696/47780 [02:41<00:08, 252.51 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40418/47780 [02:41<00:15, 461.12 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45112/47780 [02:41<00:09, 269.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45129/47780 [02:41<00:07, 335.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45343/47780 [02:41<00:13, 184.29 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45078/47780 [02:41<00:12, 208.20 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46092/47780 [02:41<00:08, 209.27 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45353/47780 [02:41<00:09, 248.85 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40465/47780 [02:41<00:16, 450.47 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45722/47780 [02:41<00:08, 241.14 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45144/47780 [02:41<00:09, 269.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45362/47780 [02:41<00:13, 184.40 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45101/47780 [02:41<00:12, 213.93 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45163/47780 [02:41<00:08, 314.06 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45378/47780 [02:42<00:09, 247.56 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46117/47780 [02:41<00:08, 198.21 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45755/47780 [02:41<00:07, 264.08 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40512/47780 [02:41<00:16, 449.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45172/47780 [02:41<00:09, 266.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45382/47780 [02:41<00:12, 186.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45133/47780 [02:42<00:11, 240.28 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45196/47780 [02:42<00:08, 311.94 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45406/47780 [02:42<00:09, 256.22 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40559/47780 [02:42<00:16, 435.89 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45199/47780 [02:42<00:09, 261.99 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45782/47780 [02:42<00:08, 245.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45158/47780 [02:42<00:10, 241.64 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45401/47780 [02:42<00:13, 180.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46138/47780 [02:42<00:09, 178.75 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45228/47780 [02:42<00:08, 308.44 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45439/47780 [02:42<00:08, 275.66 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40611/47780 [02:42<00:15, 454.64 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45230/47780 [02:42<00:09, 272.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45810/47780 [02:42<00:07, 249.38 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45420/47780 [02:42<00:13, 174.21 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45185/47780 [02:42<00:11, 226.68 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45259/47780 [02:42<00:08, 285.93 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46157/47780 [02:42<00:09, 162.88 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45467/47780 [02:42<00:09, 237.88 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45258/47780 [02:42<00:09, 268.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40657/47780 [02:42<00:16, 436.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45838/47780 [02:42<00:07, 247.31 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45438/47780 [02:42<00:13, 169.40 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45288/47780 [02:42<00:08, 286.62 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45212/47780 [02:42<00:11, 229.68 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46174/47780 [02:42<00:09, 163.59 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45492/47780 [02:42<00:09, 233.45 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45289/47780 [02:42<00:09, 270.79 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40701/47780 [02:42<00:16, 419.06 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45461/47780 [02:42<00:12, 182.07 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45242/47780 [02:42<00:10, 244.47 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45863/47780 [02:42<00:08, 227.21 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46191/47780 [02:42<00:10, 153.86 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45517/47780 [02:42<00:09, 237.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45318/47780 [02:42<00:09, 254.37 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45321/47780 [02:42<00:09, 269.46 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45485/47780 [02:42<00:11, 198.08 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40744/47780 [02:42<00:17, 391.50 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45887/47780 [02:42<00:08, 229.01 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45275/47780 [02:42<00:09, 253.87 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46214/47780 [02:42<00:09, 168.41 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45345/47780 [02:42<00:09, 254.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45542/47780 [02:42<00:10, 220.69 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45352/47780 [02:42<00:08, 280.08 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40784/47780 [02:42<00:17, 388.67 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45509/47780 [02:42<00:11, 202.56 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45911/47780 [02:42<00:08, 227.87 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45301/47780 [02:42<00:09, 249.45 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46232/47780 [02:42<00:09, 168.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45372/47780 [02:42<00:09, 256.57 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45570/47780 [02:42<00:09, 229.12 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45385/47780 [02:42<00:08, 286.92 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40828/47780 [02:42<00:17, 400.85 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45934/47780 [02:42<00:08, 219.34 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45530/47780 [02:42<00:11, 188.10 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45400/47780 [02:42<00:09, 257.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46250/47780 [02:42<00:09, 163.84 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45606/47780 [02:42<00:08, 264.18 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45327/47780 [02:42<00:11, 215.66 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45414/47780 [02:42<00:08, 281.09 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40869/47780 [02:42<00:18, 383.38 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45962/47780 [02:42<00:07, 235.54 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45550/47780 [02:42<00:12, 177.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45428/47780 [02:42<00:09, 259.07 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46267/47780 [02:42<00:09, 153.50 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45447/47780 [02:42<00:07, 291.89 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45635/47780 [02:43<00:08, 258.48 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45350/47780 [02:43<00:11, 207.60 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40908/47780 [02:42<00:17, 385.02 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45986/47780 [02:43<00:07, 228.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45457/47780 [02:43<00:08, 261.33 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45568/47780 [02:43<00:13, 168.00 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46283/47780 [02:43<00:09, 150.55 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45665/47780 [02:43<00:08, 264.00 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45378/47780 [02:43<00:10, 223.69 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45477/47780 [02:43<00:08, 281.96 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40952/47780 [02:43<00:17, 399.50 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46010/47780 [02:43<00:07, 229.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45485/47780 [02:43<00:08, 259.69 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45593/47780 [02:43<00:11, 185.42 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45696/47780 [02:43<00:07, 275.79 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46304/47780 [02:43<00:08, 164.30 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45508/47780 [02:43<00:08, 283.36 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45401/47780 [02:43<00:10, 216.67 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40993/47780 [02:43<00:17, 379.54 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46034/47780 [02:43<00:07, 224.69 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45622/47780 [02:43<00:10, 212.22 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45525/47780 [02:43<00:07, 286.77 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46321/47780 [02:43<00:08, 165.06 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45537/47780 [02:43<00:07, 284.22 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45726/47780 [02:43<00:07, 267.86 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45424/47780 [02:43<00:11, 208.67 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41038/47780 [02:43<00:17, 383.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46057/47780 [02:43<00:07, 223.52 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45560/47780 [02:43<00:07, 303.79 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45647/47780 [02:43<00:09, 215.15 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46339/47780 [02:43<00:08, 167.06 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45755/47780 [02:43<00:07, 272.30 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45566/47780 [02:43<00:07, 279.03 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41077/47780 [02:43<00:17, 381.11 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46080/47780 [02:43<00:07, 219.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45447/47780 [02:43<00:11, 201.44 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45680/47780 [02:43<00:08, 239.93 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46359/47780 [02:43<00:08, 175.26 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45591/47780 [02:43<00:07, 280.10 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45604/47780 [02:43<00:07, 296.48 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45783/47780 [02:43<00:07, 251.98 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46107/47780 [02:43<00:07, 230.85 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41127/47780 [02:43<00:16, 401.73 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45471/47780 [02:43<00:11, 203.43 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45710/47780 [02:43<00:08, 250.12 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46381/47780 [02:43<00:07, 182.78 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45637/47780 [02:43<00:07, 303.42 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45620/47780 [02:43<00:08, 264.06 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45810/47780 [02:43<00:07, 256.23 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46133/47780 [02:43<00:07, 234.92 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41177/47780 [02:43<00:15, 418.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45492/47780 [02:43<00:11, 202.81 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45681/47780 [02:43<00:06, 337.11 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45647/47780 [02:43<00:08, 262.81 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46401/47780 [02:43<00:08, 171.28 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45837/47780 [02:43<00:07, 259.63 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46158/47780 [02:43<00:06, 238.69 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45738/47780 [02:43<00:09, 226.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41219/47780 [02:43<00:15, 412.85 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45513/47780 [02:43<00:11, 199.85 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45715/47780 [02:43<00:06, 334.18 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45674/47780 [02:43<00:08, 255.46 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46183/47780 [02:43<00:06, 230.37 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41263/47780 [02:43<00:16, 402.21 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45864/47780 [02:43<00:08, 236.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45534/47780 [02:43<00:11, 202.54 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45762/47780 [02:43<00:09, 213.12 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46419/47780 [02:43<00:08, 151.87 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45703/47780 [02:43<00:07, 261.67 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41316/47780 [02:43<00:14, 434.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46212/47780 [02:43<00:06, 238.22 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45749/47780 [02:43<00:06, 293.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45787/47780 [02:43<00:09, 220.98 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45557/47780 [02:44<00:10, 203.50 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46436/47780 [02:43<00:08, 153.85 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45889/47780 [02:44<00:08, 226.32 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45734/47780 [02:44<00:07, 267.64 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41360/47780 [02:44<00:14, 430.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46240/47780 [02:44<00:06, 246.95 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45817/47780 [02:44<00:08, 236.78 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45780/47780 [02:44<00:06, 290.58 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45578/47780 [02:44<00:11, 199.83 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46454/47780 [02:44<00:08, 157.86 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45915/47780 [02:44<00:08, 227.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45763/47780 [02:44<00:07, 270.10 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45845/47780 [02:44<00:07, 244.14 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41404/47780 [02:44<00:15, 409.59 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45605/47780 [02:44<00:09, 217.79 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45811/47780 [02:44<00:06, 285.91 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45953/47780 [02:44<00:06, 268.03 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46476/47780 [02:44<00:07, 169.33 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46266/47780 [02:44<00:06, 225.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45792/47780 [02:44<00:07, 268.58 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41451/47780 [02:44<00:14, 425.18 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45627/47780 [02:44<00:09, 216.33 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46496/47780 [02:44<00:07, 177.42 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45840/47780 [02:44<00:06, 278.65 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45981/47780 [02:44<00:06, 264.34 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45873/47780 [02:44<00:07, 238.38 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46289/47780 [02:44<00:06, 224.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45819/47780 [02:44<00:07, 267.21 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45652/47780 [02:44<00:09, 223.56 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45870/47780 [02:44<00:06, 284.46 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46524/47780 [02:44<00:06, 203.45 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41494/47780 [02:44<00:15, 393.24 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45898/47780 [02:44<00:07, 235.72 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46009/47780 [02:44<00:06, 256.52 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46312/47780 [02:44<00:06, 218.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45846/47780 [02:44<00:07, 260.91 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46549/47780 [02:44<00:05, 215.36 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45901/47780 [02:44<00:06, 284.95 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41536/47780 [02:44<00:15, 397.67 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45676/47780 [02:44<00:09, 211.90 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46039/47780 [02:44<00:06, 261.91 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45924/47780 [02:44<00:08, 230.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46335/47780 [02:44<00:06, 214.50 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45881/47780 [02:44<00:07, 264.87 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41587/47780 [02:44<00:14, 424.27 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46571/47780 [02:44<00:05, 201.85 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45698/47780 [02:44<00:10, 204.59 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45933/47780 [02:44<00:06, 272.90 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46067/47780 [02:44<00:06, 262.38 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46364/47780 [02:44<00:06, 226.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45948/47780 [02:44<00:08, 218.72 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45908/47780 [02:44<00:07, 265.44 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41632/47780 [02:44<00:14, 430.57 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45719/47780 [02:44<00:10, 198.33 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45962/47780 [02:44<00:06, 262.62 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46592/47780 [02:44<00:06, 187.77 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46094/47780 [02:44<00:06, 246.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45971/47780 [02:44<00:08, 214.55 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46387/47780 [02:44<00:07, 198.76 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45935/47780 [02:44<00:06, 264.39 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41684/47780 [02:44<00:13, 448.88 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46613/47780 [02:44<00:06, 189.94 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45989/47780 [02:44<00:07, 252.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46119/47780 [02:45<00:07, 234.17 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45740/47780 [02:44<00:11, 180.49 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45995/47780 [02:44<00:08, 207.74 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46410/47780 [02:44<00:06, 205.22 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45962/47780 [02:44<00:07, 254.10 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41738/47780 [02:44<00:12, 474.91 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46638/47780 [02:44<00:05, 201.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46154/47780 [02:45<00:06, 264.85 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46020/47780 [02:44<00:06, 255.71 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46434/47780 [02:45<00:06, 210.35 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46016/47780 [02:44<00:08, 198.14 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45759/47780 [02:45<00:11, 172.36 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45994/47780 [02:45<00:06, 270.29 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41793/47780 [02:45<00:12, 494.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46672/47780 [02:45<00:04, 237.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46049/47780 [02:45<00:06, 263.99 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46182/47780 [02:45<00:06, 256.00 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45779/47780 [02:45<00:11, 177.99 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46024/47780 [02:45<00:06, 277.02 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41843/47780 [02:45<00:12, 493.75 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46036/47780 [02:45<00:09, 188.99 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46472/47780 [02:45<00:05, 240.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46701/47780 [02:45<00:04, 250.69 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46208/47780 [02:45<00:06, 256.95 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46076/47780 [02:45<00:06, 251.93 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46055/47780 [02:45<00:06, 285.30 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46504/47780 [02:45<00:04, 260.12 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46067/47780 [02:45<00:07, 217.98 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45800/47780 [02:45<00:11, 176.50 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41898/47780 [02:45<00:11, 490.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46730/47780 [02:45<00:04, 259.99 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46236/47780 [02:45<00:05, 259.21 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46102/47780 [02:45<00:06, 251.47 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46084/47780 [02:45<00:06, 270.03 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45821/47780 [02:45<00:10, 179.76 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46090/47780 [02:45<00:08, 210.95 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41951/47780 [02:45<00:12, 478.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46531/47780 [02:45<00:05, 235.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46757/47780 [02:45<00:04, 241.00 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46264/47780 [02:45<00:06, 247.50 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46129/47780 [02:45<00:06, 243.74 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46112/47780 [02:45<00:07, 212.56 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45851/47780 [02:45<00:09, 207.29 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46117/47780 [02:45<00:06, 275.80 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42011/47780 [02:45<00:11, 512.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46556/47780 [02:45<00:05, 236.38 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46290/47780 [02:45<00:06, 245.72 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46782/47780 [02:45<00:04, 223.10 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46134/47780 [02:45<00:07, 213.94 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46146/47780 [02:45<00:05, 276.75 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45872/47780 [02:45<00:09, 203.67 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42063/47780 [02:45<00:11, 492.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46154/47780 [02:45<00:07, 217.07 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46581/47780 [02:45<00:05, 222.62 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46315/47780 [02:45<00:06, 234.47 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46174/47780 [02:45<00:05, 269.31 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45895/47780 [02:45<00:09, 205.54 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46158/47780 [02:45<00:07, 209.87 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42115/47780 [02:45<00:11, 480.83 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46805/47780 [02:45<00:04, 201.56 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46177/47780 [02:45<00:07, 206.87 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46605/47780 [02:45<00:05, 218.11 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46351/47780 [02:45<00:05, 263.33 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46205/47780 [02:45<00:05, 279.48 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46183/47780 [02:45<00:07, 219.30 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45916/47780 [02:45<00:09, 200.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42167/47780 [02:45<00:11, 490.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46826/47780 [02:45<00:04, 193.33 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46199/47780 [02:45<00:08, 195.12 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46629/47780 [02:45<00:05, 208.37 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46382/47780 [02:45<00:05, 271.07 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46236/47780 [02:45<00:05, 286.20 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42217/47780 [02:45<00:11, 489.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45940/47780 [02:45<00:08, 206.08 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46206/47780 [02:45<00:07, 197.52 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46846/47780 [02:45<00:05, 184.64 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46229/47780 [02:45<00:07, 219.13 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46419/47780 [02:46<00:04, 295.45 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46651/47780 [02:46<00:05, 195.13 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46265/47780 [02:46<00:05, 272.24 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45971/47780 [02:46<00:07, 234.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42278/47780 [02:46<00:10, 517.26 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46227/47780 [02:46<00:08, 192.16 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46252/47780 [02:46<00:06, 218.71 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46867/47780 [02:46<00:04, 183.28 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46672/47780 [02:46<00:05, 197.93 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45997/47780 [02:46<00:07, 239.93 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42331/47780 [02:46<00:10, 512.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46293/47780 [02:46<00:05, 268.50 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46450/47780 [02:46<00:05, 256.40 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46248/47780 [02:46<00:07, 193.48 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46279/47780 [02:46<00:06, 232.56 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46888/47780 [02:46<00:04, 187.87 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46023/47780 [02:46<00:07, 243.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46692/47780 [02:46<00:05, 186.78 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46320/47780 [02:46<00:05, 250.56 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42383/47780 [02:46<00:11, 476.61 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46272/47780 [02:46<00:07, 202.61 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46303/47780 [02:46<00:06, 224.78 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46478/47780 [02:46<00:05, 244.59 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46907/47780 [02:46<00:04, 179.58 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46048/47780 [02:46<00:07, 230.24 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46712/47780 [02:46<00:05, 184.38 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46346/47780 [02:46<00:05, 247.15 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42432/47780 [02:46<00:11, 461.72 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46294/47780 [02:46<00:07, 205.62 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46330/47780 [02:46<00:06, 236.26 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46927/47780 [02:46<00:04, 182.22 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46504/47780 [02:46<00:05, 223.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46737/47780 [02:46<00:05, 200.94 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46074/47780 [02:46<00:07, 234.23 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46371/47780 [02:46<00:05, 239.86 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46321/47780 [02:46<00:06, 215.08 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46357/47780 [02:46<00:05, 241.97 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42479/47780 [02:46<00:12, 425.24 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46947/47780 [02:46<00:04, 180.24 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46758/47780 [02:46<00:05, 198.90 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46105/47780 [02:46<00:06, 244.52 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46529/47780 [02:46<00:05, 209.02 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46400/47780 [02:46<00:05, 250.97 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46387/47780 [02:46<00:05, 256.02 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42524/47780 [02:46<00:12, 426.40 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46350/47780 [02:46<00:06, 226.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46975/47780 [02:46<00:03, 203.10 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46130/47780 [02:46<00:06, 245.92 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46779/47780 [02:46<00:05, 193.52 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46553/47780 [02:46<00:05, 212.08 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46426/47780 [02:46<00:05, 234.05 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46413/47780 [02:46<00:05, 249.23 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42568/47780 [02:46<00:12, 423.89 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46381/47780 [02:46<00:05, 245.05 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46998/47780 [02:46<00:03, 210.09 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46161/47780 [02:46<00:06, 262.86 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46576/47780 [02:46<00:05, 215.34 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46799/47780 [02:46<00:05, 182.27 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46459/47780 [02:46<00:05, 253.63 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46439/47780 [02:46<00:05, 239.29 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42613/47780 [02:46<00:12, 407.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46408/47780 [02:46<00:05, 236.07 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46197/47780 [02:46<00:05, 286.73 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47020/47780 [02:46<00:04, 183.89 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46818/47780 [02:46<00:05, 176.82 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46598/47780 [02:47<00:06, 194.92 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46487/47780 [02:46<00:05, 252.99 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42665/47780 [02:46<00:11, 437.69 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46465/47780 [02:46<00:05, 225.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46432/47780 [02:46<00:06, 222.93 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46228/47780 [02:47<00:05, 265.57 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46618/47780 [02:47<00:05, 194.52 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46522/47780 [02:47<00:04, 277.82 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42710/47780 [02:47<00:11, 432.51 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46836/47780 [02:47<00:05, 161.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47040/47780 [02:47<00:04, 157.27 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46455/47780 [02:47<00:06, 208.49 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46489/47780 [02:47<00:06, 208.24 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46256/47780 [02:47<00:05, 259.27 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46641/47780 [02:47<00:05, 202.48 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46551/47780 [02:47<00:04, 276.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42754/47780 [02:47<00:11, 421.14 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47060/47780 [02:47<00:04, 160.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46854/47780 [02:47<00:05, 156.89 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46513/47780 [02:47<00:06, 208.51 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46481/47780 [02:47<00:06, 210.01 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46667/47780 [02:47<00:05, 213.66 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46580/47780 [02:47<00:04, 273.44 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46283/47780 [02:47<00:06, 236.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42797/47780 [02:47<00:12, 402.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47078/47780 [02:47<00:04, 165.05 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46871/47780 [02:47<00:05, 159.79 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46506/47780 [02:47<00:06, 203.24 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46692/47780 [02:47<00:05, 216.70 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42848/47780 [02:47<00:11, 431.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46318/47780 [02:47<00:05, 263.45 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46535/47780 [02:47<00:06, 180.91 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46608/47780 [02:47<00:04, 240.00 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46891/47780 [02:47<00:05, 161.94 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47096/47780 [02:47<00:04, 158.14 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46527/47780 [02:47<00:06, 202.88 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46715/47780 [02:47<00:05, 210.84 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46346/47780 [02:47<00:05, 266.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42900/47780 [02:47<00:10, 449.35 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46911/47780 [02:47<00:05, 171.16 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46635/47780 [02:47<00:04, 236.64 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47114/47780 [02:47<00:04, 156.20 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46554/47780 [02:47<00:07, 163.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46548/47780 [02:47<00:06, 203.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42948/47780 [02:47<00:10, 451.64 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46374/47780 [02:47<00:05, 253.79 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46738/47780 [02:47<00:05, 194.99 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46571/47780 [02:47<00:07, 157.84 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46929/47780 [02:47<00:05, 152.49 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46583/47780 [02:47<00:04, 240.18 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46660/47780 [02:47<00:05, 213.70 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42994/47780 [02:47<00:11, 433.80 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46758/47780 [02:47<00:05, 195.07 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46411/47780 [02:47<00:05, 272.80 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47130/47780 [02:47<00:05, 125.24 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46589/47780 [02:47<00:07, 162.64 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46611/47780 [02:47<00:04, 245.24 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46947/47780 [02:47<00:05, 150.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46684/47780 [02:47<00:05, 209.09 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43046/47780 [02:47<00:10, 457.27 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46778/47780 [02:47<00:05, 190.98 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46439/47780 [02:47<00:05, 254.54 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46613/47780 [02:47<00:06, 176.44 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46965/47780 [02:47<00:05, 155.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47144/47780 [02:47<00:05, 112.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46636/47780 [02:47<00:04, 230.79 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46706/47780 [02:47<00:05, 203.04 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43093/47780 [02:47<00:10, 454.90 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46799/47780 [02:48<00:05, 186.79 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46467/47780 [02:47<00:05, 252.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46632/47780 [02:47<00:06, 178.62 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46982/47780 [02:48<00:05, 150.28 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46727/47780 [02:48<00:05, 197.92 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47157/47780 [02:48<00:05, 106.75 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46821/47780 [02:48<00:04, 193.58 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43142/47780 [02:48<00:11, 406.15 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46663/47780 [02:48<00:05, 204.90 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46493/47780 [02:48<00:05, 248.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46652/47780 [02:48<00:06, 173.21 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46752/47780 [02:48<00:04, 208.57 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46998/47780 [02:48<00:05, 140.23 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46843/47780 [02:48<00:04, 198.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47171/47780 [02:48<00:05, 105.95 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43191/47780 [02:48<00:10, 420.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46685/47780 [02:48<00:05, 206.57 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46518/47780 [02:48<00:05, 221.86 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46774/47780 [02:48<00:04, 209.74 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46671/47780 [02:48<00:06, 160.63 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46865/47780 [02:48<00:04, 200.41 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47013/47780 [02:48<00:05, 134.69 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43250/47780 [02:48<00:09, 463.84 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47184/47780 [02:48<00:05, 106.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46709/47780 [02:48<00:05, 202.42 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46541/47780 [02:48<00:05, 222.71 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46688/47780 [02:48<00:06, 162.86 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46800/47780 [02:48<00:04, 219.74 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46887/47780 [02:48<00:04, 201.32 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43298/47780 [02:48<00:09, 453.81 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47027/47780 [02:48<00:06, 124.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47196/47780 [02:48<00:05, 104.54 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46732/47780 [02:48<00:05, 196.38 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46709/47780 [02:48<00:06, 174.00 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46829/47780 [02:48<00:03, 238.44 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46564/47780 [02:48<00:05, 211.87 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46909/47780 [02:48<00:04, 206.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43348/47780 [02:48<00:09, 463.12 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47210/47780 [02:48<00:05, 109.44 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46752/47780 [02:48<00:05, 193.74 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47040/47780 [02:48<00:06, 117.82 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46856/47780 [02:48<00:03, 246.12 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46591/47780 [02:48<00:05, 222.74 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46727/47780 [02:48<00:06, 153.79 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43396/47780 [02:48<00:09, 447.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46930/47780 [02:48<00:04, 189.91 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46772/47780 [02:48<00:05, 190.08 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47228/47780 [02:48<00:04, 121.73 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47053/47780 [02:48<00:06, 117.03 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46881/47780 [02:48<00:03, 244.48 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46614/47780 [02:48<00:05, 220.70 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43447/47780 [02:48<00:09, 457.82 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46746/47780 [02:48<00:06, 156.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46952/47780 [02:48<00:04, 190.38 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46796/47780 [02:48<00:04, 203.30 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47066/47780 [02:48<00:05, 119.15 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47243/47780 [02:48<00:04, 124.44 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46906/47780 [02:48<00:03, 225.86 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46637/47780 [02:48<00:05, 206.00 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46763/47780 [02:48<00:06, 159.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43498/47780 [02:48<00:09, 461.78 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46975/47780 [02:48<00:04, 195.29 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46817/47780 [02:48<00:04, 198.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47258/47780 [02:48<00:04, 129.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47082/47780 [02:48<00:05, 122.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46661/47780 [02:48<00:05, 208.70 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46929/47780 [02:48<00:04, 199.30 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46782/47780 [02:48<00:06, 159.45 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43547/47780 [02:48<00:09, 453.20 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46996/47780 [02:49<00:03, 197.12 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47272/47780 [02:48<00:03, 130.85 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47095/47780 [02:48<00:05, 124.48 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46838/47780 [02:48<00:05, 187.00 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46685/47780 [02:49<00:05, 215.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46800/47780 [02:49<00:05, 164.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46950/47780 [02:49<00:04, 199.64 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47017/47780 [02:49<00:03, 198.05 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43595/47780 [02:49<00:09, 447.97 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47287/47780 [02:49<00:03, 134.09 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47109/47780 [02:49<00:05, 123.69 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46709/47780 [02:49<00:04, 217.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46857/47780 [02:49<00:05, 162.66 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47040/47780 [02:49<00:03, 207.07 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46817/47780 [02:49<00:06, 159.56 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46972/47780 [02:49<00:04, 195.73 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43641/47780 [02:49<00:09, 429.24 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47303/47780 [02:49<00:03, 133.90 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46733/47780 [02:49<00:04, 219.05 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47122/47780 [02:49<00:05, 114.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46993/47780 [02:49<00:04, 196.66 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46834/47780 [02:49<00:06, 154.16 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47061/47780 [02:49<00:03, 193.79 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46883/47780 [02:49<00:05, 170.45 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43687/47780 [02:49<00:09, 415.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47317/47780 [02:49<00:03, 124.33 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47013/47780 [02:49<00:03, 195.33 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46853/47780 [02:49<00:05, 163.79 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46757/47780 [02:49<00:05, 195.82 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46902/47780 [02:49<00:05, 171.97 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47135/47780 [02:49<00:06, 102.06 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43731/47780 [02:49<00:09, 409.06 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47083/47780 [02:49<00:03, 175.10 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47330/47780 [02:49<00:03, 120.90 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47150/47780 [02:49<00:05, 112.90 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46876/47780 [02:49<00:05, 170.80 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46920/47780 [02:49<00:05, 170.32 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46780/47780 [02:49<00:05, 188.73 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43773/47780 [02:49<00:10, 381.92 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47033/47780 [02:49<00:04, 168.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47102/47780 [02:49<00:03, 170.26 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47344/47780 [02:49<00:03, 121.38 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47167/47780 [02:49<00:04, 123.54 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46800/47780 [02:49<00:05, 182.70 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43819/47780 [02:49<00:10, 394.05 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46895/47780 [02:49<00:05, 159.51 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46940/47780 [02:49<00:05, 158.84 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47051/47780 [02:49<00:04, 162.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47120/47780 [02:49<00:03, 170.39 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47358/47780 [02:49<00:03, 123.30 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46822/47780 [02:49<00:04, 191.62 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47180/47780 [02:49<00:05, 116.39 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46919/47780 [02:49<00:04, 174.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46959/47780 [02:49<00:05, 163.06 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47138/47780 [02:49<00:03, 161.74 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43860/47780 [02:49<00:11, 348.66 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47371/47780 [02:49<00:03, 113.37 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47068/47780 [02:49<00:04, 143.59 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46846/47780 [02:49<00:04, 203.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47194/47780 [02:49<00:04, 121.42 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46976/47780 [02:49<00:05, 152.60 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46938/47780 [02:49<00:05, 162.22 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47156/47780 [02:49<00:04, 155.46 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43897/47780 [02:49<00:11, 335.90 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46870/47780 [02:49<00:04, 211.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47091/47780 [02:49<00:04, 151.21 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46955/47780 [02:49<00:05, 159.98 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47207/47780 [02:49<00:05, 107.45 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43932/47780 [02:50<00:11, 330.61 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46993/47780 [02:49<00:05, 143.78 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47383/47780 [02:50<00:04, 85.33 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47172/47780 [02:50<00:04, 142.77 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46894/47780 [02:50<00:04, 218.28 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47107/47780 [02:50<00:04, 144.67 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46974/47780 [02:50<00:04, 161.90 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43975/47780 [02:50<00:10, 351.11 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47219/47780 [02:50<00:05, 98.85 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47187/47780 [02:50<00:04, 143.55 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46920/47780 [02:50<00:03, 223.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47008/47780 [02:50<00:05, 132.43 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47123/47780 [02:50<00:04, 135.37 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46991/47780 [02:50<00:04, 158.31 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44011/47780 [02:50<00:11, 331.80 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47230/47780 [02:50<00:05, 95.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47022/47780 [02:50<00:05, 131.02 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46943/47780 [02:50<00:03, 210.03 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47393/47780 [02:50<00:05, 68.24 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47202/47780 [02:50<00:04, 131.69 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47139/47780 [02:50<00:04, 138.60 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47008/47780 [02:50<00:04, 156.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44047/47780 [02:50<00:11, 339.26 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47039/47780 [02:50<00:05, 136.36 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47240/47780 [02:50<00:05, 91.65 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47216/47780 [02:50<00:04, 128.35 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46965/47780 [02:50<00:04, 193.65 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47154/47780 [02:50<00:04, 136.48 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47025/47780 [02:50<00:04, 153.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44084/47780 [02:50<00:11, 333.71 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47053/47780 [02:50<00:05, 132.33 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47233/47780 [02:50<00:03, 137.18 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47401/47780 [02:50<00:06, 54.92 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46985/47780 [02:50<00:04, 188.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47255/47780 [02:50<00:05, 94.53 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47173/47780 [02:50<00:04, 140.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47042/47780 [02:50<00:04, 153.35 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44118/47780 [02:50<00:11, 316.87 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47247/47780 [02:50<00:03, 133.60 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47069/47780 [02:50<00:05, 131.13 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47271/47780 [02:50<00:04, 110.23 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47005/47780 [02:50<00:04, 182.51 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47191/47780 [02:50<00:04, 144.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47064/47780 [02:50<00:04, 166.16 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44156/47780 [02:50<00:11, 323.77 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47408/47780 [02:50<00:07, 49.60 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47261/47780 [02:50<00:03, 133.92 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47085/47780 [02:50<00:05, 138.50 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47285/47780 [02:50<00:04, 113.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47025/47780 [02:50<00:04, 176.44 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47081/47780 [02:50<00:04, 158.31 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47214/47780 [02:50<00:03, 155.52 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44203/47780 [02:50<00:09, 358.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47276/47780 [02:50<00:03, 132.75 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47099/47780 [02:50<00:05, 131.16 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47415/47780 [02:50<00:07, 48.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47044/47780 [02:50<00:04, 176.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47298/47780 [02:50<00:04, 109.25 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47097/47780 [02:50<00:04, 156.95 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47230/47780 [02:50<00:03, 154.04 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44240/47780 [02:50<00:10, 326.82 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47117/47780 [02:50<00:04, 141.91 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47068/47780 [02:50<00:03, 193.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47421/47780 [02:50<00:07, 49.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47290/47780 [02:51<00:04, 115.02 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47310/47780 [02:51<00:04, 99.63 examples/s] 
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44275/47780 [02:51<00:10, 320.51 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47114/47780 [02:51<00:04, 136.51 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47132/47780 [02:51<00:04, 137.12 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47088/47780 [02:51<00:03, 191.29 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47427/47780 [02:51<00:06, 51.17 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47246/47780 [02:51<00:04, 127.75 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47302/47780 [02:51<00:04, 115.69 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47321/47780 [02:51<00:04, 98.94 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44308/47780 [02:51<00:10, 321.42 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47139/47780 [02:51<00:04, 159.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47151/47780 [02:51<00:04, 148.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47433/47780 [02:51<00:06, 52.43 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47110/47780 [02:51<00:03, 191.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47261/47780 [02:51<00:04, 125.88 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47314/47780 [02:51<00:04, 109.12 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47332/47780 [02:51<00:04, 99.15 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44343/47780 [02:51<00:10, 317.90 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47162/47780 [02:51<00:03, 177.17 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47167/47780 [02:51<00:04, 144.38 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47130/47780 [02:51<00:03, 188.10 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47276/47780 [02:51<00:03, 131.51 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47440/47780 [02:51<00:06, 52.81 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47327/47780 [02:51<00:04, 105.38 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47345/47780 [02:51<00:04, 103.87 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47183/47780 [02:51<00:03, 184.34 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44377/47780 [02:51<00:11, 301.00 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47150/47780 [02:51<00:03, 176.29 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47447/47780 [02:51<00:06, 52.99 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47183/47780 [02:51<00:04, 125.59 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47347/47780 [02:51<00:03, 125.36 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47202/47780 [02:51<00:03, 184.75 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47290/47780 [02:51<00:04, 111.27 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44420/47780 [02:51<00:10, 332.51 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47357/47780 [02:51<00:04, 92.62 examples/s] 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47173/47780 [02:51<00:03, 190.64 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47201/47780 [02:51<00:04, 134.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47454/47780 [02:51<00:06, 52.86 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47226/47780 [02:51<00:02, 195.47 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47367/47780 [02:51<00:03, 135.56 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47302/47780 [02:51<00:04, 107.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44454/47780 [02:51<00:10, 310.44 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47367/47780 [02:51<00:04, 86.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47217/47780 [02:51<00:04, 135.44 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47381/47780 [02:51<00:02, 135.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47246/47780 [02:51<00:02, 183.57 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47460/47780 [02:51<00:06, 49.90 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44487/47780 [02:51<00:10, 313.76 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47194/47780 [02:51<00:03, 151.87 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47315/47780 [02:51<00:04, 100.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47231/47780 [02:51<00:04, 131.86 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47377/47780 [02:51<00:04, 81.02 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44530/47780 [02:51<00:09, 337.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47400/47780 [02:51<00:02, 136.28 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47467/47780 [02:51<00:06, 49.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47213/47780 [02:51<00:03, 151.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47265/47780 [02:51<00:03, 157.98 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47326/47780 [02:51<00:04, 95.90 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47251/47780 [02:51<00:03, 144.55 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47386/47780 [02:51<00:04, 79.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44565/47780 [02:51<00:09, 330.14 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47417/47780 [02:52<00:02, 137.91 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47230/47780 [02:51<00:03, 147.83 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47475/47780 [02:51<00:05, 53.53 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47338/47780 [02:52<00:04, 99.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47267/47780 [02:51<00:03, 148.51 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47282/47780 [02:52<00:03, 134.01 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47398/47780 [02:52<00:04, 83.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47431/47780 [02:52<00:02, 129.89 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44599/47780 [02:52<00:10, 299.20 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47482/47780 [02:52<00:05, 56.52 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47349/47780 [02:52<00:04, 101.12 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47247/47780 [02:52<00:03, 137.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47284/47780 [02:52<00:03, 140.98 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47408/47780 [02:52<00:04, 83.53 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47445/47780 [02:52<00:02, 132.26 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44632/47780 [02:52<00:10, 299.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47488/47780 [02:52<00:05, 55.92 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47360/47780 [02:52<00:04, 101.43 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47297/47780 [02:52<00:04, 117.94 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47267/47780 [02:52<00:03, 151.82 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47418/47780 [02:52<00:04, 87.45 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47300/47780 [02:52<00:03, 135.32 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47459/47780 [02:52<00:02, 131.43 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44664/47780 [02:52<00:10, 291.01 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47372/47780 [02:52<00:04, 101.42 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47284/47780 [02:52<00:03, 151.87 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47312/47780 [02:52<00:03, 118.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47499/47780 [02:52<00:04, 62.10 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47428/47780 [02:52<00:03, 89.26 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47317/47780 [02:52<00:03, 141.06 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47473/47780 [02:52<00:02, 125.74 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44697/47780 [02:52<00:10, 290.81 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47383/47780 [02:52<00:03, 99.65 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47326/47780 [02:52<00:03, 118.82 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47303/47780 [02:52<00:03, 148.24 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47507/47780 [02:52<00:04, 60.80 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47334/47780 [02:52<00:03, 144.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47439/47780 [02:52<00:03, 85.32 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44728/47780 [02:52<00:10, 293.76 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47487/47780 [02:52<00:02, 122.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47394/47780 [02:52<00:03, 98.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47321/47780 [02:52<00:02, 155.77 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47339/47780 [02:52<00:03, 115.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47516/47780 [02:52<00:04, 64.85 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47351/47780 [02:52<00:03, 142.14 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47452/47780 [02:52<00:03, 91.27 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44759/47780 [02:52<00:10, 277.56 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47405/47780 [02:52<00:03, 97.95 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47339/47780 [02:52<00:02, 160.37 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47501/47780 [02:52<00:02, 107.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47354/47780 [02:52<00:03, 120.25 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47366/47780 [02:52<00:03, 135.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47462/47780 [02:52<00:03, 91.09 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44788/47780 [02:52<00:11, 259.82 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47525/47780 [02:52<00:04, 58.72 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47357/47780 [02:52<00:02, 160.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47416/47780 [02:52<00:03, 92.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47367/47780 [02:52<00:03, 117.60 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47514/47780 [02:52<00:02, 103.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47474/47780 [02:52<00:03, 96.12 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47381/47780 [02:52<00:03, 127.07 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44815/47780 [02:52<00:11, 248.14 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47377/47780 [02:52<00:02, 167.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47532/47780 [02:52<00:04, 57.32 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47427/47780 [02:52<00:03, 91.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47380/47780 [02:52<00:03, 116.74 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47527/47780 [02:53<00:02, 101.63 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47394/47780 [02:52<00:03, 124.51 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47399/47780 [02:53<00:02, 181.00 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47487/47780 [02:53<00:03, 91.57 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44842/47780 [02:53<00:12, 235.36 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47437/47780 [02:53<00:03, 88.35 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47538/47780 [02:53<00:04, 53.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47393/47780 [02:53<00:03, 110.12 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47408/47780 [02:53<00:02, 125.62 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47540/47780 [02:53<00:02, 100.60 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47419/47780 [02:53<00:02, 177.12 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44870/47780 [02:53<00:12, 237.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47501/47780 [02:53<00:02, 94.61 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47405/47780 [02:53<00:03, 109.46 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47447/47780 [02:53<00:04, 79.32 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47553/47780 [02:53<00:02, 104.97 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47422/47780 [02:53<00:02, 123.44 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47544/47780 [02:53<00:04, 47.78 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47441/47780 [02:53<00:01, 188.97 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44902/47780 [02:53<00:11, 246.43 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47512/47780 [02:53<00:02, 91.89 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47423/47780 [02:53<00:02, 120.09 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47461/47780 [02:53<00:01, 186.65 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47436/47780 [02:53<00:02, 117.69 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47550/47780 [02:53<00:04, 47.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47457/47780 [02:53<00:04, 73.79 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44930/47780 [02:53<00:11, 247.93 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47522/47780 [02:53<00:02, 91.93 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47441/47780 [02:53<00:02, 129.83 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47481/47780 [02:53<00:01, 176.98 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47449/47780 [02:53<00:02, 116.59 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47555/47780 [02:53<00:04, 46.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47465/47780 [02:53<00:04, 73.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47564/47780 [02:53<00:02, 74.96 examples/s] 
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44955/47780 [02:53<00:11, 245.12 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47534/47780 [02:53<00:02, 96.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47457/47780 [02:53<00:02, 130.70 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47562/47780 [02:53<00:04, 49.94 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47499/47780 [02:53<00:01, 164.35 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47463/47780 [02:53<00:02, 112.88 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47475/47780 [02:53<00:04, 75.17 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47544/47780 [02:53<00:02, 94.00 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44981/47780 [02:53<00:12, 221.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47476/47780 [02:53<00:02, 137.95 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47573/47780 [02:53<00:03, 63.01 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47476/47780 [02:53<00:02, 116.21 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47568/47780 [02:53<00:04, 49.02 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47558/47780 [02:53<00:02, 103.33 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47485/47780 [02:53<00:03, 76.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45004/47780 [02:53<00:13, 210.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47516/47780 [02:53<00:02, 130.78 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47491/47780 [02:53<00:02, 129.56 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47573/47780 [02:53<00:04, 45.94 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47492/47780 [02:53<00:02, 114.20 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45026/47780 [02:53<00:13, 208.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47499/47780 [02:53<00:03, 84.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47570/47780 [02:53<00:02, 93.24 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47582/47780 [02:53<00:03, 56.21 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47506/47780 [02:53<00:02, 118.02 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47579/47780 [02:53<00:04, 48.20 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45053/47780 [02:53<00:12, 214.72 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47508/47780 [02:54<00:03, 81.12 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47509/47780 [02:53<00:02, 111.08 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47580/47780 [02:54<00:02, 85.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47532/47780 [02:54<00:02, 99.66 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47519/47780 [02:54<00:02, 113.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45085/47780 [02:54<00:11, 240.26 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47521/47780 [02:54<00:02, 112.69 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47589/47780 [02:54<00:03, 49.17 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47517/47780 [02:54<00:03, 75.40 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47585/47780 [02:54<00:04, 41.45 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47544/47780 [02:54<00:02, 96.67 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45111/47780 [02:54<00:11, 235.17 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47528/47780 [02:54<00:03, 81.46 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47532/47780 [02:54<00:02, 98.40 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47535/47780 [02:54<00:02, 105.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47592/47780 [02:54<00:04, 44.29 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45140/47780 [02:54<00:10, 249.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47598/47780 [02:54<00:03, 47.37 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47555/47780 [02:54<00:02, 90.48 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47590/47780 [02:54<00:03, 56.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47546/47780 [02:54<00:02, 102.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47550/47780 [02:54<00:02, 108.35 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47538/47780 [02:54<00:03, 74.78 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45180/47780 [02:54<00:09, 282.08 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47605/47780 [02:54<00:03, 47.28 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47598/47780 [02:54<00:04, 37.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47567/47780 [02:54<00:02, 87.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47558/47780 [02:54<00:02, 100.81 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47566/47780 [02:54<00:01, 116.49 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45220/47780 [02:54<00:08, 306.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47548/47780 [02:54<00:03, 76.79 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47611/47780 [02:54<00:03, 49.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47598/47780 [02:54<00:03, 48.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47569/47780 [02:54<00:02, 102.05 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47577/47780 [02:54<00:02, 85.24 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47605/47780 [02:54<00:04, 41.37 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47566/47780 [02:54<00:02, 98.43 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45252/47780 [02:54<00:09, 280.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47579/47780 [02:54<00:02, 98.08 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47582/47780 [02:54<00:01, 105.15 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47618/47780 [02:54<00:03, 48.29 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47604/47780 [02:54<00:03, 48.69 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47611/47780 [02:54<00:03, 43.72 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47580/47780 [02:54<00:02, 99.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45286/47780 [02:54<00:08, 281.00 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47586/47780 [02:54<00:02, 71.32 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47594/47780 [02:54<00:01, 102.27 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47625/47780 [02:54<00:03, 50.37 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47610/47780 [02:54<00:03, 47.59 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47616/47780 [02:54<00:03, 43.41 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47591/47780 [02:54<00:02, 88.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45323/47780 [02:54<00:08, 301.93 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47592/47780 [02:54<00:02, 92.24 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47632/47780 [02:55<00:02, 52.60 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47596/47780 [02:55<00:02, 67.49 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47608/47780 [02:54<00:01, 101.24 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45355/47780 [02:54<00:07, 306.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47622/47780 [02:54<00:03, 44.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47617/47780 [02:55<00:03, 47.45 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47601/47780 [02:55<00:02, 75.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47638/47780 [02:55<00:02, 49.36 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47630/47780 [02:55<00:02, 50.13 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45388/47780 [02:55<00:08, 284.79 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47626/47780 [02:55<00:01, 110.72 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47605/47780 [02:55<00:02, 65.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47623/47780 [02:55<00:03, 46.30 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47602/47780 [02:55<00:02, 64.86 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47640/47780 [02:55<00:01, 116.61 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45418/47780 [02:55<00:08, 278.81 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47637/47780 [02:55<00:02, 51.25 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47610/47780 [02:55<00:02, 64.08 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47630/47780 [02:55<00:03, 47.48 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47613/47780 [02:55<00:02, 60.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47644/47780 [02:55<00:03, 42.96 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47655/47780 [02:55<00:01, 121.83 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45451/47780 [02:55<00:08, 287.42 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47643/47780 [02:55<00:02, 50.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47636/47780 [02:55<00:02, 49.36 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47649/47780 [02:55<00:02, 44.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47620/47780 [02:55<00:02, 60.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47611/47780 [02:55<00:02, 56.97 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45487/47780 [02:55<00:07, 305.99 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47617/47780 [02:55<00:02, 56.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47649/47780 [02:55<00:02, 50.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47643/47780 [02:55<00:02, 50.54 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45522/47780 [02:55<00:07, 315.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47627/47780 [02:55<00:02, 58.15 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47668/47780 [02:55<00:01, 95.93 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47654/47780 [02:55<00:03, 39.46 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47626/47780 [02:55<00:02, 59.74 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47618/47780 [02:55<00:03, 52.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47657/47780 [02:55<00:02, 54.46 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45561/47780 [02:55<00:06, 328.27 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47637/47780 [02:55<00:02, 62.69 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47660/47780 [02:55<00:02, 41.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47650/47780 [02:55<00:02, 47.19 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47627/47780 [02:55<00:02, 55.32 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47664/47780 [02:55<00:02, 53.44 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47633/47780 [02:55<00:02, 52.92 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45595/47780 [02:55<00:07, 306.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47679/47780 [02:55<00:01, 74.83 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47645/47780 [02:55<00:02, 58.85 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47655/47780 [02:55<00:02, 43.81 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47665/47780 [02:55<00:02, 39.17 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47671/47780 [02:55<00:02, 53.62 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45627/47780 [02:55<00:07, 307.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47633/47780 [02:55<00:02, 51.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47639/47780 [02:55<00:02, 49.63 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47651/47780 [02:55<00:02, 56.52 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47660/47780 [02:55<00:02, 41.17 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47670/47780 [02:56<00:02, 37.84 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47688/47780 [02:55<00:01, 65.48 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45663/47780 [02:55<00:06, 319.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47677/47780 [02:55<00:01, 53.46 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47639/47780 [02:56<00:02, 48.58 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47647/47780 [02:56<00:02, 51.07 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47658/47780 [02:56<00:02, 58.13 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45697/47780 [02:56<00:06, 306.28 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47675/47780 [02:56<00:02, 38.11 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47683/47780 [02:56<00:01, 49.54 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47666/47780 [02:56<00:02, 40.33 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47697/47780 [02:56<00:01, 59.47 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47646/47780 [02:56<00:02, 48.45 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47655/47780 [02:56<00:02, 53.19 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47664/47780 [02:56<00:02, 54.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45741/47780 [02:56<00:05, 341.47 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47673/47780 [02:56<00:02, 43.94 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47681/47780 [02:56<00:02, 37.84 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47653/47780 [02:56<00:02, 52.12 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47672/47780 [02:56<00:01, 60.13 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47692/47780 [02:56<00:01, 50.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47705/47780 [02:56<00:01, 57.58 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45778/47780 [02:56<00:06, 324.60 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47661/47780 [02:56<00:02, 47.45 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47688/47780 [02:56<00:02, 43.96 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47678/47780 [02:56<00:02, 42.67 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47700/47780 [02:56<00:01, 54.71 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47679/47780 [02:56<00:01, 58.98 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45816/47780 [02:56<00:05, 332.78 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47659/47780 [02:56<00:02, 47.98 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47713/47780 [02:56<00:01, 57.60 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47668/47780 [02:56<00:02, 47.37 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47683/47780 [02:56<00:02, 41.81 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47696/47780 [02:56<00:01, 48.25 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47689/47780 [02:56<00:01, 65.37 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47708/47780 [02:56<00:01, 56.99 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45857/47780 [02:56<00:05, 342.83 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47722/47780 [02:56<00:00, 59.77 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47667/47780 [02:56<00:02, 48.12 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47688/47780 [02:56<00:02, 43.60 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47673/47780 [02:56<00:02, 46.82 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47706/47780 [02:56<00:01, 56.16 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45894/47780 [02:56<00:05, 316.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47715/47780 [02:56<00:01, 54.51 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47697/47780 [02:56<00:01, 59.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47672/47780 [02:56<00:02, 42.82 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47695/47780 [02:56<00:02, 40.56 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47712/47780 [02:56<00:01, 48.37 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47679/47780 [02:56<00:02, 39.20 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47722/47780 [02:56<00:01, 52.26 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45928/47780 [02:56<00:06, 283.64 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47730/47780 [02:56<00:01, 47.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47705/47780 [02:56<00:01, 57.33 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47701/47780 [02:56<00:01, 40.20 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45958/47780 [02:56<00:06, 273.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47729/47780 [02:56<00:00, 51.14 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47719/47780 [02:57<00:01, 44.84 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47678/47780 [02:57<00:02, 35.48 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47711/47780 [02:57<00:01, 50.66 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47685/47780 [02:57<00:02, 33.77 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47707/47780 [02:57<00:01, 42.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45986/47780 [02:57<00:07, 254.04 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47736/47780 [02:57<00:00, 51.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47725/47780 [02:57<00:01, 44.92 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47682/47780 [02:57<00:03, 32.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47718/47780 [02:57<00:01, 47.35 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47689/47780 [02:57<00:02, 32.26 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46023/47780 [02:57<00:06, 266.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47742/47780 [02:57<00:00, 49.32 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47713/47780 [02:57<00:01, 39.05 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47724/47780 [02:57<00:01, 48.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47731/47780 [02:57<00:01, 41.79 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47686/47780 [02:57<00:03, 30.64 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46051/47780 [02:57<00:06, 254.10 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47693/47780 [02:57<00:02, 31.60 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47736/47780 [02:57<00:01, 27.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47719/47780 [02:57<00:01, 39.76 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47690/47780 [02:57<00:03, 29.36 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46077/47780 [02:57<00:07, 232.41 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47730/47780 [02:57<00:01, 43.18 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47747/47780 [02:57<00:00, 37.39 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47699/47780 [02:57<00:02, 34.68 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47725/47780 [02:57<00:01, 43.01 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46106/47780 [02:57<00:06, 244.98 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47695/47780 [02:57<00:02, 31.08 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47705/47780 [02:57<00:02, 37.09 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47738/47780 [02:57<00:00, 46.11 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47737/47780 [02:57<00:01, 30.40 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47730/47780 [02:57<00:01, 42.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46132/47780 [02:57<00:06, 243.05 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47700/47780 [02:57<00:02, 34.15 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47745/47780 [02:57<00:00, 47.98 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47710/47780 [02:57<00:01, 35.40 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47735/47780 [02:57<00:01, 39.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47741/47780 [02:57<00:01, 28.68 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46157/47780 [02:57<00:07, 225.57 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47741/47780 [02:57<00:01, 21.10 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47706/47780 [02:57<00:01, 37.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47714/47780 [02:57<00:01, 34.33 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47752/47780 [02:57<00:01, 23.30 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46180/47780 [02:57<00:07, 221.12 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47711/47780 [02:58<00:01, 37.60 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47718/47780 [02:58<00:01, 35.21 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47741/47780 [02:58<00:01, 33.08 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46228/47780 [02:58<00:05, 287.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47715/47780 [02:58<00:01, 36.72 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47745/47780 [02:58<00:01, 22.08 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47724/47780 [02:58<00:01, 39.46 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46259/47780 [02:58<00:05, 275.28 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47750/47780 [02:58<00:01, 27.70 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47745/47780 [02:58<00:01, 18.06 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47745/47780 [02:58<00:01, 29.62 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47720/47780 [02:58<00:01, 38.33 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [02:58<00:01, 19.06 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47731/47780 [02:58<00:01, 42.64 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46289/47780 [02:58<00:05, 272.08 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47726/47780 [02:58<00:01, 42.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47748/47780 [02:58<00:01, 19.58 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47749/47780 [02:58<00:01, 28.28 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46321/47780 [02:58<00:05, 275.99 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47748/47780 [02:58<00:01, 17.22 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47736/47780 [02:58<00:01, 39.86 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47731/47780 [02:58<00:01, 42.28 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46350/47780 [02:58<00:05, 272.06 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47754/47780 [02:58<00:01, 22.28 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47759/47780 [02:58<00:01, 17.45 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47752/47780 [02:58<00:01, 27.00 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47751/47780 [02:58<00:01, 17.59 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47736/47780 [02:58<00:01, 39.60 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46379/47780 [02:58<00:05, 239.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47751/47780 [02:58<00:01, 15.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47742/47780 [02:58<00:01, 33.00 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47762/47780 [02:58<00:01, 16.12 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47755/47780 [02:58<00:01, 21.40 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47753/47780 [02:58<00:01, 16.26 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46412/47780 [02:58<00:05, 251.05 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47758/47780 [02:58<00:01, 19.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47753/47780 [02:58<00:01, 15.38 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47746/47780 [02:58<00:01, 29.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47764/47780 [02:58<00:00, 16.03 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47755/47780 [02:58<00:01, 16.12 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46440/47780 [02:58<00:05, 250.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47742/47780 [02:58<00:01, 30.26 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47758/47780 [02:58<00:01, 19.46 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47755/47780 [02:58<00:01, 15.38 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46468/47780 [02:59<00:05, 256.31 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47761/47780 [02:59<00:01, 18.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47757/47780 [02:59<00:01, 15.99 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47766/47780 [02:58<00:00, 15.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47750/47780 [02:59<00:01, 28.10 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47757/47780 [02:59<00:01, 15.59 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47746/47780 [02:59<00:01, 28.00 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46500/47780 [02:59<00:04, 267.78 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47768/47780 [02:59<00:00, 15.93 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47759/47780 [02:59<00:01, 16.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47761/47780 [02:59<00:01, 18.46 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47754/47780 [02:59<00:00, 28.48 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47759/47780 [02:59<00:01, 15.56 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47764/47780 [02:59<00:00, 17.70 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46528/47780 [02:59<00:04, 252.67 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47750/47780 [02:59<00:01, 27.14 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47770/47780 [02:59<00:00, 15.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47763/47780 [02:59<00:00, 17.69 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47761/47780 [02:59<00:01, 15.79 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47758/47780 [02:59<00:00, 28.63 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46558/47780 [02:59<00:04, 264.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47761/47780 [02:59<00:01, 15.35 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47754/47780 [02:59<00:00, 27.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [02:59<00:00, 17.03 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47772/47780 [02:59<00:00, 15.58 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47765/47780 [02:59<00:00, 16.97 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47763/47780 [02:59<00:01, 15.53 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47763/47780 [02:59<00:00, 31.82 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46585/47780 [02:59<00:04, 241.82 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47763/47780 [02:59<00:01, 15.26 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47758/47780 [02:59<00:00, 28.02 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47769/47780 [02:59<00:00, 16.53 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [02:59<00:00, 16.46 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47765/47780 [02:59<00:00, 15.37 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [02:59<00:00, 15.31 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [02:59<00:00, 31.08 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46611/47780 [02:59<00:04, 236.73 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47765/47780 [02:59<00:00, 15.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47762/47780 [02:59<00:00, 29.37 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47769/47780 [02:59<00:00, 15.63 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47771/47780 [02:59<00:00, 15.81 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [02:59<00:00, 14.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [02:59<00:00, 14.76 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46639/47780 [02:59<00:04, 244.07 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47771/47780 [02:59<00:00, 30.33 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [02:59<00:00, 14.58 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47766/47780 [02:59<00:00, 29.09 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46664/47780 [02:59<00:04, 235.14 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [02:59<00:00, 14.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47773/47780 [02:59<00:00, 15.51 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47771/47780 [02:59<00:00, 15.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47770/47780 [02:59<00:00, 16.73 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47770/47780 [02:59<00:00, 28.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46693/47780 [02:59<00:04, 237.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46718/47780 [03:00<00:04, 221.47 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46741/47780 [03:00<00:04, 215.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46763/47780 [03:00<00:05, 201.42 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46788/47780 [03:00<00:04, 210.31 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [03:00<00:00,  8.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46810/47780 [03:00<00:04, 202.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46832/47780 [03:00<00:04, 199.56 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46870/47780 [03:00<00:03, 233.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46897/47780 [03:00<00:03, 229.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46922/47780 [03:01<00:03, 219.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46945/47780 [03:01<00:03, 220.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46971/47780 [03:01<00:03, 212.11 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47772/47780 [03:01<00:01,  5.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46993/47780 [03:01<00:03, 206.61 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47014/47780 [03:01<00:03, 195.60 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [03:01<00:01,  4.53 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47035/47780 [03:01<00:03, 187.36 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47062/47780 [03:01<00:03, 202.34 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47084/47780 [03:01<00:03, 183.30 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [03:01<00:00,  5.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47108/47780 [03:02<00:03, 185.95 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47128/47780 [03:02<00:03, 186.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47147/47780 [03:02<00:03, 170.40 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47166/47780 [03:02<00:03, 175.21 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47189/47780 [03:02<00:03, 180.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47775/47780 [03:02<00:01,  3.96 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [03:02<00:01,  2.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47209/47780 [03:02<00:03, 176.35 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [03:02<00:00,  4.13 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47227/47780 [03:02<00:03, 174.33 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [03:02<00:01,  4.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47246/47780 [03:02<00:03, 171.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47264/47780 [03:02<00:03, 157.50 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47282/47780 [03:03<00:03, 153.02 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47307/47780 [03:03<00:02, 169.34 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47325/47780 [03:03<00:02, 155.96 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [03:03<00:00,  4.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47346/47780 [03:03<00:02, 158.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47367/47780 [03:03<00:02, 161.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47386/47780 [03:03<00:02, 155.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47405/47780 [03:03<00:02, 150.20 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47423/47780 [03:03<00:02, 152.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [03:04<00:00,  2.75 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47440/47780 [03:04<00:02, 148.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47457/47780 [03:04<00:02, 153.09 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47473/47780 [03:04<00:01, 154.70 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47491/47780 [03:04<00:02, 143.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [03:04<00:00,  2.05 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47777/47780 [03:04<00:01,  1.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47507/47780 [03:04<00:02, 125.08 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47521/47780 [03:04<00:02, 116.48 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47535/47780 [03:04<00:02, 101.06 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47546/47780 [03:05<00:02, 101.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [03:05<00:00,  2.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47558/47780 [03:05<00:02, 99.33 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47570/47780 [03:05<00:02, 97.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00,  2.56 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00,  1.17 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47583/47780 [03:05<00:01, 102.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00,  2.03 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [03:05<00:00,  1.90 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00,  2.70 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47594/47780 [03:05<00:02, 80.72 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00, 257.25 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47605/47780 [03:05<00:02, 77.63 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00,  2.11 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47614/47780 [03:05<00:02, 74.65 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:06<00:00, 256.83 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47622/47780 [03:06<00:02, 70.41 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:06<00:00, 256.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47630/47780 [03:06<00:02, 67.51 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:06<00:00,  1.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47637/47780 [03:06<00:02, 66.19 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:06<00:00,  2.32 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:06<00:00, 256.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47648/47780 [03:06<00:01, 67.59 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47656/47780 [03:06<00:01, 65.30 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:06<00:00, 255.84 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:06<00:00, 255.92 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47667/47780 [03:06<00:01, 71.68 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:06<00:00, 255.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47676/47780 [03:06<00:01, 70.12 examples/s]
Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:42, 1100.30 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47686/47780 [03:07<00:01, 66.82 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):   8%|▊         | 4000/47780 [00:01<00:08, 4946.59 examples/s]
Truncating train dataset (num_proc=32):  51%|█████     | 24482/47780 [00:01<00:00, 36798.89 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47696/47780 [03:07<00:01, 63.19 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):  85%|████████▍ | 40385/47780 [00:01<00:00, 57539.07 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47703/47780 [03:07<00:01, 49.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:01<00:52, 896.02 examples/s]
Truncating train dataset (num_proc=32):  10%|█         | 5000/47780 [00:01<00:08, 5224.30 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47709/47780 [03:07<00:01, 47.58 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:01<00:57, 810.52 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47720/47780 [03:07<00:01, 57.33 examples/s]
Truncating train dataset (num_proc=32):  25%|██▌       | 12000/47780 [00:01<00:02, 13198.68 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):   4%|▍         | 2000/47780 [00:01<00:26, 1737.98 examples/s]
Truncating train dataset (num_proc=32):  45%|████▍     | 21467/47780 [00:01<00:01, 24381.49 examples/s]
Truncating train dataset (num_proc=32):   8%|▊         | 4000/47780 [00:01<00:10, 4047.57 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47728/47780 [03:07<00:01, 51.87 examples/s]
Truncating train dataset (num_proc=32):  26%|██▌       | 12494/47780 [00:01<00:02, 16227.05 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):  66%|██████▌   | 31440/47780 [00:01<00:00, 36735.78 examples/s]
Truncating train dataset (num_proc=32):  43%|████▎     | 20494/47780 [00:01<00:01, 26809.78 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47734/47780 [03:08<00:01, 44.22 examples/s]
Truncating train dataset (num_proc=32):  79%|███████▉  | 37919/47780 [00:01<00:00, 35555.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):  62%|██████▏   | 29482/47780 [00:01<00:00, 39276.86 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47739/47780 [03:08<00:01, 40.04 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:01<01:21, 574.83 examples/s]
Truncating train dataset (num_proc=32):  75%|███████▌  | 35948/47780 [00:02<00:00, 28364.61 examples/s]
Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:01<01:14, 625.66 examples/s]
Truncating train dataset (num_proc=32):   4%|▍         | 2000/47780 [00:01<00:35, 1289.94 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47744/47780 [03:08<00:01, 27.66 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):  91%|█████████ | 43343/47780 [00:02<00:00, 23111.58 examples/s]
Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:01<01:21, 573.11 examples/s]
Truncating train dataset (num_proc=32):  17%|█▋        | 8000/47780 [00:01<00:05, 7007.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):   4%|▍         | 2000/47780 [00:01<00:33, 1350.68 examples/s]
Truncating train dataset (num_proc=32):  25%|██▌       | 12000/47780 [00:02<00:03, 10990.44 examples/s]
Truncating train dataset (num_proc=32):  13%|█▎        | 6000/47780 [00:01<00:08, 5218.15 examples/s]
Truncating train dataset (num_proc=32):  86%|████████▌ | 40878/47780 [00:02<00:00, 25149.56 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):   6%|▋         | 3000/47780 [00:01<00:23, 1943.24 examples/s]
Truncating train dataset (num_proc=32):  38%|███▊      | 18000/47780 [00:02<00:01, 17926.39 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47749/47780 [03:08<00:01, 24.84 examples/s]
Truncating train dataset (num_proc=32):  19%|█▉        | 9000/47780 [00:02<00:05, 7330.77 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):  94%|█████████▍| 44822/47780 [00:02<00:00, 26420.03 examples/s]
Truncating train dataset (num_proc=32):  99%|█████████▉| 47287/47780 [00:02<00:00, 19288.09 examples/s]
Truncating train dataset (num_proc=32):  53%|█████▎    | 25494/47780 [00:02<00:00, 27567.44 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):  23%|██▎       | 11000/47780 [00:02<00:03, 9835.67 examples/s]
Truncating train dataset (num_proc=32):  32%|███▏      | 15493/47780 [00:02<00:02, 13567.48 examples/s]
Truncating train dataset (num_proc=32):  65%|██████▍   | 30961/47780 [00:02<00:00, 32539.39 examples/s]
Truncating train dataset (num_proc=32):  33%|███▎      | 16000/47780 [00:02<00:02, 15184.10 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47753/47780 [03:09<00:01, 22.29 examples/s]
Truncating train dataset (num_proc=32):  46%|████▌     | 21986/47780 [00:02<00:01, 19668.61 examples/s]
Truncating train dataset (num_proc=32):  77%|███████▋  | 36919/47780 [00:02<00:00, 37172.23 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):  48%|████▊     | 22974/47780 [00:02<00:01, 23124.94 examples/s]
Truncating train dataset (num_proc=32):  56%|█████▋    | 26959/47780 [00:02<00:00, 24332.69 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [03:09<00:01, 20.74 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):  70%|██████▉   | 33441/47780 [00:02<00:00, 36785.59 examples/s]
Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:02<01:49, 427.19 examples/s]
Truncating train dataset (num_proc=32):  89%|████████▊ | 42357/47780 [00:02<00:00, 34052.16 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):  69%|██████▉   | 32919/47780 [00:02<00:00, 30375.68 examples/s]
Truncating train dataset (num_proc=32):   6%|▋         | 3000/47780 [00:02<00:29, 1533.21 examples/s]
Truncating train dataset (num_proc=32):  80%|████████  | 38385/47780 [00:02<00:00, 34554.46 examples/s]
Truncating train dataset (num_proc=32):  82%|████████▏ | 39371/47780 [00:02<00:00, 34180.15 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47759/47780 [03:09<00:01, 18.18 examples/s]
Truncating train dataset (num_proc=32):  99%|█████████▉| 47287/47780 [00:02<00:00, 29994.94 examples/s]
Truncating train dataset (num_proc=32):   8%|▊         | 4000/47780 [00:02<00:20, 2157.35 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):  91%|█████████ | 43343/47780 [00:02<00:00, 36289.29 examples/s]
Truncating train dataset (num_proc=32):  98%|█████████▊| 46794/47780 [00:02<00:00, 39603.38 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47763/47780 [03:09<00:00, 20.03 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32):  41%|████      | 19481/47780 [00:02<00:01, 16745.04 examples/s]
Truncating train dataset (num_proc=32):  78%|███████▊  | 37426/47780 [00:02<00:00, 36295.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [03:09<00:00, 21.91 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [03:09<00:00, 29.71 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:13<00:00, 19288.09 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:12<00:00, 39603.38 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:13<00:00, 26420.03 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:13<00:00, 29994.94 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:13<00:00, 36289.29 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:15<00:00, 57539.07 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:14<00:00, 36295.49 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [03:22<00:00, 29.71 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:21<00:00, 785.46 examples/s]  
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:28<00:00, 1089.35 examples/s] 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:28<00:00, 492.97 examples/s]  
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:31<00:00, 440.37 examples/s]  
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:31<00:00, 547.80 examples/s]  
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:33<00:00, 1020.74 examples/s] 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:33<00:00, 785.46 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:34<00:00, 501.40 examples/s]  
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:44<00:00,  1.98s/ examples]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:41<00:00, 1137.80 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:41<00:00, 1157.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:41<00:00, 1158.65 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:41<00:00, 1144.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:41<00:00, 1147.93 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:42<00:00, 1132.26 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:42<00:00, 1133.37 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:49<00:00, 208.12 examples/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:05,626] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:05,626] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:05,627] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:05,628] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:05,638] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:05,698] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:05,753] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m df: /root/.triton/autotune: No such file or directory
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m df: /root/.triton/autotune: No such file or directory
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:06,150] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:07,996] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:07,996] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:07,996] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:07,996] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:07,996] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:07,996] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:07,996] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:27:07,996] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m   0%|          | 0/10 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3472)[0m  10%|█         | 1/10 [00:46<06:58, 46.48s/it]Chrome trace exported to: /tmp/trace_10_4_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_3_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_6_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_7_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_1_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_4_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_2_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_5_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_7_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_6_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_0_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_1_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_3_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_2_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_5_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_0_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_3_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_6_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_6_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_1_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_7_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_4_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_3_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_4_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_5_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_2_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_7_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_0_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_1_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_2_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_0_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_5_216739.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m  20%|██        | 2/10 [01:31<06:04, 45.55s/it]Chrome trace exported to: /tmp/trace_18_5_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_4_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_1_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_4_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_1_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_0_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_2_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_3_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_2_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_7_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_6_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_3_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_5_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_7_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_6_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_0_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_4_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_5_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_2_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_3_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_6_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_7_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_0_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_5_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_3_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_1_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_4_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_1_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_0_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_6_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_2_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_7_877572.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_6_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_1_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_7_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_4_388389.json
[36m(head, rank=0, pid=3472)[0m  30%|███       | 3/10 [02:15<05:15, 45.05s/it]Chrome trace exported to: /tmp/trace_26_5_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_0_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_2_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_3_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_2_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_5_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_3_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_4_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_1_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_6_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_7_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_0_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_4_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_3_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_0_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_5_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_6_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_7_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_1_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_6_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_4_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_7_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_2_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_2_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_0_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_1_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_5_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_3_356787.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_4_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_1_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_6_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_5_334053.json
[36m(head, rank=0, pid=3472)[0m  40%|████      | 4/10 [03:00<04:29, 44.88s/it]Chrome trace exported to: /tmp/trace_34_4_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_6_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_5_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_3_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_2_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_7_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_0_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_3_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_7_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_2_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_1_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_0_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_3_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_5_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_0_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_7_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_1_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_0_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_7_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_4_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_6_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_2_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_2_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_6_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_4_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_3_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_5_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_1_246316.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_6_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_7_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_1_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_4_872246.json
[36m(head, rank=0, pid=3472)[0m  50%|█████     | 5/10 [03:45<03:45, 45.01s/it]Chrome trace exported to: /tmp/trace_42_0_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_2_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_6_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_7_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_2_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_4_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_5_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_1_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_3_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_5_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_0_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_3_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_5_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_4_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_0_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_1_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_4_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_3_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_7_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_7_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_6_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_2_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_5_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_3_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_0_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_2_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_6_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_1_207473.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_4_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_1_809570.json
[36m(head, rank=0, pid=3472)[0m  60%|██████    | 6/10 [04:29<02:58, 44.66s/it]Chrome trace exported to: /tmp/trace_50_4_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_5_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_6_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_7_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_7_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_6_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_0_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_3_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_2_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_2_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_3_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_5_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_1_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_0_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_4_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_6_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_1_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_3_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_5_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_4_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_7_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_2_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_0_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_5_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_3_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_2_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_0_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_6_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_1_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_7_876646.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_7_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_1_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_4_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_6_671858.json
[36m(head, rank=0, pid=3472)[0m  70%|███████   | 7/10 [05:15<02:15, 45.04s/it]Chrome trace exported to: /tmp/trace_58_0_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_4_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_5_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_3_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_7_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_1_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_2_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_6_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_2_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_3_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_5_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_0_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_1_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_4_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_6_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_7_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_5_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_6_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_3_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_0_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_2_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_7_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_0_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_4_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_1_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_3_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_2_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_5_191161.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m  80%|████████  | 8/10 [06:01<01:30, 45.40s/it]Chrome trace exported to: /tmp/trace_66_0_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_4_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_5_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_4_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_6_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_5_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_3_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_7_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_2_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_6_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_2_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_3_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_7_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_1_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_0_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_1_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_2_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_5_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_6_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_1_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_7_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_0_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_4_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_0_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_4_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_2_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_3_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_6_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_1_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_7_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_3_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_5_542417.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_4_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_6_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_1_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_7_133326.json
[36m(head, rank=0, pid=3472)[0m  90%|█████████ | 9/10 [06:46<00:45, 45.18s/it]Chrome trace exported to: /tmp/trace_74_5_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_6_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_0_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_4_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_3_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_2_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_2_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_5_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_3_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_0_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_7_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_1_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_4_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_0_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_4_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_1_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_6_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_7_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_0_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_3_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_6_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_5_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_3_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_7_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_2_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_1_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_2_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_5_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3472)[0m 
100%|██████████| 10/10 [07:29<00:00, 44.62s/it]Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3472)[0m 
                                               
{'loss': 124.4492, 'grad_norm': 35.656002044677734, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3472)[0m 
100%|██████████| 10/10 [07:29<00:00, 44.62s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3472)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 181.75 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 181.75s (Total: 181.75s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 181.75 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 181.75s (Total: 181.75s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 181.75 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 181.75s (Total: 181.75s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 181.75 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 181.75s (Total: 181.75s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 181.75 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 181.75s (Total: 181.75s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 181.75 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 181.75s (Total: 181.75s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 181.75 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 181.75s (Total: 181.75s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 181.75 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 181.75s (Total: 181.75s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 181.75 secondsCompleted Save checkpoint in 181.75 seconds
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 181.75s (Total: 181.75s)
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 181.75s (Total: 181.75s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 181.75 seconds
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 181.75 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 181.75s (Total: 181.75s)
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 181.75s (Total: 181.75s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 181.75 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 181.75s (Total: 181.75s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 181.75 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 181.75s (Total: 181.75s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 181.75 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 181.75s (Total: 181.75s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 321.51 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 321.51s (Total: 321.51s)
[36m(head, rank=0, pid=3472)[0m 
                                               
{'train_runtime': 771.2377, 'train_samples_per_second': 1.66, 'train_steps_per_second': 0.013, 'train_loss': 124.44921875, 'epoch': 0.03}
[36m(head, rank=0, pid=3472)[0m 
100%|██████████| 10/10 [12:51<00:00, 44.62s/it]
100%|██████████| 10/10 [12:51<00:00, 77.12s/it]
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_0_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1123.12 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 321.51s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 321.51s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 321.51s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 321.51s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.37s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.04s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.08s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 365.24s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.57s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.91s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 8.70s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /tmp/checkpoint/training_run_0_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.07s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.07s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.07s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.07s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 22.09s
[36m(head, rank=0, pid=3472)[0m   • Min time: 22.09s
[36m(head, rank=0, pid=3472)[0m   • Max time: 22.09s
[36m(head, rank=0, pid=3472)[0m   • Total time: 22.09s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1123.12s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1123.12s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1123.12s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1123.12s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.57s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.91s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 8.70s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 365.24s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.08s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.37s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 321.51s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 321.51s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 321.51s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 321.51s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1147.28s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1147.28s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1147.28s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1147.28s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m --- Training Run 1 Info (Directory: /tmp/checkpoint) ---
[36m(head, rank=0, pid=3472)[0m {
[36m(head, rank=0, pid=3472)[0m   "run_id": 1,
[36m(head, rank=0, pid=3472)[0m   "timestamp": "2025-08-03T05:21:22.557739",
[36m(head, rank=0, pid=3472)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3472)[0m   "checkpoint_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3472)[0m   "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3472)[0m   "training_status": "completed",
[36m(head, rank=0, pid=3472)[0m   "output_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3472)[0m   "dataset_load_time": 2.070417642593384,
[36m(head, rank=0, pid=3472)[0m   "model_load_time": 22.08960485458374,
[36m(head, rank=0, pid=3472)[0m   "training_time": 1123.119781255722,
[36m(head, rank=0, pid=3472)[0m   "total_time": 1147.2798037528992,
[36m(head, rank=0, pid=3472)[0m   "error": null,
[36m(head, rank=0, pid=3472)[0m   "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3472)[0m   "total_checkpoint_save_time": 321.50980138778687,
[36m(head, rank=0, pid=3472)[0m   "average_checkpoint_save_time": 321.50980138778687,
[36m(head, rank=0, pid=3472)[0m   "min_checkpoint_save_time": 321.50980138778687,
[36m(head, rank=0, pid=3472)[0m   "max_checkpoint_save_time": 321.50980138778687,
[36m(head, rank=0, pid=3472)[0m   "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3472)[0m     321.50980138778687
[36m(head, rank=0, pid=3472)[0m   ],
[36m(head, rank=0, pid=3472)[0m   "num_batch_samples": 10,
[36m(head, rank=0, pid=3472)[0m   "total_batch_sample_time": 0.36911725997924805,
[36m(head, rank=0, pid=3472)[0m   "average_batch_sample_time": 0.036911725997924805,
[36m(head, rank=0, pid=3472)[0m   "min_batch_sample_time": 0.02940058708190918,
[36m(head, rank=0, pid=3472)[0m   "max_batch_sample_time": 0.07792878150939941,
[36m(head, rank=0, pid=3472)[0m   "individual_batch_sample_times": [
[36m(head, rank=0, pid=3472)[0m     0.07792878150939941,
[36m(head, rank=0, pid=3472)[0m     0.03238368034362793,
[36m(head, rank=0, pid=3472)[0m     0.031607866287231445,
[36m(head, rank=0, pid=3472)[0m     0.0314943790435791,
[36m(head, rank=0, pid=3472)[0m     0.034398555755615234,
[36m(head, rank=0, pid=3472)[0m     0.030434846878051758,
[36m(head, rank=0, pid=3472)[0m     0.03349876403808594,
[36m(head, rank=0, pid=3472)[0m     0.034177303314208984,
[36m(head, rank=0, pid=3472)[0m     0.02940058708190918,
[36m(head, rank=0, pid=3472)[0m     0.03379249572753906
[36m(head, rank=0, pid=3472)[0m   ],
[36m(head, rank=0, pid=3472)[0m   "num_training_steps": 80,
[36m(head, rank=0, pid=3472)[0m   "total_training_step_time": 365.24219250679016,
[36m(head, rank=0, pid=3472)[0m   "average_training_step_time": 4.565527406334877,
[36m(head, rank=0, pid=3472)[0m   "min_training_step_time": 3.9129109382629395,
[36m(head, rank=0, pid=3472)[0m   "max_training_step_time": 8.698423624038696,
[36m(head, rank=0, pid=3472)[0m   "individual_training_step_times": [
[36m(head, rank=0, pid=3472)[0m     8.698423624038696,
[36m(head, rank=0, pid=3472)[0m     4.768913984298706,
[36m(head, rank=0, pid=3472)[0m     5.224621057510376,
[36m(head, rank=0, pid=3472)[0m     4.341181516647339,
[36m(head, rank=0, pid=3472)[0m     5.212222576141357,
[36m(head, rank=0, pid=3472)[0m     4.00325345993042,
[36m(head, rank=0, pid=3472)[0m     4.116359233856201,
[36m(head, rank=0, pid=3472)[0m     4.188641786575317,
[36m(head, rank=0, pid=3472)[0m     4.27157187461853,
[36m(head, rank=0, pid=3472)[0m     5.221894979476929,
[36m(head, rank=0, pid=3472)[0m     4.303755044937134,
[36m(head, rank=0, pid=3472)[0m     4.175570011138916,
[36m(head, rank=0, pid=3472)[0m     4.091277360916138,
[36m(head, rank=0, pid=3472)[0m     5.442489147186279,
[36m(head, rank=0, pid=3472)[0m     4.223154783248901,
[36m(head, rank=0, pid=3472)[0m     4.827851057052612,
[36m(head, rank=0, pid=3472)[0m     5.210755109786987,
[36m(head, rank=0, pid=3472)[0m     4.365187168121338,
[36m(head, rank=0, pid=3472)[0m     4.174947500228882,
[36m(head, rank=0, pid=3472)[0m     4.1982421875,
[36m(head, rank=0, pid=3472)[0m     4.769098520278931,
[36m(head, rank=0, pid=3472)[0m     4.1378045082092285,
[36m(head, rank=0, pid=3472)[0m     5.350693941116333,
[36m(head, rank=0, pid=3472)[0m     4.228248596191406,
[36m(head, rank=0, pid=3472)[0m     5.468554973602295,
[36m(head, rank=0, pid=3472)[0m     4.446565866470337,
[36m(head, rank=0, pid=3472)[0m     4.4404284954071045,
[36m(head, rank=0, pid=3472)[0m     4.188715696334839,
[36m(head, rank=0, pid=3472)[0m     4.080707311630249,
[36m(head, rank=0, pid=3472)[0m     4.173881530761719,
[36m(head, rank=0, pid=3472)[0m     4.646348714828491,
[36m(head, rank=0, pid=3472)[0m     4.867853403091431,
[36m(head, rank=0, pid=3472)[0m     5.346790790557861,
[36m(head, rank=0, pid=3472)[0m     4.329113960266113,
[36m(head, rank=0, pid=3472)[0m     4.468588352203369,
[36m(head, rank=0, pid=3472)[0m     4.563536643981934,
[36m(head, rank=0, pid=3472)[0m     4.750756740570068,
[36m(head, rank=0, pid=3472)[0m     4.680035591125488,
[36m(head, rank=0, pid=3472)[0m     3.9437878131866455,
[36m(head, rank=0, pid=3472)[0m     4.227412700653076,
[36m(head, rank=0, pid=3472)[0m     3.9665818214416504,
[36m(head, rank=0, pid=3472)[0m     4.08193564414978,
[36m(head, rank=0, pid=3472)[0m     5.604689359664917,
[36m(head, rank=0, pid=3472)[0m     4.486351251602173,
[36m(head, rank=0, pid=3472)[0m     4.389893054962158,
[36m(head, rank=0, pid=3472)[0m     4.158052206039429,
[36m(head, rank=0, pid=3472)[0m     4.436700344085693,
[36m(head, rank=0, pid=3472)[0m     4.277735471725464,
[36m(head, rank=0, pid=3472)[0m     5.190934181213379,
[36m(head, rank=0, pid=3472)[0m     5.132425308227539,
[36m(head, rank=0, pid=3472)[0m     4.347357511520386,
[36m(head, rank=0, pid=3472)[0m     4.169230222702026,
[36m(head, rank=0, pid=3472)[0m     4.461008787155151,
[36m(head, rank=0, pid=3472)[0m     4.452099323272705,
[36m(head, rank=0, pid=3472)[0m     4.914772272109985,
[36m(head, rank=0, pid=3472)[0m     4.060308456420898,
[36m(head, rank=0, pid=3472)[0m     5.4377601146698,
[36m(head, rank=0, pid=3472)[0m     4.5271315574646,
[36m(head, rank=0, pid=3472)[0m     4.858359336853027,
[36m(head, rank=0, pid=3472)[0m     4.668599843978882,
[36m(head, rank=0, pid=3472)[0m     4.328186511993408,
[36m(head, rank=0, pid=3472)[0m     4.184178113937378,
[36m(head, rank=0, pid=3472)[0m     4.170719861984253,
[36m(head, rank=0, pid=3472)[0m     4.839539051055908,
[36m(head, rank=0, pid=3472)[0m     4.01423454284668,
[36m(head, rank=0, pid=3472)[0m     4.022454261779785,
[36m(head, rank=0, pid=3472)[0m     4.557211637496948,
[36m(head, rank=0, pid=3472)[0m     3.9756343364715576,
[36m(head, rank=0, pid=3472)[0m     4.614002466201782,
[36m(head, rank=0, pid=3472)[0m     5.544623136520386,
[36m(head, rank=0, pid=3472)[0m     4.409827947616577,
[36m(head, rank=0, pid=3472)[0m     4.388067960739136,
[36m(head, rank=0, pid=3472)[0m     3.9129109382629395,
[36m(head, rank=0, pid=3472)[0m     4.7285475730896,
[36m(head, rank=0, pid=3472)[0m     4.491965293884277,
[36m(head, rank=0, pid=3472)[0m     4.235130310058594,
[36m(head, rank=0, pid=3472)[0m     4.420000791549683,
[36m(head, rank=0, pid=3472)[0m     4.158282279968262,
[36m(head, rank=0, pid=3472)[0m     4.206444263458252,
[36m(head, rank=0, pid=3472)[0m     4.249067544937134
[36m(head, rank=0, pid=3472)[0m   ]
[36m(head, rank=0, pid=3472)[0m }
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m --- All Training Runs Summary ---
[36m(head, rank=0, pid=3472)[0m [
[36m(head, rank=0, pid=3472)[0m   {
[36m(head, rank=0, pid=3472)[0m     "run_id": 1,
[36m(head, rank=0, pid=3472)[0m     "timestamp": "2025-08-03T05:21:22.557739",
[36m(head, rank=0, pid=3472)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3472)[0m     "checkpoint_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3472)[0m     "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3472)[0m     "training_status": "completed",
[36m(head, rank=0, pid=3472)[0m     "output_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3472)[0m     "dataset_load_time": 2.070417642593384,
[36m(head, rank=0, pid=3472)[0m     "model_load_time": 22.08960485458374,
[36m(head, rank=0, pid=3472)[0m     "training_time": 1123.119781255722,
[36m(head, rank=0, pid=3472)[0m     "total_time": 1147.2798037528992,
[36m(head, rank=0, pid=3472)[0m     "error": null,
[36m(head, rank=0, pid=3472)[0m     "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3472)[0m     "total_checkpoint_save_time": 321.50980138778687,
[36m(head, rank=0, pid=3472)[0m     "average_checkpoint_save_time": 321.50980138778687,
[36m(head, rank=0, pid=3472)[0m     "min_checkpoint_save_time": 321.50980138778687,
[36m(head, rank=0, pid=3472)[0m     "max_checkpoint_save_time": 321.50980138778687,
[36m(head, rank=0, pid=3472)[0m     "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3472)[0m       321.50980138778687
[36m(head, rank=0, pid=3472)[0m     ],
[36m(head, rank=0, pid=3472)[0m     "num_batch_samples": 10,
[36m(head, rank=0, pid=3472)[0m     "total_batch_sample_time": 0.36911725997924805,
[36m(head, rank=0, pid=3472)[0m     "average_batch_sample_time": 0.036911725997924805,
[36m(head, rank=0, pid=3472)[0m     "min_batch_sample_time": 0.02940058708190918,
[36m(head, rank=0, pid=3472)[0m     "max_batch_sample_time": 0.07792878150939941,
[36m(head, rank=0, pid=3472)[0m     "individual_batch_sample_times": [
[36m(head, rank=0, pid=3472)[0m       0.07792878150939941,
[36m(head, rank=0, pid=3472)[0m       0.03238368034362793,
[36m(head, rank=0, pid=3472)[0m       0.031607866287231445,
[36m(head, rank=0, pid=3472)[0m       0.0314943790435791,
[36m(head, rank=0, pid=3472)[0m       0.034398555755615234,
[36m(head, rank=0, pid=3472)[0m       0.030434846878051758,
[36m(head, rank=0, pid=3472)[0m       0.03349876403808594,
[36m(head, rank=0, pid=3472)[0m       0.034177303314208984,
[36m(head, rank=0, pid=3472)[0m       0.02940058708190918,
[36m(head, rank=0, pid=3472)[0m       0.03379249572753906
[36m(head, rank=0, pid=3472)[0m     ],
[36m(head, rank=0, pid=3472)[0m     "num_training_steps": 80,
[36m(head, rank=0, pid=3472)[0m     "total_training_step_time": 365.24219250679016,
[36m(head, rank=0, pid=3472)[0m     "average_training_step_time": 4.565527406334877,
[36m(head, rank=0, pid=3472)[0m     "min_training_step_time": 3.9129109382629395,
[36m(head, rank=0, pid=3472)[0m     "max_training_step_time": 8.698423624038696,
[36m(head, rank=0, pid=3472)[0m     "individual_training_step_times": [
[36m(head, rank=0, pid=3472)[0m       8.698423624038696,
[36m(head, rank=0, pid=3472)[0m       4.768913984298706,
[36m(head, rank=0, pid=3472)[0m       5.224621057510376,
[36m(head, rank=0, pid=3472)[0m       4.341181516647339,
[36m(head, rank=0, pid=3472)[0m       5.212222576141357,
[36m(head, rank=0, pid=3472)[0m       4.00325345993042,
[36m(head, rank=0, pid=3472)[0m       4.116359233856201,
[36m(head, rank=0, pid=3472)[0m       4.188641786575317,
[36m(head, rank=0, pid=3472)[0m       4.27157187461853,
[36m(head, rank=0, pid=3472)[0m       5.221894979476929,
[36m(head, rank=0, pid=3472)[0m       4.303755044937134,
[36m(head, rank=0, pid=3472)[0m       4.175570011138916,
[36m(head, rank=0, pid=3472)[0m       4.091277360916138,
[36m(head, rank=0, pid=3472)[0m       5.442489147186279,
[36m(head, rank=0, pid=3472)[0m       4.223154783248901,
[36m(head, rank=0, pid=3472)[0m       4.827851057052612,
[36m(head, rank=0, pid=3472)[0m       5.210755109786987,
[36m(head, rank=0, pid=3472)[0m       4.365187168121338,
[36m(head, rank=0, pid=3472)[0m       4.174947500228882,
[36m(head, rank=0, pid=3472)[0m       4.1982421875,
[36m(head, rank=0, pid=3472)[0m       4.769098520278931,
[36m(head, rank=0, pid=3472)[0m       4.1378045082092285,
[36m(head, rank=0, pid=3472)[0m       5.350693941116333,
[36m(head, rank=0, pid=3472)[0m       4.228248596191406,
[36m(head, rank=0, pid=3472)[0m       5.468554973602295,
[36m(head, rank=0, pid=3472)[0m       4.446565866470337,
[36m(head, rank=0, pid=3472)[0m       4.4404284954071045,
[36m(head, rank=0, pid=3472)[0m       4.188715696334839,
[36m(head, rank=0, pid=3472)[0m       4.080707311630249,
[36m(head, rank=0, pid=3472)[0m       4.173881530761719,
[36m(head, rank=0, pid=3472)[0m       4.646348714828491,
[36m(head, rank=0, pid=3472)[0m       4.867853403091431,
[36m(head, rank=0, pid=3472)[0m       5.346790790557861,
[36m(head, rank=0, pid=3472)[0m       4.329113960266113,
[36m(head, rank=0, pid=3472)[0m       4.468588352203369,
[36m(head, rank=0, pid=3472)[0m       4.563536643981934,
[36m(head, rank=0, pid=3472)[0m       4.750756740570068,
[36m(head, rank=0, pid=3472)[0m       4.680035591125488,
[36m(head, rank=0, pid=3472)[0m       3.9437878131866455,
[36m(head, rank=0, pid=3472)[0m       4.227412700653076,
[36m(head, rank=0, pid=3472)[0m       3.9665818214416504,
[36m(head, rank=0, pid=3472)[0m       4.08193564414978,
[36m(head, rank=0, pid=3472)[0m       5.604689359664917,
[36m(head, rank=0, pid=3472)[0m       4.486351251602173,
[36m(head, rank=0, pid=3472)[0m       4.389893054962158,
[36m(head, rank=0, pid=3472)[0m       4.158052206039429,
[36m(head, rank=0, pid=3472)[0m       4.436700344085693,
[36m(head, rank=0, pid=3472)[0m       4.277735471725464,
[36m(head, rank=0, pid=3472)[0m       5.190934181213379,
[36m(head, rank=0, pid=3472)[0m       5.132425308227539,
[36m(head, rank=0, pid=3472)[0m       4.347357511520386,
[36m(head, rank=0, pid=3472)[0m       4.169230222702026,
[36m(head, rank=0, pid=3472)[0m       4.461008787155151,
[36m(head, rank=0, pid=3472)[0m       4.452099323272705,
[36m(head, rank=0, pid=3472)[0m       4.914772272109985,
[36m(head, rank=0, pid=3472)[0m       4.060308456420898,
[36m(head, rank=0, pid=3472)[0m       5.4377601146698,
[36m(head, rank=0, pid=3472)[0m       4.5271315574646,
[36m(head, rank=0, pid=3472)[0m       4.858359336853027,
[36m(head, rank=0, pid=3472)[0m       4.668599843978882,
[36m(head, rank=0, pid=3472)[0m       4.328186511993408,
[36m(head, rank=0, pid=3472)[0m       4.184178113937378,
[36m(head, rank=0, pid=3472)[0m       4.170719861984253,
[36m(head, rank=0, pid=3472)[0m       4.839539051055908,
[36m(head, rank=0, pid=3472)[0m       4.01423454284668,
[36m(head, rank=0, pid=3472)[0m       4.022454261779785,
[36m(head, rank=0, pid=3472)[0m       4.557211637496948,
[36m(head, rank=0, pid=3472)[0m       3.9756343364715576,
[36m(head, rank=0, pid=3472)[0m       4.614002466201782,
[36m(head, rank=0, pid=3472)[0m       5.544623136520386,
[36m(head, rank=0, pid=3472)[0m       4.409827947616577,
[36m(head, rank=0, pid=3472)[0m       4.388067960739136,
[36m(head, rank=0, pid=3472)[0m       3.9129109382629395,
[36m(head, rank=0, pid=3472)[0m       4.7285475730896,
[36m(head, rank=0, pid=3472)[0m       4.491965293884277,
[36m(head, rank=0, pid=3472)[0m       4.235130310058594,
[36m(head, rank=0, pid=3472)[0m       4.420000791549683,
[36m(head, rank=0, pid=3472)[0m       4.158282279968262,
[36m(head, rank=0, pid=3472)[0m       4.206444263458252,
[36m(head, rank=0, pid=3472)[0m       4.249067544937134
[36m(head, rank=0, pid=3472)[0m     ]
[36m(head, rank=0, pid=3472)[0m   }
[36m(head, rank=0, pid=3472)[0m ]
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m --- Timing Summary ---
[36m(head, rank=0, pid=3472)[0m {
[36m(head, rank=0, pid=3472)[0m   "total_runs": 1,
[36m(head, rank=0, pid=3472)[0m   "dataset_loading": {
[36m(head, rank=0, pid=3472)[0m     "dataset_load_count": 1,
[36m(head, rank=0, pid=3472)[0m     "dataset_load_average": 2.070417642593384,
[36m(head, rank=0, pid=3472)[0m     "dataset_load_min": 2.070417642593384,
[36m(head, rank=0, pid=3472)[0m     "dataset_load_max": 2.070417642593384,
[36m(head, rank=0, pid=3472)[0m     "dataset_load_total": 2.070417642593384
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "model_loading": {
[36m(head, rank=0, pid=3472)[0m     "model_load_count": 1,
[36m(head, rank=0, pid=3472)[0m     "model_load_average": 22.08960485458374,
[36m(head, rank=0, pid=3472)[0m     "model_load_min": 22.08960485458374,
[36m(head, rank=0, pid=3472)[0m     "model_load_max": 22.08960485458374,
[36m(head, rank=0, pid=3472)[0m     "model_load_total": 22.08960485458374
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "training": {
[36m(head, rank=0, pid=3472)[0m     "training_count": 1,
[36m(head, rank=0, pid=3472)[0m     "training_average": 1123.119781255722,
[36m(head, rank=0, pid=3472)[0m     "training_min": 1123.119781255722,
[36m(head, rank=0, pid=3472)[0m     "training_max": 1123.119781255722,
[36m(head, rank=0, pid=3472)[0m     "training_total": 1123.119781255722
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "total_run_time": {
[36m(head, rank=0, pid=3472)[0m     "total_count": 1,
[36m(head, rank=0, pid=3472)[0m     "total_average": 1147.2798037528992,
[36m(head, rank=0, pid=3472)[0m     "total_min": 1147.2798037528992,
[36m(head, rank=0, pid=3472)[0m     "total_max": 1147.2798037528992,
[36m(head, rank=0, pid=3472)[0m     "total_total": 1147.2798037528992
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "checkpoint_saving": {
[36m(head, rank=0, pid=3472)[0m     "total_checkpoints_saved": 1,
[36m(head, rank=0, pid=3472)[0m     "total_checkpoint_save_time": 321.50980138778687,
[36m(head, rank=0, pid=3472)[0m     "average_save_time_per_checkpoint": 321.50980138778687,
[36m(head, rank=0, pid=3472)[0m     "checkpoint_save_times_count": 1,
[36m(head, rank=0, pid=3472)[0m     "checkpoint_save_min": 321.50980138778687,
[36m(head, rank=0, pid=3472)[0m     "checkpoint_save_max": 321.50980138778687,
[36m(head, rank=0, pid=3472)[0m     "checkpoint_save_average": 321.50980138778687
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "batch_sampling": {
[36m(head, rank=0, pid=3472)[0m     "total_batch_samples": 10,
[36m(head, rank=0, pid=3472)[0m     "total_batch_sample_time": 0.36911725997924805,
[36m(head, rank=0, pid=3472)[0m     "average_sample_time_per_batch": 0.036911725997924805,
[36m(head, rank=0, pid=3472)[0m     "batch_sample_times_count": 10,
[36m(head, rank=0, pid=3472)[0m     "batch_sample_min": 0.02940058708190918,
[36m(head, rank=0, pid=3472)[0m     "batch_sample_max": 0.07792878150939941,
[36m(head, rank=0, pid=3472)[0m     "batch_sample_average": 0.036911725997924805
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "training_steps": {
[36m(head, rank=0, pid=3472)[0m     "total_training_steps": 80,
[36m(head, rank=0, pid=3472)[0m     "total_training_step_time": 365.24219250679016,
[36m(head, rank=0, pid=3472)[0m     "average_step_time_per_step": 4.565527406334877,
[36m(head, rank=0, pid=3472)[0m     "training_step_times_count": 80,
[36m(head, rank=0, pid=3472)[0m     "training_step_min": 3.9129109382629395,
[36m(head, rank=0, pid=3472)[0m     "training_step_max": 8.698423624038696,
[36m(head, rank=0, pid=3472)[0m     "training_step_average": 4.565527406334877
[36m(head, rank=0, pid=3472)[0m   }
[36m(head, rank=0, pid=3472)[0m }
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_1_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1167.76 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 366.60s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.58s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 9.83s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /tmp/checkpoint/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_6_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1167.94 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.02s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 367.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.59s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 9.85s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /tmp/checkpoint/training_run_6_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1.00s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1.00s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1.00s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1.00s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1167.76s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1167.76s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1167.76s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1167.76s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.58s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 9.83s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 366.60s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1171.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1171.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1171.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1171.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1167.94s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1167.94s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1167.94s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1167.94s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.59s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 9.85s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 367.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.02s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1171.37s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1171.37s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1171.37s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1171.37s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_7_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1169.12 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 365.93s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.57s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.87s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 9.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /tmp/checkpoint/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.10s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.10s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.10s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.10s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1.02s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1.02s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1.02s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1.02s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1169.12s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1169.12s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1169.12s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1169.12s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.57s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.87s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 9.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 365.93s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1172.24s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1172.24s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1172.24s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1172.24s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_6_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1169.49 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 181.75s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.36s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.04s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.08s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 364.69s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.56s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.83s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 9.83s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /tmp/checkpoint/training_run_6_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_4_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1169.44 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.11s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 367.18s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.59s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.83s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 9.81s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /tmp/checkpoint/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_4_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1169.46 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 181.75s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.35s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 366.33s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.58s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.88s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 9.83s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /tmp/checkpoint/training_run_4_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.06s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.06s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.06s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.06s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 0.97s
[36m(head, rank=0, pid=3472)[0m   • Min time: 0.97s
[36m(head, rank=0, pid=3472)[0m   • Max time: 0.97s
[36m(head, rank=0, pid=3472)[0m   • Total time: 0.97s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1169.49s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1169.49s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1169.49s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1169.49s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.56s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.83s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 9.83s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 364.69s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.08s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.36s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 181.75s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1172.52s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1172.52s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1172.52s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1172.52s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.30s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.30s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.30s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.30s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.04s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.04s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.04s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.04s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1169.46s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1169.46s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1169.46s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1169.46s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.58s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.88s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 9.83s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 366.33s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.07s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.35s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 181.75s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1172.80s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1172.80s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1172.80s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1172.80s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_2_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1169.66 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 181.75s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.35s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 363.96s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.55s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.83s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 9.83s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /tmp/checkpoint/training_run_2_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_7_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1169.66 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 181.75s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.35s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 364.23s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.55s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.91s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 9.84s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /tmp/checkpoint/training_run_7_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.10s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.10s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.10s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.10s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.02s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.02s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.02s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.02s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1169.66s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1169.66s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1169.66s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1169.66s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.55s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.83s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 9.83s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 363.96s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.07s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.35s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 181.75s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1172.77s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1172.77s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1172.77s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1172.77s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.11s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.11s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.11s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.11s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 0.95s
[36m(head, rank=0, pid=3472)[0m   • Min time: 0.95s
[36m(head, rank=0, pid=3472)[0m   • Max time: 0.95s
[36m(head, rank=0, pid=3472)[0m   • Total time: 0.95s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1169.66s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1169.66s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1169.66s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1169.66s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.55s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.91s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 9.84s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 364.23s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.07s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.35s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 181.75s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1172.72s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1172.72s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1172.72s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1172.72s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_1_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1169.84 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 181.75s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.36s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.04s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.08s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 363.72s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.55s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.72s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 9.83s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /tmp/checkpoint/training_run_1_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.08s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.08s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.08s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.08s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 0.96s
[36m(head, rank=0, pid=3472)[0m   • Min time: 0.96s
[36m(head, rank=0, pid=3472)[0m   • Max time: 0.96s
[36m(head, rank=0, pid=3472)[0m   • Total time: 0.96s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1169.84s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1169.84s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1169.84s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1169.84s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.55s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.72s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 9.83s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 363.72s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.08s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.36s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 181.75s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1172.88s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1172.88s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1172.88s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1172.88s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_3_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1170.00 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 181.75s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.36s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.04s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 366.45s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.58s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.98s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 9.83s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /tmp/checkpoint/training_run_3_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.08s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.08s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.08s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.08s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.06s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.06s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.06s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.06s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1170.00s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1170.00s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1170.00s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1170.00s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.58s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.98s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 9.83s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 366.45s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.07s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.36s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 181.75s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1173.14s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1173.14s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1173.14s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1173.14s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.32s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.32s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.32s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.32s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1.01s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1.01s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1.01s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1.01s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1169.44s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1169.44s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1169.44s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1169.44s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.59s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.83s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 9.81s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 367.18s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.11s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1172.77s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1172.77s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1172.77s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1172.77s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_5_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1170.11 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 181.75s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.36s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.04s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 366.76s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.58s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.97s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 9.84s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /tmp/checkpoint/training_run_5_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.27s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.27s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.27s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.27s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.03s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.03s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.03s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.03s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1170.11s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1170.11s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1170.11s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1170.11s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.58s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.97s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 9.84s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 366.76s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.07s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.36s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 181.75s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 181.75s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1173.41s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1173.41s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1173.41s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1173.41s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_0_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1149.44 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.36s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 362.31s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.53s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 8.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /tmp/checkpoint/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_2_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1170.84 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.36s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 365.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.56s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 9.83s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /tmp/checkpoint/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.34s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 22.10s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 22.10s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 22.10s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 22.10s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1149.44s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1149.44s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1149.44s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1149.44s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.53s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 8.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 362.31s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.36s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1173.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1173.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1173.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1173.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_0.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m --- Training Run 1 Info (Directory: /tmp/checkpoint) ---
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "run_id": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "timestamp": "2025-08-03T05:21:22.557344",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "checkpoint_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "training_status": "completed",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "output_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "dataset_load_time": 2.3388373851776123,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "model_load_time": 22.095008850097656,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "training_time": 1149.4446396827698,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_time": 1173.878485918045,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "error": null,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_checkpoint_save_time": 181.75200295448303,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "average_checkpoint_save_time": 181.75200295448303,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "min_checkpoint_save_time": 181.75200295448303,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "max_checkpoint_save_time": 181.75200295448303,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     181.75200295448303
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   ],
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_batch_sample_time": 0.3625833988189697,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "average_batch_sample_time": 0.03625833988189697,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "min_batch_sample_time": 0.02847599983215332,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "max_batch_sample_time": 0.08098053932189941,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.08098053932189941,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.03061985969543457,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.03323960304260254,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.030931472778320312,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.03309822082519531,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.03333568572998047,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.03027486801147461,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.02847599983215332,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.03300642967224121,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.02862071990966797
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   ],
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "num_training_steps": 80,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_training_step_time": 362.3099834918976,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "average_training_step_time": 4.52887479364872,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "min_training_step_time": 3.8795738220214844,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "max_training_step_time": 8.051278829574585,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "individual_training_step_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     8.051278829574585,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.379268169403076,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.223834753036499,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.343060255050659,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.243664979934692,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.003465414047241,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.538327932357788,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.188114166259766,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.2463600635528564,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.192296981811523,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.17214298248291,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.178002595901489,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.093402147293091,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.443174600601196,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.228119850158691,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.3342485427856445,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.156781196594238,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.366389751434326,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.15882420539856,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.197690963745117,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.792940139770508,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.138376474380493,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.164167165756226,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.230539798736572,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.470072031021118,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.540543079376221,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.364072561264038,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.188064813613892,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.9331977367401123,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.1738879680633545,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.4170920848846436,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.867300987243652,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.397990942001343,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.3323705196380615,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.331824779510498,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.564608812332153,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.7510621547698975,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.638796329498291,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.883930206298828,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.229422569274902,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.8795738220214844,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.231603384017944,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.370706796646118,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.487457513809204,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.413938522338867,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.1562254428863525,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.252751588821411,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.277982234954834,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.198316812515259,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.134517431259155,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.181478977203369,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.168299674987793,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.458930730819702,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.363122224807739,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.8199992179870605,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.059308052062988,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.43616247177124,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.525777578353882,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.46019721031189,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.645723104476929,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.179314374923706,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.182149171829224,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.121010780334473,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.741932392120361,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.012983798980713,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.9337122440338135,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.3683671951293945,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.058854341506958,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.6142661571502686,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.544811248779297,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.388225078582764,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.3862152099609375,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.061836242675781,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.778891563415527,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.12530517578125,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.232533693313599,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.339166879653931,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.134281635284424,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.182257413864136,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.253086566925049
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   ]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m }
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m --- All Training Runs Summary ---
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "run_id": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "timestamp": "2025-08-03T05:21:22.557344",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "checkpoint_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_status": "completed",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "output_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_time": 2.3388373851776123,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_time": 22.095008850097656,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_time": 1149.4446396827698,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_time": 1173.878485918045,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "error": null,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_checkpoint_save_time": 181.75200295448303,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_checkpoint_save_time": 181.75200295448303,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "min_checkpoint_save_time": 181.75200295448303,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "max_checkpoint_save_time": 181.75200295448303,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       181.75200295448303
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     ],
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_batch_sample_time": 0.3625833988189697,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_batch_sample_time": 0.03625833988189697,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "min_batch_sample_time": 0.02847599983215332,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "max_batch_sample_time": 0.08098053932189941,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.08098053932189941,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.03061985969543457,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.03323960304260254,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.030931472778320312,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.03309822082519531,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.03333568572998047,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.03027486801147461,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.02847599983215332,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.03300642967224121,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.02862071990966797
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     ],
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "num_training_steps": 80,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_training_step_time": 362.3099834918976,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_training_step_time": 4.52887479364872,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "min_training_step_time": 3.8795738220214844,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "max_training_step_time": 8.051278829574585,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "individual_training_step_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       8.051278829574585,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.379268169403076,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.223834753036499,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.343060255050659,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.243664979934692,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.003465414047241,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.538327932357788,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.188114166259766,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.2463600635528564,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.192296981811523,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.17214298248291,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.178002595901489,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.093402147293091,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.443174600601196,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.228119850158691,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.3342485427856445,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.156781196594238,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.366389751434326,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.15882420539856,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.197690963745117,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.792940139770508,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.138376474380493,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.164167165756226,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.230539798736572,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.470072031021118,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.540543079376221,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.364072561264038,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.188064813613892,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.9331977367401123,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.1738879680633545,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.4170920848846436,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.867300987243652,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.397990942001343,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.3323705196380615,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.331824779510498,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.564608812332153,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.7510621547698975,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.638796329498291,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.883930206298828,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.229422569274902,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.8795738220214844,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.231603384017944,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.370706796646118,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.487457513809204,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.413938522338867,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.1562254428863525,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.252751588821411,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.277982234954834,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.198316812515259,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.134517431259155,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.181478977203369,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.168299674987793,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.458930730819702,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.363122224807739,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.8199992179870605,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.059308052062988,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.43616247177124,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.525777578353882,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.46019721031189,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.645723104476929,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.179314374923706,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.182149171829224,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.121010780334473,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.741932392120361,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.012983798980713,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.9337122440338135,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.3683671951293945,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.058854341506958,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.6142661571502686,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.544811248779297,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.388225078582764,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.3862152099609375,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.061836242675781,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.778891563415527,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.12530517578125,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.232533693313599,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.339166879653931,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.134281635284424,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.182257413864136,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.253086566925049
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     ]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   }
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m --- Timing Summary ---
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_runs": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "dataset_loading": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_count": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_average": 2.3388373851776123,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_min": 2.3388373851776123,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_max": 2.3388373851776123,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_total": 2.3388373851776123
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "model_loading": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_count": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_average": 22.095008850097656,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_min": 22.095008850097656,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_max": 22.095008850097656,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_total": 22.095008850097656
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "training": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_count": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_average": 1149.4446396827698,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_min": 1149.4446396827698,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_max": 1149.4446396827698,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_total": 1149.4446396827698
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_run_time": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_count": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_average": 1173.878485918045,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_min": 1173.878485918045,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_max": 1173.878485918045,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_total": 1173.878485918045
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "checkpoint_saving": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_checkpoint_save_time": 181.75200295448303,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_save_time_per_checkpoint": 181.75200295448303,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "checkpoint_save_times_count": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "checkpoint_save_min": 181.75200295448303,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "checkpoint_save_max": 181.75200295448303,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "checkpoint_save_average": 181.75200295448303
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "batch_sampling": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_batch_samples": 10,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_batch_sample_time": 0.3625833988189697,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_sample_time_per_batch": 0.03625833988189697,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "batch_sample_times_count": 10,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "batch_sample_min": 0.02847599983215332,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "batch_sample_max": 0.08098053932189941,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "batch_sample_average": 0.03625833988189697
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "training_steps": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_training_steps": 80,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_training_step_time": 362.3099834918976,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_step_time_per_step": 4.52887479364872,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_step_times_count": 80,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_step_min": 3.8795738220214844,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_step_max": 8.051278829574585,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_step_average": 4.52887479364872
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   }
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m }
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_5_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1170.35 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.36s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 364.20s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.82s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 9.83s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /tmp/checkpoint/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_3_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1170.45 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.36s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 364.95s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.56s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.83s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 9.85s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /tmp/checkpoint/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 0.97s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 0.97s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 0.97s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 0.97s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1170.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1170.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1170.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1170.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.56s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 9.83s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 365.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.36s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1173.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1173.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1173.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1173.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.49s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.49s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.49s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.49s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1170.35s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1170.35s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1170.35s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1170.35s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.82s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 9.83s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 364.20s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.36s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1173.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1173.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1173.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1173.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.31s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.31s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.31s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.31s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 0.97s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 0.97s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 0.97s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 0.97s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1170.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1170.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1170.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1170.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.56s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.83s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 9.85s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 364.95s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.36s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 181.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1173.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1173.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1173.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1173.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3472)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.25 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.24 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.27 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.29 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.30 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.31 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.40 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.00 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.01 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.50 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.53 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.07 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.09 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.12 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.22 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.42 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 61.08it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 68.75it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 61.60it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 62.30it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 1.03 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 66.65it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 1.03 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.08 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.08 seconds
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 64.58it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 76.65it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 66.37it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 68.24it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 67.90it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 59.87it/s]
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.08 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 65.50it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 1.03 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.02 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.01 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.09 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 62.70it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 0.99 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.03 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 0.99 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 67.42it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.27 seconds
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.14 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:06<00:24,  6.11s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:06<00:25,  6.35s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:11<00:17,  5.79s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:11<00:17,  5.81s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:17<00:11,  5.54s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:16<00:11,  5.57s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:22<00:05,  5.37s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:26<00:00,  5.14s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:26<00:00,  5.37s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:22<00:05,  5.44s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:27<00:00,  5.20s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:27<00:00,  5.40s/it]
[36m(head, rank=0, pid=3472)[0m Completed Load model in 27.83 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 27.93 seconds
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:00,697] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:02,013] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:02,091] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:02,097] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:02,099] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:02,111] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:02,112] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:02,114] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:02,114] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:02,591] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:02,592] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:02,592] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:02,594] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:02,595] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:02,596] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:02,600] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:02,601] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:03,366] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:03,375] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:03,377] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:03,404] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:03,409] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:03,411] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 05:42:03,414] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:03,844] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:03,845] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:03,848] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:03,849] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:03,863] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:03,873] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:03,898] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 05:42:03,907] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m   0%|          | 0/10 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3472)[0m  10%|█         | 1/10 [00:38<05:50, 38.90s/it]Chrome trace exported to: /tmp/trace_10_7_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_4_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_5_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_3_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_2_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_1_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_3_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_0_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_1_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_6_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_7_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_4_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_2_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_6_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_5_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_0_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_2_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_5_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_3_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_6_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_1_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_4_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_7_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_7_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_4_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_1_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_5_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_3_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_6_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_2_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_0_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_0_216739.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m  20%|██        | 2/10 [01:20<05:25, 40.73s/it]Chrome trace exported to: /tmp/trace_18_7_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_6_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_4_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_7_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_1_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_5_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_5_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_6_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_1_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_3_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_4_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_0_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_2_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_3_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_2_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_0_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_7_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_2_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_5_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_1_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_6_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_4_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_3_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_3_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_7_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_0_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_5_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_2_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_4_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_0_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_6_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_1_877572.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m  30%|███       | 3/10 [02:01<04:44, 40.60s/it]Chrome trace exported to: /tmp/trace_26_2_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_1_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_7_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_5_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_6_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_1_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_4_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_3_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_2_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_7_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_5_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_6_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_0_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_4_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_3_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_0_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_2_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_6_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_7_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_1_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_5_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_4_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_3_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_0_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_6_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_0_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_4_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_2_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_7_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_5_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_3_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_1_356787.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_4_334053.json
[36m(head, rank=0, pid=3472)[0m  40%|████      | 4/10 [02:41<04:03, 40.60s/it]Chrome trace exported to: /tmp/trace_34_2_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_1_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_3_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_5_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_3_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_1_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_5_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_6_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_7_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_2_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_6_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_0_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_7_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_4_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_0_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_7_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_2_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_1_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_5_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_0_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_6_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_5_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_0_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_6_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_7_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_3_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_4_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_3_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_2_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_4_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_1_246316.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_3_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_4_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_6_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_5_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_7_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_1_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_0_872246.json
[36m(head, rank=0, pid=3472)[0m  50%|█████     | 5/10 [03:24<03:25, 41.18s/it]Chrome trace exported to: /tmp/trace_42_1_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_4_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_7_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_3_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_6_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_2_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_2_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_0_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_5_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_2_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_0_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_1_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_5_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_0_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_2_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_7_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_4_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_5_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_7_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_3_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_4_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_6_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_6_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_1_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_3_207473.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_4_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_1_809570.json
[36m(head, rank=0, pid=3472)[0m  60%|██████    | 6/10 [04:04<02:43, 40.95s/it]Chrome trace exported to: /tmp/trace_50_7_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_3_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_6_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_3_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_6_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_5_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_4_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_2_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_0_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_5_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_7_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_0_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_2_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_1_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_0_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_2_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_2_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_4_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_5_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_7_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_0_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_7_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_5_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_6_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_3_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_1_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_6_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_1_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_3_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_4_876646.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_7_671858.json
[36m(head, rank=0, pid=3472)[0m  70%|███████   | 7/10 [04:47<02:04, 41.41s/it]Chrome trace exported to: /tmp/trace_58_5_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_3_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_0_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_1_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_3_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_4_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_6_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_5_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_1_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_6_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_7_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_4_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_0_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_2_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_2_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_2_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_7_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_1_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_0_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_6_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_4_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_7_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_2_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_6_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_5_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_3_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_4_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_0_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_5_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_3_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_1_191161.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m  80%|████████  | 8/10 [05:29<01:23, 41.86s/it]Chrome trace exported to: /tmp/trace_66_2_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_5_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_6_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_4_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_1_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_0_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_4_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_6_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_1_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_7_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_5_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_0_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_2_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_7_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_3_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_3_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_2_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_0_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_7_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_3_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_5_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_4_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_7_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_3_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_5_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_1_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_6_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_4_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_2_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_1_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_0_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_6_542417.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_6_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_5_133326.json
[36m(head, rank=0, pid=3472)[0m  90%|█████████ | 9/10 [06:11<00:41, 41.66s/it]Chrome trace exported to: /tmp/trace_74_0_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_5_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_4_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_2_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_1_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_3_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_0_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_4_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_3_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_1_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_6_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_7_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_7_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_2_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_0_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_7_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_1_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_4_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_6_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_5_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_2_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_5_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_0_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_6_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_3_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_4_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_3_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_2_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_1_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_7_131244.json
[36m(head, rank=0, pid=3472)[0m 
100%|██████████| 10/10 [06:51<00:00, 41.21s/it]Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3472)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3472)[0m 
                                               
{'loss': 124.4492, 'grad_norm': 35.656002044677734, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3472)[0m 
100%|██████████| 10/10 [06:51<00:00, 41.21s/it]Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 378.71 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 378.71s (Total: 378.71s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 378.71 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 378.71s (Total: 378.71s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 378.72 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 378.72s (Total: 378.72s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 378.72 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 378.72s (Total: 378.72s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 378.72 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 378.72s (Total: 378.72s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 378.72 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 378.72s (Total: 378.72s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 378.72 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 378.72s (Total: 378.72s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 378.71 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 378.71s (Total: 378.71s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 378.71 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 378.71s (Total: 378.71s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 378.72 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 378.72s (Total: 378.72s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 378.72 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 378.72s (Total: 378.72s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 378.72 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 378.72s (Total: 378.72s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 378.72 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 378.72s (Total: 378.72s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 378.72 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 378.72s (Total: 378.72s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 378.73 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 378.73s (Total: 378.73s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 686.50 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 686.50s (Total: 686.50s)
[36m(head, rank=0, pid=3472)[0m 
                                               
{'train_runtime': 1097.7904, 'train_samples_per_second': 1.166, 'train_steps_per_second': 0.009, 'train_loss': 124.44921875, 'epoch': 0.03}
[36m(head, rank=0, pid=3472)[0m 
100%|██████████| 10/10 [18:17<00:00, 41.21s/it]
100%|██████████| 10/10 [18:17<00:00, 109.78s/it]
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_0_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1135.39 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 686.50s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 686.50s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 686.50s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 686.50s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.50s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.10s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 325.09s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.06s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.56s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 5.33s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /mnt/data/training_run_0_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.27s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.27s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.27s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.27s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 27.83s
[36m(head, rank=0, pid=3472)[0m   • Min time: 27.83s
[36m(head, rank=0, pid=3472)[0m   • Max time: 27.83s
[36m(head, rank=0, pid=3472)[0m   • Total time: 27.83s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1135.39s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1135.39s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1135.39s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1135.39s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.06s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.56s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 5.33s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 325.09s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.10s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.50s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 686.50s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 686.50s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 686.50s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 686.50s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1165.48s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1165.48s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1165.48s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1165.48s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m --- Training Run 1 Info (Directory: /mnt/data/) ---
[36m(head, rank=0, pid=3472)[0m {
[36m(head, rank=0, pid=3472)[0m   "run_id": 1,
[36m(head, rank=0, pid=3472)[0m   "timestamp": "2025-08-03T05:41:27.081315",
[36m(head, rank=0, pid=3472)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3472)[0m   "checkpoint_dir": "/mnt/data",
[36m(head, rank=0, pid=3472)[0m   "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3472)[0m   "training_status": "completed",
[36m(head, rank=0, pid=3472)[0m   "output_dir": "/mnt/data",
[36m(head, rank=0, pid=3472)[0m   "dataset_load_time": 2.2685229778289795,
[36m(head, rank=0, pid=3472)[0m   "model_load_time": 27.826565742492676,
[36m(head, rank=0, pid=3472)[0m   "training_time": 1135.3854594230652,
[36m(head, rank=0, pid=3472)[0m   "total_time": 1165.4805481433868,
[36m(head, rank=0, pid=3472)[0m   "error": null,
[36m(head, rank=0, pid=3472)[0m   "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3472)[0m   "total_checkpoint_save_time": 686.4981553554535,
[36m(head, rank=0, pid=3472)[0m   "average_checkpoint_save_time": 686.4981553554535,
[36m(head, rank=0, pid=3472)[0m   "min_checkpoint_save_time": 686.4981553554535,
[36m(head, rank=0, pid=3472)[0m   "max_checkpoint_save_time": 686.4981553554535,
[36m(head, rank=0, pid=3472)[0m   "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3472)[0m     686.4981553554535
[36m(head, rank=0, pid=3472)[0m   ],
[36m(head, rank=0, pid=3472)[0m   "num_batch_samples": 10,
[36m(head, rank=0, pid=3472)[0m   "total_batch_sample_time": 0.500438928604126,
[36m(head, rank=0, pid=3472)[0m   "average_batch_sample_time": 0.050043892860412595,
[36m(head, rank=0, pid=3472)[0m   "min_batch_sample_time": 0.03354334831237793,
[36m(head, rank=0, pid=3472)[0m   "max_batch_sample_time": 0.1034386157989502,
[36m(head, rank=0, pid=3472)[0m   "individual_batch_sample_times": [
[36m(head, rank=0, pid=3472)[0m     0.1034386157989502,
[36m(head, rank=0, pid=3472)[0m     0.05398440361022949,
[36m(head, rank=0, pid=3472)[0m     0.07239603996276855,
[36m(head, rank=0, pid=3472)[0m     0.037915945053100586,
[36m(head, rank=0, pid=3472)[0m     0.04987025260925293,
[36m(head, rank=0, pid=3472)[0m     0.0378725528717041,
[36m(head, rank=0, pid=3472)[0m     0.03695249557495117,
[36m(head, rank=0, pid=3472)[0m     0.040128469467163086,
[36m(head, rank=0, pid=3472)[0m     0.03433680534362793,
[36m(head, rank=0, pid=3472)[0m     0.03354334831237793
[36m(head, rank=0, pid=3472)[0m   ],
[36m(head, rank=0, pid=3472)[0m   "num_training_steps": 80,
[36m(head, rank=0, pid=3472)[0m   "total_training_step_time": 325.08760261535645,
[36m(head, rank=0, pid=3472)[0m   "average_training_step_time": 4.063595032691955,
[36m(head, rank=0, pid=3472)[0m   "min_training_step_time": 3.56307053565979,
[36m(head, rank=0, pid=3472)[0m   "max_training_step_time": 5.334107398986816,
[36m(head, rank=0, pid=3472)[0m   "individual_training_step_times": [
[36m(head, rank=0, pid=3472)[0m     5.334107398986816,
[36m(head, rank=0, pid=3472)[0m     4.1135804653167725,
[36m(head, rank=0, pid=3472)[0m     4.364447355270386,
[36m(head, rank=0, pid=3472)[0m     3.770709753036499,
[36m(head, rank=0, pid=3472)[0m     4.6987316608428955,
[36m(head, rank=0, pid=3472)[0m     3.8722028732299805,
[36m(head, rank=0, pid=3472)[0m     3.56307053565979,
[36m(head, rank=0, pid=3472)[0m     3.699863910675049,
[36m(head, rank=0, pid=3472)[0m     4.074611663818359,
[36m(head, rank=0, pid=3472)[0m     4.962971448898315,
[36m(head, rank=0, pid=3472)[0m     3.8178396224975586,
[36m(head, rank=0, pid=3472)[0m     3.725285530090332,
[36m(head, rank=0, pid=3472)[0m     3.6958882808685303,
[36m(head, rank=0, pid=3472)[0m     4.951407432556152,
[36m(head, rank=0, pid=3472)[0m     4.23388409614563,
[36m(head, rank=0, pid=3472)[0m     4.100517511367798,
[36m(head, rank=0, pid=3472)[0m     4.140241384506226,
[36m(head, rank=0, pid=3472)[0m     3.7381982803344727,
[36m(head, rank=0, pid=3472)[0m     4.07935905456543,
[36m(head, rank=0, pid=3472)[0m     3.710446834564209,
[36m(head, rank=0, pid=3472)[0m     4.304413795471191,
[36m(head, rank=0, pid=3472)[0m     3.7031943798065186,
[36m(head, rank=0, pid=3472)[0m     4.84118127822876,
[36m(head, rank=0, pid=3472)[0m     3.720953941345215,
[36m(head, rank=0, pid=3472)[0m     4.97178840637207,
[36m(head, rank=0, pid=3472)[0m     3.60774564743042,
[36m(head, rank=0, pid=3472)[0m     3.8501133918762207,
[36m(head, rank=0, pid=3472)[0m     3.773793935775757,
[36m(head, rank=0, pid=3472)[0m     3.7106618881225586,
[36m(head, rank=0, pid=3472)[0m     3.706540107727051,
[36m(head, rank=0, pid=3472)[0m     4.005876064300537,
[36m(head, rank=0, pid=3472)[0m     4.380264520645142,
[36m(head, rank=0, pid=3472)[0m     4.750891923904419,
[36m(head, rank=0, pid=3472)[0m     3.900939702987671,
[36m(head, rank=0, pid=3472)[0m     3.715068817138672,
[36m(head, rank=0, pid=3472)[0m     4.077746868133545,
[36m(head, rank=0, pid=3472)[0m     4.512805700302124,
[36m(head, rank=0, pid=3472)[0m     4.436145544052124,
[36m(head, rank=0, pid=3472)[0m     3.9167592525482178,
[36m(head, rank=0, pid=3472)[0m     3.866997241973877,
[36m(head, rank=0, pid=3472)[0m     3.7138826847076416,
[36m(head, rank=0, pid=3472)[0m     3.630145788192749,
[36m(head, rank=0, pid=3472)[0m     4.8219099044799805,
[36m(head, rank=0, pid=3472)[0m     3.7054741382598877,
[36m(head, rank=0, pid=3472)[0m     3.9331274032592773,
[36m(head, rank=0, pid=3472)[0m     3.955721616744995,
[36m(head, rank=0, pid=3472)[0m     3.8609421253204346,
[36m(head, rank=0, pid=3472)[0m     3.903808832168579,
[36m(head, rank=0, pid=3472)[0m     4.798289775848389,
[36m(head, rank=0, pid=3472)[0m     4.819241285324097,
[36m(head, rank=0, pid=3472)[0m     3.760003089904785,
[36m(head, rank=0, pid=3472)[0m     3.7344417572021484,
[36m(head, rank=0, pid=3472)[0m     3.9732375144958496,
[36m(head, rank=0, pid=3472)[0m     3.6996254920959473,
[36m(head, rank=0, pid=3472)[0m     4.519198894500732,
[36m(head, rank=0, pid=3472)[0m     3.7010769844055176,
[36m(head, rank=0, pid=3472)[0m     5.054412841796875,
[36m(head, rank=0, pid=3472)[0m     4.33111834526062,
[36m(head, rank=0, pid=3472)[0m     4.047072410583496,
[36m(head, rank=0, pid=3472)[0m     4.16945743560791,
[36m(head, rank=0, pid=3472)[0m     3.721389055252075,
[36m(head, rank=0, pid=3472)[0m     3.753972053527832,
[36m(head, rank=0, pid=3472)[0m     3.8694229125976562,
[36m(head, rank=0, pid=3472)[0m     4.5033793449401855,
[36m(head, rank=0, pid=3472)[0m     3.700671672821045,
[36m(head, rank=0, pid=3472)[0m     3.7024335861206055,
[36m(head, rank=0, pid=3472)[0m     3.882068634033203,
[36m(head, rank=0, pid=3472)[0m     3.580716609954834,
[36m(head, rank=0, pid=3472)[0m     4.282103061676025,
[36m(head, rank=0, pid=3472)[0m     4.861342668533325,
[36m(head, rank=0, pid=3472)[0m     3.821668863296509,
[36m(head, rank=0, pid=3472)[0m     3.8993618488311768,
[36m(head, rank=0, pid=3472)[0m     3.579648017883301,
[36m(head, rank=0, pid=3472)[0m     4.186929225921631,
[36m(head, rank=0, pid=3472)[0m     3.867835283279419,
[36m(head, rank=0, pid=3472)[0m     4.073814392089844,
[36m(head, rank=0, pid=3472)[0m     3.9556353092193604,
[36m(head, rank=0, pid=3472)[0m     3.712594747543335,
[36m(head, rank=0, pid=3472)[0m     3.8923254013061523,
[36m(head, rank=0, pid=3472)[0m     3.7068541049957275
[36m(head, rank=0, pid=3472)[0m   ]
[36m(head, rank=0, pid=3472)[0m }
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m --- All Training Runs Summary ---
[36m(head, rank=0, pid=3472)[0m [
[36m(head, rank=0, pid=3472)[0m   {
[36m(head, rank=0, pid=3472)[0m     "run_id": 1,
[36m(head, rank=0, pid=3472)[0m     "timestamp": "2025-08-03T05:41:27.081315",
[36m(head, rank=0, pid=3472)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3472)[0m     "checkpoint_dir": "/mnt/data",
[36m(head, rank=0, pid=3472)[0m     "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3472)[0m     "training_status": "completed",
[36m(head, rank=0, pid=3472)[0m     "output_dir": "/mnt/data",
[36m(head, rank=0, pid=3472)[0m     "dataset_load_time": 2.2685229778289795,
[36m(head, rank=0, pid=3472)[0m     "model_load_time": 27.826565742492676,
[36m(head, rank=0, pid=3472)[0m     "training_time": 1135.3854594230652,
[36m(head, rank=0, pid=3472)[0m     "total_time": 1165.4805481433868,
[36m(head, rank=0, pid=3472)[0m     "error": null,
[36m(head, rank=0, pid=3472)[0m     "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3472)[0m     "total_checkpoint_save_time": 686.4981553554535,
[36m(head, rank=0, pid=3472)[0m     "average_checkpoint_save_time": 686.4981553554535,
[36m(head, rank=0, pid=3472)[0m     "min_checkpoint_save_time": 686.4981553554535,
[36m(head, rank=0, pid=3472)[0m     "max_checkpoint_save_time": 686.4981553554535,
[36m(head, rank=0, pid=3472)[0m     "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3472)[0m       686.4981553554535
[36m(head, rank=0, pid=3472)[0m     ],
[36m(head, rank=0, pid=3472)[0m     "num_batch_samples": 10,
[36m(head, rank=0, pid=3472)[0m     "total_batch_sample_time": 0.500438928604126,
[36m(head, rank=0, pid=3472)[0m     "average_batch_sample_time": 0.050043892860412595,
[36m(head, rank=0, pid=3472)[0m     "min_batch_sample_time": 0.03354334831237793,
[36m(head, rank=0, pid=3472)[0m     "max_batch_sample_time": 0.1034386157989502,
[36m(head, rank=0, pid=3472)[0m     "individual_batch_sample_times": [
[36m(head, rank=0, pid=3472)[0m       0.1034386157989502,
[36m(head, rank=0, pid=3472)[0m       0.05398440361022949,
[36m(head, rank=0, pid=3472)[0m       0.07239603996276855,
[36m(head, rank=0, pid=3472)[0m       0.037915945053100586,
[36m(head, rank=0, pid=3472)[0m       0.04987025260925293,
[36m(head, rank=0, pid=3472)[0m       0.0378725528717041,
[36m(head, rank=0, pid=3472)[0m       0.03695249557495117,
[36m(head, rank=0, pid=3472)[0m       0.040128469467163086,
[36m(head, rank=0, pid=3472)[0m       0.03433680534362793,
[36m(head, rank=0, pid=3472)[0m       0.03354334831237793
[36m(head, rank=0, pid=3472)[0m     ],
[36m(head, rank=0, pid=3472)[0m     "num_training_steps": 80,
[36m(head, rank=0, pid=3472)[0m     "total_training_step_time": 325.08760261535645,
[36m(head, rank=0, pid=3472)[0m     "average_training_step_time": 4.063595032691955,
[36m(head, rank=0, pid=3472)[0m     "min_training_step_time": 3.56307053565979,
[36m(head, rank=0, pid=3472)[0m     "max_training_step_time": 5.334107398986816,
[36m(head, rank=0, pid=3472)[0m     "individual_training_step_times": [
[36m(head, rank=0, pid=3472)[0m       5.334107398986816,
[36m(head, rank=0, pid=3472)[0m       4.1135804653167725,
[36m(head, rank=0, pid=3472)[0m       4.364447355270386,
[36m(head, rank=0, pid=3472)[0m       3.770709753036499,
[36m(head, rank=0, pid=3472)[0m       4.6987316608428955,
[36m(head, rank=0, pid=3472)[0m       3.8722028732299805,
[36m(head, rank=0, pid=3472)[0m       3.56307053565979,
[36m(head, rank=0, pid=3472)[0m       3.699863910675049,
[36m(head, rank=0, pid=3472)[0m       4.074611663818359,
[36m(head, rank=0, pid=3472)[0m       4.962971448898315,
[36m(head, rank=0, pid=3472)[0m       3.8178396224975586,
[36m(head, rank=0, pid=3472)[0m       3.725285530090332,
[36m(head, rank=0, pid=3472)[0m       3.6958882808685303,
[36m(head, rank=0, pid=3472)[0m       4.951407432556152,
[36m(head, rank=0, pid=3472)[0m       4.23388409614563,
[36m(head, rank=0, pid=3472)[0m       4.100517511367798,
[36m(head, rank=0, pid=3472)[0m       4.140241384506226,
[36m(head, rank=0, pid=3472)[0m       3.7381982803344727,
[36m(head, rank=0, pid=3472)[0m       4.07935905456543,
[36m(head, rank=0, pid=3472)[0m       3.710446834564209,
[36m(head, rank=0, pid=3472)[0m       4.304413795471191,
[36m(head, rank=0, pid=3472)[0m       3.7031943798065186,
[36m(head, rank=0, pid=3472)[0m       4.84118127822876,
[36m(head, rank=0, pid=3472)[0m       3.720953941345215,
[36m(head, rank=0, pid=3472)[0m       4.97178840637207,
[36m(head, rank=0, pid=3472)[0m       3.60774564743042,
[36m(head, rank=0, pid=3472)[0m       3.8501133918762207,
[36m(head, rank=0, pid=3472)[0m       3.773793935775757,
[36m(head, rank=0, pid=3472)[0m       3.7106618881225586,
[36m(head, rank=0, pid=3472)[0m       3.706540107727051,
[36m(head, rank=0, pid=3472)[0m       4.005876064300537,
[36m(head, rank=0, pid=3472)[0m       4.380264520645142,
[36m(head, rank=0, pid=3472)[0m       4.750891923904419,
[36m(head, rank=0, pid=3472)[0m       3.900939702987671,
[36m(head, rank=0, pid=3472)[0m       3.715068817138672,
[36m(head, rank=0, pid=3472)[0m       4.077746868133545,
[36m(head, rank=0, pid=3472)[0m       4.512805700302124,
[36m(head, rank=0, pid=3472)[0m       4.436145544052124,
[36m(head, rank=0, pid=3472)[0m       3.9167592525482178,
[36m(head, rank=0, pid=3472)[0m       3.866997241973877,
[36m(head, rank=0, pid=3472)[0m       3.7138826847076416,
[36m(head, rank=0, pid=3472)[0m       3.630145788192749,
[36m(head, rank=0, pid=3472)[0m       4.8219099044799805,
[36m(head, rank=0, pid=3472)[0m       3.7054741382598877,
[36m(head, rank=0, pid=3472)[0m       3.9331274032592773,
[36m(head, rank=0, pid=3472)[0m       3.955721616744995,
[36m(head, rank=0, pid=3472)[0m       3.8609421253204346,
[36m(head, rank=0, pid=3472)[0m       3.903808832168579,
[36m(head, rank=0, pid=3472)[0m       4.798289775848389,
[36m(head, rank=0, pid=3472)[0m       4.819241285324097,
[36m(head, rank=0, pid=3472)[0m       3.760003089904785,
[36m(head, rank=0, pid=3472)[0m       3.7344417572021484,
[36m(head, rank=0, pid=3472)[0m       3.9732375144958496,
[36m(head, rank=0, pid=3472)[0m       3.6996254920959473,
[36m(head, rank=0, pid=3472)[0m       4.519198894500732,
[36m(head, rank=0, pid=3472)[0m       3.7010769844055176,
[36m(head, rank=0, pid=3472)[0m       5.054412841796875,
[36m(head, rank=0, pid=3472)[0m       4.33111834526062,
[36m(head, rank=0, pid=3472)[0m       4.047072410583496,
[36m(head, rank=0, pid=3472)[0m       4.16945743560791,
[36m(head, rank=0, pid=3472)[0m       3.721389055252075,
[36m(head, rank=0, pid=3472)[0m       3.753972053527832,
[36m(head, rank=0, pid=3472)[0m       3.8694229125976562,
[36m(head, rank=0, pid=3472)[0m       4.5033793449401855,
[36m(head, rank=0, pid=3472)[0m       3.700671672821045,
[36m(head, rank=0, pid=3472)[0m       3.7024335861206055,
[36m(head, rank=0, pid=3472)[0m       3.882068634033203,
[36m(head, rank=0, pid=3472)[0m       3.580716609954834,
[36m(head, rank=0, pid=3472)[0m       4.282103061676025,
[36m(head, rank=0, pid=3472)[0m       4.861342668533325,
[36m(head, rank=0, pid=3472)[0m       3.821668863296509,
[36m(head, rank=0, pid=3472)[0m       3.8993618488311768,
[36m(head, rank=0, pid=3472)[0m       3.579648017883301,
[36m(head, rank=0, pid=3472)[0m       4.186929225921631,
[36m(head, rank=0, pid=3472)[0m       3.867835283279419,
[36m(head, rank=0, pid=3472)[0m       4.073814392089844,
[36m(head, rank=0, pid=3472)[0m       3.9556353092193604,
[36m(head, rank=0, pid=3472)[0m       3.712594747543335,
[36m(head, rank=0, pid=3472)[0m       3.8923254013061523,
[36m(head, rank=0, pid=3472)[0m       3.7068541049957275
[36m(head, rank=0, pid=3472)[0m     ]
[36m(head, rank=0, pid=3472)[0m   }
[36m(head, rank=0, pid=3472)[0m ]
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m --- Timing Summary ---
[36m(head, rank=0, pid=3472)[0m {
[36m(head, rank=0, pid=3472)[0m   "total_runs": 1,
[36m(head, rank=0, pid=3472)[0m   "dataset_loading": {
[36m(head, rank=0, pid=3472)[0m     "dataset_load_count": 1,
[36m(head, rank=0, pid=3472)[0m     "dataset_load_average": 2.2685229778289795,
[36m(head, rank=0, pid=3472)[0m     "dataset_load_min": 2.2685229778289795,
[36m(head, rank=0, pid=3472)[0m     "dataset_load_max": 2.2685229778289795,
[36m(head, rank=0, pid=3472)[0m     "dataset_load_total": 2.2685229778289795
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "model_loading": {
[36m(head, rank=0, pid=3472)[0m     "model_load_count": 1,
[36m(head, rank=0, pid=3472)[0m     "model_load_average": 27.826565742492676,
[36m(head, rank=0, pid=3472)[0m     "model_load_min": 27.826565742492676,
[36m(head, rank=0, pid=3472)[0m     "model_load_max": 27.826565742492676,
[36m(head, rank=0, pid=3472)[0m     "model_load_total": 27.826565742492676
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "training": {
[36m(head, rank=0, pid=3472)[0m     "training_count": 1,
[36m(head, rank=0, pid=3472)[0m     "training_average": 1135.3854594230652,
[36m(head, rank=0, pid=3472)[0m     "training_min": 1135.3854594230652,
[36m(head, rank=0, pid=3472)[0m     "training_max": 1135.3854594230652,
[36m(head, rank=0, pid=3472)[0m     "training_total": 1135.3854594230652
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "total_run_time": {
[36m(head, rank=0, pid=3472)[0m     "total_count": 1,
[36m(head, rank=0, pid=3472)[0m     "total_average": 1165.4805481433868,
[36m(head, rank=0, pid=3472)[0m     "total_min": 1165.4805481433868,
[36m(head, rank=0, pid=3472)[0m     "total_max": 1165.4805481433868,
[36m(head, rank=0, pid=3472)[0m     "total_total": 1165.4805481433868
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "checkpoint_saving": {
[36m(head, rank=0, pid=3472)[0m     "total_checkpoints_saved": 1,
[36m(head, rank=0, pid=3472)[0m     "total_checkpoint_save_time": 686.4981553554535,
[36m(head, rank=0, pid=3472)[0m     "average_save_time_per_checkpoint": 686.4981553554535,
[36m(head, rank=0, pid=3472)[0m     "checkpoint_save_times_count": 1,
[36m(head, rank=0, pid=3472)[0m     "checkpoint_save_min": 686.4981553554535,
[36m(head, rank=0, pid=3472)[0m     "checkpoint_save_max": 686.4981553554535,
[36m(head, rank=0, pid=3472)[0m     "checkpoint_save_average": 686.4981553554535
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "batch_sampling": {
[36m(head, rank=0, pid=3472)[0m     "total_batch_samples": 10,
[36m(head, rank=0, pid=3472)[0m     "total_batch_sample_time": 0.500438928604126,
[36m(head, rank=0, pid=3472)[0m     "average_sample_time_per_batch": 0.050043892860412595,
[36m(head, rank=0, pid=3472)[0m     "batch_sample_times_count": 10,
[36m(head, rank=0, pid=3472)[0m     "batch_sample_min": 0.03354334831237793,
[36m(head, rank=0, pid=3472)[0m     "batch_sample_max": 0.1034386157989502,
[36m(head, rank=0, pid=3472)[0m     "batch_sample_average": 0.050043892860412595
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "training_steps": {
[36m(head, rank=0, pid=3472)[0m     "total_training_steps": 80,
[36m(head, rank=0, pid=3472)[0m     "total_training_step_time": 325.08760261535645,
[36m(head, rank=0, pid=3472)[0m     "average_step_time_per_step": 4.063595032691955,
[36m(head, rank=0, pid=3472)[0m     "training_step_times_count": 80,
[36m(head, rank=0, pid=3472)[0m     "training_step_min": 3.56307053565979,
[36m(head, rank=0, pid=3472)[0m     "training_step_max": 5.334107398986816,
[36m(head, rank=0, pid=3472)[0m     "training_step_average": 4.063595032691955
[36m(head, rank=0, pid=3472)[0m   }
[36m(head, rank=0, pid=3472)[0m }
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_2_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1210.75 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.52s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.16s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 327.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.10s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.59s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 6.94s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /mnt/data/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.12s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.12s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.12s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.12s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 0.99s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 0.99s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 0.99s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 0.99s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1210.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1210.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1210.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1210.75s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.10s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.59s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 6.94s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 327.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.16s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.52s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1213.86s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1213.86s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1213.86s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1213.86s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_7_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1212.03 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.56s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.15s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 327.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.56s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 6.95s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /mnt/data/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_3_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1212.00 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.60s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.19s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 327.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.59s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 6.92s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /mnt/data/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.01s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.01s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.01s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.01s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1.02s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1.02s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1.02s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1.02s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1212.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1212.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1212.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1212.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.56s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 6.95s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 327.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.15s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.56s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1215.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1215.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1215.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1215.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1.27s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1.27s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1.27s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1.27s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1212.00s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1212.00s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1212.00s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1212.00s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.59s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 6.92s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 327.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.19s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.60s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1215.36s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1215.36s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1215.36s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1215.36s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_1_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1212.55 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 378.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 378.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 378.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 378.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.47s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.13s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 327.01s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 6.97s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /mnt/data/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_2_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1212.59 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 378.72s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 378.72s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.53s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.17s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 325.76s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.07s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.57s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 6.93s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /mnt/data/training_run_2_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.50s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.50s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.50s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.50s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.09s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.09s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.09s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.09s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1212.59s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1212.59s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1212.59s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1212.59s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.07s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.57s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 6.93s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 325.76s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.17s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.53s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 378.72s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 378.72s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1216.18s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1216.18s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1216.18s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1216.18s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1212.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1212.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1212.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1212.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 6.97s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 327.01s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.13s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.47s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 378.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 378.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 378.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 378.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1215.65s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1215.65s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1215.65s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1215.65s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_4_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1212.88 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.53s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.16s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 326.85s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.58s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 6.94s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /mnt/data/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_1_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1212.95 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 378.71s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 378.71s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 378.71s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 378.71s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.49s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.13s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 325.76s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.07s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.55s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 6.97s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /mnt/data/training_run_1_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.00s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.00s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.00s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.00s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1212.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1212.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1212.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1212.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.58s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 6.94s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 326.85s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.16s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.53s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1215.91s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1215.91s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1215.91s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1215.91s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_4.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_6_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1212.84 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.50s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 327.54s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 6.96s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /mnt/data/training_run_6_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_6_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1212.97 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 378.72s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 378.72s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.56s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.06s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.16s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 325.73s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.07s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.58s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 6.94s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /mnt/data/training_run_6_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_5_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1213.01 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.58s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.16s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 327.36s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.56s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 6.94s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /mnt/data/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.42s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.42s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.42s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.42s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1212.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1212.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1212.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1212.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 6.96s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 327.54s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.50s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1216.40s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1216.40s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1216.40s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1216.40s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.29s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.29s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.29s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.29s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.08s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.08s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.08s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.08s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1212.97s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1212.97s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1212.97s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1212.97s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.07s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.58s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 6.94s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 325.73s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.06s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.16s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.56s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 378.72s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 378.72s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1216.34s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1216.34s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1216.34s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1216.34s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.40s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.40s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.40s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.40s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.08s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.08s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.08s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.08s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1212.95s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1212.95s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1212.95s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1212.95s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.07s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.55s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 6.97s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 325.76s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.13s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.49s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 378.71s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 378.71s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 378.71s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 378.71s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1216.43s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1216.43s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1216.43s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1216.43s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.22s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.22s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.22s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.22s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 0.99s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 0.99s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 0.99s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 0.99s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1213.01s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1213.01s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1213.01s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1213.01s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.56s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 6.94s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 327.36s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.16s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.58s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 378.72s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1216.22s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1216.22s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1216.22s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1216.22s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_0_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1187.28 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.44s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 324.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.56s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 5.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /mnt/data/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.24s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.24s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.24s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.24s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 27.93s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 27.93s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 27.93s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 27.93s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1187.28s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1187.28s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1187.28s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1187.28s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.56s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 5.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 324.88s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.44s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 378.71s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1217.46s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1217.46s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1217.46s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1217.46s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_0.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m --- Training Run 1 Info (Directory: /mnt/data/) ---
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "run_id": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "timestamp": "2025-08-03T05:41:27.081107",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "checkpoint_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "training_status": "completed",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "output_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "dataset_load_time": 2.2441418170928955,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "model_load_time": 27.932166576385498,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "training_time": 1187.2846903800964,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_time": 1217.4609987735748,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "error": null,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_checkpoint_save_time": 378.7145092487335,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "average_checkpoint_save_time": 378.7145092487335,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "min_checkpoint_save_time": 378.7145092487335,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "max_checkpoint_save_time": 378.7145092487335,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     378.7145092487335
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   ],
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_batch_sample_time": 0.43806934356689453,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "average_batch_sample_time": 0.043806934356689455,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "min_batch_sample_time": 0.028147220611572266,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "max_batch_sample_time": 0.060929298400878906,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.060929298400878906,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.057613372802734375,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.03961038589477539,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.049720048904418945,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.050937652587890625,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.034448862075805664,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.03494095802307129,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.03626298904418945,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.04545855522155762,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.028147220611572266
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   ],
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "num_training_steps": 80,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_training_step_time": 324.8769676685333,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "average_training_step_time": 4.060962095856667,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "min_training_step_time": 3.564023017883301,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "max_training_step_time": 5.058772325515747,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "individual_training_step_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.0553882122039795,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7257206439971924,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.364488363265991,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7743072509765625,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.730975151062012,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.8748016357421875,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.833421468734741,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7068192958831787,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.331717252731323,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.935821533203125,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.729668378829956,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7232720851898193,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.6974871158599854,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.953874826431274,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.709517240524292,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.6065661907196045,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.116512298583984,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7383928298950195,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.03715181350708,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.715416669845581,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.327221632003784,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.704683542251587,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.7123308181762695,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7231853008270264,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.965356111526489,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.706970691680908,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.869356870651245,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.772270679473877,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.564023017883301,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7107720375061035,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.955641746520996,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.38596773147583,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.797790288925171,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.898690938949585,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7172999382019043,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.077682018280029,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.511189222335815,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.3932459354400635,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.875946044921875,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.8731908798217773,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.634312629699707,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.770350217819214,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.848084449768066,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7090728282928467,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.955838680267334,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.9556853771209717,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.9590113162994385,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.9076130390167236,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.7997424602508545,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.820091962814331,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.721086263656616,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.736332654953003,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.9721217155456543,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.6118345260620117,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.5998334884643555,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.70540452003479,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.058772325515747,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.332695484161377,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.0403523445129395,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.147021055221558,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.5698444843292236,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.749840497970581,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.969123125076294,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.403705358505249,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7011120319366455,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.6144330501556396,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.898895502090454,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.666049003601074,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.280926704406738,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.855745315551758,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.000823259353638,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.8999006748199463,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7227883338928223,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.229317903518677,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7205772399902344,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.073670148849487,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.87278151512146,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.687971353530884,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.061638116836548,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7084310054779053
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   ]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m }
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m --- All Training Runs Summary ---
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "run_id": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "timestamp": "2025-08-03T05:41:27.081107",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "checkpoint_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_status": "completed",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "output_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_time": 2.2441418170928955,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_time": 27.932166576385498,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_time": 1187.2846903800964,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_time": 1217.4609987735748,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "error": null,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_checkpoint_save_time": 378.7145092487335,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_checkpoint_save_time": 378.7145092487335,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "min_checkpoint_save_time": 378.7145092487335,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "max_checkpoint_save_time": 378.7145092487335,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       378.7145092487335
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     ],
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_batch_sample_time": 0.43806934356689453,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_batch_sample_time": 0.043806934356689455,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "min_batch_sample_time": 0.028147220611572266,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "max_batch_sample_time": 0.060929298400878906,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.060929298400878906,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.057613372802734375,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.03961038589477539,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.049720048904418945,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.050937652587890625,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.034448862075805664,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.03494095802307129,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.03626298904418945,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.04545855522155762,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.028147220611572266
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     ],
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "num_training_steps": 80,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_training_step_time": 324.8769676685333,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_training_step_time": 4.060962095856667,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "min_training_step_time": 3.564023017883301,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "max_training_step_time": 5.058772325515747,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "individual_training_step_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.0553882122039795,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7257206439971924,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.364488363265991,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7743072509765625,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.730975151062012,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.8748016357421875,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.833421468734741,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7068192958831787,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.331717252731323,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.935821533203125,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.729668378829956,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7232720851898193,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.6974871158599854,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.953874826431274,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.709517240524292,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.6065661907196045,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.116512298583984,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7383928298950195,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.03715181350708,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.715416669845581,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.327221632003784,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.704683542251587,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.7123308181762695,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7231853008270264,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.965356111526489,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.706970691680908,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.869356870651245,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.772270679473877,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.564023017883301,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7107720375061035,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.955641746520996,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.38596773147583,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.797790288925171,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.898690938949585,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7172999382019043,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.077682018280029,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.511189222335815,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.3932459354400635,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.875946044921875,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.8731908798217773,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.634312629699707,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.770350217819214,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.848084449768066,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7090728282928467,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.955838680267334,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.9556853771209717,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.9590113162994385,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.9076130390167236,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.7997424602508545,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.820091962814331,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.721086263656616,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.736332654953003,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.9721217155456543,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.6118345260620117,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.5998334884643555,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.70540452003479,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.058772325515747,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.332695484161377,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.0403523445129395,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.147021055221558,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.5698444843292236,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.749840497970581,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.969123125076294,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.403705358505249,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7011120319366455,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.6144330501556396,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.898895502090454,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.666049003601074,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.280926704406738,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.855745315551758,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.000823259353638,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.8999006748199463,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7227883338928223,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.229317903518677,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7205772399902344,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.073670148849487,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.87278151512146,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.687971353530884,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.061638116836548,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7084310054779053
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     ]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   }
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m --- Timing Summary ---
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_runs": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "dataset_loading": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_count": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_average": 2.2441418170928955,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_min": 2.2441418170928955,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_max": 2.2441418170928955,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_total": 2.2441418170928955
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "model_loading": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_count": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_average": 27.932166576385498,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_min": 27.932166576385498,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_max": 27.932166576385498,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_total": 27.932166576385498
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "training": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_count": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_average": 1187.2846903800964,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_min": 1187.2846903800964,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_max": 1187.2846903800964,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_total": 1187.2846903800964
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_run_time": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_count": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_average": 1217.4609987735748,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_min": 1217.4609987735748,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_max": 1217.4609987735748,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_total": 1217.4609987735748
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "checkpoint_saving": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_checkpoint_save_time": 378.7145092487335,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_save_time_per_checkpoint": 378.7145092487335,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "checkpoint_save_times_count": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "checkpoint_save_min": 378.7145092487335,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "checkpoint_save_max": 378.7145092487335,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "checkpoint_save_average": 378.7145092487335
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "batch_sampling": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_batch_samples": 10,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_batch_sample_time": 0.43806934356689453,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_sample_time_per_batch": 0.043806934356689455,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "batch_sample_times_count": 10,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "batch_sample_min": 0.028147220611572266,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "batch_sample_max": 0.060929298400878906,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "batch_sample_average": 0.043806934356689455
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "training_steps": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_training_steps": 80,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_training_step_time": 324.8769676685333,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_step_time_per_step": 4.060962095856667,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_step_times_count": 80,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_step_min": 3.564023017883301,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_step_max": 5.058772325515747,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_step_average": 4.060962095856667
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   }
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m }
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_7_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1216.42 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 378.72s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 378.72s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.52s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.13s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 326.64s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.08s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.57s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 6.98s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /mnt/data/training_run_7_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.31s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.31s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.31s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.31s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.03s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.03s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.03s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.03s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1216.42s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1216.42s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1216.42s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1216.42s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.08s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.57s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 6.98s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 326.64s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.13s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.52s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 378.72s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 378.72s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1219.77s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1219.77s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1219.77s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1219.77s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_3_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1217.31 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 378.72s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 378.72s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.54s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.16s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 326.74s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.08s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.57s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 6.95s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /mnt/data/training_run_3_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_4_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1217.32 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 378.71s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 378.71s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 378.71s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 378.71s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.54s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.16s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 326.49s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.08s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.57s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 6.95s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /mnt/data/training_run_4_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.30s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.30s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.30s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.30s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.08s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.08s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.08s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.08s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1217.31s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1217.31s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1217.31s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1217.31s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.08s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.57s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 6.95s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 326.74s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.16s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.54s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 378.72s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 378.72s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1220.69s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1220.69s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1220.69s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1220.69s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_5_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1217.55 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 378.72s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 378.72s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.57s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.06s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.17s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 327.10s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.09s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.56s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 6.94s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /mnt/data/training_run_5_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.53s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.53s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.53s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.53s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.01s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.01s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.01s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.01s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1217.32s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1217.32s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1217.32s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1217.32s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.08s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.57s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 6.95s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 326.49s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.16s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.54s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 378.71s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 378.71s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 378.71s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 378.71s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1220.86s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1220.86s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1220.86s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1220.86s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.25s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.25s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.25s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.25s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.03s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.03s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.03s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.03s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1217.55s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1217.55s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1217.55s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1217.55s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.09s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.56s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 6.94s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 327.10s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.06s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.17s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.57s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 378.72s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 378.72s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 378.72s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1220.83s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1220.83s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1220.83s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1220.83s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3472)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.92 secondsCompleted Load dataset in 2.86 seconds
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.87 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.88 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.89 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.90 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.88 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.87 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 3.07 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 3.06 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 3.05 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 3.05 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 3.05 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 3.04 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 3.10 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 3.08 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  8.07it/s]
Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  6.90it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  7.75it/s]
Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  7.92it/s]
Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  7.56it/s]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  6.59it/s]
Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00, 12.21it/s]
Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00, 13.06it/s]
Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00, 11.63it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00, 11.73it/s]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00, 11.21it/s]
Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  8.83it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00, 15.47it/s]
Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00, 15.18it/s]
Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  9.19it/s]
Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  9.10it/s]
Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  9.10it/s]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  8.70it/s]
Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00, 10.25it/s]
Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00, 10.39it/s]
Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00, 10.57it/s]
Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00, 10.82it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  7.15it/s]
Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00, 11.50it/s]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  6.84it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 10.25it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 10.66it/s]
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 10.12it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  9.19it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 10.42it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.89it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 10.15it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  9.28it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  9.05it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 11.93it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 11.17it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 11.25it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 12.41it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 10.52it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 10.23it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  9.42it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  9.47it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  9.23it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  9.43it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  9.31it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  9.25it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.75it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.85it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.55 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.55 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.55 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.55 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.55 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.52 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.73 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.72 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.73 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.73 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.74 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.74 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.56 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.79 seconds
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:10<00:43, 10.83s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:10<00:41, 10.38s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:20<00:30, 10.20s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:20<00:30, 10.26s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:29<00:19,  9.84s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:29<00:19,  9.83s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:39<00:09,  9.81s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:48<00:00,  9.44s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:48<00:00,  9.69s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 49.66 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:40<00:09,  9.97s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:50<00:00, 10.01s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:50<00:00, 10.05s/it]
[36m(head, rank=0, pid=3472)[0m Completed Load model in 51.36 seconds
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Completed Training in 3.70 seconds
[36m(head, rank=0, pid=3472)[0m [rank0]: Traceback (most recent call last):
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "/e2e/train.py", line 745, in <module>
[36m(head, rank=0, pid=3472)[0m [rank0]:     main()
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "/e2e/train.py", line 614, in main
[36m(head, rank=0, pid=3472)[0m [rank0]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "/e2e/train.py", line 105, in __init__
[36m(head, rank=0, pid=3472)[0m [rank0]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3472)[0m [rank0]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 810, in _prepare_dataset
[36m(head, rank=0, pid=3472)[0m [rank0]:     dataset = dataset.map(
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 560, in wrapper
[36m(head, rank=0, pid=3472)[0m [rank0]:     out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3266, in map
[36m(head, rank=0, pid=3472)[0m [rank0]:     transformed_shards[rank] = load_processed_shard_from_cache(job_kwargs)
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3153, in load_processed_shard_from_cache
[36m(head, rank=0, pid=3472)[0m [rank0]:     return Dataset.from_file(shard_kwargs["cache_file_name"], info=info, split=shard.split)
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 800, in from_file
[36m(head, rank=0, pid=3472)[0m [rank0]:     table = ArrowReader.read_table(filename, in_memory=in_memory)
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_reader.py", line 329, in read_table
[36m(head, rank=0, pid=3472)[0m [rank0]:     return table_cls.from_file(filename)
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/table.py", line 1017, in from_file
[36m(head, rank=0, pid=3472)[0m [rank0]:     table = _memory_mapped_arrow_table_from_file(filename)
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/table.py", line 63, in _memory_mapped_arrow_table_from_file
[36m(head, rank=0, pid=3472)[0m [rank0]:     opened_stream = _memory_mapped_record_batch_reader_from_file(filename)
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/table.py", line 49, in _memory_mapped_record_batch_reader_from_file
[36m(head, rank=0, pid=3472)[0m [rank0]:     return pa.ipc.open_stream(memory_mapped_stream)
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/pyarrow/ipc.py", line 187, in open_stream
[36m(head, rank=0, pid=3472)[0m [rank0]:     return RecordBatchStreamReader(source, options=options,
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/pyarrow/ipc.py", line 52, in __init__
[36m(head, rank=0, pid=3472)[0m [rank0]:     self._open(source, options=options, memory_pool=memory_pool)
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "pyarrow/ipc.pxi", line 1038, in pyarrow.lib._RecordBatchStreamReader._open
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "pyarrow/error.pxi", line 155, in pyarrow.lib.pyarrow_internal_check_status
[36m(head, rank=0, pid=3472)[0m [rank0]:   File "pyarrow/error.pxi", line 92, in pyarrow.lib.check_status
[36m(head, rank=0, pid=3472)[0m [rank0]: pyarrow.lib.ArrowInvalid: Tried reading schema message, was null or length 0
[36m(head, rank=0, pid=3472)[0m Completed Training in 55.83 seconds
[36m(head, rank=0, pid=3472)[0m Completed Training in 55.73 seconds
[36m(head, rank=0, pid=3472)[0m [rank1]: Traceback (most recent call last):
[36m(head, rank=0, pid=3472)[0m [rank1]:   File "/e2e/train.py", line 745, in <module>
[36m(head, rank=0, pid=3472)[0m [rank1]:     main()
[36m(head, rank=0, pid=3472)[0m [rank1]:   File "/e2e/train.py", line 614, in main
[36m(head, rank=0, pid=3472)[0m [rank1]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3472)[0m [rank1]:   File "/e2e/train.py", line 105, in __init__
[36m(head, rank=0, pid=3472)[0m [rank1]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3472)[0m [rank1]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3472)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3472)[0m [rank1]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3472)[0m [rank1]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3472)[0m [rank1]:     return next(self.gen)
[36m(head, rank=0, pid=3472)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3472)[0m [rank1]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3472)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3472)[0m [rank1]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3472)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3472)[0m [rank1]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3472)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3472)[0m [rank1]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3472)[0m [rank1]:     work.wait()
[36m(head, rank=0, pid=3472)[0m [rank1]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.185]:43204
[36m(head, rank=0, pid=3472)[0m [rank2]: Traceback (most recent call last):
[36m(head, rank=0, pid=3472)[0m [rank2]:   File "/e2e/train.py", line 745, in <module>
[36m(head, rank=0, pid=3472)[0m [rank2]:     main()
[36m(head, rank=0, pid=3472)[0m [rank2]:   File "/e2e/train.py", line 614, in main
[36m(head, rank=0, pid=3472)[0m [rank2]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3472)[0m [rank2]:   File "/e2e/train.py", line 105, in __init__
[36m(head, rank=0, pid=3472)[0m [rank2]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3472)[0m [rank2]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3472)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3472)[0m [rank2]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3472)[0m [rank2]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3472)[0m [rank2]:     return next(self.gen)
[36m(head, rank=0, pid=3472)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3472)[0m [rank2]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3472)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3472)[0m [rank2]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3472)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3472)[0m [rank2]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3472)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3472)[0m [rank2]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3472)[0m [rank2]:     work.wait()
[36m(head, rank=0, pid=3472)[0m [rank2]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.185]:31652
[36m(head, rank=0, pid=3472)[0m Completed Training in 55.73 seconds
[36m(head, rank=0, pid=3472)[0m [rank4]: Traceback (most recent call last):
[36m(head, rank=0, pid=3472)[0m [rank4]:   File "/e2e/train.py", line 745, in <module>
[36m(head, rank=0, pid=3472)[0m [rank4]:     main()
[36m(head, rank=0, pid=3472)[0m [rank4]:   File "/e2e/train.py", line 614, in main
[36m(head, rank=0, pid=3472)[0m [rank4]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3472)[0m [rank4]:   File "/e2e/train.py", line 105, in __init__
[36m(head, rank=0, pid=3472)[0m [rank4]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3472)[0m [rank4]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3472)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3472)[0m [rank4]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3472)[0m [rank4]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3472)[0m [rank4]:     return next(self.gen)
[36m(head, rank=0, pid=3472)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3472)[0m [rank4]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3472)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3472)[0m [rank4]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3472)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3472)[0m [rank4]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3472)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3472)[0m [rank4]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3472)[0m [rank4]:     work.wait()
[36m(head, rank=0, pid=3472)[0m [rank4]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.185]:31652
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 8.21 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:   File "/e2e/train.py", line 745, in <module>
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:     main()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:   File "/e2e/train.py", line 614, in main
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:     return next(self.gen)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]:     work.wait()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank8]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.185]:34983
[36m(head, rank=0, pid=3472)[0m [rank0]:[W803 06:03:29.241347017 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 55.79 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:   File "/e2e/train.py", line 745, in <module>
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:     main()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:   File "/e2e/train.py", line 614, in main
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:     return next(self.gen)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]:     work.wait()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank12]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.185]:53473
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 55.81 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:   File "/e2e/train.py", line 745, in <module>
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:     main()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:   File "/e2e/train.py", line 614, in main
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:     return next(self.gen)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]:     work.wait()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank14]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.185]:25231
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 55.85 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:   File "/e2e/train.py", line 745, in <module>
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:     main()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:   File "/e2e/train.py", line 614, in main
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:     return next(self.gen)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]:     work.wait()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank15]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.185]:36064
[36m(head, rank=0, pid=3472)[0m Completed Training in 56.15 seconds
[36m(head, rank=0, pid=3472)[0m [rank3]: Traceback (most recent call last):
[36m(head, rank=0, pid=3472)[0m [rank3]:   File "/e2e/train.py", line 745, in <module>
[36m(head, rank=0, pid=3472)[0m [rank3]:     main()
[36m(head, rank=0, pid=3472)[0m [rank3]:   File "/e2e/train.py", line 614, in main
[36m(head, rank=0, pid=3472)[0m [rank3]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3472)[0m [rank3]:   File "/e2e/train.py", line 105, in __init__
[36m(head, rank=0, pid=3472)[0m [rank3]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3472)[0m [rank3]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3472)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3472)[0m [rank3]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3472)[0m [rank3]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3472)[0m [rank3]:     return next(self.gen)
[36m(head, rank=0, pid=3472)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3472)[0m [rank3]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3472)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3472)[0m [rank3]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3472)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3472)[0m [rank3]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3472)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3472)[0m [rank3]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3472)[0m [rank3]:     work.wait()
[36m(head, rank=0, pid=3472)[0m [rank3]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.185]:5550
[36m(head, rank=0, pid=3472)[0m Completed Training in 56.11 seconds
[36m(head, rank=0, pid=3472)[0m [rank5]: Traceback (most recent call last):
[36m(head, rank=0, pid=3472)[0m [rank5]:   File "/e2e/train.py", line 745, in <module>
[36m(head, rank=0, pid=3472)[0m [rank5]:     main()
[36m(head, rank=0, pid=3472)[0m [rank5]:   File "/e2e/train.py", line 614, in main
[36m(head, rank=0, pid=3472)[0m [rank5]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3472)[0m [rank5]:   File "/e2e/train.py", line 105, in __init__
[36m(head, rank=0, pid=3472)[0m [rank5]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3472)[0m [rank5]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3472)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3472)[0m [rank5]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3472)[0m [rank5]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3472)[0m [rank5]:     return next(self.gen)
[36m(head, rank=0, pid=3472)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3472)[0m [rank5]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3472)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3472)[0m [rank5]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3472)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3472)[0m [rank5]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3472)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3472)[0m [rank5]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3472)[0m [rank5]:     work.wait()
[36m(head, rank=0, pid=3472)[0m [rank5]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.185]:57500
[36m(head, rank=0, pid=3472)[0m Completed Training in 56.22 seconds
[36m(head, rank=0, pid=3472)[0m [rank6]: Traceback (most recent call last):
[36m(head, rank=0, pid=3472)[0m [rank6]:   File "/e2e/train.py", line 745, in <module>
[36m(head, rank=0, pid=3472)[0m [rank6]:     main()
[36m(head, rank=0, pid=3472)[0m [rank6]:   File "/e2e/train.py", line 614, in main
[36m(head, rank=0, pid=3472)[0m [rank6]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3472)[0m [rank6]:   File "/e2e/train.py", line 105, in __init__
[36m(head, rank=0, pid=3472)[0m [rank6]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3472)[0m [rank6]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3472)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3472)[0m [rank6]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3472)[0m [rank6]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3472)[0m [rank6]:     return next(self.gen)
[36m(head, rank=0, pid=3472)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3472)[0m [rank6]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3472)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3472)[0m [rank6]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3472)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3472)[0m [rank6]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3472)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3472)[0m [rank6]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3472)[0m [rank6]:     work.wait()
[36m(head, rank=0, pid=3472)[0m [rank6]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.185]:12977
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 56.32 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:   File "/e2e/train.py", line 745, in <module>
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:     main()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:   File "/e2e/train.py", line 614, in main
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:     return next(self.gen)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]:     work.wait()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank10]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.102.30.168]:50403
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 56.36 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:   File "/e2e/train.py", line 745, in <module>
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:     main()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:   File "/e2e/train.py", line 614, in main
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:     return next(self.gen)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]:     work.wait()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank11]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.102.30.168]:4487
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 56.37 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:   File "/e2e/train.py", line 745, in <module>
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:     main()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:   File "/e2e/train.py", line 614, in main
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:     return next(self.gen)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]:     work.wait()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank13]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.102.30.168]:4487
[36m(head, rank=0, pid=3472)[0m Completed Training in 56.60 seconds
[36m(head, rank=0, pid=3472)[0m [rank7]: Traceback (most recent call last):
[36m(head, rank=0, pid=3472)[0m [rank7]:   File "/e2e/train.py", line 745, in <module>
[36m(head, rank=0, pid=3472)[0m [rank7]:     main()
[36m(head, rank=0, pid=3472)[0m [rank7]:   File "/e2e/train.py", line 614, in main
[36m(head, rank=0, pid=3472)[0m [rank7]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3472)[0m [rank7]:   File "/e2e/train.py", line 105, in __init__
[36m(head, rank=0, pid=3472)[0m [rank7]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank7]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3472)[0m [rank7]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3472)[0m [rank7]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3472)[0m [rank7]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3472)[0m [rank7]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3472)[0m [rank7]:     return next(self.gen)
[36m(head, rank=0, pid=3472)[0m [rank7]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3472)[0m [rank7]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3472)[0m [rank7]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3472)[0m [rank7]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3472)[0m [rank7]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3472)[0m [rank7]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3472)[0m [rank7]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3472)[0m [rank7]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3472)[0m [rank7]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3472)[0m [rank7]:     work.wait()
[36m(head, rank=0, pid=3472)[0m [rank7]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.185]:22232
[36m(head, rank=0, pid=3472)[0m W0803 06:03:30.039000 2111217 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2114595 closing signal SIGTERM
[36m(head, rank=0, pid=3472)[0m W0803 06:03:30.039000 2111217 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2114596 closing signal SIGTERM
[36m(head, rank=0, pid=3472)[0m W0803 06:03:30.039000 2111217 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2114597 closing signal SIGTERM
[36m(head, rank=0, pid=3472)[0m W0803 06:03:30.040000 2111217 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2114598 closing signal SIGTERM
[36m(head, rank=0, pid=3472)[0m W0803 06:03:30.040000 2111217 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2114599 closing signal SIGTERM
[36m(head, rank=0, pid=3472)[0m W0803 06:03:30.040000 2111217 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2114600 closing signal SIGTERM
[36m(head, rank=0, pid=3472)[0m W0803 06:03:30.041000 2111217 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2114601 closing signal SIGTERM
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 56.92 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:   File "/e2e/train.py", line 745, in <module>
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:     main()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:   File "/e2e/train.py", line 614, in main
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:     return next(self.gen)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]:     work.wait()
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [rank9]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.102.30.168]:32669
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m W0803 06:03:30.571000 1857936 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1859161 closing signal SIGTERM
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m W0803 06:03:30.572000 1857936 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1859162 closing signal SIGTERM
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m W0803 06:03:30.572000 1857936 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1859163 closing signal SIGTERM
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m W0803 06:03:30.572000 1857936 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1859164 closing signal SIGTERM
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m W0803 06:03:30.573000 1857936 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1859165 closing signal SIGTERM
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m W0803 06:03:30.573000 1857936 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1859166 closing signal SIGTERM
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m W0803 06:03:30.573000 1857936 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1859168 closing signal SIGTERM
[36m(head, rank=0, pid=3472)[0m E0803 06:03:31.252000 2111217 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 2114594) of binary: /root/training/bin/python3
[36m(head, rank=0, pid=3472)[0m Traceback (most recent call last):
[36m(head, rank=0, pid=3472)[0m   File "/root/training/bin/accelerate", line 10, in <module>
[36m(head, rank=0, pid=3472)[0m     sys.exit(main())
[36m(head, rank=0, pid=3472)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
[36m(head, rank=0, pid=3472)[0m     args.func(args)
[36m(head, rank=0, pid=3472)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1186, in launch_command
[36m(head, rank=0, pid=3472)[0m     multi_gpu_launcher(args)
[36m(head, rank=0, pid=3472)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/launch.py", line 815, in multi_gpu_launcher
[36m(head, rank=0, pid=3472)[0m     distrib_run.run(args)
[36m(head, rank=0, pid=3472)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/run.py", line 883, in run
[36m(head, rank=0, pid=3472)[0m     elastic_launch(
[36m(head, rank=0, pid=3472)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
[36m(head, rank=0, pid=3472)[0m     return launch_agent(self._config, self._entrypoint, list(args))
[36m(head, rank=0, pid=3472)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 270, in launch_agent
[36m(head, rank=0, pid=3472)[0m     raise ChildFailedError(
[36m(head, rank=0, pid=3472)[0m torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
[36m(head, rank=0, pid=3472)[0m ============================================================
[36m(head, rank=0, pid=3472)[0m /e2e/train.py FAILED
[36m(head, rank=0, pid=3472)[0m ------------------------------------------------------------
[36m(head, rank=0, pid=3472)[0m Failures:
[36m(head, rank=0, pid=3472)[0m   <NO_OTHER_FAILURES>
[36m(head, rank=0, pid=3472)[0m ------------------------------------------------------------
[36m(head, rank=0, pid=3472)[0m Root Cause (first observed failure):
[36m(head, rank=0, pid=3472)[0m [0]:
[36m(head, rank=0, pid=3472)[0m   time      : 2025-08-03_06:03:30
[36m(head, rank=0, pid=3472)[0m   host      : dd-3c0a52b3-head
[36m(head, rank=0, pid=3472)[0m   rank      : 0 (local_rank: 0)
[36m(head, rank=0, pid=3472)[0m   exitcode  : 1 (pid: 2114594)
[36m(head, rank=0, pid=3472)[0m   error_file: <N/A>
[36m(head, rank=0, pid=3472)[0m   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[36m(head, rank=0, pid=3472)[0m ============================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m E0803 06:03:31.745000 1857936 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 6 (pid: 1859167) of binary: /root/training/bin/python3
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Traceback (most recent call last):
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   File "/root/training/bin/accelerate", line 10, in <module>
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     sys.exit(main())
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     args.func(args)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1186, in launch_command
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     multi_gpu_launcher(args)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/launch.py", line 815, in multi_gpu_launcher
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     distrib_run.run(args)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/run.py", line 883, in run
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     elastic_launch(
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     return launch_agent(self._config, self._entrypoint, list(args))
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 270, in launch_agent
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     raise ChildFailedError(
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ============================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m /e2e/train.py FAILED
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ------------------------------------------------------------
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Failures:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   <NO_OTHER_FAILURES>
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ------------------------------------------------------------
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Root Cause (first observed failure):
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [0]:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   time      : 2025-08-03_06:03:30
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   host      : dd-3c0a52b3-worker1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   rank      : 14 (local_rank: 6)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   exitcode  : 1 (pid: 1859167)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   error_file: <N/A>
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ============================================================
[36m(head, rank=0, pid=3472)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3472)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3472)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3472)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load dataset...
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.36 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.36 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.36 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.36 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.39 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.39 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.38 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.39 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.39 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.38 secondsCompleted Load dataset in 2.38 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.40 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.40 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.44 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m Completed Load dataset in 2.56 seconds
[36m(head, rank=0, pid=3472)[0m Starting Load model...
[36m(head, rank=0, pid=3472)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load dataset in 2.64 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Load model...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 42.58it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 44.02it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 43.15it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 42.56it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 46.68it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 42.51it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 43.96it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 43.08it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 42.50it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 46.60it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00, 36.86it/s]
Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00, 35.18it/s]
Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00, 35.01it/s]
Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00, 34.63it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 63.48it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 37.51it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 37.35it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 39.02it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 36.99it/s]
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 116.22it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 1.13 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.14 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.14 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.11 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.06 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.10 seconds
[36m(head, rank=0, pid=3472)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 116.18it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 100.09it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.05 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.05 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.06 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.06 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 1.06 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 0.93 seconds
[36m(head, rank=0, pid=3472)[0m Completed Load model in 1.09 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...Starting Training...
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  6.02it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 27.72it/s]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 3.81 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:20<01:22, 20.57s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:16<01:05, 16.32s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:37<00:56, 19.00s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:36<00:52, 17.55s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:57<00:38, 19.44s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:58<00:40, 20.19s/it]
[36m(head, rank=0, pid=3472)[0m Loading checkpoint shards:  80%|████████  | 4/5 [01:18<00:20, 20.08s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [01:38<00:00, 19.92s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [01:38<00:00, 19.68s/it]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Loading checkpoint shards:  80%|████████  | 4/5 [01:19<00:20, 20.52s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [01:39<00:00, 20.20s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [01:39<00:00, 19.89s/it]
[36m(head, rank=0, pid=3472)[0m Completed Load model in 100.54 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Load model in 100.47 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m Starting Training...
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:45,090] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:46,034] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:46,034] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:46,037] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:46,040] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:46,041] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:46,059] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:46,123] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:46,328] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:47,301] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:47,304] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:47,307] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:47,309] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:47,341] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:47,344] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m [2025-08-03 06:05:47,380] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:50,762] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:50,763] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:50,764] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:50,768] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:50,768] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:50,769] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:50,772] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:50,784] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:51,912] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:51,989] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:52,000] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:52,000] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:52,013] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:52,013] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:52,017] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [2025-08-03 06:05:52,020] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m   0%|          | 0/10 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3472)[0m  10%|█         | 1/10 [00:39<05:55, 39.55s/it]Chrome trace exported to: /tmp/trace_10_0_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_4_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_6_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_7_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_6_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_5_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_1_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_5_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_2_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_10_3_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_7_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_1_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_2_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_3_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_0_770487.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_10_4_770487.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_5_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_2_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_5_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_0_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_3_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_6_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_4_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_6_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_4_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_7_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_3_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_0_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_1_216739.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_14_2_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_7_216739.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_14_1_216739.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m  20%|██        | 2/10 [01:21<05:25, 40.70s/it]Chrome trace exported to: /tmp/trace_18_1_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_2_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_3_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_0_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_5_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_4_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_5_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_6_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_3_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_1_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_7_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_18_6_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_4_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_7_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_2_126225.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_18_0_126225.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_3_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_4_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_2_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_5_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_3_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_4_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_0_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_6_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_5_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_2_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_1_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_6_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_7_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_7_877572.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_22_1_877572.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_22_0_877572.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_6_388389.json
[36m(head, rank=0, pid=3472)[0m  30%|███       | 3/10 [02:01<04:43, 40.57s/it]Chrome trace exported to: /tmp/trace_26_3_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_1_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_2_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_1_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_0_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_0_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_5_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_6_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_4_388389.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_26_7_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_2_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_5_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_7_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_4_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_26_3_388389.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_0_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_2_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_1_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_6_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_0_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_5_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_2_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_4_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_6_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_7_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_4_356787.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_30_3_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_1_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_5_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_3_356787.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_30_7_356787.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_2_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_4_334053.json
[36m(head, rank=0, pid=3472)[0m  40%|████      | 4/10 [02:42<04:04, 40.76s/it]Chrome trace exported to: /tmp/trace_34_3_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_5_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_7_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_3_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_1_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_0_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_34_6_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_1_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_2_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_5_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_4_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_6_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_7_334053.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_34_0_334053.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_6_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_7_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_3_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_5_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_0_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_4_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_6_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_1_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_0_246316.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_38_2_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_1_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_2_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_5_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_4_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_3_246316.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_38_7_246316.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_0_872246.json
[36m(head, rank=0, pid=3472)[0m  50%|█████     | 5/10 [03:24<03:26, 41.37s/it]Chrome trace exported to: /tmp/trace_42_1_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_2_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_5_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_2_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_6_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_5_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_7_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_4_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_3_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_0_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_3_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_42_1_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_4_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_7_872246.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_42_6_872246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_5_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_7_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_1_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_3_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_4_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_2_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_6_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_0_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_1_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_5_207473.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_46_7_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_0_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_2_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_3_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_4_207473.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_46_6_207473.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_6_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_0_809570.json
[36m(head, rank=0, pid=3472)[0m  60%|██████    | 6/10 [04:05<02:44, 41.10s/it]Chrome trace exported to: /tmp/trace_50_3_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_1_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_5_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_7_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_2_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_4_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_2_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_0_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_6_809570.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_50_4_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_7_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_1_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_5_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_50_3_809570.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_0_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_2_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_5_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_6_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_1_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_6_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_4_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_7_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_3_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_2_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_1_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_7_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_5_876646.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_54_0_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_3_876646.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_54_4_876646.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_6_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_1_671858.json
[36m(head, rank=0, pid=3472)[0m  70%|███████   | 7/10 [04:47<02:04, 41.53s/it]Chrome trace exported to: /tmp/trace_58_3_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_5_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_1_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_6_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_5_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_0_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_7_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_2_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_4_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_2_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_7_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_0_671858.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_58_4_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_58_3_671858.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_4_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_2_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_1_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_0_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_4_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_2_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_3_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_1_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_7_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_6_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_3_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_5_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_6_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_0_191161.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_62_7_191161.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_62_5_191161.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_0_719176.json
[36m(head, rank=0, pid=3472)[0m  80%|████████  | 8/10 [05:30<01:23, 41.94s/it]Chrome trace exported to: /tmp/trace_66_7_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_6_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_3_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_5_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_2_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_1_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_0_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_1_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_2_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_3_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_4_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_5_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_66_7_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_4_719176.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_66_6_719176.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_6_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_0_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_1_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_5_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_4_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_1_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_5_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_6_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_2_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_3_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_0_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_7_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_4_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_2_542417.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_70_3_542417.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_70_7_542417.json
[36m(head, rank=0, pid=3472)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_0_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_6_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_4_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_5_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_3_133326.json
[36m(head, rank=0, pid=3472)[0m  90%|█████████ | 9/10 [06:12<00:41, 41.72s/it]Chrome trace exported to: /tmp/trace_74_5_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_3_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_1_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_2_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_7_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_6_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_4_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_1_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_2_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_74_7_133326.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_74_0_133326.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_1_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_4_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_3_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_2_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_0_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_6_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_7_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_5_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_2_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_78_3_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_7_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_5_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_1_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_0_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_4_131244.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_78_6_131244.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3472)[0m 
100%|██████████| 10/10 [06:56<00:00, 42.65s/it]Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3472)[0m Starting Save checkpoint...
                                               
[36m(head, rank=0, pid=3472)[0m 
{'loss': 124.4492, 'grad_norm': 35.656002044677734, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3472)[0m 
100%|██████████| 10/10 [06:56<00:00, 42.65s/it]Starting Save checkpoint...
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 351.45 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 351.45s (Total: 351.45s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 351.45 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 351.45s (Total: 351.45s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 351.45 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 351.45s (Total: 351.45s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 351.45 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 351.45s (Total: 351.45s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 351.45 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 351.45s (Total: 351.45s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 351.45 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 351.45s (Total: 351.45s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 351.45 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 351.45s (Total: 351.45s)
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Save checkpoint in 351.45 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint save time: 351.45s (Total: 351.45s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 351.45 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 351.45s (Total: 351.45s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 351.45 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 351.45s (Total: 351.45s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 351.45 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 351.45s (Total: 351.45s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 351.45 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 351.45s (Total: 351.45s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 351.45 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 351.45s (Total: 351.45s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 351.45 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 351.45s (Total: 351.45s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 351.45 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 351.45s (Total: 351.45s)
[36m(head, rank=0, pid=3472)[0m Completed Save checkpoint in 624.76 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint save time: 624.76s (Total: 624.76s)
[36m(head, rank=0, pid=3472)[0m 
                                               
{'train_runtime': 1041.5214, 'train_samples_per_second': 1.229, 'train_steps_per_second': 0.01, 'train_loss': 124.44921875, 'epoch': 0.03}
[36m(head, rank=0, pid=3472)[0m 
100%|██████████| 10/10 [17:21<00:00, 42.65s/it]
100%|██████████| 10/10 [17:21<00:00, 104.15s/it]
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_0_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1094.47 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 624.76s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 624.76s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 624.76s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 624.76s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.95s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.09s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.38s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 328.63s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.11s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.56s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 8.14s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_0_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.36s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.36s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.36s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.36s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 100.54s
[36m(head, rank=0, pid=3472)[0m   • Min time: 100.54s
[36m(head, rank=0, pid=3472)[0m   • Max time: 100.54s
[36m(head, rank=0, pid=3472)[0m   • Total time: 100.54s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1094.47s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1094.47s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1094.47s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1094.47s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.11s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.56s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 8.14s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 328.63s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.09s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.38s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.95s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 624.76s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 624.76s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 624.76s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 624.76s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1197.38s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1197.38s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1197.38s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1197.38s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m --- Training Run 1 Info (Directory: /checkpoints_s3_mount_cached) ---
[36m(head, rank=0, pid=3472)[0m {
[36m(head, rank=0, pid=3472)[0m   "run_id": 1,
[36m(head, rank=0, pid=3472)[0m   "timestamp": "2025-08-03T06:03:52.676758",
[36m(head, rank=0, pid=3472)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3472)[0m   "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3472)[0m   "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3472)[0m   "training_status": "completed",
[36m(head, rank=0, pid=3472)[0m   "output_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3472)[0m   "dataset_load_time": 2.361577272415161,
[36m(head, rank=0, pid=3472)[0m   "model_load_time": 100.54468536376953,
[36m(head, rank=0, pid=3472)[0m   "training_time": 1094.472559928894,
[36m(head, rank=0, pid=3472)[0m   "total_time": 1197.3788225650787,
[36m(head, rank=0, pid=3472)[0m   "error": null,
[36m(head, rank=0, pid=3472)[0m   "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3472)[0m   "total_checkpoint_save_time": 624.7618539333344,
[36m(head, rank=0, pid=3472)[0m   "average_checkpoint_save_time": 624.7618539333344,
[36m(head, rank=0, pid=3472)[0m   "min_checkpoint_save_time": 624.7618539333344,
[36m(head, rank=0, pid=3472)[0m   "max_checkpoint_save_time": 624.7618539333344,
[36m(head, rank=0, pid=3472)[0m   "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3472)[0m     624.7618539333344
[36m(head, rank=0, pid=3472)[0m   ],
[36m(head, rank=0, pid=3472)[0m   "num_batch_samples": 10,
[36m(head, rank=0, pid=3472)[0m   "total_batch_sample_time": 0.94818115234375,
[36m(head, rank=0, pid=3472)[0m   "average_batch_sample_time": 0.094818115234375,
[36m(head, rank=0, pid=3472)[0m   "min_batch_sample_time": 0.0336451530456543,
[36m(head, rank=0, pid=3472)[0m   "max_batch_sample_time": 0.3810257911682129,
[36m(head, rank=0, pid=3472)[0m   "individual_batch_sample_times": [
[36m(head, rank=0, pid=3472)[0m     0.3810257911682129,
[36m(head, rank=0, pid=3472)[0m     0.09609174728393555,
[36m(head, rank=0, pid=3472)[0m     0.15723586082458496,
[36m(head, rank=0, pid=3472)[0m     0.06578302383422852,
[36m(head, rank=0, pid=3472)[0m     0.06439661979675293,
[36m(head, rank=0, pid=3472)[0m     0.034311771392822266,
[36m(head, rank=0, pid=3472)[0m     0.03976583480834961,
[36m(head, rank=0, pid=3472)[0m     0.03877997398376465,
[36m(head, rank=0, pid=3472)[0m     0.0336451530456543,
[36m(head, rank=0, pid=3472)[0m     0.037145376205444336
[36m(head, rank=0, pid=3472)[0m   ],
[36m(head, rank=0, pid=3472)[0m   "num_training_steps": 80,
[36m(head, rank=0, pid=3472)[0m   "total_training_step_time": 328.62896251678467,
[36m(head, rank=0, pid=3472)[0m   "average_training_step_time": 4.107862031459808,
[36m(head, rank=0, pid=3472)[0m   "min_training_step_time": 3.5609166622161865,
[36m(head, rank=0, pid=3472)[0m   "max_training_step_time": 8.137359857559204,
[36m(head, rank=0, pid=3472)[0m   "individual_training_step_times": [
[36m(head, rank=0, pid=3472)[0m     5.256763219833374,
[36m(head, rank=0, pid=3472)[0m     3.5718648433685303,
[36m(head, rank=0, pid=3472)[0m     4.375540494918823,
[36m(head, rank=0, pid=3472)[0m     3.6704418659210205,
[36m(head, rank=0, pid=3472)[0m     4.7275166511535645,
[36m(head, rank=0, pid=3472)[0m     3.868263006210327,
[36m(head, rank=0, pid=3472)[0m     3.5609166622161865,
[36m(head, rank=0, pid=3472)[0m     3.7228548526763916,
[36m(head, rank=0, pid=3472)[0m     4.1007513999938965,
[36m(head, rank=0, pid=3472)[0m     4.777476787567139,
[36m(head, rank=0, pid=3472)[0m     4.092950105667114,
[36m(head, rank=0, pid=3472)[0m     3.7024848461151123,
[36m(head, rank=0, pid=3472)[0m     3.6926651000976562,
[36m(head, rank=0, pid=3472)[0m     5.016241550445557,
[36m(head, rank=0, pid=3472)[0m     3.782158374786377,
[36m(head, rank=0, pid=3472)[0m     4.07568097114563,
[36m(head, rank=0, pid=3472)[0m     4.20528769493103,
[36m(head, rank=0, pid=3472)[0m     3.732273578643799,
[36m(head, rank=0, pid=3472)[0m     3.800842523574829,
[36m(head, rank=0, pid=3472)[0m     3.708531618118286,
[36m(head, rank=0, pid=3472)[0m     4.307140111923218,
[36m(head, rank=0, pid=3472)[0m     3.7006678581237793,
[36m(head, rank=0, pid=3472)[0m     4.619802236557007,
[36m(head, rank=0, pid=3472)[0m     3.7437174320220947,
[36m(head, rank=0, pid=3472)[0m     5.053889036178589,
[36m(head, rank=0, pid=3472)[0m     3.607896327972412,
[36m(head, rank=0, pid=3472)[0m     4.032871723175049,
[36m(head, rank=0, pid=3472)[0m     3.774132251739502,
[36m(head, rank=0, pid=3472)[0m     3.7315549850463867,
[36m(head, rank=0, pid=3472)[0m     3.7270679473876953,
[36m(head, rank=0, pid=3472)[0m     4.056609392166138,
[36m(head, rank=0, pid=3472)[0m     4.443639755249023,
[36m(head, rank=0, pid=3472)[0m     4.810014724731445,
[36m(head, rank=0, pid=3472)[0m     3.883354902267456,
[36m(head, rank=0, pid=3472)[0m     3.7276315689086914,
[36m(head, rank=0, pid=3472)[0m     4.083902835845947,
[36m(head, rank=0, pid=3472)[0m     4.522889137268066,
[36m(head, rank=0, pid=3472)[0m     4.4358601570129395,
[36m(head, rank=0, pid=3472)[0m     3.94248104095459,
[36m(head, rank=0, pid=3472)[0m     3.872627019882202,
[36m(head, rank=0, pid=3472)[0m     3.756615400314331,
[36m(head, rank=0, pid=3472)[0m     3.563187837600708,
[36m(head, rank=0, pid=3472)[0m     4.942782878875732,
[36m(head, rank=0, pid=3472)[0m     3.7139029502868652,
[36m(head, rank=0, pid=3472)[0m     3.8863909244537354,
[36m(head, rank=0, pid=3472)[0m     3.9757742881774902,
[36m(head, rank=0, pid=3472)[0m     3.8298351764678955,
[36m(head, rank=0, pid=3472)[0m     3.9583704471588135,
[36m(head, rank=0, pid=3472)[0m     4.863569974899292,
[36m(head, rank=0, pid=3472)[0m     4.829238414764404,
[36m(head, rank=0, pid=3472)[0m     3.7969205379486084,
[36m(head, rank=0, pid=3472)[0m     3.7111804485321045,
[36m(head, rank=0, pid=3472)[0m     3.9612979888916016,
[36m(head, rank=0, pid=3472)[0m     3.7105727195739746,
[36m(head, rank=0, pid=3472)[0m     4.407940864562988,
[36m(head, rank=0, pid=3472)[0m     3.7086727619171143,
[36m(head, rank=0, pid=3472)[0m     5.087316036224365,
[36m(head, rank=0, pid=3472)[0m     4.349223375320435,
[36m(head, rank=0, pid=3472)[0m     3.9481279850006104,
[36m(head, rank=0, pid=3472)[0m     4.1687915325164795,
[36m(head, rank=0, pid=3472)[0m     3.7147765159606934,
[36m(head, rank=0, pid=3472)[0m     3.76283860206604,
[36m(head, rank=0, pid=3472)[0m     3.820672035217285,
[36m(head, rank=0, pid=3472)[0m     4.501457691192627,
[36m(head, rank=0, pid=3472)[0m     3.752716302871704,
[36m(head, rank=0, pid=3472)[0m     3.6985867023468018,
[36m(head, rank=0, pid=3472)[0m     3.8322906494140625,
[36m(head, rank=0, pid=3472)[0m     3.5735299587249756,
[36m(head, rank=0, pid=3472)[0m     4.280254364013672,
[36m(head, rank=0, pid=3472)[0m     4.85083532333374,
[36m(head, rank=0, pid=3472)[0m     3.8351306915283203,
[36m(head, rank=0, pid=3472)[0m     3.8737387657165527,
[36m(head, rank=0, pid=3472)[0m     3.647631883621216,
[36m(head, rank=0, pid=3472)[0m     4.187998294830322,
[36m(head, rank=0, pid=3472)[0m     8.137359857559204,
[36m(head, rank=0, pid=3472)[0m     4.097491502761841,
[36m(head, rank=0, pid=3472)[0m     3.973275661468506,
[36m(head, rank=0, pid=3472)[0m     3.7250568866729736,
[36m(head, rank=0, pid=3472)[0m     3.8825831413269043,
[36m(head, rank=0, pid=3472)[0m     3.7917685508728027
[36m(head, rank=0, pid=3472)[0m   ]
[36m(head, rank=0, pid=3472)[0m }
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m --- All Training Runs Summary ---
[36m(head, rank=0, pid=3472)[0m [
[36m(head, rank=0, pid=3472)[0m   {
[36m(head, rank=0, pid=3472)[0m     "run_id": 1,
[36m(head, rank=0, pid=3472)[0m     "timestamp": "2025-08-03T06:03:52.676758",
[36m(head, rank=0, pid=3472)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3472)[0m     "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3472)[0m     "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3472)[0m     "training_status": "completed",
[36m(head, rank=0, pid=3472)[0m     "output_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3472)[0m     "dataset_load_time": 2.361577272415161,
[36m(head, rank=0, pid=3472)[0m     "model_load_time": 100.54468536376953,
[36m(head, rank=0, pid=3472)[0m     "training_time": 1094.472559928894,
[36m(head, rank=0, pid=3472)[0m     "total_time": 1197.3788225650787,
[36m(head, rank=0, pid=3472)[0m     "error": null,
[36m(head, rank=0, pid=3472)[0m     "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3472)[0m     "total_checkpoint_save_time": 624.7618539333344,
[36m(head, rank=0, pid=3472)[0m     "average_checkpoint_save_time": 624.7618539333344,
[36m(head, rank=0, pid=3472)[0m     "min_checkpoint_save_time": 624.7618539333344,
[36m(head, rank=0, pid=3472)[0m     "max_checkpoint_save_time": 624.7618539333344,
[36m(head, rank=0, pid=3472)[0m     "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3472)[0m       624.7618539333344
[36m(head, rank=0, pid=3472)[0m     ],
[36m(head, rank=0, pid=3472)[0m     "num_batch_samples": 10,
[36m(head, rank=0, pid=3472)[0m     "total_batch_sample_time": 0.94818115234375,
[36m(head, rank=0, pid=3472)[0m     "average_batch_sample_time": 0.094818115234375,
[36m(head, rank=0, pid=3472)[0m     "min_batch_sample_time": 0.0336451530456543,
[36m(head, rank=0, pid=3472)[0m     "max_batch_sample_time": 0.3810257911682129,
[36m(head, rank=0, pid=3472)[0m     "individual_batch_sample_times": [
[36m(head, rank=0, pid=3472)[0m       0.3810257911682129,
[36m(head, rank=0, pid=3472)[0m       0.09609174728393555,
[36m(head, rank=0, pid=3472)[0m       0.15723586082458496,
[36m(head, rank=0, pid=3472)[0m       0.06578302383422852,
[36m(head, rank=0, pid=3472)[0m       0.06439661979675293,
[36m(head, rank=0, pid=3472)[0m       0.034311771392822266,
[36m(head, rank=0, pid=3472)[0m       0.03976583480834961,
[36m(head, rank=0, pid=3472)[0m       0.03877997398376465,
[36m(head, rank=0, pid=3472)[0m       0.0336451530456543,
[36m(head, rank=0, pid=3472)[0m       0.037145376205444336
[36m(head, rank=0, pid=3472)[0m     ],
[36m(head, rank=0, pid=3472)[0m     "num_training_steps": 80,
[36m(head, rank=0, pid=3472)[0m     "total_training_step_time": 328.62896251678467,
[36m(head, rank=0, pid=3472)[0m     "average_training_step_time": 4.107862031459808,
[36m(head, rank=0, pid=3472)[0m     "min_training_step_time": 3.5609166622161865,
[36m(head, rank=0, pid=3472)[0m     "max_training_step_time": 8.137359857559204,
[36m(head, rank=0, pid=3472)[0m     "individual_training_step_times": [
[36m(head, rank=0, pid=3472)[0m       5.256763219833374,
[36m(head, rank=0, pid=3472)[0m       3.5718648433685303,
[36m(head, rank=0, pid=3472)[0m       4.375540494918823,
[36m(head, rank=0, pid=3472)[0m       3.6704418659210205,
[36m(head, rank=0, pid=3472)[0m       4.7275166511535645,
[36m(head, rank=0, pid=3472)[0m       3.868263006210327,
[36m(head, rank=0, pid=3472)[0m       3.5609166622161865,
[36m(head, rank=0, pid=3472)[0m       3.7228548526763916,
[36m(head, rank=0, pid=3472)[0m       4.1007513999938965,
[36m(head, rank=0, pid=3472)[0m       4.777476787567139,
[36m(head, rank=0, pid=3472)[0m       4.092950105667114,
[36m(head, rank=0, pid=3472)[0m       3.7024848461151123,
[36m(head, rank=0, pid=3472)[0m       3.6926651000976562,
[36m(head, rank=0, pid=3472)[0m       5.016241550445557,
[36m(head, rank=0, pid=3472)[0m       3.782158374786377,
[36m(head, rank=0, pid=3472)[0m       4.07568097114563,
[36m(head, rank=0, pid=3472)[0m       4.20528769493103,
[36m(head, rank=0, pid=3472)[0m       3.732273578643799,
[36m(head, rank=0, pid=3472)[0m       3.800842523574829,
[36m(head, rank=0, pid=3472)[0m       3.708531618118286,
[36m(head, rank=0, pid=3472)[0m       4.307140111923218,
[36m(head, rank=0, pid=3472)[0m       3.7006678581237793,
[36m(head, rank=0, pid=3472)[0m       4.619802236557007,
[36m(head, rank=0, pid=3472)[0m       3.7437174320220947,
[36m(head, rank=0, pid=3472)[0m       5.053889036178589,
[36m(head, rank=0, pid=3472)[0m       3.607896327972412,
[36m(head, rank=0, pid=3472)[0m       4.032871723175049,
[36m(head, rank=0, pid=3472)[0m       3.774132251739502,
[36m(head, rank=0, pid=3472)[0m       3.7315549850463867,
[36m(head, rank=0, pid=3472)[0m       3.7270679473876953,
[36m(head, rank=0, pid=3472)[0m       4.056609392166138,
[36m(head, rank=0, pid=3472)[0m       4.443639755249023,
[36m(head, rank=0, pid=3472)[0m       4.810014724731445,
[36m(head, rank=0, pid=3472)[0m       3.883354902267456,
[36m(head, rank=0, pid=3472)[0m       3.7276315689086914,
[36m(head, rank=0, pid=3472)[0m       4.083902835845947,
[36m(head, rank=0, pid=3472)[0m       4.522889137268066,
[36m(head, rank=0, pid=3472)[0m       4.4358601570129395,
[36m(head, rank=0, pid=3472)[0m       3.94248104095459,
[36m(head, rank=0, pid=3472)[0m       3.872627019882202,
[36m(head, rank=0, pid=3472)[0m       3.756615400314331,
[36m(head, rank=0, pid=3472)[0m       3.563187837600708,
[36m(head, rank=0, pid=3472)[0m       4.942782878875732,
[36m(head, rank=0, pid=3472)[0m       3.7139029502868652,
[36m(head, rank=0, pid=3472)[0m       3.8863909244537354,
[36m(head, rank=0, pid=3472)[0m       3.9757742881774902,
[36m(head, rank=0, pid=3472)[0m       3.8298351764678955,
[36m(head, rank=0, pid=3472)[0m       3.9583704471588135,
[36m(head, rank=0, pid=3472)[0m       4.863569974899292,
[36m(head, rank=0, pid=3472)[0m       4.829238414764404,
[36m(head, rank=0, pid=3472)[0m       3.7969205379486084,
[36m(head, rank=0, pid=3472)[0m       3.7111804485321045,
[36m(head, rank=0, pid=3472)[0m       3.9612979888916016,
[36m(head, rank=0, pid=3472)[0m       3.7105727195739746,
[36m(head, rank=0, pid=3472)[0m       4.407940864562988,
[36m(head, rank=0, pid=3472)[0m       3.7086727619171143,
[36m(head, rank=0, pid=3472)[0m       5.087316036224365,
[36m(head, rank=0, pid=3472)[0m       4.349223375320435,
[36m(head, rank=0, pid=3472)[0m       3.9481279850006104,
[36m(head, rank=0, pid=3472)[0m       4.1687915325164795,
[36m(head, rank=0, pid=3472)[0m       3.7147765159606934,
[36m(head, rank=0, pid=3472)[0m       3.76283860206604,
[36m(head, rank=0, pid=3472)[0m       3.820672035217285,
[36m(head, rank=0, pid=3472)[0m       4.501457691192627,
[36m(head, rank=0, pid=3472)[0m       3.752716302871704,
[36m(head, rank=0, pid=3472)[0m       3.6985867023468018,
[36m(head, rank=0, pid=3472)[0m       3.8322906494140625,
[36m(head, rank=0, pid=3472)[0m       3.5735299587249756,
[36m(head, rank=0, pid=3472)[0m       4.280254364013672,
[36m(head, rank=0, pid=3472)[0m       4.85083532333374,
[36m(head, rank=0, pid=3472)[0m       3.8351306915283203,
[36m(head, rank=0, pid=3472)[0m       3.8737387657165527,
[36m(head, rank=0, pid=3472)[0m       3.647631883621216,
[36m(head, rank=0, pid=3472)[0m       4.187998294830322,
[36m(head, rank=0, pid=3472)[0m       8.137359857559204,
[36m(head, rank=0, pid=3472)[0m       4.097491502761841,
[36m(head, rank=0, pid=3472)[0m       3.973275661468506,
[36m(head, rank=0, pid=3472)[0m       3.7250568866729736,
[36m(head, rank=0, pid=3472)[0m       3.8825831413269043,
[36m(head, rank=0, pid=3472)[0m       3.7917685508728027
[36m(head, rank=0, pid=3472)[0m     ]
[36m(head, rank=0, pid=3472)[0m   }
[36m(head, rank=0, pid=3472)[0m ]
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m --- Timing Summary ---
[36m(head, rank=0, pid=3472)[0m {
[36m(head, rank=0, pid=3472)[0m   "total_runs": 1,
[36m(head, rank=0, pid=3472)[0m   "dataset_loading": {
[36m(head, rank=0, pid=3472)[0m     "dataset_load_count": 1,
[36m(head, rank=0, pid=3472)[0m     "dataset_load_average": 2.361577272415161,
[36m(head, rank=0, pid=3472)[0m     "dataset_load_min": 2.361577272415161,
[36m(head, rank=0, pid=3472)[0m     "dataset_load_max": 2.361577272415161,
[36m(head, rank=0, pid=3472)[0m     "dataset_load_total": 2.361577272415161
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "model_loading": {
[36m(head, rank=0, pid=3472)[0m     "model_load_count": 1,
[36m(head, rank=0, pid=3472)[0m     "model_load_average": 100.54468536376953,
[36m(head, rank=0, pid=3472)[0m     "model_load_min": 100.54468536376953,
[36m(head, rank=0, pid=3472)[0m     "model_load_max": 100.54468536376953,
[36m(head, rank=0, pid=3472)[0m     "model_load_total": 100.54468536376953
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "training": {
[36m(head, rank=0, pid=3472)[0m     "training_count": 1,
[36m(head, rank=0, pid=3472)[0m     "training_average": 1094.472559928894,
[36m(head, rank=0, pid=3472)[0m     "training_min": 1094.472559928894,
[36m(head, rank=0, pid=3472)[0m     "training_max": 1094.472559928894,
[36m(head, rank=0, pid=3472)[0m     "training_total": 1094.472559928894
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "total_run_time": {
[36m(head, rank=0, pid=3472)[0m     "total_count": 1,
[36m(head, rank=0, pid=3472)[0m     "total_average": 1197.3788225650787,
[36m(head, rank=0, pid=3472)[0m     "total_min": 1197.3788225650787,
[36m(head, rank=0, pid=3472)[0m     "total_max": 1197.3788225650787,
[36m(head, rank=0, pid=3472)[0m     "total_total": 1197.3788225650787
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "checkpoint_saving": {
[36m(head, rank=0, pid=3472)[0m     "total_checkpoints_saved": 1,
[36m(head, rank=0, pid=3472)[0m     "total_checkpoint_save_time": 624.7618539333344,
[36m(head, rank=0, pid=3472)[0m     "average_save_time_per_checkpoint": 624.7618539333344,
[36m(head, rank=0, pid=3472)[0m     "checkpoint_save_times_count": 1,
[36m(head, rank=0, pid=3472)[0m     "checkpoint_save_min": 624.7618539333344,
[36m(head, rank=0, pid=3472)[0m     "checkpoint_save_max": 624.7618539333344,
[36m(head, rank=0, pid=3472)[0m     "checkpoint_save_average": 624.7618539333344
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "batch_sampling": {
[36m(head, rank=0, pid=3472)[0m     "total_batch_samples": 10,
[36m(head, rank=0, pid=3472)[0m     "total_batch_sample_time": 0.94818115234375,
[36m(head, rank=0, pid=3472)[0m     "average_sample_time_per_batch": 0.094818115234375,
[36m(head, rank=0, pid=3472)[0m     "batch_sample_times_count": 10,
[36m(head, rank=0, pid=3472)[0m     "batch_sample_min": 0.0336451530456543,
[36m(head, rank=0, pid=3472)[0m     "batch_sample_max": 0.3810257911682129,
[36m(head, rank=0, pid=3472)[0m     "batch_sample_average": 0.094818115234375
[36m(head, rank=0, pid=3472)[0m   },
[36m(head, rank=0, pid=3472)[0m   "training_steps": {
[36m(head, rank=0, pid=3472)[0m     "total_training_steps": 80,
[36m(head, rank=0, pid=3472)[0m     "total_training_step_time": 328.62896251678467,
[36m(head, rank=0, pid=3472)[0m     "average_step_time_per_step": 4.107862031459808,
[36m(head, rank=0, pid=3472)[0m     "training_step_times_count": 80,
[36m(head, rank=0, pid=3472)[0m     "training_step_min": 3.5609166622161865,
[36m(head, rank=0, pid=3472)[0m     "training_step_max": 8.137359857559204,
[36m(head, rank=0, pid=3472)[0m     "training_step_average": 4.107862031459808
[36m(head, rank=0, pid=3472)[0m   }
[36m(head, rank=0, pid=3472)[0m }
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_0_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1139.73 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.85s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.20s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 331.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.15s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.57s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 8.21s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.40s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.40s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.40s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.40s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 100.47s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 100.47s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 100.47s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 100.47s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1139.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1139.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1139.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1139.73s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.15s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.57s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 8.21s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 331.84s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.20s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.85s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1242.60s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1242.60s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1242.60s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1242.60s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_0.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m --- Training Run 1 Info (Directory: /checkpoints_s3_mount_cached) ---
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "run_id": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "timestamp": "2025-08-03T06:03:52.676441",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "training_status": "completed",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "output_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "dataset_load_time": 2.3989555835723877,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "model_load_time": 100.4732666015625,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "training_time": 1139.7305274009705,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_time": 1242.6027495861053,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "error": null,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_checkpoint_save_time": 351.45232367515564,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "average_checkpoint_save_time": 351.45232367515564,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "min_checkpoint_save_time": 351.45232367515564,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "max_checkpoint_save_time": 351.45232367515564,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     351.45232367515564
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   ],
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_batch_sample_time": 0.8512740135192871,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "average_batch_sample_time": 0.08512740135192871,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "min_batch_sample_time": 0.03290152549743652,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "max_batch_sample_time": 0.20186924934387207,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.1041114330291748,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.20186924934387207,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.03737020492553711,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.1508939266204834,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.07799911499023438,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.09560179710388184,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.034505367279052734,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.08037281036376953,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.03564858436584473,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     0.03290152549743652
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   ],
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "num_training_steps": 80,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_training_step_time": 331.8433849811554,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "average_training_step_time": 4.148042312264442,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "min_training_step_time": 3.5707268714904785,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "max_training_step_time": 8.205544233322144,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "individual_training_step_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.881415128707886,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.709411382675171,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.377264499664307,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.672577142715454,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.754542350769043,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.8700714111328125,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.8773183822631836,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.725752115249634,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.384493350982666,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.7526631355285645,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.776355266571045,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7008707523345947,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.69177508354187,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.019144058227539,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.780599355697632,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.578880786895752,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.278591632843018,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.73222279548645,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.044891357421875,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.708779811859131,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.329900741577148,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7023868560791016,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.827422857284546,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.743603229522705,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.972664833068848,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7057840824127197,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.080487966537476,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7756505012512207,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.579871892929077,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7273788452148438,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.170270919799805,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.445401191711426,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.851998805999756,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.8889000415802,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.826958417892456,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.084818124771118,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.527530193328857,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.3981852531433105,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.93064284324646,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.873657703399658,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.6148393154144287,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7102513313293457,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.115038871765137,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7132296562194824,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.9109139442443848,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.978569984436035,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.825343370437622,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.9623801708221436,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.875243902206421,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.829701662063599,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.8382139205932617,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7116177082061768,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.963008165359497,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.624199867248535,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.716552019119263,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.709624767303467,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     5.049838542938232,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.353795051574707,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.016643762588501,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.145429372787476,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.5707268714904785,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.758542537689209,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.9502761363983154,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.400111675262451,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.761979103088379,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.6157875061035156,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.029742240905762,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.660109281539917,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.283061265945435,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.849979639053345,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.97107195854187,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.8744418621063232,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.787644147872925,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.23127007484436,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     8.205544233322144,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     4.095714807510376,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.8901522159576416,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7045340538024902,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.987520694732666,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     3.7896041870117188
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   ]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m }
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m --- All Training Runs Summary ---
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "run_id": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "timestamp": "2025-08-03T06:03:52.676441",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_status": "completed",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "output_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_time": 2.3989555835723877,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_time": 100.4732666015625,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_time": 1139.7305274009705,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_time": 1242.6027495861053,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "error": null,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_checkpoint_save_time": 351.45232367515564,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_checkpoint_save_time": 351.45232367515564,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "min_checkpoint_save_time": 351.45232367515564,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "max_checkpoint_save_time": 351.45232367515564,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       351.45232367515564
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     ],
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_batch_sample_time": 0.8512740135192871,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_batch_sample_time": 0.08512740135192871,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "min_batch_sample_time": 0.03290152549743652,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "max_batch_sample_time": 0.20186924934387207,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.1041114330291748,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.20186924934387207,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.03737020492553711,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.1508939266204834,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.07799911499023438,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.09560179710388184,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.034505367279052734,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.08037281036376953,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.03564858436584473,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       0.03290152549743652
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     ],
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "num_training_steps": 80,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_training_step_time": 331.8433849811554,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_training_step_time": 4.148042312264442,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "min_training_step_time": 3.5707268714904785,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "max_training_step_time": 8.205544233322144,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "individual_training_step_times": [
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.881415128707886,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.709411382675171,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.377264499664307,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.672577142715454,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.754542350769043,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.8700714111328125,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.8773183822631836,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.725752115249634,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.384493350982666,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.7526631355285645,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.776355266571045,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7008707523345947,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.69177508354187,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.019144058227539,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.780599355697632,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.578880786895752,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.278591632843018,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.73222279548645,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.044891357421875,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.708779811859131,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.329900741577148,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7023868560791016,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.827422857284546,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.743603229522705,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.972664833068848,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7057840824127197,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.080487966537476,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7756505012512207,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.579871892929077,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7273788452148438,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.170270919799805,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.445401191711426,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.851998805999756,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.8889000415802,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.826958417892456,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.084818124771118,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.527530193328857,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.3981852531433105,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.93064284324646,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.873657703399658,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.6148393154144287,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7102513313293457,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.115038871765137,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7132296562194824,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.9109139442443848,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.978569984436035,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.825343370437622,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.9623801708221436,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.875243902206421,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.829701662063599,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.8382139205932617,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7116177082061768,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.963008165359497,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.624199867248535,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.716552019119263,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.709624767303467,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       5.049838542938232,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.353795051574707,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.016643762588501,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.145429372787476,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.5707268714904785,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.758542537689209,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.9502761363983154,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.400111675262451,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.761979103088379,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.6157875061035156,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.029742240905762,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.660109281539917,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.283061265945435,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.849979639053345,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.97107195854187,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.8744418621063232,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.787644147872925,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.23127007484436,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       8.205544233322144,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       4.095714807510376,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.8901522159576416,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7045340538024902,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.987520694732666,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m       3.7896041870117188
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     ]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   }
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ]
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m --- Timing Summary ---
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_runs": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "dataset_loading": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_count": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_average": 2.3989555835723877,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_min": 2.3989555835723877,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_max": 2.3989555835723877,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "dataset_load_total": 2.3989555835723877
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "model_loading": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_count": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_average": 100.4732666015625,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_min": 100.4732666015625,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_max": 100.4732666015625,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "model_load_total": 100.4732666015625
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "training": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_count": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_average": 1139.7305274009705,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_min": 1139.7305274009705,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_max": 1139.7305274009705,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_total": 1139.7305274009705
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "total_run_time": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_count": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_average": 1242.6027495861053,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_min": 1242.6027495861053,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_max": 1242.6027495861053,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_total": 1242.6027495861053
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "checkpoint_saving": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_checkpoint_save_time": 351.45232367515564,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_save_time_per_checkpoint": 351.45232367515564,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "checkpoint_save_times_count": 1,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "checkpoint_save_min": 351.45232367515564,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "checkpoint_save_max": 351.45232367515564,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "checkpoint_save_average": 351.45232367515564
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "batch_sampling": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_batch_samples": 10,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_batch_sample_time": 0.8512740135192871,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_sample_time_per_batch": 0.08512740135192871,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "batch_sample_times_count": 10,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "batch_sample_min": 0.03290152549743652,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "batch_sample_max": 0.20186924934387207,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "batch_sample_average": 0.08512740135192871
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   },
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   "training_steps": {
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_training_steps": 80,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "total_training_step_time": 331.8433849811554,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "average_step_time_per_step": 4.148042312264442,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_step_times_count": 80,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_step_min": 3.5707268714904785,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_step_max": 8.205544233322144,
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m     "training_step_average": 4.148042312264442
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   }
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m }
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_6_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1240.09 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.98s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.10s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.47s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 333.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.17s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 8.32s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_6_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.64s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.64s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.64s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.64s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 0.93s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 0.93s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 0.93s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 0.93s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1240.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1240.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1240.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1240.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.17s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 8.32s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 333.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.10s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.47s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.98s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1243.66s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1243.66s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1243.66s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1243.66s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_2_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1240.68 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.87s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.47s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 332.37s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.15s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.59s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 8.00s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1240.68s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1240.68s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1240.68s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1240.68s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.15s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.59s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 8.00s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 332.37s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.47s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.87s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1244.11s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1244.11s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1244.11s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1244.11s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_2_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1240.47 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 351.45s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 1.12s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.11s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.50s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 331.59s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.14s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.57s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 8.25s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_2_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.56s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.56s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.56s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.56s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.09s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.09s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.09s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.09s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1240.47s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1240.47s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1240.47s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1240.47s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.14s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.57s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 8.25s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 331.59s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.11s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.50s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 1.12s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 351.45s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1244.13s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1244.13s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1244.13s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1244.13s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_1_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1241.11 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 0.92s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.37s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 331.57s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.54s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 8.15s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1241.11s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1241.11s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1241.11s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1241.11s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.54s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 8.15s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 331.57s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.09s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.37s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 0.92s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1244.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1244.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1244.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1244.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_5_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1239.07 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 1.16s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.12s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.47s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 331.86s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.15s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.58s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 8.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 3.81s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 3.81s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 3.81s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 3.81s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1239.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1239.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1239.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1239.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.15s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.58s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 8.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 331.86s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.12s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.47s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 1.16s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1245.26s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1245.26s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1245.26s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1245.26s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_5.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_1_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1241.41 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 351.45s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 1.02s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.10s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.37s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 332.44s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.16s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.56s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 8.10s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_1_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_3_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1241.14 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 351.45s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 1.04s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.10s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.49s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 332.93s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.16s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.58s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 8.21s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_3_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_7_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1241.52 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 1.28s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.13s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.48s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 331.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.56s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 8.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.36s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.36s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.36s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.36s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.13s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.13s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.13s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.13s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1241.41s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1241.41s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1241.41s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1241.41s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.16s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.56s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 8.10s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 332.44s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.10s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.37s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 1.02s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 351.45s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1244.90s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1244.90s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1244.90s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1244.90s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.36s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.36s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.36s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.36s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.14s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.14s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.14s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.14s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1241.14s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1241.14s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1241.14s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1241.14s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.16s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.58s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 8.21s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 332.93s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.10s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.49s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 1.04s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 351.45s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1244.63s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1244.63s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1244.63s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1244.63s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.39s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.39s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.39s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.39s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1241.52s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1241.52s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1241.52s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1241.52s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.56s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 8.08s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 331.07s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.13s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.48s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 1.28s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1244.96s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1244.96s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1244.96s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1244.96s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_4_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1241.70 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 1.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.10s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.48s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 331.48s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.57s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 8.13s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.39s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.39s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.39s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.39s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1241.70s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1241.70s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1241.70s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1241.70s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.57s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 8.13s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 331.48s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.10s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.48s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 1.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1245.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1245.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1245.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1245.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_4.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Chrome trace exported to: /tmp/trace_80_3_198246.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed Training in 1241.94 seconds
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total batch sample time: 1.35s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average batch sample time: 0.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min batch sample time: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max batch sample time: 0.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Total training step time: 331.15s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Average training step time: 4.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Min training step time: 3.61s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   - Max training step time: 8.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 2.39s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 2.39s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 2.39s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 2.39s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1.05s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average time: 1241.94s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min time: 1241.94s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max time: 1241.94s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time: 1241.94s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average step time per step: 4.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min step time: 3.61s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max step time: 8.06s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total training step time: 331.15s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average sample time per batch: 0.14s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min sample time: 0.04s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max sample time: 0.55s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total batch sample time: 1.35s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average save time per checkpoint: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total checkpoint save time: 351.45s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m 
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Average total time per run: 1245.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Min total time: 1245.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Max total time: 1245.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m   • Total time across all runs: 1245.38s
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m ================================================================================
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_4_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1243.20 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 351.45s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.97s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.10s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.52s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 331.83s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.15s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.55s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 8.05s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_4_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.44s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.44s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.44s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.44s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.06s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.06s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.06s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.06s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1243.20s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1243.20s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1243.20s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1243.20s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.15s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.55s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 8.05s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 331.83s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.10s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.52s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.97s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 351.45s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1246.69s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1246.69s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1246.69s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1246.69s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_6_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1243.35 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 351.45s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 1.28s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.13s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.51s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 330.99s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.14s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.58s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 8.14s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_6_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_7_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1243.37 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 351.45s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 0.84s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.08s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.35s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 331.62s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.15s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.55s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 8.20s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_7_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.39s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.39s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.39s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.39s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.11s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.11s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.11s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.11s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1243.35s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1243.35s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1243.35s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1243.35s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.14s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.58s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 8.14s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 330.99s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.13s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.51s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 1.28s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 351.45s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1246.85s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1246.85s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1246.85s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1246.85s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.36s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.36s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.36s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.36s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.14s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.14s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.14s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.14s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1243.37s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1243.37s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1243.37s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1243.37s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.15s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.55s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 8.20s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 331.62s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.08s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.35s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 0.84s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 351.45s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1246.86s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1246.86s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1246.86s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1246.86s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3472)[0m Chrome trace exported to: /tmp/trace_80_5_198246.json
[36m(head, rank=0, pid=3472)[0m Completed Training in 1244.05 seconds
[36m(head, rank=0, pid=3472)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3472)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   - Total checkpoint save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Average save time per checkpoint: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Min save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   - Max save time: 351.45s
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3472)[0m   - Total batch sample time: 1.13s
[36m(head, rank=0, pid=3472)[0m   - Average batch sample time: 0.11s
[36m(head, rank=0, pid=3472)[0m   - Min batch sample time: 0.04s
[36m(head, rank=0, pid=3472)[0m   - Max batch sample time: 0.51s
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3472)[0m   - Total training step time: 332.81s
[36m(head, rank=0, pid=3472)[0m   - Average training step time: 4.16s
[36m(head, rank=0, pid=3472)[0m   - Min training step time: 3.56s
[36m(head, rank=0, pid=3472)[0m   - Max training step time: 8.25s
[36m(head, rank=0, pid=3472)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3472)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_5_1_info.json
[36m(head, rank=0, pid=3472)[0m Completed run 1/1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 2.40s
[36m(head, rank=0, pid=3472)[0m   • Min time: 2.40s
[36m(head, rank=0, pid=3472)[0m   • Max time: 2.40s
[36m(head, rank=0, pid=3472)[0m   • Total time: 2.40s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Model Loading Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1.10s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1.10s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1.10s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1.10s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Performance:
[36m(head, rank=0, pid=3472)[0m   • Average time: 1244.05s
[36m(head, rank=0, pid=3472)[0m   • Min time: 1244.05s
[36m(head, rank=0, pid=3472)[0m   • Max time: 1244.05s
[36m(head, rank=0, pid=3472)[0m   • Total time: 1244.05s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Training Step Performance:
[36m(head, rank=0, pid=3472)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3472)[0m   • Average step time per step: 4.16s
[36m(head, rank=0, pid=3472)[0m   • Min step time: 3.56s
[36m(head, rank=0, pid=3472)[0m   • Max step time: 8.25s
[36m(head, rank=0, pid=3472)[0m   • Total training step time: 332.81s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3472)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3472)[0m   • Average sample time per batch: 0.11s
[36m(head, rank=0, pid=3472)[0m   • Min sample time: 0.04s
[36m(head, rank=0, pid=3472)[0m   • Max sample time: 0.51s
[36m(head, rank=0, pid=3472)[0m   • Total batch sample time: 1.13s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3472)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3472)[0m   • Average save time per checkpoint: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Min save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Max save time: 351.45s
[36m(head, rank=0, pid=3472)[0m   • Total checkpoint save time: 351.45s
[36m(head, rank=0, pid=3472)[0m 
[36m(head, rank=0, pid=3472)[0m Overall Run Performance:
[36m(head, rank=0, pid=3472)[0m   • Average total time per run: 1247.55s
[36m(head, rank=0, pid=3472)[0m   • Min total time: 1247.55s
[36m(head, rank=0, pid=3472)[0m   • Max total time: 1247.55s
[36m(head, rank=0, pid=3472)[0m   • Total time across all runs: 1247.55s
[36m(head, rank=0, pid=3472)[0m ================================================================================
[36m(head, rank=0, pid=3472)[0m Saved timing summary to: timing_summary_5.json
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2535, ip=10.102.30.168)[0m skypilot: cached mount uploaded complete
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3472)[0m skypilot: cached mount uploaded complete
[0m[32m✓ Job finished (status: SUCCEEDED).[0m[0m
