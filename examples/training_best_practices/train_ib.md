[33mTailing logs of job 1 on cluster 'cc'...[0m
[2m├── [0m[2mWaiting for task resources on 2 nodes.[0m
[2m└── [0mJob started. Streaming logs... [2m(Ctrl-C to exit log streaming; job will not be killed)[0m
[36m(setup pid=3097)[0m Channels:
[36m(setup pid=3097)[0m  - nvidia
[36m(setup pid=3097)[0m  - defaults
[36m(setup pid=3097)[0m Platform: linux-64
[36m(setup pid=2318, ip=10.113.50.48)[0m Channels:
[36m(setup pid=2318, ip=10.113.50.48)[0m  - nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m  - defaults
[36m(setup pid=2318, ip=10.113.50.48)[0m Platform: linux-64
[36m(setup pid=3097)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=3097)[0m Solving environment: ...working... done
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m ## Package Plan ##
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m   environment location: /root/miniconda3
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m   added / updated specs:
[36m(setup pid=3097)[0m     - cuda
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m The following packages will be downloaded:
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m     package                    |            build
[36m(setup pid=3097)[0m     ---------------------------|-----------------
[36m(setup pid=3097)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=3097)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=3097)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=3097)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=3097)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=3097)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=3097)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=3097)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=3097)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=3097)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=3097)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=3097)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=3097)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=3097)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=3097)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=3097)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=3097)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=3097)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=3097)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=3097)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=3097)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=3097)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=3097)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=3097)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=3097)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=3097)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=3097)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=3097)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=3097)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=3097)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=3097)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=3097)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=3097)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=3097)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=3097)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=3097)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=3097)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=3097)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=3097)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=3097)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=3097)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=3097)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=3097)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=3097)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=3097)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=3097)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=3097)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=3097)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=3097)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=3097)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=3097)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=3097)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=3097)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=3097)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=3097)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=3097)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=3097)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=3097)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=3097)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=3097)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=3097)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=3097)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=3097)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=3097)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=3097)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=3097)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=3097)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=3097)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=3097)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=3097)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=3097)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=3097)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=3097)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=3097)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=3097)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=3097)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=3097)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=3097)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=3097)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=3097)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=3097)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=3097)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=3097)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=3097)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=3097)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=3097)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=3097)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=3097)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=3097)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=3097)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=3097)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=3097)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=3097)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=3097)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=3097)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=3097)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=3097)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=3097)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=3097)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=3097)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=3097)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=3097)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=3097)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=3097)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=3097)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=3097)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=3097)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=3097)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=3097)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=3097)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=3097)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=3097)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=3097)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=3097)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=3097)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=3097)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=3097)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=3097)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=3097)[0m     ------------------------------------------------------------
[36m(setup pid=3097)[0m                                            Total:        2.06 GB
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=3097)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=3097)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=3097)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=3097)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=3097)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=3097)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=3097)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=3097)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=3097)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=3097)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=3097)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=3097)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=3097)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=3097)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=3097)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=3097)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=3097)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=3097)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=3097)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=3097)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=3097)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=3097)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=3097)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=3097)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=3097)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=3097)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=3097)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=3097)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=3097)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=3097)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=3097)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=3097)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=3097)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=3097)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=3097)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=3097)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=3097)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=3097)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=3097)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=3097)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=3097)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=3097)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=3097)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=3097)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=3097)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=3097)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=3097)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=3097)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=3097)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=3097)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=3097)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=3097)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=3097)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=3097)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=3097)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=3097)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3097)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=3097)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=3097)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=3097)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=3097)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=3097)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3097)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=3097)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=3097)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=3097)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=3097)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=3097)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=3097)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=3097)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=3097)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=3097)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=3097)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=3097)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=3097)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=3097)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=3097)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=3097)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3097)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=3097)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=3097)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=3097)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=3097)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=3097)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=3097)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=3097)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=3097)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=3097)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=3097)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=3097)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3097)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=3097)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=3097)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=3097)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=3097)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=3097)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=3097)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=3097)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=3097)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=3097)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=3097)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=3097)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=3097)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=3097)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=3097)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=3097)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m The following packages will be UPDATED:
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=3097)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=3097)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=3097)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=3097)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=3097)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=3097)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=3097)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=3097)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=3097)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=3097)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m Proceed ([y]/n)? 
[36m(setup pid=3097)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=2318, ip=10.113.50.48)[0m Solving environment: ...working... done
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m ## Package Plan ##
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m   environment location: /root/miniconda3
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m   added / updated specs:
[36m(setup pid=2318, ip=10.113.50.48)[0m     - cuda
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m The following packages will be downloaded:
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m     package                    |            build
[36m(setup pid=2318, ip=10.113.50.48)[0m     ---------------------------|-----------------
[36m(setup pid=2318, ip=10.113.50.48)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=2318, ip=10.113.50.48)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=2318, ip=10.113.50.48)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=2318, ip=10.113.50.48)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=2318, ip=10.113.50.48)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=2318, ip=10.113.50.48)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=2318, ip=10.113.50.48)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=2318, ip=10.113.50.48)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=2318, ip=10.113.50.48)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=2318, ip=10.113.50.48)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=2318, ip=10.113.50.48)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=2318, ip=10.113.50.48)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=2318, ip=10.113.50.48)[0m     ------------------------------------------------------------
[36m(setup pid=2318, ip=10.113.50.48)[0m                                            Total:        2.06 GB
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=2318, ip=10.113.50.48)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=2318, ip=10.113.50.48)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=2318, ip=10.113.50.48)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=2318, ip=10.113.50.48)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=2318, ip=10.113.50.48)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m The following packages will be UPDATED:
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=2318, ip=10.113.50.48)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=2318, ip=10.113.50.48)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m Proceed ([y]/n)? 
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=3097)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=3097)[0m Preparing transaction: ...working... done
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing transaction: ...working... done
[36m(setup pid=3097)[0m Verifying transaction: ...working... done
[36m(setup pid=2318, ip=10.113.50.48)[0m Verifying transaction: ...working... done
[36m(setup pid=3097)[0m Executing transaction: ...working... done
[36m(setup pid=2318, ip=10.113.50.48)[0m Executing transaction: ...working... done
[36m(setup pid=3097)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=3097)[0m Using CPython 3.10.12 interpreter at: /usr/bin/python3.10
[36m(setup pid=3097)[0m Creating virtual environment with seed packages at: /root/training
[36m(setup pid=3097)[0m  + pip==25.2
[36m(setup pid=3097)[0m  + setuptools==80.9.0
[36m(setup pid=3097)[0m  + wheel==0.45.1
[36m(setup pid=3097)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3097)[0m Resolved 29 packages in 105ms
[36m(setup pid=3097)[0m Downloading sympy (6.0MiB)
[36m(setup pid=3097)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=3097)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=3097)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=3097)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=3097)[0m Downloading pillow (6.3MiB)
[36m(setup pid=3097)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=3097)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=3097)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=3097)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=3097)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=3097)[0m Downloading triton (148.4MiB)
[36m(setup pid=3097)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=3097)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=3097)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=3097)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=3097)[0m Downloading torch (783.1MiB)
[36m(setup pid=3097)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=2318, ip=10.113.50.48)[0m Using CPython 3.10.12 interpreter at: /usr/bin/python3.10
[36m(setup pid=2318, ip=10.113.50.48)[0m Creating virtual environment with seed packages at: /root/training
[36m(setup pid=2318, ip=10.113.50.48)[0m  + pip==25.2
[36m(setup pid=2318, ip=10.113.50.48)[0m  + setuptools==80.9.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + wheel==0.45.1
[36m(setup pid=2318, ip=10.113.50.48)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3097)[0m  Downloading nvidia-cufile-cu12
[36m(setup pid=2318, ip=10.113.50.48)[0m Resolved 29 packages in 84ms
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading sympy (6.0MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading pillow (6.3MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading triton (148.4MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading torch (783.1MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading nvidia-cufile-cu12
[36m(setup pid=3097)[0m  Downloading torchaudio
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading torchaudio
[36m(setup pid=3097)[0m  Downloading torchvision
[36m(setup pid=3097)[0m  Downloading pillow
[36m(setup pid=3097)[0m  Downloading nvidia-cuda-cupti-cu12
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading torchvision
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading pillow
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading nvidia-cuda-cupti-cu12
[36m(setup pid=3097)[0m  Downloading nvidia-nvjitlink-cu12
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading nvidia-nvjitlink-cu12
[36m(setup pid=3097)[0m  Downloading nvidia-cuda-nvrtc-cu12
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading nvidia-cuda-nvrtc-cu12
[36m(setup pid=3097)[0m  Downloading nvidia-curand-cu12
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading nvidia-curand-cu12
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading sympy
[36m(setup pid=3097)[0m  Downloading sympy
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading nvidia-cusolver-cu12
[36m(setup pid=3097)[0m  Downloading nvidia-cusolver-cu12
[36m(setup pid=3097)[0m  Downloading nvidia-cusparselt-cu12
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading nvidia-cusparselt-cu12
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading triton
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading nvidia-cufft-cu12
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading nvidia-nccl-cu12
[36m(setup pid=3097)[0m  Downloading triton
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading nvidia-cusparse-cu12
[36m(setup pid=3097)[0m  Downloading nvidia-nccl-cu12
[36m(setup pid=3097)[0m  Downloading nvidia-cufft-cu12
[36m(setup pid=3097)[0m  Downloading nvidia-cusparse-cu12
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading nvidia-cublas-cu12
[36m(setup pid=3097)[0m  Downloading nvidia-cublas-cu12
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading nvidia-cudnn-cu12
[36m(setup pid=3097)[0m  Downloading nvidia-cudnn-cu12
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading torch
[36m(setup pid=2318, ip=10.113.50.48)[0m Prepared 22 packages in 20.67s
[36m(setup pid=2318, ip=10.113.50.48)[0m Installed 28 packages in 163ms
[36m(setup pid=2318, ip=10.113.50.48)[0m  + filelock==3.18.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + fsspec==2025.7.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + jinja2==3.1.6
[36m(setup pid=2318, ip=10.113.50.48)[0m  + markupsafe==3.0.2
[36m(setup pid=2318, ip=10.113.50.48)[0m  + mpmath==1.3.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + networkx==3.4.2
[36m(setup pid=2318, ip=10.113.50.48)[0m  + numpy==2.2.6
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=2318, ip=10.113.50.48)[0m  + pillow==11.3.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + sympy==1.14.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + torch==2.7.1
[36m(setup pid=2318, ip=10.113.50.48)[0m  + torchaudio==2.7.1
[36m(setup pid=2318, ip=10.113.50.48)[0m  + torchvision==0.22.1
[36m(setup pid=2318, ip=10.113.50.48)[0m  + triton==3.3.1
[36m(setup pid=2318, ip=10.113.50.48)[0m  + typing-extensions==4.14.1
[36m(setup pid=2318, ip=10.113.50.48)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2318, ip=10.113.50.48)[0m Resolved 73 packages in 232ms
[36m(setup pid=2318, ip=10.113.50.48)[0m    Building deepspeed==0.17.4
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading transformers (10.7MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading tokenizers
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading hf-xet
[36m(setup pid=3097)[0m  Downloading torch
[36m(setup pid=3097)[0m Prepared 22 packages in 21.74s
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading pyarrow
[36m(setup pid=3097)[0m Installed 28 packages in 155ms
[36m(setup pid=3097)[0m  + filelock==3.18.0
[36m(setup pid=3097)[0m  + fsspec==2025.7.0
[36m(setup pid=3097)[0m  + jinja2==3.1.6
[36m(setup pid=3097)[0m  + markupsafe==3.0.2
[36m(setup pid=3097)[0m  + mpmath==1.3.0
[36m(setup pid=3097)[0m  + networkx==3.4.2
[36m(setup pid=3097)[0m  + numpy==2.2.6
[36m(setup pid=3097)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=3097)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=3097)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=3097)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=3097)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=3097)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=3097)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=3097)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=3097)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=3097)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=3097)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=3097)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=3097)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=3097)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=3097)[0m  + pillow==11.3.0
[36m(setup pid=3097)[0m  + sympy==1.14.0
[36m(setup pid=3097)[0m  + torch==2.7.1
[36m(setup pid=3097)[0m  + torchaudio==2.7.1
[36m(setup pid=3097)[0m  + torchvision==0.22.1
[36m(setup pid=3097)[0m  + triton==3.3.1
[36m(setup pid=3097)[0m  + typing-extensions==4.14.1
[36m(setup pid=3097)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2318, ip=10.113.50.48)[0m  Downloading transformers
[36m(setup pid=3097)[0m Resolved 73 packages in 259ms
[36m(setup pid=3097)[0m    Building deepspeed==0.17.4
[36m(setup pid=3097)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=3097)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=3097)[0m Downloading transformers (10.7MiB)
[36m(setup pid=3097)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=3097)[0m  Downloading tokenizers
[36m(setup pid=3097)[0m  Downloading hf-xet
[36m(setup pid=2318, ip=10.113.50.48)[0m       Built deepspeed==0.17.4
[36m(setup pid=2318, ip=10.113.50.48)[0m Prepared 21 packages in 1.31s
[36m(setup pid=2318, ip=10.113.50.48)[0m Uninstalled 1 package in 0.88ms
[36m(setup pid=2318, ip=10.113.50.48)[0m Installed 48 packages in 78ms
[36m(setup pid=2318, ip=10.113.50.48)[0m  + accelerate==1.9.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=2318, ip=10.113.50.48)[0m  + aiohttp==3.12.15
[36m(setup pid=2318, ip=10.113.50.48)[0m  + aiosignal==1.4.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + annotated-types==0.7.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + async-timeout==5.0.1
[36m(setup pid=2318, ip=10.113.50.48)[0m  + attrs==25.3.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + certifi==2025.7.14
[36m(setup pid=2318, ip=10.113.50.48)[0m  + charset-normalizer==3.4.2
[36m(setup pid=2318, ip=10.113.50.48)[0m  + datasets==4.0.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + deepspeed==0.17.4
[36m(setup pid=2318, ip=10.113.50.48)[0m  + dill==0.3.8
[36m(setup pid=2318, ip=10.113.50.48)[0m  + einops==0.8.1
[36m(setup pid=2318, ip=10.113.50.48)[0m  + frozenlist==1.7.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  - fsspec==2025.7.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + fsspec==2025.3.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + hf-xet==1.1.5
[36m(setup pid=2318, ip=10.113.50.48)[0m  + hjson==3.1.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + huggingface-hub==0.34.3
[36m(setup pid=2318, ip=10.113.50.48)[0m  + idna==3.10
[36m(setup pid=2318, ip=10.113.50.48)[0m  + liger-kernel==0.6.1
[36m(setup pid=2318, ip=10.113.50.48)[0m  + msgpack==1.1.1
[36m(setup pid=2318, ip=10.113.50.48)[0m  + multidict==6.6.3
[36m(setup pid=2318, ip=10.113.50.48)[0m  + multiprocess==0.70.16
[36m(setup pid=2318, ip=10.113.50.48)[0m  + ninja==1.11.1.4
[36m(setup pid=2318, ip=10.113.50.48)[0m  + packaging==25.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + pandas==2.3.1
[36m(setup pid=2318, ip=10.113.50.48)[0m  + propcache==0.3.2
[36m(setup pid=2318, ip=10.113.50.48)[0m  + psutil==7.0.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + pyarrow==21.0.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + pydantic==2.11.7
[36m(setup pid=2318, ip=10.113.50.48)[0m  + pydantic-core==2.33.2
[36m(setup pid=2318, ip=10.113.50.48)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + pytz==2025.2
[36m(setup pid=2318, ip=10.113.50.48)[0m  + pyyaml==6.0.2
[36m(setup pid=2318, ip=10.113.50.48)[0m  + regex==2025.7.34
[36m(setup pid=2318, ip=10.113.50.48)[0m  + requests==2.32.4
[36m(setup pid=2318, ip=10.113.50.48)[0m  + safetensors==0.5.3
[36m(setup pid=2318, ip=10.113.50.48)[0m  + six==1.17.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + tokenizers==0.21.4
[36m(setup pid=2318, ip=10.113.50.48)[0m  + tqdm==4.67.1
[36m(setup pid=2318, ip=10.113.50.48)[0m  + transformers==4.54.1
[36m(setup pid=2318, ip=10.113.50.48)[0m  + trl==0.20.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + typing-inspection==0.4.1
[36m(setup pid=2318, ip=10.113.50.48)[0m  + tzdata==2025.2
[36m(setup pid=2318, ip=10.113.50.48)[0m  + urllib3==2.5.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + xxhash==3.5.0
[36m(setup pid=2318, ip=10.113.50.48)[0m  + yarl==1.20.1
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=3097)[0m  Downloading pyarrow
[36m(setup pid=3097)[0m  Downloading transformers
[36m(setup pid=3097)[0m       Built deepspeed==0.17.4
[36m(setup pid=3097)[0m Prepared 21 packages in 1.41s
[36m(setup pid=3097)[0m Uninstalled 1 package in 0.93ms
[36m(setup pid=2318, ip=10.113.50.48)[0m Reading package lists...
[36m(setup pid=3097)[0m Installed 48 packages in 56ms
[36m(setup pid=3097)[0m  + accelerate==1.9.0
[36m(setup pid=3097)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=3097)[0m  + aiohttp==3.12.15
[36m(setup pid=3097)[0m  + aiosignal==1.4.0
[36m(setup pid=3097)[0m  + annotated-types==0.7.0
[36m(setup pid=3097)[0m  + async-timeout==5.0.1
[36m(setup pid=3097)[0m  + attrs==25.3.0
[36m(setup pid=3097)[0m  + certifi==2025.7.14
[36m(setup pid=3097)[0m  + charset-normalizer==3.4.2
[36m(setup pid=3097)[0m  + datasets==4.0.0
[36m(setup pid=3097)[0m  + deepspeed==0.17.4
[36m(setup pid=3097)[0m  + dill==0.3.8
[36m(setup pid=3097)[0m  + einops==0.8.1
[36m(setup pid=3097)[0m  + frozenlist==1.7.0
[36m(setup pid=3097)[0m  - fsspec==2025.7.0
[36m(setup pid=3097)[0m  + fsspec==2025.3.0
[36m(setup pid=3097)[0m  + hf-xet==1.1.5
[36m(setup pid=3097)[0m  + hjson==3.1.0
[36m(setup pid=3097)[0m  + huggingface-hub==0.34.3
[36m(setup pid=3097)[0m  + idna==3.10
[36m(setup pid=3097)[0m  + liger-kernel==0.6.1
[36m(setup pid=3097)[0m  + msgpack==1.1.1
[36m(setup pid=3097)[0m  + multidict==6.6.3
[36m(setup pid=3097)[0m  + multiprocess==0.70.16
[36m(setup pid=3097)[0m  + ninja==1.11.1.4
[36m(setup pid=3097)[0m  + packaging==25.0
[36m(setup pid=3097)[0m  + pandas==2.3.1
[36m(setup pid=3097)[0m  + propcache==0.3.2
[36m(setup pid=3097)[0m  + psutil==7.0.0
[36m(setup pid=3097)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=3097)[0m  + pyarrow==21.0.0
[36m(setup pid=3097)[0m  + pydantic==2.11.7
[36m(setup pid=3097)[0m  + pydantic-core==2.33.2
[36m(setup pid=3097)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=3097)[0m  + pytz==2025.2
[36m(setup pid=3097)[0m  + pyyaml==6.0.2
[36m(setup pid=3097)[0m  + regex==2025.7.34
[36m(setup pid=3097)[0m  + requests==2.32.4
[36m(setup pid=3097)[0m  + safetensors==0.5.3
[36m(setup pid=3097)[0m  + six==1.17.0
[36m(setup pid=3097)[0m  + tokenizers==0.21.4
[36m(setup pid=3097)[0m  + tqdm==4.67.1
[36m(setup pid=3097)[0m  + transformers==4.54.1
[36m(setup pid=3097)[0m  + trl==0.20.0
[36m(setup pid=3097)[0m  + typing-inspection==0.4.1
[36m(setup pid=3097)[0m  + tzdata==2025.2
[36m(setup pid=3097)[0m  + urllib3==2.5.0
[36m(setup pid=3097)[0m  + xxhash==3.5.0
[36m(setup pid=3097)[0m  + yarl==1.20.1
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3097)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m Building dependency tree...
[36m(setup pid=2318, ip=10.113.50.48)[0m Reading state information...
[36m(setup pid=2318, ip=10.113.50.48)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2318, ip=10.113.50.48)[0m   libfuse2
[36m(setup pid=2318, ip=10.113.50.48)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2318, ip=10.113.50.48)[0m The following NEW packages will be installed:
[36m(setup pid=2318, ip=10.113.50.48)[0m   vmtouch
[36m(setup pid=2318, ip=10.113.50.48)[0m 0 upgraded, 1 newly installed, 0 to remove and 87 not upgraded.
[36m(setup pid=2318, ip=10.113.50.48)[0m Need to get 21.5 kB of archives.
[36m(setup pid=2318, ip=10.113.50.48)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 vmtouch amd64 1.3.1-2 [21.5 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2318, ip=10.113.50.48)[0m Fetched 21.5 kB in 0s (116 kB/s)
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=2318, ip=10.113.50.48)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23403 files and directories currently installed.)
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../vmtouch_1.3.1-2_amd64.deb ...
[36m(setup pid=3097)[0m Reading package lists...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking vmtouch (1.3.1-2) ...
[36m(setup pid=3097)[0m Building dependency tree...
[36m(setup pid=3097)[0m Reading state information...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up vmtouch (1.3.1-2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=2318, ip=10.113.50.48)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=3097)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3097)[0m   libfuse2
[36m(setup pid=3097)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3097)[0m The following NEW packages will be installed:
[36m(setup pid=3097)[0m   vmtouch
[36m(setup pid=3097)[0m 0 upgraded, 1 newly installed, 0 to remove and 87 not upgraded.
[36m(setup pid=3097)[0m Need to get 21.5 kB of archives.
[36m(setup pid=3097)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=3097)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 vmtouch amd64 1.3.1-2 [21.5 kB]
[36m(setup pid=3097)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3097)[0m Fetched 21.5 kB in 0s (182 kB/s)
[36m(setup pid=3097)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=3097)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23403 files and directories currently installed.)
[36m(setup pid=3097)[0m Preparing to unpack .../vmtouch_1.3.1-2_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking vmtouch (1.3.1-2) ...
[36m(setup pid=3097)[0m Setting up vmtouch (1.3.1-2) ...
[36m(setup pid=3097)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=3097)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3097)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m Reading package lists...
[36m(setup pid=2318, ip=10.113.50.48)[0m Building dependency tree...
[36m(setup pid=2318, ip=10.113.50.48)[0m Reading state information...
[36m(setup pid=2318, ip=10.113.50.48)[0m build-essential is already the newest version (12.9ubuntu3).
[36m(setup pid=2318, ip=10.113.50.48)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2318, ip=10.113.50.48)[0m   libfuse2
[36m(setup pid=2318, ip=10.113.50.48)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2318, ip=10.113.50.48)[0m The following additional packages will be installed:
[36m(setup pid=2318, ip=10.113.50.48)[0m   javascript-common libexpat1 libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=2318, ip=10.113.50.48)[0m   libjs-underscore libpython3-dev libpython3.10 libpython3.10-dev
[36m(setup pid=2318, ip=10.113.50.48)[0m   libpython3.10-minimal libpython3.10-stdlib python3-distutils python3-lib2to3
[36m(setup pid=2318, ip=10.113.50.48)[0m   python3.10 python3.10-minimal
[36m(setup pid=2318, ip=10.113.50.48)[0m Suggested packages:
[36m(setup pid=2318, ip=10.113.50.48)[0m   apache2 | lighttpd | httpd python3.10-venv python3.10-doc binfmt-support
[36m(setup pid=2318, ip=10.113.50.48)[0m The following NEW packages will be installed:
[36m(setup pid=2318, ip=10.113.50.48)[0m   javascript-common libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=2318, ip=10.113.50.48)[0m   libjs-underscore libpython3-dev libpython3.10-dev python3-dev
[36m(setup pid=2318, ip=10.113.50.48)[0m   python3-distutils python3-lib2to3 python3.10-dev
[36m(setup pid=2318, ip=10.113.50.48)[0m The following packages will be upgraded:
[36m(setup pid=2318, ip=10.113.50.48)[0m   libexpat1 libpython3.10 libpython3.10-minimal libpython3.10-stdlib
[36m(setup pid=2318, ip=10.113.50.48)[0m   python3.10 python3.10-minimal
[36m(setup pid=3097)[0m Reading package lists...
[36m(setup pid=2318, ip=10.113.50.48)[0m 6 upgraded, 11 newly installed, 0 to remove and 81 not upgraded.
[36m(setup pid=2318, ip=10.113.50.48)[0m Need to get 13.7 MB of archives.
[36m(setup pid=2318, ip=10.113.50.48)[0m After this operation, 25.1 MB of additional disk space will be used.
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1 amd64 2.4.7-1ubuntu0.6 [92.1 kB]
[36m(setup pid=3097)[0m Building dependency tree...
[36m(setup pid=3097)[0m Reading state information...
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.10 [1950 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.10 [1850 kB]
[36m(setup pid=3097)[0m build-essential is already the newest version (12.9ubuntu3).
[36m(setup pid=3097)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3097)[0m   libfuse2
[36m(setup pid=3097)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3097)[0m The following additional packages will be installed:
[36m(setup pid=3097)[0m   javascript-common libexpat1 libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=3097)[0m   libjs-underscore libpython3-dev libpython3.10 libpython3.10-dev
[36m(setup pid=3097)[0m   libpython3.10-minimal libpython3.10-stdlib python3-distutils python3-lib2to3
[36m(setup pid=3097)[0m   python3.10 python3.10-minimal
[36m(setup pid=3097)[0m Suggested packages:
[36m(setup pid=3097)[0m   apache2 | lighttpd | httpd python3.10-venv python3.10-doc binfmt-support
[36m(setup pid=3097)[0m The following NEW packages will be installed:
[36m(setup pid=3097)[0m   javascript-common libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=3097)[0m   libjs-underscore libpython3-dev libpython3.10-dev python3-dev
[36m(setup pid=3097)[0m   python3-distutils python3-lib2to3 python3.10-dev
[36m(setup pid=3097)[0m The following packages will be upgraded:
[36m(setup pid=3097)[0m   libexpat1 libpython3.10 libpython3.10-minimal libpython3.10-stdlib
[36m(setup pid=3097)[0m   python3.10 python3.10-minimal
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.10 [2277 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.10 [815 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5936 B]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1-dev amd64 2.4.7-1ubuntu0.6 [148 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-jquery all 3.6.0+dfsg+~3.5.13-1 [321 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.10 [4763 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3-dev amd64 3.10.6-1~22.04.1 [7064 B]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-lib2to3 all 3.10.8-1~22.04 [77.6 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-distutils all 3.10.8-1~22.04 [139 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2318, ip=10.113.50.48)[0m Fetched 13.7 MB in 1s (25.2 MB/s)
[36m(setup pid=2318, ip=10.113.50.48)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23413 files and directories currently installed.)
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../00-libexpat1_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libexpat1:amd64 (2.4.7-1ubuntu0.6) over (2.4.7-1ubuntu0.4) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libpython3.10:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3097)[0m 6 upgraded, 11 newly installed, 0 to remove and 81 not upgraded.
[36m(setup pid=3097)[0m Need to get 13.7 MB of archives.
[36m(setup pid=3097)[0m After this operation, 25.1 MB of additional disk space will be used.
[36m(setup pid=3097)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1 amd64 2.4.7-1ubuntu0.6 [92.1 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../02-python3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking python3.10 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3097)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.10 [1950 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking python3.10-minimal (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3097)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=3097)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.10 [1850 kB]
[36m(setup pid=3097)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.10 [2277 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package javascript-common.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../06-javascript-common_11+nmu1_all.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking javascript-common (11+nmu1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libexpat1-dev:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../07-libexpat1-dev_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libjs-jquery.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../08-libjs-jquery_3.6.0+dfsg+~3.5.13-1_all.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=3097)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.10 [815 kB]
[36m(setup pid=3097)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5936 B]
[36m(setup pid=3097)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1-dev amd64 2.4.7-1ubuntu0.6 [148 kB]
[36m(setup pid=3097)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-jquery all 3.6.0+dfsg+~3.5.13-1 [321 kB]
[36m(setup pid=3097)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libjs-underscore.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libjs-sphinxdoc.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libpython3.10-dev:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../11-libpython3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3097)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]
[36m(setup pid=3097)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.10 [4763 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libpython3-dev:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../12-libpython3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package python3.10-dev.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../13-python3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package python3-lib2to3.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../14-python3-lib2to3_3.10.8-1~22.04_all.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package python3-distutils.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../15-python3-distutils_3.10.8-1~22.04_all.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3097)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3-dev amd64 3.10.6-1~22.04.1 [7064 B]
[36m(setup pid=3097)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=3097)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-lib2to3 all 3.10.8-1~22.04 [77.6 kB]
[36m(setup pid=3097)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-distutils all 3.10.8-1~22.04 [139 kB]
[36m(setup pid=3097)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package python3-dev.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../16-python3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libexpat1:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up javascript-common (11+nmu1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=3097)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3097)[0m Fetched 13.7 MB in 1s (9210 kB/s)
[36m(setup pid=3097)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23413 files and directories currently installed.)
[36m(setup pid=3097)[0m Preparing to unpack .../00-libexpat1_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libexpat1:amd64 (2.4.7-1ubuntu0.6) over (2.4.7-1ubuntu0.4) ...
[36m(setup pid=3097)[0m Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libpython3.10:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3097)[0m Preparing to unpack .../02-python3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking python3.10 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3097)[0m Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up python3.10-minimal (3.10.12-1~22.04.10) ...
[36m(setup pid=3097)[0m Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libpython3.10:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up python3.10 (3.10.12-1~22.04.10) ...
[36m(setup pid=3097)[0m Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking python3.10-minimal (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3097)[0m Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3097)[0m Selecting previously unselected package javascript-common.
[36m(setup pid=3097)[0m Preparing to unpack .../06-javascript-common_11+nmu1_all.deb ...
[36m(setup pid=3097)[0m Unpacking javascript-common (11+nmu1) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libexpat1-dev:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../07-libexpat1-dev_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=3097)[0m Selecting previously unselected package libjs-jquery.
[36m(setup pid=3097)[0m Preparing to unpack .../08-libjs-jquery_3.6.0+dfsg+~3.5.13-1_all.deb ...
[36m(setup pid=3097)[0m Unpacking libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libjs-underscore.
[36m(setup pid=3097)[0m Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...
[36m(setup pid=3097)[0m Unpacking libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libjs-sphinxdoc.
[36m(setup pid=3097)[0m Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...
[36m(setup pid=3097)[0m Unpacking libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libpython3.10-dev:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../11-libpython3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libpython3-dev:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../12-libpython3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=3097)[0m Selecting previously unselected package python3.10-dev.
[36m(setup pid=3097)[0m Preparing to unpack .../13-python3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=3097)[0m Selecting previously unselected package python3-lib2to3.
[36m(setup pid=3097)[0m Preparing to unpack .../14-python3-lib2to3_3.10.8-1~22.04_all.deb ...
[36m(setup pid=3097)[0m Unpacking python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=3097)[0m Selecting previously unselected package python3-distutils.
[36m(setup pid=3097)[0m Preparing to unpack .../15-python3-distutils_3.10.8-1~22.04_all.deb ...
[36m(setup pid=3097)[0m Unpacking python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3097)[0m Selecting previously unselected package python3-dev.
[36m(setup pid=3097)[0m Preparing to unpack .../16-python3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=3097)[0m Setting up libexpat1:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3097)[0m Setting up javascript-common (11+nmu1) ...
[36m(setup pid=3097)[0m Setting up libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3097)[0m Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3097)[0m Setting up libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=3097)[0m Setting up python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=3097)[0m Setting up libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=3097)[0m Setting up python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3097)[0m Setting up python3.10-minimal (3.10.12-1~22.04.10) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Reading package lists...
[36m(setup pid=2318, ip=10.113.50.48)[0m Building dependency tree...
[36m(setup pid=2318, ip=10.113.50.48)[0m Reading state information...
[36m(setup pid=3097)[0m Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3097)[0m Setting up libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=3097)[0m Setting up libpython3.10:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m infiniband-diags is already the newest version (2410mlnx54-1.2410068).
[36m(setup pid=2318, ip=10.113.50.48)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2318, ip=10.113.50.48)[0m   libfuse2
[36m(setup pid=2318, ip=10.113.50.48)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2318, ip=10.113.50.48)[0m The following additional packages will be installed:
[36m(setup pid=2318, ip=10.113.50.48)[0m   dbus dmsetup gir1.2-glib-2.0 libapparmor1 libargon2-1 libatm1 libbpf0
[36m(setup pid=2318, ip=10.113.50.48)[0m   libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1 libgirepository-1.0-1
[36m(setup pid=2318, ip=10.113.50.48)[0m   libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5 libmnl0 libnl-genl-3-200
[36m(setup pid=2318, ip=10.113.50.48)[0m   libsensors-config libsensors5 libsystemd0 libxtables12 networkd-dispatcher
[36m(setup pid=2318, ip=10.113.50.48)[0m   python3-dbus python3-gi shared-mime-info systemd systemd-timesyncd
[36m(setup pid=2318, ip=10.113.50.48)[0m   vim-common vim-runtime xdg-user-dirs
[36m(setup pid=2318, ip=10.113.50.48)[0m Suggested packages:
[36m(setup pid=2318, ip=10.113.50.48)[0m   default-dbus-session-bus | dbus-session-bus lm-sensors lsof strace
[36m(setup pid=2318, ip=10.113.50.48)[0m   iproute2-doc iw | wireless-tools python-dbus-doc isag systemd-container
[36m(setup pid=2318, ip=10.113.50.48)[0m   libtss2-esys-3.0.2-0 libtss2-mu0 libtss2-rc0 policykit-1 ctags vim-doc
[36m(setup pid=2318, ip=10.113.50.48)[0m   vim-scripts
[36m(setup pid=3097)[0m Setting up python3.10 (3.10.12-1~22.04.10) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m The following NEW packages will be installed:
[36m(setup pid=2318, ip=10.113.50.48)[0m   dbus dmsetup gir1.2-glib-2.0 htop iproute2 libapparmor1 libargon2-1 libatm1
[36m(setup pid=2318, ip=10.113.50.48)[0m   libbpf0 libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1
[36m(setup pid=2318, ip=10.113.50.48)[0m   libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5
[36m(setup pid=2318, ip=10.113.50.48)[0m   libmnl0 libnl-genl-3-200 libsensors-config libsensors5 libxtables12
[36m(setup pid=2318, ip=10.113.50.48)[0m   networkd-dispatcher python3-dbus python3-gi shared-mime-info sysstat systemd
[36m(setup pid=2318, ip=10.113.50.48)[0m   systemd-timesyncd xdg-user-dirs
[36m(setup pid=2318, ip=10.113.50.48)[0m The following packages will be upgraded:
[36m(setup pid=2318, ip=10.113.50.48)[0m   libsystemd0 net-tools vim vim-common vim-runtime
[36m(setup pid=2318, ip=10.113.50.48)[0m 5 upgraded, 31 newly installed, 0 to remove and 76 not upgraded.
[36m(setup pid=2318, ip=10.113.50.48)[0m Need to get 19.2 MB of archives.
[36m(setup pid=2318, ip=10.113.50.48)[0m After this operation, 35.4 MB of additional disk space will be used.
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsystemd0 amd64 249.11-0ubuntu3.16 [317 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapparmor1 amd64 3.0.4-2ubuntu2.4 [39.7 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libargon2-1 amd64 0~20171227-0.3 [19.5 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdevmapper1.02.1 amd64 2:1.02.175-2.1ubuntu5 [139 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjson-c5 amd64 0.15-3~ubuntu1.22.04.2 [33.5 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcryptsetup12 amd64 2:2.4.3-1ubuntu1.3 [211 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip4tc2 amd64 1.8.7-1ubuntu5.2 [19.9 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd amd64 249.11-0ubuntu3.16 [4581 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-3 amd64 1.12.20-2ubuntu4.1 [189 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dbus amd64 1.12.20-2ubuntu4.1 [158 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dmsetup amd64 2:1.02.175-2.1ubuntu5 [81.7 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.5 [1466 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgirepository-1.0-1 amd64 1.72.0-1 [55.6 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-glib-2.0 amd64 1.72.0-1 [164 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libelf1 amd64 0.186-1ubuntu0.1 [51.1 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbpf0 amd64 1:0.5.0-1ubuntu22.04.1 [140 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmnl0 amd64 1.0.4-3build2 [13.2 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxtables12 amd64 1.8.7-1ubuntu5.2 [31.3 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 iproute2 amd64 5.15.0-1ubuntu2 [1070 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatm1 amd64 1:2.5.1-4build2 [22.8 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.5 [4656 B]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-dbus amd64 1.2.18-3build1 [99.5 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-gi amd64 3.42.1-0ubuntu1 [229 kB]
[36m(setup pid=3097)[0m Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3097)[0m Setting up python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 networkd-dispatcher all 2.1-2ubuntu0.22.04.2 [15.8 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-timesyncd amd64 249.11-0ubuntu3.16 [31.2 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim amd64 2:8.2.3995-1ubuntu2.24 [1728 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:28 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-runtime all 2:8.2.3995-1ubuntu2.24 [6833 kB]
[36m(setup pid=3097)[0m Setting up libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-common all 2:8.2.3995-1ubuntu2.24 [81.5 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 htop amd64 3.0.5-7build2 [128 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:33 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:34 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:35 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 net-tools amd64 1.60+git20181103.0eebece-1ubuntu5.4 [204 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Get:36 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]
[36m(setup pid=3097)[0m Setting up python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2318, ip=10.113.50.48)[0m Fetched 19.2 MB in 1s (26.3 MB/s)
[36m(setup pid=3097)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23989 files and directories currently installed.)
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../libsystemd0_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3097)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libsystemd0:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libsystemd0:amd64 (249.11-0ubuntu3.16) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libapparmor1:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23989 files and directories currently installed.)
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../00-libapparmor1_3.0.4-2ubuntu2.4_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libargon2-1:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../01-libargon2-1_0~20171227-0.3_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libdevmapper1.02.1:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../02-libdevmapper1.02.1_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libjson-c5:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../03-libjson-c5_0.15-3~ubuntu1.22.04.2_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libcryptsetup12:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../04-libcryptsetup12_2%3a2.4.3-1ubuntu1.3_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libip4tc2:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../05-libip4tc2_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package systemd.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../06-systemd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3097)[0m Reading package lists...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libdbus-1-3:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../07-libdbus-1-3_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package dbus.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../08-dbus_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package dmsetup.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../09-dmsetup_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libglib2.0-0:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../10-libglib2.0-0_2.72.4-0ubuntu2.5_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libgirepository-1.0-1:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../11-libgirepository-1.0-1_1.72.0-1_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=3097)[0m Building dependency tree...
[36m(setup pid=3097)[0m Reading state information...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package gir1.2-glib-2.0:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../12-gir1.2-glib-2.0_1.72.0-1_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../13-libelf1_0.186-1ubuntu0.1_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libbpf0:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../14-libbpf0_1%3a0.5.0-1ubuntu22.04.1_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../15-libmnl0_1.0.4-3build2_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../16-libxtables12_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3097)[0m infiniband-diags is already the newest version (2410mlnx54-1.2410068).
[36m(setup pid=3097)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3097)[0m   libfuse2
[36m(setup pid=3097)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3097)[0m The following additional packages will be installed:
[36m(setup pid=3097)[0m   dbus dmsetup gir1.2-glib-2.0 libapparmor1 libargon2-1 libatm1 libbpf0
[36m(setup pid=3097)[0m   libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1 libgirepository-1.0-1
[36m(setup pid=3097)[0m   libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5 libmnl0 libnl-genl-3-200
[36m(setup pid=3097)[0m   libsensors-config libsensors5 libsystemd0 libxtables12 networkd-dispatcher
[36m(setup pid=3097)[0m   python3-dbus python3-gi shared-mime-info systemd systemd-timesyncd
[36m(setup pid=3097)[0m   vim-common vim-runtime xdg-user-dirs
[36m(setup pid=3097)[0m Suggested packages:
[36m(setup pid=3097)[0m   default-dbus-session-bus | dbus-session-bus lm-sensors lsof strace
[36m(setup pid=3097)[0m   iproute2-doc iw | wireless-tools python-dbus-doc isag systemd-container
[36m(setup pid=3097)[0m   libtss2-esys-3.0.2-0 libtss2-mu0 libtss2-rc0 policykit-1 ctags vim-doc
[36m(setup pid=3097)[0m   vim-scripts
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package iproute2.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../17-iproute2_5.15.0-1ubuntu2_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../18-libatm1_1%3a2.5.1-4build2_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libglib2.0-data.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../19-libglib2.0-data_2.72.4-0ubuntu2.5_all.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package python3-dbus.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../20-python3-dbus_1.2.18-3build1_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package python3-gi.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../21-python3-gi_3.42.1-0ubuntu1_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=3097)[0m The following NEW packages will be installed:
[36m(setup pid=3097)[0m   dbus dmsetup gir1.2-glib-2.0 htop iproute2 libapparmor1 libargon2-1 libatm1
[36m(setup pid=3097)[0m   libbpf0 libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1
[36m(setup pid=3097)[0m   libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5
[36m(setup pid=3097)[0m   libmnl0 libnl-genl-3-200 libsensors-config libsensors5 libxtables12
[36m(setup pid=3097)[0m   networkd-dispatcher python3-dbus python3-gi shared-mime-info sysstat systemd
[36m(setup pid=3097)[0m   systemd-timesyncd xdg-user-dirs
[36m(setup pid=3097)[0m The following packages will be upgraded:
[36m(setup pid=3097)[0m   libsystemd0 net-tools vim vim-common vim-runtime
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package networkd-dispatcher.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../22-networkd-dispatcher_2.1-2ubuntu0.22.04.2_all.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package shared-mime-info.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../23-shared-mime-info_2.1-2_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking shared-mime-info (2.1-2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package systemd-timesyncd.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../24-systemd-timesyncd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking systemd-timesyncd (249.11-0ubuntu3.16) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../25-vim_2%3a8.2.3995-1ubuntu2.24_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking vim (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3097)[0m 5 upgraded, 31 newly installed, 0 to remove and 76 not upgraded.
[36m(setup pid=3097)[0m Need to get 19.2 MB of archives.
[36m(setup pid=3097)[0m After this operation, 35.4 MB of additional disk space will be used.
[36m(setup pid=3097)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsystemd0 amd64 249.11-0ubuntu3.16 [317 kB]
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../26-vim-runtime_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking vim-runtime (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3097)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapparmor1 amd64 3.0.4-2ubuntu2.4 [39.7 kB]
[36m(setup pid=3097)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libargon2-1 amd64 0~20171227-0.3 [19.5 kB]
[36m(setup pid=3097)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdevmapper1.02.1 amd64 2:1.02.175-2.1ubuntu5 [139 kB]
[36m(setup pid=3097)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjson-c5 amd64 0.15-3~ubuntu1.22.04.2 [33.5 kB]
[36m(setup pid=3097)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcryptsetup12 amd64 2:2.4.3-1ubuntu1.3 [211 kB]
[36m(setup pid=3097)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip4tc2 amd64 1.8.7-1ubuntu5.2 [19.9 kB]
[36m(setup pid=3097)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd amd64 249.11-0ubuntu3.16 [4581 kB]
[36m(setup pid=3097)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-3 amd64 1.12.20-2ubuntu4.1 [189 kB]
[36m(setup pid=3097)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dbus amd64 1.12.20-2ubuntu4.1 [158 kB]
[36m(setup pid=3097)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dmsetup amd64 2:1.02.175-2.1ubuntu5 [81.7 kB]
[36m(setup pid=3097)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.5 [1466 kB]
[36m(setup pid=3097)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgirepository-1.0-1 amd64 1.72.0-1 [55.6 kB]
[36m(setup pid=3097)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-glib-2.0 amd64 1.72.0-1 [164 kB]
[36m(setup pid=3097)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libelf1 amd64 0.186-1ubuntu0.1 [51.1 kB]
[36m(setup pid=3097)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbpf0 amd64 1:0.5.0-1ubuntu22.04.1 [140 kB]
[36m(setup pid=3097)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmnl0 amd64 1.0.4-3build2 [13.2 kB]
[36m(setup pid=3097)[0m Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxtables12 amd64 1.8.7-1ubuntu5.2 [31.3 kB]
[36m(setup pid=3097)[0m Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 iproute2 amd64 5.15.0-1ubuntu2 [1070 kB]
[36m(setup pid=3097)[0m Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatm1 amd64 1:2.5.1-4build2 [22.8 kB]
[36m(setup pid=3097)[0m Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.5 [4656 B]
[36m(setup pid=3097)[0m Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-dbus amd64 1.2.18-3build1 [99.5 kB]
[36m(setup pid=3097)[0m Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-gi amd64 3.42.1-0ubuntu1 [229 kB]
[36m(setup pid=3097)[0m Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 networkd-dispatcher all 2.1-2ubuntu0.22.04.2 [15.8 kB]
[36m(setup pid=3097)[0m Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]
[36m(setup pid=3097)[0m Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-timesyncd amd64 249.11-0ubuntu3.16 [31.2 kB]
[36m(setup pid=3097)[0m Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim amd64 2:8.2.3995-1ubuntu2.24 [1728 kB]
[36m(setup pid=3097)[0m Get:28 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-runtime all 2:8.2.3995-1ubuntu2.24 [6833 kB]
[36m(setup pid=3097)[0m Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-common all 2:8.2.3995-1ubuntu2.24 [81.5 kB]
[36m(setup pid=3097)[0m Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]
[36m(setup pid=3097)[0m Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]
[36m(setup pid=3097)[0m Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 htop amd64 3.0.5-7build2 [128 kB]
[36m(setup pid=3097)[0m Get:33 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]
[36m(setup pid=3097)[0m Get:34 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]
[36m(setup pid=3097)[0m Get:35 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 net-tools amd64 1.60+git20181103.0eebece-1ubuntu5.4 [204 kB]
[36m(setup pid=3097)[0m Get:36 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]
[36m(setup pid=3097)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3097)[0m Fetched 19.2 MB in 1s (29.1 MB/s)
[36m(setup pid=3097)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23989 files and directories currently installed.)
[36m(setup pid=3097)[0m Preparing to unpack .../libsystemd0_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libsystemd0:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...
[36m(setup pid=3097)[0m Setting up libsystemd0:amd64 (249.11-0ubuntu3.16) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libapparmor1:amd64.
[36m(setup pid=3097)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23989 files and directories currently installed.)
[36m(setup pid=3097)[0m Preparing to unpack .../00-libapparmor1_3.0.4-2ubuntu2.4_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libargon2-1:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../01-libargon2-1_0~20171227-0.3_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libdevmapper1.02.1:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../02-libdevmapper1.02.1_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libjson-c5:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../03-libjson-c5_0.15-3~ubuntu1.22.04.2_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libcryptsetup12:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../04-libcryptsetup12_2%3a2.4.3-1ubuntu1.3_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libip4tc2:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../05-libip4tc2_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3097)[0m Selecting previously unselected package systemd.
[36m(setup pid=3097)[0m Preparing to unpack .../06-systemd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libdbus-1-3:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../07-libdbus-1-3_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3097)[0m Selecting previously unselected package dbus.
[36m(setup pid=3097)[0m Preparing to unpack .../08-dbus_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3097)[0m Selecting previously unselected package dmsetup.
[36m(setup pid=3097)[0m Preparing to unpack .../09-dmsetup_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libglib2.0-0:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../10-libglib2.0-0_2.72.4-0ubuntu2.5_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libgirepository-1.0-1:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../11-libgirepository-1.0-1_1.72.0-1_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=3097)[0m Selecting previously unselected package gir1.2-glib-2.0:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../12-gir1.2-glib-2.0_1.72.0-1_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../13-libelf1_0.186-1ubuntu0.1_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libbpf0:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../14-libbpf0_1%3a0.5.0-1ubuntu22.04.1_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../15-libmnl0_1.0.4-3build2_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../16-libxtables12_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3097)[0m Selecting previously unselected package iproute2.
[36m(setup pid=3097)[0m Preparing to unpack .../17-iproute2_5.15.0-1ubuntu2_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../18-libatm1_1%3a2.5.1-4build2_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libglib2.0-data.
[36m(setup pid=3097)[0m Preparing to unpack .../19-libglib2.0-data_2.72.4-0ubuntu2.5_all.deb ...
[36m(setup pid=3097)[0m Unpacking libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3097)[0m Selecting previously unselected package python3-dbus.
[36m(setup pid=3097)[0m Preparing to unpack .../20-python3-dbus_1.2.18-3build1_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking python3-dbus (1.2.18-3build1) ...
[36m(setup pid=3097)[0m Selecting previously unselected package python3-gi.
[36m(setup pid=3097)[0m Preparing to unpack .../21-python3-gi_3.42.1-0ubuntu1_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=3097)[0m Selecting previously unselected package networkd-dispatcher.
[36m(setup pid=3097)[0m Preparing to unpack .../22-networkd-dispatcher_2.1-2ubuntu0.22.04.2_all.deb ...
[36m(setup pid=3097)[0m Unpacking networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=3097)[0m Selecting previously unselected package shared-mime-info.
[36m(setup pid=3097)[0m Preparing to unpack .../23-shared-mime-info_2.1-2_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking shared-mime-info (2.1-2) ...
[36m(setup pid=3097)[0m Selecting previously unselected package systemd-timesyncd.
[36m(setup pid=3097)[0m Preparing to unpack .../24-systemd-timesyncd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking systemd-timesyncd (249.11-0ubuntu3.16) ...
[36m(setup pid=3097)[0m Preparing to unpack .../25-vim_2%3a8.2.3995-1ubuntu2.24_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking vim (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3097)[0m Preparing to unpack .../26-vim-runtime_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=3097)[0m Unpacking vim-runtime (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../27-vim-common_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking vim-common (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package xdg-user-dirs.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../28-xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libnl-genl-3-200:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../29-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package htop.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../30-htop_3.0.5-7build2_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking htop (3.0.5-7build2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../31-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../32-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../33-net-tools_1.60+git20181103.0eebece-1ubuntu5.4_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking net-tools (1.60+git20181103.0eebece-1ubuntu5.4) over (1.60+git20181103.0eebece-1ubuntu5) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Selecting previously unselected package sysstat.
[36m(setup pid=2318, ip=10.113.50.48)[0m Preparing to unpack .../34-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Unpacking sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5.4) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m No schema files found: doing nothing.
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up vim-common (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up shared-mime-info (2.1-2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up vim-runtime (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=2318, ip=10.113.50.48)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=2318, ip=10.113.50.48)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=2318, ip=10.113.50.48)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /lib/systemd/system/sysstat-collect.timer.
[36m(setup pid=3097)[0m Preparing to unpack .../27-vim-common_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /lib/systemd/system/sysstat-summary.timer.
[36m(setup pid=2318, ip=10.113.50.48)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.
[36m(setup pid=3097)[0m Unpacking vim-common (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3097)[0m Selecting previously unselected package xdg-user-dirs.
[36m(setup pid=3097)[0m Preparing to unpack .../28-xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libnl-genl-3-200:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../29-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up vim (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3097)[0m Selecting previously unselected package htop.
[36m(setup pid=3097)[0m Preparing to unpack .../30-htop_3.0.5-7build2_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking htop (3.0.5-7build2) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=3097)[0m Preparing to unpack .../31-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...
[36m(setup pid=3097)[0m Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3097)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=3097)[0m Preparing to unpack .../32-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3097)[0m Preparing to unpack .../33-net-tools_1.60+git20181103.0eebece-1ubuntu5.4_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking net-tools (1.60+git20181103.0eebece-1ubuntu5.4) over (1.60+git20181103.0eebece-1ubuntu5) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up htop (3.0.5-7build2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=3097)[0m Selecting previously unselected package sysstat.
[36m(setup pid=3097)[0m Preparing to unpack .../34-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...
[36m(setup pid=3097)[0m Unpacking sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=3097)[0m Setting up libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3097)[0m Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5.4) ...
[36m(setup pid=3097)[0m Setting up libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3097)[0m Setting up xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3097)[0m Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m Configuration file '/etc/systemd/system.conf'
[36m(setup pid=2318, ip=10.113.50.48)[0m  ==> File on system created by you or by a script.
[36m(setup pid=2318, ip=10.113.50.48)[0m  ==> File also in package provided by package maintainer.
[36m(setup pid=2318, ip=10.113.50.48)[0m    What would you like to do about it ?  Your options are:
[36m(setup pid=2318, ip=10.113.50.48)[0m     Y or I  : install the package maintainer's version
[36m(setup pid=2318, ip=10.113.50.48)[0m     N or O  : keep your currently-installed version
[36m(setup pid=2318, ip=10.113.50.48)[0m       D     : show the differences between the versions
[36m(setup pid=2318, ip=10.113.50.48)[0m       Z     : start a shell to examine the situation
[36m(setup pid=2318, ip=10.113.50.48)[0m  The default action is to keep your current version.
[36m(setup pid=2318, ip=10.113.50.48)[0m *** system.conf (Y/I/N/O/D/Z) [default=N] ? dpkg: error processing package systemd (--configure):
[36m(setup pid=2318, ip=10.113.50.48)[0m  end of file on stdin at conffile prompt
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=3097)[0m No schema files found: doing nothing.
[36m(setup pid=3097)[0m Setting up libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=3097)[0m Setting up libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3097)[0m Setting up libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=3097)[0m Setting up libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3097)[0m Setting up vim-common (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3097)[0m Setting up libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3097)[0m Setting up dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m dpkg: dependency problems prevent configuration of systemd-timesyncd:
[36m(setup pid=2318, ip=10.113.50.48)[0m  systemd-timesyncd depends on systemd (= 249.11-0ubuntu3.16); however:
[36m(setup pid=2318, ip=10.113.50.48)[0m   Package systemd is not configured yet.
[36m(setup pid=2318, ip=10.113.50.48)[0m 
[36m(setup pid=2318, ip=10.113.50.48)[0m dpkg: error processing package systemd-timesyncd (--configure):
[36m(setup pid=2318, ip=10.113.50.48)[0m  dependency problems - leaving unconfigured
[36m(setup pid=2318, ip=10.113.50.48)[0m Setting up networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=3097)[0m Setting up shared-mime-info (2.1-2) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Created symlink /etc/systemd/system/multi-user.target.wants/networkd-dispatcher.service → /lib/systemd/system/networkd-dispatcher.service.
[36m(setup pid=2318, ip=10.113.50.48)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2318, ip=10.113.50.48)[0m Errors were encountered while processing:
[36m(setup pid=2318, ip=10.113.50.48)[0m  systemd
[36m(setup pid=2318, ip=10.113.50.48)[0m  systemd-timesyncd
[36m(setup pid=2318, ip=10.113.50.48)[0m E: Sub-process /usr/bin/dpkg returned an error code (1)
[36m(setup pid=2318, ip=10.113.50.48)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2318, ip=10.113.50.48)[0m Resolved 3 packages in 45ms
[36m(setup pid=2318, ip=10.113.50.48)[0m Prepared 1 package in 9ms
[36m(setup pid=2318, ip=10.113.50.48)[0m Installed 2 packages in 16ms
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=2318, ip=10.113.50.48)[0m  + nvitop==1.5.2
[36m(setup pid=3097)[0m Setting up libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=3097)[0m Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3097)[0m Setting up libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3097)[0m Setting up libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3097)[0m Setting up dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3097)[0m Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=3097)[0m Setting up libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=3097)[0m Setting up vim-runtime (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3097)[0m Setting up libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=3097)[0m Setting up libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=3097)[0m Setting up sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=3097)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=3097)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=3097)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /lib/systemd/system/sysstat-collect.timer.
[36m(setup pid=3097)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /lib/systemd/system/sysstat-summary.timer.
[36m(setup pid=3097)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.
[36m(setup pid=3097)[0m Setting up python3-dbus (1.2.18-3build1) ...
[36m(setup pid=3097)[0m Setting up vim (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3097)[0m Setting up htop (3.0.5-7build2) ...
[36m(setup pid=3097)[0m Setting up gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=3097)[0m Setting up libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=3097)[0m Setting up libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3097)[0m Setting up iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=3097)[0m Setting up systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m Configuration file '/etc/systemd/system.conf'
[36m(setup pid=3097)[0m  ==> File on system created by you or by a script.
[36m(setup pid=3097)[0m  ==> File also in package provided by package maintainer.
[36m(setup pid=3097)[0m    What would you like to do about it ?  Your options are:
[36m(setup pid=3097)[0m     Y or I  : install the package maintainer's version
[36m(setup pid=3097)[0m     N or O  : keep your currently-installed version
[36m(setup pid=3097)[0m       D     : show the differences between the versions
[36m(setup pid=3097)[0m       Z     : start a shell to examine the situation
[36m(setup pid=3097)[0m  The default action is to keep your current version.
[36m(setup pid=3097)[0m *** system.conf (Y/I/N/O/D/Z) [default=N] ? dpkg: error processing package systemd (--configure):
[36m(setup pid=3097)[0m  end of file on stdin at conffile prompt
[36m(setup pid=3097)[0m Setting up python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=3097)[0m dpkg: dependency problems prevent configuration of systemd-timesyncd:
[36m(setup pid=3097)[0m  systemd-timesyncd depends on systemd (= 249.11-0ubuntu3.16); however:
[36m(setup pid=3097)[0m   Package systemd is not configured yet.
[36m(setup pid=3097)[0m 
[36m(setup pid=3097)[0m dpkg: error processing package systemd-timesyncd (--configure):
[36m(setup pid=3097)[0m  dependency problems - leaving unconfigured
[36m(setup pid=3097)[0m Setting up networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=3097)[0m Created symlink /etc/systemd/system/multi-user.target.wants/networkd-dispatcher.service → /lib/systemd/system/networkd-dispatcher.service.
[36m(setup pid=3097)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=3097)[0m Errors were encountered while processing:
[36m(setup pid=3097)[0m  systemd
[36m(setup pid=3097)[0m  systemd-timesyncd
[36m(setup pid=3097)[0m E: Sub-process /usr/bin/dpkg returned an error code (1)
[36m(setup pid=3097)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3097)[0m Resolved 3 packages in 43ms
[36m(setup pid=3097)[0m Prepared 1 package in 10ms
[36m(setup pid=3097)[0m Installed 2 packages in 17ms
[36m(setup pid=3097)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=3097)[0m  + nvitop==1.5.2
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3097)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Setting num_proc from 32 to 10 for the train split as it only contains 10 shards.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(head, rank=0, pid=3097)[0m Setting num_proc from 32 to 10 for the train split as it only contains 10 shards.
[36m(head, rank=0, pid=3097)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3097)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Generating train split:   2%|▏         | 1000/47780 [00:00<00:25, 1810.41 examples/s]
[36m(head, rank=0, pid=3097)[0m Generating train split:   2%|▏         | 1000/47780 [00:00<00:24, 1948.86 examples/s]
[36m(head, rank=0, pid=3097)[0m Generating train split:   8%|▊         | 4000/47780 [00:00<00:05, 8036.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Generating train split:  17%|█▋        | 8000/47780 [00:00<00:02, 15640.40 examples/s]
[36m(head, rank=0, pid=3097)[0m Generating train split:  23%|██▎       | 11000/47780 [00:00<00:01, 21989.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Generating train split:  25%|██▌       | 12000/47780 [00:00<00:01, 19960.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Generating train split:  42%|████▏     | 20000/47780 [00:00<00:00, 32591.07 examples/s]
[36m(head, rank=0, pid=3097)[0m Generating train split:  31%|███▏      | 15000/47780 [00:00<00:01, 24893.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Generating train split:  52%|█████▏    | 25000/47780 [00:01<00:00, 32346.78 examples/s]
[36m(head, rank=0, pid=3097)[0m Generating train split:  44%|████▍     | 21000/47780 [00:01<00:00, 29400.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Generating train split:  69%|██████▊   | 32778/47780 [00:01<00:00, 42179.58 examples/s]
[36m(head, rank=0, pid=3097)[0m Generating train split:  63%|██████▎   | 30000/47780 [00:01<00:00, 42385.47 examples/s]
[36m(head, rank=0, pid=3097)[0m Generating train split:  75%|███████▌  | 36000/47780 [00:01<00:00, 46281.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Generating train split:  89%|████████▊ | 42334/47780 [00:01<00:00, 55288.87 examples/s]
Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 34163.68 examples/s]
[36m(head, rank=0, pid=3097)[0m Generating train split:  98%|█████████▊| 47002/47780 [00:01<00:00, 61946.20 examples/s]
Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 33998.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3097)[0m 
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:  20%|██        | 1/5 [00:07<00:31,  7.78s/it]
Fetching 5 files:  20%|██        | 1/5 [00:07<00:31,  7.77s/it]
Fetching 5 files:  20%|██        | 1/5 [00:07<00:31,  7.79s/it]
Fetching 5 files:  20%|██        | 1/5 [00:07<00:30,  7.70s/it]
Fetching 5 files:  20%|██        | 1/5 [00:07<00:30,  7.71s/it]
Fetching 5 files:  20%|██        | 1/5 [00:07<00:31,  7.80s/it]
Fetching 5 files:  20%|██        | 1/5 [00:07<00:31,  7.82s/it]
[36m(head, rank=0, pid=3097)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:  20%|██        | 1/5 [00:14<00:56, 14.07s/it]
Fetching 5 files:  20%|██        | 1/5 [00:14<00:56, 14.03s/it]
Fetching 5 files:  20%|██        | 1/5 [00:14<00:56, 14.07s/it]
Fetching 5 files:  20%|██        | 1/5 [00:14<00:56, 14.09s/it]
Fetching 5 files:  20%|██        | 1/5 [00:14<00:56, 14.05s/it]
Fetching 5 files:  20%|██        | 1/5 [00:14<00:56, 14.06s/it]
Fetching 5 files:  20%|██        | 1/5 [00:14<00:56, 14.07s/it]
[36m(head, rank=0, pid=3097)[0m Fetching 5 files:  20%|██        | 1/5 [00:14<00:56, 14.11s/it]
Fetching 5 files:  40%|████      | 2/5 [00:14<00:17,  5.91s/it]
Fetching 5 files:  40%|████      | 2/5 [00:14<00:17,  5.89s/it]
Fetching 5 files:  40%|████      | 2/5 [00:14<00:17,  5.91s/it]
Fetching 5 files:  40%|████      | 2/5 [00:14<00:17,  5.91s/it]
Fetching 5 files:  40%|████      | 2/5 [00:14<00:17,  5.90s/it]
Fetching 5 files:  40%|████      | 2/5 [00:14<00:17,  5.92s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  2.86s/it]
[36m(head, rank=0, pid=3097)[0m 
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  2.85s/it]
[36m(head, rank=0, pid=3097)[0m 
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  2.85s/it]
[36m(head, rank=0, pid=3097)[0m 
Fetching 5 files:  40%|████      | 2/5 [00:14<00:17,  5.91s/it]
Fetching 5 files:  40%|████      | 2/5 [00:14<00:17,  5.92s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  2.86s/it]
[36m(head, rank=0, pid=3097)[0m 
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  2.86s/it]
[36m(head, rank=0, pid=3097)[0m 
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  2.87s/it]
[36m(head, rank=0, pid=3097)[0m 
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  2.87s/it]
[36m(head, rank=0, pid=3097)[0m 
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  2.86s/it]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Fetching 5 files:  20%|██        | 1/5 [00:07<00:31,  7.82s/it]
[36m(head, rank=0, pid=3097)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 144.01it/s]
[36m(head, rank=0, pid=3097)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 144.46it/s]
[36m(head, rank=0, pid=3097)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 148.54it/s]
[36m(head, rank=0, pid=3097)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 138.59it/s]
[36m(head, rank=0, pid=3097)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 131.78it/s]
[36m(head, rank=0, pid=3097)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 126.23it/s]
[36m(head, rank=0, pid=3097)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 132.56it/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Fetching 5 files:  60%|██████    | 3/5 [00:15<00:09,  4.75s/it]
Fetching 5 files:  60%|██████    | 3/5 [00:15<00:09,  4.75s/it]
Fetching 5 files:  60%|██████    | 3/5 [00:15<00:09,  4.75s/it]
Fetching 5 files:  60%|██████    | 3/5 [00:15<00:09,  4.76s/it]
Fetching 5 files:  60%|██████    | 3/5 [00:15<00:09,  4.76s/it]
Fetching 5 files:  60%|██████    | 3/5 [00:15<00:09,  4.74s/it]
Fetching 5 files:  60%|██████    | 3/5 [00:15<00:09,  4.74s/it]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Fetching 5 files:  60%|██████    | 3/5 [00:15<00:09,  4.78s/it]
Fetching 5 files:  80%|████████  | 4/5 [00:15<00:03,  3.15s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:15<00:00,  3.06s/it]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Fetching 5 files:  80%|████████  | 4/5 [00:15<00:03,  3.15s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:15<00:00,  3.06s/it]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Fetching 5 files:  80%|████████  | 4/5 [00:15<00:03,  3.13s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:15<00:00,  3.04s/it]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Fetching 5 files:  80%|████████  | 4/5 [00:15<00:03,  3.15s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:15<00:00,  3.06s/it]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Fetching 5 files:  80%|████████  | 4/5 [00:15<00:03,  3.14s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:15<00:00,  3.04s/it]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Fetching 5 files:  80%|████████  | 4/5 [00:15<00:03,  3.16s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:15<00:00,  3.06s/it]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Fetching 5 files: 100%|██████████| 5/5 [00:15<00:00,  3.06s/it]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Fetching 5 files:  80%|████████  | 4/5 [00:15<00:03,  3.16s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:15<00:00,  3.07s/it]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 150.89it/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 146.39it/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 145.62it/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 160.91it/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 146.96it/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 146.59it/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 150.41it/s]
[36m(head, rank=0, pid=3097)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(head, rank=0, pid=3097)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:16,  4.10s/it]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:16,  4.07s/it]
[36m(head, rank=0, pid=3097)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:07<00:11,  3.94s/it]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:07<00:11,  3.88s/it]
[36m(head, rank=0, pid=3097)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:11<00:07,  3.87s/it]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:11<00:07,  3.81s/it]
[36m(head, rank=0, pid=3097)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:15<00:03,  3.82s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.76s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.82s/it]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:15<00:03,  3.78s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.70s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.77s/it]
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   0%|          | 7/47780 [00:10<19:57:07,  1.50s/ examples]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   0%|          | 27/47780 [00:10<4:04:24,  3.26 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   0%|          | 41/47780 [00:11<2:22:40,  5.58 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   0%|          | 75/47780 [00:11<59:58, 13.26 examples/s]  
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   0%|          | 133/47780 [00:11<26:32, 29.92 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   0%|          | 208/47780 [00:11<14:18, 55.40 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   1%|          | 269/47780 [00:12<10:20, 76.55 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   1%|          | 353/47780 [00:12<07:09, 110.47 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   1%|          | 444/47780 [00:12<05:30, 143.26 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 609/47780 [00:13<03:27, 227.63 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 762/47780 [00:13<02:41, 290.68 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 907/47780 [00:13<02:18, 337.79 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1048/47780 [00:14<02:07, 367.96 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1184/47780 [00:14<02:01, 382.36 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1373/47780 [00:14<01:43, 448.79 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1572/47780 [00:15<01:31, 504.46 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1777/47780 [00:15<01:24, 547.37 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1976/47780 [00:15<01:19, 574.32 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2210/47780 [00:16<01:14, 613.51 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2431/47780 [00:16<01:14, 609.37 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2722/47780 [00:16<01:04, 697.58 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2980/47780 [00:17<01:01, 729.45 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3231/47780 [00:17<01:00, 735.01 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3501/47780 [00:17<00:57, 764.20 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3777/47780 [00:18<00:56, 780.87 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4103/47780 [00:18<00:53, 819.50 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4440/47780 [00:18<00:49, 876.68 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4839/47780 [00:18<00:35, 1223.61 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5021/47780 [00:19<00:36, 1180.23 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5177/47780 [00:19<00:36, 1157.09 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5318/47780 [00:19<00:38, 1092.66 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5444/47780 [00:19<00:38, 1106.33 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5567/47780 [00:19<00:37, 1115.62 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5693/47780 [00:19<00:37, 1134.51 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5814/47780 [00:19<00:38, 1091.83 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5928/47780 [00:19<00:40, 1037.97 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6050/47780 [00:20<00:39, 1068.35 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6165/47780 [00:20<00:38, 1089.35 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6285/47780 [00:20<00:37, 1117.90 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6400/47780 [00:20<00:36, 1123.48 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6525/47780 [00:20<00:35, 1158.87 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6644/47780 [00:20<00:35, 1167.54 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6777/47780 [00:20<00:33, 1213.55 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6901/47780 [00:20<00:34, 1192.55 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7035/47780 [00:20<00:33, 1233.82 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7159/47780 [00:20<00:32, 1231.88 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7284/47780 [00:21<00:33, 1210.38 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7406/47780 [00:21<00:33, 1212.89 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7544/47780 [00:21<00:31, 1259.81 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7674/47780 [00:21<00:32, 1238.50 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7800/47780 [00:21<00:32, 1233.99 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7924/47780 [00:21<00:33, 1176.42 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8045/47780 [00:21<00:33, 1171.45 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8181/47780 [00:21<00:32, 1220.71 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8305/47780 [00:21<00:33, 1194.56 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8425/47780 [00:21<00:34, 1156.20 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8543/47780 [00:22<00:35, 1105.68 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8655/47780 [00:22<00:35, 1104.32 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8782/47780 [00:22<00:33, 1150.52 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8902/47780 [00:22<00:33, 1148.75 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9033/47780 [00:22<00:33, 1170.23 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9153/47780 [00:22<00:32, 1173.15 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9286/47780 [00:22<00:31, 1212.06 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9419/47780 [00:22<00:31, 1227.10 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9550/47780 [00:22<00:31, 1223.27 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9674/47780 [00:23<00:32, 1184.37 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9793/47780 [00:23<00:32, 1175.92 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9912/47780 [00:23<00:33, 1131.93 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10034/47780 [00:23<00:32, 1145.39 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10149/47780 [00:23<00:33, 1130.28 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10263/47780 [00:23<00:34, 1090.17 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10374/47780 [00:23<00:34, 1092.68 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10492/47780 [00:23<00:33, 1112.26 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10608/47780 [00:23<00:33, 1123.54 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10724/47780 [00:24<00:33, 1101.76 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10843/47780 [00:24<00:32, 1126.73 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10960/47780 [00:24<00:32, 1138.11 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11076/47780 [00:24<00:33, 1102.78 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11203/47780 [00:24<00:32, 1130.50 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11322/47780 [00:24<00:31, 1147.08 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11444/47780 [00:24<00:31, 1167.05 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11570/47780 [00:24<00:30, 1190.63 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11691/47780 [00:24<00:31, 1130.70 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11827/47780 [00:24<00:30, 1190.06 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 11948/47780 [00:25<00:30, 1157.60 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12066/47780 [00:25<00:31, 1133.77 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12181/47780 [00:25<00:31, 1121.06 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12304/47780 [00:25<00:30, 1149.85 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12423/47780 [00:25<00:30, 1158.29 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12540/47780 [00:25<00:31, 1114.56 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12663/47780 [00:25<00:30, 1142.32 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12789/47780 [00:25<00:29, 1169.15 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12912/47780 [00:25<00:29, 1174.60 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13045/47780 [00:26<00:29, 1197.41 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13165/47780 [00:26<00:28, 1195.25 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13285/47780 [00:26<00:28, 1192.52 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13411/47780 [00:26<00:28, 1206.80 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13534/47780 [00:26<00:28, 1207.82 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13656/47780 [00:26<00:29, 1173.37 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13789/47780 [00:26<00:27, 1217.33 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13913/47780 [00:26<00:29, 1147.85 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14029/47780 [00:26<00:29, 1146.71 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14145/47780 [00:26<00:29, 1126.09 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14286/47780 [00:27<00:28, 1191.90 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14409/47780 [00:27<00:28, 1181.16 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14529/47780 [00:27<00:28, 1180.16 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14654/47780 [00:27<00:28, 1169.91 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14774/47780 [00:27<00:28, 1145.11 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14890/47780 [00:27<00:29, 1124.00 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 15015/47780 [00:27<00:28, 1154.16 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15131/47780 [00:27<00:29, 1110.07 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15283/47780 [00:27<00:27, 1185.39 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15403/47780 [00:28<00:27, 1188.00 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15532/47780 [00:28<00:26, 1216.71 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15655/47780 [00:28<00:27, 1187.81 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15774/47780 [00:28<00:26, 1185.92 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15894/47780 [00:28<00:28, 1117.03 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16007/47780 [00:28<00:28, 1117.39 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16129/47780 [00:28<00:27, 1143.97 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16246/47780 [00:28<00:27, 1145.82 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16370/47780 [00:28<00:27, 1156.65 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16500/47780 [00:28<00:26, 1197.91 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16623/47780 [00:29<00:26, 1187.58 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16743/47780 [00:29<00:26, 1158.90 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16863/47780 [00:29<00:26, 1167.07 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17003/47780 [00:29<00:25, 1228.99 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17128/47780 [00:29<00:26, 1161.06 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17248/47780 [00:29<00:26, 1147.98 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17373/47780 [00:29<00:25, 1172.61 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17524/47780 [00:29<00:23, 1262.24 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17652/47780 [00:29<00:24, 1242.03 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17779/47780 [00:30<00:24, 1201.89 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17902/47780 [00:30<00:25, 1174.17 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18035/47780 [00:30<00:24, 1197.17 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18167/47780 [00:30<00:24, 1217.58 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18290/47780 [00:30<00:25, 1140.67 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18411/47780 [00:30<00:25, 1149.92 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18529/47780 [00:30<00:25, 1140.33 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18651/47780 [00:30<00:25, 1129.97 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18765/47780 [00:30<00:25, 1127.14 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18879/47780 [00:30<00:25, 1128.79 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19007/47780 [00:31<00:24, 1168.48 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19126/47780 [00:31<00:25, 1141.70 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19245/47780 [00:31<00:25, 1140.85 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19370/47780 [00:31<00:24, 1160.75 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19487/47780 [00:31<00:24, 1146.07 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19619/47780 [00:31<00:23, 1183.90 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19738/47780 [00:31<00:24, 1163.27 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19866/47780 [00:31<00:23, 1196.65 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19986/47780 [00:31<00:23, 1184.89 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20109/47780 [00:32<00:23, 1192.23 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20230/47780 [00:32<00:23, 1195.51 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20350/47780 [00:32<00:23, 1182.26 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20472/47780 [00:32<00:23, 1181.88 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20592/47780 [00:32<00:23, 1164.47 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20711/47780 [00:32<00:23, 1129.10 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20848/47780 [00:32<00:22, 1188.66 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20969/47780 [00:32<00:23, 1134.31 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21093/47780 [00:32<00:22, 1163.93 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21213/47780 [00:32<00:23, 1139.50 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21341/47780 [00:33<00:22, 1169.94 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21464/47780 [00:33<00:22, 1178.19 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21584/47780 [00:33<00:22, 1152.18 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21700/47780 [00:33<00:22, 1147.77 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21820/47780 [00:33<00:22, 1150.02 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21949/47780 [00:33<00:21, 1181.27 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22091/47780 [00:33<00:20, 1246.07 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22224/47780 [00:33<00:20, 1238.63 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22354/47780 [00:33<00:20, 1252.51 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22481/47780 [00:34<00:20, 1215.27 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22603/47780 [00:34<00:20, 1199.85 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22726/47780 [00:34<00:20, 1208.08 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22847/47780 [00:34<00:21, 1170.30 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22967/47780 [00:34<00:21, 1175.33 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23111/47780 [00:34<00:19, 1234.44 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23241/47780 [00:34<00:19, 1252.94 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23370/47780 [00:34<00:20, 1208.02 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23493/47780 [00:34<00:20, 1166.29 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23611/47780 [00:34<00:20, 1165.17 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23737/47780 [00:35<00:20, 1191.70 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23867/47780 [00:35<00:19, 1221.49 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23991/47780 [00:35<00:19, 1221.27 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24115/47780 [00:35<00:19, 1186.06 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24236/47780 [00:35<00:20, 1127.01 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24350/47780 [00:35<00:21, 1076.13 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24467/47780 [00:35<00:21, 1101.27 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24601/47780 [00:35<00:19, 1165.72 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24729/47780 [00:35<00:19, 1193.01 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24854/47780 [00:36<00:19, 1193.88 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24974/47780 [00:36<00:19, 1156.00 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25092/47780 [00:36<00:20, 1116.46 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25206/47780 [00:36<00:21, 1074.13 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25317/47780 [00:36<00:20, 1080.52 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25426/47780 [00:36<00:21, 1056.27 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25534/47780 [00:36<00:21, 1021.54 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25637/47780 [00:36<00:21, 1008.37 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25750/47780 [00:36<00:21, 1039.04 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25855/47780 [00:37<00:21, 1039.90 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25962/47780 [00:37<00:21, 1023.99 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26069/47780 [00:37<00:20, 1034.49 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26175/47780 [00:37<00:20, 1030.51 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26280/47780 [00:37<00:21, 1011.41 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26397/47780 [00:37<00:20, 1054.47 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26523/47780 [00:37<00:19, 1090.31 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26634/47780 [00:37<00:19, 1064.04 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26755/47780 [00:37<00:19, 1097.90 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26866/47780 [00:37<00:20, 1039.07 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26978/47780 [00:38<00:19, 1044.96 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27094/47780 [00:38<00:19, 1070.55 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27212/47780 [00:38<00:18, 1098.39 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27353/47780 [00:38<00:17, 1172.95 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27476/47780 [00:38<00:17, 1187.60 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27600/47780 [00:38<00:16, 1199.14 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27729/47780 [00:38<00:16, 1216.60 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27855/47780 [00:38<00:16, 1219.56 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27980/47780 [00:38<00:16, 1186.17 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28100/47780 [00:39<00:17, 1118.37 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28213/47780 [00:39<00:19, 1029.79 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28319/47780 [00:39<00:19, 995.11 examples/s] 
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28438/47780 [00:39<00:18, 1039.79 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28544/47780 [00:39<00:19, 970.52 examples/s] 
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28648/47780 [00:39<00:19, 986.45 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28748/47780 [00:39<00:19, 985.01 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28850/47780 [00:39<00:19, 962.68 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28947/47780 [00:39<00:19, 963.12 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29051/47780 [00:40<00:19, 971.89 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29164/47780 [00:40<00:18, 1017.03 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29267/47780 [00:40<00:18, 996.78 examples/s] 
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29369/47780 [00:40<00:18, 980.50 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29471/47780 [00:40<00:19, 961.57 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29568/47780 [00:40<00:19, 935.22 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29675/47780 [00:40<00:18, 972.37 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29775/47780 [00:40<00:18, 971.24 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29888/47780 [00:40<00:17, 1005.97 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29991/47780 [00:40<00:17, 1008.51 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30100/47780 [00:41<00:17, 1030.02 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30226/47780 [00:41<00:16, 1096.71 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30349/47780 [00:41<00:15, 1133.02 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30479/47780 [00:41<00:14, 1163.19 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30608/47780 [00:41<00:14, 1197.32 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30728/47780 [00:41<00:15, 1091.64 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30854/47780 [00:41<00:14, 1131.03 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30970/47780 [00:41<00:15, 1080.38 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31093/47780 [00:41<00:14, 1118.73 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31212/47780 [00:42<00:14, 1138.82 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31328/47780 [00:42<00:14, 1105.07 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31441/47780 [00:42<00:14, 1099.77 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31560/47780 [00:42<00:14, 1122.92 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31678/47780 [00:42<00:14, 1139.04 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31800/47780 [00:42<00:13, 1158.10 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31920/47780 [00:42<00:14, 1115.60 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32033/47780 [00:42<00:14, 1114.77 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32145/47780 [00:42<00:14, 1048.55 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32255/47780 [00:43<00:14, 1055.54 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32363/47780 [00:43<00:14, 1040.61 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32468/47780 [00:43<00:14, 1032.76 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32585/47780 [00:43<00:14, 1062.93 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32698/47780 [00:43<00:14, 1074.14 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32807/47780 [00:43<00:13, 1072.63 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32936/47780 [00:43<00:13, 1132.29 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33050/47780 [00:43<00:13, 1096.76 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33162/47780 [00:43<00:13, 1061.37 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33274/47780 [00:43<00:14, 1020.54 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33380/47780 [00:44<00:14, 994.82 examples/s] 
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33483/47780 [00:44<00:14, 1002.06 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33587/47780 [00:44<00:14, 1008.56 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33692/47780 [00:44<00:14, 1002.48 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33797/47780 [00:44<00:13, 1011.97 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33900/47780 [00:44<00:14, 965.51 examples/s] 
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33999/47780 [00:44<00:14, 933.93 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34095/47780 [00:44<00:14, 918.85 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34190/47780 [00:44<00:14, 926.74 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34294/47780 [00:45<00:14, 939.79 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34390/47780 [00:45<00:14, 925.64 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34483/47780 [00:45<00:14, 907.16 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34575/47780 [00:45<00:14, 908.19 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34672/47780 [00:45<00:14, 923.24 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34766/47780 [00:45<00:14, 910.92 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34858/47780 [00:45<00:14, 911.28 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34951/47780 [00:45<00:14, 860.85 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35045/47780 [00:45<00:14, 880.22 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35137/47780 [00:46<00:14, 875.49 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35236/47780 [00:46<00:13, 906.10 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35330/47780 [00:46<00:13, 914.60 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35423/47780 [00:46<00:13, 885.20 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35513/47780 [00:46<00:14, 865.77 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35610/47780 [00:46<00:13, 881.11 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35705/47780 [00:46<00:13, 893.29 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35801/47780 [00:46<00:13, 911.55 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35896/47780 [00:46<00:12, 914.86 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36003/47780 [00:46<00:12, 959.00 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36117/47780 [00:47<00:11, 990.61 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36218/47780 [00:47<00:11, 991.82 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36320/47780 [00:47<00:11, 983.09 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36419/47780 [00:47<00:12, 944.24 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36525/47780 [00:47<00:11, 973.84 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36624/47780 [00:47<00:11, 957.97 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36728/47780 [00:47<00:11, 970.50 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36827/47780 [00:47<00:11, 967.25 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36940/47780 [00:47<00:10, 1014.14 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37059/47780 [00:47<00:10, 1060.40 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37179/47780 [00:48<00:09, 1096.31 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37290/47780 [00:48<00:09, 1078.56 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37405/47780 [00:48<00:09, 1076.41 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37543/47780 [00:48<00:08, 1163.69 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37664/47780 [00:48<00:08, 1172.62 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37782/47780 [00:48<00:08, 1138.16 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37914/47780 [00:48<00:08, 1186.04 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38051/47780 [00:48<00:07, 1232.92 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38176/47780 [00:48<00:08, 1199.07 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38297/47780 [00:49<00:08, 1162.70 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38414/47780 [00:49<00:08, 1099.23 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38534/47780 [00:49<00:08, 1126.92 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38649/47780 [00:49<00:08, 1100.00 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38761/47780 [00:49<00:08, 1101.80 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38876/47780 [00:49<00:08, 1110.60 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38995/47780 [00:49<00:07, 1122.11 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39109/47780 [00:49<00:07, 1100.31 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39225/47780 [00:49<00:07, 1113.36 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39337/47780 [00:50<00:07, 1067.42 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39446/47780 [00:50<00:08, 1001.18 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39549/47780 [00:50<00:08, 966.38 examples/s] 
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39647/47780 [00:50<00:08, 962.76 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39761/47780 [00:50<00:08, 996.41 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39870/47780 [00:50<00:07, 1022.39 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39974/47780 [00:50<00:07, 1010.81 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40077/47780 [00:50<00:07, 975.24 examples/s] 
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40194/47780 [00:50<00:07, 1024.11 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40299/47780 [00:50<00:07, 1024.50 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40406/47780 [00:51<00:07, 1015.67 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40508/47780 [00:51<00:07, 1014.07 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40611/47780 [00:51<00:07, 993.78 examples/s] 
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40740/47780 [00:51<00:06, 1070.28 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40881/47780 [00:51<00:05, 1165.26 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40999/47780 [00:51<00:05, 1139.49 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41114/47780 [00:51<00:06, 1084.72 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41241/47780 [00:51<00:05, 1136.50 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41357/47780 [00:51<00:05, 1115.39 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41486/47780 [00:52<00:05, 1153.10 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41605/47780 [00:52<00:05, 1156.56 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41723/47780 [00:52<00:05, 1132.68 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41846/47780 [00:52<00:05, 1141.31 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41969/47780 [00:52<00:05, 1147.98 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42095/47780 [00:52<00:04, 1174.10 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42214/47780 [00:52<00:05, 1102.51 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42338/47780 [00:52<00:04, 1140.34 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42455/47780 [00:52<00:04, 1130.51 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42569/47780 [00:53<00:04, 1067.46 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42677/47780 [00:53<00:04, 1037.50 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42783/47780 [00:53<00:05, 977.67 examples/s] 
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42902/47780 [00:53<00:04, 1032.74 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43011/47780 [00:53<00:04, 1025.21 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43117/47780 [00:53<00:04, 983.92 examples/s] 
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43217/47780 [00:53<00:04, 967.61 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43316/47780 [00:53<00:04, 927.37 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43412/47780 [00:53<00:04, 925.92 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43505/47780 [00:54<00:04, 921.95 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43599/47780 [00:54<00:04, 886.87 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43691/47780 [00:54<00:04, 886.51 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43780/47780 [00:54<00:04, 873.89 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43872/47780 [00:54<00:04, 876.05 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43961/47780 [00:54<00:04, 878.00 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44052/47780 [00:54<00:04, 870.83 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44142/47780 [00:54<00:04, 854.39 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44230/47780 [00:54<00:04, 860.02 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44330/47780 [00:54<00:03, 887.02 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44420/47780 [00:55<00:03, 865.34 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44507/47780 [00:55<00:03, 846.12 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44592/47780 [00:55<00:03, 821.98 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44676/47780 [00:55<00:03, 785.10 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44763/47780 [00:55<00:03, 793.58 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44853/47780 [00:55<00:03, 822.85 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44947/47780 [00:55<00:03, 855.59 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45034/47780 [00:55<00:03, 815.29 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45121/47780 [00:55<00:03, 820.10 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45204/47780 [00:56<00:03, 803.99 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45287/47780 [00:56<00:03, 791.07 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45367/47780 [00:56<00:03, 750.12 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45444/47780 [00:56<00:03, 700.02 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45518/47780 [00:56<00:03, 705.03 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45590/47780 [00:56<00:03, 687.01 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45660/47780 [00:56<00:03, 656.22 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45739/47780 [00:56<00:02, 690.24 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45811/47780 [00:56<00:03, 647.51 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45880/47780 [00:57<00:02, 635.54 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45946/47780 [00:57<00:02, 628.51 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46015/47780 [00:57<00:02, 609.48 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46077/47780 [00:57<00:02, 602.30 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46138/47780 [00:57<00:02, 555.51 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46198/47780 [00:57<00:02, 566.08 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46257/47780 [00:57<00:02, 554.03 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46313/47780 [00:57<00:02, 534.93 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46368/47780 [00:58<00:02, 519.01 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46425/47780 [00:58<00:02, 528.53 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46479/47780 [00:58<00:02, 526.10 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46532/47780 [00:58<00:02, 508.47 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46584/47780 [00:58<00:02, 495.56 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46634/47780 [00:58<00:02, 464.31 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46683/47780 [00:58<00:02, 468.93 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46741/47780 [00:58<00:02, 494.56 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46791/47780 [00:58<00:01, 494.83 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46843/47780 [00:58<00:01, 476.14 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46892/47780 [00:59<00:01, 461.16 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46951/47780 [00:59<00:01, 484.31 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47000/47780 [00:59<00:01, 456.86 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47047/47780 [00:59<00:01, 456.81 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47097/47780 [00:59<00:01, 459.07 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47144/47780 [00:59<00:01, 432.94 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47190/47780 [00:59<00:01, 439.21 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47236/47780 [00:59<00:01, 423.61 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47281/47780 [01:00<00:01, 404.16 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47323/47780 [01:00<00:01, 373.81 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47367/47780 [01:00<00:01, 374.82 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47412/47780 [01:00<00:00, 391.30 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47453/47780 [01:00<00:00, 356.38 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47493/47780 [01:00<00:00, 302.51 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47528/47780 [01:00<00:00, 302.51 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47561/47780 [01:00<00:00, 260.43 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47590/47780 [01:01<00:00, 213.09 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47615/47780 [01:01<00:01, 144.62 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47634/47780 [01:01<00:01, 118.49 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47650/47780 [01:02<00:01, 107.56 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47664/47780 [01:02<00:01, 97.04 examples/s] 
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47677/47780 [01:02<00:01, 96.59 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47690/47780 [01:02<00:00, 91.28 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47705/47780 [01:02<00:00, 99.01 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47716/47780 [01:02<00:00, 95.02 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47730/47780 [01:02<00:00, 96.32 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47740/47780 [01:03<00:00, 73.61 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47750/47780 [01:03<00:00, 53.26 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47757/47780 [01:03<00:00, 47.57 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47765/47780 [01:03<00:00, 51.11 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47772/47780 [01:04<00:00, 46.86 examples/s]
[36m(head, rank=0, pid=3097)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [01:04<00:00, 43.16 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [01:06<00:00, 715.82 examples/s]
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3097)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:09<07:13, 108.02 examples/s]
[36m(head, rank=0, pid=3097)[0m Truncating train dataset (num_proc=32):  18%|█▊        | 8494/47780 [00:09<00:31, 1240.99 examples/s]
[36m(head, rank=0, pid=3097)[0m Truncating train dataset (num_proc=32):  41%|████      | 19455/47780 [00:09<00:08, 3535.07 examples/s]
[36m(head, rank=0, pid=3097)[0m Truncating train dataset (num_proc=32):  85%|████████▍ | 40385/47780 [00:09<00:00, 9560.13 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:15<00:00, 3081.28 examples/s]
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:33,346] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3097)[0m df: /root/.triton/autotune: No such file or directory
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3097)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:33,944] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:33,969] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:34,005] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:34,005] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:34,010] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:34,049] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:34,054] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:35,493] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:35,493] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:35,494] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:35,494] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:35,494] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:35,494] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:35,494] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3097)[0m [2025-08-02 00:43:35,494] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:01<4:11:31,  3.17 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<4:48:41,  2.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<4:42:46,  2.82 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<4:51:58,  2.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 16/47780 [00:02<1:36:54,  8.22 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:18:22,  2.50 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 34/47780 [00:02<45:38, 17.44 examples/s] 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:21:09,  2.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 18/47780 [00:02<1:31:23,  8.71 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 16/47780 [00:02<1:46:23,  7.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 46/47780 [00:02<31:26, 25.31 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 62/47780 [00:02<25:32, 31.13 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 19/47780 [00:02<1:38:06,  8.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 19/47780 [00:02<1:38:55,  8.05 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 41/47780 [00:02<38:51, 20.48 examples/s]  
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 40/47780 [00:02<39:54, 19.94 examples/s]  
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 85/47780 [00:03<17:35, 45.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 108/47780 [00:03<14:41, 54.08 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 40/47780 [00:03<45:12, 17.60 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:03<7:12:02,  1.84 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 73/47780 [00:03<22:09, 35.88 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 58/47780 [00:03<30:13, 26.32 examples/s]  
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 73/47780 [00:03<21:58, 36.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 161/47780 [00:03<09:27, 83.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 181/47780 [00:03<08:37, 92.02 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 76/47780 [00:03<22:32, 35.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 28/47780 [00:03<1:21:16,  9.79 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 127/47780 [00:03<12:33, 63.20 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 101/47780 [00:03<17:48, 44.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 126/47780 [00:03<13:25, 59.13 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 226/47780 [00:03<07:33, 104.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|          | 255/47780 [00:03<06:38, 119.25 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 143/47780 [00:03<11:27, 69.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 191/47780 [00:04<08:43, 90.88 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 182/47780 [00:04<09:30, 83.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 217/47780 [00:04<07:45, 102.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 60/47780 [00:04<38:17, 20.77 examples/s]  
Tokenizing train dataset (num_proc=32):   1%|          | 353/47780 [00:04<05:29, 144.09 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 208/47780 [00:04<08:24, 94.30 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|          | 320/47780 [00:04<06:21, 124.24 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 249/47780 [00:04<08:16, 95.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 233/47780 [00:04<09:19, 84.91 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 294/47780 [00:04<07:08, 110.92 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 110/47780 [00:04<21:20, 37.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|          | 483/47780 [00:04<04:17, 183.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|          | 275/47780 [00:04<07:37, 103.84 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 440/47780 [00:05<05:17, 149.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|          | 384/47780 [00:05<04:58, 158.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|          | 330/47780 [00:05<07:06, 111.13 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 434/47780 [00:05<05:14, 150.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 670/47780 [00:05<03:14, 242.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 195/47780 [00:05<12:10, 65.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|          | 473/47780 [00:05<04:29, 175.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|          | 387/47780 [00:05<05:57, 132.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 629/47780 [00:05<03:50, 204.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 598/47780 [00:05<03:44, 210.53 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 443/47780 [00:05<05:48, 135.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 598/47780 [00:05<03:48, 206.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 848/47780 [00:05<02:52, 272.36 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 302/47780 [00:06<08:13, 96.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|          | 522/47780 [00:06<04:28, 175.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 824/47780 [00:06<03:13, 243.22 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 717/47780 [00:06<03:28, 226.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 603/47780 [00:06<04:03, 194.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1016/47780 [00:06<02:37, 297.52 examples/s]
Tokenizing train dataset (num_proc=32):   1%|▏         | 687/47780 [00:06<03:30, 223.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 723/47780 [00:06<03:48, 206.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|          | 417/47780 [00:06<06:27, 122.19 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1023/47780 [00:06<02:55, 266.88 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 834/47780 [00:06<03:40, 212.62 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 728/47780 [00:06<03:57, 197.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1174/47780 [00:07<02:38, 294.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 899/47780 [00:07<03:09, 247.78 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|          | 518/47780 [00:07<05:30, 143.08 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 840/47780 [00:07<03:48, 205.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1355/47780 [00:07<02:23, 323.07 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1158/47780 [00:07<03:07, 249.02 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 987/47780 [00:07<03:32, 220.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 899/47780 [00:07<03:28, 224.57 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1062/47780 [00:07<03:08, 247.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 642/47780 [00:07<04:52, 160.99 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1500/47780 [00:08<02:36, 295.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1062/47780 [00:07<03:06, 250.40 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1368/47780 [00:08<02:51, 271.09 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1076/47780 [00:08<03:12, 242.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1151/47780 [00:08<03:20, 232.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1352/47780 [00:08<02:11, 352.70 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1216/47780 [00:08<03:08, 247.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 817/47780 [00:08<03:58, 197.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1703/47780 [00:08<02:28, 310.25 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1215/47780 [00:08<03:18, 234.81 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1549/47780 [00:08<02:50, 270.61 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1245/47780 [00:08<03:15, 237.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1428/47780 [00:08<02:53, 267.43 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▎         | 1751/47780 [00:09<02:01, 379.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1433/47780 [00:08<02:46, 277.91 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 961/47780 [00:09<03:51, 202.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1611/47780 [00:09<02:01, 379.44 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1116/47780 [00:09<02:42, 287.20 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1934/47780 [00:09<02:17, 333.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1419/47780 [00:09<02:59, 257.61 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1572/47780 [00:09<03:04, 250.20 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1511/47780 [00:09<02:45, 279.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1599/47780 [00:09<02:09, 356.73 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1792/47780 [00:09<01:57, 391.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1715/47780 [00:09<02:00, 382.56 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▎         | 1685/47780 [00:09<02:50, 270.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1827/47780 [00:09<02:59, 256.51 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2095/47780 [00:09<02:27, 309.95 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2053/47780 [00:09<01:56, 393.14 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1176/47780 [00:09<03:45, 206.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1260/47780 [00:09<03:04, 252.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1888/47780 [00:10<02:33, 298.68 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2067/47780 [00:10<01:48, 420.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1739/47780 [00:10<03:46, 203.28 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2254/47780 [00:10<02:35, 292.22 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2158/47780 [00:10<02:24, 315.32 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1673/47780 [00:10<03:20, 229.44 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1797/47780 [00:10<02:58, 257.71 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2285/47780 [00:10<01:57, 388.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1795/47780 [00:10<02:35, 295.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2074/47780 [00:10<01:49, 417.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1316/47780 [00:10<04:36, 168.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2415/47780 [00:11<02:40, 281.79 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2374/47780 [00:11<02:41, 281.60 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1916/47780 [00:11<02:58, 256.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1874/47780 [00:11<04:04, 187.88 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2552/47780 [00:11<01:50, 410.77 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2178/47780 [00:11<01:44, 435.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2212/47780 [00:11<01:57, 387.92 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2199/47780 [00:11<02:20, 323.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1550/47780 [00:11<03:41, 208.70 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2168/47780 [00:11<03:44, 203.30 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▎         | 1783/47780 [00:11<02:14, 342.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2530/47780 [00:11<03:14, 232.54 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2376/47780 [00:11<02:24, 315.14 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2337/47780 [00:11<02:19, 325.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2291/47780 [00:12<02:29, 303.92 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2653/47780 [00:12<02:56, 255.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2303/47780 [00:12<03:11, 238.02 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2874/47780 [00:12<01:50, 406.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2606/47780 [00:12<02:25, 310.43 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1879/47780 [00:12<03:34, 214.47 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2459/47780 [00:12<02:50, 266.08 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▋         | 2992/47780 [00:13<02:24, 310.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2807/47780 [00:13<03:07, 239.47 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2551/47780 [00:12<02:47, 269.24 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2102/47780 [00:12<02:15, 335.88 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2739/47780 [00:13<01:44, 432.70 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3215/47780 [00:13<01:42, 434.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2757/47780 [00:13<01:59, 376.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2614/47780 [00:13<03:03, 245.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 2990/47780 [00:13<01:42, 436.70 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2802/47780 [00:13<02:24, 310.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 2993/47780 [00:13<01:48, 411.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3347/47780 [00:13<02:11, 336.95 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3160/47780 [00:13<02:00, 371.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2855/47780 [00:13<02:39, 281.97 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▋         | 3104/47780 [00:14<03:36, 205.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 3102/47780 [00:14<01:45, 425.18 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2218/47780 [00:14<03:26, 220.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3480/47780 [00:14<01:45, 421.20 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2869/47780 [00:14<03:07, 239.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2416/47780 [00:14<02:20, 322.53 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3198/47780 [00:14<01:46, 416.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3573/47780 [00:14<02:05, 351.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 3088/47780 [00:14<02:56, 253.07 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3232/47780 [00:14<02:24, 307.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3630/47780 [00:14<02:12, 332.44 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3354/47780 [00:14<02:06, 351.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3371/47780 [00:15<01:56, 382.67 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3839/47780 [00:15<01:57, 372.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3506/47780 [00:15<01:42, 433.95 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3285/47780 [00:15<02:59, 247.78 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3908/47780 [00:15<01:52, 390.30 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3627/47780 [00:15<01:46, 413.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3200/47780 [00:15<03:26, 215.81 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3614/47780 [00:15<01:39, 444.46 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3764/47780 [00:15<02:33, 286.55 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2533/47780 [00:15<03:57, 190.20 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3950/47780 [00:15<01:52, 388.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2906/47780 [00:15<02:01, 370.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3975/47780 [00:16<02:47, 261.65 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4321/47780 [00:16<01:29, 484.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3789/47780 [00:16<02:17, 319.34 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3775/47780 [00:16<02:09, 339.24 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3479/47780 [00:16<03:41, 199.95 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3934/47780 [00:16<01:44, 419.70 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 1/47780 [00:16<218:58:14, 16.50s/ examples]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3640/47780 [00:16<02:39, 277.12 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 4061/47780 [00:16<02:49, 258.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3631/47780 [00:16<03:26, 213.51 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 4021/47780 [00:16<01:47, 406.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4600/47780 [00:16<01:38, 439.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3741/47780 [00:17<03:10, 231.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3959/47780 [00:17<02:00, 362.59 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▊         | 4159/47780 [00:17<01:26, 506.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4065/47780 [00:17<02:33, 283.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3909/47780 [00:17<03:25, 213.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 31/47780 [00:17<5:24:47,  2.45 examples/s] 
Tokenizing train dataset (num_proc=32):   9%|▉         | 4346/47780 [00:17<01:37, 444.61 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4201/47780 [00:17<02:08, 339.67 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 72/47780 [00:17<1:52:52,  7.04 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4738/47780 [00:17<02:11, 326.51 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▋         | 3070/47780 [00:17<03:39, 203.98 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4304/47780 [00:17<02:55, 247.32 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4974/47780 [00:17<01:33, 457.01 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3396/47780 [00:17<02:14, 329.13 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4528/47780 [00:17<02:01, 356.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5181/47780 [00:17<01:11, 593.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5453/47780 [00:18<00:51, 822.01 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4201/47780 [00:18<02:41, 269.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4577/47780 [00:18<01:37, 444.94 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4300/47780 [00:18<02:24, 301.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5639/47780 [00:18<01:09, 603.43 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4652/47780 [00:18<02:39, 270.52 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 98/47780 [00:18<1:23:51,  9.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4933/47780 [00:18<01:40, 425.84 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4488/47780 [00:18<02:41, 268.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   0%|          | 142/47780 [00:18<45:02, 17.63 examples/s] 
Tokenizing train dataset (num_proc=32):  10%|▉         | 4751/47780 [00:18<01:46, 404.38 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4344/47780 [00:18<03:09, 228.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5780/47780 [00:19<01:24, 499.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4697/47780 [00:19<01:51, 385.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5888/47780 [00:19<01:31, 457.52 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3564/47780 [00:19<03:17, 224.01 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 5974/47780 [00:19<01:28, 473.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3813/47780 [00:19<02:17, 319.16 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4777/47780 [00:19<02:23, 298.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6051/47780 [00:19<01:29, 468.32 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5073/47780 [00:19<01:39, 431.02 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6120/47780 [00:19<01:28, 470.58 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6182/47780 [00:19<01:30, 461.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5066/47780 [00:19<02:35, 274.44 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 167/47780 [00:19<42:24, 18.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5336/47780 [00:20<01:41, 418.14 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6238/47780 [00:20<01:36, 431.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6288/47780 [00:20<01:39, 415.95 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6334/47780 [00:20<01:44, 396.76 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4524/47780 [00:20<03:47, 189.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4871/47780 [00:20<02:47, 256.34 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6377/47780 [00:20<01:51, 369.86 examples/s]
Tokenizing train dataset (num_proc=32):  10%|█         | 4900/47780 [00:20<03:05, 230.81 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4714/47780 [00:20<02:44, 262.33 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5263/47780 [00:20<01:59, 355.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5196/47780 [00:20<01:47, 397.48 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6417/47780 [00:20<01:52, 366.94 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5317/47780 [00:20<01:40, 424.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5461/47780 [00:20<01:33, 450.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6462/47780 [00:20<01:48, 382.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6503/47780 [00:20<01:47, 384.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6544/47780 [00:21<01:53, 362.04 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6581/47780 [00:21<01:55, 356.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5479/47780 [00:21<02:29, 282.54 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3969/47780 [00:21<03:30, 207.87 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6630/47780 [00:21<01:47, 383.84 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5704/47780 [00:21<01:45, 399.64 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4254/47780 [00:21<02:17, 316.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6670/47780 [00:21<01:51, 368.40 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 220/47780 [00:21<31:58, 24.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6716/47780 [00:21<01:45, 388.48 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 308/47780 [00:21<15:52, 49.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6756/47780 [00:21<01:50, 371.38 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█▏        | 5382/47780 [00:21<02:18, 306.39 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6794/47780 [00:21<02:05, 326.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4955/47780 [00:21<03:00, 236.99 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5680/47780 [00:21<01:33, 448.54 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6837/47780 [00:21<01:56, 350.20 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5356/47780 [00:21<01:41, 416.75 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6876/47780 [00:21<01:53, 360.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5615/47780 [00:21<02:29, 282.21 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5690/47780 [00:21<01:10, 600.89 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6928/47780 [00:22<01:42, 400.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5932/47780 [00:21<01:34, 442.84 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6969/47780 [00:22<01:44, 389.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5517/47780 [00:22<02:34, 274.33 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7009/47780 [00:22<01:47, 380.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5859/47780 [00:22<01:40, 415.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7048/47780 [00:22<01:47, 378.30 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7087/47780 [00:22<01:47, 377.59 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5842/47780 [00:22<02:47, 249.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7131/47780 [00:22<01:45, 385.17 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6121/47780 [00:22<01:46, 391.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7184/47780 [00:22<01:35, 422.98 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4414/47780 [00:22<03:16, 220.78 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7227/47780 [00:22<01:36, 420.26 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4645/47780 [00:22<02:18, 310.92 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7270/47780 [00:22<01:39, 405.59 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6275/47780 [00:22<01:43, 399.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7311/47780 [00:23<01:45, 383.89 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6043/47780 [00:22<01:56, 358.81 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 341/47780 [00:22<20:41, 38.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7351/47780 [00:23<01:45, 384.03 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 498/47780 [00:23<08:37, 91.32 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5862/47780 [00:23<02:29, 281.31 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7390/47780 [00:23<02:04, 323.76 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6396/47780 [00:23<01:46, 389.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6011/47780 [00:23<02:02, 341.18 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6105/47780 [00:23<02:26, 284.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7425/47780 [00:23<02:07, 317.41 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6385/47780 [00:23<01:39, 414.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7458/47780 [00:23<02:12, 305.33 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6491/47780 [00:23<01:49, 377.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7490/47780 [00:23<02:10, 308.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7522/47780 [00:23<02:10, 308.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7554/47780 [00:23<02:09, 311.65 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6568/47780 [00:23<01:54, 358.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7586/47780 [00:23<02:09, 310.31 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6547/47780 [00:23<01:46, 387.33 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7630/47780 [00:24<01:56, 343.86 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5900/47780 [00:23<02:31, 275.78 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6631/47780 [00:24<01:56, 352.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7679/47780 [00:24<01:43, 385.87 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6313/47780 [00:24<01:33, 442.12 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6686/47780 [00:24<01:53, 362.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7720/47780 [00:24<01:45, 378.89 examples/s]
Tokenizing train dataset (num_proc=32):  10%|█         | 4793/47780 [00:24<03:21, 213.35 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6736/47780 [00:24<01:53, 360.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7772/47780 [00:24<01:35, 417.72 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6670/47780 [00:24<01:51, 369.09 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5023/47780 [00:24<02:20, 304.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7815/47780 [00:24<01:36, 413.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6782/47780 [00:24<01:58, 346.15 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6823/47780 [00:24<01:59, 343.15 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7857/47780 [00:24<01:53, 350.97 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6148/47780 [00:24<03:04, 225.10 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6766/47780 [00:24<01:52, 364.39 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7905/47780 [00:24<01:43, 384.07 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6862/47780 [00:24<02:05, 326.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6541/47780 [00:24<01:41, 407.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7946/47780 [00:24<01:51, 356.77 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6898/47780 [00:24<02:09, 315.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6844/47780 [00:24<01:54, 357.93 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7984/47780 [00:24<01:57, 337.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6937/47780 [00:24<02:03, 330.93 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6974/47780 [00:25<02:00, 338.03 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6908/47780 [00:25<01:57, 347.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8019/47780 [00:25<02:06, 315.19 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7011/47780 [00:25<02:00, 339.35 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8055/47780 [00:25<02:02, 323.33 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6962/47780 [00:25<01:57, 348.57 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7054/47780 [00:25<01:52, 362.78 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8090/47780 [00:25<02:00, 330.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7011/47780 [00:25<01:52, 361.66 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7102/47780 [00:25<01:44, 390.25 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8124/47780 [00:25<02:05, 315.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   1%|          | 564/47780 [00:25<13:28, 58.43 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7058/47780 [00:25<01:50, 367.29 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7142/47780 [00:25<01:46, 380.40 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8160/47780 [00:25<02:03, 321.16 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6180/47780 [00:25<03:59, 173.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 760/47780 [00:25<06:32, 119.71 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7103/47780 [00:25<01:48, 376.01 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5156/47780 [00:25<03:13, 220.14 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7184/47780 [00:25<01:46, 380.43 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6470/47780 [00:25<02:35, 265.85 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8198/47780 [00:25<01:59, 329.94 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5341/47780 [00:25<02:21, 299.42 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7223/47780 [00:25<01:48, 372.64 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6822/47780 [00:25<01:38, 415.63 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8233/47780 [00:25<01:59, 331.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7147/47780 [00:25<01:55, 352.55 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7261/47780 [00:25<01:56, 347.40 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8270/47780 [00:25<01:56, 338.59 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7036/47780 [00:25<01:19, 513.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7187/47780 [00:25<01:56, 347.60 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7304/47780 [00:25<01:50, 366.36 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8306/47780 [00:25<01:54, 344.65 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6540/47780 [00:25<02:30, 274.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7225/47780 [00:25<01:57, 344.92 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7346/47780 [00:26<01:46, 381.00 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6831/47780 [00:26<01:48, 378.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8341/47780 [00:26<02:01, 325.15 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7262/47780 [00:26<02:00, 335.82 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6727/47780 [00:26<02:29, 274.17 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7393/47780 [00:26<01:39, 404.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8377/47780 [00:26<02:03, 319.33 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7307/47780 [00:26<01:52, 360.53 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7063/47780 [00:26<01:35, 424.56 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7434/47780 [00:26<01:45, 381.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8417/47780 [00:26<01:57, 334.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7352/47780 [00:26<01:45, 383.46 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7237/47780 [00:26<01:24, 478.28 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7490/47780 [00:26<01:34, 426.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8459/47780 [00:26<01:51, 354.11 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7392/47780 [00:26<01:50, 364.05 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7535/47780 [00:26<01:36, 419.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8498/47780 [00:26<01:49, 360.18 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7430/47780 [00:26<01:50, 364.93 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7584/47780 [00:26<01:32, 433.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8544/47780 [00:26<01:42, 383.15 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7482/47780 [00:26<01:40, 402.60 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 849/47780 [00:26<07:17, 107.23 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7628/47780 [00:26<01:32, 435.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7259/47780 [00:26<01:36, 421.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8583/47780 [00:26<01:43, 377.79 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7525/47780 [00:26<01:40, 401.33 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7672/47780 [00:26<01:33, 431.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7390/47780 [00:26<01:31, 440.10 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7567/47780 [00:26<01:40, 401.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8621/47780 [00:26<01:53, 344.84 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7717/47780 [00:26<01:37, 408.90 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8657/47780 [00:26<01:52, 346.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7609/47780 [00:26<01:40, 397.90 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7650/47780 [00:27<01:44, 383.74 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7760/47780 [00:27<01:54, 348.98 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8693/47780 [00:27<02:03, 315.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5464/47780 [00:27<03:38, 193.74 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7507/47780 [00:27<01:35, 422.99 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7408/47780 [00:27<01:41, 396.64 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7690/47780 [00:27<01:44, 384.27 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7797/47780 [00:27<01:53, 353.73 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8726/47780 [00:27<02:06, 309.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5772/47780 [00:27<02:07, 330.37 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7729/47780 [00:27<01:45, 381.37 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8761/47780 [00:27<02:01, 320.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7834/47780 [00:27<02:03, 322.76 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7600/47780 [00:27<01:36, 417.14 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7768/47780 [00:27<01:50, 363.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8799/47780 [00:27<01:56, 334.68 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7869/47780 [00:27<02:07, 313.17 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7029/47780 [00:27<02:29, 271.92 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7805/47780 [00:27<01:51, 357.38 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8833/47780 [00:27<02:04, 313.73 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7902/47780 [00:27<02:08, 310.13 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7522/47780 [00:27<01:49, 368.08 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7381/47780 [00:27<01:38, 411.74 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7848/47780 [00:27<01:45, 377.58 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7677/47780 [00:27<01:40, 397.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8869/47780 [00:27<01:59, 326.25 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7934/47780 [00:27<02:14, 297.03 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 913/47780 [00:27<08:25, 92.63 examples/s] 
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7888/47780 [00:27<01:43, 383.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8905/47780 [00:27<01:55, 335.71 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1041/47780 [00:27<05:30, 141.30 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7965/47780 [00:27<02:20, 282.61 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7741/47780 [00:27<01:45, 380.46 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7931/47780 [00:27<01:42, 388.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8942/47780 [00:27<01:53, 341.58 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7610/47780 [00:27<01:55, 348.93 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8002/47780 [00:27<02:14, 296.10 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7970/47780 [00:27<01:44, 379.86 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8978/47780 [00:27<01:55, 335.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7795/47780 [00:27<01:44, 382.71 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8012/47780 [00:27<01:42, 387.21 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8038/47780 [00:28<02:11, 302.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9017/47780 [00:28<01:50, 350.61 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7845/47780 [00:28<01:46, 376.14 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7681/47780 [00:28<01:58, 337.82 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8084/47780 [00:28<01:57, 338.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8052/47780 [00:28<01:45, 377.51 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9053/47780 [00:28<01:54, 338.03 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7587/47780 [00:28<01:44, 385.95 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7891/47780 [00:28<01:49, 365.47 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8123/47780 [00:28<01:53, 348.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8090/47780 [00:28<01:47, 369.95 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9088/47780 [00:28<02:06, 306.57 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7739/47780 [00:28<02:00, 331.42 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7933/47780 [00:28<01:48, 366.73 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8131/47780 [00:28<01:45, 377.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8164/47780 [00:28<01:50, 358.01 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9129/47780 [00:28<01:56, 330.73 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1111/47780 [00:28<05:51, 132.90 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7974/47780 [00:28<01:46, 373.25 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8169/47780 [00:28<01:45, 373.97 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8202/47780 [00:28<01:51, 356.20 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7789/47780 [00:28<02:00, 331.90 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9166/47780 [00:28<01:53, 341.46 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8211/47780 [00:28<01:43, 382.64 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8253/47780 [00:28<01:40, 395.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8015/47780 [00:28<01:48, 365.46 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5921/47780 [00:28<03:06, 224.52 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7835/47780 [00:28<01:56, 342.67 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9204/47780 [00:28<01:50, 348.33 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7741/47780 [00:28<01:44, 382.02 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8255/47780 [00:28<01:39, 398.94 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8293/47780 [00:28<01:40, 391.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8057/47780 [00:28<01:45, 374.79 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6179/47780 [00:28<02:03, 337.35 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7879/47780 [00:28<01:54, 349.18 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9240/47780 [00:28<01:54, 336.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8296/47780 [00:28<01:39, 398.14 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8333/47780 [00:28<01:46, 369.08 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8096/47780 [00:28<01:53, 350.49 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7921/47780 [00:28<01:55, 346.40 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9286/47780 [00:28<01:43, 370.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8336/47780 [00:28<01:39, 397.07 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8372/47780 [00:28<01:46, 370.73 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8151/47780 [00:28<01:42, 388.48 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9335/47780 [00:28<01:35, 400.50 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8377/47780 [00:28<01:40, 393.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7961/47780 [00:28<02:02, 324.51 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8410/47780 [00:29<01:47, 365.03 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7860/47780 [00:28<01:48, 366.55 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9376/47780 [00:29<01:40, 382.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7997/47780 [00:29<02:01, 328.70 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8193/47780 [00:29<01:58, 335.03 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8417/47780 [00:29<01:46, 369.64 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8447/47780 [00:29<01:50, 354.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9415/47780 [00:29<01:40, 382.45 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8258/47780 [00:29<01:37, 405.31 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8033/47780 [00:29<02:05, 315.65 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8487/47780 [00:29<01:47, 367.22 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8455/47780 [00:29<01:51, 352.07 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1163/47780 [00:29<07:04, 109.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9454/47780 [00:29<01:44, 367.62 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8067/47780 [00:29<02:04, 318.91 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8524/47780 [00:29<01:52, 348.18 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7953/47780 [00:29<01:52, 355.52 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8491/47780 [00:29<01:57, 335.57 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8303/47780 [00:29<01:44, 377.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1240/47780 [00:29<05:19, 145.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9496/47780 [00:29<01:47, 355.64 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8100/47780 [00:29<02:04, 318.34 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8525/47780 [00:29<01:59, 329.62 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8561/47780 [00:29<01:58, 332.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8344/47780 [00:29<01:49, 361.46 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9532/47780 [00:29<01:51, 341.88 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8133/47780 [00:29<02:09, 305.56 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8559/47780 [00:29<02:04, 315.62 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8595/47780 [00:29<01:59, 326.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8382/47780 [00:29<01:52, 348.98 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9567/47780 [00:29<01:51, 342.86 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8027/47780 [00:29<01:58, 334.98 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8165/47780 [00:29<02:10, 304.21 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8593/47780 [00:29<02:01, 322.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8636/47780 [00:29<01:53, 346.10 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8418/47780 [00:29<02:02, 322.23 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9602/47780 [00:29<01:58, 322.49 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8205/47780 [00:29<02:01, 326.79 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8630/47780 [00:29<01:57, 331.92 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8671/47780 [00:29<01:56, 334.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8087/47780 [00:29<01:59, 332.39 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8458/47780 [00:29<01:57, 334.99 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9635/47780 [00:29<01:58, 322.98 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8245/47780 [00:29<01:54, 344.85 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8674/47780 [00:29<01:50, 354.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8709/47780 [00:29<01:56, 336.37 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8282/47780 [00:29<01:53, 348.16 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8493/47780 [00:29<02:04, 316.47 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9669/47780 [00:29<02:04, 307.18 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8719/47780 [00:29<01:43, 377.31 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8139/47780 [00:29<02:02, 323.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8743/47780 [00:30<01:57, 331.01 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8531/47780 [00:29<01:58, 332.46 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8318/47780 [00:29<01:54, 343.77 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9700/47780 [00:30<02:04, 306.76 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6330/47780 [00:30<03:03, 226.04 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8762/47780 [00:30<01:40, 387.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8184/47780 [00:30<01:58, 333.88 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8778/47780 [00:30<02:05, 311.78 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8579/47780 [00:30<01:46, 368.28 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6620/47780 [00:30<01:56, 353.90 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9734/47780 [00:30<02:01, 313.74 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8353/47780 [00:30<02:00, 326.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8801/47780 [00:30<01:46, 367.27 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8810/47780 [00:30<02:05, 310.70 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8227/47780 [00:30<02:00, 328.86 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9767/47780 [00:30<02:00, 314.83 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8386/47780 [00:30<02:04, 317.53 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8617/47780 [00:30<01:55, 338.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8838/47780 [00:30<01:50, 352.36 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8844/47780 [00:30<02:07, 305.24 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8267/47780 [00:30<01:58, 332.64 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9799/47780 [00:30<02:02, 308.82 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8666/47780 [00:30<01:43, 377.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8419/47780 [00:30<02:05, 314.84 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8874/47780 [00:30<01:58, 328.96 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8878/47780 [00:30<02:04, 311.40 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8307/47780 [00:30<01:55, 341.99 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9835/47780 [00:30<01:58, 320.17 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8713/47780 [00:30<01:36, 402.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8462/47780 [00:30<01:53, 346.07 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1289/47780 [00:30<08:08, 95.23 examples/s] 
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8912/47780 [00:30<02:03, 315.76 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8345/47780 [00:30<01:53, 346.94 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8908/47780 [00:30<02:07, 305.67 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8507/47780 [00:30<01:45, 371.53 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9868/47780 [00:30<02:05, 302.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1393/47780 [00:30<05:15, 146.80 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8951/47780 [00:30<01:56, 332.99 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8383/47780 [00:30<01:52, 351.28 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8755/47780 [00:30<01:59, 327.26 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8940/47780 [00:30<02:13, 291.08 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9901/47780 [00:30<02:03, 306.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8545/47780 [00:30<01:48, 361.52 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8985/47780 [00:30<01:55, 334.76 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8820/47780 [00:30<01:36, 405.58 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8428/47780 [00:30<01:48, 363.91 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8970/47780 [00:30<02:15, 286.97 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8582/47780 [00:30<01:47, 363.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9944/47780 [00:30<01:53, 333.61 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8467/47780 [00:30<01:46, 368.01 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9019/47780 [00:30<02:05, 307.99 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9003/47780 [00:30<02:13, 289.86 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8865/47780 [00:30<01:42, 378.18 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9979/47780 [00:30<01:52, 336.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8619/47780 [00:30<01:52, 348.40 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8508/47780 [00:30<01:43, 377.69 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9060/47780 [00:31<01:56, 332.49 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9039/47780 [00:30<02:05, 308.73 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10015/47780 [00:31<01:50, 341.21 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8907/47780 [00:30<01:41, 381.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8655/47780 [00:30<01:53, 344.44 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9096/47780 [00:31<01:53, 339.86 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8547/47780 [00:31<01:47, 365.81 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10055/47780 [00:31<01:45, 357.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9071/47780 [00:31<02:06, 304.81 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8690/47780 [00:31<02:00, 324.03 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8949/47780 [00:31<01:47, 360.40 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9131/47780 [00:31<01:54, 338.83 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8585/47780 [00:31<01:49, 358.14 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10091/47780 [00:31<01:47, 350.70 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9105/47780 [00:31<02:04, 311.31 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8723/47780 [00:31<02:01, 321.75 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8988/47780 [00:31<01:50, 350.32 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8646/47780 [00:31<01:32, 423.13 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9166/47780 [00:31<02:00, 319.87 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10134/47780 [00:31<01:41, 370.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9137/47780 [00:31<02:04, 310.02 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8759/47780 [00:31<01:59, 326.11 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9025/47780 [00:31<01:53, 341.23 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9201/47780 [00:31<01:59, 321.61 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10174/47780 [00:31<01:39, 377.84 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9172/47780 [00:31<02:00, 321.34 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8690/47780 [00:31<01:37, 402.76 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8792/47780 [00:31<02:08, 303.17 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9060/47780 [00:31<01:56, 332.55 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10213/47780 [00:31<01:39, 377.07 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9207/47780 [00:31<01:58, 326.41 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9234/47780 [00:31<02:03, 313.33 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8731/47780 [00:31<01:41, 386.27 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8827/47780 [00:31<02:04, 312.56 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9098/47780 [00:31<01:52, 342.56 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9249/47780 [00:31<01:49, 353.49 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10252/47780 [00:31<01:41, 371.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8771/47780 [00:31<01:40, 389.35 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9266/47780 [00:31<02:18, 278.01 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8859/47780 [00:31<02:06, 307.63 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9141/47780 [00:31<01:46, 362.41 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10295/47780 [00:31<01:37, 384.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9286/47780 [00:31<01:53, 338.57 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8811/47780 [00:31<01:46, 367.63 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9295/47780 [00:31<02:19, 275.36 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8894/47780 [00:31<02:03, 315.92 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9193/47780 [00:31<01:38, 393.09 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10334/47780 [00:31<01:43, 360.71 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9321/47780 [00:31<01:57, 326.82 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8850/47780 [00:31<01:50, 351.07 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9330/47780 [00:31<02:17, 280.43 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8933/47780 [00:31<01:57, 329.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9233/47780 [00:31<01:40, 382.29 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9359/47780 [00:31<01:54, 334.27 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10371/47780 [00:32<01:47, 347.77 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8886/47780 [00:31<01:52, 346.17 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9359/47780 [00:32<02:17, 279.99 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8967/47780 [00:31<02:01, 318.20 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9274/47780 [00:31<01:39, 385.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6784/47780 [00:31<03:21, 203.69 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9393/47780 [00:32<01:57, 328.09 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10410/47780 [00:32<01:45, 355.84 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8934/47780 [00:32<01:41, 382.58 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9390/47780 [00:32<02:14, 284.71 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9001/47780 [00:32<01:59, 323.94 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9313/47780 [00:32<01:40, 380.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7198/47780 [00:32<01:51, 363.99 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9432/47780 [00:32<01:53, 338.30 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10447/47780 [00:32<01:47, 347.71 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8974/47780 [00:32<01:40, 386.71 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9421/47780 [00:32<02:12, 288.79 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9036/47780 [00:32<01:58, 327.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9352/47780 [00:32<01:47, 356.75 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9466/47780 [00:32<01:54, 335.04 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10482/47780 [00:32<01:49, 341.13 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9456/47780 [00:32<02:05, 305.96 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9014/47780 [00:32<01:43, 373.79 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9069/47780 [00:32<02:03, 312.97 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9392/47780 [00:32<01:46, 359.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1449/47780 [00:32<09:36, 80.38 examples/s] 
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9508/47780 [00:32<01:46, 359.25 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10517/47780 [00:32<01:49, 339.45 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9491/47780 [00:32<02:01, 315.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9052/47780 [00:32<01:51, 348.51 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9429/47780 [00:32<01:47, 355.97 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9101/47780 [00:32<02:13, 289.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1749/47780 [00:32<03:37, 211.57 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9547/47780 [00:32<01:47, 355.25 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10560/47780 [00:32<01:41, 365.14 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9089/47780 [00:32<01:50, 350.55 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9523/47780 [00:32<02:10, 292.60 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9468/47780 [00:32<01:44, 365.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9136/47780 [00:32<02:06, 305.18 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9584/47780 [00:32<01:47, 356.15 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10597/47780 [00:32<01:46, 349.73 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9125/47780 [00:32<01:54, 337.59 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9515/47780 [00:32<01:37, 390.75 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9553/47780 [00:32<02:21, 270.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9168/47780 [00:32<02:06, 304.17 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9622/47780 [00:32<01:48, 350.73 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10633/47780 [00:32<01:46, 348.95 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9164/47780 [00:32<01:50, 348.78 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9591/47780 [00:32<02:08, 296.92 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9555/47780 [00:32<01:38, 388.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9208/47780 [00:32<01:58, 326.62 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9659/47780 [00:32<01:47, 353.36 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10669/47780 [00:32<01:47, 344.93 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9200/47780 [00:32<01:50, 347.67 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9623/47780 [00:32<02:05, 302.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9241/47780 [00:32<01:57, 327.19 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9695/47780 [00:32<01:47, 353.63 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9594/47780 [00:32<01:47, 356.66 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10704/47780 [00:32<01:55, 320.81 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9240/47780 [00:32<01:49, 353.33 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9274/47780 [00:32<01:58, 324.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9655/47780 [00:33<02:07, 298.04 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9632/47780 [00:32<01:45, 362.95 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10737/47780 [00:33<01:54, 323.22 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9731/47780 [00:33<02:02, 311.82 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9281/47780 [00:33<01:46, 362.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9307/47780 [00:33<01:59, 322.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9687/47780 [00:33<02:06, 300.88 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9669/47780 [00:33<01:53, 334.48 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10772/47780 [00:33<01:54, 323.50 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9769/47780 [00:33<01:55, 329.40 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9320/47780 [00:33<01:46, 361.70 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9727/47780 [00:33<01:55, 328.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9342/47780 [00:33<01:58, 323.32 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9707/47780 [00:33<01:49, 346.69 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10805/47780 [00:33<01:58, 311.39 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9803/47780 [00:33<02:01, 311.61 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9761/47780 [00:33<01:54, 332.01 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9357/47780 [00:33<01:47, 356.10 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9376/47780 [00:33<01:59, 320.12 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9743/47780 [00:33<01:59, 318.37 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9835/47780 [00:33<02:03, 308.33 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9796/47780 [00:33<01:52, 336.85 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9394/47780 [00:33<01:47, 356.46 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9410/47780 [00:33<02:01, 315.24 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10837/47780 [00:33<02:13, 276.38 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9782/47780 [00:33<01:53, 334.38 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9849/47780 [00:33<01:37, 389.46 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9434/47780 [00:33<01:44, 368.61 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9867/47780 [00:33<02:12, 285.80 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9444/47780 [00:33<02:02, 311.75 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10877/47780 [00:33<02:01, 302.81 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9817/47780 [00:33<01:59, 317.84 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9896/47780 [00:33<01:33, 403.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9473/47780 [00:33<01:43, 370.76 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9479/47780 [00:33<01:58, 322.45 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9903/47780 [00:33<02:04, 303.11 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10916/47780 [00:33<01:56, 315.69 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9513/47780 [00:33<01:42, 375.01 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9937/47780 [00:33<01:35, 396.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9862/47780 [00:33<01:53, 335.34 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9520/47780 [00:33<01:50, 347.53 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9934/47780 [00:33<02:07, 298.00 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10957/47780 [00:33<01:48, 340.82 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1868/47780 [00:33<04:56, 154.96 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9905/47780 [00:33<01:46, 356.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9555/47780 [00:33<01:50, 347.38 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9977/47780 [00:33<01:40, 375.38 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9967/47780 [00:33<02:04, 304.02 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10994/47780 [00:33<01:48, 337.89 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9551/47780 [00:33<01:56, 327.03 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2002/47780 [00:33<03:38, 209.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9596/47780 [00:33<01:45, 362.43 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7398/47780 [00:33<02:52, 234.36 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9943/47780 [00:33<01:47, 350.96 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9999/47780 [00:33<02:03, 305.02 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11031/47780 [00:33<01:45, 346.71 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10015/47780 [00:33<01:47, 352.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9585/47780 [00:33<01:58, 322.73 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9633/47780 [00:34<01:46, 359.45 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7707/47780 [00:34<01:56, 345.00 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10034/47780 [00:34<01:58, 317.61 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9979/47780 [00:33<01:47, 350.08 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10054/47780 [00:34<01:46, 355.68 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9623/47780 [00:34<01:53, 335.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11067/47780 [00:34<01:50, 331.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9673/47780 [00:34<01:43, 367.98 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10016/47780 [00:34<01:47, 351.57 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10098/47780 [00:34<01:40, 374.90 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10066/47780 [00:34<02:06, 297.38 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9659/47780 [00:34<01:52, 338.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11102/47780 [00:34<01:50, 333.34 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9711/47780 [00:34<01:43, 367.22 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10136/47780 [00:34<01:41, 371.67 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9694/47780 [00:34<01:55, 331.08 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10052/47780 [00:34<01:58, 317.94 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11136/47780 [00:34<01:53, 324.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10097/47780 [00:34<02:15, 278.50 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9748/47780 [00:34<01:51, 340.03 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10174/47780 [00:34<01:40, 373.75 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9734/47780 [00:34<01:49, 346.08 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11178/47780 [00:34<01:45, 347.24 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10127/47780 [00:34<02:14, 279.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10085/47780 [00:34<02:06, 298.93 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9783/47780 [00:34<01:55, 328.03 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9772/47780 [00:34<01:46, 355.40 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10212/47780 [00:34<01:46, 351.57 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11216/47780 [00:34<01:43, 352.36 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10160/47780 [00:34<02:09, 290.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10124/47780 [00:34<01:56, 322.75 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9814/47780 [00:34<01:42, 370.06 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9821/47780 [00:34<01:53, 335.25 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11255/47780 [00:34<01:40, 363.00 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10248/47780 [00:34<01:48, 346.58 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10194/47780 [00:34<02:05, 300.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10163/47780 [00:34<01:50, 341.01 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7895/47780 [00:34<01:59, 332.60 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9863/47780 [00:34<01:46, 355.10 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9858/47780 [00:34<01:38, 385.82 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10283/47780 [00:34<01:49, 342.98 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11292/47780 [00:34<01:43, 352.73 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10232/47780 [00:34<01:57, 319.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10198/47780 [00:34<01:51, 335.85 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9905/47780 [00:34<01:41, 373.27 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11328/47780 [00:34<01:45, 346.78 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10265/47780 [00:34<01:57, 318.86 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10233/47780 [00:34<01:54, 328.48 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10318/47780 [00:34<01:59, 313.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9897/47780 [00:34<01:53, 332.66 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9943/47780 [00:34<01:42, 370.08 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10300/47780 [00:34<01:54, 327.80 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11363/47780 [00:34<01:51, 325.75 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10267/47780 [00:34<01:55, 325.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10352/47780 [00:34<01:57, 317.37 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9933/47780 [00:34<01:57, 323.29 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9981/47780 [00:34<01:47, 352.85 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10333/47780 [00:34<01:55, 324.39 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10301/47780 [00:35<01:55, 325.61 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11396/47780 [00:35<01:53, 319.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10385/47780 [00:35<02:03, 303.98 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9974/47780 [00:35<01:51, 338.75 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8036/47780 [00:35<01:59, 332.99 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10022/47780 [00:35<01:42, 368.84 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10366/47780 [00:35<02:02, 304.24 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11429/47780 [00:35<01:58, 307.67 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10334/47780 [00:35<02:02, 306.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10416/47780 [00:35<02:03, 302.36 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10015/47780 [00:35<01:45, 357.60 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10060/47780 [00:35<01:42, 367.68 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10447/47780 [00:35<02:02, 304.30 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11461/47780 [00:35<01:58, 305.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10368/47780 [00:35<01:59, 311.90 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10397/47780 [00:35<02:15, 275.58 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10052/47780 [00:35<01:48, 348.57 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10100/47780 [00:35<01:43, 365.04 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11506/47780 [00:35<01:44, 345.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10405/47780 [00:35<01:55, 324.61 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10431/47780 [00:35<02:07, 292.52 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10478/47780 [00:35<02:08, 289.64 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8145/47780 [00:35<01:57, 336.11 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10088/47780 [00:35<01:52, 334.08 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10140/47780 [00:35<01:43, 365.22 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10439/47780 [00:35<01:54, 325.26 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2098/47780 [00:35<05:42, 133.52 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11541/47780 [00:35<01:47, 335.59 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10461/47780 [00:35<02:12, 282.30 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10508/47780 [00:35<02:13, 279.76 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10122/47780 [00:35<01:52, 335.30 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10177/47780 [00:35<01:50, 340.20 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10472/47780 [00:35<01:54, 326.33 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2314/47780 [00:35<03:23, 223.26 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11581/47780 [00:35<01:44, 345.97 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10537/47780 [00:35<02:11, 282.56 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10490/47780 [00:35<02:13, 278.54 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10156/47780 [00:35<01:52, 333.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8234/47780 [00:35<01:54, 345.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10212/47780 [00:35<01:52, 332.73 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10505/47780 [00:35<01:59, 313.12 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10526/47780 [00:35<02:05, 297.65 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10571/47780 [00:35<02:07, 292.51 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10198/47780 [00:35<01:46, 354.29 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11617/47780 [00:35<01:52, 320.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10249/47780 [00:35<01:49, 342.41 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10540/47780 [00:35<01:56, 319.91 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10565/47780 [00:35<01:55, 323.49 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8307/47780 [00:35<01:52, 350.61 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10601/47780 [00:35<02:07, 290.92 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10241/47780 [00:35<01:42, 367.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11650/47780 [00:35<02:01, 297.74 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10574/47780 [00:35<01:54, 323.65 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10600/47780 [00:35<01:52, 330.44 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10284/47780 [00:35<02:02, 306.99 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10278/47780 [00:35<01:44, 360.04 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10636/47780 [00:35<02:07, 291.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11681/47780 [00:36<02:02, 294.18 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8369/47780 [00:35<01:52, 349.70 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10612/47780 [00:35<01:51, 334.35 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10634/47780 [00:35<01:52, 330.13 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10320/47780 [00:36<01:40, 372.64 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10666/47780 [00:36<02:07, 290.48 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10321/47780 [00:36<02:00, 310.53 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11711/47780 [00:36<02:03, 293.08 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10670/47780 [00:36<01:50, 334.91 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10646/47780 [00:36<01:55, 320.68 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10365/47780 [00:36<01:35, 390.71 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10356/47780 [00:36<01:57, 317.64 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8423/47780 [00:36<01:52, 348.86 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10696/47780 [00:36<02:12, 280.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11741/47780 [00:36<02:03, 291.49 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10709/47780 [00:36<01:50, 335.44 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10679/47780 [00:36<01:59, 310.28 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10389/47780 [00:36<01:56, 320.70 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10728/47780 [00:36<02:11, 282.55 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10405/47780 [00:36<01:43, 361.93 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8472/47780 [00:36<01:50, 354.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11771/47780 [00:36<02:06, 284.64 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10712/47780 [00:36<01:57, 315.57 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10745/47780 [00:36<01:49, 337.97 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10422/47780 [00:36<02:01, 306.47 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10759/47780 [00:36<02:10, 283.85 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10443/47780 [00:36<01:43, 360.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11801/47780 [00:36<02:11, 273.59 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8518/47780 [00:36<01:53, 347.31 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10747/47780 [00:36<01:54, 323.06 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10779/47780 [00:36<01:50, 334.78 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10458/47780 [00:36<01:56, 321.16 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10788/47780 [00:36<02:09, 285.39 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10480/47780 [00:36<01:46, 351.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11838/47780 [00:36<02:00, 299.50 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10782/47780 [00:36<01:52, 329.17 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8561/47780 [00:36<01:53, 344.89 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10813/47780 [00:36<01:52, 329.08 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10819/47780 [00:36<02:07, 289.40 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10503/47780 [00:36<01:51, 334.83 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10516/47780 [00:36<01:49, 339.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11874/47780 [00:36<01:54, 312.94 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10819/47780 [00:36<01:48, 340.91 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10853/47780 [00:36<01:48, 341.64 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8600/47780 [00:36<01:56, 337.73 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10857/47780 [00:36<01:57, 315.39 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10554/47780 [00:36<01:39, 374.57 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11907/47780 [00:36<01:53, 314.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10553/47780 [00:36<01:48, 343.88 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10854/47780 [00:36<01:52, 328.27 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10893/47780 [00:36<01:52, 328.09 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8638/47780 [00:36<01:55, 338.31 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10888/47780 [00:36<01:56, 317.99 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10592/47780 [00:36<01:39, 375.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11944/47780 [00:36<01:48, 330.46 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10599/47780 [00:36<01:39, 372.20 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10887/47780 [00:36<01:56, 317.91 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10926/47780 [00:36<01:54, 321.35 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10932/47780 [00:36<01:45, 348.24 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8674/47780 [00:36<01:57, 333.99 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10638/47780 [00:36<01:33, 395.61 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11979/47780 [00:36<01:46, 335.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10642/47780 [00:36<01:36, 384.26 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10969/47780 [00:36<01:45, 350.28 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10919/47780 [00:36<02:04, 296.19 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10960/47780 [00:37<01:56, 315.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10683/47780 [00:36<01:35, 386.88 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12019/47780 [00:37<01:45, 340.42 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10678/47780 [00:37<01:42, 363.37 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8709/47780 [00:37<02:14, 290.24 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10949/47780 [00:37<02:05, 292.90 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11005/47780 [00:37<01:48, 337.62 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10992/47780 [00:37<02:03, 296.77 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10730/47780 [00:37<01:31, 406.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12054/47780 [00:37<01:44, 342.11 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10715/47780 [00:37<01:42, 361.49 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8742/47780 [00:37<02:11, 297.13 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10979/47780 [00:37<02:07, 288.19 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11041/47780 [00:37<01:47, 340.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10772/47780 [00:37<01:30, 410.38 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11038/47780 [00:37<01:49, 334.19 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10757/47780 [00:37<01:39, 373.60 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12089/47780 [00:37<01:53, 314.69 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8778/47780 [00:37<02:06, 309.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11009/47780 [00:37<02:07, 288.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11076/47780 [00:37<01:52, 327.54 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10796/47780 [00:37<01:39, 369.87 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10814/47780 [00:37<01:36, 384.96 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12125/47780 [00:37<01:51, 320.46 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11072/47780 [00:37<02:00, 304.85 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8817/47780 [00:37<01:59, 326.63 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2425/47780 [00:37<05:32, 136.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11039/47780 [00:37<02:06, 291.53 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11109/47780 [00:37<01:55, 318.24 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10855/47780 [00:37<01:36, 384.39 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10834/47780 [00:37<01:41, 364.09 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11106/47780 [00:37<02:00, 305.14 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12160/47780 [00:37<01:51, 318.17 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8860/47780 [00:37<01:51, 350.48 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2514/47780 [00:37<04:31, 166.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11070/47780 [00:37<02:06, 290.43 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10896/47780 [00:37<01:34, 391.54 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11141/47780 [00:37<02:01, 302.58 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10871/47780 [00:37<01:44, 353.87 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11142/47780 [00:37<01:55, 316.50 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8896/47780 [00:37<01:51, 349.24 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12197/47780 [00:37<01:52, 314.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11105/47780 [00:37<02:01, 301.31 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10936/47780 [00:37<01:38, 372.71 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11172/47780 [00:37<02:08, 284.95 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10907/47780 [00:37<01:49, 336.97 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8933/47780 [00:37<01:50, 350.81 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12230/47780 [00:37<02:01, 293.21 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11175/47780 [00:37<02:12, 276.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11136/47780 [00:37<02:05, 293.01 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10977/47780 [00:37<01:37, 378.96 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8972/47780 [00:37<01:48, 358.16 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11201/47780 [00:37<02:14, 271.09 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10942/47780 [00:37<01:57, 312.98 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12261/47780 [00:37<02:01, 291.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11223/47780 [00:37<01:51, 328.55 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11172/47780 [00:37<01:59, 305.09 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9010/47780 [00:37<01:46, 364.38 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11016/47780 [00:37<01:42, 360.28 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11237/47780 [00:37<02:04, 292.70 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10979/47780 [00:37<01:52, 328.08 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11258/47780 [00:37<01:50, 330.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12291/47780 [00:37<02:04, 285.97 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11212/47780 [00:37<01:51, 328.16 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9049/47780 [00:37<01:45, 367.48 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11268/47780 [00:37<02:02, 297.17 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11056/47780 [00:37<01:42, 356.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11013/47780 [00:37<01:52, 327.75 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11248/47780 [00:38<01:49, 333.52 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11293/47780 [00:38<01:53, 321.84 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12320/47780 [00:38<02:08, 275.59 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11303/47780 [00:38<01:58, 308.82 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9086/47780 [00:38<01:50, 349.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11092/47780 [00:38<01:50, 331.34 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11328/47780 [00:38<01:51, 326.16 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11285/47780 [00:38<01:48, 336.27 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12349/47780 [00:38<02:07, 277.79 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11047/47780 [00:38<02:04, 294.40 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11342/47780 [00:38<01:49, 331.79 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9126/47780 [00:38<01:49, 353.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11136/47780 [00:38<01:42, 357.47 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12377/47780 [00:38<02:09, 272.37 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11324/47780 [00:38<01:46, 343.81 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11110/47780 [00:38<01:38, 372.20 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11362/47780 [00:38<01:57, 309.44 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11376/47780 [00:38<01:48, 334.07 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9162/47780 [00:38<01:52, 344.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2691/47780 [00:38<04:09, 180.46 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11361/47780 [00:38<01:44, 347.36 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12405/47780 [00:38<02:10, 270.90 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11403/47780 [00:38<01:48, 335.87 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11152/47780 [00:38<01:36, 379.97 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11174/47780 [00:38<01:52, 324.06 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11417/47780 [00:38<01:44, 348.14 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9200/47780 [00:38<01:50, 349.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2923/47780 [00:38<02:33, 291.70 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12435/47780 [00:38<02:06, 278.96 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11448/47780 [00:38<01:41, 356.93 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11192/47780 [00:38<01:39, 369.05 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11396/47780 [00:38<01:51, 325.04 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11208/47780 [00:38<01:58, 308.78 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11454/47780 [00:38<01:43, 350.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9236/47780 [00:38<01:50, 349.11 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12467/47780 [00:38<02:03, 284.95 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11486/47780 [00:38<01:41, 358.18 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11439/47780 [00:38<01:43, 350.99 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11233/47780 [00:38<01:39, 368.40 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11240/47780 [00:38<02:05, 291.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9271/47780 [00:38<01:50, 349.14 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12497/47780 [00:38<02:01, 289.28 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11491/47780 [00:38<02:02, 297.20 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11525/47780 [00:38<01:39, 364.34 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11275/47780 [00:38<01:35, 382.31 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11475/47780 [00:38<01:49, 330.50 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11270/47780 [00:38<02:05, 290.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9306/47780 [00:38<01:52, 341.56 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12530/47780 [00:38<01:58, 297.66 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11548/47780 [00:38<01:39, 363.97 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11315/47780 [00:38<01:35, 382.83 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11562/47780 [00:38<01:43, 349.71 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11511/47780 [00:38<01:49, 331.80 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11306/47780 [00:38<01:59, 305.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9341/47780 [00:38<01:55, 332.93 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12563/47780 [00:38<01:54, 306.85 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11587/47780 [00:38<01:43, 348.28 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11598/47780 [00:38<01:47, 337.22 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11354/47780 [00:38<01:41, 360.34 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11545/47780 [00:38<01:53, 320.01 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11337/47780 [00:38<02:02, 296.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9375/47780 [00:38<01:57, 326.83 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12604/47780 [00:39<01:46, 329.56 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11625/47780 [00:38<01:42, 353.26 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11635/47780 [00:39<01:47, 335.57 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11579/47780 [00:39<01:53, 318.41 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11369/47780 [00:39<02:01, 300.21 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11392/47780 [00:39<01:49, 333.20 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9411/47780 [00:39<01:55, 333.04 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12644/47780 [00:39<01:43, 338.29 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11662/47780 [00:39<01:46, 338.99 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11669/47780 [00:39<01:47, 336.02 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11624/47780 [00:39<01:42, 353.24 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11403/47780 [00:39<01:56, 311.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9445/47780 [00:39<01:55, 330.82 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11427/47780 [00:39<01:52, 322.44 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12678/47780 [00:39<01:46, 330.62 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11443/47780 [00:39<01:48, 335.15 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11698/47780 [00:39<01:53, 317.32 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11703/47780 [00:39<01:56, 309.77 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▋         | 3033/47780 [00:39<03:13, 231.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9480/47780 [00:39<01:55, 332.89 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11660/47780 [00:39<01:52, 320.68 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11470/47780 [00:39<01:45, 345.13 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12713/47780 [00:39<01:45, 332.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11477/47780 [00:39<01:48, 333.86 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9517/47780 [00:39<01:55, 332.08 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11741/47780 [00:39<01:55, 312.59 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11699/47780 [00:39<01:46, 339.03 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11510/47780 [00:39<01:40, 359.81 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11731/47780 [00:39<02:01, 296.24 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12747/47780 [00:39<01:47, 327.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11513/47780 [00:39<01:46, 341.34 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9554/47780 [00:39<01:51, 342.83 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11776/47780 [00:39<01:51, 321.92 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11547/47780 [00:39<01:42, 355.00 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11734/47780 [00:39<01:51, 324.04 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11762/47780 [00:39<02:03, 290.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12785/47780 [00:39<01:42, 342.26 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11548/47780 [00:39<01:53, 318.04 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9589/47780 [00:39<01:52, 338.70 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11809/47780 [00:39<01:54, 313.35 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11794/47780 [00:39<02:01, 295.36 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11583/47780 [00:39<01:46, 341.02 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11767/47780 [00:39<01:55, 312.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12820/47780 [00:39<01:46, 328.21 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11594/47780 [00:39<01:41, 357.63 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9623/47780 [00:39<01:57, 326.07 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11627/47780 [00:39<01:38, 366.27 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11824/47780 [00:39<02:05, 287.34 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11799/47780 [00:39<01:56, 307.56 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12853/47780 [00:39<01:49, 318.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11841/47780 [00:39<02:10, 275.96 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11631/47780 [00:39<01:45, 341.64 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9656/47780 [00:39<02:07, 300.05 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11853/47780 [00:39<02:08, 278.56 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11664/47780 [00:39<01:45, 341.04 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12886/47780 [00:39<01:50, 315.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11892/47780 [00:39<01:46, 336.12 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11831/47780 [00:39<02:15, 264.57 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11670/47780 [00:39<01:42, 351.38 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11888/47780 [00:39<02:05, 285.95 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12924/47780 [00:40<01:44, 333.25 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11704/47780 [00:39<01:45, 343.48 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11928/47780 [00:40<01:46, 338.04 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9687/47780 [00:39<02:13, 284.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11873/47780 [00:39<01:59, 300.20 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11706/47780 [00:40<01:46, 338.79 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12961/47780 [00:40<01:42, 340.37 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11921/47780 [00:40<02:01, 294.86 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9729/47780 [00:40<01:58, 320.50 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11739/47780 [00:40<01:46, 339.13 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11963/47780 [00:40<01:48, 331.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3114/47780 [00:40<04:01, 184.91 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11907/47780 [00:40<01:57, 304.55 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11741/47780 [00:40<01:50, 326.43 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11774/47780 [00:40<01:45, 340.83 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12996/47780 [00:40<01:44, 331.55 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11954/47780 [00:40<02:01, 294.65 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12004/47780 [00:40<01:41, 352.65 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9762/47780 [00:40<02:00, 315.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3282/47780 [00:40<02:44, 271.11 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11939/47780 [00:40<01:56, 307.81 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11775/47780 [00:40<01:51, 322.17 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11809/47780 [00:40<01:45, 339.64 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12040/47780 [00:40<01:41, 352.09 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11987/47780 [00:40<01:58, 301.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13030/47780 [00:40<01:46, 326.61 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11978/47780 [00:40<01:49, 327.71 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9795/47780 [00:40<02:13, 284.99 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11809/47780 [00:40<01:53, 318.17 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12077/47780 [00:40<01:40, 355.96 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12036/47780 [00:40<01:42, 350.25 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11844/47780 [00:40<01:48, 331.22 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13063/47780 [00:40<01:49, 316.15 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12012/47780 [00:40<01:49, 326.81 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9825/47780 [00:40<02:22, 267.23 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12114/47780 [00:40<01:40, 355.19 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12073/47780 [00:40<01:41, 352.66 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11842/47780 [00:40<01:59, 301.31 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13095/47780 [00:40<01:51, 310.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11878/47780 [00:40<01:57, 305.99 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12046/47780 [00:40<01:52, 316.63 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9853/47780 [00:40<02:23, 264.33 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11882/47780 [00:40<01:50, 324.68 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12150/47780 [00:40<01:44, 341.68 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13130/47780 [00:40<01:48, 318.43 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12109/47780 [00:40<01:48, 329.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11915/47780 [00:40<01:50, 323.26 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12083/47780 [00:40<01:47, 331.13 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9880/47780 [00:40<02:31, 250.22 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12185/47780 [00:40<01:48, 328.96 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11951/47780 [00:40<01:47, 333.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13162/47780 [00:40<01:53, 304.86 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11915/47780 [00:40<02:02, 293.55 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12126/47780 [00:40<01:40, 356.09 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12144/47780 [00:40<01:56, 306.70 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9910/47780 [00:40<02:26, 257.95 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12219/47780 [00:40<01:48, 328.45 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11985/47780 [00:40<01:47, 331.67 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13193/47780 [00:40<01:54, 302.10 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11946/47780 [00:40<02:02, 291.41 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12195/47780 [00:40<01:39, 356.76 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12163/47780 [00:40<01:46, 332.92 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9937/47780 [00:40<02:25, 260.88 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12253/47780 [00:40<01:49, 324.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12023/47780 [00:40<01:45, 337.85 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11979/47780 [00:40<01:58, 301.52 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13224/47780 [00:41<02:02, 282.39 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12232/47780 [00:40<01:42, 348.39 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12197/47780 [00:40<01:47, 330.10 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9985/47780 [00:40<02:00, 314.85 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12288/47780 [00:41<01:48, 327.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12060/47780 [00:41<01:45, 339.66 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12010/47780 [00:41<02:01, 294.67 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13260/47780 [00:41<01:56, 297.34 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12272/47780 [00:41<01:41, 351.49 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12231/47780 [00:41<01:49, 323.43 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10023/47780 [00:41<01:55, 325.71 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12102/47780 [00:41<01:38, 362.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12327/47780 [00:41<01:44, 337.90 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12042/47780 [00:41<01:59, 298.54 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13292/47780 [00:41<01:54, 300.36 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12309/47780 [00:41<01:40, 352.76 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12264/47780 [00:41<01:49, 324.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10056/47780 [00:41<01:55, 326.71 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12139/47780 [00:41<01:41, 352.14 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12362/47780 [00:41<01:47, 329.99 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12076/47780 [00:41<01:56, 306.62 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13325/47780 [00:41<01:52, 305.22 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12346/47780 [00:41<01:42, 345.90 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12297/47780 [00:41<01:54, 309.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10089/47780 [00:41<01:55, 327.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12176/47780 [00:41<01:40, 353.28 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12396/47780 [00:41<01:49, 321.97 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12109/47780 [00:41<01:55, 309.77 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13356/47780 [00:41<01:54, 299.46 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3375/47780 [00:41<04:13, 175.08 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12381/47780 [00:41<01:44, 339.35 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10122/47780 [00:41<01:56, 324.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12329/47780 [00:41<01:56, 304.99 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12213/47780 [00:41<01:42, 346.10 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12429/47780 [00:41<01:53, 310.17 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13395/47780 [00:41<01:46, 321.91 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12141/47780 [00:41<01:59, 298.98 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3572/47780 [00:41<02:41, 274.39 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12419/47780 [00:41<01:41, 346.94 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10159/47780 [00:41<01:55, 326.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12369/47780 [00:41<01:49, 324.62 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12252/47780 [00:41<01:41, 350.58 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12464/47780 [00:41<01:51, 317.76 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13428/47780 [00:41<01:47, 320.26 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12184/47780 [00:41<01:47, 332.07 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10197/47780 [00:41<01:50, 338.99 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12405/47780 [00:41<01:46, 330.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12454/47780 [00:41<01:49, 321.98 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12288/47780 [00:41<01:42, 345.51 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13469/47780 [00:41<01:40, 342.42 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12224/47780 [00:41<01:42, 347.54 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12497/47780 [00:41<01:58, 297.46 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10233/47780 [00:41<01:49, 344.10 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12445/47780 [00:41<01:41, 346.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12488/47780 [00:41<01:49, 323.25 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12326/47780 [00:41<01:40, 351.30 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13509/47780 [00:41<01:36, 354.94 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12259/47780 [00:41<01:43, 343.99 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12528/47780 [00:41<01:58, 298.03 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12487/47780 [00:41<01:36, 367.59 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10268/47780 [00:41<01:52, 333.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12521/47780 [00:41<01:55, 305.14 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12368/47780 [00:41<01:36, 366.77 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12294/47780 [00:41<01:43, 342.08 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13545/47780 [00:41<01:38, 348.34 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12559/47780 [00:41<02:01, 290.88 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12527/47780 [00:41<01:34, 372.74 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10302/47780 [00:41<01:52, 332.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12556/47780 [00:41<01:51, 317.31 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13587/47780 [00:42<01:33, 364.77 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12407/47780 [00:41<01:39, 356.56 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12330/47780 [00:41<01:45, 335.09 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12589/47780 [00:42<02:03, 284.28 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10343/47780 [00:42<01:45, 354.53 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12589/47780 [00:42<01:52, 313.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12565/47780 [00:42<01:44, 335.85 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12443/47780 [00:42<01:39, 356.63 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13629/47780 [00:42<01:30, 376.42 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12369/47780 [00:42<01:43, 343.45 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12620/47780 [00:42<02:04, 282.48 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10379/47780 [00:42<01:49, 340.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12600/47780 [00:42<01:44, 338.24 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12621/47780 [00:42<02:00, 292.74 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12487/47780 [00:42<01:34, 373.40 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12408/47780 [00:42<01:39, 356.42 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12650/47780 [00:42<02:05, 281.01 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13669/47780 [00:42<01:41, 336.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10414/47780 [00:42<01:51, 334.86 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12659/47780 [00:42<01:53, 309.68 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12635/47780 [00:42<01:51, 314.55 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12526/47780 [00:42<01:33, 376.77 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12444/47780 [00:42<01:47, 327.24 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12686/47780 [00:42<01:57, 299.67 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13708/47780 [00:42<01:38, 347.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10449/47780 [00:42<01:53, 329.65 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12565/47780 [00:42<01:33, 377.18 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12668/47780 [00:42<01:56, 302.68 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12691/47780 [00:42<02:00, 290.25 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12480/47780 [00:42<01:45, 335.48 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12717/47780 [00:42<01:58, 296.04 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13744/47780 [00:42<01:41, 336.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10484/47780 [00:42<01:54, 326.51 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12608/47780 [00:42<01:30, 388.50 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12708/47780 [00:42<01:46, 328.51 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12726/47780 [00:42<01:54, 306.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12514/47780 [00:42<01:47, 329.35 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12747/47780 [00:42<02:05, 279.94 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13780/47780 [00:42<01:45, 321.16 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10517/47780 [00:42<01:58, 313.36 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12750/47780 [00:42<01:40, 349.93 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12758/47780 [00:42<01:55, 303.34 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12647/47780 [00:42<01:34, 371.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12548/47780 [00:42<01:55, 305.40 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12776/47780 [00:42<02:08, 273.22 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10549/47780 [00:42<01:59, 311.65 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13813/47780 [00:42<01:46, 319.95 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12688/47780 [00:42<01:31, 382.21 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12790/47780 [00:42<01:54, 306.39 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12786/47780 [00:42<01:42, 341.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12582/47780 [00:42<01:52, 311.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12810/47780 [00:42<02:00, 290.16 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3675/47780 [00:42<04:13, 174.11 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10583/47780 [00:42<02:00, 309.56 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12822/47780 [00:42<01:41, 345.36 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13846/47780 [00:42<01:56, 291.22 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12823/47780 [00:42<01:53, 307.42 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12729/47780 [00:42<01:33, 373.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12615/47780 [00:42<01:52, 313.29 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12840/47780 [00:42<02:00, 289.78 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3869/47780 [00:42<02:44, 267.00 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10623/47780 [00:42<01:52, 331.28 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12862/47780 [00:42<01:38, 354.17 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13876/47780 [00:43<01:57, 287.48 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12854/47780 [00:42<01:55, 301.39 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12772/47780 [00:42<01:30, 385.07 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12648/47780 [00:42<01:52, 311.04 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12872/47780 [00:43<02:03, 282.00 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10657/47780 [00:43<01:56, 319.22 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12885/47780 [00:43<01:54, 303.51 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12906/47780 [00:43<01:33, 371.50 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12811/47780 [00:43<01:32, 377.86 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13906/47780 [00:43<02:00, 281.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12680/47780 [00:43<01:53, 310.05 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12905/47780 [00:43<02:01, 286.61 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10694/47780 [00:43<01:52, 330.27 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12945/47780 [00:43<01:33, 370.93 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12916/47780 [00:43<01:56, 298.49 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13936/47780 [00:43<02:03, 274.80 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12849/47780 [00:43<01:37, 358.04 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12716/47780 [00:43<01:48, 324.24 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12949/47780 [00:43<01:46, 328.56 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10728/47780 [00:43<01:52, 328.51 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12984/47780 [00:43<01:34, 368.03 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12950/47780 [00:43<01:55, 300.59 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13965/47780 [00:43<02:02, 275.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12887/47780 [00:43<01:39, 352.04 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12751/47780 [00:43<01:46, 327.90 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10766/47780 [00:43<01:47, 343.13 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12981/47780 [00:43<01:57, 296.47 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13995/47780 [00:43<02:00, 279.53 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13021/47780 [00:43<01:39, 348.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12983/47780 [00:43<01:59, 291.78 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12784/47780 [00:43<01:47, 324.43 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12923/47780 [00:43<01:46, 328.54 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10802/47780 [00:43<01:51, 332.54 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13011/47780 [00:43<01:59, 290.93 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14024/47780 [00:43<02:00, 279.35 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13018/47780 [00:43<01:55, 301.07 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13057/47780 [00:43<01:43, 336.94 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12961/47780 [00:43<01:42, 339.20 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12817/47780 [00:43<01:49, 318.61 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10847/47780 [00:43<01:41, 362.21 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13049/47780 [00:43<01:51, 312.80 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13057/47780 [00:43<01:47, 321.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14055/47780 [00:43<01:59, 281.25 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13093/47780 [00:43<01:49, 318.18 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12849/47780 [00:43<01:54, 305.29 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12996/47780 [00:43<01:47, 324.33 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10884/47780 [00:43<01:41, 363.97 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13090/47780 [00:43<01:44, 332.86 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13090/47780 [00:43<01:47, 322.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14084/47780 [00:43<02:00, 280.39 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13126/47780 [00:43<01:47, 321.26 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12880/47780 [00:43<01:55, 303.18 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13045/47780 [00:43<01:35, 365.35 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10924/47780 [00:43<01:39, 370.42 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13124/47780 [00:43<01:46, 325.03 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13128/47780 [00:43<01:42, 338.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14115/47780 [00:43<02:00, 279.73 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13165/47780 [00:43<01:42, 337.17 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12911/47780 [00:43<01:56, 298.13 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13083/47780 [00:43<01:48, 319.45 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13158/47780 [00:43<01:48, 318.36 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14145/47780 [00:43<01:57, 285.26 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10962/47780 [00:43<01:52, 327.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13162/47780 [00:43<01:45, 327.70 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12942/47780 [00:43<01:56, 298.30 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13201/47780 [00:43<01:49, 315.35 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13192/47780 [00:44<01:47, 320.98 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13117/47780 [00:44<01:51, 312.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14174/47780 [00:44<02:03, 271.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13196/47780 [00:44<01:50, 313.13 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10996/47780 [00:44<02:00, 305.08 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13241/47780 [00:44<01:43, 334.58 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12976/47780 [00:44<01:56, 299.91 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3981/47780 [00:44<03:57, 184.39 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13237/47780 [00:44<01:36, 357.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13150/47780 [00:44<01:54, 301.25 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14208/47780 [00:44<01:59, 281.27 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11039/47780 [00:44<01:49, 334.09 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13228/47780 [00:44<01:55, 298.91 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13009/47780 [00:44<01:53, 305.18 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13276/47780 [00:44<01:45, 327.77 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4280/47780 [00:44<02:10, 333.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13274/47780 [00:44<01:41, 341.61 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14259/47780 [00:44<01:37, 344.98 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13181/47780 [00:44<01:57, 293.84 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11075/47780 [00:44<01:50, 333.34 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13261/47780 [00:44<01:53, 303.92 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13051/47780 [00:44<01:42, 337.86 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13313/47780 [00:44<01:41, 338.95 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13317/47780 [00:44<01:34, 366.22 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14297/47780 [00:44<01:34, 354.79 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13215/47780 [00:44<01:53, 303.34 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11113/47780 [00:44<01:45, 345.99 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13292/47780 [00:44<01:55, 299.11 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13090/47780 [00:44<01:39, 348.94 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13348/47780 [00:44<01:45, 327.92 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14333/47780 [00:44<01:34, 352.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13355/47780 [00:44<01:36, 357.65 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13246/47780 [00:44<01:53, 304.30 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11152/47780 [00:44<01:46, 343.48 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13323/47780 [00:44<01:55, 298.81 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13126/47780 [00:44<01:39, 348.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13382/47780 [00:44<01:43, 331.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13393/47780 [00:44<01:35, 360.37 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13277/47780 [00:44<01:57, 293.78 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14370/47780 [00:44<01:39, 334.33 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11189/47780 [00:44<01:45, 347.06 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13162/47780 [00:44<01:39, 347.55 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13353/47780 [00:44<01:59, 289.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13417/47780 [00:44<01:43, 332.82 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13443/47780 [00:44<01:27, 391.22 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14410/47780 [00:44<01:34, 352.58 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13307/47780 [00:44<01:58, 291.85 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11225/47780 [00:44<01:47, 341.14 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13382/47780 [00:44<02:00, 286.28 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13197/47780 [00:44<01:41, 340.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13452/47780 [00:44<01:42, 333.98 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14446/47780 [00:44<01:34, 354.43 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13483/47780 [00:44<01:35, 360.97 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13412/47780 [00:44<01:59, 287.00 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13337/47780 [00:44<02:02, 281.72 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11260/47780 [00:44<01:51, 327.12 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13232/47780 [00:44<01:44, 331.53 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13486/47780 [00:44<01:50, 311.42 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14489/47780 [00:44<01:28, 376.27 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13443/47780 [00:44<01:56, 293.57 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13380/47780 [00:44<01:48, 315.96 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13520/47780 [00:44<01:37, 351.58 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13271/47780 [00:44<01:40, 344.51 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11295/47780 [00:44<01:50, 329.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13522/47780 [00:44<01:48, 316.99 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14530/47780 [00:45<01:28, 377.65 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13473/47780 [00:44<01:56, 295.29 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13418/47780 [00:44<01:42, 333.80 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13557/47780 [00:45<01:36, 356.41 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11330/47780 [00:44<01:50, 330.71 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13306/47780 [00:45<01:44, 330.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13554/47780 [00:45<01:54, 299.84 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14568/47780 [00:45<01:28, 373.51 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13505/47780 [00:45<01:54, 299.20 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13455/47780 [00:45<01:39, 343.88 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13595/47780 [00:45<01:38, 347.75 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11364/47780 [00:45<01:52, 323.01 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13349/47780 [00:45<01:37, 354.61 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13585/47780 [00:45<02:00, 284.63 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14606/47780 [00:45<01:31, 363.27 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13540/47780 [00:45<01:50, 310.43 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13635/47780 [00:45<01:34, 362.10 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13490/47780 [00:45<01:46, 323.44 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11404/47780 [00:45<01:46, 341.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13385/47780 [00:45<01:41, 340.29 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13614/47780 [00:45<02:03, 277.77 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14643/47780 [00:45<01:37, 341.05 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13572/47780 [00:45<01:58, 289.67 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11446/47780 [00:45<01:40, 361.92 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13672/47780 [00:45<01:37, 348.76 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13523/47780 [00:45<01:48, 314.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13420/47780 [00:45<01:41, 339.64 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13644/47780 [00:45<02:02, 277.66 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14683/47780 [00:45<01:33, 355.54 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13605/47780 [00:45<01:54, 297.39 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11483/47780 [00:45<01:43, 349.43 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13708/47780 [00:45<01:40, 340.12 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13555/47780 [00:45<01:55, 296.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13455/47780 [00:45<01:48, 317.13 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13686/47780 [00:45<01:48, 313.38 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13649/47780 [00:45<01:42, 333.94 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11519/47780 [00:45<01:46, 339.43 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13589/47780 [00:45<01:50, 308.19 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13743/47780 [00:45<01:44, 325.15 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14719/47780 [00:45<01:45, 312.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13489/47780 [00:45<01:47, 320.21 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13721/47780 [00:45<01:46, 319.71 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13690/47780 [00:45<01:35, 355.25 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13632/47780 [00:45<01:40, 338.52 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14769/47780 [00:45<01:32, 358.33 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13525/47780 [00:45<01:43, 331.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11554/47780 [00:45<01:53, 319.07 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13776/47780 [00:45<01:53, 299.15 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13737/47780 [00:45<01:27, 388.38 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13754/47780 [00:45<01:58, 286.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14807/47780 [00:45<01:34, 349.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11587/47780 [00:45<01:57, 308.32 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13809/47780 [00:45<01:51, 305.20 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13667/47780 [00:45<01:52, 304.04 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13559/47780 [00:45<01:52, 305.41 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4425/47780 [00:45<03:38, 198.48 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13777/47780 [00:45<01:28, 383.32 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13784/47780 [00:45<01:58, 286.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14843/47780 [00:45<01:35, 344.62 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13715/47780 [00:45<01:37, 350.48 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13601/47780 [00:45<01:42, 333.33 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11619/47780 [00:45<02:02, 295.57 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13840/47780 [00:45<01:58, 287.58 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4734/47780 [00:45<02:09, 332.28 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13816/47780 [00:45<01:35, 355.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13814/47780 [00:45<02:04, 273.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14879/47780 [00:46<01:36, 341.31 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13753/47780 [00:46<01:39, 343.46 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13876/47780 [00:46<01:51, 303.88 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11649/47780 [00:46<02:06, 284.70 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13635/47780 [00:46<01:52, 304.70 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13855/47780 [00:46<01:33, 363.67 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13842/47780 [00:46<02:05, 269.40 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13789/47780 [00:46<01:37, 347.80 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11679/47780 [00:46<02:05, 288.80 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13907/47780 [00:46<01:53, 298.83 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13668/47780 [00:46<01:50, 308.15 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14914/47780 [00:46<01:51, 294.42 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13873/47780 [00:46<02:03, 274.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13892/47780 [00:46<01:41, 332.72 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13828/47780 [00:46<01:35, 355.91 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11713/47780 [00:46<02:00, 299.72 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13945/47780 [00:46<01:47, 314.38 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13709/47780 [00:46<01:44, 325.31 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14967/47780 [00:46<01:33, 351.14 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13915/47780 [00:46<01:47, 314.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13929/47780 [00:46<01:39, 339.86 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13865/47780 [00:46<01:34, 358.49 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11744/47780 [00:46<02:00, 298.86 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13977/47780 [00:46<01:52, 299.24 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13748/47780 [00:46<01:39, 342.77 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13949/47780 [00:46<01:47, 314.45 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 15004/47780 [00:46<01:40, 324.64 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13965/47780 [00:46<01:44, 324.03 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13902/47780 [00:46<01:37, 346.63 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11778/47780 [00:46<01:56, 310.11 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14012/47780 [00:46<01:47, 313.12 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13784/47780 [00:46<01:44, 325.95 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15038/47780 [00:46<01:41, 322.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13981/47780 [00:46<01:50, 305.60 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14006/47780 [00:46<01:37, 346.92 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13937/47780 [00:46<01:38, 344.27 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11810/47780 [00:46<01:56, 309.66 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14044/47780 [00:46<01:50, 304.86 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13818/47780 [00:46<01:43, 329.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15080/47780 [00:46<01:33, 348.04 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14044/47780 [00:46<01:36, 348.69 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13980/47780 [00:46<01:31, 367.86 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14012/47780 [00:46<02:00, 281.25 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11845/47780 [00:46<01:54, 314.68 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14075/47780 [00:46<01:58, 284.02 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13853/47780 [00:46<01:46, 317.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15116/47780 [00:46<01:33, 350.86 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14083/47780 [00:46<01:34, 356.32 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11885/47780 [00:46<01:46, 335.47 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14020/47780 [00:46<01:32, 364.27 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14041/47780 [00:46<02:07, 263.90 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14108/47780 [00:46<01:54, 293.29 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13890/47780 [00:46<01:43, 328.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15159/47780 [00:46<01:28, 367.06 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11921/47780 [00:46<01:44, 342.56 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14061/47780 [00:46<01:31, 370.03 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14119/47780 [00:46<01:40, 334.14 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14068/47780 [00:46<02:12, 255.00 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14138/47780 [00:46<01:55, 291.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13926/47780 [00:46<01:41, 333.47 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15197/47780 [00:47<01:37, 335.07 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11956/47780 [00:46<01:45, 340.73 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14158/47780 [00:46<01:38, 342.57 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14099/47780 [00:46<01:34, 356.64 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14094/47780 [00:46<02:16, 246.18 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14171/47780 [00:47<01:54, 292.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13960/47780 [00:47<01:45, 319.50 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15232/47780 [00:47<01:38, 331.66 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11991/47780 [00:47<01:47, 331.83 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14193/47780 [00:47<01:39, 336.77 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14136/47780 [00:47<01:38, 341.09 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14123/47780 [00:47<02:13, 252.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14203/47780 [00:47<01:52, 297.19 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13998/47780 [00:47<01:43, 326.95 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15266/47780 [00:47<01:43, 313.84 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12025/47780 [00:47<01:52, 319.20 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14171/47780 [00:47<01:40, 335.36 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14227/47780 [00:47<01:47, 313.35 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14150/47780 [00:47<02:15, 248.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14237/47780 [00:47<01:49, 305.62 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14036/47780 [00:47<01:39, 337.92 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15300/47780 [00:47<01:41, 320.74 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12063/47780 [00:47<01:46, 336.31 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14206/47780 [00:47<01:41, 329.37 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14259/47780 [00:47<01:50, 302.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14175/47780 [00:47<02:16, 246.66 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14268/47780 [00:47<01:54, 293.52 examples/s]
Tokenizing train dataset (num_proc=32):  10%|█         | 4899/47780 [00:47<03:08, 227.93 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15334/47780 [00:47<01:40, 322.59 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12097/47780 [00:47<01:49, 326.02 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14240/47780 [00:47<01:44, 321.34 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14070/47780 [00:47<02:03, 273.30 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14205/47780 [00:47<02:09, 258.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14290/47780 [00:47<01:52, 297.36 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14303/47780 [00:47<01:49, 305.89 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5174/47780 [00:47<02:03, 344.65 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15367/47780 [00:47<01:41, 320.71 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12131/47780 [00:47<01:50, 323.07 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14279/47780 [00:47<01:38, 340.31 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14120/47780 [00:47<01:44, 322.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14240/47780 [00:47<01:59, 281.18 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14335/47780 [00:47<01:50, 303.10 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14320/47780 [00:47<02:07, 263.28 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15415/47780 [00:47<01:30, 358.15 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12164/47780 [00:47<01:54, 310.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14274/47780 [00:47<01:56, 288.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14315/47780 [00:47<01:43, 323.57 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14155/47780 [00:47<01:47, 313.81 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14368/47780 [00:47<01:54, 290.97 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14364/47780 [00:47<01:49, 304.54 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15456/47780 [00:47<01:28, 364.79 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12205/47780 [00:47<01:46, 335.01 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14306/47780 [00:47<01:52, 297.12 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14354/47780 [00:47<01:39, 335.10 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14190/47780 [00:47<01:47, 313.60 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14398/47780 [00:47<01:55, 289.86 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14397/47780 [00:47<01:47, 309.21 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12240/47780 [00:47<01:46, 333.11 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15493/47780 [00:47<01:36, 335.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14337/47780 [00:47<01:51, 300.40 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14392/47780 [00:47<01:37, 343.72 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14228/47780 [00:47<01:44, 320.81 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14429/47780 [00:47<01:54, 292.17 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14429/47780 [00:47<01:54, 290.12 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12278/47780 [00:47<01:42, 344.95 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14368/47780 [00:47<01:51, 300.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15528/47780 [00:48<01:39, 325.11 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14427/47780 [00:47<01:39, 334.19 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14262/47780 [00:47<01:43, 322.46 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14463/47780 [00:48<01:51, 299.15 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14470/47780 [00:48<01:43, 322.00 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12314/47780 [00:48<01:42, 345.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14399/47780 [00:48<01:50, 303.05 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15561/47780 [00:48<01:42, 313.17 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14466/47780 [00:48<01:36, 345.98 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14300/47780 [00:48<01:39, 338.04 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14502/47780 [00:48<01:43, 321.66 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14504/47780 [00:48<01:43, 320.02 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12352/47780 [00:48<01:45, 335.46 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14430/47780 [00:48<01:53, 294.44 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15593/47780 [00:48<01:42, 313.10 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14501/47780 [00:48<01:36, 346.58 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14335/47780 [00:48<01:43, 323.25 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14535/47780 [00:48<01:46, 312.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14537/47780 [00:48<01:45, 315.74 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15625/47780 [00:48<01:42, 313.26 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12386/47780 [00:48<01:52, 315.55 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14461/47780 [00:48<02:00, 276.80 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14536/47780 [00:48<01:39, 333.26 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14369/47780 [00:48<01:47, 310.45 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14567/47780 [00:48<01:50, 301.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14569/47780 [00:48<01:52, 294.25 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15657/47780 [00:48<01:42, 312.01 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12423/47780 [00:48<01:49, 323.75 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14492/47780 [00:48<01:57, 282.83 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14575/47780 [00:48<01:35, 348.80 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14603/47780 [00:48<01:45, 314.36 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14402/47780 [00:48<01:54, 290.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14599/47780 [00:48<01:53, 292.63 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15689/47780 [00:48<01:47, 298.42 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14522/47780 [00:48<01:59, 278.19 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12456/47780 [00:48<01:55, 305.22 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14611/47780 [00:48<01:40, 329.23 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14635/47780 [00:48<01:48, 305.02 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14629/47780 [00:48<01:55, 288.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14432/47780 [00:48<02:00, 276.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5337/47780 [00:48<02:44, 258.15 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15719/47780 [00:48<01:48, 295.20 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14551/47780 [00:48<01:58, 281.11 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12489/47780 [00:48<01:55, 305.31 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14645/47780 [00:48<01:41, 325.05 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14670/47780 [00:48<01:44, 316.08 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14668/47780 [00:48<01:45, 313.24 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14466/47780 [00:48<01:53, 292.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5497/47780 [00:48<02:09, 326.60 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15749/47780 [00:48<01:49, 292.11 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14582/47780 [00:48<01:55, 287.69 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12528/47780 [00:48<01:48, 324.99 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14683/47780 [00:48<01:38, 336.85 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14703/47780 [00:48<01:49, 301.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14505/47780 [00:48<01:44, 317.95 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14700/47780 [00:48<01:54, 288.99 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15788/47780 [00:48<01:41, 316.61 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14611/47780 [00:48<02:00, 274.18 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12569/47780 [00:48<01:43, 341.04 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14717/47780 [00:48<01:39, 331.28 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14734/47780 [00:48<01:51, 297.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14538/47780 [00:48<01:46, 311.89 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14735/47780 [00:48<01:49, 302.29 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15825/47780 [00:48<01:38, 324.64 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14644/47780 [00:48<01:55, 287.25 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12604/47780 [00:48<01:43, 339.83 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14751/47780 [00:48<01:41, 325.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14764/47780 [00:49<01:51, 294.80 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14570/47780 [00:49<01:52, 294.40 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14766/47780 [00:49<01:53, 291.45 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12645/47780 [00:49<01:38, 355.68 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14673/47780 [00:49<01:57, 281.45 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15858/47780 [00:49<01:47, 295.69 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14795/47780 [00:49<01:34, 349.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14807/47780 [00:49<01:39, 333.01 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14605/47780 [00:49<01:47, 309.51 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14797/47780 [00:49<01:51, 296.40 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15919/47780 [00:49<01:23, 380.55 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14831/47780 [00:49<01:36, 340.68 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14702/47780 [00:49<02:07, 260.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12681/47780 [00:49<01:49, 319.97 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14841/47780 [00:49<01:47, 306.93 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14637/47780 [00:49<01:47, 309.07 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14827/47780 [00:49<01:55, 284.69 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15972/47780 [00:49<01:17, 408.48 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14736/47780 [00:49<01:57, 281.60 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14869/47780 [00:49<01:36, 340.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12717/47780 [00:49<01:47, 327.52 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14874/47780 [00:49<01:45, 313.08 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14672/47780 [00:49<01:43, 320.59 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14861/47780 [00:49<01:52, 293.54 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16016/47780 [00:49<01:17, 412.38 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14765/47780 [00:49<02:00, 274.81 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12751/47780 [00:49<01:49, 320.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14906/47780 [00:49<01:38, 333.87 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14906/47780 [00:49<01:47, 304.39 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14705/47780 [00:49<01:50, 298.87 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14893/47780 [00:49<01:49, 300.55 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14793/47780 [00:49<02:00, 274.67 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16058/47780 [00:49<01:20, 395.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12786/47780 [00:49<01:48, 321.37 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14940/47780 [00:49<01:44, 313.36 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14937/47780 [00:49<01:52, 292.84 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14924/47780 [00:49<01:49, 300.32 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5627/47780 [00:49<02:43, 257.89 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14736/47780 [00:49<01:57, 280.73 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14828/47780 [00:49<01:51, 294.73 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16100/47780 [00:49<01:19, 399.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12823/47780 [00:49<01:45, 331.28 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14972/47780 [00:49<01:50, 297.24 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14971/47780 [00:49<01:51, 293.19 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14957/47780 [00:49<01:47, 305.70 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5731/47780 [00:49<02:18, 303.90 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14765/47780 [00:49<01:56, 283.05 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14860/47780 [00:49<01:50, 298.44 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16142/47780 [00:49<01:19, 395.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12857/47780 [00:49<01:44, 333.74 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15003/47780 [00:49<01:50, 297.42 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15002/47780 [00:49<01:54, 285.58 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14796/47780 [00:49<01:53, 290.38 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14988/47780 [00:49<01:55, 283.61 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14896/47780 [00:49<01:44, 315.97 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12895/47780 [00:49<01:42, 339.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16182/47780 [00:49<01:25, 371.62 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15039/47780 [00:49<01:46, 307.88 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15031/47780 [00:49<01:59, 273.64 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14835/47780 [00:49<01:44, 315.25 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15023/47780 [00:49<01:49, 298.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14929/47780 [00:49<01:43, 316.22 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12930/47780 [00:49<01:50, 314.31 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16222/47780 [00:50<01:31, 345.67 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15072/47780 [00:50<01:44, 314.02 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15067/47780 [00:49<01:50, 295.40 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14875/47780 [00:49<01:37, 336.58 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15058/47780 [00:49<01:44, 312.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14961/47780 [00:49<01:46, 307.18 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12964/47780 [00:50<01:48, 320.56 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16261/47780 [00:50<01:29, 353.63 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15100/47780 [00:50<01:48, 301.52 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14909/47780 [00:50<01:38, 332.81 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15106/47780 [00:50<01:52, 291.53 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15090/47780 [00:50<01:48, 302.53 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14995/47780 [00:50<01:44, 312.81 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16299/47780 [00:50<01:27, 360.69 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12997/47780 [00:50<01:56, 298.34 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15137/47780 [00:50<01:42, 317.10 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15144/47780 [00:50<01:43, 315.30 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14943/47780 [00:50<01:47, 305.83 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15027/47780 [00:50<01:48, 303.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15122/47780 [00:50<01:52, 289.91 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13036/47780 [00:50<01:48, 321.10 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15169/47780 [00:50<01:47, 304.07 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15180/47780 [00:50<01:42, 317.18 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16336/47780 [00:50<01:40, 314.37 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14991/47780 [00:50<01:33, 350.51 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15062/47780 [00:50<01:44, 312.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15156/47780 [00:50<01:49, 297.12 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13069/47780 [00:50<01:50, 313.14 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16384/47780 [00:50<01:27, 356.81 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15214/47780 [00:50<01:41, 320.23 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15030/47780 [00:50<01:32, 353.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15200/47780 [00:50<01:54, 283.69 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15094/47780 [00:50<01:49, 299.27 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15189/47780 [00:50<01:49, 296.40 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13102/47780 [00:50<01:49, 317.77 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15247/47780 [00:50<01:42, 315.99 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16422/47780 [00:50<01:30, 347.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15229/47780 [00:50<01:56, 279.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15066/47780 [00:50<01:35, 343.28 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15224/47780 [00:50<01:44, 311.00 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15130/47780 [00:50<01:45, 310.67 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13137/47780 [00:50<01:47, 323.29 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15279/47780 [00:50<01:47, 303.30 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15258/47780 [00:50<01:56, 279.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16471/47780 [00:50<01:22, 378.07 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15105/47780 [00:50<01:33, 349.06 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15256/47780 [00:50<01:45, 307.94 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15162/47780 [00:50<01:49, 298.29 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13170/47780 [00:50<01:47, 321.29 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15310/47780 [00:50<01:47, 301.77 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15289/47780 [00:50<01:55, 281.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15144/47780 [00:50<01:30, 359.67 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15287/47780 [00:50<01:45, 307.48 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16510/47780 [00:50<01:24, 369.29 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15196/47780 [00:50<01:47, 303.33 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5828/47780 [00:50<03:33, 196.55 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13203/47780 [00:50<01:50, 313.20 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15184/47780 [00:50<01:28, 367.98 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15321/47780 [00:50<01:52, 289.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15319/47780 [00:50<01:44, 310.78 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16548/47780 [00:50<01:24, 368.01 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15341/47780 [00:50<01:52, 287.28 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15227/47780 [00:50<01:51, 293.07 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6070/47780 [00:50<02:08, 324.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13235/47780 [00:50<01:53, 304.26 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15226/47780 [00:50<01:26, 375.71 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15360/47780 [00:50<01:37, 333.92 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15351/47780 [00:50<01:56, 277.20 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15372/47780 [00:51<01:52, 287.72 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15257/47780 [00:50<01:51, 290.65 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16586/47780 [00:51<01:33, 333.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13272/47780 [00:51<01:49, 316.06 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15268/47780 [00:51<01:24, 386.98 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15403/47780 [00:51<01:30, 355.90 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15403/47780 [00:51<01:50, 293.74 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15379/47780 [00:51<01:58, 273.83 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15291/47780 [00:51<01:47, 301.29 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16621/47780 [00:51<01:37, 320.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13305/47780 [00:51<01:51, 309.63 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15434/47780 [00:51<01:48, 298.35 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15413/47780 [00:51<01:53, 286.36 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15308/47780 [00:51<01:31, 353.07 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15326/47780 [00:51<01:44, 311.57 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15439/47780 [00:51<01:44, 310.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16654/47780 [00:51<01:46, 293.00 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13337/47780 [00:51<01:58, 289.56 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15470/47780 [00:51<01:42, 316.06 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15442/47780 [00:51<01:56, 277.12 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15345/47780 [00:51<01:31, 354.57 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15473/47780 [00:51<01:41, 318.09 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6186/47780 [00:51<02:12, 313.06 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15358/47780 [00:51<01:51, 290.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16684/47780 [00:51<01:46, 291.45 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13369/47780 [00:51<01:56, 294.86 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15502/47780 [00:51<01:49, 293.85 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15386/47780 [00:51<01:28, 366.10 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15473/47780 [00:51<01:57, 274.93 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15506/47780 [00:51<01:41, 317.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15391/47780 [00:51<01:48, 298.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16715/47780 [00:51<01:46, 290.58 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13400/47780 [00:51<01:55, 296.48 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15540/47780 [00:51<01:42, 313.99 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15505/47780 [00:51<01:53, 284.25 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15541/47780 [00:51<01:38, 326.82 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15424/47780 [00:51<01:31, 352.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15422/47780 [00:51<01:58, 273.75 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16747/47780 [00:51<01:46, 292.17 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13430/47780 [00:51<01:57, 293.42 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15572/47780 [00:51<01:44, 308.10 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15535/47780 [00:51<01:52, 285.55 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15578/47780 [00:51<01:34, 338.99 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15460/47780 [00:51<01:33, 344.51 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15457/47780 [00:51<01:51, 291.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6276/47780 [00:51<02:19, 297.96 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16779/47780 [00:51<01:45, 293.37 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13460/47780 [00:51<02:00, 285.54 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15605/47780 [00:51<01:45, 304.21 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15565/47780 [00:51<01:53, 283.26 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15613/47780 [00:51<01:41, 316.32 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15495/47780 [00:51<01:38, 327.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15496/47780 [00:51<01:41, 317.91 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16813/47780 [00:51<01:42, 302.93 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13498/47780 [00:51<01:51, 308.70 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15636/47780 [00:51<01:47, 299.33 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15603/47780 [00:51<01:45, 303.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15646/47780 [00:51<01:42, 313.66 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15529/47780 [00:51<01:45, 304.46 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15529/47780 [00:51<01:43, 312.12 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13530/47780 [00:51<01:52, 304.65 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16844/47780 [00:51<01:47, 288.58 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15637/47780 [00:51<01:43, 310.56 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15679/47780 [00:51<01:42, 314.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15667/47780 [00:52<01:54, 280.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15562/47780 [00:51<01:41, 316.10 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15561/47780 [00:51<01:49, 293.19 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13564/47780 [00:52<01:51, 308.05 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16874/47780 [00:52<01:47, 288.73 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6347/47780 [00:51<02:30, 274.47 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15669/47780 [00:52<01:43, 309.46 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15707/47780 [00:52<01:42, 312.73 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15716/47780 [00:52<01:37, 329.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15594/47780 [00:52<01:41, 317.06 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15598/47780 [00:52<01:42, 313.47 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16905/47780 [00:52<01:48, 284.86 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13595/47780 [00:52<01:55, 294.87 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6407/47780 [00:52<02:17, 301.70 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15700/47780 [00:52<01:43, 309.52 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15739/47780 [00:52<01:48, 294.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15751/47780 [00:52<01:42, 311.33 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15626/47780 [00:52<01:44, 307.30 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15633/47780 [00:52<01:41, 316.69 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13626/47780 [00:52<01:55, 296.06 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16934/47780 [00:52<01:56, 265.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15731/47780 [00:52<01:46, 302.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15662/47780 [00:52<01:39, 322.13 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15784/47780 [00:52<01:45, 303.14 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15769/47780 [00:52<01:53, 281.24 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15669/47780 [00:52<01:37, 328.55 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6462/47780 [00:52<02:18, 298.08 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13656/47780 [00:52<01:54, 296.80 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15764/47780 [00:52<01:44, 307.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 16963/47780 [00:52<01:54, 269.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15818/47780 [00:52<01:42, 313.13 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15695/47780 [00:52<01:42, 313.40 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15803/47780 [00:52<01:51, 287.74 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15706/47780 [00:52<01:35, 334.56 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13694/47780 [00:52<01:48, 315.46 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15806/47780 [00:52<01:34, 340.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 16992/47780 [00:52<01:52, 274.81 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15729/47780 [00:52<01:40, 317.59 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15740/47780 [00:52<01:36, 333.07 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15850/47780 [00:52<01:46, 298.64 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15834/47780 [00:52<01:51, 286.78 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6509/47780 [00:52<02:26, 282.27 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13727/47780 [00:52<01:47, 318.07 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17025/47780 [00:52<01:45, 290.32 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15841/47780 [00:52<01:34, 339.02 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15774/47780 [00:52<01:36, 332.00 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15887/47780 [00:52<01:40, 316.11 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15762/47780 [00:52<01:44, 306.84 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15864/47780 [00:52<01:52, 283.09 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13761/47780 [00:52<01:45, 321.16 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17055/47780 [00:52<01:48, 283.67 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6550/47780 [00:52<02:26, 281.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15875/47780 [00:52<01:39, 320.09 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15808/47780 [00:52<01:37, 327.25 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15794/47780 [00:52<01:43, 308.06 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15922/47780 [00:52<01:40, 316.78 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15905/47780 [00:52<01:41, 313.59 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13794/47780 [00:52<01:45, 323.36 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17084/47780 [00:52<01:51, 275.95 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15913/47780 [00:52<01:37, 326.43 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15845/47780 [00:52<01:35, 335.60 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15954/47780 [00:52<01:40, 317.62 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15825/47780 [00:52<01:43, 307.75 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6587/47780 [00:52<02:32, 269.78 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15937/47780 [00:52<01:42, 311.10 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13828/47780 [00:52<01:44, 324.43 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17121/47780 [00:52<01:41, 302.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15947/47780 [00:52<01:37, 325.85 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15856/47780 [00:52<01:43, 308.38 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15986/47780 [00:52<01:42, 311.25 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15972/47780 [00:53<01:39, 319.25 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13861/47780 [00:52<01:45, 322.65 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15879/47780 [00:52<01:40, 317.34 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6620/47780 [00:52<02:32, 270.66 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17154/47780 [00:53<01:40, 303.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15981/47780 [00:52<01:37, 326.92 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15890/47780 [00:53<01:42, 310.59 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 16006/47780 [00:53<01:39, 319.24 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16019/47780 [00:53<01:46, 299.52 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15911/47780 [00:53<01:42, 312.29 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13894/47780 [00:53<01:50, 306.46 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6651/47780 [00:53<02:36, 262.49 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17185/47780 [00:53<01:43, 295.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16014/47780 [00:53<01:43, 306.71 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15930/47780 [00:53<01:36, 328.96 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16051/47780 [00:53<01:30, 351.12 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15943/47780 [00:53<01:43, 307.51 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13925/47780 [00:53<01:50, 307.15 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16055/47780 [00:53<01:43, 306.23 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17219/47780 [00:53<01:39, 308.00 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6680/47780 [00:53<02:35, 263.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16045/47780 [00:53<01:43, 307.57 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15963/47780 [00:53<01:36, 328.76 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16087/47780 [00:53<01:31, 345.65 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15981/47780 [00:53<01:36, 327.95 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13958/47780 [00:53<01:51, 303.20 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16089/47780 [00:53<01:42, 308.74 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17254/47780 [00:53<01:35, 320.08 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6710/47780 [00:53<02:34, 266.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16076/47780 [00:53<01:44, 304.51 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 16000/47780 [00:53<01:34, 337.27 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16125/47780 [00:53<01:29, 355.05 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16128/47780 [00:53<01:36, 327.77 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13989/47780 [00:53<01:53, 298.47 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16014/47780 [00:53<01:45, 300.25 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6738/47780 [00:53<02:36, 261.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17287/47780 [00:53<01:41, 301.22 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16107/47780 [00:53<01:48, 290.83 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16035/47780 [00:53<01:33, 340.82 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16164/47780 [00:53<01:33, 336.79 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16161/47780 [00:53<01:37, 323.16 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16052/47780 [00:53<01:39, 319.20 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14019/47780 [00:53<01:59, 282.66 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6769/47780 [00:53<02:30, 272.04 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17324/47780 [00:53<01:38, 310.70 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16140/47780 [00:53<01:45, 300.73 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16070/47780 [00:53<01:34, 335.86 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16205/47780 [00:53<01:30, 349.88 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16195/47780 [00:53<01:37, 324.18 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16085/47780 [00:53<01:39, 317.85 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14057/47780 [00:53<01:51, 303.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6801/47780 [00:53<02:24, 284.34 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17357/47780 [00:53<01:40, 302.55 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16171/47780 [00:53<01:51, 283.53 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16104/47780 [00:53<01:39, 317.95 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16242/47780 [00:53<01:28, 355.54 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16229/47780 [00:53<01:38, 321.44 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6831/47780 [00:53<02:24, 283.68 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14088/47780 [00:53<01:55, 291.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16120/47780 [00:53<01:45, 300.36 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17388/47780 [00:53<01:44, 291.34 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16202/47780 [00:53<01:49, 288.09 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16149/47780 [00:53<01:29, 351.81 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16281/47780 [00:53<01:26, 365.33 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16262/47780 [00:53<01:37, 323.66 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14126/47780 [00:53<01:48, 308.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6860/47780 [00:53<02:30, 272.41 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16152/47780 [00:53<01:47, 293.04 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17418/47780 [00:53<01:45, 287.03 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16232/47780 [00:53<01:56, 270.33 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16318/47780 [00:53<01:28, 354.53 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16185/47780 [00:53<01:34, 335.00 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16305/47780 [00:53<01:30, 349.09 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6893/47780 [00:53<02:21, 287.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14161/47780 [00:53<01:46, 314.25 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17447/47780 [00:54<01:46, 285.40 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16183/47780 [00:53<01:54, 276.88 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16267/47780 [00:54<01:48, 291.36 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16219/47780 [00:54<01:35, 329.21 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16357/47780 [00:54<01:28, 356.48 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16341/47780 [00:54<01:33, 337.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14196/47780 [00:54<01:43, 324.05 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17478/47780 [00:54<01:44, 289.09 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6923/47780 [00:54<02:35, 262.08 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16212/47780 [00:54<01:53, 277.11 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16299/47780 [00:54<01:46, 296.48 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16395/47780 [00:54<01:26, 362.87 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16255/47780 [00:54<01:33, 337.67 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16376/47780 [00:54<01:33, 337.28 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14230/47780 [00:54<01:50, 304.23 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6952/47780 [00:54<02:33, 266.66 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17507/47780 [00:54<01:47, 282.89 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16246/47780 [00:54<01:49, 288.21 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16291/47780 [00:54<01:32, 340.26 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16432/47780 [00:54<01:26, 361.19 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16329/47780 [00:54<01:54, 275.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16411/47780 [00:54<01:32, 337.44 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14266/47780 [00:54<01:45, 316.17 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16279/47780 [00:54<01:45, 299.51 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6980/47780 [00:54<02:34, 264.05 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17536/47780 [00:54<01:53, 265.90 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16334/47780 [00:54<01:27, 357.92 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16358/47780 [00:54<01:54, 273.32 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16445/47780 [00:54<01:33, 335.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16469/47780 [00:54<01:35, 329.11 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14298/47780 [00:54<01:45, 317.08 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7007/47780 [00:54<02:34, 263.25 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16310/47780 [00:54<01:46, 295.89 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17570/47780 [00:54<01:47, 281.15 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16386/47780 [00:54<01:55, 272.48 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16370/47780 [00:54<01:32, 338.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16479/47780 [00:54<01:36, 324.01 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16503/47780 [00:54<01:38, 318.29 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14330/47780 [00:54<01:46, 314.63 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7034/47780 [00:54<02:35, 262.30 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16343/47780 [00:54<01:43, 304.84 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17599/47780 [00:54<01:50, 274.30 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16422/47780 [00:54<01:46, 293.28 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16405/47780 [00:54<01:35, 327.49 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16521/47780 [00:54<01:29, 347.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16546/47780 [00:54<01:29, 348.58 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14362/47780 [00:54<01:48, 309.03 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7071/47780 [00:54<02:19, 292.73 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16376/47780 [00:54<01:41, 309.48 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17627/47780 [00:54<01:52, 267.13 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16455/47780 [00:54<01:46, 294.10 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16563/47780 [00:54<01:25, 364.33 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16440/47780 [00:54<01:35, 328.97 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16583/47780 [00:54<01:31, 339.51 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14397/47780 [00:54<01:45, 317.18 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16408/47780 [00:54<01:45, 298.65 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7101/47780 [00:54<02:27, 275.83 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17662/47780 [00:54<01:45, 286.76 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16608/47780 [00:54<01:20, 388.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16481/47780 [00:54<01:32, 337.64 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16487/47780 [00:54<01:53, 276.18 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14430/47780 [00:54<01:43, 320.79 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16618/47780 [00:54<01:34, 330.81 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7138/47780 [00:54<02:15, 300.42 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16439/47780 [00:54<01:48, 288.78 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17693/47780 [00:54<01:44, 286.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16647/47780 [00:54<01:24, 368.06 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16515/47780 [00:54<01:34, 330.99 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16522/47780 [00:54<01:46, 293.21 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14464/47780 [00:54<01:42, 326.29 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16661/47780 [00:54<01:27, 354.92 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7170/47780 [00:54<02:16, 297.48 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16470/47780 [00:54<01:47, 291.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17727/47780 [00:55<01:40, 298.55 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16552/47780 [00:54<01:45, 294.63 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16697/47780 [00:54<01:27, 356.14 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16549/47780 [00:54<01:37, 319.23 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14501/47780 [00:55<01:40, 331.52 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16685/47780 [00:55<01:30, 343.95 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16506/47780 [00:55<01:41, 307.48 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7201/47780 [00:55<02:18, 293.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17757/47780 [00:55<01:41, 295.20 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16589/47780 [00:55<01:39, 312.96 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14535/47780 [00:55<01:40, 330.19 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16733/47780 [00:55<01:28, 349.48 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16586/47780 [00:55<01:35, 326.04 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16541/47780 [00:55<01:37, 319.42 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16720/47780 [00:55<01:41, 305.85 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7234/47780 [00:55<02:22, 284.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17791/47780 [00:55<01:40, 298.19 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14578/47780 [00:55<01:33, 355.17 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16621/47780 [00:55<01:43, 300.87 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16619/47780 [00:55<01:41, 305.93 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16769/47780 [00:55<01:35, 323.09 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16579/47780 [00:55<01:33, 333.13 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16756/47780 [00:55<01:37, 317.86 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7271/47780 [00:55<02:12, 305.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17828/47780 [00:55<01:34, 318.49 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14622/47780 [00:55<01:28, 375.44 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16652/47780 [00:55<01:44, 296.68 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16657/47780 [00:55<01:36, 323.27 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16809/47780 [00:55<01:30, 343.82 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16615/47780 [00:55<01:33, 333.34 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7302/47780 [00:55<02:12, 306.18 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17860/47780 [00:55<01:34, 315.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16789/47780 [00:55<01:45, 294.44 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14660/47780 [00:55<01:29, 369.23 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16686/47780 [00:55<01:42, 303.18 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16845/47780 [00:55<01:29, 344.57 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16690/47780 [00:55<01:37, 318.13 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16650/47780 [00:55<01:33, 333.84 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7334/47780 [00:55<02:13, 303.22 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17903/47780 [00:55<01:27, 340.65 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16820/47780 [00:55<01:44, 295.62 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14700/47780 [00:55<01:28, 372.72 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16717/47780 [00:55<01:42, 304.04 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16723/47780 [00:55<01:37, 317.86 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16884/47780 [00:55<01:29, 345.61 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16687/47780 [00:55<01:32, 336.80 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17942/47780 [00:55<01:24, 354.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7365/47780 [00:55<02:18, 291.42 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16851/47780 [00:55<01:47, 287.17 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16748/47780 [00:55<01:42, 302.02 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16924/47780 [00:55<01:26, 357.10 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16769/47780 [00:55<01:28, 350.02 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14738/47780 [00:55<01:36, 342.84 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16723/47780 [00:55<01:31, 339.65 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7395/47780 [00:55<02:20, 287.28 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16882/47780 [00:55<01:45, 292.05 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17978/47780 [00:55<01:35, 312.34 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16779/47780 [00:55<01:45, 294.82 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14777/47780 [00:55<01:32, 355.60 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16757/47780 [00:55<01:32, 335.48 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16805/47780 [00:55<01:33, 332.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16960/47780 [00:55<01:32, 334.27 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7424/47780 [00:55<02:21, 285.39 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16914/47780 [00:55<01:43, 297.90 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18011/47780 [00:55<01:36, 308.82 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16813/47780 [00:55<01:44, 297.30 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14817/47780 [00:55<01:30, 364.36 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16793/47780 [00:55<01:30, 342.53 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16842/47780 [00:55<01:32, 333.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 16994/47780 [00:55<01:33, 328.89 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7461/47780 [00:55<02:13, 302.75 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16947/47780 [00:55<01:41, 303.35 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18043/47780 [00:56<01:35, 310.73 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14854/47780 [00:55<01:33, 354.01 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16876/47780 [00:55<01:32, 334.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16843/47780 [00:56<01:57, 262.54 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17028/47780 [00:56<01:38, 311.63 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16828/47780 [00:56<01:40, 309.07 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16982/47780 [00:56<01:38, 313.19 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7492/47780 [00:56<02:19, 288.52 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18075/47780 [00:56<01:36, 307.61 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14890/47780 [00:56<01:33, 351.65 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16910/47780 [00:56<01:35, 321.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16870/47780 [00:56<01:58, 261.73 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16872/47780 [00:56<01:29, 344.49 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17022/47780 [00:56<01:30, 338.07 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7521/47780 [00:56<02:21, 285.31 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17060/47780 [00:56<01:45, 291.64 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18113/47780 [00:56<01:32, 319.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14926/47780 [00:56<01:34, 347.60 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16943/47780 [00:56<01:39, 310.67 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16897/47780 [00:56<02:01, 254.21 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17061/47780 [00:56<01:26, 353.15 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16910/47780 [00:56<01:30, 339.33 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17101/47780 [00:56<01:35, 319.65 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7554/47780 [00:56<02:19, 288.57 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18146/47780 [00:56<01:42, 289.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14961/47780 [00:56<01:40, 327.43 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16985/47780 [00:56<01:31, 336.95 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16945/47780 [00:56<01:30, 341.93 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16923/47780 [00:56<02:05, 246.34 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17098/47780 [00:56<01:31, 334.43 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17134/47780 [00:56<01:37, 315.77 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7583/47780 [00:56<02:25, 276.69 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18179/47780 [00:56<01:39, 297.33 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 15002/47780 [00:56<01:34, 347.28 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17022/47780 [00:56<01:29, 342.41 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16980/47780 [00:56<01:29, 344.16 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16955/47780 [00:56<01:59, 258.19 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17134/47780 [00:56<01:30, 337.89 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17178/47780 [00:56<01:28, 346.07 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7612/47780 [00:56<02:23, 280.35 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15039/47780 [00:56<01:34, 345.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18210/47780 [00:56<01:40, 294.32 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16982/47780 [00:56<01:59, 258.74 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17015/47780 [00:56<01:35, 323.50 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17214/47780 [00:56<01:31, 334.67 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7643/47780 [00:56<02:22, 282.35 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17169/47780 [00:56<01:37, 312.77 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17057/47780 [00:56<01:43, 296.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15075/47780 [00:56<01:34, 345.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18240/47780 [00:56<01:44, 283.48 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17009/47780 [00:56<01:57, 261.37 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17053/47780 [00:56<01:31, 335.81 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17252/47780 [00:56<01:27, 347.21 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7686/47780 [00:56<02:05, 318.88 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17099/47780 [00:56<01:35, 322.45 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17201/47780 [00:56<01:41, 301.81 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15110/47780 [00:56<01:35, 342.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18272/47780 [00:56<01:40, 292.63 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17038/47780 [00:56<01:55, 266.94 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17087/47780 [00:56<01:32, 333.18 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17288/47780 [00:56<01:27, 347.26 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7722/47780 [00:56<02:03, 324.91 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17133/47780 [00:56<01:34, 323.68 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17233/47780 [00:56<01:41, 300.30 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18311/47780 [00:56<01:32, 317.35 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15145/47780 [00:56<01:43, 316.11 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17067/47780 [00:56<01:53, 270.28 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17126/47780 [00:56<01:27, 349.27 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17325/47780 [00:56<01:26, 353.69 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7755/47780 [00:56<02:12, 302.20 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17268/47780 [00:56<01:39, 307.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17167/47780 [00:56<01:40, 304.35 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18344/47780 [00:57<01:36, 303.67 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15179/47780 [00:56<01:42, 319.26 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17104/47780 [00:56<01:43, 295.87 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17162/47780 [00:56<01:28, 344.41 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17361/47780 [00:56<01:30, 336.00 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17299/47780 [00:57<01:39, 307.07 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7797/47780 [00:56<02:00, 330.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17213/47780 [00:57<01:29, 342.66 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18376/47780 [00:57<01:35, 307.90 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17146/47780 [00:57<01:32, 331.66 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17202/47780 [00:57<01:26, 352.54 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15212/47780 [00:57<01:53, 287.04 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17395/47780 [00:57<01:34, 320.74 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17332/47780 [00:57<01:37, 310.92 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7832/47780 [00:57<01:59, 334.49 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17251/47780 [00:57<01:35, 321.15 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17180/47780 [00:57<01:32, 330.32 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18409/47780 [00:57<01:39, 294.40 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17238/47780 [00:57<01:29, 341.50 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15243/47780 [00:57<01:51, 292.94 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7866/47780 [00:57<02:02, 326.68 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17364/47780 [00:57<01:41, 299.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17430/47780 [00:57<01:39, 305.26 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17214/47780 [00:57<01:32, 332.13 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17285/47780 [00:57<01:35, 319.45 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18439/47780 [00:57<01:41, 289.15 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17276/47780 [00:57<01:27, 349.88 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15275/47780 [00:57<01:49, 297.23 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7906/47780 [00:57<01:54, 347.42 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17396/47780 [00:57<01:41, 298.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17461/47780 [00:57<01:40, 301.15 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17318/47780 [00:57<01:34, 322.28 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17248/47780 [00:57<01:35, 319.76 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18474/47780 [00:57<01:37, 299.83 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17316/47780 [00:57<01:24, 360.05 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15306/47780 [00:57<01:47, 300.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7942/47780 [00:57<02:00, 331.34 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17427/47780 [00:57<01:44, 291.46 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17492/47780 [00:57<01:44, 291.10 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17352/47780 [00:57<01:35, 319.90 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18510/47780 [00:57<01:36, 304.07 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17282/47780 [00:57<01:39, 305.24 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17360/47780 [00:57<01:21, 374.27 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15339/47780 [00:57<01:48, 298.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7977/47780 [00:57<01:59, 333.49 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17458/47780 [00:57<01:43, 294.12 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17528/47780 [00:57<01:38, 306.94 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17389/47780 [00:57<01:33, 326.70 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17317/47780 [00:57<01:35, 317.50 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18545/47780 [00:57<01:32, 314.85 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17398/47780 [00:57<01:27, 347.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15370/47780 [00:57<01:54, 282.88 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17490/47780 [00:57<01:41, 298.00 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8012/47780 [00:57<02:04, 319.74 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17559/47780 [00:57<01:41, 298.02 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17422/47780 [00:57<01:39, 306.59 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18577/47780 [00:57<01:37, 299.99 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17350/47780 [00:57<01:42, 297.47 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17434/47780 [00:57<01:27, 347.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15399/47780 [00:57<01:55, 281.43 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17523/47780 [00:57<01:38, 306.95 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17596/47780 [00:57<01:36, 314.33 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8045/47780 [00:57<02:07, 312.44 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17460/47780 [00:57<01:33, 323.58 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17381/47780 [00:57<01:41, 300.56 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17469/47780 [00:57<01:27, 346.59 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15435/47780 [00:57<01:46, 303.30 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18611/47780 [00:57<01:40, 288.93 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17557/47780 [00:57<01:37, 309.24 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17628/47780 [00:57<01:36, 312.05 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8080/47780 [00:57<02:08, 309.13 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17494/47780 [00:57<01:37, 310.74 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17412/47780 [00:57<01:45, 287.37 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17504/47780 [00:57<01:31, 330.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18641/47780 [00:58<01:41, 288.39 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17591/47780 [00:58<01:36, 311.41 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15466/47780 [00:57<01:55, 280.03 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17660/47780 [00:57<01:37, 307.55 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8112/47780 [00:57<02:10, 304.85 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17451/47780 [00:58<01:37, 312.17 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18670/47780 [00:58<01:45, 277.14 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17526/47780 [00:58<01:47, 282.42 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17538/47780 [00:58<01:34, 318.75 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17630/47780 [00:58<01:31, 329.52 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15499/47780 [00:58<01:52, 287.38 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8152/47780 [00:58<02:00, 328.69 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17691/47780 [00:58<01:45, 285.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17488/47780 [00:58<01:33, 324.38 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17561/47780 [00:58<01:40, 300.03 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18700/47780 [00:58<01:44, 277.31 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17571/47780 [00:58<01:35, 315.02 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17664/47780 [00:58<01:31, 329.31 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15529/47780 [00:58<01:55, 278.65 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8187/47780 [00:58<01:59, 330.48 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17720/47780 [00:58<01:45, 283.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17521/47780 [00:58<01:33, 322.16 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17604/47780 [00:58<01:30, 331.72 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18734/47780 [00:58<01:39, 291.34 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17698/47780 [00:58<01:30, 331.34 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17606/47780 [00:58<01:34, 319.25 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15562/47780 [00:58<01:52, 286.39 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17749/47780 [00:58<01:49, 273.33 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8221/47780 [00:58<02:08, 308.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17555/47780 [00:58<01:34, 320.45 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17639/47780 [00:58<01:30, 333.26 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18766/47780 [00:58<01:36, 299.39 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17639/47780 [00:58<01:36, 313.81 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17732/47780 [00:58<01:33, 319.86 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15597/47780 [00:58<01:47, 300.67 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8259/47780 [00:58<02:01, 324.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17777/47780 [00:58<01:55, 260.21 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17592/47780 [00:58<01:32, 327.13 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17684/47780 [00:58<01:23, 362.39 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18803/47780 [00:58<01:33, 310.19 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17684/47780 [00:58<01:26, 348.21 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17765/47780 [00:58<01:34, 318.94 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15630/47780 [00:58<01:45, 305.48 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17815/47780 [00:58<01:42, 292.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8292/47780 [00:58<02:06, 312.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17630/47780 [00:58<01:29, 338.36 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18835/47780 [00:58<01:32, 311.38 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17728/47780 [00:58<01:20, 372.83 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17722/47780 [00:58<01:29, 335.99 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17797/47780 [00:58<01:37, 308.36 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15674/47780 [00:58<01:36, 332.27 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17850/47780 [00:58<01:39, 299.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8324/47780 [00:58<02:08, 306.95 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17666/47780 [00:58<01:30, 333.03 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18873/47780 [00:58<01:28, 327.70 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17771/47780 [00:58<01:17, 385.56 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17834/47780 [00:58<01:32, 324.17 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17758/47780 [00:58<01:29, 335.51 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15709/47780 [00:58<01:37, 329.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17888/47780 [00:58<01:35, 311.41 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18907/47780 [00:58<01:27, 330.97 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8355/47780 [00:58<02:20, 280.37 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17702/47780 [00:58<01:33, 322.45 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17867/47780 [00:58<01:32, 324.42 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17805/47780 [00:58<01:22, 364.58 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17811/47780 [00:58<01:26, 347.60 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15742/47780 [00:58<01:40, 319.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17921/47780 [00:58<01:35, 313.18 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18941/47780 [00:58<01:28, 326.12 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8384/47780 [00:58<02:20, 280.03 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17901/47780 [00:59<01:33, 317.95 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17842/47780 [00:58<01:23, 358.24 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17735/47780 [00:58<01:38, 303.75 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15774/47780 [00:58<01:40, 319.21 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17847/47780 [00:58<01:29, 332.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17956/47780 [00:58<01:32, 323.55 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18974/47780 [00:59<01:29, 320.08 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8413/47780 [00:59<02:26, 268.01 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17933/47780 [00:59<01:34, 314.50 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15810/47780 [00:59<01:36, 330.89 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17768/47780 [00:59<01:39, 301.68 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17879/47780 [00:59<01:26, 344.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17885/47780 [00:59<01:27, 340.71 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17989/47780 [00:59<01:39, 298.04 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8441/47780 [00:59<02:26, 268.36 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17970/47780 [00:59<01:30, 329.96 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19008/47780 [00:59<01:35, 301.43 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15844/47780 [00:59<01:36, 329.98 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17799/47780 [00:59<01:40, 299.57 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17914/47780 [00:59<01:27, 339.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17920/47780 [00:59<01:31, 325.28 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18020/47780 [00:59<01:40, 294.83 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18006/47780 [00:59<01:28, 335.73 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8469/47780 [00:59<02:26, 268.56 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19044/47780 [00:59<01:31, 314.18 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17837/47780 [00:59<01:33, 319.51 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15879/47780 [00:59<01:39, 320.95 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17950/47780 [00:59<01:31, 326.30 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17954/47780 [00:59<01:30, 329.06 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18042/47780 [00:59<01:27, 338.79 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18050/47780 [00:59<01:44, 283.54 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19076/47780 [00:59<01:33, 305.50 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8496/47780 [00:59<02:35, 251.87 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15912/47780 [00:59<01:39, 319.35 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17983/47780 [00:59<01:31, 324.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17999/47780 [00:59<01:22, 359.05 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17870/47780 [00:59<01:44, 286.77 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18091/47780 [00:59<01:19, 375.80 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18080/47780 [00:59<01:47, 276.09 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19117/47780 [00:59<01:25, 334.30 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8526/47780 [00:59<02:31, 259.47 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15958/47780 [00:59<01:30, 352.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18018/47780 [00:59<01:30, 327.63 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17901/47780 [00:59<01:43, 289.87 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18037/47780 [00:59<01:24, 353.10 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18111/47780 [00:59<01:45, 282.40 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8554/47780 [00:59<02:31, 259.15 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19151/47780 [00:59<01:31, 311.60 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18051/47780 [00:59<01:32, 321.67 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18131/47780 [00:59<01:28, 334.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15994/47780 [00:59<01:35, 331.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18079/47780 [00:59<01:19, 371.54 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17935/47780 [00:59<01:40, 297.10 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18143/47780 [00:59<01:41, 292.66 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8586/47780 [00:59<02:23, 273.39 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19184/47780 [00:59<01:31, 313.12 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18169/47780 [00:59<01:26, 343.22 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18084/47780 [00:59<01:33, 316.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16039/47780 [00:59<01:28, 360.32 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17966/47780 [00:59<01:41, 294.12 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18117/47780 [00:59<01:23, 353.72 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18179/47780 [00:59<01:35, 308.42 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8615/47780 [00:59<02:20, 277.87 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19216/47780 [00:59<01:33, 304.76 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16077/47780 [00:59<01:26, 365.61 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18116/47780 [00:59<01:33, 316.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18205/47780 [00:59<01:26, 340.26 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18005/47780 [00:59<01:33, 317.24 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18153/47780 [00:59<01:25, 348.22 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18218/47780 [00:59<01:29, 329.42 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8649/47780 [00:59<02:13, 293.65 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19247/47780 [00:59<01:34, 302.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18148/47780 [00:59<01:35, 311.43 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18038/47780 [00:59<01:34, 313.78 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18199/47780 [00:59<01:18, 375.16 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16114/47780 [00:59<01:36, 329.38 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18240/47780 [01:00<01:36, 305.33 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18254/47780 [00:59<01:31, 321.91 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8680/47780 [00:59<02:11, 296.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19278/47780 [01:00<01:34, 301.15 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18180/47780 [01:00<01:37, 303.48 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16148/47780 [01:00<01:35, 332.03 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18070/47780 [01:00<01:38, 300.85 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18272/47780 [01:00<01:37, 303.13 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18237/47780 [01:00<01:24, 348.90 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18290/47780 [01:00<01:29, 329.07 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8710/47780 [01:00<02:18, 281.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19316/47780 [01:00<01:28, 322.88 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18218/47780 [01:00<01:32, 319.10 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18103/47780 [01:00<01:36, 306.76 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18287/47780 [01:00<01:16, 385.83 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16184/47780 [01:00<01:39, 317.87 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18303/47780 [01:00<01:41, 289.76 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18324/47780 [01:00<01:29, 328.11 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19349/47780 [01:00<01:30, 315.32 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8748/47780 [01:00<02:11, 296.13 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18259/47780 [01:00<01:26, 341.84 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18327/47780 [01:00<01:16, 385.46 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16217/47780 [01:00<01:43, 305.53 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18333/47780 [01:00<01:43, 283.37 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18134/47780 [01:00<01:49, 270.51 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18357/47780 [01:00<01:33, 314.02 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19391/47780 [01:00<01:22, 345.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8781/47780 [01:00<02:07, 305.54 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18294/47780 [01:00<01:26, 341.99 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16248/47780 [01:00<01:43, 303.47 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18362/47780 [01:00<01:44, 282.28 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18366/47780 [01:00<01:21, 360.71 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18175/47780 [01:00<01:37, 304.25 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18398/47780 [01:00<01:26, 337.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8812/47780 [01:00<02:09, 301.61 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19426/47780 [01:00<01:30, 313.68 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18329/47780 [01:00<01:33, 315.31 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18391/47780 [01:00<01:45, 277.79 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18403/47780 [01:00<01:22, 355.68 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18207/47780 [01:00<01:36, 305.02 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16279/47780 [01:00<01:48, 291.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18434/47780 [01:00<01:25, 344.07 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8843/47780 [01:00<02:18, 280.26 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19459/47780 [01:00<01:29, 317.93 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18364/47780 [01:00<01:30, 324.84 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18425/47780 [01:00<01:40, 292.06 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18445/47780 [01:00<01:19, 370.71 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16311/47780 [01:00<01:48, 290.63 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18469/47780 [01:00<01:26, 337.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18241/47780 [01:00<01:37, 301.45 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8884/47780 [01:00<02:03, 315.39 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18397/47780 [01:00<01:33, 315.53 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19492/47780 [01:00<01:34, 298.11 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18463/47780 [01:00<01:33, 313.47 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18507/47780 [01:00<01:23, 350.01 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16343/47780 [01:00<01:46, 295.57 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18272/47780 [01:00<01:37, 302.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18483/47780 [01:00<01:23, 352.90 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8917/47780 [01:00<02:07, 305.91 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18435/47780 [01:00<01:29, 326.38 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19524/47780 [01:00<01:33, 300.88 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18545/47780 [01:00<01:21, 358.56 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16379/47780 [01:00<01:41, 310.17 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18495/47780 [01:00<01:37, 301.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18304/47780 [01:00<01:39, 295.41 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18519/47780 [01:00<01:25, 341.73 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8949/47780 [01:00<02:10, 297.28 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19571/47780 [01:00<01:21, 347.49 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18470/47780 [01:00<01:32, 315.33 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16411/47780 [01:00<01:42, 305.70 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18355/47780 [01:00<01:23, 351.28 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18526/47780 [01:01<01:42, 284.75 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18554/47780 [01:00<01:28, 331.87 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18581/47780 [01:00<01:32, 314.82 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8982/47780 [01:00<02:06, 305.76 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19612/47780 [01:01<01:17, 361.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18504/47780 [01:01<01:31, 318.64 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16442/47780 [01:01<01:47, 290.66 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18596/47780 [01:01<01:22, 352.13 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18391/47780 [01:01<01:26, 338.10 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18555/47780 [01:01<01:52, 260.72 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9015/47780 [01:01<02:09, 299.08 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18614/47780 [01:01<01:40, 290.77 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19649/47780 [01:01<01:21, 343.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18541/47780 [01:01<01:28, 329.19 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16477/47780 [01:01<01:44, 300.41 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18632/47780 [01:01<01:25, 341.52 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18592/47780 [01:01<01:40, 289.35 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18426/47780 [01:01<01:32, 316.99 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18653/47780 [01:01<01:32, 313.24 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19689/47780 [01:01<01:18, 355.82 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18575/47780 [01:01<01:28, 328.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9049/47780 [01:01<02:11, 295.14 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16512/47780 [01:01<01:40, 310.78 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18669/47780 [01:01<01:24, 344.09 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18624/47780 [01:01<01:38, 294.75 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18459/47780 [01:01<01:32, 317.10 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18687/47780 [01:01<01:31, 316.95 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9087/47780 [01:01<02:01, 317.28 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19728/47780 [01:01<01:18, 357.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18608/47780 [01:01<01:36, 301.39 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16548/47780 [01:01<01:39, 313.99 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18655/47780 [01:01<01:38, 295.05 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18496/47780 [01:01<01:29, 328.03 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18704/47780 [01:01<01:31, 316.17 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19765/47780 [01:01<01:17, 360.52 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18720/47780 [01:01<01:36, 300.84 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18644/47780 [01:01<01:32, 314.02 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9120/47780 [01:01<02:15, 286.03 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16588/47780 [01:01<01:33, 334.48 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18693/47780 [01:01<01:32, 315.65 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18530/47780 [01:01<01:31, 320.74 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18737/47780 [01:01<01:34, 306.55 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18752/47780 [01:01<01:35, 302.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19802/47780 [01:01<01:23, 333.21 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9151/47780 [01:01<02:12, 291.83 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18676/47780 [01:01<01:37, 298.91 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16622/47780 [01:01<01:34, 328.29 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18726/47780 [01:01<01:30, 319.39 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18563/47780 [01:01<01:33, 312.70 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18783/47780 [01:01<01:35, 304.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18768/47780 [01:01<01:41, 286.47 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9181/47780 [01:01<02:12, 291.91 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19836/47780 [01:01<01:28, 315.54 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18707/47780 [01:01<01:39, 292.38 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16655/47780 [01:01<01:38, 317.55 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18595/47780 [01:01<01:33, 311.12 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18759/47780 [01:01<01:36, 301.44 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18814/47780 [01:01<01:36, 299.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18810/47780 [01:01<01:30, 321.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9213/47780 [01:01<02:08, 299.28 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19871/47780 [01:01<01:26, 323.47 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18741/47780 [01:01<01:36, 302.17 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16687/47780 [01:01<01:40, 309.05 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18802/47780 [01:01<01:26, 334.14 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18629/47780 [01:01<01:32, 315.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18848/47780 [01:01<01:34, 307.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18852/47780 [01:01<01:26, 333.82 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19904/47780 [01:01<01:29, 312.57 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18773/47780 [01:01<01:35, 303.79 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9245/47780 [01:01<02:18, 279.10 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16719/47780 [01:01<01:40, 310.25 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18671/47780 [01:01<01:24, 344.23 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18885/47780 [01:01<01:29, 321.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18836/47780 [01:02<01:33, 311.10 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19942/47780 [01:02<01:24, 329.99 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18805/47780 [01:02<01:35, 304.91 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18890/47780 [01:02<01:32, 312.50 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9276/47780 [01:01<02:16, 281.42 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16755/47780 [01:02<01:36, 322.16 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18706/47780 [01:02<01:29, 324.20 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18918/47780 [01:02<01:30, 320.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18868/47780 [01:02<01:37, 297.36 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18836/47780 [01:02<01:35, 302.74 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18935/47780 [01:02<01:22, 348.11 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19976/47780 [01:02<01:27, 318.19 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9305/47780 [01:02<02:23, 268.61 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16788/47780 [01:02<01:43, 300.16 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18744/47780 [01:02<01:27, 332.78 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18951/47780 [01:02<01:33, 308.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18901/47780 [01:02<01:36, 299.74 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18871/47780 [01:02<01:32, 312.80 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18971/47780 [01:02<01:22, 347.19 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20009/47780 [01:02<01:29, 309.77 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9337/47780 [01:02<02:17, 280.56 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16824/47780 [01:02<01:39, 309.82 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18780/47780 [01:02<01:25, 340.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18985/47780 [01:02<01:31, 313.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18932/47780 [01:02<01:36, 298.99 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18907/47780 [01:02<01:28, 326.22 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19008/47780 [01:02<01:27, 328.44 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20041/47780 [01:02<01:36, 288.06 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16856/47780 [01:02<01:40, 308.97 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9367/47780 [01:02<02:23, 267.24 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18815/47780 [01:02<01:25, 340.29 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19018/47780 [01:02<01:31, 315.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18972/47780 [01:02<01:28, 323.77 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18940/47780 [01:02<01:35, 302.80 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20074/47780 [01:02<01:33, 296.76 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16890/47780 [01:02<01:37, 316.13 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18854/47780 [01:02<01:23, 345.78 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9395/47780 [01:02<02:27, 259.79 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19043/47780 [01:02<01:34, 304.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19057/47780 [01:02<01:26, 333.03 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19005/47780 [01:02<01:31, 314.75 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18971/47780 [01:02<01:36, 299.77 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20112/47780 [01:02<01:28, 312.69 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9427/47780 [01:02<02:20, 272.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16923/47780 [01:02<01:43, 297.70 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18892/47780 [01:02<01:27, 328.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19075/47780 [01:02<01:37, 293.21 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19038/47780 [01:02<01:32, 312.17 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19091/47780 [01:02<01:38, 291.56 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19002/47780 [01:02<01:41, 284.23 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20149/47780 [01:02<01:25, 321.37 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9457/47780 [01:02<02:16, 280.30 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16960/47780 [01:02<01:37, 314.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19108/47780 [01:02<01:34, 302.08 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18926/47780 [01:02<01:28, 324.60 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19070/47780 [01:02<01:35, 300.77 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19122/47780 [01:02<01:39, 287.08 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19045/47780 [01:02<01:31, 314.90 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20183/47780 [01:02<01:24, 326.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9490/47780 [01:02<02:12, 288.08 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19139/47780 [01:02<01:40, 283.85 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16992/47780 [01:02<01:47, 286.84 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19102/47780 [01:02<01:33, 305.86 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18959/47780 [01:02<01:34, 305.93 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19153/47780 [01:02<01:37, 292.95 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19078/47780 [01:02<01:30, 318.88 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9521/47780 [01:02<02:11, 291.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20217/47780 [01:02<01:27, 315.79 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19181/47780 [01:02<01:29, 319.72 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17030/47780 [01:02<01:40, 305.45 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18990/47780 [01:02<01:37, 293.89 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19186/47780 [01:02<01:36, 296.87 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19133/47780 [01:03<01:42, 278.52 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9557/47780 [01:02<02:03, 309.50 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20256/47780 [01:03<01:22, 333.07 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19111/47780 [01:03<01:34, 301.83 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19214/47780 [01:03<01:31, 312.41 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19023/47780 [01:03<01:35, 301.03 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19219/47780 [01:03<01:34, 302.85 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19172/47780 [01:03<01:33, 305.49 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17062/47780 [01:03<01:50, 279.12 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9589/47780 [01:03<02:03, 310.20 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20295/47780 [01:03<01:19, 345.33 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19152/47780 [01:03<01:26, 331.15 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19068/47780 [01:03<01:25, 334.92 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19250/47780 [01:03<01:33, 304.82 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19246/47780 [01:03<01:38, 288.78 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17115/47780 [01:03<01:29, 340.96 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19204/47780 [01:03<01:36, 296.22 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20330/47780 [01:03<01:20, 338.98 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19187/47780 [01:03<01:28, 322.20 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9621/47780 [01:03<02:09, 295.42 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19110/47780 [01:03<01:21, 350.86 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19287/47780 [01:03<01:29, 317.86 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19281/47780 [01:03<01:36, 295.67 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17154/47780 [01:03<01:27, 349.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19236/47780 [01:03<01:35, 299.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19220/47780 [01:03<01:29, 320.22 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20365/47780 [01:03<01:25, 320.16 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9655/47780 [01:03<02:09, 295.01 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19159/47780 [01:03<01:13, 389.87 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17198/47780 [01:03<01:22, 370.62 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19271/47780 [01:03<01:30, 313.41 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19320/47780 [01:03<01:32, 307.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19311/47780 [01:03<01:40, 284.43 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9685/47780 [01:03<02:08, 296.26 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19253/47780 [01:03<01:31, 312.60 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20398/47780 [01:03<01:26, 315.89 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19347/47780 [01:03<01:33, 303.72 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19303/47780 [01:03<01:33, 305.21 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19355/47780 [01:03<01:31, 312.35 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19199/47780 [01:03<01:19, 359.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17236/47780 [01:03<01:26, 353.24 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20431/47780 [01:03<01:26, 316.34 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9715/47780 [01:03<02:15, 281.11 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19285/47780 [01:03<01:36, 295.11 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19378/47780 [01:03<01:34, 300.46 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19245/47780 [01:03<01:14, 382.97 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19387/47780 [01:03<01:31, 310.71 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19334/47780 [01:03<01:34, 299.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17272/47780 [01:03<01:29, 340.11 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20469/47780 [01:03<01:21, 334.20 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9750/47780 [01:03<02:07, 297.37 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19323/47780 [01:03<01:31, 311.71 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19411/47780 [01:03<01:32, 305.40 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19420/47780 [01:03<01:34, 300.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19284/47780 [01:03<01:18, 364.59 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19365/47780 [01:03<01:39, 286.79 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20503/47780 [01:03<01:23, 328.50 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17307/47780 [01:03<01:37, 312.49 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9780/47780 [01:03<02:08, 294.73 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19355/47780 [01:03<01:31, 310.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19447/47780 [01:03<01:28, 321.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19396/47780 [01:03<01:37, 289.78 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19326/47780 [01:03<01:17, 367.54 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19452/47780 [01:03<01:37, 292.03 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20544/47780 [01:03<01:17, 351.79 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17352/47780 [01:03<01:27, 348.48 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9822/47780 [01:03<01:55, 329.57 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19387/47780 [01:03<01:40, 281.59 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19480/47780 [01:03<01:34, 299.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19427/47780 [01:04<01:35, 295.40 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19485/47780 [01:03<01:33, 301.44 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20580/47780 [01:04<01:21, 334.64 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17388/47780 [01:03<01:31, 332.18 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9856/47780 [01:03<02:01, 311.45 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19364/47780 [01:04<01:27, 324.27 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19434/47780 [01:04<01:26, 327.81 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19513/47780 [01:04<01:32, 304.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19457/47780 [01:04<01:36, 293.05 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19516/47780 [01:04<01:37, 288.81 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20614/47780 [01:04<01:23, 325.30 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17424/47780 [01:04<01:31, 330.26 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9892/47780 [01:04<02:00, 314.87 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19473/47780 [01:04<01:22, 344.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19398/47780 [01:04<01:31, 309.82 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19546/47780 [01:04<01:32, 304.78 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19490/47780 [01:04<01:35, 297.16 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19551/47780 [01:04<01:34, 299.04 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20657/47780 [01:04<01:17, 350.56 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9927/47780 [01:04<01:56, 324.58 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17459/47780 [01:04<01:35, 318.42 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19431/47780 [01:04<01:30, 314.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19514/47780 [01:04<01:18, 359.06 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19583/47780 [01:04<01:30, 312.66 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19520/47780 [01:04<01:40, 281.89 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19582/47780 [01:04<01:34, 298.88 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20693/47780 [01:04<01:19, 341.59 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9974/47780 [01:04<01:46, 353.96 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19479/47780 [01:04<01:19, 355.53 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17494/47780 [01:04<01:33, 323.32 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19556/47780 [01:04<01:17, 364.06 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19617/47780 [01:04<01:29, 313.41 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19620/47780 [01:04<01:30, 311.09 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19549/47780 [01:04<01:48, 260.89 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20731/47780 [01:04<01:17, 348.49 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17527/47780 [01:04<01:33, 324.86 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10010/47780 [01:04<01:49, 343.38 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19533/47780 [01:04<01:11, 397.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19593/47780 [01:04<01:20, 350.36 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19649/47780 [01:04<01:34, 297.96 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19652/47780 [01:04<01:31, 306.80 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20771/47780 [01:04<01:16, 354.84 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19579/47780 [01:04<01:49, 257.56 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19575/47780 [01:04<01:10, 399.29 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17560/47780 [01:04<01:40, 299.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19631/47780 [01:04<01:19, 354.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10045/47780 [01:04<02:00, 313.50 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19679/47780 [01:04<01:35, 295.65 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19684/47780 [01:04<01:32, 303.29 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20812/47780 [01:04<01:13, 366.67 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19606/47780 [01:04<01:48, 260.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19617/47780 [01:04<01:14, 379.53 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19667/47780 [01:04<01:20, 348.14 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17591/47780 [01:04<01:47, 281.13 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10077/47780 [01:04<02:12, 285.43 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19715/47780 [01:04<01:33, 299.58 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19709/47780 [01:04<01:40, 278.10 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20849/47780 [01:04<01:13, 367.27 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19633/47780 [01:04<01:55, 244.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19702/47780 [01:04<01:20, 348.00 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19656/47780 [01:04<01:19, 355.07 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17624/47780 [01:04<01:44, 289.13 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10107/47780 [01:04<02:17, 274.77 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19745/47780 [01:04<01:39, 282.64 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20887/47780 [01:04<01:15, 354.76 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19738/47780 [01:04<01:46, 263.70 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19658/47780 [01:04<01:54, 245.72 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19737/47780 [01:04<01:24, 330.25 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19696/47780 [01:04<01:17, 360.29 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17654/47780 [01:04<01:44, 287.76 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10135/47780 [01:04<02:17, 272.84 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19774/47780 [01:04<01:41, 275.68 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20926/47780 [01:05<01:15, 356.63 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19686/47780 [01:05<01:51, 252.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19765/47780 [01:04<01:48, 257.23 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19771/47780 [01:05<01:29, 312.11 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17684/47780 [01:05<01:47, 281.13 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19733/47780 [01:05<01:21, 343.01 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10163/47780 [01:05<02:18, 272.24 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19806/47780 [01:05<01:37, 287.75 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20962/47780 [01:05<01:15, 353.50 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19792/47780 [01:05<01:47, 260.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19712/47780 [01:05<01:56, 240.21 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17722/47780 [01:05<01:39, 301.24 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19803/47780 [01:05<01:31, 304.32 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19768/47780 [01:05<01:22, 337.87 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10193/47780 [01:05<02:15, 277.16 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19835/47780 [01:05<01:38, 282.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19819/47780 [01:05<01:48, 258.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19743/47780 [01:05<01:50, 254.80 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20998/47780 [01:05<01:26, 309.53 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19841/47780 [01:05<01:26, 321.30 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10222/47780 [01:05<02:16, 274.77 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17754/47780 [01:05<01:47, 279.44 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19868/47780 [01:05<01:34, 294.65 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19803/47780 [01:05<01:30, 310.55 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19850/47780 [01:05<01:44, 266.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19771/47780 [01:05<01:48, 257.83 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21035/47780 [01:05<01:22, 325.17 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19880/47780 [01:05<01:21, 340.35 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10264/47780 [01:05<02:00, 311.99 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17813/47780 [01:05<01:24, 354.67 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19835/47780 [01:05<01:31, 306.92 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19898/47780 [01:05<01:39, 281.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19806/47780 [01:05<01:39, 281.99 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19877/47780 [01:05<01:51, 250.58 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21069/47780 [01:05<01:22, 322.39 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10303/47780 [01:05<01:52, 334.14 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19915/47780 [01:05<01:26, 320.77 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17856/47780 [01:05<01:20, 371.04 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19936/47780 [01:05<01:30, 308.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19866/47780 [01:05<01:33, 297.71 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19841/47780 [01:05<01:34, 294.50 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19912/47780 [01:05<01:42, 271.75 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21102/47780 [01:05<01:30, 294.99 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19954/47780 [01:05<01:22, 336.74 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17902/47780 [01:05<01:16, 391.36 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10337/47780 [01:05<02:04, 301.19 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19968/47780 [01:05<01:32, 301.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19896/47780 [01:05<01:36, 289.20 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19947/47780 [01:05<01:35, 290.17 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19873/47780 [01:05<01:38, 282.35 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21142/47780 [01:05<01:24, 315.98 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19989/47780 [01:05<01:29, 311.98 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17942/47780 [01:05<01:20, 372.85 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10371/47780 [01:05<02:00, 311.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20006/47780 [01:05<01:27, 316.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19926/47780 [01:05<01:38, 282.65 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19980/47780 [01:05<01:32, 301.32 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19907/47780 [01:05<01:34, 295.24 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21175/47780 [01:05<01:25, 312.93 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20035/47780 [01:05<01:18, 351.68 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17980/47780 [01:05<01:20, 370.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10405/47780 [01:05<02:01, 308.60 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19956/47780 [01:05<01:37, 284.66 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20040/47780 [01:05<01:30, 305.96 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20011/47780 [01:05<01:37, 286.03 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19937/47780 [01:05<01:34, 294.64 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21207/47780 [01:05<01:25, 311.15 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20073/47780 [01:05<01:19, 348.67 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18018/47780 [01:05<01:21, 365.07 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10441/47780 [01:05<01:57, 317.74 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19985/47780 [01:05<01:42, 269.88 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20072/47780 [01:05<01:33, 296.91 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20047/47780 [01:05<01:33, 298.03 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19967/47780 [01:06<01:39, 278.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21239/47780 [01:06<01:27, 303.54 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10480/47780 [01:05<01:52, 333.02 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20110/47780 [01:06<01:21, 339.33 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18055/47780 [01:06<01:25, 346.98 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20023/47780 [01:06<01:34, 294.73 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20109/47780 [01:06<01:29, 310.16 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20080/47780 [01:06<01:30, 306.69 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19996/47780 [01:06<01:42, 270.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21270/47780 [01:06<01:27, 302.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20145/47780 [01:06<01:21, 339.40 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18098/47780 [01:06<01:21, 365.95 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20143/47780 [01:06<01:26, 318.39 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10514/47780 [01:06<02:01, 306.80 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20112/47780 [01:06<01:32, 300.58 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20053/47780 [01:06<01:39, 277.88 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20032/47780 [01:06<01:37, 285.31 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21301/47780 [01:06<01:27, 302.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20183/47780 [01:06<01:18, 350.02 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18135/47780 [01:06<01:20, 366.98 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10550/47780 [01:06<01:56, 318.23 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20143/47780 [01:06<01:31, 301.94 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20176/47780 [01:06<01:30, 304.44 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20089/47780 [01:06<01:32, 299.99 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21332/47780 [01:06<01:27, 302.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20061/47780 [01:06<01:39, 277.51 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20219/47780 [01:06<01:22, 333.48 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18172/47780 [01:06<01:23, 355.30 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10584/47780 [01:06<01:54, 324.04 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20128/47780 [01:06<01:25, 322.86 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20174/47780 [01:06<01:33, 295.10 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20207/47780 [01:06<01:36, 286.94 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21366/47780 [01:06<01:25, 310.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20089/47780 [01:06<01:40, 274.52 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18208/47780 [01:06<01:23, 352.69 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20253/47780 [01:06<01:27, 314.52 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10618/47780 [01:06<02:00, 307.52 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20162/47780 [01:06<01:27, 315.64 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20204/47780 [01:06<01:38, 280.74 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20239/47780 [01:06<01:34, 292.68 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21402/47780 [01:06<01:21, 324.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20139/47780 [01:06<01:23, 330.89 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18244/47780 [01:06<01:24, 350.66 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20285/47780 [01:06<01:27, 312.49 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10654/47780 [01:06<01:56, 318.59 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20243/47780 [01:06<01:29, 307.86 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20269/47780 [01:06<01:33, 293.88 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20194/47780 [01:06<01:31, 303.02 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21437/47780 [01:06<01:20, 328.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20173/47780 [01:06<01:25, 322.64 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18280/47780 [01:06<01:25, 345.12 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10688/47780 [01:06<01:55, 320.97 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20305/47780 [01:06<01:29, 306.45 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21475/47780 [01:06<01:17, 339.50 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20225/47780 [01:06<01:32, 298.55 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20284/47780 [01:06<01:24, 325.38 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20317/47780 [01:06<01:39, 275.02 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20206/47780 [01:06<01:25, 323.99 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18315/47780 [01:06<01:28, 331.99 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10727/47780 [01:06<01:50, 336.66 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20318/47780 [01:06<01:23, 329.43 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20336/47780 [01:06<01:31, 300.37 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21509/47780 [01:06<01:19, 331.90 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20260/47780 [01:06<01:30, 302.80 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20346/47780 [01:06<01:43, 264.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20239/47780 [01:06<01:29, 307.96 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18349/47780 [01:06<01:28, 333.31 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10763/47780 [01:06<01:51, 331.92 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20352/47780 [01:06<01:23, 328.88 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20297/47780 [01:06<01:25, 321.26 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20367/47780 [01:06<01:33, 294.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21543/47780 [01:07<01:24, 309.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20270/47780 [01:07<01:30, 305.61 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20376/47780 [01:06<01:43, 266.03 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18383/47780 [01:06<01:31, 322.75 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20397/47780 [01:07<01:36, 282.34 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20330/47780 [01:07<01:29, 306.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20385/47780 [01:07<01:30, 304.02 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21576/47780 [01:07<01:25, 308.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10797/47780 [01:07<02:05, 293.59 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20414/47780 [01:07<01:33, 293.08 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20301/47780 [01:07<01:35, 288.31 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18416/47780 [01:07<01:37, 300.68 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20430/47780 [01:07<01:32, 295.29 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20370/47780 [01:07<01:24, 325.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20416/47780 [01:07<01:31, 299.71 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10839/47780 [01:07<01:56, 317.57 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20444/47780 [01:07<01:33, 291.29 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21608/47780 [01:07<01:29, 291.91 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20331/47780 [01:07<01:39, 275.50 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18451/47780 [01:07<01:33, 313.29 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20460/47780 [01:07<01:34, 290.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20410/47780 [01:07<01:19, 342.42 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20476/47780 [01:07<01:31, 298.11 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10872/47780 [01:07<01:58, 310.97 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20447/47780 [01:07<01:38, 277.92 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20360/47780 [01:07<01:38, 278.72 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21638/47780 [01:07<01:35, 273.24 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18483/47780 [01:07<01:36, 303.45 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20495/47780 [01:07<01:29, 303.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20450/47780 [01:07<01:17, 350.69 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20480/47780 [01:07<01:34, 288.61 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10904/47780 [01:07<02:04, 297.34 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20389/47780 [01:07<01:39, 276.64 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20507/47780 [01:07<01:40, 271.86 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21668/47780 [01:07<01:34, 277.30 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18522/47780 [01:07<01:29, 325.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20495/47780 [01:07<01:12, 374.55 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20528/47780 [01:07<01:31, 297.51 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20515/47780 [01:07<01:31, 298.88 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10939/47780 [01:07<01:59, 308.14 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20420/47780 [01:07<01:36, 282.86 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20540/47780 [01:07<01:36, 281.64 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21697/47780 [01:07<01:39, 260.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18558/47780 [01:07<01:32, 317.21 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20534/47780 [01:07<01:15, 362.14 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20566/47780 [01:07<01:28, 307.14 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20548/47780 [01:07<01:29, 304.21 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10974/47780 [01:07<01:57, 312.84 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20450/47780 [01:07<01:38, 278.23 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20570/47780 [01:07<01:38, 277.64 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21726/47780 [01:07<01:37, 265.95 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18590/47780 [01:07<01:31, 317.79 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20601/47780 [01:07<01:25, 318.90 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20573/47780 [01:07<01:15, 358.03 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20579/47780 [01:07<01:29, 302.39 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11011/47780 [01:07<01:51, 328.63 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20484/47780 [01:07<01:33, 292.50 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20601/47780 [01:07<01:34, 286.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21755/47780 [01:07<01:36, 269.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18622/47780 [01:07<01:36, 301.35 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20634/47780 [01:07<01:26, 314.93 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20610/47780 [01:07<01:16, 357.42 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11045/47780 [01:07<01:53, 324.38 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20516/47780 [01:07<01:31, 296.79 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20630/47780 [01:07<01:34, 287.27 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20610/47780 [01:07<01:37, 278.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21783/47780 [01:07<01:41, 255.36 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18653/47780 [01:07<01:39, 293.87 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20654/47780 [01:07<01:11, 380.49 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20667/47780 [01:07<01:27, 311.21 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20553/47780 [01:07<01:26, 314.17 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11080/47780 [01:07<01:55, 317.34 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20659/47780 [01:07<01:36, 280.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20650/47780 [01:07<01:29, 302.13 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21815/47780 [01:08<01:40, 258.96 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18684/47780 [01:07<01:37, 298.01 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20702/47780 [01:08<01:08, 396.66 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20704/47780 [01:08<01:24, 321.43 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11112/47780 [01:08<01:58, 310.72 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20694/47780 [01:08<01:35, 282.32 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20585/47780 [01:08<01:34, 289.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20682/47780 [01:08<01:32, 293.46 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21849/47780 [01:08<01:33, 277.61 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18719/47780 [01:08<01:36, 299.81 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20745/47780 [01:08<01:06, 405.51 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20737/47780 [01:08<01:25, 315.82 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11149/47780 [01:08<01:53, 324.02 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20728/47780 [01:08<01:30, 298.15 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20626/47780 [01:08<01:24, 319.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20725/47780 [01:08<01:22, 327.96 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21881/47780 [01:08<01:30, 286.14 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18751/47780 [01:08<01:35, 305.21 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20769/47780 [01:08<01:27, 307.36 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20786/47780 [01:08<01:13, 367.81 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11182/47780 [01:08<01:59, 305.05 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20768/47780 [01:08<01:25, 316.32 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20759/47780 [01:08<01:27, 310.16 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21911/47780 [01:08<01:29, 289.86 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20659/47780 [01:08<01:35, 283.64 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18783/47780 [01:08<01:36, 299.42 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20804/47780 [01:08<01:27, 309.01 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11213/47780 [01:08<01:59, 305.99 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20803/47780 [01:08<01:23, 322.34 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20824/47780 [01:08<01:19, 338.58 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20791/47780 [01:08<01:29, 303.09 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21944/47780 [01:08<01:27, 296.66 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20691/47780 [01:08<01:33, 290.15 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18818/47780 [01:08<01:34, 306.78 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20835/47780 [01:08<01:30, 296.15 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11247/47780 [01:08<01:56, 312.45 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20860/47780 [01:08<01:19, 340.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20836/47780 [01:08<01:26, 310.08 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21975/47780 [01:08<01:26, 298.75 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20822/47780 [01:08<01:31, 295.63 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20728/47780 [01:08<01:26, 311.35 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18855/47780 [01:08<01:30, 321.08 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20880/47780 [01:08<01:19, 338.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11280/47780 [01:08<01:56, 313.60 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20895/47780 [01:08<01:22, 326.03 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22010/47780 [01:08<01:22, 313.51 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20868/47780 [01:08<01:29, 299.32 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20853/47780 [01:08<01:30, 296.23 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20770/47780 [01:08<01:20, 334.43 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20923/47780 [01:08<01:14, 360.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18888/47780 [01:08<01:38, 293.53 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22042/47780 [01:08<01:22, 311.68 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20929/47780 [01:08<01:22, 325.81 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11312/47780 [01:08<02:07, 286.23 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20888/47780 [01:08<01:26, 311.22 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20805/47780 [01:08<01:21, 331.38 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20899/47780 [01:08<01:36, 277.95 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18933/47780 [01:08<01:26, 332.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20960/47780 [01:08<01:17, 347.19 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22076/47780 [01:08<01:22, 312.11 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20964/47780 [01:08<01:22, 324.54 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11344/47780 [01:08<02:06, 288.98 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20844/47780 [01:08<01:17, 347.60 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20934/47780 [01:08<01:32, 291.02 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20920/47780 [01:08<01:35, 281.29 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18969/47780 [01:08<01:25, 336.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20996/47780 [01:08<01:16, 350.31 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22115/47780 [01:08<01:17, 331.34 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11378/47780 [01:08<02:02, 296.59 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20997/47780 [01:08<01:26, 309.65 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20968/47780 [01:08<01:29, 301.09 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20960/47780 [01:08<01:27, 306.90 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20880/47780 [01:09<01:25, 315.24 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19004/47780 [01:08<01:27, 328.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21032/47780 [01:08<01:20, 331.08 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11416/47780 [01:08<01:54, 317.85 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22149/47780 [01:09<01:21, 315.33 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21029/47780 [01:09<01:28, 302.18 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21001/47780 [01:09<01:29, 300.85 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20913/47780 [01:09<01:24, 319.20 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20995/47780 [01:09<01:28, 302.18 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19038/47780 [01:09<01:28, 324.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21068/47780 [01:09<01:20, 333.59 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11456/47780 [01:09<01:47, 339.32 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22188/47780 [01:09<01:16, 332.95 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21074/47780 [01:09<01:18, 339.40 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21045/47780 [01:09<01:19, 337.53 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21031/47780 [01:09<01:24, 317.44 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19072/47780 [01:09<01:28, 325.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20946/47780 [01:09<01:29, 300.97 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21102/47780 [01:09<01:24, 315.74 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11492/47780 [01:09<01:48, 333.28 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21110/47780 [01:09<01:18, 337.62 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22222/47780 [01:09<01:23, 306.49 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21080/47780 [01:09<01:22, 324.35 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21064/47780 [01:09<01:27, 304.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20982/47780 [01:09<01:26, 308.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19105/47780 [01:09<01:33, 305.63 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11534/47780 [01:09<01:43, 350.52 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21134/47780 [01:09<01:31, 291.19 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21145/47780 [01:09<01:21, 325.76 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21123/47780 [01:09<01:15, 351.78 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22255/47780 [01:09<01:25, 297.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21097/47780 [01:09<01:26, 309.14 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19136/47780 [01:09<01:35, 300.41 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21014/47780 [01:09<01:31, 292.78 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11577/47780 [01:09<01:37, 373.02 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21166/47780 [01:09<01:29, 298.36 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21159/47780 [01:09<01:18, 339.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22292/47780 [01:09<01:22, 310.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21178/47780 [01:09<01:27, 303.81 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21129/47780 [01:09<01:30, 294.75 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19171/47780 [01:09<01:31, 313.44 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21044/47780 [01:09<01:31, 293.73 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11616/47780 [01:09<01:41, 357.21 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21198/47780 [01:09<01:16, 349.33 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21197/47780 [01:09<01:38, 269.81 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21209/47780 [01:09<01:27, 302.02 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22324/47780 [01:09<01:24, 302.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19203/47780 [01:09<01:30, 315.23 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21161/47780 [01:09<01:29, 298.30 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21074/47780 [01:09<01:33, 284.74 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11654/47780 [01:09<01:39, 363.46 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21231/47780 [01:09<01:33, 284.90 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21240/47780 [01:09<01:28, 301.02 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21235/47780 [01:09<01:19, 332.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22359/47780 [01:09<01:22, 308.92 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19236/47780 [01:09<01:30, 316.69 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21192/47780 [01:09<01:29, 297.90 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21103/47780 [01:09<01:33, 284.56 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11692/47780 [01:09<01:43, 348.54 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21276/47780 [01:09<01:24, 312.03 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21261/47780 [01:09<01:35, 276.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21269/47780 [01:09<01:19, 331.57 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19270/47780 [01:09<01:32, 308.19 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22391/47780 [01:09<01:27, 291.55 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21134/47780 [01:09<01:32, 288.67 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21222/47780 [01:09<01:35, 276.73 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11733/47780 [01:09<01:39, 361.67 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21312/47780 [01:09<01:22, 321.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21304/47780 [01:09<01:18, 336.11 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21296/47780 [01:09<01:33, 284.49 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22425/47780 [01:10<01:24, 299.27 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21164/47780 [01:10<01:34, 281.61 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21254/47780 [01:09<01:32, 285.29 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19301/47780 [01:09<01:41, 280.75 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11770/47780 [01:09<01:42, 351.95 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21338/47780 [01:10<01:18, 337.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21345/47780 [01:10<01:25, 309.02 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21331/47780 [01:10<01:28, 299.04 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22456/47780 [01:10<01:24, 299.04 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21193/47780 [01:10<01:35, 278.29 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21283/47780 [01:10<01:34, 281.76 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19330/47780 [01:10<01:43, 274.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11812/47780 [01:10<01:36, 370.99 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21373/47780 [01:10<01:21, 322.20 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21362/47780 [01:10<01:28, 298.06 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21377/47780 [01:10<01:27, 301.94 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22488/47780 [01:10<01:23, 301.27 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21223/47780 [01:10<01:33, 284.24 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21317/47780 [01:10<01:29, 296.93 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19358/47780 [01:10<01:47, 264.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11850/47780 [01:10<01:42, 350.51 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21398/47780 [01:10<01:24, 312.48 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21413/47780 [01:10<01:23, 317.02 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21406/47780 [01:10<01:23, 315.49 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21258/47780 [01:10<01:27, 301.97 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22519/47780 [01:10<01:25, 293.99 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21350/47780 [01:10<01:28, 299.45 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19387/47780 [01:10<01:46, 265.70 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21446/47780 [01:10<01:22, 318.32 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21430/47780 [01:10<01:24, 310.35 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11888/47780 [01:10<01:49, 328.69 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21438/47780 [01:10<01:24, 311.62 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22549/47780 [01:10<01:26, 292.40 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21394/47780 [01:10<01:18, 335.76 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21289/47780 [01:10<01:31, 288.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19417/47780 [01:10<01:46, 266.35 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21478/47780 [01:10<01:25, 308.07 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21462/47780 [01:10<01:27, 300.13 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22581/47780 [01:10<01:23, 300.21 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21470/47780 [01:10<01:28, 297.12 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21326/47780 [01:10<01:25, 308.38 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21429/47780 [01:10<01:20, 327.26 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19455/47780 [01:10<01:38, 288.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11922/47780 [01:10<02:12, 271.51 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21510/47780 [01:10<01:25, 307.92 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21493/47780 [01:10<01:28, 295.38 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21506/47780 [01:10<01:24, 311.01 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22613/47780 [01:10<01:29, 282.66 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21462/47780 [01:10<01:22, 318.53 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21358/47780 [01:10<01:34, 279.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19484/47780 [01:10<01:41, 279.52 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21541/47780 [01:10<01:26, 305.08 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21525/47780 [01:10<01:27, 299.83 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11952/47780 [01:10<02:24, 247.26 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21538/47780 [01:10<01:26, 302.18 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21494/47780 [01:10<01:23, 315.34 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22642/47780 [01:10<01:31, 274.72 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21398/47780 [01:10<01:26, 306.14 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19516/47780 [01:10<01:37, 290.62 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21574/47780 [01:10<01:24, 308.63 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21575/47780 [01:10<01:22, 318.81 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12011/47780 [01:10<01:52, 317.95 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21533/47780 [01:10<01:18, 333.21 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22674/47780 [01:10<01:27, 287.07 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21556/47780 [01:10<01:36, 271.86 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21436/47780 [01:10<01:20, 325.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19546/47780 [01:10<01:36, 293.21 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21605/47780 [01:10<01:27, 298.50 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21615/47780 [01:10<01:16, 341.53 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12049/47780 [01:10<01:48, 329.68 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21567/47780 [01:10<01:19, 331.04 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22707/47780 [01:10<01:25, 294.03 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21584/47780 [01:10<01:37, 267.88 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21470/47780 [01:11<01:22, 318.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19582/47780 [01:10<01:30, 312.37 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21636/47780 [01:11<01:29, 291.82 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12084/47780 [01:10<01:47, 331.59 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21601/47780 [01:11<01:18, 333.24 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21651/47780 [01:11<01:20, 324.88 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21613/47780 [01:11<01:36, 271.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22738/47780 [01:11<01:26, 291.04 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19614/47780 [01:11<01:33, 300.67 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21503/47780 [01:11<01:27, 301.68 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21668/47780 [01:11<01:27, 299.77 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12122/47780 [01:11<01:44, 340.78 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21711/47780 [01:11<01:05, 397.45 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21635/47780 [01:11<01:19, 327.67 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21641/47780 [01:11<01:36, 270.67 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22776/47780 [01:11<01:21, 308.65 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21534/47780 [01:11<01:26, 303.93 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19645/47780 [01:11<01:37, 289.88 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21702/47780 [01:11<01:23, 311.32 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12158/47780 [01:11<01:46, 334.55 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21669/47780 [01:11<01:36, 270.30 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22808/47780 [01:11<01:21, 306.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21752/47780 [01:11<01:12, 359.53 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21670/47780 [01:11<01:29, 292.60 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21565/47780 [01:11<01:29, 292.60 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19676/47780 [01:11<01:38, 286.15 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21735/47780 [01:11<01:29, 292.46 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12194/47780 [01:11<01:45, 338.40 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21700/47780 [01:11<01:33, 278.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22839/47780 [01:11<01:21, 307.31 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21806/47780 [01:11<01:05, 397.01 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21708/47780 [01:11<01:23, 313.57 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21595/47780 [01:11<01:30, 288.08 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19706/47780 [01:11<01:41, 277.59 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21767/47780 [01:11<01:27, 297.08 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12232/47780 [01:11<01:41, 349.63 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21728/47780 [01:11<01:33, 277.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22871/47780 [01:11<01:21, 307.03 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21847/47780 [01:11<01:07, 381.84 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21741/47780 [01:11<01:25, 304.39 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21624/47780 [01:11<01:30, 288.48 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19737/47780 [01:11<01:38, 283.57 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12268/47780 [01:11<01:45, 337.01 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21797/47780 [01:11<01:32, 281.47 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21756/47780 [01:11<01:39, 260.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22902/47780 [01:11<01:26, 288.02 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21656/47780 [01:11<01:28, 294.50 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21886/47780 [01:11<01:10, 364.78 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21772/47780 [01:11<01:29, 290.29 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19768/47780 [01:11<01:39, 281.38 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21826/47780 [01:11<01:32, 281.52 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21785/47780 [01:11<01:38, 263.81 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12303/47780 [01:11<01:51, 318.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22942/47780 [01:11<01:18, 316.33 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21693/47780 [01:11<01:23, 312.59 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21804/47780 [01:11<01:27, 298.11 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19799/47780 [01:11<01:36, 289.32 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21923/47780 [01:11<01:15, 343.63 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21856/47780 [01:11<01:33, 277.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21816/47780 [01:11<01:34, 273.75 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22974/47780 [01:11<01:19, 310.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12336/47780 [01:11<01:53, 311.82 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21726/47780 [01:11<01:22, 317.58 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21837/47780 [01:11<01:25, 303.94 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19829/47780 [01:11<01:40, 279.28 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21959/47780 [01:11<01:16, 335.87 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21893/47780 [01:11<01:27, 296.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21847/47780 [01:11<01:31, 283.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12370/47780 [01:11<01:51, 316.79 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23006/47780 [01:11<01:21, 302.58 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21758/47780 [01:11<01:22, 314.73 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21868/47780 [01:11<01:30, 286.40 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19859/47780 [01:11<01:41, 276.20 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21996/47780 [01:11<01:18, 329.07 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21877/47780 [01:11<01:30, 285.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12402/47780 [01:11<01:52, 314.05 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21923/47780 [01:11<01:32, 280.02 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23044/47780 [01:12<01:18, 315.23 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21792/47780 [01:12<01:21, 318.20 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21897/47780 [01:12<01:30, 287.01 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19898/47780 [01:12<01:32, 301.21 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22030/47780 [01:12<01:18, 328.65 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21906/47780 [01:12<01:30, 286.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21956/47780 [01:12<01:28, 292.51 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12434/47780 [01:12<01:57, 301.99 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21824/47780 [01:12<01:21, 318.69 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23076/47780 [01:12<01:22, 297.92 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21926/47780 [01:12<01:32, 279.75 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19934/47780 [01:12<01:29, 310.82 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22067/47780 [01:12<01:15, 339.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21942/47780 [01:12<01:23, 307.97 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21986/47780 [01:12<01:28, 291.16 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12467/47780 [01:12<01:55, 306.58 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21856/47780 [01:12<01:22, 314.96 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23106/47780 [01:12<01:25, 289.16 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21955/47780 [01:12<01:32, 278.20 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19969/47780 [01:12<01:28, 314.74 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22102/47780 [01:12<01:18, 328.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21973/47780 [01:12<01:29, 288.92 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22019/47780 [01:12<01:26, 299.05 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12503/47780 [01:12<01:49, 321.60 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21888/47780 [01:12<01:24, 305.96 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23139/47780 [01:12<01:23, 294.31 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21990/47780 [01:12<01:29, 289.09 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20005/47780 [01:12<01:26, 319.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22136/47780 [01:12<01:18, 327.47 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22003/47780 [01:12<01:32, 278.98 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12537/47780 [01:12<01:51, 315.94 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21919/47780 [01:12<01:25, 303.45 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22050/47780 [01:12<01:28, 290.85 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23169/47780 [01:12<01:24, 292.70 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22026/47780 [01:12<01:23, 308.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22169/47780 [01:12<01:18, 324.94 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20038/47780 [01:12<01:34, 293.31 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22034/47780 [01:12<01:29, 287.60 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22084/47780 [01:12<01:25, 299.28 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21950/47780 [01:12<01:27, 295.14 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12569/47780 [01:12<02:04, 283.84 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23199/47780 [01:12<01:29, 275.47 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22058/47780 [01:12<01:25, 301.46 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22212/47780 [01:12<01:12, 350.93 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22067/47780 [01:12<01:26, 296.27 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20068/47780 [01:12<01:35, 288.86 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22115/47780 [01:12<01:25, 298.65 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21980/47780 [01:12<01:32, 280.04 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12619/47780 [01:12<01:43, 339.05 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22089/47780 [01:12<01:25, 299.91 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23231/47780 [01:12<01:27, 279.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22261/47780 [01:12<01:07, 377.66 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22147/47780 [01:12<01:24, 303.85 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22098/47780 [01:12<01:27, 293.43 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20099/47780 [01:12<01:36, 285.39 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22020/47780 [01:12<01:22, 310.82 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12654/47780 [01:12<01:47, 327.60 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23268/47780 [01:12<01:20, 304.01 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22120/47780 [01:12<01:25, 300.08 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22299/47780 [01:12<01:08, 369.51 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22181/47780 [01:12<01:23, 308.39 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20130/47780 [01:12<01:35, 288.87 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22052/47780 [01:12<01:24, 303.10 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22128/47780 [01:12<01:38, 259.67 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22157/47780 [01:12<01:20, 316.60 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23305/47780 [01:12<01:17, 315.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12688/47780 [01:12<01:49, 320.44 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22341/47780 [01:12<01:06, 380.27 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22215/47780 [01:12<01:22, 310.51 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20166/47780 [01:12<01:31, 301.95 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22159/47780 [01:12<01:34, 270.11 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22083/47780 [01:13<01:26, 298.38 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22194/47780 [01:12<01:17, 331.99 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23346/47780 [01:13<01:11, 342.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12721/47780 [01:12<01:48, 322.70 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22250/47780 [01:13<01:19, 321.76 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20200/47780 [01:13<01:30, 305.71 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22380/47780 [01:13<01:17, 326.78 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22190/47780 [01:13<01:31, 280.68 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22114/47780 [01:13<01:26, 298.25 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23382/47780 [01:13<01:11, 343.51 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12754/47780 [01:13<01:48, 321.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22228/47780 [01:13<01:19, 319.50 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22288/47780 [01:13<01:15, 338.36 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20237/47780 [01:13<01:26, 316.91 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22415/47780 [01:13<01:17, 329.34 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22221/47780 [01:13<01:30, 283.03 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23417/47780 [01:13<01:10, 344.99 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22145/47780 [01:13<01:28, 290.85 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12788/47780 [01:13<01:49, 319.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22265/47780 [01:13<01:16, 332.28 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22322/47780 [01:13<01:18, 324.01 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20274/47780 [01:13<01:22, 331.73 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22260/47780 [01:13<01:22, 309.46 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23453/47780 [01:13<01:10, 345.57 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22179/47780 [01:13<01:24, 302.17 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12831/47780 [01:13<01:40, 347.28 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22449/47780 [01:13<01:21, 312.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22299/47780 [01:13<01:17, 328.25 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22359/47780 [01:13<01:15, 337.12 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20309/47780 [01:13<01:25, 322.22 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12867/47780 [01:13<01:42, 340.63 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22332/47780 [01:13<01:18, 324.79 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23488/47780 [01:13<01:14, 324.05 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22210/47780 [01:13<01:28, 287.75 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22292/47780 [01:13<01:29, 285.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22481/47780 [01:13<01:25, 295.54 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20350/47780 [01:13<01:19, 343.21 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22393/47780 [01:13<01:22, 309.45 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22370/47780 [01:13<01:15, 337.34 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23522/47780 [01:13<01:13, 328.20 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12902/47780 [01:13<01:44, 334.28 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22244/47780 [01:13<01:26, 295.95 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22333/47780 [01:13<01:21, 313.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22512/47780 [01:13<01:27, 290.14 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20385/47780 [01:13<01:20, 340.81 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22425/47780 [01:13<01:28, 286.85 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22406/47780 [01:13<01:14, 340.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22275/47780 [01:13<01:25, 299.83 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22366/47780 [01:13<01:23, 304.11 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12937/47780 [01:13<01:49, 317.04 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23556/47780 [01:13<01:19, 304.10 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22542/47780 [01:13<01:29, 280.55 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20420/47780 [01:13<01:23, 328.83 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22475/47780 [01:13<01:14, 341.39 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22441/47780 [01:13<01:16, 331.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22306/47780 [01:13<01:28, 288.77 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22398/47780 [01:13<01:24, 299.29 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12970/47780 [01:13<01:52, 310.17 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22573/47780 [01:13<01:29, 280.77 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23587/47780 [01:13<01:22, 293.10 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20458/47780 [01:13<01:20, 339.29 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22476/47780 [01:13<01:15, 336.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22511/47780 [01:13<01:16, 330.55 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22350/47780 [01:13<01:18, 324.73 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22429/47780 [01:13<01:25, 295.62 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22606/47780 [01:13<01:25, 292.88 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13002/47780 [01:13<01:58, 294.37 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23617/47780 [01:13<01:26, 279.67 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20494/47780 [01:13<01:19, 341.29 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22510/47780 [01:13<01:14, 337.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22545/47780 [01:13<01:18, 322.62 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22383/47780 [01:14<01:19, 319.09 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22460/47780 [01:13<01:25, 294.63 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22637/47780 [01:13<01:26, 291.74 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23646/47780 [01:14<01:26, 278.91 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13032/47780 [01:13<02:07, 271.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20529/47780 [01:14<01:21, 336.13 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22578/47780 [01:14<01:20, 313.72 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22417/47780 [01:14<01:18, 323.89 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22544/47780 [01:14<01:21, 309.46 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22667/47780 [01:14<01:25, 293.59 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22492/47780 [01:14<01:25, 296.68 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23675/47780 [01:14<01:26, 279.13 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13076/47780 [01:14<01:49, 315.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20563/47780 [01:14<01:27, 311.35 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22583/47780 [01:14<01:16, 328.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22528/47780 [01:14<01:21, 311.23 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22697/47780 [01:14<01:30, 276.46 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22610/47780 [01:14<01:29, 282.04 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23704/47780 [01:14<01:27, 276.29 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22451/47780 [01:14<01:26, 291.97 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13110/47780 [01:14<01:47, 322.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20595/47780 [01:14<01:29, 304.54 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22617/47780 [01:14<01:18, 320.72 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22560/47780 [01:14<01:22, 306.84 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23742/47780 [01:14<01:19, 302.15 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22483/47780 [01:14<01:25, 296.89 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22645/47780 [01:14<01:24, 296.44 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22725/47780 [01:14<01:36, 260.14 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13143/47780 [01:14<01:50, 313.58 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20626/47780 [01:14<01:32, 292.88 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22596/47780 [01:14<01:18, 321.90 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22650/47780 [01:14<01:23, 301.44 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22676/47780 [01:14<01:23, 299.92 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22519/47780 [01:14<01:22, 307.48 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23773/47780 [01:14<01:20, 297.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22754/47780 [01:14<01:36, 259.71 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13175/47780 [01:14<02:04, 278.33 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20673/47780 [01:14<01:20, 336.44 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22629/47780 [01:14<01:18, 320.54 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22710/47780 [01:14<01:20, 310.95 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22681/47780 [01:14<01:24, 295.63 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23810/47780 [01:14<01:16, 314.68 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22551/47780 [01:14<01:23, 300.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22781/47780 [01:14<01:35, 262.06 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13204/47780 [01:14<02:04, 278.58 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20708/47780 [01:14<01:22, 327.15 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22662/47780 [01:14<01:21, 308.91 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22744/47780 [01:14<01:19, 315.88 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22711/47780 [01:14<01:24, 296.58 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23842/47780 [01:14<01:15, 315.57 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22587/47780 [01:14<01:20, 313.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22814/47780 [01:14<01:30, 275.42 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20744/47780 [01:14<01:21, 332.67 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13233/47780 [01:14<02:09, 267.24 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22779/47780 [01:14<01:17, 321.99 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22741/47780 [01:14<01:24, 295.47 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22694/47780 [01:14<01:24, 295.21 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23874/47780 [01:14<01:18, 303.35 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22842/47780 [01:14<01:30, 276.22 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22619/47780 [01:14<01:25, 295.77 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20781/47780 [01:14<01:20, 335.53 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13261/47780 [01:14<02:09, 266.82 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22813/47780 [01:14<01:18, 316.78 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22724/47780 [01:14<01:25, 293.40 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23908/47780 [01:14<01:18, 303.41 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22870/47780 [01:14<01:31, 271.34 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22651/47780 [01:14<01:24, 295.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22771/47780 [01:14<01:37, 257.80 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20821/47780 [01:14<01:16, 353.67 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13289/47780 [01:14<02:10, 265.15 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22847/47780 [01:14<01:18, 319.14 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22763/47780 [01:14<01:18, 320.55 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22899/47780 [01:14<01:30, 273.92 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23940/47780 [01:15<01:20, 297.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22683/47780 [01:15<01:23, 302.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22819/47780 [01:14<01:21, 307.65 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13329/47780 [01:14<01:54, 299.82 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20857/47780 [01:15<01:19, 338.00 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22881/47780 [01:15<01:16, 324.98 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22798/47780 [01:15<01:16, 325.43 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22928/47780 [01:15<01:29, 278.50 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23973/47780 [01:15<01:18, 303.71 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22714/47780 [01:15<01:24, 297.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22856/47780 [01:15<01:17, 322.34 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20895/47780 [01:15<01:19, 340.23 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22838/47780 [01:15<01:11, 346.85 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13360/47780 [01:15<02:00, 286.00 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22914/47780 [01:15<01:20, 308.32 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24004/47780 [01:15<01:18, 302.65 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22745/47780 [01:15<01:23, 299.43 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22956/47780 [01:15<01:34, 263.52 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22890/47780 [01:15<01:17, 320.38 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20932/47780 [01:15<01:17, 344.54 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22881/47780 [01:15<01:07, 371.10 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13394/47780 [01:15<01:59, 288.63 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22951/47780 [01:15<01:17, 318.90 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24035/47780 [01:15<01:18, 300.70 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22777/47780 [01:15<01:22, 303.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22987/47780 [01:15<01:31, 270.55 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22923/47780 [01:15<01:24, 293.46 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20969/47780 [01:15<01:17, 347.78 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22919/47780 [01:15<01:08, 360.76 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13425/47780 [01:15<01:57, 291.96 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24066/47780 [01:15<01:20, 293.25 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22808/47780 [01:15<01:24, 295.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23015/47780 [01:15<01:32, 267.14 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22984/47780 [01:15<01:26, 286.46 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22954/47780 [01:15<01:26, 285.75 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21004/47780 [01:15<01:17, 343.32 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22956/47780 [01:15<01:12, 341.70 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13455/47780 [01:15<02:02, 280.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24100/47780 [01:15<01:18, 303.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22838/47780 [01:15<01:25, 290.15 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23042/47780 [01:15<01:35, 259.20 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23015/47780 [01:15<01:26, 286.51 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22984/47780 [01:15<01:30, 274.75 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13488/47780 [01:15<01:57, 291.37 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22991/47780 [01:15<01:14, 334.37 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21039/47780 [01:15<01:26, 310.82 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24136/47780 [01:15<01:14, 315.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22875/47780 [01:15<01:20, 309.39 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23069/47780 [01:15<01:38, 250.99 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23057/47780 [01:15<01:18, 315.74 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23018/47780 [01:15<01:25, 289.43 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13522/47780 [01:15<01:56, 294.97 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21071/47780 [01:15<01:29, 297.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24168/47780 [01:15<01:17, 306.39 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22908/47780 [01:15<01:22, 301.43 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23092/47780 [01:15<01:16, 324.82 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23100/47780 [01:15<01:33, 264.42 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23025/47780 [01:15<01:26, 286.55 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23048/47780 [01:15<01:24, 291.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13556/47780 [01:15<01:52, 304.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21102/47780 [01:15<01:28, 300.68 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24204/47780 [01:15<01:14, 318.07 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22948/47780 [01:15<01:15, 328.83 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23127/47780 [01:15<01:34, 260.12 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23075/47780 [01:15<01:12, 339.20 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23125/47780 [01:15<01:24, 293.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23078/47780 [01:15<01:27, 281.95 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24238/47780 [01:15<01:13, 320.69 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21133/47780 [01:15<01:31, 290.44 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22986/47780 [01:16<01:13, 335.74 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13588/47780 [01:15<02:01, 280.27 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23155/47780 [01:15<01:32, 265.35 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23111/47780 [01:15<01:13, 337.23 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23156/47780 [01:15<01:24, 291.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23107/47780 [01:15<01:27, 281.02 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24271/47780 [01:16<01:13, 319.65 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13625/47780 [01:16<01:52, 304.25 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21163/47780 [01:16<01:33, 284.39 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23020/47780 [01:16<01:15, 329.59 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23183/47780 [01:16<01:33, 263.97 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23192/47780 [01:16<01:20, 307.06 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23146/47780 [01:16<01:16, 321.84 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23142/47780 [01:16<01:23, 293.99 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24307/47780 [01:16<01:10, 331.31 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21192/47780 [01:16<01:35, 279.11 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23210/47780 [01:16<01:33, 262.52 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13657/47780 [01:16<02:02, 277.91 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23224/47780 [01:16<01:19, 307.18 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23054/47780 [01:16<01:26, 287.06 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23173/47780 [01:16<01:23, 295.04 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23180/47780 [01:16<01:22, 299.57 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21221/47780 [01:16<01:36, 275.79 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24341/47780 [01:16<01:19, 295.85 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23240/47780 [01:16<01:33, 261.33 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13687/47780 [01:16<02:01, 280.67 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23257/47780 [01:16<01:19, 310.19 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23091/47780 [01:16<01:20, 305.31 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23203/47780 [01:16<01:23, 295.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23211/47780 [01:16<01:21, 301.89 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21255/47780 [01:16<01:31, 290.64 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24373/47780 [01:16<01:17, 301.52 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23276/47780 [01:16<01:26, 282.79 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23292/47780 [01:16<01:17, 317.92 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13716/47780 [01:16<02:06, 269.94 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23126/47780 [01:16<01:17, 317.10 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23235/47780 [01:16<01:22, 296.59 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23242/47780 [01:16<01:28, 277.22 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21290/47780 [01:16<01:26, 307.34 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24404/47780 [01:16<01:21, 288.52 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23325/47780 [01:16<01:16, 317.95 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13751/47780 [01:16<01:57, 290.06 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23306/47780 [01:16<01:30, 269.38 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23161/47780 [01:16<01:16, 322.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23271/47780 [01:16<01:18, 311.32 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23284/47780 [01:16<01:20, 305.10 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21324/47780 [01:16<01:25, 309.76 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24437/47780 [01:16<01:18, 296.76 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23358/47780 [01:16<01:16, 317.63 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23195/47780 [01:16<01:15, 323.82 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23305/47780 [01:16<01:17, 315.90 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13781/47780 [01:16<02:05, 271.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23334/47780 [01:16<01:37, 249.93 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21358/47780 [01:16<01:24, 311.15 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23316/47780 [01:16<01:23, 293.29 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24468/47780 [01:16<01:17, 300.23 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23400/47780 [01:16<01:11, 343.21 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23232/47780 [01:16<01:13, 333.52 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13813/47780 [01:16<01:59, 284.68 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23338/47780 [01:16<01:18, 312.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23372/47780 [01:16<01:27, 278.90 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21390/47780 [01:16<01:25, 310.30 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23347/47780 [01:16<01:22, 294.47 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23266/47780 [01:16<01:13, 335.06 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23435/47780 [01:16<01:13, 329.42 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24499/47780 [01:16<01:23, 277.82 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13847/47780 [01:16<01:56, 290.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23402/47780 [01:16<01:25, 283.88 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23370/47780 [01:16<01:22, 294.48 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21422/47780 [01:16<01:25, 309.28 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23377/47780 [01:16<01:30, 269.86 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24529/47780 [01:17<01:22, 280.88 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23469/47780 [01:16<01:15, 321.89 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23300/47780 [01:17<01:17, 314.65 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13883/47780 [01:16<01:50, 306.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23431/47780 [01:16<01:25, 283.20 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23411/47780 [01:16<01:15, 323.19 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21454/47780 [01:16<01:25, 309.07 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23406/47780 [01:17<01:30, 269.59 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23502/47780 [01:17<01:14, 324.14 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13914/47780 [01:17<01:50, 307.35 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23332/47780 [01:17<01:19, 308.95 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23464/47780 [01:17<01:22, 293.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24558/47780 [01:17<01:26, 268.49 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23445/47780 [01:17<01:15, 320.57 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21488/47780 [01:17<01:22, 318.03 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23434/47780 [01:17<01:30, 269.44 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23535/47780 [01:17<01:17, 314.00 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23497/47780 [01:17<01:20, 303.46 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24586/47780 [01:17<01:25, 271.23 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23364/47780 [01:17<01:21, 299.28 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13945/47780 [01:17<01:56, 290.79 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23488/47780 [01:17<01:09, 351.19 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21522/47780 [01:17<01:21, 320.82 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23567/47780 [01:17<01:17, 313.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23462/47780 [01:17<01:32, 263.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23400/47780 [01:17<01:17, 316.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24617/47780 [01:17<01:25, 270.46 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13976/47780 [01:17<01:55, 293.46 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23528/47780 [01:17<01:27, 276.72 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23526/47780 [01:17<01:11, 340.25 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21557/47780 [01:17<01:19, 329.25 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23599/47780 [01:17<01:17, 311.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23496/47780 [01:17<01:26, 281.65 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24645/47780 [01:17<01:24, 272.67 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23435/47780 [01:17<01:15, 321.04 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23561/47780 [01:17<01:24, 287.99 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23565/47780 [01:17<01:08, 353.90 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21594/47780 [01:17<01:16, 341.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14006/47780 [01:17<02:02, 276.45 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23525/47780 [01:17<01:30, 268.92 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23631/47780 [01:17<01:21, 294.53 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24673/47780 [01:17<01:28, 260.00 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23468/47780 [01:17<01:20, 302.32 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23595/47780 [01:17<01:20, 299.21 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14038/47780 [01:17<01:57, 288.26 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23601/47780 [01:17<01:09, 348.04 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21630/47780 [01:17<01:18, 334.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23564/47780 [01:17<01:20, 300.96 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24703/47780 [01:17<01:25, 268.55 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23664/47780 [01:17<01:22, 293.71 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23641/47780 [01:17<01:10, 342.59 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23500/47780 [01:17<01:20, 302.82 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14071/47780 [01:17<01:53, 296.97 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23648/47780 [01:17<01:03, 382.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21666/47780 [01:17<01:18, 334.45 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23597/47780 [01:17<01:19, 303.53 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23707/47780 [01:17<01:12, 331.50 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24741/47780 [01:17<01:16, 299.82 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23534/47780 [01:17<01:18, 308.72 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21702/47780 [01:17<01:16, 341.80 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23676/47780 [01:17<01:13, 327.66 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14101/47780 [01:17<02:02, 275.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23687/47780 [01:17<01:12, 331.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23629/47780 [01:17<01:19, 304.81 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23742/47780 [01:17<01:12, 332.53 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24772/47780 [01:17<01:17, 295.72 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23567/47780 [01:17<01:20, 301.22 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21738/47780 [01:17<01:17, 335.16 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23710/47780 [01:17<01:17, 310.54 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14129/47780 [01:17<02:05, 267.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23726/47780 [01:17<01:09, 347.04 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24808/47780 [01:17<01:14, 307.32 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23660/47780 [01:17<01:26, 280.06 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23600/47780 [01:17<01:19, 302.50 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23776/47780 [01:17<01:18, 307.00 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21772/47780 [01:17<01:21, 318.14 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14158/47780 [01:17<02:08, 262.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23744/47780 [01:17<01:19, 302.01 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23764/47780 [01:18<01:16, 312.21 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24844/47780 [01:18<01:11, 322.20 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23632/47780 [01:18<01:19, 303.95 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23811/47780 [01:18<01:17, 308.41 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23689/47780 [01:18<01:29, 268.39 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21807/47780 [01:18<01:20, 323.85 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23787/47780 [01:18<01:11, 335.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14186/47780 [01:18<02:08, 261.77 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23798/47780 [01:18<01:15, 318.16 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24886/47780 [01:18<01:06, 346.76 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23663/47780 [01:18<01:20, 298.81 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23844/47780 [01:18<01:17, 307.74 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23721/47780 [01:18<01:27, 273.85 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23823/47780 [01:18<01:10, 339.78 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14218/47780 [01:18<02:01, 276.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21840/47780 [01:18<01:27, 295.11 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23831/47780 [01:18<01:15, 318.04 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24921/47780 [01:18<01:11, 321.61 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23876/47780 [01:18<01:17, 310.09 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23749/47780 [01:18<01:27, 275.44 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23693/47780 [01:18<01:26, 279.88 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23858/47780 [01:18<01:12, 331.34 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14246/47780 [01:18<02:05, 267.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21873/47780 [01:18<01:25, 301.57 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23864/47780 [01:18<01:16, 313.90 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23913/47780 [01:18<01:13, 324.51 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23778/47780 [01:18<01:26, 276.45 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24954/47780 [01:18<01:15, 303.33 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23722/47780 [01:18<01:25, 279.77 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23893/47780 [01:18<01:11, 336.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14278/47780 [01:18<01:58, 281.55 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21905/47780 [01:18<01:29, 287.76 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23897/47780 [01:18<01:17, 308.12 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23809/47780 [01:18<01:25, 279.72 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24985/47780 [01:18<01:14, 305.11 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23946/47780 [01:18<01:18, 302.03 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23751/47780 [01:18<01:27, 273.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23931/47780 [01:18<01:09, 341.35 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14307/47780 [01:18<02:08, 260.03 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21936/47780 [01:18<01:30, 284.46 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23931/47780 [01:18<01:16, 311.49 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23839/47780 [01:18<01:23, 285.38 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23977/47780 [01:18<01:18, 303.76 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23780/47780 [01:18<01:27, 274.81 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23969/47780 [01:18<01:07, 352.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25016/47780 [01:18<01:20, 284.46 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14345/47780 [01:18<01:55, 289.57 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21965/47780 [01:18<01:30, 285.92 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23967/47780 [01:18<01:13, 324.26 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24008/47780 [01:18<01:06, 359.07 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23808/47780 [01:18<01:27, 272.98 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23868/47780 [01:18<01:29, 266.21 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25045/47780 [01:18<01:19, 285.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24009/47780 [01:18<01:22, 289.12 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14375/47780 [01:18<01:54, 291.98 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21996/47780 [01:18<01:29, 289.48 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24000/47780 [01:18<01:13, 321.65 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23902/47780 [01:18<01:23, 286.10 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23845/47780 [01:18<01:21, 294.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25078/47780 [01:18<01:17, 291.78 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14405/47780 [01:18<01:58, 281.93 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24046/47780 [01:18<01:14, 317.50 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22033/47780 [01:18<01:24, 304.16 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24039/47780 [01:18<01:31, 258.22 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24033/47780 [01:18<01:16, 310.17 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23941/47780 [01:18<01:16, 311.30 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23875/47780 [01:18<01:20, 295.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25112/47780 [01:18<01:14, 305.04 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14435/47780 [01:18<01:57, 283.23 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24083/47780 [01:18<01:12, 327.52 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22065/47780 [01:18<01:24, 302.96 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24072/47780 [01:18<01:25, 276.59 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24065/47780 [01:18<01:18, 302.24 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23907/47780 [01:19<01:19, 301.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25145/47780 [01:19<01:14, 305.62 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23973/47780 [01:19<01:22, 290.23 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14464/47780 [01:19<01:58, 282.30 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24120/47780 [01:19<01:11, 332.07 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22105/47780 [01:19<01:19, 324.62 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24102/47780 [01:19<01:27, 270.99 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24108/47780 [01:19<01:11, 331.27 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23938/47780 [01:19<01:20, 294.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25179/47780 [01:19<01:12, 311.87 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24013/47780 [01:19<01:15, 313.88 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24155/47780 [01:19<01:10, 333.37 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22142/47780 [01:19<01:17, 332.26 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14493/47780 [01:19<02:04, 266.52 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24145/47780 [01:19<01:09, 341.52 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24132/47780 [01:19<01:29, 264.98 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25211/47780 [01:19<01:13, 307.14 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23973/47780 [01:19<01:19, 301.02 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24046/47780 [01:19<01:15, 314.83 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22179/47780 [01:19<01:14, 342.93 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14525/47780 [01:19<01:58, 281.28 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24189/47780 [01:19<01:12, 323.94 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24172/47780 [01:19<01:20, 294.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24180/47780 [01:19<01:12, 324.86 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24005/47780 [01:19<01:20, 296.45 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25242/47780 [01:19<01:18, 288.09 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24078/47780 [01:19<01:17, 305.99 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22214/47780 [01:19<01:15, 336.77 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14555/47780 [01:19<02:03, 268.04 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24222/47780 [01:19<01:18, 298.96 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24213/47780 [01:19<01:13, 320.02 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24208/47780 [01:19<01:17, 302.45 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24041/47780 [01:19<01:15, 314.26 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25273/47780 [01:19<01:17, 291.00 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24109/47780 [01:19<01:20, 293.99 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22248/47780 [01:19<01:18, 326.63 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14583/47780 [01:19<02:06, 262.75 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24242/47780 [01:19<01:16, 306.15 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24246/47780 [01:19<01:17, 302.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24253/47780 [01:19<01:24, 278.40 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24073/47780 [01:19<01:21, 290.41 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24140/47780 [01:19<01:19, 297.93 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25303/47780 [01:19<01:22, 272.13 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22282/47780 [01:19<01:17, 327.06 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24281/47780 [01:19<01:11, 327.11 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14610/47780 [01:19<02:13, 248.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24286/47780 [01:19<01:20, 291.64 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24277/47780 [01:19<01:21, 288.94 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24174/47780 [01:19<01:16, 307.57 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24106/47780 [01:19<01:19, 296.85 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25331/47780 [01:19<01:22, 271.21 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22315/47780 [01:19<01:20, 316.66 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14647/47780 [01:19<01:57, 281.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24316/47780 [01:19<01:12, 324.73 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24310/47780 [01:19<01:19, 293.53 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24316/47780 [01:19<01:27, 267.73 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24136/47780 [01:19<01:20, 294.25 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24205/47780 [01:19<01:23, 281.73 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22347/47780 [01:19<01:22, 307.03 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25359/47780 [01:19<01:31, 246.33 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14691/47780 [01:19<01:42, 321.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24351/47780 [01:19<01:11, 328.22 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24340/47780 [01:19<01:20, 291.86 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24358/47780 [01:19<01:16, 305.30 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24172/47780 [01:19<01:17, 304.23 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24234/47780 [01:19<01:23, 282.32 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22381/47780 [01:19<01:22, 309.70 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25385/47780 [01:20<01:34, 237.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14724/47780 [01:19<01:46, 309.70 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24385/47780 [01:19<01:16, 304.44 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24370/47780 [01:19<01:22, 284.51 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24391/47780 [01:19<01:16, 304.67 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24210/47780 [01:20<01:13, 320.29 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24267/47780 [01:20<01:21, 287.74 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22413/47780 [01:20<01:22, 306.21 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25411/47780 [01:20<01:32, 240.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14763/47780 [01:20<01:40, 328.78 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24416/47780 [01:20<01:19, 294.93 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24423/47780 [01:20<01:17, 299.96 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24248/47780 [01:20<01:10, 333.51 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24399/47780 [01:20<01:27, 268.39 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24299/47780 [01:20<01:19, 293.62 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22447/47780 [01:20<01:21, 309.07 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25437/47780 [01:20<01:30, 246.03 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14798/47780 [01:20<01:42, 320.49 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24447/47780 [01:20<01:21, 287.28 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24457/47780 [01:20<01:17, 301.94 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24430/47780 [01:20<01:24, 276.74 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24282/47780 [01:20<01:13, 320.47 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22480/47780 [01:20<01:21, 310.72 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24329/47780 [01:20<01:24, 276.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25468/47780 [01:20<01:26, 258.15 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14831/47780 [01:20<01:43, 319.66 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24479/47780 [01:20<01:19, 294.52 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24498/47780 [01:20<01:10, 331.44 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24462/47780 [01:20<01:21, 285.43 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24315/47780 [01:20<01:13, 319.14 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24362/47780 [01:20<01:20, 291.03 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25499/47780 [01:20<01:23, 266.73 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22512/47780 [01:20<01:27, 287.20 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14864/47780 [01:20<01:47, 305.30 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24534/47780 [01:20<01:09, 333.91 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24491/47780 [01:20<01:21, 286.52 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24509/47780 [01:20<01:22, 281.51 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24349/47780 [01:20<01:12, 322.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24392/47780 [01:20<01:22, 283.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25531/47780 [01:20<01:18, 281.73 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22542/47780 [01:20<01:29, 281.36 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14897/47780 [01:20<01:45, 312.04 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24520/47780 [01:20<01:23, 278.34 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24382/47780 [01:20<01:14, 313.34 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24538/47780 [01:20<01:26, 269.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24570/47780 [01:20<01:13, 316.23 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25560/47780 [01:20<01:19, 280.92 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24421/47780 [01:20<01:24, 276.21 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22571/47780 [01:20<01:29, 280.78 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14929/47780 [01:20<01:53, 288.25 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24551/47780 [01:20<01:22, 280.16 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24566/47780 [01:20<01:27, 266.62 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24414/47780 [01:20<01:18, 298.57 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24610/47780 [01:20<01:10, 327.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25592/47780 [01:20<01:15, 291.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24456/47780 [01:20<01:19, 293.92 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22611/47780 [01:20<01:20, 313.96 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14959/47780 [01:20<01:52, 291.41 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24582/47780 [01:20<01:21, 286.28 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24451/47780 [01:20<01:13, 316.62 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24593/47780 [01:20<01:29, 258.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24644/47780 [01:20<01:14, 309.20 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24486/47780 [01:20<01:22, 282.79 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25622/47780 [01:20<01:23, 266.63 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22643/47780 [01:20<01:23, 301.89 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14994/47780 [01:20<01:47, 304.34 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24611/47780 [01:20<01:22, 279.26 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24621/47780 [01:20<01:28, 262.02 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24484/47780 [01:20<01:13, 314.89 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24520/47780 [01:20<01:19, 293.10 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24676/47780 [01:20<01:18, 293.97 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25658/47780 [01:20<01:17, 285.84 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22674/47780 [01:20<01:28, 284.71 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15025/47780 [01:20<01:47, 305.60 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24642/47780 [01:20<01:23, 276.89 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24516/47780 [01:21<01:14, 314.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24649/47780 [01:20<01:27, 264.00 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24555/47780 [01:20<01:15, 308.24 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25697/47780 [01:21<01:10, 311.27 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22714/47780 [01:21<01:20, 313.08 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24706/47780 [01:21<01:25, 270.66 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15056/47780 [01:21<01:52, 290.17 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24672/47780 [01:21<01:21, 283.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24548/47780 [01:21<01:15, 307.49 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24588/47780 [01:21<01:17, 300.22 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24676/47780 [01:21<01:39, 232.05 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25735/47780 [01:21<01:07, 326.82 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22752/47780 [01:21<01:15, 331.67 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24740/47780 [01:21<01:20, 287.19 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24706/47780 [01:21<01:17, 296.26 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15086/47780 [01:21<01:57, 277.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24579/47780 [01:21<01:17, 297.92 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24708/47780 [01:21<01:31, 251.72 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24623/47780 [01:21<01:15, 306.88 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22791/47780 [01:21<01:13, 340.54 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24770/47780 [01:21<01:20, 284.90 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25769/47780 [01:21<01:15, 291.40 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24741/47780 [01:21<01:14, 308.28 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15127/47780 [01:21<01:45, 310.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24609/47780 [01:21<01:18, 293.66 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24654/47780 [01:21<01:18, 293.22 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22826/47780 [01:21<01:13, 339.02 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24734/47780 [01:21<01:39, 231.74 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24799/47780 [01:21<01:26, 266.99 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25809/47780 [01:21<01:09, 316.10 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24640/47780 [01:21<01:18, 296.60 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24772/47780 [01:21<01:19, 288.25 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15159/47780 [01:21<01:52, 290.51 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24684/47780 [01:21<01:18, 294.04 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22865/47780 [01:21<01:12, 346.00 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24763/47780 [01:21<01:33, 246.78 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24829/47780 [01:21<01:24, 272.93 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25845/47780 [01:21<01:08, 321.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24676/47780 [01:21<01:13, 314.80 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24802/47780 [01:21<01:21, 281.81 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15191/47780 [01:21<01:56, 279.93 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24714/47780 [01:21<01:20, 285.96 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22908/47780 [01:21<01:07, 369.86 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24791/47780 [01:21<01:30, 253.43 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24864/47780 [01:21<01:19, 287.72 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25883/47780 [01:21<01:06, 330.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24715/47780 [01:21<01:08, 335.08 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24831/47780 [01:21<01:24, 272.69 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15223/47780 [01:21<01:53, 288.05 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24746/47780 [01:21<01:18, 292.16 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24821/47780 [01:21<01:27, 262.84 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22948/47780 [01:21<01:13, 339.41 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24894/47780 [01:21<01:21, 281.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25917/47780 [01:21<01:07, 325.53 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24749/47780 [01:21<01:10, 325.27 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15253/47780 [01:21<01:52, 288.12 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24859/47780 [01:21<01:26, 265.69 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24776/47780 [01:21<01:19, 287.92 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24849/47780 [01:21<01:29, 256.60 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25950/47780 [01:21<01:07, 323.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24926/47780 [01:21<01:19, 285.99 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24790/47780 [01:21<01:06, 347.24 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22983/47780 [01:21<01:17, 318.08 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24899/47780 [01:21<01:17, 295.87 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15283/47780 [01:21<01:57, 275.67 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24812/47780 [01:21<01:16, 301.55 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24877/47780 [01:21<01:27, 262.91 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25983/47780 [01:21<01:07, 324.78 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24955/47780 [01:21<01:20, 283.33 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24825/47780 [01:21<01:09, 328.52 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23016/47780 [01:21<01:21, 305.01 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24931/47780 [01:21<01:15, 302.54 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15318/47780 [01:21<01:51, 290.14 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24906/47780 [01:21<01:25, 267.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24843/47780 [01:21<01:21, 281.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26016/47780 [01:22<01:09, 312.19 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24984/47780 [01:22<01:22, 276.37 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24859/47780 [01:22<01:10, 324.88 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23047/47780 [01:22<01:21, 302.90 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24962/47780 [01:22<01:18, 292.03 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15356/47780 [01:22<01:43, 314.67 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24933/47780 [01:22<01:26, 265.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24880/47780 [01:22<01:14, 305.67 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26050/47780 [01:22<01:08, 316.41 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25012/47780 [01:22<01:25, 265.64 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24896/47780 [01:22<01:09, 330.07 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23078/47780 [01:22<01:24, 292.33 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15388/47780 [01:22<01:45, 307.74 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24992/47780 [01:22<01:24, 270.02 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24960/47780 [01:22<01:27, 260.51 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26091/47780 [01:22<01:03, 339.27 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24931/47780 [01:22<01:08, 335.38 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24911/47780 [01:22<01:24, 270.55 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25043/47780 [01:22<01:25, 265.91 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15421/47780 [01:22<01:44, 308.59 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23108/47780 [01:22<01:28, 279.44 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25021/47780 [01:22<01:23, 272.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24994/47780 [01:22<01:21, 278.25 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26126/47780 [01:22<01:06, 325.93 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24939/47780 [01:22<01:23, 272.94 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25075/47780 [01:22<01:21, 277.86 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23137/47780 [01:22<01:29, 276.30 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15454/47780 [01:22<01:46, 304.38 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24965/47780 [01:22<01:17, 296.29 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25049/47780 [01:22<01:24, 268.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25022/47780 [01:22<01:22, 274.31 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26160/47780 [01:22<01:06, 323.88 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25103/47780 [01:22<01:24, 268.80 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24967/47780 [01:22<01:28, 257.75 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23174/47780 [01:22<01:21, 301.65 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25002/47780 [01:22<01:12, 315.76 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15485/47780 [01:22<01:48, 297.83 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25053/47780 [01:22<01:20, 281.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25077/47780 [01:22<01:28, 257.37 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26196/47780 [01:22<01:04, 333.80 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25130/47780 [01:22<01:25, 265.14 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24994/47780 [01:22<01:30, 250.76 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25035/47780 [01:22<01:12, 314.56 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23210/47780 [01:22<01:19, 307.96 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15519/47780 [01:22<01:47, 300.97 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25082/47780 [01:22<01:21, 277.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25105/47780 [01:22<01:26, 263.42 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26230/47780 [01:22<01:07, 320.97 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25157/47780 [01:22<01:26, 262.32 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25072/47780 [01:22<01:09, 324.50 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23243/47780 [01:22<01:19, 308.93 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15550/47780 [01:22<01:47, 300.19 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25021/47780 [01:22<01:35, 237.88 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25114/47780 [01:22<01:19, 286.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25139/47780 [01:22<01:21, 277.05 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26263/47780 [01:22<01:07, 320.08 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25184/47780 [01:22<01:26, 261.45 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15583/47780 [01:22<01:44, 308.38 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23275/47780 [01:22<01:20, 303.20 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25105/47780 [01:22<01:12, 313.92 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25172/47780 [01:22<01:17, 290.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25046/47780 [01:22<01:38, 230.42 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25150/47780 [01:22<01:17, 290.70 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25211/47780 [01:22<01:27, 258.18 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26296/47780 [01:22<01:12, 295.97 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15614/47780 [01:22<01:46, 301.86 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25141/47780 [01:22<01:11, 317.67 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23306/47780 [01:22<01:24, 289.14 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25202/47780 [01:22<01:17, 290.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25070/47780 [01:22<01:39, 229.18 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25188/47780 [01:22<01:11, 315.62 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25237/47780 [01:23<01:33, 241.99 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15645/47780 [01:22<01:49, 294.10 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25175/47780 [01:23<01:12, 313.79 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23346/47780 [01:23<01:17, 316.27 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25232/47780 [01:23<01:17, 289.34 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25094/47780 [01:23<01:37, 231.85 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26326/47780 [01:23<01:20, 265.38 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25225/47780 [01:23<01:08, 329.19 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25262/47780 [01:23<01:32, 244.15 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15682/47780 [01:23<01:42, 312.32 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25207/47780 [01:23<01:11, 314.84 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25118/47780 [01:23<01:36, 234.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25260/47780 [01:23<01:07, 333.06 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25262/47780 [01:23<01:19, 282.89 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26361/47780 [01:23<01:16, 281.30 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23378/47780 [01:23<01:23, 293.99 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25291/47780 [01:23<01:28, 254.35 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15715/47780 [01:23<01:41, 314.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25240/47780 [01:23<01:11, 315.85 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26398/47780 [01:23<01:10, 301.80 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25292/47780 [01:23<01:19, 284.47 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25143/47780 [01:23<01:40, 226.01 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25296/47780 [01:23<01:08, 329.93 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23415/47780 [01:23<01:18, 311.44 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25326/47780 [01:23<01:22, 271.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15751/47780 [01:23<01:37, 326.87 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25272/47780 [01:23<01:13, 306.13 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25321/47780 [01:23<01:19, 282.61 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25333/47780 [01:23<01:05, 341.11 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25167/47780 [01:23<01:39, 227.47 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23447/47780 [01:23<01:20, 300.52 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26429/47780 [01:23<01:17, 274.67 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25354/47780 [01:23<01:22, 273.33 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15784/47780 [01:23<01:39, 320.38 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25197/47780 [01:23<01:31, 247.84 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25303/47780 [01:23<01:15, 297.49 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25350/47780 [01:23<01:20, 277.22 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23478/47780 [01:23<01:20, 302.91 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25368/47780 [01:23<01:10, 317.84 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26458/47780 [01:23<01:17, 274.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25398/47780 [01:23<01:11, 312.18 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25227/47780 [01:23<01:26, 259.95 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25334/47780 [01:23<01:14, 300.77 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15817/47780 [01:23<01:48, 295.55 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25384/47780 [01:23<01:18, 283.52 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26490/47780 [01:23<01:17, 275.44 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23509/47780 [01:23<01:26, 279.67 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25401/47780 [01:23<01:16, 292.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25430/47780 [01:23<01:14, 299.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25255/47780 [01:23<01:24, 265.63 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25366/47780 [01:23<01:15, 296.23 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15851/47780 [01:23<01:45, 301.41 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25433/47780 [01:23<01:06, 337.95 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26521/47780 [01:23<01:16, 278.81 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23538/47780 [01:23<01:28, 273.76 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25431/47780 [01:23<01:18, 283.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25464/47780 [01:23<01:11, 310.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25292/47780 [01:23<01:16, 292.68 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25404/47780 [01:23<01:10, 316.62 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25467/47780 [01:23<01:06, 336.97 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15891/47780 [01:23<01:39, 321.59 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26556/47780 [01:23<01:11, 298.20 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23574/47780 [01:23<01:21, 297.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25464/47780 [01:23<01:16, 291.50 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25496/47780 [01:23<01:15, 294.67 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25437/47780 [01:23<01:09, 320.33 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25505/47780 [01:23<01:04, 347.14 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15924/47780 [01:23<01:40, 316.88 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25322/47780 [01:23<01:25, 263.99 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26591/47780 [01:24<01:10, 302.61 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25500/47780 [01:23<01:12, 306.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23605/47780 [01:23<01:26, 279.06 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25474/47780 [01:24<01:07, 330.82 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25540/47780 [01:23<01:04, 345.27 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25526/47780 [01:23<01:18, 283.73 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15960/47780 [01:23<01:36, 328.79 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25353/47780 [01:24<01:21, 273.56 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26622/47780 [01:24<01:11, 297.63 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25540/47780 [01:24<01:09, 318.70 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23635/47780 [01:24<01:26, 278.63 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25508/47780 [01:24<01:07, 329.80 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15994/47780 [01:24<01:37, 324.69 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25555/47780 [01:24<01:23, 267.51 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25575/47780 [01:24<01:09, 317.81 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25381/47780 [01:24<01:26, 257.85 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26652/47780 [01:24<01:13, 288.88 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23667/47780 [01:24<01:23, 289.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25573/47780 [01:24<01:11, 309.66 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25543/47780 [01:24<01:08, 323.88 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16028/47780 [01:24<01:37, 325.54 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25608/47780 [01:24<01:11, 312.01 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25586/47780 [01:24<01:24, 262.22 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26684/47780 [01:24<01:12, 291.20 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25408/47780 [01:24<01:31, 245.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23697/47780 [01:24<01:24, 286.08 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25605/47780 [01:24<01:15, 294.87 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25580/47780 [01:24<01:06, 332.97 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16061/47780 [01:24<01:38, 322.70 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25642/47780 [01:24<01:09, 319.65 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25620/47780 [01:24<01:18, 282.70 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26720/47780 [01:24<01:08, 307.07 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23727/47780 [01:24<01:23, 287.08 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25434/47780 [01:24<01:42, 219.03 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25614/47780 [01:24<01:07, 328.23 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16096/47780 [01:24<01:36, 328.73 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25635/47780 [01:24<01:19, 278.14 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25675/47780 [01:24<01:09, 318.96 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25659/47780 [01:24<01:12, 305.58 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26751/47780 [01:24<01:09, 304.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23756/47780 [01:24<01:23, 287.71 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25471/47780 [01:24<01:26, 256.77 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25647/47780 [01:24<01:08, 324.61 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25664/47780 [01:24<01:26, 256.81 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16129/47780 [01:24<01:46, 296.52 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25708/47780 [01:24<01:13, 301.52 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25698/47780 [01:24<01:09, 318.47 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26782/47780 [01:24<01:09, 302.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23785/47780 [01:24<01:28, 272.58 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25690/47780 [01:24<01:03, 347.54 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25498/47780 [01:24<01:29, 249.81 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25737/47780 [01:24<01:05, 338.28 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25739/47780 [01:24<01:15, 292.34 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25695/47780 [01:24<01:27, 252.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16160/47780 [01:24<01:55, 274.22 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23818/47780 [01:24<01:23, 285.71 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26814/47780 [01:24<01:14, 281.38 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25725/47780 [01:24<01:03, 346.46 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25527/47780 [01:24<01:26, 257.79 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25726/47780 [01:24<01:23, 264.28 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16201/47780 [01:24<01:42, 308.98 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25772/47780 [01:24<01:08, 319.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25769/47780 [01:24<01:19, 275.22 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26843/47780 [01:24<01:17, 268.99 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23847/47780 [01:24<01:30, 265.80 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25767/47780 [01:24<01:00, 361.02 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25561/47780 [01:24<01:21, 271.42 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25805/47780 [01:24<01:08, 318.81 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16233/47780 [01:24<01:42, 308.46 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25797/47780 [01:24<01:20, 274.05 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25753/47780 [01:24<01:27, 252.47 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26873/47780 [01:24<01:16, 274.72 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23876/47780 [01:24<01:28, 269.45 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25601/47780 [01:24<01:13, 302.13 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25805/47780 [01:25<01:08, 321.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25839/47780 [01:24<01:08, 321.62 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25828/47780 [01:25<01:18, 280.28 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16269/47780 [01:24<01:44, 302.11 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25779/47780 [01:25<01:30, 244.12 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26908/47780 [01:25<01:11, 292.29 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23904/47780 [01:25<01:32, 257.89 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25638/47780 [01:25<01:09, 318.67 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25839/47780 [01:25<01:07, 326.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25872/47780 [01:25<01:09, 316.82 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25859/47780 [01:25<01:17, 284.27 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16308/47780 [01:25<01:37, 322.99 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25804/47780 [01:25<01:32, 237.99 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26944/47780 [01:25<01:09, 301.23 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25674/47780 [01:25<01:06, 330.14 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23931/47780 [01:25<01:32, 258.55 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25875/47780 [01:25<01:06, 328.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25907/47780 [01:25<01:07, 322.63 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16349/47780 [01:25<01:31, 343.16 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25837/47780 [01:25<01:24, 260.09 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25893/47780 [01:25<01:18, 279.25 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25708/47780 [01:25<01:06, 329.49 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23958/47780 [01:25<01:31, 261.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26975/47780 [01:25<01:11, 290.50 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25909/47780 [01:25<01:13, 298.29 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16388/47780 [01:25<01:29, 352.18 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25929/47780 [01:25<01:13, 297.88 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25940/47780 [01:25<01:15, 291.06 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25742/47780 [01:25<01:06, 332.09 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23988/47780 [01:25<01:28, 269.71 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25864/47780 [01:25<01:28, 249.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27011/47780 [01:25<01:07, 309.56 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25941/47780 [01:25<01:11, 303.94 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16429/47780 [01:25<01:26, 360.74 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25970/47780 [01:25<01:15, 287.50 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25960/47780 [01:25<01:14, 291.10 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24024/47780 [01:25<01:20, 295.62 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25777/47780 [01:25<01:06, 329.51 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25895/47780 [01:25<01:24, 259.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27043/47780 [01:25<01:09, 299.24 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25983/47780 [01:25<01:05, 332.55 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16466/47780 [01:25<01:26, 362.99 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24056/47780 [01:25<01:18, 302.50 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26001/47780 [01:25<01:15, 288.27 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25990/47780 [01:25<01:19, 275.64 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25922/47780 [01:25<01:26, 251.56 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27081/47780 [01:25<01:05, 314.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25811/47780 [01:25<01:16, 286.55 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26019/47780 [01:25<01:03, 340.16 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26034/47780 [01:25<01:13, 295.69 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24088/47780 [01:25<01:22, 287.58 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27118/47780 [01:25<01:03, 326.80 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25956/47780 [01:25<01:19, 272.81 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16504/47780 [01:25<01:36, 322.85 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26019/47780 [01:25<01:20, 270.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25841/47780 [01:25<01:16, 286.82 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26055/47780 [01:25<01:04, 338.13 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26064/47780 [01:25<01:13, 296.89 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24118/47780 [01:25<01:21, 290.84 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25985/47780 [01:25<01:19, 275.47 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26049/47780 [01:25<01:18, 275.75 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27151/47780 [01:25<01:04, 320.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16538/47780 [01:25<01:39, 314.54 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26090/47780 [01:25<01:03, 341.02 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25871/47780 [01:25<01:20, 272.92 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26100/47780 [01:25<01:09, 311.89 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26018/47780 [01:25<01:15, 289.86 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27184/47780 [01:25<01:03, 322.25 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16574/47780 [01:25<01:37, 320.06 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26077/47780 [01:25<01:21, 265.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24148/47780 [01:25<01:29, 263.47 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26125/47780 [01:26<01:03, 340.23 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25907/47780 [01:25<01:13, 295.61 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26132/47780 [01:25<01:13, 296.36 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26050/47780 [01:26<01:15, 288.53 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16611/47780 [01:25<01:33, 333.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26104/47780 [01:26<01:24, 257.97 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27217/47780 [01:26<01:10, 290.67 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24175/47780 [01:26<01:32, 254.27 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26160/47780 [01:26<01:06, 324.14 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25938/47780 [01:26<01:18, 278.55 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26081/47780 [01:26<01:14, 291.56 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16645/47780 [01:26<01:36, 324.17 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26141/47780 [01:26<01:14, 288.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26162/47780 [01:26<01:20, 267.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27252/47780 [01:26<01:08, 301.29 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24207/47780 [01:26<01:30, 260.72 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26193/47780 [01:26<01:09, 311.82 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25967/47780 [01:26<01:19, 275.55 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26112/47780 [01:26<01:13, 296.09 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26173/47780 [01:26<01:14, 291.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16679/47780 [01:26<01:39, 311.46 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27285/47780 [01:26<01:07, 303.63 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26190/47780 [01:26<01:26, 249.88 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24235/47780 [01:26<01:30, 260.34 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26225/47780 [01:26<01:08, 313.64 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26000/47780 [01:26<01:15, 287.46 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26203/47780 [01:26<01:13, 293.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26143/47780 [01:26<01:19, 272.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16724/47780 [01:26<01:29, 345.69 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24271/47780 [01:26<01:21, 287.46 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26220/47780 [01:26<01:22, 262.71 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27317/47780 [01:26<01:12, 282.36 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26261/47780 [01:26<01:07, 319.94 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26030/47780 [01:26<01:23, 261.92 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26233/47780 [01:26<01:15, 285.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26175/47780 [01:26<01:16, 282.33 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16764/47780 [01:26<01:28, 349.12 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26297/47780 [01:26<01:04, 331.15 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24301/47780 [01:26<01:27, 269.87 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27347/47780 [01:26<01:12, 280.73 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26247/47780 [01:26<01:28, 243.80 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26058/47780 [01:26<01:23, 261.03 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26267/47780 [01:26<01:11, 300.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26211/47780 [01:26<01:11, 303.66 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16800/47780 [01:26<01:32, 333.22 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27377/47780 [01:26<01:11, 285.90 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24336/47780 [01:26<01:21, 288.45 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26275/47780 [01:26<01:25, 250.48 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26331/47780 [01:26<01:07, 315.82 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26090/47780 [01:26<01:20, 271.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26308/47780 [01:26<01:05, 329.16 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26242/47780 [01:26<01:16, 283.18 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16837/47780 [01:26<01:30, 340.06 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27409/47780 [01:26<01:09, 292.26 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24368/47780 [01:26<01:19, 293.98 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26301/47780 [01:26<01:27, 245.21 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26363/47780 [01:26<01:09, 309.18 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26347/47780 [01:26<01:03, 339.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26118/47780 [01:26<01:21, 264.82 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26275/47780 [01:26<01:13, 292.79 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16872/47780 [01:26<01:31, 338.65 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27439/47780 [01:26<01:11, 284.78 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24401/47780 [01:26<01:18, 297.34 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26327/47780 [01:26<01:27, 246.42 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26395/47780 [01:26<01:12, 293.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26148/47780 [01:26<01:19, 272.67 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26382/47780 [01:26<01:06, 322.92 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26305/47780 [01:26<01:12, 294.20 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24431/47780 [01:26<01:18, 297.84 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27468/47780 [01:26<01:11, 282.97 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16907/47780 [01:26<01:37, 317.07 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26357/47780 [01:26<01:22, 258.45 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26176/47780 [01:26<01:18, 273.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26425/47780 [01:27<01:16, 279.61 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26419/47780 [01:26<01:04, 332.71 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26335/47780 [01:26<01:13, 289.99 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24465/47780 [01:27<01:15, 306.81 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16940/47780 [01:27<01:41, 304.05 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26384/47780 [01:27<01:26, 247.91 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27497/47780 [01:27<01:18, 258.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26204/47780 [01:27<01:18, 275.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26454/47780 [01:27<01:18, 270.89 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26367/47780 [01:27<01:12, 295.01 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26454/47780 [01:27<01:06, 319.65 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24496/47780 [01:27<01:17, 300.77 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16974/47780 [01:27<01:39, 310.37 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26414/47780 [01:27<01:22, 259.43 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27535/47780 [01:27<01:12, 279.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26232/47780 [01:27<01:21, 264.87 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26402/47780 [01:27<01:09, 307.31 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26482/47780 [01:27<01:22, 259.02 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26493/47780 [01:27<01:02, 339.08 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24530/47780 [01:27<01:14, 312.01 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17008/47780 [01:27<01:37, 315.05 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26452/47780 [01:27<01:12, 292.78 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27564/47780 [01:27<01:12, 279.18 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26261/47780 [01:27<01:21, 265.62 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26512/47780 [01:27<01:19, 267.34 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26528/47780 [01:27<01:02, 337.98 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26433/47780 [01:27<01:12, 293.88 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24562/47780 [01:27<01:16, 303.77 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26483/47780 [01:27<01:12, 294.31 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17040/47780 [01:27<01:42, 299.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27594/47780 [01:27<01:11, 281.61 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26290/47780 [01:27<01:20, 266.31 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26547/47780 [01:27<01:13, 289.78 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26563/47780 [01:27<01:04, 326.82 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26463/47780 [01:27<01:14, 286.44 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24593/47780 [01:27<01:15, 305.50 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26514/47780 [01:27<01:11, 295.73 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17075/47780 [01:27<01:40, 306.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27623/47780 [01:27<01:11, 280.98 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26322/47780 [01:27<01:17, 275.49 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26584/47780 [01:27<01:08, 307.89 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26493/47780 [01:27<01:13, 288.95 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24631/47780 [01:27<01:12, 319.73 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26596/47780 [01:27<01:09, 303.23 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26549/47780 [01:27<01:09, 304.36 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17113/47780 [01:27<01:33, 327.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27652/47780 [01:27<01:11, 283.29 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26350/47780 [01:27<01:23, 256.37 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26523/47780 [01:27<01:13, 289.79 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26617/47780 [01:27<01:12, 292.20 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24664/47780 [01:27<01:16, 303.67 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26627/47780 [01:27<01:12, 292.18 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26585/47780 [01:27<01:07, 313.30 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17147/47780 [01:27<01:33, 326.85 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27681/47780 [01:27<01:11, 282.31 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26647/47780 [01:27<01:11, 294.01 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26379/47780 [01:27<01:22, 260.01 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26554/47780 [01:27<01:13, 289.04 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24695/47780 [01:27<01:21, 284.53 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17181/47780 [01:27<01:36, 316.21 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26623/47780 [01:27<01:03, 332.30 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26657/47780 [01:27<01:17, 271.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27710/47780 [01:27<01:14, 271.17 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26586/47780 [01:27<01:11, 295.90 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26677/47780 [01:27<01:12, 289.25 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26416/47780 [01:27<01:13, 288.94 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24726/47780 [01:27<01:19, 291.28 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26657/47780 [01:27<01:07, 312.46 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26688/47780 [01:27<01:15, 278.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27742/47780 [01:27<01:10, 282.59 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17213/47780 [01:27<01:41, 300.59 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26616/47780 [01:27<01:11, 295.68 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26446/47780 [01:27<01:14, 286.53 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26707/47780 [01:28<01:15, 279.94 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24756/47780 [01:28<01:21, 281.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26689/47780 [01:27<01:09, 304.48 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26717/47780 [01:28<01:17, 272.86 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27775/47780 [01:28<01:09, 286.23 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17245/47780 [01:27<01:40, 302.48 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26477/47780 [01:28<01:14, 286.99 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26646/47780 [01:28<01:15, 280.88 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26736/47780 [01:28<01:19, 265.14 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24786/47780 [01:28<01:20, 286.26 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27810/47780 [01:28<01:05, 304.07 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26745/47780 [01:28<01:17, 273.13 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26724/47780 [01:28<01:07, 310.44 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17277/47780 [01:28<01:39, 307.16 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26675/47780 [01:28<01:17, 273.43 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26779/47780 [01:28<01:08, 306.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26506/47780 [01:28<01:21, 261.28 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26756/47780 [01:28<01:07, 309.74 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26781/47780 [01:28<01:11, 292.82 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17317/47780 [01:28<01:32, 330.28 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24815/47780 [01:28<01:24, 272.25 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27841/47780 [01:28<01:08, 292.16 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26812/47780 [01:28<01:06, 312.96 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26710/47780 [01:28<01:13, 286.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26533/47780 [01:28<01:21, 260.75 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26814/47780 [01:28<01:09, 303.21 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26792/47780 [01:28<01:05, 319.72 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17351/47780 [01:28<01:32, 329.22 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24849/47780 [01:28<01:19, 287.77 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27871/47780 [01:28<01:08, 291.57 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26568/47780 [01:28<01:15, 282.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26740/47780 [01:28<01:17, 271.44 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26859/47780 [01:28<01:01, 341.40 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17388/47780 [01:28<01:29, 340.96 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26845/47780 [01:28<01:13, 285.12 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24883/47780 [01:28<01:15, 302.46 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27901/47780 [01:28<01:10, 282.28 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26825/47780 [01:28<01:10, 298.73 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26597/47780 [01:28<01:15, 281.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26770/47780 [01:28<01:17, 270.45 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26880/47780 [01:28<01:09, 299.65 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17428/47780 [01:28<01:25, 354.12 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24914/47780 [01:28<01:16, 297.82 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26895/47780 [01:28<01:03, 327.84 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26858/47780 [01:28<01:09, 301.30 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27930/47780 [01:28<01:12, 273.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26626/47780 [01:28<01:17, 274.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26799/47780 [01:28<01:16, 273.21 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17465/47780 [01:28<01:26, 350.29 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26911/47780 [01:28<01:11, 292.80 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26929/47780 [01:28<01:03, 326.68 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26894/47780 [01:28<01:06, 314.02 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27959/47780 [01:28<01:11, 275.47 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26828/47780 [01:28<01:15, 277.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26655/47780 [01:28<01:18, 269.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24944/47780 [01:28<01:36, 236.37 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26942/47780 [01:28<01:11, 292.36 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26962/47780 [01:28<01:04, 324.54 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26931/47780 [01:28<01:03, 329.62 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28004/47780 [01:28<01:01, 323.30 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17501/47780 [01:28<01:33, 322.97 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26861/47780 [01:28<01:11, 292.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25013/47780 [01:28<01:05, 347.03 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26683/47780 [01:28<01:21, 258.15 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26973/47780 [01:28<01:11, 292.41 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 26996/47780 [01:28<01:04, 321.95 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26965/47780 [01:28<01:04, 324.94 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17534/47780 [01:28<01:38, 308.22 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28038/47780 [01:28<01:04, 307.97 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26895/47780 [01:28<01:09, 299.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25052/47780 [01:28<01:04, 354.23 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26710/47780 [01:28<01:21, 259.77 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27005/47780 [01:29<01:09, 299.54 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27000/47780 [01:28<01:03, 328.75 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27029/47780 [01:28<01:08, 305.13 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17566/47780 [01:28<01:41, 298.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28070/47780 [01:29<01:07, 292.22 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26738/47780 [01:29<01:19, 265.14 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26926/47780 [01:29<01:12, 287.37 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25091/47780 [01:29<01:07, 335.45 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27034/47780 [01:29<01:02, 331.71 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27036/47780 [01:29<01:12, 286.84 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27060/47780 [01:29<01:09, 298.27 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17600/47780 [01:29<01:38, 306.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28100/47780 [01:29<01:08, 288.27 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26768/47780 [01:29<01:17, 271.03 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26955/47780 [01:29<01:12, 286.41 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27069/47780 [01:29<01:09, 295.89 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27068/47780 [01:29<01:04, 323.23 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27096/47780 [01:29<01:06, 311.81 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25127/47780 [01:29<01:11, 315.07 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28133/47780 [01:29<01:05, 299.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17631/47780 [01:29<01:42, 294.23 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26987/47780 [01:29<01:10, 293.12 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26798/47780 [01:29<01:18, 267.01 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27101/47780 [01:29<01:05, 314.19 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27099/47780 [01:29<01:13, 281.05 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27128/47780 [01:29<01:07, 304.48 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25161/47780 [01:29<01:15, 300.48 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28165/47780 [01:29<01:04, 301.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17661/47780 [01:29<01:47, 280.50 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27023/47780 [01:29<01:07, 305.31 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26832/47780 [01:29<01:13, 284.30 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27133/47780 [01:29<01:06, 312.41 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27132/47780 [01:29<01:10, 291.40 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27159/47780 [01:29<01:09, 295.17 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28199/47780 [01:29<01:04, 305.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25193/47780 [01:29<01:16, 296.29 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17690/47780 [01:29<01:50, 271.37 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27055/47780 [01:29<01:07, 309.30 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26861/47780 [01:29<01:21, 256.86 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27162/47780 [01:29<01:14, 278.20 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27194/47780 [01:29<01:06, 307.45 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27165/47780 [01:29<01:10, 291.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28230/47780 [01:29<01:04, 303.44 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25224/47780 [01:29<01:21, 276.89 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27088/47780 [01:29<01:06, 311.77 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17721/47780 [01:29<01:50, 271.01 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26888/47780 [01:29<01:20, 260.27 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27228/47780 [01:29<01:05, 315.96 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27195/47780 [01:29<01:11, 286.08 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27195/47780 [01:29<01:10, 290.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28265/47780 [01:29<01:02, 309.78 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27122/47780 [01:29<01:05, 316.30 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17751/47780 [01:29<01:48, 277.87 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25253/47780 [01:29<01:29, 250.35 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26915/47780 [01:29<01:22, 254.05 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27265/47780 [01:29<01:02, 328.36 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28302/47780 [01:29<01:00, 319.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27225/47780 [01:29<01:15, 271.83 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27225/47780 [01:29<01:17, 265.96 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17786/47780 [01:29<01:41, 295.35 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27154/47780 [01:29<01:10, 293.46 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25303/47780 [01:29<01:12, 310.66 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26948/47780 [01:29<01:15, 274.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27298/47780 [01:29<01:03, 325.05 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27256/47780 [01:29<01:15, 273.29 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28335/47780 [01:29<01:02, 311.70 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27253/47780 [01:29<01:16, 267.20 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17821/47780 [01:29<01:39, 300.10 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27190/47780 [01:29<01:06, 308.51 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27334/47780 [01:29<01:01, 334.88 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26976/47780 [01:29<01:20, 259.45 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25336/47780 [01:29<01:17, 288.73 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27282/47780 [01:29<01:14, 273.35 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27284/47780 [01:30<01:16, 266.32 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28367/47780 [01:30<01:04, 300.64 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27223/47780 [01:30<01:06, 307.68 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17853/47780 [01:30<01:50, 270.80 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27368/47780 [01:30<01:02, 325.19 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25367/47780 [01:30<01:18, 285.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27003/47780 [01:30<01:22, 252.29 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27310/47780 [01:30<01:16, 268.93 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27317/47780 [01:30<01:13, 277.81 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27254/47780 [01:30<01:07, 304.14 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28399/47780 [01:30<01:12, 267.06 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27401/47780 [01:30<01:03, 322.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17901/47780 [01:30<01:34, 317.23 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27029/47780 [01:30<01:25, 241.50 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27338/47780 [01:30<01:15, 269.16 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25397/47780 [01:30<01:22, 271.94 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27345/47780 [01:30<01:16, 266.60 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28438/47780 [01:30<01:05, 297.21 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27285/47780 [01:30<01:11, 288.62 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17934/47780 [01:30<01:36, 310.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27434/47780 [01:30<01:04, 314.10 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25428/47780 [01:30<01:19, 280.24 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27061/47780 [01:30<01:20, 258.46 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27376/47780 [01:30<01:13, 278.34 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27366/47780 [01:30<01:19, 257.77 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28476/47780 [01:30<01:00, 318.01 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27318/47780 [01:30<01:09, 294.98 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27468/47780 [01:30<01:03, 317.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17966/47780 [01:30<01:38, 303.38 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27099/47780 [01:30<01:11, 288.94 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25460/47780 [01:30<01:18, 283.66 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27405/47780 [01:30<01:13, 275.73 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27402/47780 [01:30<01:11, 283.05 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27348/47780 [01:30<01:11, 286.72 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28512/47780 [01:30<01:01, 311.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17999/47780 [01:30<01:36, 310.18 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27500/47780 [01:30<01:07, 300.93 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27139/47780 [01:30<01:04, 319.67 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25489/47780 [01:30<01:20, 276.08 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27437/47780 [01:30<01:12, 281.87 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27432/47780 [01:30<01:13, 275.36 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28544/47780 [01:30<01:02, 307.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18041/47780 [01:30<01:29, 333.83 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27377/47780 [01:30<01:18, 261.36 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27175/47780 [01:30<01:02, 331.11 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27532/47780 [01:30<01:08, 296.52 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27479/47780 [01:30<01:03, 318.46 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25517/47780 [01:30<01:24, 262.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27460/47780 [01:30<01:17, 262.33 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18076/47780 [01:30<01:31, 323.92 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27570/47780 [01:30<01:03, 319.45 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27404/47780 [01:30<01:18, 257.94 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27209/47780 [01:30<01:03, 322.95 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27512/47780 [01:30<01:03, 320.19 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28576/47780 [01:30<01:12, 264.45 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25545/47780 [01:30<01:24, 262.02 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27487/47780 [01:30<01:18, 257.95 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18109/47780 [01:30<01:32, 322.01 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27432/47780 [01:30<01:17, 261.33 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27242/47780 [01:30<01:05, 315.80 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27603/47780 [01:30<01:06, 305.41 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28609/47780 [01:30<01:08, 278.38 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27545/47780 [01:30<01:08, 295.97 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25572/47780 [01:30<01:27, 253.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27518/47780 [01:30<01:16, 264.14 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27462/47780 [01:30<01:14, 271.82 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18142/47780 [01:30<01:37, 303.85 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27643/47780 [01:30<01:02, 323.99 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27274/47780 [01:30<01:07, 304.60 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28638/47780 [01:31<01:08, 278.18 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25601/47780 [01:30<01:25, 260.42 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27576/47780 [01:31<01:08, 293.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27548/47780 [01:30<01:14, 269.90 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18175/47780 [01:30<01:36, 307.54 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27676/47780 [01:31<01:04, 312.07 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27308/47780 [01:31<01:07, 304.54 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28670/47780 [01:31<01:08, 280.57 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27495/47780 [01:31<01:19, 254.08 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25628/47780 [01:31<01:25, 260.12 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27583/47780 [01:31<01:10, 287.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27606/47780 [01:31<01:12, 279.76 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18209/47780 [01:31<01:34, 312.97 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27712/47780 [01:31<01:03, 316.52 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27529/47780 [01:31<01:13, 276.65 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28699/47780 [01:31<01:08, 280.25 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27340/47780 [01:31<01:08, 298.92 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25655/47780 [01:31<01:28, 251.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27635/47780 [01:31<01:12, 279.02 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27613/47780 [01:31<01:16, 264.15 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18250/47780 [01:31<01:27, 336.82 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27559/47780 [01:31<01:11, 282.94 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27752/47780 [01:31<00:59, 337.88 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28728/47780 [01:31<01:08, 276.60 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27370/47780 [01:31<01:09, 292.48 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25690/47780 [01:31<01:20, 275.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27664/47780 [01:31<01:11, 279.52 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27648/47780 [01:31<01:10, 287.08 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27591/47780 [01:31<01:08, 293.10 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18284/47780 [01:31<01:33, 315.00 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28756/47780 [01:31<01:09, 274.33 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27787/47780 [01:31<01:01, 326.81 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27400/47780 [01:31<01:09, 291.16 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27693/47780 [01:31<01:14, 269.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25718/47780 [01:31<01:25, 259.51 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27678/47780 [01:31<01:12, 278.03 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27622/47780 [01:31<01:09, 291.04 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18324/47780 [01:31<01:28, 332.16 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27821/47780 [01:31<01:01, 324.02 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28784/47780 [01:31<01:11, 266.95 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27430/47780 [01:31<01:15, 269.55 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27725/47780 [01:31<01:11, 281.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25748/47780 [01:31<01:21, 270.43 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27713/47780 [01:31<01:08, 291.57 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27652/47780 [01:31<01:10, 284.49 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27859/47780 [01:31<00:58, 339.74 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28816/47780 [01:31<01:07, 279.00 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18358/47780 [01:31<01:32, 316.66 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27461/47780 [01:31<01:13, 277.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27760/47780 [01:31<01:06, 300.48 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25776/47780 [01:31<01:26, 253.30 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27748/47780 [01:31<01:07, 295.20 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28849/47780 [01:31<01:04, 293.50 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27894/47780 [01:31<01:03, 312.81 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27794/47780 [01:31<01:04, 311.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27681/47780 [01:31<01:17, 259.08 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18390/47780 [01:31<01:41, 289.12 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27492/47780 [01:31<01:15, 268.37 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25807/47780 [01:31<01:22, 265.89 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28880/47780 [01:31<01:03, 298.25 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27778/47780 [01:31<01:12, 274.63 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27837/47780 [01:31<00:58, 342.45 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27926/47780 [01:31<01:03, 311.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27520/47780 [01:31<01:14, 271.50 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25841/47780 [01:31<01:17, 283.27 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18420/47780 [01:31<01:45, 277.34 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27708/47780 [01:31<01:23, 239.11 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28918/47780 [01:31<00:59, 318.22 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27809/47780 [01:31<01:11, 278.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27959/47780 [01:31<01:02, 316.37 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27872/47780 [01:31<01:00, 329.25 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27548/47780 [01:31<01:16, 264.04 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27740/47780 [01:31<01:17, 260.05 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25876/47780 [01:31<01:14, 295.41 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18451/47780 [01:31<01:46, 275.37 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28952/47780 [01:32<00:59, 313.92 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27996/47780 [01:32<00:59, 331.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27838/47780 [01:32<01:16, 259.33 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27906/47780 [01:32<01:01, 324.29 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27581/47780 [01:32<01:12, 277.63 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25910/47780 [01:32<01:11, 304.58 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27767/47780 [01:32<01:20, 249.46 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18479/47780 [01:32<01:56, 251.57 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28985/47780 [01:32<00:59, 314.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27867/47780 [01:32<01:15, 264.23 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28030/47780 [01:32<01:03, 310.25 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27940/47780 [01:32<01:00, 325.66 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27615/47780 [01:32<01:10, 285.46 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25949/47780 [01:32<01:06, 328.06 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27801/47780 [01:32<01:13, 273.55 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18508/47780 [01:32<01:52, 261.33 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29024/47780 [01:32<00:55, 336.54 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27896/47780 [01:32<01:14, 265.31 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27973/47780 [01:32<01:01, 323.22 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28062/47780 [01:32<01:05, 302.13 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27832/47780 [01:32<01:10, 283.63 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27644/47780 [01:32<01:12, 277.52 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25983/47780 [01:32<01:12, 301.02 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29058/47780 [01:32<00:57, 325.53 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18535/47780 [01:32<01:58, 247.48 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27925/47780 [01:32<01:16, 258.05 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28093/47780 [01:32<01:06, 297.74 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27672/47780 [01:32<01:12, 278.07 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28006/47780 [01:32<01:04, 306.90 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27862/47780 [01:32<01:12, 276.04 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26019/47780 [01:32<01:10, 310.43 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29095/47780 [01:32<00:55, 334.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18561/47780 [01:32<02:01, 241.11 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27951/47780 [01:32<01:16, 258.21 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28130/47780 [01:32<01:02, 314.43 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28037/47780 [01:32<01:05, 301.17 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27899/47780 [01:32<01:06, 298.82 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27700/47780 [01:32<01:19, 252.57 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29131/47780 [01:32<00:56, 330.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18593/47780 [01:32<01:52, 259.25 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26051/47780 [01:32<01:21, 265.54 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28069/47780 [01:32<01:06, 296.94 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27977/47780 [01:32<01:24, 235.47 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28162/47780 [01:32<01:06, 295.85 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27930/47780 [01:32<01:09, 285.96 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29170/47780 [01:32<00:54, 343.70 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18623/47780 [01:32<01:49, 267.42 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27726/47780 [01:32<01:28, 227.73 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26107/47780 [01:32<01:04, 338.37 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28192/47780 [01:32<01:06, 293.24 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28099/47780 [01:32<01:10, 279.15 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27963/47780 [01:32<01:07, 294.83 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28001/47780 [01:32<01:30, 218.11 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18657/47780 [01:32<01:41, 287.46 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29205/47780 [01:32<00:56, 329.69 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27750/47780 [01:32<01:28, 226.30 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26145/47780 [01:32<01:04, 333.46 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28222/47780 [01:32<01:06, 292.97 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28132/47780 [01:32<01:09, 283.70 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28024/47780 [01:32<01:29, 221.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27994/47780 [01:32<01:08, 289.32 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27774/47780 [01:32<01:28, 226.87 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18687/47780 [01:32<01:47, 269.80 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29240/47780 [01:32<01:01, 302.17 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28253/47780 [01:32<01:08, 284.39 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28173/47780 [01:32<01:02, 315.49 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26180/47780 [01:32<01:10, 305.54 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28024/47780 [01:32<01:09, 285.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28048/47780 [01:32<01:30, 216.86 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18722/47780 [01:32<01:40, 288.47 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27797/47780 [01:32<01:33, 214.35 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29272/47780 [01:33<01:03, 290.02 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28054/47780 [01:33<01:08, 287.16 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28077/47780 [01:33<01:23, 236.51 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28283/47780 [01:33<01:12, 270.25 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28206/47780 [01:33<01:04, 305.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26212/47780 [01:33<01:14, 288.42 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18752/47780 [01:33<01:42, 281.90 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27828/47780 [01:33<01:26, 229.96 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29302/47780 [01:33<01:08, 270.95 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28104/47780 [01:33<01:21, 240.71 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28084/47780 [01:33<01:10, 280.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28237/47780 [01:33<01:05, 296.26 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28311/47780 [01:33<01:15, 259.22 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26242/47780 [01:33<01:16, 283.03 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18785/47780 [01:33<01:40, 289.27 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27860/47780 [01:33<01:19, 251.91 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29330/47780 [01:33<01:08, 270.70 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28130/47780 [01:33<01:21, 240.56 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28340/47780 [01:33<01:13, 264.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28273/47780 [01:33<01:04, 304.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26271/47780 [01:33<01:16, 281.87 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28114/47780 [01:33<01:14, 262.60 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18820/47780 [01:33<01:35, 302.87 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27886/47780 [01:33<01:22, 240.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29366/47780 [01:33<01:03, 291.06 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28306/47780 [01:33<01:03, 304.63 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28367/47780 [01:33<01:15, 257.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26300/47780 [01:33<01:16, 280.16 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28155/47780 [01:33<01:27, 225.48 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28141/47780 [01:33<01:18, 251.03 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18851/47780 [01:33<01:36, 298.32 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27911/47780 [01:33<01:23, 237.31 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29408/47780 [01:33<00:56, 325.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28337/47780 [01:33<01:03, 306.09 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26329/47780 [01:33<01:18, 274.70 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28188/47780 [01:33<01:18, 250.54 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28393/47780 [01:33<01:19, 242.42 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28167/47780 [01:33<01:21, 240.72 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18882/47780 [01:33<01:39, 291.58 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27939/47780 [01:33<01:21, 244.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29442/47780 [01:33<00:55, 328.61 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28368/47780 [01:33<01:06, 293.98 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26362/47780 [01:33<01:14, 286.79 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28214/47780 [01:33<01:18, 248.74 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28422/47780 [01:33<01:16, 252.43 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18913/47780 [01:33<01:38, 293.23 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28195/47780 [01:33<01:21, 240.53 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27964/47780 [01:33<01:25, 232.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29481/47780 [01:33<00:55, 329.60 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26397/47780 [01:33<01:11, 301.10 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28247/47780 [01:33<01:12, 270.91 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28398/47780 [01:33<01:08, 282.79 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28452/47780 [01:33<01:15, 257.05 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18943/47780 [01:33<01:40, 285.63 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28220/47780 [01:33<01:22, 238.09 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27988/47780 [01:33<01:26, 230.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29516/47780 [01:33<00:55, 327.98 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26428/47780 [01:33<01:11, 296.96 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28275/47780 [01:33<01:13, 264.59 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28429/47780 [01:33<01:08, 281.02 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28480/47780 [01:33<01:14, 258.49 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18974/47780 [01:33<01:38, 292.45 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28256/47780 [01:33<01:12, 268.39 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28017/47780 [01:33<01:20, 246.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29556/47780 [01:33<00:53, 340.51 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28306/47780 [01:33<01:10, 274.36 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26458/47780 [01:33<01:13, 291.18 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28463/47780 [01:33<01:05, 297.16 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28507/47780 [01:33<01:13, 260.93 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19008/47780 [01:33<01:35, 302.74 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28286/47780 [01:33<01:10, 276.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28046/47780 [01:33<01:17, 253.24 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29591/47780 [01:34<00:55, 329.00 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26493/47780 [01:34<01:09, 304.44 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28534/47780 [01:34<01:13, 260.45 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28335/47780 [01:34<01:13, 263.64 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28493/47780 [01:34<01:11, 270.31 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19041/47780 [01:34<01:36, 296.56 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28314/47780 [01:34<01:16, 254.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28082/47780 [01:34<01:10, 280.47 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29625/47780 [01:34<00:57, 317.35 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28567/47780 [01:34<01:09, 277.28 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28367/47780 [01:34<01:10, 276.12 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26525/47780 [01:34<01:15, 282.98 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28521/47780 [01:34<01:13, 263.31 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19071/47780 [01:34<01:40, 284.77 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28344/47780 [01:34<01:12, 266.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28114/47780 [01:34<01:08, 288.38 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29661/47780 [01:34<00:55, 326.92 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28399/47780 [01:34<01:08, 282.29 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26555/47780 [01:34<01:14, 284.49 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28595/47780 [01:34<01:12, 262.99 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19109/47780 [01:34<01:33, 308.01 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28548/47780 [01:34<01:14, 257.90 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28377/47780 [01:34<01:08, 283.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28151/47780 [01:34<01:04, 304.49 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29694/47780 [01:34<00:55, 327.38 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28428/47780 [01:34<01:11, 272.26 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26585/47780 [01:34<01:15, 282.52 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28622/47780 [01:34<01:15, 253.49 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28406/47780 [01:34<01:07, 285.03 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28575/47780 [01:34<01:15, 255.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19140/47780 [01:34<01:37, 295.22 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28182/47780 [01:34<01:07, 289.79 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29727/47780 [01:34<00:57, 312.78 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26619/47780 [01:34<01:10, 298.36 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28456/47780 [01:34<01:11, 271.39 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28653/47780 [01:34<01:11, 266.17 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28435/47780 [01:34<01:08, 284.45 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28603/47780 [01:34<01:13, 259.65 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19181/47780 [01:34<01:32, 309.86 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28215/47780 [01:34<01:06, 294.35 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29759/47780 [01:34<00:58, 307.91 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26650/47780 [01:34<01:13, 288.73 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28466/47780 [01:34<01:06, 289.01 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28680/47780 [01:34<01:15, 253.02 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28484/47780 [01:34<01:17, 250.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28630/47780 [01:34<01:16, 251.29 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28248/47780 [01:34<01:04, 304.13 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19213/47780 [01:34<01:38, 290.61 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26687/47780 [01:34<01:07, 311.40 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29790/47780 [01:34<01:04, 280.09 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28498/47780 [01:34<01:04, 298.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28706/47780 [01:34<01:16, 249.49 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28659/47780 [01:34<01:16, 250.84 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28510/47780 [01:34<01:22, 233.51 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28285/47780 [01:34<01:00, 319.68 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19243/47780 [01:34<01:37, 292.94 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26723/47780 [01:34<01:05, 321.70 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29828/47780 [01:34<00:59, 300.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28530/47780 [01:34<01:04, 297.44 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28326/47780 [01:34<00:56, 345.62 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28732/47780 [01:34<01:22, 231.63 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28685/47780 [01:34<01:18, 243.33 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28536/47780 [01:34<01:24, 228.38 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19274/47780 [01:34<01:42, 279.30 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26758/47780 [01:34<01:04, 326.19 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29859/47780 [01:34<01:02, 287.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28560/47780 [01:34<01:08, 281.33 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28711/47780 [01:35<01:17, 247.22 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28759/47780 [01:34<01:20, 236.97 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28565/47780 [01:34<01:18, 244.46 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28361/47780 [01:34<01:00, 320.33 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19308/47780 [01:34<01:38, 289.31 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26792/47780 [01:34<01:05, 322.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28601/47780 [01:35<01:00, 317.48 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29889/47780 [01:35<01:04, 276.00 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28737/47780 [01:35<01:17, 245.35 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28592/47780 [01:35<01:17, 248.98 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28784/47780 [01:35<01:24, 225.79 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28405/47780 [01:35<00:59, 328.31 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19338/47780 [01:35<01:40, 282.34 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26830/47780 [01:35<01:01, 338.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28634/47780 [01:35<01:00, 317.81 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29922/47780 [01:35<01:02, 284.17 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28618/47780 [01:35<01:17, 248.47 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28807/47780 [01:35<01:23, 226.89 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28762/47780 [01:35<01:24, 223.90 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28455/47780 [01:35<00:53, 362.97 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19367/47780 [01:35<01:46, 267.45 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26865/47780 [01:35<01:05, 320.16 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28667/47780 [01:35<01:01, 310.23 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29951/47780 [01:35<01:05, 273.96 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28834/47780 [01:35<01:19, 237.21 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28644/47780 [01:35<01:20, 239.03 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28785/47780 [01:35<01:30, 210.19 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26899/47780 [01:35<01:04, 325.65 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28492/47780 [01:35<00:55, 346.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19400/47780 [01:35<01:40, 281.35 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28706/47780 [01:35<00:58, 326.20 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29982/47780 [01:35<01:05, 270.20 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28670/47780 [01:35<01:18, 244.77 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28858/47780 [01:35<01:26, 219.73 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28807/47780 [01:35<01:30, 210.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28527/47780 [01:35<00:57, 335.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19429/47780 [01:35<01:45, 268.71 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28751/47780 [01:35<00:53, 353.36 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26932/47780 [01:35<01:11, 293.35 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30025/47780 [01:35<00:58, 305.42 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28698/47780 [01:35<01:18, 243.70 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28882/47780 [01:35<01:23, 224.98 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28831/47780 [01:35<01:26, 218.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19462/47780 [01:35<01:39, 285.31 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28561/47780 [01:35<00:59, 322.98 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28793/47780 [01:35<00:51, 368.09 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26963/47780 [01:35<01:12, 287.94 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28723/47780 [01:35<01:19, 240.08 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30056/47780 [01:35<01:00, 290.61 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28911/47780 [01:35<01:20, 235.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28854/47780 [01:35<01:27, 216.81 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28596/47780 [01:35<00:58, 327.17 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19491/47780 [01:35<01:44, 271.61 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28832/47780 [01:35<00:51, 370.20 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26994/47780 [01:35<01:12, 287.77 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28750/47780 [01:35<01:16, 248.08 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30092/47780 [01:35<00:57, 306.25 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28935/47780 [01:35<01:21, 230.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28881/47780 [01:35<01:21, 231.63 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19520/47780 [01:35<01:42, 275.00 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28629/47780 [01:35<01:00, 315.56 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27024/47780 [01:35<01:13, 281.89 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28871/47780 [01:35<00:55, 340.19 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28778/47780 [01:35<01:14, 254.79 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30123/47780 [01:35<01:00, 294.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28961/47780 [01:35<01:22, 229.46 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28663/47780 [01:35<00:59, 321.03 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28905/47780 [01:35<01:28, 212.17 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19550/47780 [01:35<01:46, 265.88 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27053/47780 [01:35<01:16, 269.77 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28806/47780 [01:35<01:13, 259.10 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28906/47780 [01:35<00:59, 318.34 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30153/47780 [01:35<01:00, 292.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28998/47780 [01:35<01:13, 256.94 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28934/47780 [01:36<01:21, 230.78 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28696/47780 [01:35<01:00, 316.05 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19577/47780 [01:35<01:45, 266.31 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28843/47780 [01:35<01:05, 287.78 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27081/47780 [01:36<01:17, 267.91 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28945/47780 [01:36<00:56, 331.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30184/47780 [01:36<00:59, 294.26 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29028/47780 [01:36<01:11, 263.03 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28733/47780 [01:36<00:58, 323.98 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28958/47780 [01:36<01:24, 221.46 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19604/47780 [01:36<01:51, 253.65 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28884/47780 [01:36<00:59, 316.89 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27108/47780 [01:36<01:22, 250.73 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30214/47780 [01:36<01:02, 282.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28979/47780 [01:36<01:00, 308.78 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29055/47780 [01:36<01:12, 259.27 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28766/47780 [01:36<01:01, 311.33 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28981/47780 [01:36<01:27, 213.91 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19634/47780 [01:36<01:46, 263.56 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28918/47780 [01:36<00:59, 318.85 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27134/47780 [01:36<01:24, 245.07 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30243/47780 [01:36<01:04, 269.86 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29081/47780 [01:36<01:17, 242.80 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29006/47780 [01:36<01:23, 223.70 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29011/47780 [01:36<01:06, 280.29 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28799/47780 [01:36<01:01, 310.02 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19666/47780 [01:36<01:41, 276.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28950/47780 [01:36<01:02, 301.76 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27159/47780 [01:36<01:27, 236.04 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30276/47780 [01:36<01:01, 283.41 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29110/47780 [01:36<01:14, 250.56 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28837/47780 [01:36<00:57, 329.50 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29031/47780 [01:36<01:22, 226.16 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29040/47780 [01:36<01:11, 261.30 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19694/47780 [01:36<01:49, 256.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28981/47780 [01:36<01:02, 300.43 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27183/47780 [01:36<01:27, 236.20 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30305/47780 [01:36<01:03, 274.18 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29142/47780 [01:36<01:10, 263.82 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28873/47780 [01:36<00:56, 337.56 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29058/47780 [01:36<01:18, 238.17 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19722/47780 [01:36<01:48, 257.71 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29012/47780 [01:36<01:03, 296.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29067/47780 [01:36<01:16, 244.22 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27207/47780 [01:36<01:31, 225.94 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30338/47780 [01:36<01:00, 288.51 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29169/47780 [01:36<01:10, 262.74 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28913/47780 [01:36<00:53, 352.43 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29083/47780 [01:36<01:19, 233.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19756/47780 [01:36<01:39, 280.26 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29042/47780 [01:36<01:06, 280.17 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29093/47780 [01:36<01:17, 240.93 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27237/47780 [01:36<01:23, 246.22 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30368/47780 [01:36<01:01, 284.96 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28950/47780 [01:36<00:52, 357.32 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29200/47780 [01:36<01:08, 272.91 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29107/47780 [01:36<01:21, 228.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19788/47780 [01:36<01:37, 286.04 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29074/47780 [01:36<01:04, 289.55 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29124/47780 [01:36<01:12, 256.04 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30397/47780 [01:36<01:01, 283.28 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27262/47780 [01:36<01:26, 236.52 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28986/47780 [01:36<00:54, 344.54 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29228/47780 [01:36<01:09, 265.86 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29130/47780 [01:36<01:28, 211.70 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19817/47780 [01:36<01:44, 267.95 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30426/47780 [01:36<01:00, 285.20 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27289/47780 [01:36<01:24, 243.31 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29104/47780 [01:36<01:09, 268.37 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29150/47780 [01:36<01:19, 234.71 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29262/47780 [01:36<01:05, 283.72 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29021/47780 [01:36<00:55, 339.68 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29156/47780 [01:37<01:23, 222.43 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19846/47780 [01:36<01:42, 273.78 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30457/47780 [01:37<01:00, 285.92 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29136/47780 [01:37<01:08, 273.95 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27314/47780 [01:37<01:31, 224.87 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29291/47780 [01:37<01:07, 275.65 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29056/47780 [01:37<00:58, 320.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29184/47780 [01:37<01:18, 238.21 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19874/47780 [01:37<01:44, 266.78 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29174/47780 [01:37<01:34, 197.39 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29169/47780 [01:37<01:05, 285.41 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30486/47780 [01:37<01:05, 262.70 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27339/47780 [01:37<01:29, 229.12 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29319/47780 [01:37<01:08, 268.20 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29089/47780 [01:37<01:00, 309.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29209/47780 [01:37<01:17, 239.03 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19907/47780 [01:37<01:39, 281.54 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29237/47780 [01:37<01:01, 299.16 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29200/47780 [01:37<01:06, 279.85 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30518/47780 [01:37<01:02, 275.59 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27364/47780 [01:37<01:28, 230.18 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29348/47780 [01:37<01:08, 268.18 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29237/47780 [01:37<01:13, 250.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29121/47780 [01:37<01:01, 305.79 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29271/47780 [01:37<01:05, 281.24 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19937/47780 [01:37<01:49, 254.94 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29241/47780 [01:37<00:58, 315.62 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30546/47780 [01:37<01:02, 276.45 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27388/47780 [01:37<01:28, 230.88 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29263/47780 [01:37<01:13, 252.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29375/47780 [01:37<01:12, 254.75 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29152/47780 [01:37<01:08, 273.25 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29302/47780 [01:37<01:04, 286.98 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19973/47780 [01:37<01:39, 279.76 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29275/47780 [01:37<00:57, 319.92 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30584/47780 [01:37<00:57, 299.54 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27412/47780 [01:37<01:27, 232.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29290/47780 [01:37<01:12, 255.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29401/47780 [01:37<01:13, 250.34 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29186/47780 [01:37<01:03, 290.63 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20002/47780 [01:37<01:40, 276.35 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29310/47780 [01:37<00:57, 322.71 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30617/47780 [01:37<00:56, 304.85 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27440/47780 [01:37<01:23, 243.40 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29333/47780 [01:37<01:07, 271.62 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29320/47780 [01:37<01:09, 265.67 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29431/47780 [01:37<01:09, 264.02 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29218/47780 [01:37<01:03, 292.60 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29343/47780 [01:37<00:57, 322.22 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30664/47780 [01:37<00:48, 352.08 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20031/47780 [01:37<01:41, 273.21 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27465/47780 [01:37<01:22, 245.30 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29351/47780 [01:37<01:06, 277.12 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29362/47780 [01:37<01:10, 262.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29463/47780 [01:37<01:05, 279.92 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29248/47780 [01:37<01:02, 294.27 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30700/47780 [01:37<00:49, 346.37 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27495/47780 [01:37<01:18, 257.35 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29376/47780 [01:37<00:59, 309.98 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29382/47780 [01:37<01:04, 283.30 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20059/47780 [01:37<01:48, 255.74 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29394/47780 [01:37<01:06, 274.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29501/47780 [01:37<00:59, 308.67 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29278/47780 [01:37<01:03, 289.75 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27524/47780 [01:37<01:16, 264.70 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30737/47780 [01:37<00:50, 338.36 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29420/47780 [01:37<00:54, 339.38 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29412/47780 [01:37<01:04, 286.25 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20095/47780 [01:37<01:39, 279.59 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29533/47780 [01:37<00:59, 308.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29426/47780 [01:37<01:05, 280.84 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29312/47780 [01:37<01:01, 300.62 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27557/47780 [01:37<01:11, 283.75 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30784/47780 [01:38<00:46, 366.40 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20125/47780 [01:37<01:38, 280.64 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29455/47780 [01:37<01:05, 281.48 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29449/47780 [01:38<01:01, 296.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29455/47780 [01:37<00:56, 324.00 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29565/47780 [01:38<01:05, 276.55 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29351/47780 [01:38<00:56, 325.98 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27586/47780 [01:38<01:11, 281.73 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30821/47780 [01:38<00:47, 358.79 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20162/47780 [01:38<01:31, 302.35 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29485/47780 [01:38<01:04, 285.43 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29494/47780 [01:38<00:53, 339.95 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29480/47780 [01:38<01:02, 293.98 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29395/47780 [01:38<00:52, 353.08 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29597/47780 [01:38<01:06, 273.51 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27620/47780 [01:38<01:07, 298.53 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30859/47780 [01:38<00:47, 357.31 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29517/47780 [01:38<01:02, 291.86 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20200/47780 [01:38<01:27, 313.46 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29516/47780 [01:38<00:59, 305.93 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29529/47780 [01:38<00:55, 326.54 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29433/47780 [01:38<00:51, 358.68 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29628/47780 [01:38<01:06, 274.43 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27656/47780 [01:38<01:05, 306.84 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30895/47780 [01:38<00:48, 350.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29547/47780 [01:38<01:04, 284.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20232/47780 [01:38<01:29, 307.99 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29562/47780 [01:38<00:57, 317.89 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29547/47780 [01:38<01:02, 293.33 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29470/47780 [01:38<00:51, 353.06 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29666/47780 [01:38<01:00, 299.66 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27688/47780 [01:38<01:05, 306.97 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30934/47780 [01:38<00:46, 361.10 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29579/47780 [01:38<01:03, 287.40 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20263/47780 [01:38<01:32, 298.87 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29578/47780 [01:38<01:03, 285.55 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29594/47780 [01:38<01:01, 296.67 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29506/47780 [01:38<00:52, 347.68 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29697/47780 [01:38<01:00, 299.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27722/47780 [01:38<01:04, 309.38 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20304/47780 [01:38<01:24, 326.48 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29608/47780 [01:38<01:05, 276.19 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30971/47780 [01:38<00:51, 328.65 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29607/47780 [01:38<01:05, 277.61 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29624/47780 [01:38<01:01, 295.03 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29543/47780 [01:38<00:52, 350.04 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29728/47780 [01:38<01:04, 279.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27754/47780 [01:38<01:07, 298.69 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20337/47780 [01:38<01:26, 316.70 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29637/47780 [01:38<01:09, 259.86 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29638/47780 [01:38<01:04, 280.30 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29580/47780 [01:38<00:52, 343.92 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29654/47780 [01:38<01:05, 277.73 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29763/47780 [01:38<01:00, 298.79 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27784/47780 [01:38<01:06, 298.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31005/47780 [01:38<00:59, 280.66 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20369/47780 [01:38<01:29, 306.91 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29667/47780 [01:38<01:07, 267.68 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29667/47780 [01:38<01:05, 278.07 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29615/47780 [01:38<00:52, 345.29 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29685/47780 [01:38<01:03, 284.08 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29810/47780 [01:38<00:52, 343.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31035/47780 [01:38<01:00, 274.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27814/47780 [01:38<01:11, 279.78 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20401/47780 [01:38<01:29, 307.37 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29695/47780 [01:38<01:06, 270.96 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29695/47780 [01:38<01:10, 257.06 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29715/47780 [01:38<01:04, 282.03 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29650/47780 [01:38<00:55, 327.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29845/47780 [01:38<00:54, 326.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27862/47780 [01:38<00:59, 332.01 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31065/47780 [01:39<01:01, 269.94 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20434/47780 [01:38<01:27, 312.61 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29725/47780 [01:39<01:06, 273.45 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29724/47780 [01:38<01:08, 262.96 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29745/47780 [01:38<01:03, 284.09 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29684/47780 [01:39<00:55, 324.10 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29882/47780 [01:39<00:54, 327.30 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31097/47780 [01:39<00:59, 280.31 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27896/47780 [01:39<01:02, 319.59 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20467/47780 [01:39<01:26, 315.33 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29759/47780 [01:39<01:03, 284.06 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29774/47780 [01:39<01:03, 285.42 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29765/47780 [01:39<00:59, 302.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29721/47780 [01:39<00:53, 336.98 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31129/47780 [01:39<00:57, 287.97 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27938/47780 [01:39<00:57, 343.82 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29916/47780 [01:39<00:57, 312.80 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20501/47780 [01:39<01:25, 318.76 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29796/47780 [01:39<00:59, 301.05 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29788/47780 [01:39<01:05, 276.02 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29803/47780 [01:39<01:06, 268.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29755/47780 [01:39<00:56, 319.23 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27977/47780 [01:39<00:56, 352.98 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31159/47780 [01:39<00:59, 278.08 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29948/47780 [01:39<00:59, 299.23 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20533/47780 [01:39<01:32, 295.22 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29826/47780 [01:39<00:59, 302.13 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29827/47780 [01:39<01:01, 291.46 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29831/47780 [01:39<01:06, 268.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29788/47780 [01:39<00:57, 312.13 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28013/47780 [01:39<00:56, 350.96 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31188/47780 [01:39<00:59, 278.23 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29980/47780 [01:39<00:58, 302.39 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20567/47780 [01:39<01:28, 307.37 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29859/47780 [01:39<00:58, 306.61 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29862/47780 [01:39<01:05, 274.13 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29857/47780 [01:39<01:05, 274.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29820/47780 [01:39<00:59, 304.19 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28049/47780 [01:39<00:57, 341.76 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31217/47780 [01:39<01:01, 267.54 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30011/47780 [01:39<01:00, 293.80 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20599/47780 [01:39<01:30, 300.65 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29895/47780 [01:39<01:02, 287.68 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29890/47780 [01:39<01:02, 287.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29894/47780 [01:39<01:00, 297.49 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29851/47780 [01:39<01:03, 283.38 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28084/47780 [01:39<01:00, 325.64 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30049/47780 [01:39<00:56, 314.65 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31244/47780 [01:39<01:05, 253.95 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20630/47780 [01:39<01:33, 290.35 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29924/47780 [01:39<01:05, 271.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29921/47780 [01:39<01:04, 275.86 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29925/47780 [01:39<01:04, 276.14 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29889/47780 [01:39<00:58, 306.42 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30081/47780 [01:39<00:56, 312.70 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31270/47780 [01:39<01:05, 253.18 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28117/47780 [01:39<01:04, 303.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20664/47780 [01:39<01:29, 301.67 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29956/47780 [01:39<01:00, 292.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29952/47780 [01:39<01:07, 265.05 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29973/47780 [01:39<00:54, 326.93 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29924/47780 [01:39<00:56, 314.94 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30113/47780 [01:39<00:58, 301.03 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31299/47780 [01:39<01:02, 263.35 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20695/47780 [01:39<01:29, 302.49 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28148/47780 [01:39<01:06, 295.60 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29979/47780 [01:39<01:07, 263.43 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29986/47780 [01:39<01:01, 287.57 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30007/47780 [01:39<00:56, 316.78 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29964/47780 [01:39<00:54, 327.79 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31326/47780 [01:39<01:02, 264.99 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30144/47780 [01:39<01:00, 290.57 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28178/47780 [01:39<01:08, 284.43 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20726/47780 [01:39<01:35, 282.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30008/47780 [01:39<01:07, 265.19 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30016/47780 [01:39<01:02, 285.47 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30007/47780 [01:39<00:49, 356.05 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30040/47780 [01:40<00:57, 310.14 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31354/47780 [01:40<01:01, 266.57 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30178/47780 [01:40<00:58, 300.91 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28207/47780 [01:40<01:09, 282.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20755/47780 [01:40<01:40, 269.90 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30045/47780 [01:40<01:03, 279.80 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30035/47780 [01:40<01:09, 255.10 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30043/47780 [01:40<00:50, 348.67 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30072/47780 [01:40<00:58, 302.92 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31381/47780 [01:40<01:04, 255.64 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30209/47780 [01:40<00:58, 299.46 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28246/47780 [01:40<01:02, 312.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20783/47780 [01:40<01:40, 269.75 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30063/47780 [01:40<01:07, 261.93 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30074/47780 [01:40<01:03, 277.13 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30081/47780 [01:40<00:49, 354.61 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30108/47780 [01:40<00:57, 305.28 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30243/47780 [01:40<00:56, 308.41 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31407/47780 [01:40<01:05, 248.23 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28284/47780 [01:40<00:58, 331.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20811/47780 [01:40<01:41, 266.64 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30103/47780 [01:40<01:03, 277.60 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30118/47780 [01:40<00:49, 354.57 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30090/47780 [01:40<01:10, 252.62 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30286/47780 [01:40<00:51, 339.00 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31434/47780 [01:40<01:04, 251.88 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28318/47780 [01:40<01:02, 312.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30139/47780 [01:40<01:05, 271.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20838/47780 [01:40<01:41, 264.44 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30135/47780 [01:40<01:00, 289.63 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30131/47780 [01:40<01:00, 290.42 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30154/47780 [01:40<00:51, 340.08 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30321/47780 [01:40<00:51, 341.88 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31462/47780 [01:40<01:03, 256.83 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28351/47780 [01:40<01:02, 310.48 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30178/47780 [01:40<00:58, 298.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20868/47780 [01:40<01:39, 271.83 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30165/47780 [01:40<01:01, 286.07 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30163/47780 [01:40<01:00, 292.18 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30189/47780 [01:40<00:55, 314.92 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30356/47780 [01:40<00:51, 336.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31488/47780 [01:40<01:06, 243.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20900/47780 [01:40<01:35, 282.18 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28383/47780 [01:40<01:04, 299.70 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30200/47780 [01:40<00:58, 301.07 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30209/47780 [01:40<01:03, 277.71 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30193/47780 [01:40<01:01, 284.49 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30222/47780 [01:40<00:55, 318.86 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30391/47780 [01:40<00:54, 321.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31517/47780 [01:40<01:04, 253.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20929/47780 [01:40<01:35, 281.23 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28417/47780 [01:40<01:03, 304.08 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30231/47780 [01:40<00:59, 296.72 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30238/47780 [01:40<01:05, 269.77 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30225/47780 [01:40<01:00, 291.57 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30429/47780 [01:40<00:52, 331.10 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30255/47780 [01:40<00:57, 304.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31543/47780 [01:40<01:06, 244.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20971/47780 [01:40<01:25, 314.08 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28449/47780 [01:40<01:02, 308.33 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30265/47780 [01:40<00:56, 308.90 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30257/47780 [01:40<00:59, 296.16 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30266/47780 [01:40<01:08, 256.36 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30289/47780 [01:40<00:56, 308.24 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30463/47780 [01:40<00:56, 309.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28489/47780 [01:40<00:57, 334.35 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21006/47780 [01:40<01:23, 319.01 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31568/47780 [01:40<01:11, 225.80 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30296/47780 [01:40<00:57, 302.49 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30287/47780 [01:40<01:01, 283.87 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30321/47780 [01:40<00:58, 300.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30293/47780 [01:41<01:16, 228.95 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28523/47780 [01:41<00:58, 329.49 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30495/47780 [01:41<00:56, 305.27 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21038/47780 [01:40<01:26, 308.20 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31606/47780 [01:41<01:01, 261.62 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30327/47780 [01:41<00:59, 291.19 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30316/47780 [01:41<01:07, 256.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30333/47780 [01:41<01:04, 268.54 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30352/47780 [01:41<01:00, 287.84 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21080/47780 [01:41<01:18, 338.27 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28557/47780 [01:41<01:00, 320.11 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31633/47780 [01:41<01:02, 258.29 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30357/47780 [01:41<00:59, 293.67 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30526/47780 [01:41<01:02, 276.36 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30379/47780 [01:41<00:55, 314.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30347/47780 [01:41<01:07, 257.77 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30385/47780 [01:41<00:59, 293.32 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28590/47780 [01:41<01:01, 312.59 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21114/47780 [01:41<01:22, 323.75 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31661/47780 [01:41<01:02, 258.52 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30556/47780 [01:41<01:02, 276.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30387/47780 [01:41<01:02, 278.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30375/47780 [01:41<01:06, 260.59 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30412/47780 [01:41<00:56, 309.65 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30415/47780 [01:41<01:00, 288.75 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21151/47780 [01:41<01:19, 333.16 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28622/47780 [01:41<01:03, 303.23 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31688/47780 [01:41<01:02, 258.45 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30417/47780 [01:41<01:01, 282.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30590/47780 [01:41<00:59, 286.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30411/47780 [01:41<01:00, 285.07 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30445/47780 [01:41<01:00, 284.48 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28655/47780 [01:41<01:01, 308.70 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21185/47780 [01:41<01:22, 324.06 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31714/47780 [01:41<01:04, 247.94 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30622/47780 [01:41<00:58, 293.43 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30444/47780 [01:41<01:04, 270.32 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30446/47780 [01:41<01:09, 250.29 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30440/47780 [01:41<01:01, 282.48 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28686/47780 [01:41<01:02, 306.74 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31744/47780 [01:41<01:01, 261.64 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30474/47780 [01:41<01:06, 260.63 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21218/47780 [01:41<01:26, 308.46 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30488/47780 [01:41<00:55, 310.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30659/47780 [01:41<00:57, 299.89 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30491/47780 [01:41<00:59, 290.42 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30470/47780 [01:41<01:01, 281.96 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21251/47780 [01:41<01:25, 310.24 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30524/47780 [01:41<00:53, 323.25 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28717/47780 [01:41<01:07, 280.61 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31773/47780 [01:41<01:03, 252.48 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30702/47780 [01:41<00:51, 329.95 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30501/47780 [01:41<01:09, 247.36 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30503/47780 [01:41<00:59, 292.37 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30521/47780 [01:41<01:00, 284.15 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28746/47780 [01:41<01:07, 280.09 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30528/47780 [01:41<01:08, 250.69 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30558/47780 [01:41<00:54, 314.02 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31799/47780 [01:41<01:04, 246.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21283/47780 [01:41<01:30, 293.84 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30537/47780 [01:41<00:56, 303.54 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30736/47780 [01:41<00:58, 293.65 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30550/47780 [01:41<01:00, 282.71 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28783/47780 [01:41<01:02, 301.84 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31827/47780 [01:41<01:02, 253.69 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30567/47780 [01:41<01:00, 282.41 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21314/47780 [01:41<01:29, 294.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30591/47780 [01:41<00:55, 311.28 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30776/47780 [01:41<00:53, 315.08 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30579/47780 [01:41<01:01, 281.31 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30570/47780 [01:41<00:56, 302.04 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28816/47780 [01:42<01:01, 309.65 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31856/47780 [01:42<01:01, 260.94 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21348/47780 [01:41<01:26, 304.17 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30625/47780 [01:42<00:54, 316.14 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30597/47780 [01:42<01:00, 284.11 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30608/47780 [01:42<01:01, 280.43 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30614/47780 [01:42<00:50, 337.95 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30809/47780 [01:42<00:56, 302.49 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30630/47780 [01:42<00:57, 296.71 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21379/47780 [01:42<01:27, 302.37 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30662/47780 [01:42<00:52, 327.52 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31883/47780 [01:42<01:05, 244.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28851/47780 [01:42<01:05, 288.14 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30639/47780 [01:42<00:59, 287.61 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30648/47780 [01:42<00:51, 330.93 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30840/47780 [01:42<01:00, 280.60 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21410/47780 [01:42<01:26, 304.26 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30660/47780 [01:42<00:58, 291.29 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30696/47780 [01:42<00:52, 327.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28883/47780 [01:42<01:03, 296.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31910/47780 [01:42<01:04, 245.71 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30668/47780 [01:42<01:00, 283.50 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30683/47780 [01:42<00:53, 322.07 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30729/47780 [01:42<00:53, 320.90 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30869/47780 [01:42<01:03, 266.16 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30690/47780 [01:42<00:59, 286.93 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28916/47780 [01:42<01:02, 302.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21441/47780 [01:42<01:33, 283.15 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31936/47780 [01:42<01:06, 236.66 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30719/47780 [01:42<00:52, 324.67 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30697/47780 [01:42<01:06, 255.87 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30902/47780 [01:42<01:00, 280.09 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30727/47780 [01:42<00:56, 300.62 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30762/47780 [01:42<00:55, 309.37 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21470/47780 [01:42<01:33, 280.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28947/47780 [01:42<01:03, 294.70 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31961/47780 [01:42<01:08, 231.79 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30752/47780 [01:42<00:52, 322.33 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30730/47780 [01:42<01:02, 272.91 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30931/47780 [01:42<01:00, 279.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30758/47780 [01:42<00:56, 299.80 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21500/47780 [01:42<01:33, 281.17 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30794/47780 [01:42<00:58, 292.65 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28977/47780 [01:42<01:06, 283.66 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31993/47780 [01:42<01:02, 253.03 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30787/47780 [01:42<00:52, 323.51 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30766/47780 [01:42<00:57, 296.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30960/47780 [01:42<01:01, 274.91 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29007/47780 [01:42<01:05, 288.19 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30789/47780 [01:42<00:58, 288.95 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21529/47780 [01:42<01:39, 263.19 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30824/47780 [01:42<01:00, 282.31 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30798/47780 [01:42<00:58, 290.90 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32019/47780 [01:42<01:08, 230.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30820/47780 [01:42<00:56, 301.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30989/47780 [01:42<01:03, 266.15 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30819/47780 [01:42<00:58, 288.18 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21556/47780 [01:42<01:39, 262.31 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30860/47780 [01:42<00:56, 300.18 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29037/47780 [01:42<01:10, 264.52 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30830/47780 [01:42<00:56, 298.50 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32043/47780 [01:42<01:09, 227.65 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30851/47780 [01:42<00:58, 290.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31020/47780 [01:42<01:00, 277.95 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30848/47780 [01:42<01:00, 280.34 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21585/47780 [01:42<01:37, 269.53 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30892/47780 [01:42<00:56, 298.40 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29066/47780 [01:42<01:09, 268.35 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32068/47780 [01:43<01:07, 231.56 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30862/47780 [01:42<00:59, 285.16 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30881/47780 [01:42<00:59, 283.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31055/47780 [01:42<00:56, 294.88 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30881/47780 [01:42<00:58, 291.09 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21613/47780 [01:42<01:37, 269.32 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29096/47780 [01:43<01:08, 274.20 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30927/47780 [01:43<00:56, 299.06 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32094/47780 [01:43<01:06, 236.77 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30892/47780 [01:43<00:58, 289.14 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30916/47780 [01:43<00:56, 299.01 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31087/47780 [01:43<00:56, 295.17 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30915/47780 [01:43<00:56, 297.05 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21641/47780 [01:43<01:37, 269.05 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29127/47780 [01:43<01:06, 278.86 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30959/47780 [01:43<00:56, 299.18 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32118/47780 [01:43<01:06, 234.84 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30924/47780 [01:43<00:56, 297.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30954/47780 [01:43<00:53, 314.69 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31117/47780 [01:43<00:59, 277.83 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30948/47780 [01:43<00:56, 297.49 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21668/47780 [01:43<01:41, 258.13 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29161/47780 [01:43<01:02, 295.91 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30990/47780 [01:43<00:56, 295.67 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32148/47780 [01:43<01:01, 253.29 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30986/47780 [01:43<00:53, 316.04 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30955/47780 [01:43<01:00, 278.61 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30988/47780 [01:43<00:52, 319.38 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31156/47780 [01:43<00:55, 298.67 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21695/47780 [01:43<01:41, 258.25 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29191/47780 [01:43<01:04, 289.27 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31027/47780 [01:43<00:53, 312.98 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32179/47780 [01:43<00:58, 266.83 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31021/47780 [01:43<00:51, 325.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30987/47780 [01:43<00:58, 287.18 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31024/47780 [01:43<00:50, 330.80 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31188/47780 [01:43<00:55, 301.34 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21721/47780 [01:43<01:43, 253.00 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31059/47780 [01:43<00:53, 311.46 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29221/47780 [01:43<01:06, 279.95 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32209/47780 [01:43<00:56, 273.30 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31055/47780 [01:43<00:51, 322.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31021/47780 [01:43<00:55, 301.86 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31219/47780 [01:43<00:55, 298.89 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21751/47780 [01:43<01:37, 266.36 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31058/47780 [01:43<00:53, 315.32 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31091/47780 [01:43<00:53, 313.27 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29250/47780 [01:43<01:06, 276.59 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32237/47780 [01:43<00:59, 263.01 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31058/47780 [01:43<00:52, 321.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31089/47780 [01:43<00:52, 319.81 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31261/47780 [01:43<00:49, 331.24 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31092/47780 [01:43<00:51, 322.04 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21786/47780 [01:43<01:31, 284.45 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31123/47780 [01:43<00:54, 304.58 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29278/47780 [01:43<01:08, 271.43 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32267/47780 [01:43<00:58, 264.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31091/47780 [01:43<00:53, 311.44 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31122/47780 [01:43<00:52, 315.36 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31129/47780 [01:43<00:49, 335.53 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31295/47780 [01:43<00:52, 316.31 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21815/47780 [01:43<01:35, 273.08 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29306/47780 [01:43<01:10, 261.99 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31154/47780 [01:43<00:58, 284.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32294/47780 [01:43<00:58, 265.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31124/47780 [01:43<00:53, 311.45 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31157/47780 [01:43<00:52, 318.54 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31166/47780 [01:43<00:48, 344.93 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31327/47780 [01:43<00:53, 309.55 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21847/47780 [01:43<01:32, 279.80 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31183/47780 [01:43<00:59, 279.63 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29333/47780 [01:43<01:11, 258.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31156/47780 [01:43<00:53, 313.54 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32321/47780 [01:43<01:01, 249.63 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31193/47780 [01:43<00:50, 327.14 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31205/47780 [01:43<00:48, 339.09 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31360/47780 [01:43<00:52, 315.14 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21876/47780 [01:43<01:36, 269.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31212/47780 [01:44<01:00, 273.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31227/47780 [01:44<00:50, 330.26 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32348/47780 [01:44<01:02, 247.31 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31189/47780 [01:44<00:56, 294.64 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29359/47780 [01:44<01:20, 228.11 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31392/47780 [01:44<00:51, 316.22 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31240/47780 [01:44<00:50, 330.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21908/47780 [01:44<01:32, 278.55 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32378/47780 [01:44<00:58, 261.82 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31262/47780 [01:44<00:52, 317.53 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31240/47780 [01:44<01:04, 255.06 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31219/47780 [01:44<00:58, 282.37 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29383/47780 [01:44<01:22, 222.28 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31425/47780 [01:44<00:51, 317.07 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31274/47780 [01:44<00:51, 318.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21936/47780 [01:44<01:35, 270.06 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32405/47780 [01:44<00:58, 261.12 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31273/47780 [01:44<01:01, 269.62 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31309/47780 [01:44<00:46, 352.58 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31248/47780 [01:44<00:59, 279.47 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29411/47780 [01:44<01:18, 234.81 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31457/47780 [01:44<00:53, 302.86 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31307/47780 [01:44<00:51, 318.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21966/47780 [01:44<01:32, 278.33 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32434/47780 [01:44<00:58, 263.62 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31345/47780 [01:44<00:46, 350.05 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31304/47780 [01:44<00:59, 276.87 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31279/47780 [01:44<00:57, 284.74 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29435/47780 [01:44<01:23, 219.47 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31348/47780 [01:44<00:48, 340.60 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31488/47780 [01:44<00:55, 291.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21994/47780 [01:44<01:34, 272.29 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31382/47780 [01:44<00:46, 352.49 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31334/47780 [01:44<00:58, 280.99 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32461/47780 [01:44<01:02, 245.97 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31308/47780 [01:44<00:58, 283.08 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31384/47780 [01:44<00:47, 345.99 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29463/47780 [01:44<01:19, 230.72 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22030/47780 [01:44<01:27, 294.30 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31518/47780 [01:44<00:58, 276.37 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31364/47780 [01:44<00:57, 286.30 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31422/47780 [01:44<00:45, 361.99 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32490/47780 [01:44<00:59, 255.15 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31337/47780 [01:44<00:59, 275.60 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31421/47780 [01:44<00:46, 352.81 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29492/47780 [01:44<01:14, 244.11 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31552/47780 [01:44<00:55, 293.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22060/47780 [01:44<01:31, 282.51 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31393/47780 [01:44<00:59, 277.31 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32517/47780 [01:44<01:00, 250.61 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31374/47780 [01:44<00:54, 298.91 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31459/47780 [01:44<00:48, 337.06 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31465/47780 [01:44<00:43, 374.68 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29517/47780 [01:44<01:15, 242.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22090/47780 [01:44<01:29, 287.40 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31582/47780 [01:44<01:01, 263.07 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31496/47780 [01:44<00:47, 346.15 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31421/47780 [01:44<01:00, 268.35 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31407/47780 [01:44<00:53, 304.43 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32545/47780 [01:44<01:00, 253.38 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31503/47780 [01:44<00:45, 358.68 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29547/47780 [01:44<01:12, 252.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22119/47780 [01:44<01:29, 287.77 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31618/47780 [01:44<00:57, 279.60 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31448/47780 [01:44<01:02, 261.99 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31531/47780 [01:44<00:47, 342.78 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31444/47780 [01:44<00:50, 323.23 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32571/47780 [01:44<01:00, 249.38 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29581/47780 [01:44<01:06, 274.93 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31541/47780 [01:44<00:45, 356.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22152/47780 [01:44<01:28, 290.75 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31476/47780 [01:45<01:01, 266.14 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31647/47780 [01:44<00:58, 276.32 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31570/47780 [01:44<00:46, 348.99 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32598/47780 [01:45<00:59, 253.43 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29609/47780 [01:45<01:07, 270.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31577/47780 [01:45<00:46, 345.63 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31477/47780 [01:45<01:00, 268.97 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22183/47780 [01:45<01:33, 273.71 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31676/47780 [01:45<00:58, 273.95 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32628/47780 [01:45<00:56, 265.86 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31606/47780 [01:45<00:47, 340.41 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31504/47780 [01:45<01:04, 252.35 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29642/47780 [01:45<01:03, 283.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31612/47780 [01:45<00:46, 346.33 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22217/47780 [01:45<01:28, 289.22 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31506/47780 [01:45<01:02, 260.06 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31704/47780 [01:45<00:59, 269.67 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32658/47780 [01:45<00:56, 269.48 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31533/47780 [01:45<01:02, 260.18 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31641/47780 [01:45<00:49, 327.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29677/47780 [01:45<01:00, 299.59 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31647/47780 [01:45<00:51, 315.84 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31549/47780 [01:45<00:53, 301.64 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22247/47780 [01:45<01:31, 279.46 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31742/47780 [01:45<00:53, 298.77 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32691/47780 [01:45<00:53, 280.42 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31560/47780 [01:45<01:03, 257.10 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31674/47780 [01:45<00:49, 324.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29708/47780 [01:45<01:01, 292.42 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31585/47780 [01:45<00:51, 317.05 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31680/47780 [01:45<00:53, 300.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22276/47780 [01:45<01:33, 273.72 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32727/47780 [01:45<00:49, 303.07 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31593/47780 [01:45<00:58, 277.60 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31773/47780 [01:45<00:56, 284.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29739/47780 [01:45<01:01, 294.11 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31707/47780 [01:45<00:54, 293.30 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31618/47780 [01:45<00:52, 310.65 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22305/47780 [01:45<01:31, 278.01 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31711/47780 [01:45<00:55, 290.03 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31806/47780 [01:45<00:54, 293.78 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32758/47780 [01:45<00:53, 282.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29774/47780 [01:45<00:59, 303.19 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31737/47780 [01:45<00:56, 282.98 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31622/47780 [01:45<01:08, 235.05 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31651/47780 [01:45<00:52, 309.10 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22338/47780 [01:45<01:27, 290.33 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31743/47780 [01:45<00:54, 292.12 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32789/47780 [01:45<00:51, 289.72 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31836/47780 [01:45<00:57, 279.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29805/47780 [01:45<00:58, 305.05 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31769/47780 [01:45<00:56, 284.09 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31654/47780 [01:45<01:04, 251.94 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31684/47780 [01:45<00:51, 314.66 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22368/47780 [01:45<01:32, 276.07 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31779/47780 [01:45<00:53, 300.91 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31867/47780 [01:45<00:56, 282.13 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32819/47780 [01:45<00:53, 279.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29836/47780 [01:45<00:59, 299.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31801/47780 [01:45<00:54, 290.61 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31681/47780 [01:45<01:08, 236.36 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31810/47780 [01:45<00:53, 296.70 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22396/47780 [01:45<01:35, 266.27 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31716/47780 [01:45<00:56, 286.77 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31900/47780 [01:45<00:54, 293.24 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32853/47780 [01:45<00:50, 293.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29868/47780 [01:45<00:59, 302.03 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31831/47780 [01:45<00:56, 283.50 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31720/47780 [01:46<00:59, 271.29 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31842/47780 [01:45<00:53, 299.64 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31748/47780 [01:45<00:54, 291.88 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22425/47780 [01:45<01:34, 269.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31935/47780 [01:45<00:52, 301.34 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29899/47780 [01:45<00:59, 300.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32883/47780 [01:46<00:52, 284.48 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31860/47780 [01:46<00:56, 281.90 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31873/47780 [01:46<00:54, 294.18 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22453/47780 [01:46<01:35, 265.73 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31778/47780 [01:46<00:56, 281.94 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31749/47780 [01:46<01:02, 256.65 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32914/47780 [01:46<00:51, 289.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31966/47780 [01:46<00:53, 293.18 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29934/47780 [01:46<00:58, 304.51 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31889/47780 [01:46<00:59, 266.71 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31809/47780 [01:46<00:55, 287.15 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22484/47780 [01:46<01:32, 272.62 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31903/47780 [01:46<00:55, 284.97 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31779/47780 [01:46<01:00, 265.30 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32948/47780 [01:46<00:49, 297.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29978/47780 [01:46<00:51, 343.15 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31996/47780 [01:46<00:56, 279.93 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31932/47780 [01:46<00:51, 308.17 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22521/47780 [01:46<01:25, 296.85 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31843/47780 [01:46<00:53, 298.80 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31933/47780 [01:46<00:54, 288.84 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31807/47780 [01:46<01:01, 258.16 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32983/47780 [01:46<00:49, 301.94 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32033/47780 [01:46<00:52, 298.16 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30013/47780 [01:46<00:57, 309.29 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31965/47780 [01:46<00:51, 310.04 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31874/47780 [01:46<00:52, 301.80 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22552/47780 [01:46<01:25, 295.20 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31964/47780 [01:46<00:54, 291.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31835/47780 [01:46<01:00, 263.92 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32068/47780 [01:46<00:50, 312.34 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33014/47780 [01:46<00:51, 288.05 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30046/47780 [01:46<00:57, 308.02 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31997/47780 [01:46<00:50, 311.18 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31920/47780 [01:46<00:46, 343.84 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31997/47780 [01:46<00:52, 302.68 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22582/47780 [01:46<01:27, 288.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31862/47780 [01:46<01:00, 265.24 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32100/47780 [01:46<00:52, 300.91 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33046/47780 [01:46<00:50, 289.93 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30078/47780 [01:46<01:01, 289.40 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32029/47780 [01:46<00:52, 298.79 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31955/47780 [01:46<00:46, 337.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32029/47780 [01:46<00:53, 297.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31890/47780 [01:46<01:00, 260.89 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22612/47780 [01:46<01:32, 273.36 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33086/47780 [01:46<00:46, 314.73 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32131/47780 [01:46<00:53, 293.33 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30108/47780 [01:46<01:02, 283.17 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32060/47780 [01:46<00:54, 286.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31989/47780 [01:46<00:47, 330.70 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31923/47780 [01:46<00:57, 274.24 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22645/47780 [01:46<01:27, 288.42 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32060/47780 [01:46<00:58, 270.32 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33118/47780 [01:46<00:46, 312.08 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32162/47780 [01:46<00:54, 285.48 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30137/47780 [01:46<01:03, 276.09 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32029/47780 [01:46<00:44, 350.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32089/47780 [01:46<00:56, 277.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31951/47780 [01:46<00:57, 273.70 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22675/47780 [01:46<01:29, 279.62 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32099/47780 [01:46<00:51, 302.37 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33155/47780 [01:46<00:44, 328.46 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32191/47780 [01:46<00:55, 283.37 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30167/47780 [01:46<01:02, 281.53 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32071/47780 [01:46<00:43, 361.85 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32127/47780 [01:46<00:52, 299.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31979/47780 [01:46<00:57, 274.53 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22712/47780 [01:46<01:24, 297.97 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32130/47780 [01:46<00:52, 297.23 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32220/47780 [01:46<00:55, 282.54 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33189/47780 [01:47<00:48, 300.31 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30197/47780 [01:46<01:01, 283.92 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32007/47780 [01:47<00:57, 275.82 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32108/47780 [01:47<00:45, 341.19 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32159/47780 [01:47<00:53, 292.19 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22742/47780 [01:47<01:29, 279.73 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32161/47780 [01:47<00:55, 281.79 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32251/47780 [01:47<00:55, 277.64 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33220/47780 [01:47<00:50, 287.10 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30226/47780 [01:47<01:04, 270.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32035/47780 [01:47<00:57, 274.22 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32190/47780 [01:47<00:52, 296.98 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32143/47780 [01:47<00:47, 328.91 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22784/47780 [01:47<01:19, 314.79 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32190/47780 [01:47<00:57, 269.35 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32279/47780 [01:47<00:56, 274.90 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30257/47780 [01:47<01:02, 278.70 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32063/47780 [01:47<00:57, 272.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32220/47780 [01:47<00:52, 294.74 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33250/47780 [01:47<00:54, 268.13 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32177/47780 [01:47<00:48, 324.26 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32315/47780 [01:47<00:52, 296.01 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22816/47780 [01:47<01:26, 287.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32218/47780 [01:47<01:03, 246.96 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33281/47780 [01:47<00:53, 273.06 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32091/47780 [01:47<01:00, 259.71 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30286/47780 [01:47<01:07, 260.56 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32250/47780 [01:47<00:55, 279.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32210/47780 [01:47<00:53, 293.69 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32346/47780 [01:47<00:52, 293.26 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22846/47780 [01:47<01:26, 287.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32254/47780 [01:47<00:56, 275.42 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32119/47780 [01:47<00:59, 262.27 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33315/47780 [01:47<00:50, 284.03 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32279/47780 [01:47<00:58, 265.20 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30313/47780 [01:47<01:11, 242.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32240/47780 [01:47<00:53, 292.35 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32389/47780 [01:47<00:46, 328.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22882/47780 [01:47<01:23, 298.96 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32283/47780 [01:47<00:59, 259.95 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32149/47780 [01:47<00:57, 273.03 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33350/47780 [01:47<00:48, 296.68 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30340/47780 [01:47<01:10, 248.70 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32306/47780 [01:47<00:59, 260.80 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32423/47780 [01:47<00:46, 331.62 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32270/47780 [01:47<00:55, 281.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22913/47780 [01:47<01:22, 300.58 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32314/47780 [01:47<00:57, 270.27 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33383/47780 [01:47<00:47, 302.56 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32177/47780 [01:47<00:58, 265.60 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30370/47780 [01:47<01:06, 261.26 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32333/47780 [01:47<01:00, 255.00 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32459/47780 [01:47<00:45, 336.31 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32302/47780 [01:47<00:54, 286.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22944/47780 [01:47<01:23, 296.59 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32345/47780 [01:47<00:55, 278.03 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32205/47780 [01:47<00:58, 267.07 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33414/47780 [01:47<00:47, 300.81 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30397/47780 [01:47<01:07, 257.92 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32360/47780 [01:47<00:59, 258.89 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32496/47780 [01:47<00:44, 341.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32337/47780 [01:47<00:52, 294.04 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22974/47780 [01:47<01:30, 275.38 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32238/47780 [01:47<00:55, 281.98 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33446/47780 [01:47<00:48, 296.60 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32374/47780 [01:47<00:57, 265.96 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30434/47780 [01:47<01:01, 283.00 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32386/47780 [01:47<01:00, 256.34 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32540/47780 [01:47<00:41, 366.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32372/47780 [01:47<00:49, 309.39 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23008/47780 [01:47<01:28, 281.28 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32267/47780 [01:48<00:54, 283.75 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33476/47780 [01:48<00:48, 297.28 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32412/47780 [01:47<01:00, 254.64 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32401/47780 [01:47<01:01, 250.91 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30463/47780 [01:48<01:02, 278.48 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32404/47780 [01:48<00:50, 302.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32577/47780 [01:48<00:44, 339.61 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23050/47780 [01:48<01:18, 315.26 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32306/47780 [01:48<00:50, 308.02 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33506/47780 [01:48<00:49, 287.36 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32427/47780 [01:48<01:01, 250.39 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30494/47780 [01:48<01:00, 287.34 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32441/47780 [01:48<00:59, 258.83 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32436/47780 [01:48<00:50, 303.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32617/47780 [01:48<00:43, 352.44 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23084/47780 [01:48<01:16, 322.09 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32341/47780 [01:48<00:48, 319.98 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33538/47780 [01:48<00:48, 291.11 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30524/47780 [01:48<00:59, 287.97 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32471/47780 [01:48<00:57, 267.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32453/47780 [01:48<01:02, 245.06 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32467/47780 [01:48<00:54, 279.64 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23123/47780 [01:48<01:13, 333.85 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32654/47780 [01:48<00:47, 317.96 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33570/47780 [01:48<00:47, 299.32 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32374/47780 [01:48<00:52, 294.32 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30558/47780 [01:48<00:56, 302.82 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32519/47780 [01:48<00:46, 328.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32481/47780 [01:48<01:01, 249.60 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32521/47780 [01:48<00:43, 347.18 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23160/47780 [01:48<01:11, 344.08 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32687/47780 [01:48<00:49, 304.86 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33602/47780 [01:48<00:49, 285.54 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32554/47780 [01:48<00:46, 330.97 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30589/47780 [01:48<00:57, 298.05 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32509/47780 [01:48<00:59, 258.04 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32408/47780 [01:48<00:52, 291.95 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32568/47780 [01:48<00:39, 380.94 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23200/47780 [01:48<01:09, 356.07 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30624/47780 [01:48<00:54, 312.91 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32591/47780 [01:48<00:44, 338.50 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32545/47780 [01:48<00:53, 285.47 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33631/47780 [01:48<00:52, 271.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32438/47780 [01:48<00:54, 278.98 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32719/47780 [01:48<00:56, 264.47 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23248/47780 [01:48<01:02, 391.91 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32607/47780 [01:48<00:42, 356.31 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30658/47780 [01:48<00:54, 313.73 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32641/47780 [01:48<00:39, 381.17 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32583/47780 [01:48<00:49, 307.30 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33661/47780 [01:48<00:51, 273.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32467/47780 [01:48<00:55, 273.47 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23288/47780 [01:48<01:06, 370.86 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32645/47780 [01:48<00:41, 361.73 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32747/47780 [01:48<01:01, 246.15 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30690/47780 [01:48<00:55, 308.42 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32614/47780 [01:48<00:50, 297.89 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33690/47780 [01:48<00:50, 277.99 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32680/47780 [01:48<00:42, 358.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32495/47780 [01:48<00:56, 268.80 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23329/47780 [01:48<01:04, 379.54 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32682/47780 [01:48<00:41, 359.78 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32773/47780 [01:48<01:00, 247.30 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33718/47780 [01:48<00:50, 278.40 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30721/47780 [01:48<00:58, 291.64 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32644/47780 [01:48<00:53, 285.42 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32717/47780 [01:48<00:43, 349.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32528/47780 [01:48<00:54, 279.77 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32803/47780 [01:48<00:58, 255.88 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32720/47780 [01:48<00:42, 353.77 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23368/47780 [01:48<01:08, 357.90 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33748/47780 [01:49<00:49, 281.53 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30753/47780 [01:48<00:57, 296.63 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32677/47780 [01:48<00:50, 297.87 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32753/47780 [01:48<00:43, 349.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32560/47780 [01:49<00:52, 287.75 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32756/47780 [01:49<00:43, 347.40 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32830/47780 [01:49<01:01, 243.88 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23405/47780 [01:49<01:11, 342.29 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33787/47780 [01:49<00:45, 309.39 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30784/47780 [01:49<00:59, 284.37 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32599/47780 [01:49<00:48, 313.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32707/47780 [01:49<00:54, 279.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32789/47780 [01:49<00:45, 329.93 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32859/47780 [01:49<00:58, 253.58 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32791/47780 [01:49<00:45, 329.44 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23440/47780 [01:49<01:15, 324.48 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32743/47780 [01:49<00:50, 298.50 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32637/47780 [01:49<00:46, 325.82 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33820/47780 [01:49<00:48, 285.22 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32824/47780 [01:49<00:45, 331.81 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30813/47780 [01:49<01:02, 270.85 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32890/47780 [01:49<00:55, 268.52 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32825/47780 [01:49<00:48, 308.22 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23473/47780 [01:49<01:16, 317.44 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32781/47780 [01:49<00:46, 321.38 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33860/47780 [01:49<00:43, 316.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32673/47780 [01:49<00:45, 330.64 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32858/47780 [01:49<00:45, 330.42 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30841/47780 [01:49<01:03, 264.72 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32922/47780 [01:49<00:53, 279.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32815/47780 [01:49<00:46, 323.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32857/47780 [01:49<00:50, 296.11 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33893/47780 [01:49<00:45, 304.21 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32707/47780 [01:49<00:46, 325.07 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30876/47780 [01:49<00:58, 287.28 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23505/47780 [01:49<01:27, 278.86 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32892/47780 [01:49<00:51, 290.34 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32959/47780 [01:49<00:49, 302.07 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32848/47780 [01:49<00:46, 321.26 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30908/47780 [01:49<00:57, 294.00 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33930/47780 [01:49<00:44, 314.71 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32740/47780 [01:49<00:49, 305.98 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32887/47780 [01:49<00:53, 276.23 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23542/47780 [01:49<01:20, 299.34 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32993/47780 [01:49<00:48, 302.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32922/47780 [01:49<00:53, 278.27 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32881/47780 [01:49<00:50, 296.41 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32920/47780 [01:49<00:51, 287.46 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32771/47780 [01:49<00:49, 303.59 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30938/47780 [01:49<01:01, 273.63 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33962/47780 [01:49<00:48, 287.52 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23573/47780 [01:49<01:26, 281.28 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33030/47780 [01:49<00:45, 321.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32951/47780 [01:49<00:53, 275.63 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32919/47780 [01:49<00:47, 312.35 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32802/47780 [01:49<00:51, 288.84 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30966/47780 [01:49<01:03, 266.85 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32950/47780 [01:49<00:54, 273.22 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23602/47780 [01:49<01:25, 283.53 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33992/47780 [01:49<00:49, 276.00 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33063/47780 [01:49<00:46, 316.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32988/47780 [01:49<00:49, 297.61 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32832/47780 [01:49<00:51, 289.08 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32983/47780 [01:49<00:51, 285.37 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30993/47780 [01:49<01:03, 264.61 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23633/47780 [01:49<01:24, 286.60 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32951/47780 [01:49<00:52, 283.25 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33104/47780 [01:49<00:43, 339.50 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34021/47780 [01:49<00:50, 271.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33025/47780 [01:49<00:47, 310.86 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32864/47780 [01:50<00:50, 294.89 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31023/47780 [01:49<01:01, 273.66 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33018/47780 [01:49<00:49, 296.43 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23667/47780 [01:49<01:21, 295.88 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34057/47780 [01:50<00:47, 288.45 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33057/47780 [01:49<00:47, 309.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32981/47780 [01:49<00:55, 265.10 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33139/47780 [01:50<00:47, 310.12 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31056/47780 [01:50<00:58, 287.62 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32894/47780 [01:50<00:50, 292.99 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33048/47780 [01:50<00:50, 294.26 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23704/47780 [01:50<01:16, 314.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34088/47780 [01:50<00:49, 276.47 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33089/47780 [01:50<00:52, 280.97 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33171/47780 [01:50<00:50, 291.05 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33009/47780 [01:50<01:01, 241.77 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32924/47780 [01:50<00:50, 291.65 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33078/47780 [01:50<00:49, 295.83 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31086/47780 [01:50<00:59, 282.95 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23739/47780 [01:50<01:14, 322.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34118/47780 [01:50<00:49, 277.15 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33120/47780 [01:50<00:51, 286.03 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33205/47780 [01:50<00:48, 300.76 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33039/47780 [01:50<00:57, 255.96 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32954/47780 [01:50<00:50, 293.68 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31130/47780 [01:50<00:51, 325.94 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33110/47780 [01:50<00:49, 299.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23772/47780 [01:50<01:15, 317.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34147/47780 [01:50<00:48, 280.57 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33151/47780 [01:50<00:51, 286.17 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33236/47780 [01:50<00:47, 303.02 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33066/47780 [01:50<00:57, 257.07 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32984/47780 [01:50<00:50, 292.43 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33150/47780 [01:50<00:44, 328.28 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31166/47780 [01:50<00:49, 335.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23804/47780 [01:50<01:23, 286.08 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34176/47780 [01:50<00:51, 265.15 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33180/47780 [01:50<00:51, 281.01 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33093/47780 [01:50<00:58, 252.38 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33268/47780 [01:50<00:51, 282.47 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31201/47780 [01:50<00:50, 328.44 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33014/47780 [01:50<00:53, 273.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33184/47780 [01:50<00:50, 288.19 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23834/47780 [01:50<01:24, 282.67 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34205/47780 [01:50<00:50, 269.20 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33214/47780 [01:50<00:48, 297.33 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33123/47780 [01:50<00:56, 259.86 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31237/47780 [01:50<00:49, 337.25 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33297/47780 [01:50<00:51, 278.65 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33045/47780 [01:50<00:52, 282.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33216/47780 [01:50<00:50, 290.46 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23863/47780 [01:50<01:24, 282.19 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34233/47780 [01:50<00:51, 263.42 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33150/47780 [01:50<00:57, 254.58 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31272/47780 [01:50<00:48, 340.89 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33331/47780 [01:50<00:49, 292.29 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33245/47780 [01:50<00:53, 270.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33074/47780 [01:50<00:52, 277.74 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23892/47780 [01:50<01:25, 280.90 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33247/47780 [01:50<00:51, 280.54 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34261/47780 [01:50<00:50, 267.79 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33185/47780 [01:50<00:52, 280.59 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31307/47780 [01:50<00:51, 322.23 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33273/47780 [01:50<00:55, 261.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33361/47780 [01:50<00:51, 278.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33102/47780 [01:50<00:58, 250.32 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33276/47780 [01:50<00:51, 282.54 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23921/47780 [01:50<01:27, 271.39 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34292/47780 [01:50<00:50, 264.90 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33218/47780 [01:50<00:49, 294.47 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31341/47780 [01:50<00:50, 322.79 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33304/47780 [01:50<00:53, 271.85 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33395/47780 [01:50<00:49, 292.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33128/47780 [01:51<00:57, 252.86 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33308/47780 [01:50<00:50, 287.04 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23949/47780 [01:50<01:28, 270.72 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34320/47780 [01:51<00:50, 266.21 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33254/47780 [01:50<00:47, 306.34 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31376/47780 [01:51<00:49, 330.21 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33341/47780 [01:51<00:48, 295.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33428/47780 [01:51<00:47, 299.64 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33154/47780 [01:51<01:01, 239.19 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33338/47780 [01:51<00:50, 284.25 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23978/47780 [01:51<01:28, 270.36 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34347/47780 [01:51<00:53, 252.53 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33373/47780 [01:51<00:47, 300.89 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31410/47780 [01:51<00:51, 318.24 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33459/47780 [01:51<00:50, 283.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33287/47780 [01:51<00:54, 264.56 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33382/47780 [01:51<00:44, 324.41 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24007/47780 [01:51<01:26, 275.73 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33186/47780 [01:51<00:57, 255.47 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34373/47780 [01:51<00:54, 244.28 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33404/47780 [01:51<00:48, 294.75 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31443/47780 [01:51<00:50, 321.35 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33488/47780 [01:51<00:51, 279.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33337/47780 [01:51<00:44, 321.84 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24038/47780 [01:51<01:24, 282.58 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33415/47780 [01:51<00:45, 318.46 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33212/47780 [01:51<00:58, 248.88 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34400/47780 [01:51<00:53, 251.31 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31476/47780 [01:51<00:50, 320.15 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33434/47780 [01:51<00:50, 286.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33518/47780 [01:51<00:50, 281.70 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33377/47780 [01:51<00:43, 328.50 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24067/47780 [01:51<01:23, 283.53 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33464/47780 [01:51<00:39, 363.30 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33243/47780 [01:51<00:54, 265.44 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34430/47780 [01:51<00:50, 263.61 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31509/47780 [01:51<00:53, 305.33 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33469/47780 [01:51<00:49, 291.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33547/47780 [01:51<00:51, 277.78 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33413/47780 [01:51<00:42, 336.67 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33501/47780 [01:51<00:39, 361.11 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33274/47780 [01:51<00:53, 271.92 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24096/47780 [01:51<01:32, 256.70 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34457/47780 [01:51<00:51, 260.93 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31540/47780 [01:51<00:54, 300.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33503/47780 [01:51<00:48, 295.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33575/47780 [01:51<00:52, 272.21 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33448/47780 [01:51<00:43, 332.93 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33309/47780 [01:51<00:49, 290.72 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24126/47780 [01:51<01:29, 265.43 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33539/47780 [01:51<00:42, 332.29 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34484/47780 [01:51<00:52, 254.78 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31574/47780 [01:51<00:52, 311.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33538/47780 [01:51<00:45, 310.22 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33603/47780 [01:51<00:53, 265.48 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33484/47780 [01:51<00:43, 326.43 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33350/47780 [01:51<00:44, 320.71 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24158/47780 [01:51<01:25, 277.60 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33574/47780 [01:51<00:42, 336.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33570/47780 [01:51<00:46, 304.97 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31606/47780 [01:51<00:55, 293.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34510/47780 [01:51<00:57, 230.12 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33632/47780 [01:51<00:52, 269.32 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33386/47780 [01:51<00:43, 328.39 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24194/47780 [01:51<01:20, 294.26 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33609/47780 [01:51<00:42, 332.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33519/47780 [01:51<00:49, 285.67 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31645/47780 [01:51<00:51, 314.27 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33601/47780 [01:51<00:47, 297.42 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34537/47780 [01:51<00:56, 235.70 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33661/47780 [01:51<00:54, 260.41 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33419/47780 [01:51<00:45, 317.56 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24228/47780 [01:51<01:16, 307.04 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33646/47780 [01:51<00:41, 342.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33561/47780 [01:51<00:44, 319.57 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31678/47780 [01:51<00:50, 317.67 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34562/47780 [01:52<00:55, 239.40 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33631/47780 [01:51<00:49, 285.10 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33691/47780 [01:52<00:52, 268.53 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33451/47780 [01:52<00:46, 310.59 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24267/47780 [01:51<01:11, 330.79 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33681/47780 [01:52<00:41, 337.85 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33595/47780 [01:52<00:46, 305.08 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34593/47780 [01:52<00:51, 256.47 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31714/47780 [01:52<00:49, 322.61 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33718/47780 [01:52<00:52, 266.66 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33660/47780 [01:52<00:50, 276.93 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33497/47780 [01:52<00:40, 350.25 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33718/47780 [01:52<00:40, 343.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24304/47780 [01:52<01:10, 330.79 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33627/47780 [01:52<00:47, 299.97 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34623/47780 [01:52<00:49, 265.98 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31752/47780 [01:52<00:47, 335.09 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33688/47780 [01:52<00:52, 269.24 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33746/47780 [01:52<00:53, 260.32 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33754/47780 [01:52<00:41, 340.54 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33533/47780 [01:52<00:43, 327.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24338/47780 [01:52<01:13, 318.47 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34650/47780 [01:52<00:49, 267.02 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31786/47780 [01:52<00:48, 332.37 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33658/47780 [01:52<00:49, 284.36 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33717/47780 [01:52<00:52, 266.15 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33773/47780 [01:52<00:56, 249.42 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33789/47780 [01:52<00:41, 335.25 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33567/47780 [01:52<00:43, 326.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24371/47780 [01:52<01:17, 303.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34677/47780 [01:52<00:49, 265.15 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31823/47780 [01:52<00:47, 338.23 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33693/47780 [01:52<00:47, 298.58 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33746/47780 [01:52<00:51, 272.64 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33801/47780 [01:52<00:54, 255.03 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33823/47780 [01:52<00:42, 329.30 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33600/47780 [01:52<00:44, 316.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24402/47780 [01:52<01:17, 302.73 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34707/47780 [01:52<00:49, 263.20 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33732/47780 [01:52<00:43, 322.81 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31857/47780 [01:52<00:49, 324.88 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33775/47780 [01:52<00:51, 271.82 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33827/47780 [01:52<00:54, 256.42 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33856/47780 [01:52<00:44, 315.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24433/47780 [01:52<01:19, 295.15 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33765/47780 [01:52<00:44, 311.56 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31890/47780 [01:52<00:50, 312.43 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33863/47780 [01:52<00:48, 285.86 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33635/47780 [01:52<00:53, 266.82 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33812/47780 [01:52<00:47, 292.60 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34735/47780 [01:52<00:53, 242.44 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33893/47780 [01:52<00:42, 330.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24467/47780 [01:52<01:16, 304.59 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33678/47780 [01:52<00:45, 306.77 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33893/47780 [01:52<00:48, 286.53 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34770/47780 [01:52<00:47, 271.31 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33797/47780 [01:52<00:47, 297.34 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33843/47780 [01:52<00:47, 291.09 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31922/47780 [01:52<00:57, 274.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24500/47780 [01:52<01:14, 311.77 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33929/47780 [01:52<00:45, 305.49 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33924/47780 [01:52<00:47, 290.36 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34800/47780 [01:52<00:46, 276.58 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33828/47780 [01:52<00:47, 296.74 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33883/47780 [01:52<00:43, 318.40 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33711/47780 [01:52<00:48, 288.43 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31959/47780 [01:52<00:53, 296.20 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24539/47780 [01:52<01:10, 330.36 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33964/47780 [01:52<00:44, 312.76 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33861/47780 [01:52<00:45, 303.66 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33915/47780 [01:52<00:43, 318.59 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34829/47780 [01:53<00:48, 268.07 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33954/47780 [01:52<00:52, 262.66 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31992/47780 [01:52<00:52, 302.00 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24573/47780 [01:52<01:09, 332.07 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33742/47780 [01:53<00:51, 274.43 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34000/47780 [01:53<00:42, 325.65 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34860/47780 [01:53<00:46, 279.61 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33947/47780 [01:53<00:44, 308.27 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33892/47780 [01:53<00:48, 285.97 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33984/47780 [01:53<00:51, 266.87 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33774/47780 [01:53<00:49, 283.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32023/47780 [01:53<00:54, 291.14 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24607/47780 [01:53<01:13, 313.48 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34033/47780 [01:53<00:42, 322.82 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33978/47780 [01:53<00:45, 305.55 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34889/47780 [01:53<00:47, 270.59 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33921/47780 [01:53<00:48, 287.02 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34015/47780 [01:53<00:49, 278.72 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33804/47780 [01:53<00:48, 287.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32054/47780 [01:53<00:53, 293.39 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24641/47780 [01:53<01:12, 317.55 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34067/47780 [01:53<00:44, 310.58 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34924/47780 [01:53<00:43, 292.77 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34009/47780 [01:53<00:46, 296.53 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33950/47780 [01:53<00:50, 272.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32088/47780 [01:53<00:51, 306.36 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34044/47780 [01:53<00:51, 266.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33834/47780 [01:53<00:49, 284.51 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24673/47780 [01:53<01:14, 311.18 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34100/47780 [01:53<00:44, 310.28 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34039/47780 [01:53<00:47, 291.21 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34954/47780 [01:53<00:45, 283.25 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33978/47780 [01:53<00:50, 274.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32126/47780 [01:53<00:48, 323.59 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34072/47780 [01:53<00:51, 264.65 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33866/47780 [01:53<00:48, 285.31 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24708/47780 [01:53<01:12, 318.45 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34143/47780 [01:53<00:39, 342.47 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34069/47780 [01:53<00:48, 281.62 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34006/47780 [01:53<00:51, 267.24 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32163/47780 [01:53<00:46, 333.10 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34983/47780 [01:53<00:48, 265.47 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34101/47780 [01:53<00:50, 268.82 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33906/47780 [01:53<00:44, 313.53 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24741/47780 [01:53<01:13, 314.29 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34178/47780 [01:53<00:40, 336.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34102/47780 [01:53<00:46, 294.12 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32198/47780 [01:53<00:47, 330.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35022/47780 [01:53<00:43, 293.53 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34033/47780 [01:53<00:54, 253.40 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34130/47780 [01:53<00:50, 268.62 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33939/47780 [01:53<00:45, 307.54 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24777/47780 [01:53<01:11, 322.94 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34212/47780 [01:53<00:40, 337.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32235/47780 [01:53<00:45, 341.67 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34073/47780 [01:53<00:47, 290.87 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35052/47780 [01:53<00:44, 288.76 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34133/47780 [01:53<00:49, 276.04 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34157/47780 [01:53<00:52, 260.14 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24814/47780 [01:53<01:08, 333.72 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33976/47780 [01:53<00:43, 318.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34248/47780 [01:53<00:40, 336.27 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34109/47780 [01:53<00:44, 309.97 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35092/47780 [01:53<00:39, 319.00 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34178/47780 [01:53<00:42, 317.30 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34185/47780 [01:53<00:51, 265.50 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32270/47780 [01:53<00:48, 321.66 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34011/47780 [01:53<00:42, 323.40 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34282/47780 [01:53<00:40, 333.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24848/47780 [01:53<01:12, 316.90 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35125/47780 [01:54<00:41, 305.45 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34215/47780 [01:53<00:49, 272.45 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34212/47780 [01:53<00:44, 306.19 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34141/47780 [01:53<00:47, 286.64 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32303/47780 [01:53<00:50, 306.82 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24880/47780 [01:53<01:12, 314.50 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34044/47780 [01:54<00:44, 310.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34316/47780 [01:54<00:44, 303.72 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34244/47780 [01:54<00:51, 265.32 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32338/47780 [01:54<00:48, 318.66 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24916/47780 [01:54<01:09, 327.27 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34078/47780 [01:54<00:43, 316.01 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34176/47780 [01:54<00:46, 294.52 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34243/47780 [01:54<00:45, 300.67 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35157/47780 [01:54<00:43, 292.22 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34347/47780 [01:54<00:45, 295.78 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34271/47780 [01:54<00:50, 266.19 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24949/47780 [01:54<01:10, 324.63 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34113/47780 [01:54<00:41, 325.49 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34274/47780 [01:54<00:45, 300.13 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32371/47780 [01:54<00:50, 304.79 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34206/47780 [01:54<00:47, 286.42 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35191/47780 [01:54<00:43, 287.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34377/47780 [01:54<00:48, 276.04 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34147/47780 [01:54<00:42, 318.88 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32403/47780 [01:54<00:49, 308.68 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24982/47780 [01:54<01:13, 308.25 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35221/47780 [01:54<00:43, 290.34 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34305/47780 [01:54<00:48, 278.16 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34298/47780 [01:54<00:56, 240.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34235/47780 [01:54<00:53, 251.76 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34406/47780 [01:54<00:50, 262.75 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34180/47780 [01:54<00:42, 318.04 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34325/47780 [01:54<00:54, 245.56 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34336/47780 [01:54<00:47, 280.73 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25014/47780 [01:54<01:18, 288.77 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32436/47780 [01:54<00:53, 285.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34273/47780 [01:54<00:47, 281.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35251/47780 [01:54<00:48, 256.04 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34435/47780 [01:54<00:49, 269.88 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34350/47780 [01:54<00:54, 246.77 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34212/47780 [01:54<00:45, 300.74 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34365/47780 [01:54<00:47, 279.82 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25044/47780 [01:54<01:19, 285.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32466/47780 [01:54<00:54, 283.02 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35281/47780 [01:54<00:47, 262.66 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34463/47780 [01:54<00:49, 269.67 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34303/47780 [01:54<00:50, 264.75 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34380/47780 [01:54<00:51, 258.80 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34246/47780 [01:54<00:44, 305.83 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34402/47780 [01:54<00:44, 301.94 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32495/47780 [01:54<00:55, 276.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25073/47780 [01:54<01:24, 268.46 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35314/47780 [01:54<00:45, 275.11 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34336/47780 [01:54<00:47, 280.89 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34492/47780 [01:54<00:48, 272.11 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34422/47780 [01:54<00:43, 304.01 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34437/47780 [01:54<00:43, 308.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32529/47780 [01:54<00:52, 293.06 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35344/47780 [01:54<00:44, 278.32 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34277/47780 [01:54<00:50, 269.88 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25102/47780 [01:54<01:26, 260.81 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34365/47780 [01:54<00:48, 277.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34520/47780 [01:54<00:50, 263.05 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34471/47780 [01:54<00:42, 313.96 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34453/47780 [01:54<00:47, 280.21 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32559/47780 [01:54<00:53, 286.27 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35374/47780 [01:54<00:43, 284.23 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34314/47780 [01:54<00:45, 293.39 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25140/47780 [01:54<01:18, 289.68 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34394/47780 [01:54<00:48, 277.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34547/47780 [01:54<00:49, 264.92 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34504/47780 [01:54<00:41, 318.24 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34484/47780 [01:54<00:46, 285.72 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32588/47780 [01:54<00:53, 284.09 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35408/47780 [01:55<00:41, 296.77 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25179/47780 [01:54<01:11, 317.04 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34574/47780 [01:55<00:49, 266.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34345/47780 [01:55<00:47, 284.81 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34423/47780 [01:55<00:49, 272.02 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34539/47780 [01:55<00:40, 324.02 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32620/47780 [01:55<00:52, 291.00 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35438/47780 [01:55<00:41, 293.91 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25214/47780 [01:55<01:09, 322.65 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34514/47780 [01:55<00:50, 260.53 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34602/47780 [01:55<00:48, 270.04 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34384/47780 [01:55<00:43, 307.43 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34451/47780 [01:55<00:52, 254.01 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34573/47780 [01:55<00:41, 321.11 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32657/47780 [01:55<00:48, 312.69 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35468/47780 [01:55<00:43, 286.16 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34554/47780 [01:55<00:44, 297.35 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25247/47780 [01:55<01:12, 310.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34421/47780 [01:55<00:41, 321.12 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34481/47780 [01:55<00:50, 264.01 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34630/47780 [01:55<00:54, 242.00 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34607/47780 [01:55<00:40, 323.74 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35501/47780 [01:55<00:41, 295.41 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32689/47780 [01:55<00:51, 291.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25279/47780 [01:55<01:12, 309.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34585/47780 [01:55<00:46, 282.43 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34454/47780 [01:55<00:43, 303.06 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34664/47780 [01:55<00:49, 263.04 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34516/47780 [01:55<00:48, 272.70 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34640/47780 [01:55<00:41, 317.36 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32731/47780 [01:55<00:46, 327.15 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35535/47780 [01:55<00:41, 297.92 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34621/47780 [01:55<00:43, 303.14 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34490/47780 [01:55<00:42, 315.22 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25311/47780 [01:55<01:19, 280.98 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34691/47780 [01:55<00:49, 262.03 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34674/47780 [01:55<00:40, 320.14 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34563/47780 [01:55<00:41, 315.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35565/47780 [01:55<00:41, 291.72 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32765/47780 [01:55<00:49, 303.88 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34522/47780 [01:55<00:41, 315.83 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34654/47780 [01:55<00:45, 290.93 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34596/47780 [01:55<00:42, 312.73 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34708/47780 [01:55<00:41, 314.68 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25340/47780 [01:55<01:29, 251.11 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34718/47780 [01:55<00:56, 232.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35602/47780 [01:55<00:39, 306.99 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34554/47780 [01:55<00:43, 307.29 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32798/47780 [01:55<00:50, 297.79 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34684/47780 [01:55<00:46, 281.12 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34629/47780 [01:55<00:41, 314.34 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34742/47780 [01:55<00:41, 314.91 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34743/47780 [01:55<00:55, 234.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25381/47780 [01:55<01:19, 282.71 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35634/47780 [01:55<00:40, 300.57 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32830/47780 [01:55<00:49, 303.66 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34717/47780 [01:55<00:44, 294.15 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34585/47780 [01:55<00:45, 288.80 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34666/47780 [01:55<00:40, 322.69 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34774/47780 [01:55<00:42, 306.13 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25413/47780 [01:55<01:17, 289.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34768/47780 [01:55<00:55, 233.86 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35674/47780 [01:55<00:37, 324.80 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32861/47780 [01:55<00:49, 298.68 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34747/47780 [01:55<00:44, 293.04 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34615/47780 [01:55<00:47, 278.99 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34812/47780 [01:55<00:40, 323.21 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34793/47780 [01:55<00:55, 235.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34699/47780 [01:55<00:43, 304.04 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35707/47780 [01:56<00:37, 326.27 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25444/47780 [01:55<01:24, 265.45 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32894/47780 [01:55<00:48, 304.32 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34777/47780 [01:55<00:45, 285.12 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34651/47780 [01:56<00:43, 298.43 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34832/47780 [01:56<00:46, 278.64 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34736/47780 [01:56<00:40, 318.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34845/47780 [01:56<00:41, 310.83 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25482/47780 [01:56<01:16, 292.93 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32925/47780 [01:56<00:49, 302.25 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35740/47780 [01:56<00:38, 308.88 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34810/47780 [01:56<00:43, 296.09 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34866/47780 [01:56<00:44, 292.65 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34882/47780 [01:56<00:39, 323.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34682/47780 [01:56<00:48, 271.35 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25515/47780 [01:56<01:13, 302.65 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35776/47780 [01:56<00:37, 316.81 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34769/47780 [01:56<00:46, 281.08 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32956/47780 [01:56<00:50, 294.64 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34840/47780 [01:56<00:45, 281.60 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34710/47780 [01:56<00:48, 267.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34896/47780 [01:56<00:46, 278.91 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25552/47780 [01:56<01:09, 317.90 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34915/47780 [01:56<00:44, 289.03 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32990/47780 [01:56<00:48, 307.33 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35810/47780 [01:56<00:39, 302.16 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34801/47780 [01:56<00:47, 274.16 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34873/47780 [01:56<00:44, 290.02 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34929/47780 [01:56<00:43, 293.05 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34738/47780 [01:56<00:50, 257.52 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25591/47780 [01:56<01:06, 334.33 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34945/47780 [01:56<00:45, 283.42 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33021/47780 [01:56<00:50, 294.38 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34836/47780 [01:56<00:44, 287.88 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35841/47780 [01:56<00:41, 289.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34903/47780 [01:56<00:48, 263.79 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34959/47780 [01:56<00:44, 285.32 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34769/47780 [01:56<00:48, 265.80 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34977/47780 [01:56<00:44, 290.13 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25625/47780 [01:56<01:11, 311.03 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33054/47780 [01:56<00:48, 301.29 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35883/47780 [01:56<00:36, 324.35 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34866/47780 [01:56<00:46, 279.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34930/47780 [01:56<00:49, 261.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34990/47780 [01:56<00:44, 289.07 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34806/47780 [01:56<00:44, 291.04 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35007/47780 [01:56<00:44, 289.72 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25662/47780 [01:56<01:08, 321.18 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33086/47780 [01:56<00:48, 303.29 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35918/47780 [01:56<00:35, 331.19 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34897/47780 [01:56<00:46, 278.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34967/47780 [01:56<00:44, 288.43 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35020/47780 [01:56<00:45, 279.28 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34836/47780 [01:56<00:45, 286.96 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33117/47780 [01:56<00:49, 298.06 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35037/47780 [01:56<00:45, 277.04 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25695/47780 [01:56<01:11, 308.61 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35952/47780 [01:56<00:36, 322.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34926/47780 [01:56<00:47, 272.54 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35008/47780 [01:56<00:40, 311.76 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34867/47780 [01:56<00:44, 287.05 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35049/47780 [01:56<00:47, 267.64 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35065/47780 [01:56<00:47, 268.54 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33147/47780 [01:56<00:51, 282.34 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25727/47780 [01:56<01:14, 295.93 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34957/47780 [01:56<00:45, 279.94 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35986/47780 [01:56<00:37, 310.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35041/47780 [01:56<00:40, 313.42 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34896/47780 [01:56<00:45, 283.42 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35078/47780 [01:56<00:47, 268.65 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35101/47780 [01:56<00:43, 291.04 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33176/47780 [01:56<00:53, 275.49 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25758/47780 [01:56<01:15, 293.21 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34989/47780 [01:56<00:45, 281.61 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36022/47780 [01:57<00:37, 310.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35079/47780 [01:56<00:38, 328.56 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34925/47780 [01:57<00:46, 277.24 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35108/47780 [01:57<00:45, 276.67 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35133/47780 [01:57<00:43, 292.46 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33204/47780 [01:57<00:56, 259.49 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35021/47780 [01:57<00:44, 286.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36054/47780 [01:57<00:37, 309.62 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35115/47780 [01:57<00:38, 329.85 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25788/47780 [01:57<01:22, 265.98 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35138/47780 [01:57<00:45, 280.16 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34953/47780 [01:57<00:49, 257.71 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33231/47780 [01:57<00:56, 259.49 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35056/47780 [01:57<00:41, 303.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35163/47780 [01:57<00:47, 266.66 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25818/47780 [01:57<01:21, 269.45 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36086/47780 [01:57<00:39, 292.90 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35149/47780 [01:57<00:40, 311.91 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35167/47780 [01:57<00:47, 267.58 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34987/47780 [01:57<00:45, 279.31 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35090/47780 [01:57<00:40, 313.95 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35199/47780 [01:57<00:43, 290.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33264/47780 [01:57<00:52, 276.04 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25853/47780 [01:57<01:15, 290.97 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35182/47780 [01:57<00:39, 316.54 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36116/47780 [01:57<00:41, 280.04 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35211/47780 [01:57<00:39, 315.47 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35016/47780 [01:57<00:47, 267.47 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35123/47780 [01:57<00:40, 315.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33296/47780 [01:57<00:51, 282.13 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25895/47780 [01:57<01:07, 326.45 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35229/47780 [01:57<00:46, 270.77 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35214/47780 [01:57<00:40, 313.91 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36145/47780 [01:57<00:43, 267.46 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35048/47780 [01:57<00:46, 273.39 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35244/47780 [01:57<00:43, 289.53 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35161/47780 [01:57<00:37, 333.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33328/47780 [01:57<00:49, 292.73 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35265/47780 [01:57<00:43, 288.87 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25929/47780 [01:57<01:09, 316.15 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35246/47780 [01:57<00:40, 308.79 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36172/47780 [01:57<00:44, 260.17 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35078/47780 [01:57<00:45, 280.68 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35274/47780 [01:57<00:44, 282.35 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33358/47780 [01:57<00:49, 291.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35195/47780 [01:57<00:39, 317.24 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25962/47780 [01:57<01:09, 313.98 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35286/47780 [01:57<00:37, 334.63 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35295/47780 [01:57<00:44, 282.74 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35107/47780 [01:57<00:46, 271.08 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35304/47780 [01:57<00:45, 276.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33388/47780 [01:57<00:50, 283.91 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36199/47780 [01:57<00:51, 224.08 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35227/47780 [01:57<00:41, 300.71 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35329/47780 [01:57<00:41, 298.28 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25994/47780 [01:57<01:10, 311.16 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35322/47780 [01:57<00:36, 338.06 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35135/47780 [01:57<00:47, 266.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35332/47780 [01:57<00:45, 274.20 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33417/47780 [01:57<00:51, 278.01 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36229/47780 [01:57<00:48, 238.28 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35258/47780 [01:57<00:42, 296.89 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26026/47780 [01:57<01:12, 300.46 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35363/47780 [01:57<00:42, 292.98 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35162/47780 [01:57<00:47, 265.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35356/47780 [01:57<00:37, 330.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33445/47780 [01:57<00:52, 273.84 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35361/47780 [01:57<00:48, 253.58 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35288/47780 [01:57<00:43, 288.14 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26060/47780 [01:57<01:09, 311.18 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36254/47780 [01:58<00:51, 224.99 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35393/47780 [01:57<00:42, 292.28 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35390/47780 [01:57<00:41, 299.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35190/47780 [01:58<00:46, 269.59 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33490/47780 [01:58<00:44, 320.35 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35319/47780 [01:58<00:43, 287.79 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26092/47780 [01:58<01:11, 303.33 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35387/47780 [01:58<00:51, 242.54 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36278/47780 [01:58<00:51, 221.90 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35423/47780 [01:58<00:45, 272.43 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35421/47780 [01:58<00:42, 292.22 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35218/47780 [01:58<00:47, 263.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33530/47780 [01:58<00:41, 342.93 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35348/47780 [01:58<00:44, 279.12 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26123/47780 [01:58<01:13, 295.08 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35421/47780 [01:58<00:47, 259.91 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36306/47780 [01:58<00:49, 230.10 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35464/47780 [01:58<00:40, 300.46 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35249/47780 [01:58<00:45, 276.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35451/47780 [01:58<00:44, 274.20 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33565/47780 [01:58<00:42, 333.52 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35376/47780 [01:58<00:44, 279.09 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26155/47780 [01:58<01:12, 298.91 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35451/47780 [01:58<00:46, 267.86 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36335/47780 [01:58<00:46, 245.98 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35495/47780 [01:58<00:40, 302.59 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35281/47780 [01:58<00:44, 282.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35487/47780 [01:58<00:41, 292.98 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33600/47780 [01:58<00:45, 310.06 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35411/47780 [01:58<00:41, 296.10 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26192/47780 [01:58<01:07, 318.99 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36366/47780 [01:58<00:43, 262.32 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35481/47780 [01:58<00:45, 272.54 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35526/47780 [01:58<00:40, 301.84 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35311/47780 [01:58<00:44, 281.46 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35517/47780 [01:58<00:44, 274.50 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33632/47780 [01:58<00:45, 308.92 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26225/47780 [01:58<01:07, 318.29 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36395/47780 [01:58<00:42, 265.43 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35441/47780 [01:58<00:44, 278.06 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35561/47780 [01:58<00:39, 311.93 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35509/47780 [01:58<00:47, 258.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35340/47780 [01:58<00:45, 271.42 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35547/47780 [01:58<00:43, 281.23 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26259/47780 [01:58<01:07, 321.10 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35536/47780 [01:58<00:46, 261.28 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35593/47780 [01:58<00:39, 312.22 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36422/47780 [01:58<00:44, 252.55 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35470/47780 [01:58<00:45, 268.78 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33664/47780 [01:58<00:49, 283.75 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35374/47780 [01:58<00:44, 281.19 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35582/47780 [01:58<00:42, 287.16 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26292/47780 [01:58<01:10, 306.01 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36448/47780 [01:58<00:44, 254.46 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35625/47780 [01:58<00:39, 309.22 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35563/47780 [01:58<00:47, 258.04 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35498/47780 [01:58<00:48, 255.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33693/47780 [01:58<00:52, 268.53 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35407/47780 [01:58<00:42, 294.05 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35617/47780 [01:58<00:40, 302.55 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26326/47780 [01:58<01:08, 315.49 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36476/47780 [01:58<00:43, 258.81 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35591/47780 [01:58<00:47, 258.75 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35656/47780 [01:58<00:41, 289.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33721/47780 [01:58<00:53, 263.21 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35524/47780 [01:58<00:50, 240.77 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35653/47780 [01:58<00:38, 317.38 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35437/47780 [01:58<00:43, 280.60 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26358/47780 [01:58<01:10, 302.51 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36503/47780 [01:58<00:45, 250.08 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35617/47780 [01:58<00:48, 250.51 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35694/47780 [01:58<00:40, 301.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33750/47780 [01:58<00:52, 267.48 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35550/47780 [01:58<00:50, 241.02 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35469/47780 [01:59<00:42, 291.48 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35686/47780 [01:58<00:40, 300.87 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36531/47780 [01:59<00:43, 255.98 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35647/47780 [01:59<00:46, 261.45 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26389/47780 [01:59<01:14, 287.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33779/47780 [01:59<00:51, 270.73 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35725/47780 [01:59<00:41, 290.93 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35582/47780 [01:59<00:48, 253.82 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35500/47780 [01:59<00:42, 290.23 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35717/47780 [01:59<00:39, 302.93 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35679/47780 [01:59<00:44, 274.95 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26420/47780 [01:59<01:15, 282.40 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33808/47780 [01:59<00:51, 270.06 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35764/47780 [01:59<00:37, 317.90 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36557/47780 [01:59<00:48, 230.97 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35612/47780 [01:59<00:46, 264.27 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35530/47780 [01:59<00:42, 286.49 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35751/47780 [01:59<00:38, 313.09 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35708/47780 [01:59<00:43, 275.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26449/47780 [01:59<01:15, 281.16 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35803/47780 [01:59<00:35, 334.57 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33836/47780 [01:59<00:52, 266.72 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36582/47780 [01:59<00:47, 233.54 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35641/47780 [01:59<00:45, 264.51 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35785/47780 [01:59<00:37, 320.79 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35560/47780 [01:59<00:43, 280.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35739/47780 [01:59<00:42, 282.67 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33864/47780 [01:59<00:51, 267.62 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35837/47780 [01:59<00:35, 332.04 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36610/47780 [01:59<00:45, 245.76 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26478/47780 [01:59<01:20, 266.07 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35678/47780 [01:59<00:41, 288.60 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35818/47780 [01:59<00:39, 302.61 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35589/47780 [01:59<00:45, 268.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35776/47780 [01:59<00:39, 307.26 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35872/47780 [01:59<00:35, 333.69 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33893/47780 [01:59<00:51, 269.15 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36635/47780 [01:59<00:46, 240.34 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35711/47780 [01:59<00:40, 300.21 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26505/47780 [01:59<01:23, 256.00 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35849/47780 [01:59<00:39, 302.57 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35617/47780 [01:59<00:44, 271.46 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35807/47780 [01:59<00:40, 294.74 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35907/47780 [01:59<00:35, 336.84 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33930/47780 [01:59<00:46, 296.91 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36663/47780 [01:59<00:44, 250.37 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35745/47780 [01:59<00:38, 311.31 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26536/47780 [01:59<01:20, 264.89 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35887/47780 [01:59<00:36, 323.30 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35645/47780 [01:59<00:45, 267.32 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35837/47780 [01:59<00:42, 283.51 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35943/47780 [01:59<00:34, 341.28 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33965/47780 [01:59<00:44, 308.25 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35777/47780 [01:59<00:38, 310.21 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35923/47780 [01:59<00:35, 330.03 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26563/47780 [01:59<01:30, 234.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35672/47780 [01:59<00:48, 250.41 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35866/47780 [01:59<00:42, 279.11 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34004/47780 [01:59<00:42, 326.50 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35816/47780 [01:59<00:36, 326.25 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35978/47780 [01:59<00:37, 317.78 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36689/47780 [01:59<00:59, 185.44 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35957/47780 [01:59<00:36, 325.10 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35700/47780 [01:59<00:47, 254.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26588/47780 [01:59<01:32, 229.59 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35895/47780 [01:59<00:44, 264.33 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34037/47780 [01:59<00:44, 310.59 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35852/47780 [01:59<00:36, 328.36 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36742/47780 [01:59<00:42, 262.32 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36011/47780 [01:59<00:37, 314.08 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35990/47780 [01:59<00:36, 324.75 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35729/47780 [02:00<00:46, 258.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26613/47780 [01:59<01:31, 230.22 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35888/47780 [02:00<00:36, 329.88 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36773/47780 [02:00<00:40, 269.49 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34069/47780 [02:00<00:45, 300.20 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36043/47780 [02:00<00:37, 308.95 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35922/47780 [02:00<00:47, 249.28 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35755/47780 [02:00<00:46, 258.31 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36023/47780 [02:00<00:40, 293.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26637/47780 [02:00<01:31, 230.15 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34100/47780 [02:00<00:45, 299.62 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35922/47780 [02:00<00:36, 321.75 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35951/47780 [02:00<00:45, 257.70 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36075/47780 [02:00<00:40, 286.29 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36803/47780 [02:00<00:43, 250.93 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35781/47780 [02:00<00:47, 252.95 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36054/47780 [02:00<00:39, 295.23 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26662/47780 [02:00<01:32, 228.29 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34132/47780 [02:00<00:44, 305.24 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35978/47780 [02:00<00:46, 256.51 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35955/47780 [02:00<00:39, 302.81 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36105/47780 [02:00<00:42, 275.03 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36831/47780 [02:00<00:44, 248.18 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35810/47780 [02:00<00:46, 257.95 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36084/47780 [02:00<00:41, 284.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26690/47780 [02:00<01:27, 239.82 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34163/47780 [02:00<00:45, 299.41 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36006/47780 [02:00<00:44, 262.02 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36143/47780 [02:00<00:38, 300.06 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35987/47780 [02:00<00:40, 289.05 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36858/47780 [02:00<00:43, 250.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35836/47780 [02:00<00:47, 250.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26717/47780 [02:00<01:25, 245.55 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36115/47780 [02:00<00:40, 284.81 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34196/47780 [02:00<00:45, 301.68 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36033/47780 [02:00<00:45, 258.26 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36176/47780 [02:00<00:37, 308.26 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36017/47780 [02:00<00:40, 291.86 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36886/47780 [02:00<00:42, 256.22 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35864/47780 [02:00<00:46, 258.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36151/47780 [02:00<00:38, 302.48 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26742/47780 [02:00<01:29, 236.11 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34227/47780 [02:00<00:45, 297.08 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36065/47780 [02:00<00:42, 275.39 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36224/47780 [02:00<00:32, 356.59 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36047/47780 [02:00<00:41, 281.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35890/47780 [02:00<00:46, 253.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36913/47780 [02:00<00:44, 244.01 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26767/47780 [02:00<01:27, 239.97 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36182/47780 [02:00<00:41, 278.25 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34260/47780 [02:00<00:45, 296.62 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36094/47780 [02:00<00:43, 265.74 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36076/47780 [02:00<00:41, 282.60 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35921/47780 [02:00<00:44, 269.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36261/47780 [02:00<00:34, 336.95 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26792/47780 [02:00<01:27, 240.15 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36940/47780 [02:00<00:45, 240.67 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36211/47780 [02:00<00:41, 276.48 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34291/47780 [02:00<00:45, 296.71 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36121/47780 [02:00<00:47, 246.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36297/47780 [02:00<00:34, 336.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35949/47780 [02:00<00:44, 263.24 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26818/47780 [02:00<01:25, 245.62 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36105/47780 [02:00<00:45, 254.46 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36242/47780 [02:00<00:40, 285.42 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36966/47780 [02:00<00:48, 221.84 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34321/47780 [02:00<00:46, 291.28 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36155/47780 [02:00<00:42, 271.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36332/47780 [02:00<00:33, 337.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35984/47780 [02:00<00:41, 284.81 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26843/47780 [02:00<01:29, 233.36 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36135/47780 [02:00<00:43, 265.51 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36273/47780 [02:00<00:39, 288.78 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36992/47780 [02:01<00:47, 229.51 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34357/47780 [02:00<00:43, 307.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36183/47780 [02:01<00:43, 265.22 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36013/47780 [02:01<00:41, 282.79 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26869/47780 [02:01<01:26, 240.49 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36169/47780 [02:01<00:40, 283.94 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36367/47780 [02:01<00:39, 290.57 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37016/47780 [02:01<00:48, 220.60 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34389/47780 [02:01<00:44, 300.62 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36303/47780 [02:01<00:45, 254.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36214/47780 [02:01<00:42, 271.64 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36199/47780 [02:01<00:40, 285.35 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36042/47780 [02:01<00:44, 266.76 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26899/47780 [02:01<01:23, 249.50 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36398/47780 [02:01<00:40, 283.89 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37044/47780 [02:01<00:45, 236.34 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34431/47780 [02:01<00:39, 334.21 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36330/47780 [02:01<00:44, 258.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36244/47780 [02:01<00:41, 276.42 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36241/47780 [02:01<00:36, 319.69 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36076/47780 [02:01<00:42, 277.85 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26925/47780 [02:01<01:24, 246.93 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37069/47780 [02:01<00:45, 237.44 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36428/47780 [02:01<00:40, 282.14 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34465/47780 [02:01<00:41, 321.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36272/47780 [02:01<00:41, 276.38 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36357/47780 [02:01<00:47, 240.93 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36274/47780 [02:01<00:35, 321.29 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26955/47780 [02:01<01:19, 261.97 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36104/47780 [02:01<00:42, 275.28 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37094/47780 [02:01<00:44, 238.26 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36466/47780 [02:01<00:37, 305.10 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34498/47780 [02:01<00:42, 309.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36382/47780 [02:01<00:47, 240.78 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36306/47780 [02:01<00:40, 282.76 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26986/47780 [02:01<01:15, 274.79 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36319/47780 [02:01<00:34, 332.90 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36132/47780 [02:01<00:45, 256.17 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37120/47780 [02:01<00:46, 228.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36498/47780 [02:01<00:38, 292.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36335/47780 [02:01<00:40, 282.21 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36414/47780 [02:01<00:44, 254.06 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34531/47780 [02:01<00:45, 292.29 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27015/47780 [02:01<01:18, 264.56 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36359/47780 [02:01<00:33, 340.20 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36158/47780 [02:01<00:48, 241.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37144/47780 [02:01<00:48, 219.87 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36442/47780 [02:01<00:43, 261.10 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36366/47780 [02:01<00:40, 283.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36528/47780 [02:01<00:41, 274.01 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34561/47780 [02:01<00:48, 273.73 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27045/47780 [02:01<01:16, 271.81 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36394/47780 [02:01<00:35, 318.45 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36183/47780 [02:01<00:50, 229.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36473/47780 [02:01<00:41, 274.69 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37170/47780 [02:01<00:47, 223.55 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36556/47780 [02:01<00:41, 267.34 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36396/47780 [02:01<00:42, 266.73 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27082/47780 [02:01<01:09, 299.67 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34590/47780 [02:01<00:48, 272.22 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36427/47780 [02:01<00:36, 312.65 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36208/47780 [02:01<00:49, 232.36 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36502/47780 [02:01<00:40, 276.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37193/47780 [02:01<00:47, 225.25 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36589/47780 [02:01<00:40, 278.19 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36427/47780 [02:01<00:40, 278.55 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34618/47780 [02:01<00:49, 266.07 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27113/47780 [02:01<01:11, 289.14 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36461/47780 [02:01<00:35, 315.35 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36232/47780 [02:02<00:50, 229.53 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37218/47780 [02:02<00:45, 229.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36533/47780 [02:01<00:40, 279.32 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36618/47780 [02:01<00:42, 264.18 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27143/47780 [02:01<01:10, 291.82 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34647/47780 [02:02<00:49, 266.70 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36456/47780 [02:02<00:43, 261.19 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36497/47780 [02:02<00:35, 320.69 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36260/47780 [02:02<00:47, 242.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37244/47780 [02:02<00:44, 238.06 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36562/47780 [02:02<00:41, 270.07 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36650/47780 [02:02<00:39, 278.72 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34678/47780 [02:02<00:47, 273.57 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27173/47780 [02:02<01:17, 266.85 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36483/47780 [02:02<00:46, 242.62 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36530/47780 [02:02<00:34, 322.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37276/47780 [02:02<00:40, 261.58 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36285/47780 [02:02<00:50, 229.48 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36680/47780 [02:02<00:39, 281.89 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36591/47780 [02:02<00:47, 235.90 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34706/47780 [02:02<00:50, 259.82 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27205/47780 [02:02<01:13, 278.54 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36515/47780 [02:02<00:43, 260.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37305/47780 [02:02<00:39, 266.12 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36563/47780 [02:02<00:37, 301.21 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36310/47780 [02:02<00:50, 225.27 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36714/47780 [02:02<00:37, 294.79 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36616/47780 [02:02<00:47, 234.59 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27237/47780 [02:02<01:12, 283.82 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36542/47780 [02:02<00:44, 254.30 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37334/47780 [02:02<00:38, 270.85 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34733/47780 [02:02<00:54, 239.18 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36595/47780 [02:02<00:38, 293.46 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36751/47780 [02:02<00:35, 309.12 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36342/47780 [02:02<00:48, 235.77 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36642/47780 [02:02<00:46, 240.56 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27276/47780 [02:02<01:05, 312.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36575/47780 [02:02<00:41, 272.06 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37362/47780 [02:02<00:40, 258.34 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36630/47780 [02:02<00:36, 305.54 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34758/47780 [02:02<00:57, 227.74 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36784/47780 [02:02<00:35, 311.75 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36369/47780 [02:02<00:47, 242.68 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27308/47780 [02:02<01:05, 312.00 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36667/47780 [02:02<00:47, 236.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36608/47780 [02:02<00:40, 279.25 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36664/47780 [02:02<00:35, 311.53 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37389/47780 [02:02<00:41, 247.63 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34790/47780 [02:02<00:53, 241.69 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36816/47780 [02:02<00:35, 311.55 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36396/47780 [02:02<00:45, 250.11 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36698/47780 [02:02<00:43, 256.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36637/47780 [02:02<00:39, 281.89 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27340/47780 [02:02<01:12, 281.96 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36696/47780 [02:02<00:36, 300.15 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37415/47780 [02:02<00:42, 245.61 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34817/47780 [02:02<00:54, 236.71 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36422/47780 [02:02<00:46, 244.56 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36848/47780 [02:02<00:36, 299.14 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36725/47780 [02:02<00:43, 254.30 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36671/47780 [02:02<00:37, 298.13 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27375/47780 [02:02<01:08, 296.99 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36739/47780 [02:02<00:33, 332.95 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37441/47780 [02:02<00:42, 241.56 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34847/47780 [02:02<00:51, 253.19 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36449/47780 [02:02<00:46, 246.09 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36879/47780 [02:02<00:37, 289.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36751/47780 [02:02<00:45, 242.50 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36702/47780 [02:02<00:41, 267.90 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36775/47780 [02:02<00:32, 336.77 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27406/47780 [02:02<01:13, 279.01 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37473/47780 [02:02<00:39, 260.40 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36474/47780 [02:03<00:46, 244.51 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34873/47780 [02:02<00:53, 242.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36779/47780 [02:02<00:43, 252.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36909/47780 [02:02<00:41, 260.24 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36735/47780 [02:03<00:39, 278.45 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36809/47780 [02:03<00:32, 337.11 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37504/47780 [02:03<00:37, 271.35 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36515/47780 [02:03<00:39, 288.44 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34901/47780 [02:03<00:51, 249.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27435/47780 [02:03<01:18, 259.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36805/47780 [02:03<00:44, 243.96 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36942/47780 [02:03<00:40, 264.77 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36843/47780 [02:03<00:32, 337.09 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36766/47780 [02:03<00:39, 280.96 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37533/47780 [02:03<00:37, 270.33 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34927/47780 [02:03<00:51, 249.67 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36544/47780 [02:03<00:41, 273.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27464/47780 [02:03<01:18, 259.26 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36969/47780 [02:03<00:40, 266.04 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36830/47780 [02:03<00:47, 232.80 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36879/47780 [02:03<00:32, 337.52 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36799/47780 [02:03<00:37, 291.20 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37564/47780 [02:03<00:36, 278.69 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34953/47780 [02:03<00:51, 247.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36574/47780 [02:03<00:40, 277.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27491/47780 [02:03<01:25, 237.22 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36996/47780 [02:03<00:41, 261.41 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36915/47780 [02:03<00:31, 343.86 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36830/47780 [02:03<00:37, 290.03 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37595/47780 [02:03<00:35, 284.35 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36854/47780 [02:03<00:52, 209.05 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34978/47780 [02:03<00:54, 234.68 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36602/47780 [02:03<00:44, 252.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27516/47780 [02:03<01:24, 239.20 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37023/47780 [02:03<00:41, 260.93 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36950/47780 [02:03<00:31, 341.34 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37632/47780 [02:03<00:33, 305.62 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36864/47780 [02:03<00:37, 290.98 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36876/47780 [02:03<00:53, 203.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35002/47780 [02:03<00:54, 233.60 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37054/47780 [02:03<00:39, 273.89 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36628/47780 [02:03<00:46, 239.14 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27543/47780 [02:03<01:30, 224.42 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37666/47780 [02:03<00:32, 315.55 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36985/47780 [02:03<00:33, 317.52 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36900/47780 [02:03<00:35, 303.44 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35026/47780 [02:03<00:54, 231.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36897/47780 [02:03<00:56, 193.34 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36657/47780 [02:03<00:45, 244.88 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37085/47780 [02:03<00:39, 269.57 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27573/47780 [02:03<01:24, 239.26 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37698/47780 [02:03<00:32, 305.88 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36932/47780 [02:03<00:35, 304.64 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37018/47780 [02:03<00:35, 301.48 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35051/47780 [02:03<00:54, 235.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36923/47780 [02:03<00:52, 208.43 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36684/47780 [02:03<00:44, 251.62 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37119/47780 [02:03<00:36, 289.18 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27602/47780 [02:03<01:19, 252.58 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36967/47780 [02:03<00:34, 314.10 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37729/47780 [02:03<00:33, 300.33 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35077/47780 [02:03<00:52, 242.32 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37049/47780 [02:03<00:37, 287.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36950/47780 [02:03<00:49, 220.30 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36713/47780 [02:03<00:42, 262.23 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27630/47780 [02:03<01:17, 259.77 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36999/47780 [02:03<00:35, 305.11 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37149/47780 [02:03<00:40, 262.09 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37760/47780 [02:03<00:35, 283.10 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37080/47780 [02:03<00:37, 285.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35104/47780 [02:03<00:54, 233.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36973/47780 [02:03<00:49, 216.75 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36740/47780 [02:04<00:42, 258.35 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27657/47780 [02:03<01:19, 254.49 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37032/47780 [02:03<00:34, 311.83 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37789/47780 [02:04<00:35, 283.33 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36996/47780 [02:04<00:49, 219.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37176/47780 [02:04<00:44, 237.72 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37109/47780 [02:04<00:39, 270.84 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35128/47780 [02:04<00:56, 225.79 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36780/47780 [02:04<00:37, 296.51 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27699/47780 [02:04<01:08, 294.26 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37066/47780 [02:04<00:33, 319.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37818/47780 [02:04<00:36, 274.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37201/47780 [02:04<00:45, 234.94 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35164/47780 [02:04<00:48, 259.93 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37139/47780 [02:04<00:38, 273.52 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36810/47780 [02:04<00:37, 293.72 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27731/47780 [02:04<01:06, 301.49 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37021/47780 [02:04<00:53, 200.73 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37106/47780 [02:04<00:31, 339.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37848/47780 [02:04<00:35, 278.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37174/47780 [02:04<00:36, 294.29 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37229/47780 [02:04<00:43, 241.16 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35196/47780 [02:04<00:47, 267.74 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36846/47780 [02:04<00:35, 305.20 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37065/47780 [02:04<00:41, 260.71 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27762/47780 [02:04<01:10, 284.43 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37141/47780 [02:04<00:33, 320.28 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37877/47780 [02:04<00:35, 281.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37204/47780 [02:04<00:35, 295.72 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37254/47780 [02:04<00:44, 236.51 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35233/47780 [02:04<00:43, 289.87 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36877/47780 [02:04<00:35, 306.21 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37093/47780 [02:04<00:43, 247.32 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27791/47780 [02:04<01:11, 278.91 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37180/47780 [02:04<00:31, 332.58 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37907/47780 [02:04<00:35, 277.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37237/47780 [02:04<00:34, 302.47 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37284/47780 [02:04<00:41, 250.94 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35263/47780 [02:04<00:47, 265.83 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36908/47780 [02:04<00:38, 281.33 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27824/47780 [02:04<01:10, 284.44 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37219/47780 [02:04<00:30, 348.53 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37119/47780 [02:04<00:44, 240.45 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37942/47780 [02:04<00:33, 289.88 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37268/47780 [02:04<00:35, 297.81 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37312/47780 [02:04<00:40, 257.14 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36937/47780 [02:04<00:39, 271.68 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37267/47780 [02:04<00:27, 377.61 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27857/47780 [02:04<01:09, 287.44 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35292/47780 [02:04<00:50, 248.41 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37144/47780 [02:04<00:44, 237.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37972/47780 [02:04<00:34, 283.48 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37298/47780 [02:04<00:36, 288.13 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37341/47780 [02:04<00:39, 262.47 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36965/47780 [02:04<00:40, 265.15 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37170/47780 [02:04<00:43, 243.69 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35323/47780 [02:04<00:47, 261.60 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37305/47780 [02:04<00:29, 360.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38006/47780 [02:04<00:32, 297.48 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37368/47780 [02:04<00:39, 261.78 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37327/47780 [02:04<00:37, 276.21 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27886/47780 [02:04<01:22, 240.27 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35350/47780 [02:04<00:47, 263.68 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37195/47780 [02:04<00:44, 237.73 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36992/47780 [02:04<00:42, 252.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38044/47780 [02:04<00:30, 317.65 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37395/47780 [02:04<00:39, 263.89 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37343/47780 [02:04<00:31, 334.54 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37361/47780 [02:04<00:36, 287.78 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27931/47780 [02:04<01:08, 289.41 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37225/47780 [02:04<00:41, 253.49 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35377/47780 [02:04<00:48, 257.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37025/47780 [02:05<00:39, 270.76 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38076/47780 [02:05<00:31, 303.85 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37377/47780 [02:04<00:31, 334.61 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37422/47780 [02:04<00:40, 256.56 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37390/47780 [02:05<00:37, 276.03 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27962/47780 [02:04<01:10, 280.26 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37256/47780 [02:05<00:39, 265.21 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37058/47780 [02:05<00:37, 285.85 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35405/47780 [02:05<00:48, 254.74 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38107/47780 [02:05<00:31, 302.30 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37419/47780 [02:05<00:28, 358.17 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37448/47780 [02:05<00:42, 243.86 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37419/47780 [02:05<00:37, 279.63 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27992/47780 [02:05<01:10, 279.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37087/47780 [02:05<00:37, 284.61 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37283/47780 [02:05<00:42, 246.85 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37456/47780 [02:05<00:29, 353.69 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38138/47780 [02:05<00:33, 291.36 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37473/47780 [02:05<00:42, 240.18 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35431/47780 [02:05<00:55, 223.79 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28021/47780 [02:05<01:11, 276.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37448/47780 [02:05<00:40, 256.41 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37116/47780 [02:05<00:40, 265.57 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37310/47780 [02:05<00:42, 247.78 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37510/47780 [02:05<00:25, 397.49 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38169/47780 [02:05<00:33, 283.91 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37503/47780 [02:05<00:40, 256.84 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35459/47780 [02:05<00:53, 231.24 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37486/47780 [02:05<00:35, 289.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28050/47780 [02:05<01:12, 271.30 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37336/47780 [02:05<00:41, 250.92 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37149/47780 [02:05<00:38, 274.09 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37535/47780 [02:05<00:38, 265.89 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35486/47780 [02:05<00:53, 229.42 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37520/47780 [02:05<00:34, 297.35 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38200/47780 [02:05<00:37, 256.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28080/47780 [02:05<01:11, 276.14 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37550/47780 [02:05<00:31, 321.23 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37362/47780 [02:05<00:42, 242.82 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37177/47780 [02:05<00:39, 265.68 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37561/47780 [02:05<00:31, 328.48 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37562/47780 [02:05<00:41, 244.90 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28111/47780 [02:05<01:08, 285.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38235/47780 [02:05<00:35, 272.23 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37595/47780 [02:05<00:29, 350.00 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35510/47780 [02:05<00:58, 208.22 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37392/47780 [02:05<00:40, 255.85 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37204/47780 [02:05<00:42, 248.92 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37595/47780 [02:05<00:31, 328.30 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37591/47780 [02:05<00:39, 256.85 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28140/47780 [02:05<01:11, 276.38 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38264/47780 [02:05<00:35, 266.10 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37634/47780 [02:05<00:28, 360.30 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35547/47780 [02:05<00:49, 246.40 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37419/47780 [02:05<00:39, 259.80 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37232/47780 [02:05<00:41, 257.07 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37623/47780 [02:05<00:37, 271.63 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37629/47780 [02:05<00:32, 316.80 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28168/47780 [02:05<01:12, 269.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38293/47780 [02:05<00:34, 272.22 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35573/47780 [02:05<00:49, 247.18 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37672/47780 [02:05<00:29, 343.16 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37450/47780 [02:05<00:38, 268.11 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37258/47780 [02:05<00:42, 249.84 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37652/47780 [02:05<00:36, 273.77 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37662/47780 [02:05<00:31, 317.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28202/47780 [02:05<01:08, 285.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38322/47780 [02:05<00:34, 275.30 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35606/47780 [02:05<00:45, 266.92 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37480/47780 [02:05<00:37, 277.19 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37708/47780 [02:05<00:30, 333.40 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37284/47780 [02:06<00:41, 252.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37689/47780 [02:05<00:33, 297.94 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35638/47780 [02:06<00:43, 278.54 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28231/47780 [02:05<01:11, 271.65 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38350/47780 [02:06<00:35, 263.24 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37694/47780 [02:06<00:35, 285.59 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37743/47780 [02:06<00:29, 334.59 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37508/47780 [02:06<00:39, 259.69 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37310/47780 [02:06<00:41, 251.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37720/47780 [02:06<00:33, 300.74 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28260/47780 [02:06<01:11, 273.77 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38377/47780 [02:06<00:36, 260.00 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37732/47780 [02:06<00:33, 301.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35667/47780 [02:06<00:46, 261.00 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37779/47780 [02:06<00:29, 334.26 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37535/47780 [02:06<00:40, 254.26 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37341/47780 [02:06<00:39, 264.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37751/47780 [02:06<00:35, 284.12 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38406/47780 [02:06<00:34, 268.35 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28288/47780 [02:06<01:11, 272.37 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37763/47780 [02:06<00:33, 296.05 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37814/47780 [02:06<00:30, 327.65 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37561/47780 [02:06<00:40, 250.26 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37368/47780 [02:06<00:41, 249.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35694/47780 [02:06<00:52, 231.10 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37780/47780 [02:06<00:36, 276.31 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38435/47780 [02:06<00:35, 259.72 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28317/47780 [02:06<01:14, 259.56 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37796/47780 [02:06<00:33, 299.63 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37848/47780 [02:06<00:30, 327.05 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37587/47780 [02:06<00:40, 250.10 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37394/47780 [02:06<00:41, 247.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35730/47780 [02:06<00:45, 263.62 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37808/47780 [02:06<00:36, 272.03 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28348/47780 [02:06<01:11, 270.57 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38462/47780 [02:06<00:37, 248.46 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37828/47780 [02:06<00:35, 283.36 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37619/47780 [02:06<00:38, 264.12 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37881/47780 [02:06<00:32, 307.86 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37423/47780 [02:06<00:40, 256.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35759/47780 [02:06<00:45, 262.30 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37841/47780 [02:06<00:35, 278.41 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28381/47780 [02:06<01:07, 286.99 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38488/47780 [02:06<00:38, 243.90 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37647/47780 [02:06<00:37, 268.62 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37857/47780 [02:06<00:34, 285.09 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37921/47780 [02:06<00:29, 329.02 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35787/47780 [02:06<00:44, 266.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37450/47780 [02:06<00:41, 246.10 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37872/47780 [02:06<00:34, 284.03 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28412/47780 [02:06<01:06, 290.49 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37678/47780 [02:06<00:36, 280.45 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37888/47780 [02:06<00:33, 291.95 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35819/47780 [02:06<00:42, 278.78 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37481/47780 [02:06<00:39, 260.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37955/47780 [02:06<00:32, 301.91 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38513/47780 [02:06<00:43, 212.77 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37901/47780 [02:06<00:35, 279.21 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28446/47780 [02:06<01:04, 301.35 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37707/47780 [02:06<00:35, 283.10 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37920/47780 [02:06<00:33, 296.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37514/47780 [02:06<00:37, 277.28 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35848/47780 [02:06<00:44, 266.65 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38535/47780 [02:06<00:45, 203.94 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37986/47780 [02:06<00:34, 285.25 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37929/47780 [02:06<00:36, 273.23 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28485/47780 [02:06<01:00, 319.55 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37736/47780 [02:06<00:36, 276.92 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37953/47780 [02:06<00:32, 299.43 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37543/47780 [02:06<00:36, 277.66 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35880/47780 [02:06<00:43, 272.70 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37958/47780 [02:06<00:35, 275.08 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38020/47780 [02:06<00:33, 293.91 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38556/47780 [02:07<00:46, 199.60 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37990/47780 [02:06<00:30, 319.47 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37764/47780 [02:06<00:38, 261.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37572/47780 [02:07<00:36, 280.97 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35916/47780 [02:07<00:39, 296.75 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37992/47780 [02:07<00:33, 293.27 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28518/47780 [02:07<01:16, 252.86 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38050/47780 [02:07<00:35, 277.46 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38024/47780 [02:07<00:30, 321.16 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38577/47780 [02:07<00:50, 183.22 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37797/47780 [02:07<00:36, 274.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37604/47780 [02:07<00:35, 289.22 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35953/47780 [02:07<00:37, 317.28 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28572/47780 [02:07<01:00, 319.61 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38022/47780 [02:07<00:35, 276.44 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38080/47780 [02:07<00:34, 280.76 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38057/47780 [02:07<00:30, 316.92 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38596/47780 [02:07<00:50, 183.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37825/47780 [02:07<00:37, 262.23 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35986/47780 [02:07<00:38, 308.30 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37635/47780 [02:07<00:37, 274.15 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38057/47780 [02:07<00:33, 293.10 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28607/47780 [02:07<01:02, 305.38 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38109/47780 [02:07<00:34, 277.09 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38615/47780 [02:07<00:49, 184.78 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38089/47780 [02:07<00:30, 313.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37857/47780 [02:07<00:35, 277.25 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37663/47780 [02:07<00:38, 265.79 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38092/47780 [02:07<00:31, 305.49 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36018/47780 [02:07<00:42, 278.82 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28650/47780 [02:07<00:57, 333.81 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38137/47780 [02:07<00:36, 266.07 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38636/47780 [02:07<00:48, 187.56 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38121/47780 [02:07<00:31, 305.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37889/47780 [02:07<00:34, 286.14 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37690/47780 [02:07<00:38, 264.04 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38123/47780 [02:07<00:32, 300.79 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28689/47780 [02:07<00:54, 348.43 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36047/47780 [02:07<00:42, 278.85 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38659/47780 [02:07<00:46, 194.97 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38152/47780 [02:07<00:32, 296.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38165/47780 [02:07<00:37, 256.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37918/47780 [02:07<00:35, 280.82 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37717/47780 [02:07<00:40, 248.89 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38154/47780 [02:07<00:32, 292.94 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28726/47780 [02:07<00:56, 336.21 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38682/47780 [02:07<00:45, 198.92 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38197/47780 [02:07<00:35, 273.40 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38187/47780 [02:07<00:31, 307.87 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36077/47780 [02:07<00:45, 258.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37948/47780 [02:07<00:34, 286.28 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37743/47780 [02:07<00:40, 247.21 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28764/47780 [02:07<00:55, 342.41 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38232/47780 [02:07<00:32, 294.53 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36111/47780 [02:07<00:42, 277.51 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38184/47780 [02:07<00:35, 268.16 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38233/47780 [02:07<00:28, 337.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38703/47780 [02:07<00:47, 192.64 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37977/47780 [02:07<00:35, 274.61 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37773/47780 [02:07<00:38, 261.09 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28800/47780 [02:07<00:56, 337.80 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36140/47780 [02:07<00:42, 274.91 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38270/47780 [02:07<00:27, 345.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38262/47780 [02:07<00:34, 277.34 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38734/47780 [02:07<00:42, 214.82 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38212/47780 [02:07<00:39, 242.56 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38005/47780 [02:07<00:38, 255.87 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37801/47780 [02:07<00:37, 266.16 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28835/47780 [02:07<00:57, 330.39 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38305/47780 [02:07<00:27, 342.53 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36168/47780 [02:07<00:43, 270.04 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38761/47780 [02:08<00:39, 228.91 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38291/47780 [02:07<00:35, 266.13 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38031/47780 [02:07<00:39, 249.77 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37848/47780 [02:08<00:30, 321.56 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38237/47780 [02:08<00:42, 226.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28870/47780 [02:08<00:56, 335.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38794/47780 [02:08<00:35, 256.30 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36196/47780 [02:08<00:44, 263.00 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38324/47780 [02:08<00:33, 280.55 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38340/47780 [02:08<00:29, 318.98 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38067/47780 [02:08<00:35, 275.95 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37884/47780 [02:08<00:29, 332.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38262/47780 [02:08<00:41, 229.31 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38354/47780 [02:08<00:32, 285.91 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36223/47780 [02:08<00:44, 257.81 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38376/47780 [02:08<00:29, 323.46 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28904/47780 [02:08<01:03, 296.70 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38821/47780 [02:08<00:37, 238.45 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38103/47780 [02:08<00:32, 296.23 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37927/47780 [02:08<00:27, 357.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38293/47780 [02:08<00:38, 248.31 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38383/47780 [02:08<00:34, 274.57 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28935/47780 [02:08<01:02, 299.40 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38851/47780 [02:08<00:34, 255.13 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38409/47780 [02:08<00:30, 309.35 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38138/47780 [02:08<00:30, 311.27 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37964/47780 [02:08<00:27, 357.74 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36251/47780 [02:08<00:49, 233.02 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38326/47780 [02:08<00:34, 270.31 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38416/47780 [02:08<00:32, 284.44 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28966/47780 [02:08<01:03, 296.69 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38877/47780 [02:08<00:34, 256.19 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38187/47780 [02:08<00:26, 362.30 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36282/47780 [02:08<00:45, 250.22 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38355/47780 [02:08<00:34, 272.93 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38441/47780 [02:08<00:32, 288.84 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38000/47780 [02:08<00:30, 316.39 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38446/47780 [02:08<00:32, 288.04 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28998/47780 [02:08<01:03, 296.54 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38904/47780 [02:08<00:36, 246.38 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36311/47780 [02:08<00:43, 260.80 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38224/47780 [02:08<00:28, 340.31 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38471/47780 [02:08<00:32, 288.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38384/47780 [02:08<00:35, 268.38 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38476/47780 [02:08<00:33, 281.55 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38033/47780 [02:08<00:35, 278.16 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38929/47780 [02:08<00:35, 247.18 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29028/47780 [02:08<01:06, 283.64 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36339/47780 [02:08<00:43, 263.37 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38506/47780 [02:08<00:30, 302.21 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38412/47780 [02:08<00:34, 268.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38259/47780 [02:08<00:29, 318.90 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38955/47780 [02:08<00:36, 243.54 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38505/47780 [02:08<00:34, 268.91 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38063/47780 [02:08<00:36, 269.74 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38537/47780 [02:08<00:30, 303.92 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29057/47780 [02:08<01:09, 268.79 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36366/47780 [02:08<00:45, 250.84 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38440/47780 [02:08<00:36, 257.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38292/47780 [02:08<00:31, 305.02 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38536/47780 [02:08<00:33, 277.26 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29085/47780 [02:08<01:08, 271.67 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38091/47780 [02:08<00:36, 266.94 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36395/47780 [02:08<00:43, 259.03 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38571/47780 [02:08<00:30, 300.98 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38474/47780 [02:08<00:33, 277.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38325/47780 [02:08<00:30, 310.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38980/47780 [02:08<00:42, 209.18 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38121/47780 [02:09<00:35, 273.05 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38566/47780 [02:08<00:33, 271.27 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29113/47780 [02:08<01:11, 262.24 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38603/47780 [02:08<00:31, 293.34 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38357/47780 [02:08<00:30, 304.69 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38504/47780 [02:08<00:34, 265.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36422/47780 [02:08<00:47, 237.38 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39002/47780 [02:09<00:42, 205.65 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38154/47780 [02:09<00:33, 288.42 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38594/47780 [02:09<00:33, 273.56 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29140/47780 [02:09<01:11, 261.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38633/47780 [02:09<00:31, 288.63 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36448/47780 [02:09<00:47, 236.57 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39024/47780 [02:09<00:43, 200.91 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38531/47780 [02:09<00:36, 250.50 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38388/47780 [02:09<00:33, 280.94 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38190/47780 [02:09<00:31, 308.38 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38625/47780 [02:09<00:32, 281.16 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29171/47780 [02:09<01:09, 269.32 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38666/47780 [02:09<00:30, 300.05 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36474/47780 [02:09<00:47, 240.31 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38560/47780 [02:09<00:36, 255.61 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39047/47780 [02:09<00:42, 204.32 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38420/47780 [02:09<00:32, 288.55 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38222/47780 [02:09<00:31, 301.10 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38654/47780 [02:09<00:34, 268.19 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29199/47780 [02:09<01:08, 269.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38697/47780 [02:09<00:31, 289.59 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36499/47780 [02:09<00:47, 237.74 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38589/47780 [02:09<00:34, 264.95 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39068/47780 [02:09<00:42, 203.58 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38451/47780 [02:09<00:32, 288.12 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38254/47780 [02:09<00:31, 305.27 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38688/47780 [02:09<00:31, 285.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29227/47780 [02:09<01:13, 253.85 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38727/47780 [02:09<00:33, 271.48 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36526/47780 [02:09<00:46, 241.35 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38622/47780 [02:09<00:32, 280.13 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39090/47780 [02:09<00:42, 205.93 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38482/47780 [02:09<00:32, 281.78 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38286/47780 [02:09<00:31, 304.02 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38717/47780 [02:09<00:32, 276.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29255/47780 [02:09<01:11, 259.05 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38765/47780 [02:09<00:30, 298.76 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38656/47780 [02:09<00:30, 297.02 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39112/47780 [02:09<00:41, 207.54 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36551/47780 [02:09<00:48, 233.12 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38511/47780 [02:09<00:34, 272.06 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38317/47780 [02:09<00:32, 293.78 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38750/47780 [02:09<00:31, 287.28 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29282/47780 [02:09<01:12, 253.50 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38799/47780 [02:09<00:29, 302.36 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39137/47780 [02:09<00:39, 217.24 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36578/47780 [02:09<00:48, 233.29 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38686/47780 [02:09<00:32, 275.76 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38539/47780 [02:09<00:34, 271.41 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38348/47780 [02:09<00:32, 287.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38779/47780 [02:09<00:31, 283.33 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29315/47780 [02:09<01:07, 274.57 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38831/47780 [02:09<00:29, 305.71 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36608/47780 [02:09<00:44, 251.52 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39159/47780 [02:09<00:41, 206.11 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38715/47780 [02:09<00:33, 272.64 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38567/47780 [02:09<00:35, 256.07 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38808/47780 [02:09<00:31, 280.68 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29343/47780 [02:09<01:08, 270.03 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38378/47780 [02:09<00:37, 251.43 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38862/47780 [02:09<00:30, 294.24 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36634/47780 [02:09<00:44, 250.75 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38743/47780 [02:09<00:33, 272.36 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39189/47780 [02:09<00:38, 224.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38837/47780 [02:09<00:31, 281.42 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29374/47780 [02:09<01:06, 275.79 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38593/47780 [02:09<00:39, 232.28 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38894/47780 [02:09<00:29, 298.89 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36665/47780 [02:09<00:41, 265.01 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38404/47780 [02:10<00:38, 243.37 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38772/47780 [02:09<00:32, 274.63 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39219/47780 [02:10<00:35, 240.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38866/47780 [02:10<00:32, 277.43 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29406/47780 [02:10<01:05, 281.94 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38617/47780 [02:10<00:40, 224.75 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36696/47780 [02:10<00:39, 277.89 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38925/47780 [02:10<00:30, 288.60 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38429/47780 [02:10<00:38, 240.36 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38800/47780 [02:10<00:35, 255.62 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39244/47780 [02:10<00:39, 218.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38894/47780 [02:10<00:33, 269.09 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29435/47780 [02:10<01:04, 284.17 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38647/47780 [02:10<00:37, 244.37 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36736/47780 [02:10<00:36, 301.66 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38464/47780 [02:10<00:35, 264.08 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38955/47780 [02:10<00:32, 268.04 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39273/47780 [02:10<00:35, 237.11 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38826/47780 [02:10<00:38, 233.82 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29464/47780 [02:10<01:04, 285.84 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38921/47780 [02:10<00:34, 254.74 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36768/47780 [02:10<00:36, 304.63 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38672/47780 [02:10<00:40, 226.49 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38491/47780 [02:10<00:36, 257.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38983/47780 [02:10<00:32, 269.24 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29493/47780 [02:10<01:03, 286.60 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39299/47780 [02:10<00:37, 229.01 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38853/47780 [02:10<00:37, 238.39 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38962/47780 [02:10<00:29, 297.79 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38699/47780 [02:10<00:38, 236.70 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36799/47780 [02:10<00:37, 289.17 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38520/47780 [02:10<00:36, 255.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39015/47780 [02:10<00:31, 276.23 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29525/47780 [02:10<01:01, 296.10 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39325/47780 [02:10<00:36, 234.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38994/47780 [02:10<00:28, 303.85 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38884/47780 [02:10<00:35, 252.02 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38725/47780 [02:10<00:37, 242.90 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38556/47780 [02:10<00:32, 280.26 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36829/47780 [02:10<00:40, 271.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39044/47780 [02:10<00:32, 271.07 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39352/47780 [02:10<00:34, 241.79 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29555/47780 [02:10<01:06, 272.23 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38910/47780 [02:10<00:36, 241.05 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39025/47780 [02:10<00:30, 282.97 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38751/47780 [02:10<00:38, 235.25 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39073/47780 [02:10<00:32, 270.09 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38585/47780 [02:10<00:35, 260.00 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36857/47780 [02:10<00:42, 259.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39382/47780 [02:10<00:32, 258.00 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38943/47780 [02:10<00:34, 259.50 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39060/47780 [02:10<00:29, 298.23 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29583/47780 [02:10<01:10, 257.16 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38781/47780 [02:10<00:36, 248.43 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39101/47780 [02:10<00:32, 264.25 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39409/47780 [02:10<00:33, 252.75 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38615/47780 [02:10<00:36, 253.42 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36884/47780 [02:10<00:46, 234.58 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38970/47780 [02:10<00:34, 254.07 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29610/47780 [02:10<01:09, 260.26 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39091/47780 [02:10<00:30, 285.48 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38810/47780 [02:10<00:34, 259.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39128/47780 [02:10<00:32, 265.65 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38645/47780 [02:10<00:34, 263.79 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38996/47780 [02:10<00:34, 255.41 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36909/47780 [02:10<00:46, 236.12 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29642/47780 [02:10<01:05, 276.92 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39435/47780 [02:10<00:35, 233.41 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39124/47780 [02:10<00:29, 294.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38842/47780 [02:10<00:32, 276.79 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39155/47780 [02:10<00:34, 252.28 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36936/47780 [02:10<00:44, 242.55 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39462/47780 [02:11<00:34, 238.39 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29678/47780 [02:10<01:01, 294.32 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38672/47780 [02:11<00:37, 241.85 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38870/47780 [02:11<00:32, 274.91 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39023/47780 [02:11<00:35, 243.32 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39154/47780 [02:11<00:30, 280.32 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39184/47780 [02:11<00:33, 257.46 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36963/47780 [02:11<00:43, 247.42 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29711/47780 [02:11<01:02, 291.23 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38697/47780 [02:11<00:38, 238.90 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38902/47780 [02:11<00:31, 278.29 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39051/47780 [02:11<00:35, 242.65 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39487/47780 [02:11<00:36, 224.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39183/47780 [02:11<00:31, 274.09 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39210/47780 [02:11<00:33, 255.34 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36994/47780 [02:11<00:42, 253.44 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38728/47780 [02:11<00:35, 257.29 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29749/47780 [02:11<00:57, 312.71 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38937/47780 [02:11<00:29, 295.42 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39081/47780 [02:11<00:34, 255.58 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39510/47780 [02:11<00:37, 220.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39211/47780 [02:11<00:33, 255.99 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39236/47780 [02:11<00:34, 245.56 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37034/47780 [02:11<00:36, 293.59 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29785/47780 [02:11<00:56, 318.80 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39107/47780 [02:11<00:34, 253.96 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39539/47780 [02:11<00:34, 237.36 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38967/47780 [02:11<00:31, 282.96 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38755/47780 [02:11<00:37, 242.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39239/47780 [02:11<00:32, 259.49 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39261/47780 [02:11<00:36, 231.39 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37069/47780 [02:11<00:34, 309.46 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29820/47780 [02:11<00:55, 326.16 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39134/47780 [02:11<00:33, 255.60 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39574/47780 [02:11<00:30, 265.73 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38784/47780 [02:11<00:36, 247.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39266/47780 [02:11<00:32, 259.52 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38996/47780 [02:11<00:33, 259.44 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39285/47780 [02:11<00:36, 233.55 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29853/47780 [02:11<00:55, 323.90 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37101/47780 [02:11<00:36, 295.83 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39160/47780 [02:11<00:33, 253.95 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38810/47780 [02:11<00:37, 240.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39294/47780 [02:11<00:32, 259.67 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39029/47780 [02:11<00:31, 278.30 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39601/47780 [02:11<00:34, 234.19 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39309/47780 [02:11<00:36, 232.87 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37131/47780 [02:11<00:36, 290.29 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39196/47780 [02:11<00:30, 281.26 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29886/47780 [02:11<01:01, 292.99 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38847/47780 [02:11<00:32, 272.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39323/47780 [02:11<00:31, 267.98 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39644/47780 [02:11<00:28, 283.47 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39058/47780 [02:11<00:33, 263.92 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39334/47780 [02:11<00:35, 234.99 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39225/47780 [02:11<00:30, 283.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37161/47780 [02:11<00:38, 274.70 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29933/47780 [02:11<00:53, 333.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39356/47780 [02:11<00:29, 282.52 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38875/47780 [02:11<00:34, 261.34 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39675/47780 [02:11<00:28, 284.48 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39088/47780 [02:11<00:32, 270.75 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39361/47780 [02:11<00:35, 239.48 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39254/47780 [02:11<00:31, 270.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37191/47780 [02:11<00:38, 277.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39390/47780 [02:11<00:28, 295.72 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29967/47780 [02:11<00:55, 321.17 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38902/47780 [02:11<00:34, 253.99 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39121/47780 [02:11<00:31, 278.08 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39705/47780 [02:12<00:30, 265.49 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39393/47780 [02:11<00:32, 256.40 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39430/47780 [02:11<00:25, 325.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39282/47780 [02:11<00:32, 260.90 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37220/47780 [02:11<00:39, 266.75 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30000/47780 [02:11<00:56, 313.52 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38938/47780 [02:12<00:32, 274.17 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39735/47780 [02:12<00:29, 274.63 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39419/47780 [02:12<00:32, 254.33 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39150/47780 [02:12<00:33, 254.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39316/47780 [02:12<00:30, 279.97 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39463/47780 [02:12<00:26, 315.64 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37259/47780 [02:12<00:36, 291.23 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38971/47780 [02:12<00:30, 286.39 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30032/47780 [02:12<01:00, 295.50 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39764/47780 [02:12<00:30, 263.65 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39176/47780 [02:12<00:34, 249.30 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39445/47780 [02:12<00:37, 222.95 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39497/47780 [02:12<00:26, 317.90 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39345/47780 [02:12<00:31, 270.22 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37290/47780 [02:12<00:35, 293.32 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39007/47780 [02:12<00:28, 303.60 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30063/47780 [02:12<00:59, 296.45 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39793/47780 [02:12<00:29, 270.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39204/47780 [02:12<00:33, 254.86 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39471/47780 [02:12<00:36, 228.58 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39380/47780 [02:12<00:29, 289.46 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37320/47780 [02:12<00:37, 282.50 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39529/47780 [02:12<00:27, 298.87 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39041/47780 [02:12<00:28, 307.90 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30093/47780 [02:12<01:03, 278.99 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39824/47780 [02:12<00:28, 279.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39239/47780 [02:12<00:30, 278.12 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39495/47780 [02:12<00:36, 228.69 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37349/47780 [02:12<00:37, 278.41 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39410/47780 [02:12<00:30, 274.00 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39561/47780 [02:12<00:28, 291.64 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39072/47780 [02:12<00:30, 289.03 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30123/47780 [02:12<01:03, 278.60 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39856/47780 [02:12<00:28, 278.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39269/47780 [02:12<00:31, 269.14 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39519/47780 [02:12<00:37, 219.68 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37381/47780 [02:12<00:35, 289.77 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39438/47780 [02:12<00:30, 269.80 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39591/47780 [02:12<00:29, 281.45 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39106/47780 [02:12<00:29, 298.71 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39887/47780 [02:12<00:27, 284.01 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30152/47780 [02:12<01:05, 269.47 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39297/47780 [02:12<00:32, 263.01 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39543/47780 [02:12<00:38, 215.63 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37411/47780 [02:12<00:37, 280.14 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39627/47780 [02:12<00:27, 296.96 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39467/47780 [02:12<00:33, 250.22 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39137/47780 [02:12<00:30, 285.74 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39922/47780 [02:12<00:26, 295.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30180/47780 [02:12<01:07, 261.85 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39327/47780 [02:12<00:31, 270.63 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39566/47780 [02:12<00:38, 214.81 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37440/47780 [02:12<00:38, 270.78 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39657/47780 [02:12<00:27, 291.39 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39171/47780 [02:12<00:28, 297.45 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39956/47780 [02:12<00:25, 307.88 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30207/47780 [02:12<01:06, 263.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39493/47780 [02:12<00:35, 235.34 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39355/47780 [02:12<00:32, 258.78 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39596/47780 [02:12<00:35, 230.67 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37468/47780 [02:12<00:38, 267.40 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39698/47780 [02:12<00:24, 324.50 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39991/47780 [02:12<00:24, 317.04 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39201/47780 [02:12<00:29, 291.70 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30237/47780 [02:12<01:05, 267.78 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39517/47780 [02:12<00:35, 231.89 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39387/47780 [02:12<00:30, 272.54 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39627/47780 [02:12<00:32, 249.94 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37495/47780 [02:12<00:38, 267.95 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39739/47780 [02:12<00:23, 344.96 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39232/47780 [02:13<00:29, 289.95 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30270/47780 [02:12<01:01, 285.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40023/47780 [02:13<00:26, 296.18 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39546/47780 [02:13<00:34, 242.16 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39424/47780 [02:13<00:28, 296.58 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39660/47780 [02:13<00:29, 272.05 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39774/47780 [02:13<00:23, 338.69 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37522/47780 [02:13<00:40, 254.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30301/47780 [02:13<00:59, 292.05 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39572/47780 [02:13<00:33, 244.22 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39262/47780 [02:13<00:31, 273.61 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40053/47780 [02:13<00:27, 279.60 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39464/47780 [02:13<00:25, 322.03 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39688/47780 [02:13<00:30, 262.13 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37557/47780 [02:13<00:36, 277.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30344/47780 [02:13<00:54, 317.86 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39600/47780 [02:13<00:32, 254.11 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39809/47780 [02:13<00:26, 306.44 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39295/47780 [02:13<00:29, 286.89 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39497/47780 [02:13<00:26, 313.55 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40082/47780 [02:13<00:29, 262.41 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39718/47780 [02:13<00:30, 267.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37591/47780 [02:13<00:34, 292.09 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39841/47780 [02:13<00:25, 307.59 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30379/47780 [02:13<00:53, 323.25 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39627/47780 [02:13<00:32, 253.04 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39347/47780 [02:13<00:24, 340.54 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39529/47780 [02:13<00:27, 295.51 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39747/47780 [02:13<00:29, 273.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40109/47780 [02:13<00:31, 241.38 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37621/47780 [02:13<00:37, 272.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39880/47780 [02:13<00:23, 329.68 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30418/47780 [02:13<00:51, 338.41 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39663/47780 [02:13<00:29, 277.19 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39382/47780 [02:13<00:25, 335.68 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39781/47780 [02:13<00:27, 289.53 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39559/47780 [02:13<00:29, 278.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40134/47780 [02:13<00:31, 241.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39914/47780 [02:13<00:23, 328.95 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37649/47780 [02:13<00:38, 263.07 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30456/47780 [02:13<00:50, 342.38 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39416/47780 [02:13<00:25, 329.28 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39815/47780 [02:13<00:26, 304.07 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39691/47780 [02:13<00:34, 237.26 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39588/47780 [02:13<00:30, 272.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40160/47780 [02:13<00:32, 235.97 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30491/47780 [02:13<00:51, 337.71 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39949/47780 [02:13<00:24, 320.03 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37676/47780 [02:13<00:38, 259.36 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39449/47780 [02:13<00:25, 325.75 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39716/47780 [02:13<00:33, 238.17 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39846/47780 [02:13<00:27, 292.78 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39622/47780 [02:13<00:28, 290.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40197/47780 [02:13<00:28, 269.06 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37705/47780 [02:13<00:38, 264.81 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39982/47780 [02:13<00:25, 309.25 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30525/47780 [02:13<00:54, 319.08 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39482/47780 [02:13<00:25, 319.78 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39878/47780 [02:13<00:26, 296.49 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39741/47780 [02:13<00:35, 229.37 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39652/47780 [02:13<00:28, 280.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40227/47780 [02:13<00:28, 268.76 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37740/47780 [02:13<00:34, 288.67 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30558/47780 [02:13<00:55, 312.92 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39514/47780 [02:13<00:26, 312.85 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40014/47780 [02:13<00:26, 297.93 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39767/47780 [02:13<00:33, 237.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39908/47780 [02:13<00:27, 290.86 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40256/47780 [02:14<00:28, 265.70 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39681/47780 [02:13<00:31, 260.50 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37770/47780 [02:13<00:37, 270.30 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39546/47780 [02:14<00:26, 307.59 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40046/47780 [02:13<00:26, 295.32 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30590/47780 [02:13<00:57, 300.23 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39792/47780 [02:14<00:33, 240.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39938/47780 [02:14<00:28, 274.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40292/47780 [02:14<00:25, 291.15 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39709/47780 [02:14<00:30, 262.81 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40076/47780 [02:14<00:26, 290.28 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30626/47780 [02:14<00:54, 313.53 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37798/47780 [02:14<00:38, 261.33 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39578/47780 [02:14<00:28, 285.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39817/47780 [02:14<00:33, 238.22 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39972/47780 [02:14<00:27, 286.36 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40323/47780 [02:14<00:25, 287.40 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39738/47780 [02:14<00:29, 268.97 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30661/47780 [02:14<00:53, 322.43 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40116/47780 [02:14<00:24, 317.31 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37827/47780 [02:14<00:38, 255.43 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39619/47780 [02:14<00:25, 319.30 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39845/47780 [02:14<00:31, 249.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40005/47780 [02:14<00:26, 298.25 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39773/47780 [02:14<00:27, 290.51 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40354/47780 [02:14<00:26, 281.08 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40158/47780 [02:14<00:22, 342.47 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30694/47780 [02:14<00:53, 318.61 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37853/47780 [02:14<00:39, 251.24 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39872/47780 [02:14<00:32, 242.98 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39652/47780 [02:14<00:28, 289.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40041/47780 [02:14<00:24, 312.49 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39807/47780 [02:14<00:26, 303.93 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40385/47780 [02:14<00:26, 273.99 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30731/47780 [02:14<00:52, 326.04 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37882/47780 [02:14<00:37, 261.85 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40193/47780 [02:14<00:23, 319.05 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39903/47780 [02:14<00:30, 260.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40074/47780 [02:14<00:24, 313.99 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39682/47780 [02:14<00:28, 283.57 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39838/47780 [02:14<00:27, 285.38 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40417/47780 [02:14<00:25, 286.51 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30771/47780 [02:14<00:49, 346.97 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37912/47780 [02:14<00:36, 272.59 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40226/47780 [02:14<00:24, 311.75 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39943/47780 [02:14<00:26, 296.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40106/47780 [02:14<00:24, 315.23 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39713/47780 [02:14<00:27, 290.43 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39873/47780 [02:14<00:26, 300.48 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40456/47780 [02:14<00:23, 312.00 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30813/47780 [02:14<00:46, 363.96 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37940/47780 [02:14<00:37, 265.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40264/47780 [02:14<00:23, 324.00 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39744/47780 [02:14<00:27, 295.81 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39973/47780 [02:14<00:28, 278.64 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40138/47780 [02:14<00:25, 299.67 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39905/47780 [02:14<00:26, 296.01 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30852/47780 [02:14<00:46, 367.27 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40488/47780 [02:14<00:24, 294.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40299/47780 [02:14<00:22, 330.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37967/47780 [02:14<00:40, 244.62 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39775/47780 [02:14<00:27, 293.40 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40004/47780 [02:14<00:27, 284.07 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40169/47780 [02:14<00:26, 292.47 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39939/47780 [02:14<00:25, 308.34 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40518/47780 [02:14<00:25, 283.01 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40333/47780 [02:14<00:22, 329.59 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30889/47780 [02:14<00:51, 329.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37997/47780 [02:14<00:38, 256.79 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39808/47780 [02:14<00:26, 296.98 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40033/47780 [02:14<00:29, 264.90 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40200/47780 [02:14<00:26, 281.83 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39972/47780 [02:14<00:25, 310.85 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40553/47780 [02:15<00:23, 301.30 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30929/47780 [02:14<00:48, 348.46 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40368/47780 [02:14<00:22, 327.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38024/47780 [02:14<00:37, 258.42 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39842/47780 [02:15<00:26, 302.50 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40060/47780 [02:15<00:29, 265.61 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40016/47780 [02:15<00:22, 344.25 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40229/47780 [02:15<00:27, 275.03 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40584/47780 [02:15<00:24, 291.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40401/47780 [02:15<00:23, 317.57 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30965/47780 [02:15<00:49, 340.00 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39874/47780 [02:15<00:25, 307.39 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38051/47780 [02:15<00:39, 246.75 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40052/47780 [02:15<00:22, 348.49 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40087/47780 [02:15<00:30, 255.72 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40258/47780 [02:15<00:27, 273.51 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40617/47780 [02:15<00:23, 298.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40445/47780 [02:15<00:20, 351.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31003/47780 [02:15<00:49, 341.16 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38080/47780 [02:15<00:38, 250.63 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40088/47780 [02:15<00:23, 333.66 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39905/47780 [02:15<00:28, 273.10 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40113/47780 [02:15<00:31, 242.74 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40286/47780 [02:15<00:27, 268.20 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40657/47780 [02:15<00:22, 323.57 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31039/47780 [02:15<00:48, 345.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40483/47780 [02:15<00:20, 352.24 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38108/47780 [02:15<00:37, 258.50 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40138/47780 [02:15<00:31, 241.85 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39936/47780 [02:15<00:28, 271.64 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40313/47780 [02:15<00:28, 257.77 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40122/47780 [02:15<00:24, 316.53 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40690/47780 [02:15<00:21, 325.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31074/47780 [02:15<00:48, 342.60 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40519/47780 [02:15<00:21, 342.60 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38135/47780 [02:15<00:37, 256.20 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39966/47780 [02:15<00:28, 279.05 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40163/47780 [02:15<00:32, 237.44 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40341/47780 [02:15<00:28, 261.10 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40723/47780 [02:15<00:22, 312.25 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40154/47780 [02:15<00:25, 300.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31115/47780 [02:15<00:46, 361.59 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40554/47780 [02:15<00:21, 340.88 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38163/47780 [02:15<00:36, 262.92 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39995/47780 [02:15<00:28, 275.74 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40369/47780 [02:15<00:27, 265.86 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40195/47780 [02:15<00:29, 259.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40757/47780 [02:15<00:22, 316.46 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31153/47780 [02:15<00:47, 350.39 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40593/47780 [02:15<00:20, 347.17 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38193/47780 [02:15<00:35, 273.59 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40185/47780 [02:15<00:28, 263.43 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40401/47780 [02:15<00:26, 278.68 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40027/47780 [02:15<00:27, 282.29 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40222/47780 [02:15<00:30, 248.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40789/47780 [02:15<00:22, 313.59 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31198/47780 [02:15<00:44, 371.28 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40630/47780 [02:15<00:20, 349.50 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38225/47780 [02:15<00:33, 287.10 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40219/47780 [02:15<00:26, 282.62 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40439/47780 [02:15<00:24, 303.60 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40058/47780 [02:15<00:26, 289.15 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40252/47780 [02:15<00:28, 260.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40821/47780 [02:15<00:22, 311.80 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38254/47780 [02:15<00:34, 278.16 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40667/47780 [02:15<00:20, 339.66 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40253/47780 [02:15<00:25, 297.52 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31236/47780 [02:15<00:48, 339.09 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40474/47780 [02:15<00:23, 314.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40091/47780 [02:15<00:26, 295.08 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40853/47780 [02:15<00:23, 290.70 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38282/47780 [02:15<00:34, 275.36 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40284/47780 [02:15<00:25, 294.88 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40702/47780 [02:15<00:22, 321.14 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40284/47780 [02:15<00:33, 222.23 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40516/47780 [02:15<00:21, 340.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31271/47780 [02:15<00:53, 308.78 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40887/47780 [02:16<00:23, 297.13 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40121/47780 [02:16<00:30, 253.79 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38311/47780 [02:16<00:34, 276.61 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40315/47780 [02:16<00:26, 286.74 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40322/47780 [02:16<00:28, 260.66 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40735/47780 [02:16<00:23, 294.26 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31308/47780 [02:16<00:51, 321.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40555/47780 [02:16<00:21, 339.14 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40925/47780 [02:16<00:21, 314.21 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40151/47780 [02:16<00:29, 262.27 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40345/47780 [02:16<00:26, 282.98 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38339/47780 [02:16<00:37, 254.67 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40352/47780 [02:16<00:27, 267.85 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40766/47780 [02:16<00:23, 295.44 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40589/47780 [02:16<00:21, 335.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31348/47780 [02:16<00:49, 335.04 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40961/47780 [02:16<00:21, 323.43 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40384/47780 [02:16<00:23, 310.02 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40180/47780 [02:16<00:31, 243.59 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38365/47780 [02:16<00:38, 245.09 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40381/47780 [02:16<00:28, 262.90 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40796/47780 [02:16<00:24, 289.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31386/47780 [02:16<00:47, 343.61 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40623/47780 [02:16<00:23, 308.74 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40994/47780 [02:16<00:21, 313.76 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40419/47780 [02:16<00:23, 314.20 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40213/47780 [02:16<00:28, 263.05 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40411/47780 [02:16<00:27, 269.96 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40833/47780 [02:16<00:22, 308.88 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38390/47780 [02:16<00:40, 230.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31421/47780 [02:16<00:49, 330.39 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40655/47780 [02:16<00:25, 283.99 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41032/47780 [02:16<00:20, 322.28 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40455/47780 [02:16<00:22, 323.53 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40866/47780 [02:16<00:22, 311.27 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38415/47780 [02:16<00:39, 234.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40241/47780 [02:16<00:30, 246.34 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40439/47780 [02:16<00:28, 253.20 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31455/47780 [02:16<00:52, 312.66 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41070/47780 [02:16<00:19, 338.38 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40684/47780 [02:16<00:26, 265.98 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40488/47780 [02:16<00:23, 307.49 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38443/47780 [02:16<00:37, 246.18 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40900/47780 [02:16<00:22, 312.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40268/47780 [02:16<00:29, 252.47 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31492/47780 [02:16<00:49, 328.06 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40465/47780 [02:16<00:31, 230.27 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41105/47780 [02:16<00:20, 330.40 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40712/47780 [02:16<00:26, 263.85 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40525/47780 [02:16<00:22, 321.69 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40936/47780 [02:16<00:21, 322.70 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38476/47780 [02:16<00:35, 260.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40295/47780 [02:16<00:30, 249.16 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31529/47780 [02:16<00:47, 339.46 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40492/47780 [02:16<00:30, 240.43 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41139/47780 [02:16<00:19, 332.38 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40755/47780 [02:16<00:23, 305.19 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40969/47780 [02:16<00:21, 316.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38509/47780 [02:16<00:33, 274.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40321/47780 [02:16<00:30, 245.34 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40558/47780 [02:16<00:24, 294.03 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31568/47780 [02:16<00:46, 350.16 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40517/47780 [02:16<00:32, 223.77 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41173/47780 [02:16<00:21, 311.30 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40787/47780 [02:16<00:22, 305.25 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40349/47780 [02:17<00:29, 253.85 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41001/47780 [02:16<00:22, 307.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38543/47780 [02:16<00:32, 285.55 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40588/47780 [02:16<00:25, 286.06 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31615/47780 [02:16<00:43, 367.60 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40546/47780 [02:16<00:30, 238.88 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41205/47780 [02:17<00:21, 302.78 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40818/47780 [02:17<00:23, 300.02 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38580/47780 [02:17<00:29, 306.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41048/47780 [02:17<00:19, 349.91 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40377/47780 [02:17<00:29, 254.08 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40617/47780 [02:17<00:26, 267.28 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31652/47780 [02:17<00:49, 324.23 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40571/47780 [02:17<00:30, 232.79 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40849/47780 [02:17<00:23, 290.07 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38611/47780 [02:17<00:29, 307.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41238/47780 [02:17<00:22, 288.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41091/47780 [02:17<00:18, 368.60 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40404/47780 [02:17<00:29, 254.26 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40647/47780 [02:17<00:25, 275.91 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31707/47780 [02:17<00:42, 379.62 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40595/47780 [02:17<00:33, 215.14 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38642/47780 [02:17<00:29, 304.72 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40883/47780 [02:17<00:23, 288.23 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41136/47780 [02:17<00:17, 387.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40431/47780 [02:17<00:28, 256.67 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41268/47780 [02:17<00:23, 273.57 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40675/47780 [02:17<00:26, 263.67 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31747/47780 [02:17<00:45, 354.20 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38677/47780 [02:17<00:28, 314.20 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41176/47780 [02:17<00:16, 390.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40619/47780 [02:17<00:32, 217.11 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40458/47780 [02:17<00:28, 256.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40933/47780 [02:17<00:20, 334.83 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41297/47780 [02:17<00:24, 266.40 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40703/47780 [02:17<00:26, 264.19 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31784/47780 [02:17<00:45, 355.26 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41219/47780 [02:17<00:16, 402.10 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40642/47780 [02:17<00:33, 215.01 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40967/47780 [02:17<00:20, 325.45 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40495/47780 [02:17<00:26, 273.42 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41327/47780 [02:17<00:23, 275.28 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38709/47780 [02:17<00:32, 280.11 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40730/47780 [02:17<00:27, 260.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41265/47780 [02:17<00:15, 409.76 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31821/47780 [02:17<00:46, 340.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40664/47780 [02:17<00:33, 210.43 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41368/47780 [02:17<00:20, 309.45 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40526/47780 [02:17<00:25, 280.60 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38738/47780 [02:17<00:32, 277.56 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41000/47780 [02:17<00:22, 297.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40759/47780 [02:17<00:27, 256.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31856/47780 [02:17<00:46, 341.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40686/47780 [02:17<00:33, 210.82 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40561/47780 [02:17<00:24, 299.38 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41307/47780 [02:17<00:17, 369.15 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38774/47780 [02:17<00:30, 299.37 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41400/47780 [02:17<00:21, 295.33 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40792/47780 [02:17<00:25, 274.10 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41031/47780 [02:17<00:23, 285.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40710/47780 [02:17<00:32, 216.44 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31891/47780 [02:17<00:49, 320.31 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38812/47780 [02:17<00:28, 318.39 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41435/47780 [02:17<00:20, 304.07 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40593/47780 [02:17<00:25, 277.54 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41345/47780 [02:17<00:18, 349.35 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40826/47780 [02:17<00:23, 292.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41060/47780 [02:17<00:25, 262.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40741/47780 [02:17<00:29, 240.17 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31931/47780 [02:17<00:46, 338.49 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41471/47780 [02:17<00:19, 319.60 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38845/47780 [02:17<00:28, 310.56 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40624/47780 [02:17<00:24, 286.33 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41383/47780 [02:17<00:18, 354.88 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40859/47780 [02:17<00:23, 293.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41087/47780 [02:17<00:26, 253.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40769/47780 [02:17<00:28, 248.73 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31966/47780 [02:17<00:46, 341.20 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38877/47780 [02:18<00:28, 310.00 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41505/47780 [02:18<00:19, 314.41 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40654/47780 [02:18<00:25, 274.78 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41419/47780 [02:18<00:19, 333.74 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40890/47780 [02:18<00:25, 270.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40801/47780 [02:18<00:25, 269.04 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41113/47780 [02:18<00:27, 242.85 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32002/47780 [02:18<00:45, 346.37 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40690/47780 [02:18<00:23, 298.08 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38910/47780 [02:18<00:29, 295.67 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41539/47780 [02:18<00:20, 303.60 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41463/47780 [02:18<00:18, 343.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40922/47780 [02:18<00:24, 280.79 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41138/47780 [02:18<00:27, 244.45 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40830/47780 [02:18<00:27, 257.09 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32037/47780 [02:18<00:47, 329.14 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40727/47780 [02:18<00:22, 314.82 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38941/47780 [02:18<00:29, 296.47 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41572/47780 [02:18<00:20, 305.36 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41500/47780 [02:18<00:17, 350.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40954/47780 [02:18<00:23, 288.45 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41165/47780 [02:18<00:27, 243.63 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32075/47780 [02:18<00:46, 339.49 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40856/47780 [02:18<00:28, 247.07 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40766/47780 [02:18<00:21, 328.62 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38971/47780 [02:18<00:31, 281.64 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41541/47780 [02:18<00:17, 363.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40984/47780 [02:18<00:23, 285.13 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41204/47780 [02:18<00:23, 280.66 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41603/47780 [02:18<00:23, 260.27 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32115/47780 [02:18<00:44, 352.55 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40889/47780 [02:18<00:25, 267.09 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40801/47780 [02:18<00:20, 334.62 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39002/47780 [02:18<00:30, 283.17 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41582/47780 [02:18<00:16, 371.96 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41024/47780 [02:18<00:21, 307.17 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41631/47780 [02:18<00:23, 259.68 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32151/47780 [02:18<00:44, 354.05 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41233/47780 [02:18<00:24, 265.42 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40916/47780 [02:18<00:27, 253.69 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40837/47780 [02:18<00:20, 338.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41623/47780 [02:18<00:16, 382.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41057/47780 [02:18<00:21, 310.08 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39031/47780 [02:18<00:35, 249.20 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32197/47780 [02:18<00:40, 381.04 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41658/47780 [02:18<00:24, 252.57 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40945/47780 [02:18<00:25, 263.10 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40873/47780 [02:18<00:20, 340.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41260/47780 [02:18<00:26, 250.26 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41099/47780 [02:18<00:20, 333.65 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39067/47780 [02:18<00:31, 274.82 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32238/47780 [02:18<00:40, 380.63 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41662/47780 [02:18<00:19, 321.88 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41686/47780 [02:18<00:23, 256.53 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40978/47780 [02:18<00:24, 276.36 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40908/47780 [02:18<00:20, 342.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41287/47780 [02:18<00:25, 253.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41141/47780 [02:18<00:18, 358.06 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39100/47780 [02:18<00:30, 283.45 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32288/47780 [02:18<00:37, 414.66 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41713/47780 [02:18<00:23, 257.18 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41731/47780 [02:18<00:14, 403.64 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41320/47780 [02:18<00:24, 268.21 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41006/47780 [02:18<00:25, 265.22 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40943/47780 [02:18<00:22, 305.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41178/47780 [02:18<00:18, 357.19 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41740/47780 [02:19<00:23, 252.80 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39130/47780 [02:18<00:32, 264.64 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41775/47780 [02:18<00:15, 396.01 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41037/47780 [02:18<00:24, 274.87 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41348/47780 [02:18<00:23, 268.22 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32331/47780 [02:18<00:41, 370.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40975/47780 [02:19<00:22, 299.87 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41214/47780 [02:19<00:18, 345.89 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41769/47780 [02:19<00:23, 260.11 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39162/47780 [02:19<00:31, 276.63 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41376/47780 [02:19<00:24, 265.93 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41066/47780 [02:19<00:24, 272.87 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32395/47780 [02:19<00:34, 440.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41819/47780 [02:19<00:15, 373.19 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41006/47780 [02:19<00:23, 289.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41251/47780 [02:19<00:18, 352.65 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41407/47780 [02:19<00:22, 278.30 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41096/47780 [02:19<00:23, 280.54 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41796/47780 [02:19<00:24, 243.31 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39191/47780 [02:19<00:32, 267.83 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32441/47780 [02:19<00:35, 432.47 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41867/47780 [02:19<00:14, 400.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41038/47780 [02:19<00:22, 297.37 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41287/47780 [02:19<00:19, 339.61 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39223/47780 [02:19<00:30, 280.54 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41125/47780 [02:19<00:23, 278.67 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41436/47780 [02:19<00:24, 263.46 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32486/47780 [02:19<00:36, 421.80 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41821/47780 [02:19<00:25, 230.64 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41909/47780 [02:19<00:14, 392.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41080/47780 [02:19<00:20, 331.46 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39262/47780 [02:19<00:27, 306.58 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41322/47780 [02:19<00:21, 298.48 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41158/47780 [02:19<00:23, 287.46 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32530/47780 [02:19<00:36, 417.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41845/47780 [02:19<00:25, 230.10 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41114/47780 [02:19<00:20, 323.65 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41463/47780 [02:19<00:26, 235.97 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41950/47780 [02:19<00:16, 351.48 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41361/47780 [02:19<00:19, 322.14 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39295/47780 [02:19<00:28, 299.11 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41870/47780 [02:19<00:25, 233.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41187/47780 [02:19<00:24, 267.40 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32573/47780 [02:19<00:39, 386.87 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41488/47780 [02:19<00:26, 237.59 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41149/47780 [02:19<00:20, 317.17 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41987/47780 [02:19<00:16, 349.30 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39326/47780 [02:19<00:28, 299.46 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41395/47780 [02:19<00:20, 310.07 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41896/47780 [02:19<00:24, 240.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41215/47780 [02:19<00:25, 259.43 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32618/47780 [02:19<00:37, 399.32 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41532/47780 [02:19<00:21, 286.06 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41181/47780 [02:19<00:21, 310.78 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42023/47780 [02:19<00:16, 351.68 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39361/47780 [02:19<00:27, 310.15 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41921/47780 [02:19<00:24, 243.42 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41427/47780 [02:19<00:21, 300.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41247/47780 [02:19<00:23, 275.81 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32659/47780 [02:19<00:38, 389.58 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41563/47780 [02:19<00:21, 289.57 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41213/47780 [02:19<00:21, 300.23 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42059/47780 [02:19<00:16, 342.38 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41948/47780 [02:19<00:23, 248.16 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39401/47780 [02:19<00:25, 328.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41459/47780 [02:19<00:20, 304.45 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32704/47780 [02:19<00:37, 406.19 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41606/47780 [02:19<00:18, 325.02 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41275/47780 [02:19<00:26, 249.25 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42097/47780 [02:19<00:16, 349.76 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39440/47780 [02:19<00:24, 342.03 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41983/47780 [02:20<00:21, 271.40 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41493/47780 [02:19<00:20, 311.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41244/47780 [02:20<00:25, 259.83 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41643/47780 [02:19<00:18, 333.97 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41301/47780 [02:19<00:25, 249.42 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42142/47780 [02:20<00:14, 377.33 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32747/47780 [02:19<00:39, 378.59 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39476/47780 [02:20<00:23, 347.14 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41281/47780 [02:20<00:23, 281.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42011/47780 [02:20<00:22, 256.24 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41525/47780 [02:20<00:21, 296.98 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41680/47780 [02:20<00:18, 336.54 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41331/47780 [02:20<00:25, 257.56 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42181/47780 [02:20<00:15, 368.37 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32786/47780 [02:20<00:42, 354.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39512/47780 [02:20<00:25, 328.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42037/47780 [02:20<00:22, 254.12 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41557/47780 [02:20<00:21, 292.40 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41311/47780 [02:20<00:24, 261.95 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41715/47780 [02:20<00:18, 332.36 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41361/47780 [02:20<00:23, 268.22 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42221/47780 [02:20<00:14, 377.21 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32828/47780 [02:20<00:40, 368.28 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39554/47780 [02:20<00:23, 353.67 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42065/47780 [02:20<00:22, 258.90 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41588/47780 [02:20<00:21, 289.23 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41343/47780 [02:20<00:23, 275.74 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41392/47780 [02:20<00:23, 274.91 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42260/47780 [02:20<00:14, 372.80 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41749/47780 [02:20<00:19, 303.34 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32866/47780 [02:20<00:41, 358.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39590/47780 [02:20<00:23, 347.59 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42091/47780 [02:20<00:23, 245.03 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41619/47780 [02:20<00:21, 288.85 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41432/47780 [02:20<00:20, 310.36 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42300/47780 [02:20<00:14, 380.42 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41372/47780 [02:20<00:25, 248.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41781/47780 [02:20<00:21, 281.11 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32903/47780 [02:20<00:45, 330.34 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42116/47780 [02:20<00:23, 243.12 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39626/47780 [02:20<00:24, 326.73 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41649/47780 [02:20<00:21, 287.89 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41464/47780 [02:20<00:20, 309.15 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42339/47780 [02:20<00:14, 370.48 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41411/47780 [02:20<00:22, 279.01 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41810/47780 [02:20<00:21, 277.25 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32939/47780 [02:20<00:44, 334.50 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42145/47780 [02:20<00:22, 248.66 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41496/47780 [02:20<00:20, 308.61 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39660/47780 [02:20<00:27, 299.34 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42377/47780 [02:20<00:15, 356.94 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41450/47780 [02:20<00:20, 307.98 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41678/47780 [02:20<00:24, 248.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41849/47780 [02:20<00:19, 304.44 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42176/47780 [02:20<00:21, 265.60 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32974/47780 [02:20<00:47, 308.47 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39696/47780 [02:20<00:25, 315.11 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41528/47780 [02:20<00:21, 286.07 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41705/47780 [02:20<00:24, 250.03 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41482/47780 [02:20<00:21, 295.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42414/47780 [02:20<00:16, 332.19 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41880/47780 [02:20<00:19, 295.73 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42206/47780 [02:20<00:20, 272.61 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39734/47780 [02:20<00:24, 332.65 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33007/47780 [02:20<00:48, 301.63 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41559/47780 [02:20<00:21, 292.54 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41739/47780 [02:20<00:22, 271.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41518/47780 [02:20<00:20, 312.52 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42451/47780 [02:20<00:16, 322.84 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41910/47780 [02:20<00:19, 293.82 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39776/47780 [02:20<00:22, 353.42 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33047/47780 [02:20<00:45, 324.35 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42234/47780 [02:21<00:22, 248.70 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41589/47780 [02:20<00:21, 287.85 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41551/47780 [02:21<00:20, 310.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41767/47780 [02:20<00:22, 267.48 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41950/47780 [02:21<00:18, 310.02 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42484/47780 [02:21<00:17, 302.51 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33083/47780 [02:21<00:44, 333.91 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42260/47780 [02:21<00:21, 251.71 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39812/47780 [02:21<00:23, 341.00 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41620/47780 [02:21<00:22, 275.43 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41585/47780 [02:21<00:19, 311.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41797/47780 [02:21<00:22, 270.75 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41982/47780 [02:21<00:18, 305.52 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42517/47780 [02:21<00:17, 308.81 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42289/47780 [02:21<00:21, 259.86 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33117/47780 [02:21<00:45, 320.82 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41651/47780 [02:21<00:21, 284.75 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39847/47780 [02:21<00:24, 317.50 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41617/47780 [02:21<00:19, 310.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41829/47780 [02:21<00:21, 281.42 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42549/47780 [02:21<00:16, 311.02 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33163/47780 [02:21<00:40, 358.93 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42316/47780 [02:21<00:21, 251.42 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41860/47780 [02:21<00:20, 289.26 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41652/47780 [02:21<00:19, 318.09 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39880/47780 [02:21<00:25, 313.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41687/47780 [02:21<00:20, 296.24 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42581/47780 [02:21<00:16, 311.28 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42013/47780 [02:21<00:25, 228.13 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33207/47780 [02:21<00:38, 374.28 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41900/47780 [02:21<00:18, 315.70 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41719/47780 [02:21<00:20, 299.78 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41686/47780 [02:21<00:18, 320.82 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42342/47780 [02:21<00:23, 232.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39912/47780 [02:21<00:25, 309.00 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42618/47780 [02:21<00:15, 325.11 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42069/47780 [02:21<00:19, 296.05 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33246/47780 [02:21<00:38, 378.68 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41750/47780 [02:21<00:19, 302.14 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39944/47780 [02:21<00:25, 308.67 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42366/47780 [02:21<00:23, 229.61 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41932/47780 [02:21<00:20, 291.89 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41719/47780 [02:21<00:20, 298.37 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42651/47780 [02:21<00:16, 315.85 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42102/47780 [02:21<00:19, 292.87 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33285/47780 [02:21<00:38, 372.87 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39979/47780 [02:21<00:24, 317.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42396/47780 [02:21<00:21, 246.44 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41968/47780 [02:21<00:18, 307.33 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41781/47780 [02:21<00:22, 267.84 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41750/47780 [02:21<00:21, 286.72 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42683/47780 [02:21<00:17, 293.22 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42134/47780 [02:21<00:19, 285.21 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33323/47780 [02:21<00:41, 351.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42422/47780 [02:21<00:21, 250.15 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40012/47780 [02:21<00:25, 309.71 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42004/47780 [02:21<00:18, 311.49 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41812/47780 [02:21<00:21, 276.09 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41785/47780 [02:21<00:20, 297.50 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42716/47780 [02:21<00:16, 300.38 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33359/47780 [02:21<00:42, 342.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42165/47780 [02:21<00:20, 277.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42454/47780 [02:21<00:20, 263.95 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40044/47780 [02:21<00:26, 295.88 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41845/47780 [02:21<00:20, 287.63 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42036/47780 [02:21<00:19, 300.54 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42750/47780 [02:21<00:16, 308.02 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41816/47780 [02:21<00:21, 273.71 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33394/47780 [02:21<00:41, 343.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42194/47780 [02:21<00:19, 280.34 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40075/47780 [02:21<00:26, 293.31 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42483/47780 [02:22<00:21, 251.29 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42069/47780 [02:21<00:18, 305.26 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41876/47780 [02:21<00:21, 278.26 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42782/47780 [02:21<00:16, 308.16 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41850/47780 [02:22<00:20, 288.14 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33430/47780 [02:21<00:41, 345.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42223/47780 [02:22<00:19, 280.30 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42513/47780 [02:22<00:19, 264.58 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40105/47780 [02:22<00:26, 285.29 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42818/47780 [02:22<00:15, 321.87 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42100/47780 [02:22<00:19, 284.27 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41907/47780 [02:22<00:21, 275.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41880/47780 [02:22<00:21, 276.40 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42257/47780 [02:22<00:19, 287.42 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33465/47780 [02:22<00:43, 328.15 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42540/47780 [02:22<00:19, 264.67 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40135/47780 [02:22<00:26, 286.52 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42853/47780 [02:22<00:15, 326.55 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42144/47780 [02:22<00:17, 322.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41935/47780 [02:22<00:22, 254.26 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42289/47780 [02:22<00:18, 296.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41909/47780 [02:22<00:22, 265.35 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33499/47780 [02:22<00:44, 323.75 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40165/47780 [02:22<00:27, 280.83 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42567/47780 [02:22<00:21, 245.25 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42890/47780 [02:22<00:14, 334.79 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42177/47780 [02:22<00:17, 317.62 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41967/47780 [02:22<00:21, 268.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41949/47780 [02:22<00:19, 298.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42324/47780 [02:22<00:17, 304.85 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33542/47780 [02:22<00:40, 353.35 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42596/47780 [02:22<00:20, 257.28 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40197/47780 [02:22<00:26, 282.30 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42924/47780 [02:22<00:15, 322.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41987/47780 [02:22<00:18, 320.92 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42356/47780 [02:22<00:17, 302.17 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41995/47780 [02:22<00:22, 252.67 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33579/47780 [02:22<00:40, 350.28 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42211/47780 [02:22<00:19, 282.77 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42623/47780 [02:22<00:20, 255.23 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40226/47780 [02:22<00:26, 281.33 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42959/47780 [02:22<00:14, 330.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42020/47780 [02:22<00:18, 315.59 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42396/47780 [02:22<00:16, 329.64 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33621/47780 [02:22<00:38, 366.06 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42255/47780 [02:22<00:17, 320.43 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42032/47780 [02:22<00:20, 274.96 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42652/47780 [02:22<00:19, 262.26 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40255/47780 [02:22<00:26, 280.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43006/47780 [02:22<00:13, 362.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42055/47780 [02:22<00:17, 322.51 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33669/47780 [02:22<00:35, 398.75 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42430/47780 [02:22<00:16, 317.55 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40290/47780 [02:22<00:25, 293.76 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42060/47780 [02:22<00:23, 247.16 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42679/47780 [02:22<00:20, 244.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43049/47780 [02:22<00:12, 374.79 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42289/47780 [02:22<00:22, 246.57 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33710/47780 [02:22<00:37, 379.02 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42088/47780 [02:22<00:18, 300.58 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42463/47780 [02:22<00:17, 307.91 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40323/47780 [02:22<00:24, 303.83 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42087/47780 [02:22<00:23, 245.47 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43102/47780 [02:22<00:11, 417.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42708/47780 [02:22<00:20, 246.39 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42340/47780 [02:22<00:17, 302.90 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42496/47780 [02:22<00:17, 297.29 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42119/47780 [02:22<00:19, 284.37 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33749/47780 [02:22<00:39, 357.84 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40354/47780 [02:22<00:25, 286.03 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43144/47780 [02:22<00:11, 408.90 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42112/47780 [02:22<00:23, 239.22 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42752/47780 [02:23<00:16, 296.14 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42149/47780 [02:23<00:19, 288.33 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33786/47780 [02:22<00:38, 360.39 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42527/47780 [02:23<00:17, 297.21 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42375/47780 [02:23<00:18, 294.40 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40383/47780 [02:23<00:26, 281.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42137/47780 [02:23<00:24, 226.79 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42783/47780 [02:23<00:17, 278.26 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43186/47780 [02:23<00:12, 369.07 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33831/47780 [02:23<00:36, 383.10 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42183/47780 [02:23<00:18, 296.39 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42557/47780 [02:23<00:17, 292.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40412/47780 [02:23<00:26, 276.69 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42164/47780 [02:23<00:24, 231.61 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42812/47780 [02:23<00:17, 278.44 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42408/47780 [02:23<00:20, 262.20 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43229/47780 [02:23<00:11, 381.72 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33873/47780 [02:23<00:35, 389.26 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42214/47780 [02:23<00:19, 281.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42587/47780 [02:23<00:19, 261.52 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40440/47780 [02:23<00:28, 257.54 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42443/47780 [02:23<00:19, 279.84 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42188/47780 [02:23<00:24, 228.81 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42843/47780 [02:23<00:17, 277.91 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43270/47780 [02:23<00:11, 376.72 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33915/47780 [02:23<00:35, 393.28 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42275/47780 [02:23<00:15, 366.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42614/47780 [02:23<00:20, 252.83 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40474/47780 [02:23<00:26, 276.92 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42216/47780 [02:23<00:22, 242.07 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42878/47780 [02:23<00:16, 297.66 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43312/47780 [02:23<00:11, 388.08 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42475/47780 [02:23<00:18, 279.24 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33970/47780 [02:23<00:31, 433.80 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42314/47780 [02:23<00:15, 356.89 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42640/47780 [02:23<00:20, 252.47 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40503/47780 [02:23<00:26, 274.24 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42246/47780 [02:23<00:22, 248.08 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43355/47780 [02:23<00:11, 395.63 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42909/47780 [02:23<00:17, 276.07 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42506/47780 [02:23<00:19, 267.60 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34030/47780 [02:23<00:28, 475.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42356/47780 [02:23<00:14, 370.67 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42666/47780 [02:23<00:20, 246.41 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40531/47780 [02:23<00:27, 264.27 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42275/47780 [02:23<00:21, 251.28 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43395/47780 [02:23<00:11, 367.50 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34078/47780 [02:23<00:29, 460.99 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42534/47780 [02:23<00:20, 258.15 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42938/47780 [02:23<00:18, 257.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42395/47780 [02:23<00:14, 371.61 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40563/47780 [02:23<00:26, 276.71 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42691/47780 [02:23<00:21, 237.02 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43436/47780 [02:23<00:11, 371.88 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42301/47780 [02:23<00:23, 235.50 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42561/47780 [02:23<00:20, 260.67 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34125/47780 [02:23<00:31, 434.41 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42966/47780 [02:23<00:19, 245.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42433/47780 [02:23<00:15, 350.51 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40594/47780 [02:23<00:25, 285.96 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42716/47780 [02:23<00:21, 239.99 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43476/47780 [02:23<00:11, 379.14 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42325/47780 [02:23<00:23, 234.22 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42588/47780 [02:23<00:20, 259.15 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34172/47780 [02:23<00:30, 439.36 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42994/47780 [02:23<00:18, 253.46 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42472/47780 [02:23<00:14, 357.06 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40623/47780 [02:23<00:25, 277.58 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42741/47780 [02:23<00:21, 230.17 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43520/47780 [02:23<00:10, 387.97 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42350/47780 [02:23<00:22, 238.49 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42621/47780 [02:23<00:19, 271.07 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34217/47780 [02:23<00:31, 437.45 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43023/47780 [02:24<00:18, 261.68 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42509/47780 [02:24<00:15, 334.55 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40659/47780 [02:24<00:24, 287.85 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42768/47780 [02:24<00:21, 231.36 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43560/47780 [02:24<00:10, 386.74 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42374/47780 [02:24<00:22, 237.04 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34263/47780 [02:24<00:30, 442.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43050/47780 [02:24<00:18, 260.85 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42649/47780 [02:24<00:20, 248.77 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40695/47780 [02:24<00:23, 307.84 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42796/47780 [02:24<00:20, 244.58 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42398/47780 [02:24<00:22, 234.40 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42543/47780 [02:24<00:16, 309.45 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43599/47780 [02:24<00:11, 378.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34309/47780 [02:24<00:31, 429.02 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42676/47780 [02:24<00:20, 244.75 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43079/47780 [02:24<00:18, 250.98 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43638/47780 [02:24<00:10, 378.13 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42430/47780 [02:24<00:21, 253.16 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42575/47780 [02:24<00:17, 304.99 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40726/47780 [02:24<00:24, 283.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42821/47780 [02:24<00:22, 220.74 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42701/47780 [02:24<00:20, 245.44 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34353/47780 [02:24<00:34, 383.81 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43106/47780 [02:24<00:19, 239.21 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43682/47780 [02:24<00:10, 391.48 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42457/47780 [02:24<00:21, 252.06 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40755/47780 [02:24<00:24, 284.64 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42606/47780 [02:24<00:17, 300.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42856/47780 [02:24<00:19, 250.30 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42729/47780 [02:24<00:20, 249.44 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43131/47780 [02:24<00:19, 234.47 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34393/47780 [02:24<00:37, 361.56 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40789/47780 [02:24<00:23, 299.85 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42641/47780 [02:24<00:16, 312.69 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43722/47780 [02:24<00:11, 368.42 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42882/47780 [02:24<00:19, 252.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42483/47780 [02:24<00:22, 230.55 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42764/47780 [02:24<00:18, 271.25 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34431/47780 [02:24<00:36, 363.95 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43156/47780 [02:24<00:19, 236.17 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42677/47780 [02:24<00:15, 323.86 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40820/47780 [02:24<00:23, 293.97 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42507/47780 [02:24<00:23, 228.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43760/47780 [02:24<00:11, 344.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42908/47780 [02:24<00:20, 238.82 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42793/47780 [02:24<00:18, 273.65 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42712/47780 [02:24<00:15, 330.96 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43180/47780 [02:24<00:20, 224.63 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34469/47780 [02:24<00:38, 347.58 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40853/47780 [02:24<00:23, 299.70 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42531/47780 [02:24<00:22, 231.34 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42936/47780 [02:24<00:19, 247.61 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43796/47780 [02:24<00:12, 327.79 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42822/47780 [02:24<00:18, 271.73 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34508/47780 [02:24<00:37, 356.03 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40884/47780 [02:24<00:22, 302.36 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43213/47780 [02:24<00:18, 248.06 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42746/47780 [02:24<00:16, 308.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42559/47780 [02:24<00:21, 239.85 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43842/47780 [02:24<00:10, 362.52 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42851/47780 [02:24<00:18, 270.96 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42963/47780 [02:24<00:20, 230.62 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34557/47780 [02:24<00:33, 392.42 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43241/47780 [02:24<00:17, 254.18 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40917/47780 [02:24<00:22, 303.61 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42783/47780 [02:24<00:15, 318.91 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42584/47780 [02:24<00:21, 237.18 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43879/47780 [02:24<00:10, 364.40 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42879/47780 [02:24<00:18, 261.70 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42991/47780 [02:24<00:20, 236.20 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40949/47780 [02:24<00:22, 308.29 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43274/47780 [02:25<00:16, 271.53 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34597/47780 [02:24<00:34, 378.03 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42816/47780 [02:25<00:15, 321.41 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42619/47780 [02:25<00:19, 266.35 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43924/47780 [02:25<00:10, 376.49 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42911/47780 [02:25<00:17, 274.94 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43031/47780 [02:25<00:17, 275.20 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40981/47780 [02:25<00:22, 308.16 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34636/47780 [02:25<00:34, 379.37 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43302/47780 [02:25<00:17, 262.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42653/47780 [02:25<00:18, 283.91 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42850/47780 [02:25<00:17, 288.02 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43972/47780 [02:25<00:09, 383.81 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42945/47780 [02:25<00:16, 289.98 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43061/47780 [02:25<00:17, 269.31 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41013/47780 [02:25<00:22, 301.07 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42690/47780 [02:25<00:16, 305.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43329/47780 [02:25<00:18, 245.36 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42885/47780 [02:25<00:16, 301.16 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42980/47780 [02:25<00:15, 303.82 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44014/47780 [02:25<00:09, 385.30 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34675/47780 [02:25<00:42, 306.79 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43093/47780 [02:25<00:17, 274.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41049/47780 [02:25<00:22, 304.04 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42916/47780 [02:25<00:16, 303.09 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42721/47780 [02:25<00:17, 282.98 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43355/47780 [02:25<00:19, 229.79 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44053/47780 [02:25<00:09, 377.80 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43011/47780 [02:25<00:15, 301.37 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34740/47780 [02:25<00:33, 384.14 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43123/47780 [02:25<00:16, 278.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41081/47780 [02:25<00:21, 308.50 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42947/47780 [02:25<00:15, 302.10 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43384/47780 [02:25<00:17, 245.48 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42751/47780 [02:25<00:17, 285.30 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43042/47780 [02:25<00:16, 287.99 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34783/47780 [02:25<00:33, 387.66 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44091/47780 [02:25<00:10, 358.45 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41112/47780 [02:25<00:21, 308.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43152/47780 [02:25<00:17, 269.52 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42782/47780 [02:25<00:17, 289.01 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42978/47780 [02:25<00:16, 297.19 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43071/47780 [02:25<00:16, 284.74 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43410/47780 [02:25<00:19, 220.37 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44128/47780 [02:25<00:10, 346.51 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41146/47780 [02:25<00:20, 317.62 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34825/47780 [02:25<00:34, 378.22 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43182/47780 [02:25<00:16, 271.44 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42813/47780 [02:25<00:16, 292.25 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43008/47780 [02:25<00:16, 291.53 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43101/47780 [02:25<00:16, 287.62 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34865/47780 [02:25<00:33, 382.42 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43443/47780 [02:25<00:17, 242.20 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41178/47780 [02:25<00:20, 315.26 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44164/47780 [02:25<00:10, 342.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43210/47780 [02:25<00:17, 268.29 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42843/47780 [02:25<00:18, 270.63 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43038/47780 [02:25<00:17, 275.41 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43130/47780 [02:25<00:16, 287.06 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43472/47780 [02:25<00:16, 253.77 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34914/47780 [02:25<00:31, 407.22 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44199/47780 [02:25<00:10, 341.09 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41211/47780 [02:25<00:21, 312.21 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43239/47780 [02:25<00:16, 271.50 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43163/47780 [02:25<00:15, 299.46 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43071/47780 [02:25<00:16, 287.27 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42873/47780 [02:25<00:17, 274.17 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43502/47780 [02:26<00:16, 263.39 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41245/47780 [02:25<00:20, 320.19 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43267/47780 [02:25<00:16, 272.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34956/47780 [02:25<00:32, 389.07 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44234/47780 [02:25<00:11, 308.97 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43194/47780 [02:26<00:15, 302.16 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43101/47780 [02:26<00:16, 282.55 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43534/47780 [02:26<00:15, 279.01 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42901/47780 [02:26<00:18, 258.62 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43295/47780 [02:26<00:16, 272.77 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35007/47780 [02:26<00:30, 417.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41278/47780 [02:26<00:21, 298.61 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44267/47780 [02:26<00:11, 303.22 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43225/47780 [02:26<00:15, 291.16 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43566/47780 [02:26<00:14, 284.36 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42929/47780 [02:26<00:18, 258.85 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35052/47780 [02:26<00:29, 426.61 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43130/47780 [02:26<00:17, 260.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43323/47780 [02:26<00:16, 267.87 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44300/47780 [02:26<00:11, 302.03 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41309/47780 [02:26<00:24, 268.77 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43255/47780 [02:26<00:15, 286.77 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42962/47780 [02:26<00:17, 278.34 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35096/47780 [02:26<00:29, 425.70 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43595/47780 [02:26<00:15, 273.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43158/47780 [02:26<00:17, 257.33 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43350/47780 [02:26<00:17, 246.66 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44339/47780 [02:26<00:10, 325.52 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41337/47780 [02:26<00:25, 257.26 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42993/47780 [02:26<00:16, 287.22 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35141/47780 [02:26<00:29, 432.60 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43623/47780 [02:26<00:15, 269.28 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43189/47780 [02:26<00:17, 268.67 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43284/47780 [02:26<00:17, 258.19 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43376/47780 [02:26<00:17, 247.50 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44373/47780 [02:26<00:10, 316.21 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41364/47780 [02:26<00:26, 243.47 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43025/47780 [02:26<00:16, 287.35 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43656/47780 [02:26<00:14, 283.17 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35185/47780 [02:26<00:29, 419.90 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43324/47780 [02:26<00:15, 293.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43224/47780 [02:26<00:16, 284.32 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43407/47780 [02:26<00:16, 262.03 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44406/47780 [02:26<00:11, 297.28 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43058/47780 [02:26<00:15, 295.64 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41396/47780 [02:26<00:24, 255.54 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43690/47780 [02:26<00:13, 299.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35234/47780 [02:26<00:28, 439.93 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43356/47780 [02:26<00:15, 279.14 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43253/47780 [02:26<00:17, 262.91 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43434/47780 [02:26<00:17, 252.37 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44437/47780 [02:26<00:11, 284.22 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35280/47780 [02:26<00:28, 440.91 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43089/47780 [02:26<00:16, 283.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41422/47780 [02:26<00:25, 248.17 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43721/47780 [02:26<00:14, 282.86 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43385/47780 [02:26<00:15, 275.64 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43460/47780 [02:26<00:17, 252.15 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43280/47780 [02:26<00:18, 241.38 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44477/47780 [02:26<00:10, 312.79 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35325/47780 [02:26<00:28, 432.89 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41454/47780 [02:26<00:23, 265.33 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43118/47780 [02:26<00:16, 279.05 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43753/47780 [02:26<00:14, 280.73 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43413/47780 [02:26<00:16, 257.24 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43487/47780 [02:26<00:18, 238.07 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44515/47780 [02:26<00:09, 329.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43305/47780 [02:26<00:20, 223.26 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41481/47780 [02:26<00:24, 258.03 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43147/47780 [02:26<00:16, 272.76 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35369/47780 [02:26<00:30, 402.92 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43788/47780 [02:26<00:13, 297.61 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43520/47780 [02:26<00:16, 258.37 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43443/47780 [02:26<00:17, 248.96 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44549/47780 [02:26<00:10, 315.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43328/47780 [02:27<00:20, 217.82 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43176/47780 [02:26<00:16, 276.13 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41508/47780 [02:27<00:24, 253.07 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43819/47780 [02:27<00:13, 296.67 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35411/47780 [02:26<00:31, 398.40 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43547/47780 [02:27<00:16, 258.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43470/47780 [02:27<00:17, 245.33 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44585/47780 [02:27<00:10, 314.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43204/47780 [02:27<00:16, 275.74 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43351/47780 [02:27<00:20, 213.06 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35452/47780 [02:27<00:31, 393.35 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41535/47780 [02:27<00:25, 244.16 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43849/47780 [02:27<00:14, 275.52 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43580/47780 [02:27<00:15, 278.13 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43495/47780 [02:27<00:17, 244.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44617/47780 [02:27<00:10, 312.73 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43232/47780 [02:27<00:17, 258.96 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43373/47780 [02:27<00:21, 201.66 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35492/47780 [02:27<00:32, 381.54 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41560/47780 [02:27<00:27, 230.31 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43878/47780 [02:27<00:14, 270.56 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43610/47780 [02:27<00:15, 260.64 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43530/47780 [02:27<00:15, 273.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44652/47780 [02:27<00:09, 323.10 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43396/47780 [02:27<00:21, 204.70 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35531/47780 [02:27<00:33, 370.78 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43912/47780 [02:27<00:13, 289.54 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41586/47780 [02:27<00:27, 228.81 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43259/47780 [02:27<00:19, 229.03 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43637/47780 [02:27<00:15, 262.74 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43566/47780 [02:27<00:14, 297.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44685/47780 [02:27<00:09, 325.00 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43419/47780 [02:27<00:21, 207.03 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35588/47780 [02:27<00:28, 423.18 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41611/47780 [02:27<00:26, 229.30 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43286/47780 [02:27<00:18, 238.22 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43942/47780 [02:27<00:14, 271.18 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43672/47780 [02:27<00:14, 284.41 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43601/47780 [02:27<00:14, 295.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44724/47780 [02:27<00:09, 336.06 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43444/47780 [02:27<00:20, 216.39 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35631/47780 [02:27<00:29, 408.00 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41637/47780 [02:27<00:26, 235.45 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43311/47780 [02:27<00:18, 240.23 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43971/47780 [02:27<00:14, 270.69 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43701/47780 [02:27<00:14, 280.31 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43631/47780 [02:27<00:13, 296.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44758/47780 [02:27<00:09, 334.93 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43479/47780 [02:27<00:17, 247.15 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35685/47780 [02:27<00:27, 443.42 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41666/47780 [02:27<00:24, 250.46 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43341/47780 [02:27<00:17, 253.95 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44000/47780 [02:27<00:13, 275.95 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43730/47780 [02:27<00:14, 282.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43665/47780 [02:27<00:13, 307.10 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44794/47780 [02:27<00:09, 325.71 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43506/47780 [02:27<00:17, 246.09 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35730/47780 [02:27<00:27, 435.31 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44036/47780 [02:27<00:12, 296.78 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41694/47780 [02:27<00:24, 247.80 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43368/47780 [02:27<00:17, 253.21 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43768/47780 [02:27<00:12, 308.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43696/47780 [02:27<00:13, 296.21 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44831/47780 [02:27<00:08, 330.60 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35796/47780 [02:27<00:24, 499.16 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43533/47780 [02:27<00:17, 241.32 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43397/47780 [02:27<00:16, 260.17 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43802/47780 [02:27<00:12, 312.30 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44066/47780 [02:27<00:12, 287.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41719/47780 [02:27<00:25, 237.79 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43727/47780 [02:27<00:14, 281.08 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44865/47780 [02:27<00:09, 307.66 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35847/47780 [02:27<00:24, 485.23 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43564/47780 [02:28<00:16, 258.30 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43434/47780 [02:27<00:14, 291.38 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43837/47780 [02:28<00:12, 319.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44095/47780 [02:28<00:13, 278.64 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41743/47780 [02:28<00:27, 218.98 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43756/47780 [02:28<00:14, 279.85 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44899/47780 [02:28<00:09, 307.78 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35897/47780 [02:28<00:24, 478.74 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43471/47780 [02:28<00:13, 313.82 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43594/47780 [02:28<00:16, 250.11 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43870/47780 [02:28<00:12, 311.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44124/47780 [02:28<00:13, 278.40 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41766/47780 [02:28<00:27, 217.15 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43789/47780 [02:28<00:13, 291.20 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44930/47780 [02:28<00:09, 307.89 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35948/47780 [02:28<00:24, 481.43 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43503/47780 [02:28<00:13, 308.38 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43631/47780 [02:28<00:14, 279.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43914/47780 [02:28<00:11, 340.60 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44152/47780 [02:28<00:13, 261.14 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43822/47780 [02:28<00:13, 301.97 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41792/47780 [02:28<00:26, 224.06 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44961/47780 [02:28<00:09, 290.45 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35997/47780 [02:28<00:24, 471.43 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43535/47780 [02:28<00:13, 308.14 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43664/47780 [02:28<00:14, 287.04 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43950/47780 [02:28<00:11, 342.26 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44179/47780 [02:28<00:14, 255.40 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41817/47780 [02:28<00:26, 226.29 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43853/47780 [02:28<00:13, 293.92 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44993/47780 [02:28<00:09, 294.10 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36046/47780 [02:28<00:25, 468.52 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43698/47780 [02:28<00:13, 298.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43567/47780 [02:28<00:14, 286.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43985/47780 [02:28<00:11, 333.17 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44205/47780 [02:28<00:14, 253.88 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41847/47780 [02:28<00:24, 246.68 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43900/47780 [02:28<00:11, 336.83 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45031/47780 [02:28<00:08, 311.22 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36093/47780 [02:28<00:24, 468.81 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43729/47780 [02:28<00:13, 295.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44026/47780 [02:28<00:10, 350.83 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44240/47780 [02:28<00:12, 277.65 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41874/47780 [02:28<00:23, 247.66 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43935/47780 [02:28<00:11, 332.92 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43600/47780 [02:28<00:15, 262.78 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45087/47780 [02:28<00:07, 380.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36140/47780 [02:28<00:26, 434.12 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44269/47780 [02:28<00:12, 271.86 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43761/47780 [02:28<00:14, 274.08 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41904/47780 [02:28<00:22, 256.81 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44062/47780 [02:28<00:11, 320.59 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43971/47780 [02:28<00:11, 334.22 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43645/47780 [02:28<00:13, 310.87 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45130/47780 [02:28<00:06, 386.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36186/47780 [02:28<00:26, 441.22 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41940/47780 [02:28<00:20, 282.81 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44096/47780 [02:28<00:11, 325.36 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44309/47780 [02:28<00:11, 298.14 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43789/47780 [02:28<00:15, 264.65 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43679/47780 [02:28<00:13, 311.75 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44005/47780 [02:28<00:11, 315.90 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36231/47780 [02:28<00:26, 433.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45178/47780 [02:28<00:06, 378.44 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44132/47780 [02:28<00:11, 328.03 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43714/47780 [02:28<00:12, 319.06 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44340/47780 [02:28<00:11, 288.77 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41971/47780 [02:28<00:21, 274.96 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43816/47780 [02:28<00:16, 247.36 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44037/47780 [02:28<00:12, 304.43 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36286/47780 [02:28<00:24, 461.47 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45217/47780 [02:28<00:07, 347.02 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44166/47780 [02:28<00:11, 327.40 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41999/47780 [02:29<00:21, 263.29 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44369/47780 [02:29<00:12, 273.16 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44072/47780 [02:29<00:12, 308.05 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43747/47780 [02:29<00:13, 293.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43842/47780 [02:29<00:16, 234.82 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36333/47780 [02:29<00:26, 425.24 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45253/47780 [02:29<00:07, 343.68 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42040/47780 [02:29<00:19, 298.58 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44199/47780 [02:29<00:11, 298.81 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44400/47780 [02:29<00:12, 277.60 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44109/47780 [02:29<00:11, 323.70 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43878/47780 [02:29<00:14, 267.31 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43778/47780 [02:29<00:14, 271.49 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36394/47780 [02:29<00:24, 464.97 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45299/47780 [02:29<00:06, 370.83 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44236/47780 [02:29<00:11, 314.99 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44428/47780 [02:29<00:12, 275.22 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42072/47780 [02:29<00:19, 294.60 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43907/47780 [02:29<00:14, 271.90 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44142/47780 [02:29<00:11, 304.66 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43810/47780 [02:29<00:14, 272.44 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36444/47780 [02:29<00:24, 469.91 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45338/47780 [02:29<00:07, 339.01 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44275/47780 [02:29<00:10, 330.66 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42102/47780 [02:29<00:19, 292.87 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44456/47780 [02:29<00:12, 267.09 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43935/47780 [02:29<00:14, 259.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44173/47780 [02:29<00:12, 296.67 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43838/47780 [02:29<00:15, 260.81 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36492/47780 [02:29<00:25, 446.39 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45393/47780 [02:29<00:06, 393.95 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44484/47780 [02:29<00:12, 268.91 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42132/47780 [02:29<00:19, 288.37 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44309/47780 [02:29<00:10, 322.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43962/47780 [02:29<00:15, 254.34 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44203/47780 [02:29<00:12, 280.31 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43865/47780 [02:29<00:15, 255.08 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36538/47780 [02:29<00:25, 436.86 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44524/47780 [02:29<00:10, 305.24 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42168/47780 [02:29<00:18, 305.17 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44342/47780 [02:29<00:10, 321.10 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45435/47780 [02:29<00:06, 376.45 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43988/47780 [02:29<00:15, 240.09 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44232/47780 [02:29<00:13, 272.85 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36583/47780 [02:29<00:26, 417.46 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43891/47780 [02:29<00:16, 238.42 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44380/47780 [02:29<00:10, 337.57 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42201/47780 [02:29<00:18, 308.70 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45476/47780 [02:29<00:06, 377.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44556/47780 [02:29<00:11, 283.11 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44263/47780 [02:29<00:12, 282.68 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44019/47780 [02:29<00:15, 250.67 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43923/47780 [02:29<00:14, 257.35 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42234/47780 [02:29<00:17, 311.28 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45519/47780 [02:29<00:05, 391.73 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44415/47780 [02:29<00:10, 324.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36626/47780 [02:29<00:29, 379.73 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44585/47780 [02:29<00:11, 273.32 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44298/47780 [02:29<00:11, 301.37 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44046/47780 [02:29<00:14, 253.32 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43951/47780 [02:29<00:14, 261.68 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42269/47780 [02:29<00:17, 308.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45560/47780 [02:29<00:05, 375.77 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36691/47780 [02:29<00:25, 436.25 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44340/47780 [02:29<00:10, 328.16 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44078/47780 [02:29<00:13, 271.78 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44449/47780 [02:29<00:11, 288.55 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44613/47780 [02:29<00:12, 257.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43978/47780 [02:29<00:14, 262.88 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45601/47780 [02:30<00:05, 376.54 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36754/47780 [02:29<00:22, 482.45 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42302/47780 [02:30<00:18, 291.07 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44107/47780 [02:30<00:13, 273.78 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44479/47780 [02:30<00:11, 288.42 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44645/47780 [02:30<00:11, 272.01 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44374/47780 [02:30<00:10, 320.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44005/47780 [02:30<00:14, 255.99 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36806/47780 [02:30<00:22, 489.57 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42348/47780 [02:30<00:16, 333.65 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45640/47780 [02:30<00:05, 360.03 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44139/47780 [02:30<00:12, 286.98 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44673/47780 [02:30<00:11, 270.88 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44516/47780 [02:30<00:10, 303.84 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44411/47780 [02:30<00:10, 323.67 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44035/47780 [02:30<00:14, 259.91 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36857/47780 [02:30<00:22, 486.87 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42384/47780 [02:30<00:16, 337.23 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45677/47780 [02:30<00:05, 360.67 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44168/47780 [02:30<00:12, 282.82 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44706/47780 [02:30<00:10, 287.25 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44553/47780 [02:30<00:10, 321.78 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44450/47780 [02:30<00:09, 339.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44064/47780 [02:30<00:13, 268.26 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42426/47780 [02:30<00:14, 360.48 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45718/47780 [02:30<00:05, 373.15 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44197/47780 [02:30<00:13, 273.90 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44738/47780 [02:30<00:10, 281.28 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44586/47780 [02:30<00:10, 310.27 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36907/47780 [02:30<00:26, 415.65 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44485/47780 [02:30<00:10, 303.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44091/47780 [02:30<00:14, 260.02 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42463/47780 [02:30<00:14, 359.28 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45759/47780 [02:30<00:05, 359.23 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44226/47780 [02:30<00:12, 275.54 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44618/47780 [02:30<00:10, 301.87 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44771/47780 [02:30<00:10, 279.02 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36971/47780 [02:30<00:22, 472.62 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44517/47780 [02:30<00:11, 295.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44118/47780 [02:30<00:14, 254.22 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42500/47780 [02:30<00:15, 349.89 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44255/47780 [02:30<00:12, 277.81 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45796/47780 [02:30<00:05, 354.36 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37049/47780 [02:30<00:19, 554.41 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44800/47780 [02:30<00:11, 269.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44652/47780 [02:30<00:10, 285.15 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42538/47780 [02:30<00:14, 352.50 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44144/47780 [02:30<00:15, 232.09 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44548/47780 [02:30<00:11, 270.48 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45832/47780 [02:30<00:05, 348.22 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44283/47780 [02:30<00:13, 267.72 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44828/47780 [02:30<00:11, 267.29 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44694/47780 [02:30<00:09, 314.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37109/47780 [02:30<00:20, 520.23 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44169/47780 [02:30<00:15, 235.35 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44579/47780 [02:30<00:11, 272.25 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45871/47780 [02:30<00:05, 359.87 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42574/47780 [02:30<00:16, 323.25 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44310/47780 [02:30<00:13, 253.99 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44858/47780 [02:30<00:10, 267.42 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37168/47780 [02:30<00:19, 534.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44726/47780 [02:30<00:09, 312.14 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44607/47780 [02:30<00:11, 271.46 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44197/47780 [02:30<00:15, 226.85 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42607/47780 [02:30<00:16, 318.09 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44337/47780 [02:30<00:14, 242.38 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44759/47780 [02:30<00:09, 313.43 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45909/47780 [02:30<00:05, 315.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37224/47780 [02:30<00:20, 523.62 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44885/47780 [02:31<00:11, 247.93 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44646/47780 [02:30<00:10, 300.26 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44221/47780 [02:30<00:15, 223.27 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42644/47780 [02:30<00:15, 325.48 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44377/47780 [02:31<00:12, 278.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37284/47780 [02:30<00:19, 541.14 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44791/47780 [02:31<00:09, 301.67 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44678/47780 [02:31<00:10, 299.09 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45942/47780 [02:31<00:06, 278.04 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44911/47780 [02:31<00:12, 221.96 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44246/47780 [02:31<00:15, 230.41 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42677/47780 [02:31<00:16, 309.33 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44406/47780 [02:31<00:11, 281.51 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44830/47780 [02:31<00:09, 326.15 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37343/47780 [02:31<00:19, 533.20 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44709/47780 [02:31<00:10, 295.55 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44934/47780 [02:31<00:13, 216.22 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44271/47780 [02:31<00:15, 221.18 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45973/47780 [02:31<00:06, 260.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42709/47780 [02:31<00:17, 296.03 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44868/47780 [02:31<00:08, 341.38 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37398/47780 [02:31<00:19, 533.98 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44435/47780 [02:31<00:12, 260.87 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44739/47780 [02:31<00:10, 283.75 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44957/47780 [02:31<00:13, 214.56 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44295/47780 [02:31<00:15, 224.05 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46002/47780 [02:31<00:06, 267.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42739/47780 [02:31<00:16, 296.53 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44909/47780 [02:31<00:08, 349.57 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37452/47780 [02:31<00:20, 506.63 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44462/47780 [02:31<00:13, 237.77 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44979/47780 [02:31<00:13, 213.85 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46041/47780 [02:31<00:05, 298.25 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44319/47780 [02:31<00:15, 220.90 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42772/47780 [02:31<00:16, 300.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44769/47780 [02:31<00:11, 259.76 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44953/47780 [02:31<00:07, 370.98 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37504/47780 [02:31<00:20, 499.46 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44490/47780 [02:31<00:13, 241.82 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45006/47780 [02:31<00:12, 223.12 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44343/47780 [02:31<00:15, 223.69 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42803/47780 [02:31<00:16, 299.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44796/47780 [02:31<00:11, 257.03 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46075/47780 [02:31<00:06, 277.72 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44992/47780 [02:31<00:07, 353.24 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37555/47780 [02:31<00:21, 481.55 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44515/47780 [02:31<00:13, 240.75 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45031/47780 [02:31<00:12, 228.06 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44369/47780 [02:31<00:14, 228.31 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42836/47780 [02:31<00:16, 301.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44824/47780 [02:31<00:11, 258.91 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45031/47780 [02:31<00:07, 358.29 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46104/47780 [02:31<00:06, 257.20 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37604/47780 [02:31<00:21, 462.65 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44540/47780 [02:31<00:13, 234.10 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45056/47780 [02:31<00:11, 229.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44393/47780 [02:31<00:14, 226.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42874/47780 [02:31<00:15, 314.34 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44855/47780 [02:31<00:10, 266.68 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37671/47780 [02:31<00:19, 519.26 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45069/47780 [02:31<00:08, 323.94 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44567/47780 [02:31<00:13, 241.07 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46131/47780 [02:31<00:06, 236.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45086/47780 [02:31<00:10, 246.25 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44885/47780 [02:31<00:10, 275.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44419/47780 [02:31<00:14, 227.24 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42908/47780 [02:31<00:15, 306.43 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37730/47780 [02:31<00:19, 527.74 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45103/47780 [02:31<00:08, 315.36 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46160/47780 [02:31<00:06, 247.34 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45114/47780 [02:32<00:10, 250.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44592/47780 [02:32<00:14, 227.53 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44914/47780 [02:31<00:10, 267.18 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44449/47780 [02:31<00:14, 235.77 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42939/47780 [02:31<00:16, 297.43 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37784/47780 [02:31<00:19, 518.84 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45152/47780 [02:32<00:09, 283.76 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46186/47780 [02:32<00:06, 242.81 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44616/47780 [02:32<00:13, 226.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45137/47780 [02:32<00:08, 296.68 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44473/47780 [02:32<00:14, 231.35 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44941/47780 [02:32<00:11, 256.44 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42970/47780 [02:32<00:16, 287.95 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37837/47780 [02:32<00:20, 494.95 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45185/47780 [02:32<00:08, 293.68 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46211/47780 [02:32<00:06, 239.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44639/47780 [02:32<00:14, 219.79 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45168/47780 [02:32<00:09, 287.32 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44500/47780 [02:32<00:13, 234.69 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42999/47780 [02:32<00:16, 282.24 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37892/47780 [02:32<00:19, 507.63 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44967/47780 [02:32<00:12, 225.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46243/47780 [02:32<00:05, 259.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45215/47780 [02:32<00:09, 279.32 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44662/47780 [02:32<00:14, 213.29 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45198/47780 [02:32<00:09, 282.33 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44531/47780 [02:32<00:12, 255.49 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43028/47780 [02:32<00:17, 278.52 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44994/47780 [02:32<00:11, 236.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37951/47780 [02:32<00:18, 525.31 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45249/47780 [02:32<00:08, 293.24 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46270/47780 [02:32<00:06, 245.47 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44688/47780 [02:32<00:13, 221.05 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45244/47780 [02:32<00:07, 326.55 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44557/47780 [02:32<00:12, 250.12 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43056/47780 [02:32<00:17, 275.93 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45019/47780 [02:32<00:11, 238.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38004/47780 [02:32<00:19, 498.69 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46298/47780 [02:32<00:06, 246.75 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44717/47780 [02:32<00:13, 232.38 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45279/47780 [02:32<00:09, 275.89 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44583/47780 [02:32<00:12, 248.40 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43089/47780 [02:32<00:16, 291.18 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45280/47780 [02:32<00:07, 313.55 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45047/47780 [02:32<00:11, 246.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38063/47780 [02:32<00:18, 521.96 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46326/47780 [02:32<00:05, 250.39 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44741/47780 [02:32<00:13, 229.50 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45313/47780 [02:32<00:07, 316.18 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43125/47780 [02:32<00:15, 302.67 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45307/47780 [02:32<00:09, 249.88 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44608/47780 [02:32<00:14, 225.81 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45073/47780 [02:32<00:11, 242.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38116/47780 [02:32<00:19, 497.96 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46353/47780 [02:32<00:05, 254.85 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44768/47780 [02:32<00:12, 240.77 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43170/47780 [02:32<00:13, 342.42 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45346/47780 [02:32<00:07, 313.07 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45346/47780 [02:32<00:08, 280.57 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45098/47780 [02:32<00:11, 241.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38175/47780 [02:32<00:18, 519.50 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46387/47780 [02:32<00:05, 276.77 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44631/47780 [02:32<00:16, 195.20 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44796/47780 [02:32<00:11, 249.19 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45378/47780 [02:32<00:08, 282.10 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45379/47780 [02:32<00:08, 292.93 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43207/47780 [02:32<00:14, 321.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45123/47780 [02:32<00:11, 230.73 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38228/47780 [02:32<00:19, 494.63 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46415/47780 [02:32<00:04, 274.14 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44826/47780 [02:32<00:11, 261.13 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44652/47780 [02:32<00:16, 184.20 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43243/47780 [02:32<00:13, 327.63 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45421/47780 [02:32<00:07, 322.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45411/47780 [02:33<00:08, 285.51 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45147/47780 [02:33<00:11, 226.33 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38278/47780 [02:32<00:19, 478.47 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44869/47780 [02:33<00:09, 301.29 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44673/47780 [02:33<00:16, 188.84 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46443/47780 [02:33<00:05, 252.63 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43277/47780 [02:33<00:14, 319.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45454/47780 [02:33<00:07, 304.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45440/47780 [02:33<00:08, 267.18 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45171/47780 [02:33<00:11, 219.93 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38331/47780 [02:33<00:19, 488.94 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44900/47780 [02:33<00:09, 291.88 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46469/47780 [02:33<00:05, 253.65 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44693/47780 [02:33<00:17, 178.75 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43310/47780 [02:33<00:13, 319.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45485/47780 [02:33<00:07, 302.57 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45468/47780 [02:33<00:09, 256.19 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45195/47780 [02:33<00:11, 218.38 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38386/47780 [02:33<00:19, 489.81 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46496/47780 [02:33<00:05, 256.71 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44930/47780 [02:33<00:10, 281.09 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44719/47780 [02:33<00:15, 198.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43348/47780 [02:33<00:13, 329.30 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45516/47780 [02:33<00:07, 283.57 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45219/47780 [02:33<00:11, 221.92 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45494/47780 [02:33<00:09, 252.14 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38444/47780 [02:33<00:18, 510.31 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46522/47780 [02:33<00:05, 246.76 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44962/47780 [02:33<00:10, 270.90 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44740/47780 [02:33<00:15, 195.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43382/47780 [02:33<00:13, 331.74 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45547/47780 [02:33<00:07, 289.89 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45521/47780 [02:33<00:09, 241.43 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38496/47780 [02:33<00:19, 469.56 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45242/47780 [02:33<00:12, 199.18 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46547/47780 [02:33<00:05, 233.81 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44770/47780 [02:33<00:13, 222.38 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43416/47780 [02:33<00:14, 294.07 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44990/47780 [02:33<00:11, 234.33 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45577/47780 [02:33<00:08, 271.26 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38544/47780 [02:33<00:19, 471.42 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45268/47780 [02:33<00:11, 213.34 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45546/47780 [02:33<00:09, 227.18 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46573/47780 [02:33<00:05, 240.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44797/47780 [02:33<00:12, 234.14 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43453/47780 [02:33<00:13, 310.93 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45605/47780 [02:33<00:08, 255.73 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38592/47780 [02:33<00:20, 449.72 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45290/47780 [02:33<00:11, 208.35 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45015/47780 [02:33<00:13, 207.39 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46598/47780 [02:33<00:05, 225.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45570/47780 [02:33<00:10, 209.46 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44821/47780 [02:33<00:13, 213.75 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43491/47780 [02:33<00:13, 319.30 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38638/47780 [02:33<00:20, 444.53 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45317/47780 [02:33<00:11, 219.45 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45631/47780 [02:33<00:09, 232.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46623/47780 [02:33<00:05, 227.33 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45592/47780 [02:33<00:10, 204.68 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44844/47780 [02:33<00:13, 212.88 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43532/47780 [02:33<00:12, 344.08 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45037/47780 [02:33<00:14, 186.29 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45340/47780 [02:33<00:11, 220.86 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38684/47780 [02:33<00:20, 435.33 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45661/47780 [02:33<00:08, 244.64 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46650/47780 [02:33<00:05, 220.34 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43570/47780 [02:33<00:12, 350.50 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45613/47780 [02:34<00:11, 191.75 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44867/47780 [02:33<00:14, 200.19 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45057/47780 [02:34<00:15, 174.10 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38729/47780 [02:33<00:20, 436.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45363/47780 [02:34<00:11, 211.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45695/47780 [02:34<00:07, 265.74 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45636/47780 [02:34<00:10, 200.71 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43609/47780 [02:34<00:11, 357.65 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46681/47780 [02:34<00:04, 229.81 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44888/47780 [02:34<00:15, 188.69 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45075/47780 [02:34<00:15, 170.28 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38773/47780 [02:34<00:21, 417.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45385/47780 [02:34<00:11, 207.41 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45657/47780 [02:34<00:10, 203.02 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45723/47780 [02:34<00:08, 247.93 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43654/47780 [02:34<00:10, 379.65 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46707/47780 [02:34<00:04, 236.87 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44912/47780 [02:34<00:14, 198.81 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45094/47780 [02:34<00:15, 171.74 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38835/47780 [02:34<00:19, 470.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45407/47780 [02:34<00:11, 204.04 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45756/47780 [02:34<00:07, 268.13 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45683/47780 [02:34<00:09, 216.68 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43693/47780 [02:34<00:11, 361.54 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44933/47780 [02:34<00:14, 194.27 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45113/47780 [02:34<00:15, 171.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46731/47780 [02:34<00:05, 200.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38883/47780 [02:34<00:20, 441.16 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45428/47780 [02:34<00:12, 194.63 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45705/47780 [02:34<00:10, 202.88 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45784/47780 [02:34<00:07, 250.39 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43730/47780 [02:34<00:11, 351.91 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44956/47780 [02:34<00:14, 200.79 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45132/47780 [02:34<00:15, 173.17 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46756/47780 [02:34<00:04, 208.34 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38936/47780 [02:34<00:19, 464.30 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45453/47780 [02:34<00:11, 205.24 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45732/47780 [02:34<00:09, 220.49 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43766/47780 [02:34<00:11, 346.27 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44984/47780 [02:34<00:12, 217.51 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45810/47780 [02:34<00:08, 228.67 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45159/47780 [02:34<00:13, 197.14 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46778/47780 [02:34<00:04, 203.72 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38984/47780 [02:34<00:19, 442.89 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45474/47780 [02:34<00:11, 203.09 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45761/47780 [02:34<00:08, 233.13 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43808/47780 [02:34<00:10, 363.51 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45184/47780 [02:34<00:12, 210.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45006/47780 [02:34<00:13, 206.46 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45495/47780 [02:34<00:11, 204.39 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39029/47780 [02:34<00:19, 438.40 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46799/47780 [02:34<00:05, 192.77 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45834/47780 [02:34<00:09, 198.54 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43845/47780 [02:34<00:11, 349.19 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45786/47780 [02:34<00:09, 218.21 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45207/47780 [02:34<00:12, 211.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45028/47780 [02:34<00:13, 203.32 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45516/47780 [02:34<00:11, 192.44 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39074/47780 [02:34<00:21, 406.64 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46823/47780 [02:34<00:04, 192.19 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45855/47780 [02:34<00:09, 193.55 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45809/47780 [02:34<00:08, 221.28 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45237/47780 [02:34<00:10, 233.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43881/47780 [02:34<00:12, 319.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45050/47780 [02:34<00:13, 205.29 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39121/47780 [02:34<00:20, 417.07 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46846/47780 [02:34<00:04, 197.78 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45536/47780 [02:34<00:12, 180.24 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45875/47780 [02:34<00:10, 185.27 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45832/47780 [02:35<00:09, 216.39 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45266/47780 [02:35<00:10, 246.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43921/47780 [02:34<00:11, 338.16 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45071/47780 [02:34<00:14, 188.80 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39164/47780 [02:35<00:21, 402.35 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46869/47780 [02:35<00:04, 202.27 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45562/47780 [02:35<00:11, 196.27 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45899/47780 [02:35<00:09, 197.85 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45855/47780 [02:35<00:08, 219.62 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43956/47780 [02:35<00:11, 341.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45291/47780 [02:35<00:10, 239.43 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45097/47780 [02:35<00:13, 204.12 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46896/47780 [02:35<00:04, 217.16 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39208/47780 [02:35<00:21, 402.06 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45584/47780 [02:35<00:10, 202.55 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45920/47780 [02:35<00:09, 198.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43997/47780 [02:35<00:10, 356.76 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45879/47780 [02:35<00:09, 196.44 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45316/47780 [02:35<00:11, 219.98 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45118/47780 [02:35<00:13, 201.37 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39257/47780 [02:35<00:20, 425.23 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45607/47780 [02:35<00:10, 207.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46919/47780 [02:35<00:04, 197.34 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44034/47780 [02:35<00:11, 340.33 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45941/47780 [02:35<00:10, 173.52 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45339/47780 [02:35<00:11, 213.83 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45139/47780 [02:35<00:13, 197.83 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45900/47780 [02:35<00:10, 186.75 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39301/47780 [02:35<00:19, 424.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45628/47780 [02:35<00:10, 203.85 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46941/47780 [02:35<00:04, 195.57 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44069/47780 [02:35<00:11, 318.34 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45960/47780 [02:35<00:10, 168.06 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45361/47780 [02:35<00:11, 208.80 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45162/47780 [02:35<00:12, 202.16 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45920/47780 [02:35<00:10, 183.62 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39360/47780 [02:35<00:18, 466.28 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45649/47780 [02:35<00:10, 196.46 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46961/47780 [02:35<00:04, 188.50 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44106/47780 [02:35<00:11, 324.86 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45192/47780 [02:35<00:11, 227.30 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45978/47780 [02:35<00:10, 167.11 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45942/47780 [02:35<00:09, 192.03 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45383/47780 [02:35<00:11, 205.55 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39421/47780 [02:35<00:16, 501.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45671/47780 [02:35<00:10, 200.67 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44139/47780 [02:35<00:11, 321.68 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46982/47780 [02:35<00:04, 184.52 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45963/47780 [02:35<00:09, 191.94 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45216/47780 [02:35<00:11, 221.11 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45421/47780 [02:35<00:09, 245.66 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39472/47780 [02:35<00:16, 489.75 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45694/47780 [02:35<00:10, 208.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45996/47780 [02:35<00:11, 151.42 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44173/47780 [02:35<00:11, 321.86 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47005/47780 [02:35<00:04, 187.59 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45245/47780 [02:35<00:10, 239.32 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45452/47780 [02:35<00:08, 262.14 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39522/47780 [02:35<00:17, 485.04 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45983/47780 [02:35<00:09, 183.34 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45727/47780 [02:35<00:08, 239.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46014/47780 [02:35<00:11, 153.95 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44206/47780 [02:35<00:11, 308.50 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45479/47780 [02:35<00:08, 263.92 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47024/47780 [02:35<00:04, 184.72 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45273/47780 [02:35<00:10, 237.95 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46008/47780 [02:35<00:09, 194.58 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39571/47780 [02:35<00:17, 459.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45753/47780 [02:35<00:08, 235.05 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46043/47780 [02:35<00:09, 181.41 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45507/47780 [02:36<00:08, 264.74 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47048/47780 [02:35<00:03, 193.74 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44240/47780 [02:35<00:11, 305.20 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45297/47780 [02:35<00:10, 237.95 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46028/47780 [02:36<00:09, 194.37 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39618/47780 [02:35<00:18, 448.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45777/47780 [02:36<00:08, 231.80 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46069/47780 [02:36<00:08, 193.39 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45534/47780 [02:36<00:08, 259.13 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45322/47780 [02:36<00:10, 240.08 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47068/47780 [02:36<00:03, 190.66 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46050/47780 [02:36<00:08, 199.98 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44283/47780 [02:36<00:10, 320.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39664/47780 [02:36<00:18, 437.52 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45801/47780 [02:36<00:08, 220.61 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46089/47780 [02:36<00:09, 186.22 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45568/47780 [02:36<00:07, 277.90 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45354/47780 [02:36<00:09, 257.47 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47089/47780 [02:36<00:03, 188.33 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44324/47780 [02:36<00:10, 342.05 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46073/47780 [02:36<00:08, 205.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39714/47780 [02:36<00:17, 453.42 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45831/47780 [02:36<00:08, 232.35 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46111/47780 [02:36<00:08, 193.52 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45380/47780 [02:36<00:09, 249.92 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44360/47780 [02:36<00:09, 345.94 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46100/47780 [02:36<00:07, 220.88 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45597/47780 [02:36<00:08, 257.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39760/47780 [02:36<00:17, 450.30 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47109/47780 [02:36<00:03, 174.33 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45863/47780 [02:36<00:07, 256.01 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46134/47780 [02:36<00:08, 198.98 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45406/47780 [02:36<00:09, 243.89 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46126/47780 [02:36<00:07, 227.25 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44396/47780 [02:36<00:10, 331.69 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39810/47780 [02:36<00:17, 464.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45625/47780 [02:36<00:08, 255.98 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45898/47780 [02:36<00:06, 282.35 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47130/47780 [02:36<00:03, 176.21 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46159/47780 [02:36<00:07, 209.51 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45446/47780 [02:36<00:08, 285.67 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46150/47780 [02:36<00:07, 225.62 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44434/47780 [02:36<00:09, 341.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39858/47780 [02:36<00:17, 457.32 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45651/47780 [02:36<00:08, 246.38 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45931/47780 [02:36<00:06, 293.15 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47149/47780 [02:36<00:03, 177.96 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46191/47780 [02:36<00:06, 240.28 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46173/47780 [02:36<00:07, 219.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39915/47780 [02:36<00:16, 486.85 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45475/47780 [02:36<00:08, 265.21 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44469/47780 [02:36<00:10, 322.66 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45680/47780 [02:36<00:08, 254.12 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45968/47780 [02:36<00:05, 314.26 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47167/47780 [02:36<00:03, 169.35 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46216/47780 [02:36<00:06, 233.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39966/47780 [02:36<00:15, 492.38 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46196/47780 [02:36<00:07, 211.38 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45706/47780 [02:36<00:08, 250.72 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45506/47780 [02:36<00:08, 266.36 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46000/47780 [02:36<00:05, 300.56 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47186/47780 [02:36<00:03, 172.06 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44502/47780 [02:36<00:11, 296.73 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46240/47780 [02:36<00:07, 207.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40016/47780 [02:36<00:15, 491.20 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46218/47780 [02:36<00:07, 207.72 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45534/47780 [02:36<00:08, 266.72 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45732/47780 [02:36<00:08, 238.48 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44533/47780 [02:36<00:10, 297.83 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46031/47780 [02:36<00:06, 271.59 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40075/47780 [02:36<00:15, 510.10 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47205/47780 [02:36<00:03, 149.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46262/47780 [02:36<00:07, 202.14 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45561/47780 [02:36<00:08, 266.22 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46239/47780 [02:37<00:07, 203.14 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44569/47780 [02:37<00:10, 303.75 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45757/47780 [02:37<00:08, 227.55 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46059/47780 [02:37<00:06, 249.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47224/47780 [02:37<00:03, 158.47 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46286/47780 [02:37<00:07, 208.61 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40127/47780 [02:37<00:15, 485.73 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45592/47780 [02:37<00:07, 276.68 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46276/47780 [02:37<00:06, 240.13 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44615/47780 [02:37<00:09, 334.45 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45780/47780 [02:37<00:09, 212.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46085/47780 [02:37<00:06, 250.22 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40179/47780 [02:37<00:15, 494.11 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46309/47780 [02:37<00:07, 202.85 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47241/47780 [02:37<00:03, 147.85 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45620/47780 [02:37<00:08, 264.14 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46312/47780 [02:37<00:05, 260.37 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44656/47780 [02:37<00:09, 342.48 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45802/47780 [02:37<00:09, 205.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46114/47780 [02:37<00:06, 259.38 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40233/47780 [02:37<00:15, 501.49 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46335/47780 [02:37<00:06, 214.83 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45653/47780 [02:37<00:07, 280.82 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46340/47780 [02:37<00:05, 265.12 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44695/47780 [02:37<00:08, 352.43 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47257/47780 [02:37<00:03, 132.11 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46144/47780 [02:37<00:06, 269.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45823/47780 [02:37<00:09, 201.71 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40287/47780 [02:37<00:14, 507.49 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46359/47780 [02:37<00:06, 217.96 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45683/47780 [02:37<00:07, 267.69 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46368/47780 [02:37<00:05, 263.25 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44735/47780 [02:37<00:08, 359.10 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47274/47780 [02:37<00:03, 138.54 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46173/47780 [02:37<00:05, 268.63 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45844/47780 [02:37<00:09, 193.62 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40338/47780 [02:37<00:15, 465.64 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46383/47780 [02:37<00:06, 204.94 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45714/47780 [02:37<00:07, 269.78 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44783/47780 [02:37<00:07, 391.97 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46396/47780 [02:37<00:05, 241.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47290/47780 [02:37<00:03, 138.75 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45866/47780 [02:37<00:09, 200.07 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46201/47780 [02:37<00:06, 259.32 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40393/47780 [02:37<00:15, 488.75 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46406/47780 [02:37<00:06, 207.04 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45742/47780 [02:37<00:07, 262.27 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44823/47780 [02:37<00:08, 354.54 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45887/47780 [02:37<00:09, 196.09 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46231/47780 [02:37<00:05, 263.87 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47306/47780 [02:37<00:03, 135.60 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46422/47780 [02:37<00:06, 220.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40448/47780 [02:37<00:14, 501.76 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45770/47780 [02:37<00:08, 245.34 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46427/47780 [02:37<00:07, 186.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47320/47780 [02:37<00:03, 136.20 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46447/47780 [02:37<00:05, 227.67 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46263/47780 [02:37<00:05, 268.03 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45907/47780 [02:37<00:10, 186.88 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44860/47780 [02:37<00:08, 327.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40515/47780 [02:37<00:13, 542.73 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45795/47780 [02:37<00:08, 241.98 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46447/47780 [02:37<00:07, 185.15 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46471/47780 [02:37<00:05, 228.25 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47337/47780 [02:37<00:03, 137.56 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40573/47780 [02:37<00:13, 546.76 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46295/47780 [02:37<00:05, 272.92 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44897/47780 [02:37<00:08, 327.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45934/47780 [02:38<00:09, 197.27 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45821/47780 [02:37<00:08, 243.77 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46467/47780 [02:38<00:07, 182.86 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46497/47780 [02:38<00:05, 227.46 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40633/47780 [02:37<00:12, 558.42 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47351/47780 [02:38<00:03, 132.92 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46325/47780 [02:38<00:05, 271.87 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44931/47780 [02:38<00:08, 323.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45960/47780 [02:38<00:08, 209.02 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46486/47780 [02:38<00:07, 181.58 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46520/47780 [02:38<00:05, 227.11 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40692/47780 [02:38<00:12, 555.76 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46353/47780 [02:38<00:05, 270.85 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44979/47780 [02:38<00:07, 360.86 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45987/47780 [02:38<00:07, 224.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47367/47780 [02:38<00:03, 129.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45851/47780 [02:38<00:09, 213.76 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46505/47780 [02:38<00:07, 178.04 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40762/47780 [02:38<00:12, 581.77 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45018/47780 [02:38<00:07, 363.87 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46011/47780 [02:38<00:07, 227.35 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46382/47780 [02:38<00:05, 267.56 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46544/47780 [02:38<00:05, 209.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45875/47780 [02:38<00:09, 207.13 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46525/47780 [02:38<00:07, 174.71 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47381/47780 [02:38<00:03, 109.29 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40824/47780 [02:38<00:11, 584.10 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45058/47780 [02:38<00:07, 372.72 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46571/47780 [02:38<00:05, 223.96 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46409/47780 [02:38<00:05, 257.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46034/47780 [02:38<00:08, 217.00 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45898/47780 [02:38<00:09, 203.38 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47393/47780 [02:38<00:03, 110.69 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40886/47780 [02:38<00:11, 589.66 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45096/47780 [02:38<00:07, 368.28 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46544/47780 [02:38<00:07, 170.62 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46595/47780 [02:38<00:05, 226.39 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46059/47780 [02:38<00:07, 225.33 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46436/47780 [02:38<00:05, 248.84 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45930/47780 [02:38<00:08, 228.10 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45134/47780 [02:38<00:07, 368.86 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40946/47780 [02:38<00:12, 550.00 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46461/47780 [02:38<00:05, 245.18 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46082/47780 [02:38<00:07, 214.88 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46563/47780 [02:38<00:07, 161.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46621/47780 [02:38<00:05, 218.53 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47405/47780 [02:38<00:03, 95.06 examples/s] 
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45957/47780 [02:38<00:07, 229.97 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45172/47780 [02:38<00:07, 356.79 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41008/47780 [02:38<00:11, 568.28 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46486/47780 [02:38<00:05, 245.89 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46583/47780 [02:38<00:07, 170.34 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46111/47780 [02:38<00:07, 230.58 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46644/47780 [02:38<00:05, 211.33 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47417/47780 [02:38<00:03, 98.42 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45984/47780 [02:38<00:07, 231.05 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45213/47780 [02:38<00:06, 368.67 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41067/47780 [02:38<00:11, 568.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46514/47780 [02:38<00:05, 248.87 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46142/47780 [02:38<00:06, 242.26 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46603/47780 [02:38<00:07, 165.25 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47428/47780 [02:38<00:03, 100.05 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46667/47780 [02:38<00:05, 200.43 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46009/47780 [02:38<00:07, 233.73 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41125/47780 [02:38<00:11, 562.04 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46540/47780 [02:38<00:04, 250.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45251/47780 [02:38<00:07, 342.45 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46173/47780 [02:38<00:06, 254.35 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46623/47780 [02:38<00:06, 166.76 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47440/47780 [02:38<00:03, 104.30 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46688/47780 [02:39<00:05, 196.91 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46034/47780 [02:38<00:07, 234.95 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41188/47780 [02:38<00:11, 578.50 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46569/47780 [02:39<00:04, 258.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45287/47780 [02:39<00:07, 346.84 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46200/47780 [02:39<00:06, 241.64 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46641/47780 [02:39<00:06, 165.39 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46719/47780 [02:39<00:04, 224.59 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47458/47780 [02:39<00:02, 115.53 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46058/47780 [02:39<00:07, 227.56 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41247/47780 [02:39<00:11, 546.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46595/47780 [02:39<00:04, 254.68 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45334/47780 [02:39<00:06, 364.29 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46743/47780 [02:39<00:04, 228.46 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46658/47780 [02:39<00:06, 163.08 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46225/47780 [02:39<00:06, 225.84 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46082/47780 [02:39<00:07, 220.28 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41304/47780 [02:39<00:11, 550.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47470/47780 [02:39<00:02, 104.85 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45375/47780 [02:39<00:06, 370.50 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46621/47780 [02:39<00:05, 225.50 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46248/47780 [02:39<00:06, 224.75 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46105/47780 [02:39<00:07, 220.51 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46768/47780 [02:39<00:04, 205.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41364/47780 [02:39<00:11, 564.02 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46675/47780 [02:39<00:07, 138.13 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45414/47780 [02:39<00:06, 370.58 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46273/47780 [02:39<00:06, 222.42 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46128/47780 [02:39<00:07, 212.00 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41423/47780 [02:39<00:11, 562.45 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47481/47780 [02:39<00:03, 84.01 examples/s] 
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45459/47780 [02:39<00:06, 386.64 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46645/47780 [02:39<00:06, 186.62 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46791/47780 [02:39<00:05, 189.64 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46690/47780 [02:39<00:08, 130.76 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46300/47780 [02:39<00:06, 224.58 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46150/47780 [02:39<00:07, 213.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41482/47780 [02:39<00:11, 567.19 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47494/47780 [02:39<00:03, 91.24 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45504/47780 [02:39<00:05, 397.19 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46812/47780 [02:39<00:04, 194.11 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46668/47780 [02:39<00:05, 187.01 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46705/47780 [02:39<00:08, 129.97 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46323/47780 [02:39<00:06, 221.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41539/47780 [02:39<00:11, 555.65 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46173/47780 [02:39<00:07, 201.30 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45544/47780 [02:39<00:05, 389.35 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46833/47780 [02:39<00:04, 197.39 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47504/47780 [02:39<00:03, 87.92 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46688/47780 [02:39<00:05, 188.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46719/47780 [02:39<00:08, 131.73 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46346/47780 [02:39<00:06, 214.64 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41595/47780 [02:39<00:11, 526.76 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45588/47780 [02:39<00:05, 399.03 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46198/47780 [02:39<00:07, 202.91 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46854/47780 [02:39<00:04, 194.94 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46708/47780 [02:39<00:05, 185.16 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46733/47780 [02:39<00:07, 130.93 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47514/47780 [02:39<00:03, 77.77 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46375/47780 [02:39<00:06, 229.83 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41649/47780 [02:39<00:11, 520.35 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45628/47780 [02:39<00:05, 386.50 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46224/47780 [02:39<00:07, 215.99 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46874/47780 [02:39<00:04, 193.47 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46727/47780 [02:39<00:05, 176.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46749/47780 [02:39<00:08, 124.34 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46399/47780 [02:40<00:06, 226.81 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41702/47780 [02:39<00:11, 518.61 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47523/47780 [02:39<00:03, 75.18 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46247/47780 [02:39<00:07, 218.15 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45667/47780 [02:39<00:05, 371.09 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46897/47780 [02:40<00:04, 184.67 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46747/47780 [02:40<00:05, 178.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46768/47780 [02:40<00:07, 138.74 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46428/47780 [02:40<00:05, 242.69 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41764/47780 [02:40<00:11, 545.10 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46276/47780 [02:40<00:06, 231.77 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45711/47780 [02:40<00:05, 388.56 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47533/47780 [02:40<00:03, 75.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46768/47780 [02:40<00:05, 185.43 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46916/47780 [02:40<00:05, 169.65 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41822/47780 [02:40<00:10, 548.59 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46453/47780 [02:40<00:05, 237.58 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46788/47780 [02:40<00:06, 145.14 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45752/47780 [02:40<00:05, 394.44 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46302/47780 [02:40<00:06, 229.59 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47545/47780 [02:40<00:02, 80.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46790/47780 [02:40<00:05, 186.14 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41878/47780 [02:40<00:10, 543.04 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46484/47780 [02:40<00:05, 254.57 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46936/47780 [02:40<00:05, 164.20 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46805/47780 [02:40<00:06, 146.32 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46326/47780 [02:40<00:06, 220.38 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47557/47780 [02:40<00:02, 85.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46809/47780 [02:40<00:05, 182.18 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45792/47780 [02:40<00:05, 333.84 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41933/47780 [02:40<00:11, 524.34 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46955/47780 [02:40<00:04, 168.68 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46820/47780 [02:40<00:06, 142.83 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46352/47780 [02:40<00:06, 224.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46511/47780 [02:40<00:05, 217.54 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45828/47780 [02:40<00:05, 329.75 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46828/47780 [02:40<00:05, 169.60 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41988/47780 [02:40<00:10, 531.39 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47576/47780 [02:40<00:02, 100.86 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46975/47780 [02:40<00:04, 172.68 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46835/47780 [02:40<00:06, 141.17 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46376/47780 [02:40<00:06, 221.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46540/47780 [02:40<00:05, 232.86 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45864/47780 [02:40<00:05, 335.73 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42055/47780 [02:40<00:10, 569.10 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46848/47780 [02:40<00:05, 173.60 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47587/47780 [02:40<00:01, 103.04 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46993/47780 [02:40<00:04, 171.18 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46851/47780 [02:40<00:06, 140.31 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46403/47780 [02:40<00:05, 234.90 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46566/47780 [02:40<00:05, 220.63 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42128/47780 [02:40<00:09, 612.44 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45899/47780 [02:40<00:05, 320.54 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46869/47780 [02:40<00:05, 178.18 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47012/47780 [02:40<00:04, 172.11 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46867/47780 [02:40<00:06, 144.94 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47598/47780 [02:40<00:01, 95.01 examples/s] 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46428/47780 [02:40<00:05, 230.22 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46591/47780 [02:40<00:05, 227.40 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42190/47780 [02:40<00:09, 606.29 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45933/47780 [02:40<00:05, 311.75 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46889/47780 [02:40<00:04, 178.24 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47040/47780 [02:40<00:03, 190.83 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46883/47780 [02:40<00:06, 145.03 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47609/47780 [02:40<00:01, 93.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46457/47780 [02:40<00:05, 246.26 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42251/47780 [02:40<00:09, 593.86 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46615/47780 [02:40<00:05, 211.88 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45969/47780 [02:40<00:05, 311.23 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46911/47780 [02:40<00:04, 180.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47065/47780 [02:41<00:03, 203.01 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46902/47780 [02:40<00:05, 152.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46485/47780 [02:40<00:05, 252.31 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47623/47780 [02:40<00:01, 99.49 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42316/47780 [02:40<00:09, 601.88 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46006/47780 [02:41<00:05, 322.10 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46930/47780 [02:41<00:04, 177.88 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46920/47780 [02:41<00:05, 160.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46637/47780 [02:41<00:05, 192.11 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47636/47780 [02:41<00:01, 105.13 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47086/47780 [02:41<00:03, 183.65 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46511/47780 [02:41<00:05, 230.10 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42377/47780 [02:41<00:08, 602.54 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46042/47780 [02:41<00:05, 326.06 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46950/47780 [02:41<00:04, 174.02 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46658/47780 [02:41<00:05, 187.87 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47105/47780 [02:41<00:03, 175.65 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46939/47780 [02:41<00:05, 144.05 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47647/47780 [02:41<00:01, 96.52 examples/s] 
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42439/47780 [02:41<00:09, 576.19 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46535/47780 [02:41<00:05, 218.31 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46079/47780 [02:41<00:05, 335.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46978/47780 [02:41<00:03, 201.51 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46678/47780 [02:41<00:05, 186.33 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47125/47780 [02:41<00:03, 181.44 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46954/47780 [02:41<00:05, 140.69 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46559/47780 [02:41<00:05, 222.04 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42500/47780 [02:41<00:09, 567.78 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46113/47780 [02:41<00:05, 322.01 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46697/47780 [02:41<00:05, 184.14 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46999/47780 [02:41<00:04, 180.75 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47144/47780 [02:41<00:03, 180.02 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46969/47780 [02:41<00:05, 142.72 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42564/47780 [02:41<00:08, 580.25 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46583/47780 [02:41<00:05, 215.89 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47658/47780 [02:41<00:01, 74.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46146/47780 [02:41<00:05, 310.55 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46724/47780 [02:41<00:05, 204.88 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47025/47780 [02:41<00:03, 200.03 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47164/47780 [02:41<00:03, 175.99 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46987/47780 [02:41<00:05, 147.91 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42623/47780 [02:41<00:09, 570.92 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46607/47780 [02:41<00:05, 217.42 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46179/47780 [02:41<00:05, 291.47 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46746/47780 [02:41<00:05, 199.90 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47046/47780 [02:41<00:03, 193.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47191/47780 [02:41<00:02, 198.30 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42699/47780 [02:41<00:08, 622.53 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46642/47780 [02:41<00:04, 250.56 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47002/47780 [02:41<00:05, 135.29 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47668/47780 [02:41<00:01, 62.34 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46209/47780 [02:41<00:05, 286.62 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46772/47780 [02:41<00:04, 211.73 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47067/47780 [02:41<00:03, 196.97 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42763/47780 [02:41<00:07, 627.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46668/47780 [02:41<00:04, 249.35 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47213/47780 [02:41<00:03, 179.16 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46242/47780 [02:41<00:05, 286.16 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46795/47780 [02:41<00:04, 211.57 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47016/47780 [02:41<00:06, 116.39 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47089/47780 [02:41<00:03, 200.67 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42841/47780 [02:41<00:07, 663.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46694/47780 [02:41<00:04, 247.86 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47232/47780 [02:41<00:03, 165.39 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47111/47780 [02:41<00:03, 204.27 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46817/47780 [02:42<00:04, 208.59 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46274/47780 [02:41<00:05, 285.98 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47677/47780 [02:41<00:01, 51.69 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42920/47780 [02:41<00:06, 697.87 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47029/47780 [02:41<00:06, 110.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46721/47780 [02:41<00:04, 244.44 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46312/47780 [02:42<00:04, 306.51 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46838/47780 [02:42<00:04, 200.99 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47250/47780 [02:42<00:03, 158.48 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42990/47780 [02:42<00:06, 695.26 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47132/47780 [02:42<00:03, 187.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47042/47780 [02:42<00:06, 113.21 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47683/47780 [02:42<00:02, 48.44 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46755/47780 [02:42<00:04, 246.55 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43062/47780 [02:42<00:06, 699.13 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46343/47780 [02:42<00:04, 294.54 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46865/47780 [02:42<00:04, 213.42 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47268/47780 [02:42<00:03, 156.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47153/47780 [02:42<00:03, 188.88 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47055/47780 [02:42<00:06, 107.42 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47690/47780 [02:42<00:01, 49.76 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46780/47780 [02:42<00:04, 224.92 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46373/47780 [02:42<00:05, 279.57 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43135/47780 [02:42<00:07, 652.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46887/47780 [02:42<00:04, 202.22 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47284/47780 [02:42<00:03, 144.89 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47173/47780 [02:42<00:03, 171.62 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47069/47780 [02:42<00:06, 109.08 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46806/47780 [02:42<00:04, 219.84 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47698/47780 [02:42<00:01, 50.51 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43203/47780 [02:42<00:06, 659.90 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46402/47780 [02:42<00:05, 274.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46908/47780 [02:42<00:04, 200.70 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47304/47780 [02:42<00:03, 152.10 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47194/47780 [02:42<00:03, 179.83 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47082/47780 [02:42<00:06, 111.59 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46831/47780 [02:42<00:04, 223.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43271/47780 [02:42<00:06, 649.29 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46937/47780 [02:42<00:03, 218.66 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46430/47780 [02:42<00:05, 261.18 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47704/47780 [02:42<00:01, 49.52 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47213/47780 [02:42<00:03, 177.07 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47320/47780 [02:42<00:03, 146.11 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47095/47780 [02:42<00:05, 116.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43339/47780 [02:42<00:06, 649.54 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46854/47780 [02:42<00:04, 216.39 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46964/47780 [02:42<00:03, 230.77 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46457/47780 [02:42<00:05, 261.33 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47714/47780 [02:42<00:01, 56.84 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47338/47780 [02:42<00:02, 153.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47231/47780 [02:42<00:03, 168.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47108/47780 [02:42<00:06, 105.54 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46992/47780 [02:42<00:03, 243.31 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43407/47780 [02:42<00:06, 627.25 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46876/47780 [02:42<00:04, 208.32 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46484/47780 [02:42<00:05, 256.92 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47354/47780 [02:42<00:02, 148.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47250/47780 [02:42<00:03, 159.53 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46901/47780 [02:42<00:04, 218.58 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43471/47780 [02:42<00:07, 613.84 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47122/47780 [02:42<00:06, 105.10 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47720/47780 [02:42<00:01, 47.67 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47020/47780 [02:42<00:03, 228.55 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46510/47780 [02:42<00:05, 233.39 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47375/47780 [02:42<00:02, 157.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47270/47780 [02:42<00:03, 166.65 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43533/47780 [02:42<00:07, 601.37 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46927/47780 [02:42<00:04, 213.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47137/47780 [02:42<00:05, 109.78 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47044/47780 [02:43<00:03, 223.61 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46534/47780 [02:42<00:05, 227.82 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47726/47780 [02:42<00:01, 46.13 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47394/47780 [02:43<00:02, 165.46 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47291/47780 [02:42<00:02, 177.96 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43609/47780 [02:43<00:06, 645.92 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47153/47780 [02:43<00:05, 119.95 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47070/47780 [02:43<00:03, 231.14 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46950/47780 [02:43<00:04, 205.19 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46563/47780 [02:43<00:05, 233.67 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47732/47780 [02:43<00:01, 44.98 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47411/47780 [02:43<00:02, 147.77 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47310/47780 [02:43<00:02, 164.77 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43677/47780 [02:43<00:06, 620.29 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47169/47780 [02:43<00:04, 129.80 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47102/47780 [02:43<00:02, 253.22 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46971/47780 [02:43<00:04, 197.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46587/47780 [02:43<00:05, 227.34 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47329/47780 [02:43<00:02, 168.91 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47428/47780 [02:43<00:02, 142.58 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43740/47780 [02:43<00:06, 611.37 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47129/47780 [02:43<00:02, 248.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47183/47780 [02:43<00:04, 122.14 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46994/47780 [02:43<00:03, 202.10 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47738/47780 [02:43<00:01, 40.65 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46611/47780 [02:43<00:05, 225.99 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47350/47780 [02:43<00:02, 177.91 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47443/47780 [02:43<00:02, 133.43 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43802/47780 [02:43<00:07, 557.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47024/47780 [02:43<00:03, 225.52 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47158/47780 [02:43<00:02, 231.72 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47201/47780 [02:43<00:04, 126.02 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46634/47780 [02:43<00:05, 208.27 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47457/47780 [02:43<00:02, 132.20 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43875/47780 [02:43<00:06, 592.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47370/47780 [02:43<00:02, 157.59 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47047/47780 [02:43<00:03, 224.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47182/47780 [02:43<00:02, 221.13 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47214/47780 [02:43<00:04, 120.77 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46662/47780 [02:43<00:05, 223.38 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47744/47780 [02:43<00:01, 33.03 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43938/47780 [02:43<00:06, 594.67 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47471/47780 [02:43<00:02, 130.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47387/47780 [02:43<00:02, 154.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47079/47780 [02:43<00:02, 237.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47232/47780 [02:43<00:04, 133.53 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46686/47780 [02:43<00:04, 220.32 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47206/47780 [02:43<00:02, 206.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44015/47780 [02:43<00:05, 636.78 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47104/47780 [02:43<00:02, 235.20 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47485/47780 [02:43<00:02, 122.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47404/47780 [02:43<00:02, 143.92 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47748/47780 [02:43<00:01, 28.97 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47247/47780 [02:43<00:04, 128.28 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46710/47780 [02:43<00:05, 207.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47228/47780 [02:43<00:02, 198.85 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47499/47780 [02:43<00:02, 123.59 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44081/47780 [02:43<00:06, 565.36 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47419/47780 [02:43<00:02, 143.00 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47261/47780 [02:43<00:04, 127.65 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47249/47780 [02:43<00:02, 200.12 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47130/47780 [02:43<00:03, 199.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46732/47780 [02:43<00:05, 193.62 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47752/47780 [02:43<00:01, 26.89 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47512/47780 [02:44<00:02, 118.93 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47437/47780 [02:43<00:02, 149.72 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44140/47780 [02:43<00:06, 549.11 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47274/47780 [02:44<00:04, 123.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47270/47780 [02:44<00:02, 190.38 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46757/47780 [02:44<00:05, 204.30 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47151/47780 [02:44<00:03, 190.51 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47456/47780 [02:44<00:02, 157.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47524/47780 [02:44<00:02, 115.86 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44215/47780 [02:44<00:06, 587.86 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [02:44<00:00, 26.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47289/47780 [02:44<00:03, 130.19 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47290/47780 [02:44<00:02, 186.51 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46781/47780 [02:44<00:04, 206.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47171/47780 [02:44<00:03, 184.75 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44276/47780 [02:44<00:06, 564.88 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47536/47780 [02:44<00:02, 109.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47473/47780 [02:44<00:02, 139.85 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47309/47780 [02:44<00:02, 186.82 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47303/47780 [02:44<00:03, 120.81 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47760/47780 [02:44<00:00, 26.74 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47190/47780 [02:44<00:03, 181.72 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46802/47780 [02:44<00:04, 195.82 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44334/47780 [02:44<00:06, 519.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47547/47780 [02:44<00:02, 101.30 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47330/47780 [02:44<00:02, 184.01 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47316/47780 [02:44<00:03, 116.43 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47210/47780 [02:44<00:03, 182.73 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47488/47780 [02:44<00:02, 129.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46830/47780 [02:44<00:04, 208.18 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47764/47780 [02:44<00:00, 24.63 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44387/47780 [02:44<00:06, 491.71 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47558/47780 [02:44<00:02, 95.33 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47239/47780 [02:44<00:02, 209.06 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47354/47780 [02:44<00:02, 188.91 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47329/47780 [02:44<00:03, 113.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46854/47780 [02:44<00:04, 213.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47502/47780 [02:44<00:02, 110.28 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44437/47780 [02:44<00:06, 477.57 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47261/47780 [02:44<00:02, 203.76 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47381/47780 [02:44<00:01, 204.54 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47768/47780 [02:44<00:00, 25.10 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46880/47780 [02:44<00:04, 215.50 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47570/47780 [02:44<00:02, 91.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47341/47780 [02:44<00:04, 105.63 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47514/47780 [02:44<00:02, 109.56 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44490/47780 [02:44<00:06, 488.70 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47405/47780 [02:44<00:01, 212.15 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47582/47780 [02:44<00:02, 97.95 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46904/47780 [02:44<00:04, 216.30 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47354/47780 [02:44<00:03, 108.09 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47772/47780 [02:44<00:00, 25.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47530/47780 [02:44<00:02, 118.96 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44547/47780 [02:44<00:06, 510.24 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47283/47780 [02:44<00:02, 167.44 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47429/47780 [02:44<00:01, 213.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47366/47780 [02:44<00:03, 111.00 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46926/47780 [02:44<00:04, 204.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47600/47780 [02:44<00:01, 108.78 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44603/47780 [02:44<00:06, 521.69 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47543/47780 [02:44<00:01, 119.13 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47301/47780 [02:44<00:03, 159.43 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47453/47780 [02:45<00:01, 201.07 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46947/47780 [02:44<00:04, 204.16 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47381/47780 [02:44<00:03, 111.23 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44657/47780 [02:44<00:05, 524.40 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47559/47780 [02:45<00:01, 121.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47612/47780 [02:45<00:01, 95.76 examples/s] 
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46968/47780 [02:45<00:04, 200.65 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47319/47780 [02:45<00:03, 142.42 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47400/47780 [02:45<00:02, 130.54 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44717/47780 [02:45<00:05, 543.47 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47474/47780 [02:45<00:01, 170.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47625/47780 [02:45<00:01, 97.79 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46990/47780 [02:45<00:03, 203.19 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47335/47780 [02:45<00:03, 140.57 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44772/47780 [02:45<00:05, 522.18 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47415/47780 [02:45<00:02, 127.11 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47572/47780 [02:45<00:02, 100.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47493/47780 [02:45<00:01, 165.45 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47014/47780 [02:45<00:03, 211.62 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47637/47780 [02:45<00:01, 96.32 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44828/47780 [02:45<00:05, 531.13 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47584/47780 [02:45<00:01, 103.46 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47350/47780 [02:45<00:03, 136.94 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47431/47780 [02:45<00:02, 127.88 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47514/47780 [02:45<00:01, 168.64 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47037/47780 [02:45<00:03, 211.76 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47650/47780 [02:45<00:01, 103.69 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44899/47780 [02:45<00:04, 577.32 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47777/47780 [02:45<00:00, 14.22 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47597/47780 [02:45<00:01, 107.40 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47444/47780 [02:45<00:02, 123.85 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47366/47780 [02:45<00:03, 128.22 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47062/47780 [02:45<00:03, 213.23 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47662/47780 [02:45<00:01, 102.71 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47532/47780 [02:45<00:01, 153.78 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44958/47780 [02:45<00:04, 565.97 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47457/47780 [02:45<00:02, 123.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47610/47780 [02:45<00:01, 103.02 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47084/47780 [02:45<00:03, 211.37 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47550/47780 [02:45<00:01, 159.48 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45016/47780 [02:45<00:04, 565.88 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47380/47780 [02:45<00:03, 110.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47674/47780 [02:45<00:01, 97.54 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47622/47780 [02:45<00:01, 102.94 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47471/47780 [02:45<00:02, 116.50 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47109/47780 [02:45<00:03, 214.46 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45073/47780 [02:45<00:05, 535.25 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47684/47780 [02:45<00:00, 98.02 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47392/47780 [02:45<00:03, 106.39 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47567/47780 [02:45<00:01, 136.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47486/47780 [02:45<00:02, 124.74 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47637/47780 [02:45<00:01, 111.04 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47131/47780 [02:45<00:03, 213.01 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45127/47780 [02:45<00:05, 499.84 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47403/47780 [02:45<00:03, 101.70 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47587/47780 [02:45<00:01, 146.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47694/47780 [02:45<00:01, 84.97 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47154/47780 [02:45<00:02, 208.87 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47649/47780 [02:45<00:01, 100.91 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47500/47780 [02:45<00:02, 111.84 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45184/47780 [02:45<00:05, 508.22 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47603/47780 [02:46<00:01, 148.57 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47416/47780 [02:46<00:03, 97.00 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47517/47780 [02:46<00:02, 119.27 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47176/47780 [02:46<00:03, 193.72 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45247/47780 [02:46<00:04, 539.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47661/47780 [02:46<00:01, 95.73 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47704/47780 [02:46<00:01, 66.58 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47620/47780 [02:46<00:01, 139.90 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47427/47780 [02:46<00:03, 93.85 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47196/47780 [02:46<00:03, 191.84 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45309/47780 [02:46<00:04, 560.56 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47531/47780 [02:46<00:02, 102.69 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47672/47780 [02:46<00:01, 84.54 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47642/47780 [02:46<00:00, 148.21 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47216/47780 [02:46<00:02, 193.85 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47439/47780 [02:46<00:03, 95.87 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45367/47780 [02:46<00:04, 539.28 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47712/47780 [02:46<00:01, 60.86 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47544/47780 [02:46<00:02, 102.92 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47661/47780 [02:46<00:00, 156.51 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47451/47780 [02:46<00:03, 100.44 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47240/47780 [02:46<00:02, 198.32 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45423/47780 [02:46<00:04, 521.64 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47682/47780 [02:46<00:01, 75.04 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47721/47780 [02:46<00:00, 63.66 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47682/47780 [02:46<00:00, 164.71 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47261/47780 [02:46<00:02, 194.43 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45481/47780 [02:46<00:04, 537.48 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47465/47780 [02:46<00:03, 99.59 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47559/47780 [02:46<00:02, 98.05 examples/s] 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47731/47780 [02:46<00:00, 68.38 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47700/47780 [02:46<00:00, 159.83 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45537/47780 [02:46<00:04, 532.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47281/47780 [02:46<00:02, 183.26 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47476/47780 [02:46<00:03, 96.36 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47571/47780 [02:46<00:02, 95.60 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47691/47780 [02:46<00:01, 58.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47741/47780 [02:46<00:00, 68.64 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47307/47780 [02:46<00:02, 199.76 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45591/47780 [02:46<00:04, 481.63 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47585/47780 [02:46<00:01, 105.32 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47487/47780 [02:46<00:03, 90.31 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47751/47780 [02:46<00:00, 72.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47329/47780 [02:46<00:02, 202.49 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45650/47780 [02:46<00:04, 506.67 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47597/47780 [02:46<00:01, 101.42 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47498/47780 [02:46<00:03, 91.08 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47760/47780 [02:47<00:00, 72.24 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47700/47780 [02:46<00:01, 48.54 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45715/47780 [02:46<00:03, 537.86 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47350/47780 [02:46<00:02, 190.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47608/47780 [02:47<00:01, 102.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47509/47780 [02:47<00:03, 84.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47370/47780 [02:47<00:02, 184.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45770/47780 [02:47<00:04, 494.33 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47706/47780 [02:47<00:01, 43.26 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47620/47780 [02:47<00:01, 92.25 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47520/47780 [02:47<00:02, 87.52 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47396/47780 [02:47<00:01, 200.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47717/47780 [02:47<00:00, 70.54 examples/s] 
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45823/47780 [02:47<00:04, 462.92 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47531/47780 [02:47<00:02, 89.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47418/47780 [02:47<00:01, 196.53 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47712/47780 [02:47<00:01, 39.77 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47630/47780 [02:47<00:01, 79.15 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45873/47780 [02:47<00:04, 430.47 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47439/47780 [02:47<00:01, 196.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47545/47780 [02:47<00:02, 96.73 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47717/47780 [02:47<00:01, 40.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45918/47780 [02:47<00:04, 424.07 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47640/47780 [02:47<00:01, 71.74 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47460/47780 [02:47<00:01, 179.04 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47557/47780 [02:47<00:02, 93.13 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45962/47780 [02:47<00:04, 408.85 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47649/47780 [02:47<00:01, 69.81 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47723/47780 [02:47<00:01, 36.51 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47480/47780 [02:47<00:01, 173.70 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47731/47780 [02:47<00:00, 52.12 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47572/47780 [02:47<00:02, 98.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46010/47780 [02:47<00:04, 414.45 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47500/47780 [02:47<00:01, 175.92 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47727/47780 [02:47<00:01, 34.67 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46054/47780 [02:47<00:04, 411.38 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47585/47780 [02:47<00:01, 99.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47658/47780 [02:47<00:01, 65.39 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47523/47780 [02:47<00:01, 178.12 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46096/47780 [02:47<00:04, 402.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47731/47780 [02:47<00:01, 34.22 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47602/47780 [02:47<00:01, 107.70 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47665/47780 [02:47<00:01, 61.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47542/47780 [02:48<00:01, 177.73 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47741/47780 [02:48<00:00, 43.72 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46137/47780 [02:48<00:04, 360.60 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47674/47780 [02:48<00:01, 65.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47614/47780 [02:48<00:01, 103.60 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47562/47780 [02:48<00:01, 164.17 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47736/47780 [02:48<00:01, 28.74 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46176/47780 [02:48<00:04, 354.18 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47685/47780 [02:48<00:01, 72.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47627/47780 [02:48<00:01, 103.75 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46219/47780 [02:48<00:04, 373.08 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47741/47780 [02:48<00:01, 29.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47749/47780 [02:48<00:00, 40.29 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47639/47780 [02:48<00:01, 100.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47579/47780 [02:48<00:01, 140.67 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47693/47780 [02:48<00:01, 66.78 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46258/47780 [02:48<00:04, 366.62 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47701/47780 [02:48<00:01, 69.47 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47745/47780 [02:48<00:01, 29.02 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47651/47780 [02:48<00:01, 90.89 examples/s] 
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46296/47780 [02:48<00:04, 352.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47758/47780 [02:48<00:00, 41.94 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47594/47780 [02:48<00:01, 108.82 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47661/47780 [02:48<00:01, 88.47 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46333/47780 [02:48<00:04, 350.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47749/47780 [02:48<00:01, 28.39 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47710/47780 [02:48<00:01, 51.62 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46369/47780 [02:48<00:04, 336.72 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47766/47780 [02:48<00:00, 39.73 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47671/47780 [02:48<00:01, 82.89 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47753/47780 [02:48<00:00, 27.72 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46406/47780 [02:48<00:04, 341.66 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47608/47780 [02:48<00:02, 82.38 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47681/47780 [02:48<00:01, 85.91 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47716/47780 [02:48<00:01, 44.99 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47758/47780 [02:48<00:00, 29.11 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46444/47780 [02:48<00:03, 334.67 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47690/47780 [02:48<00:01, 83.95 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47619/47780 [02:49<00:01, 81.97 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46483/47780 [02:49<00:03, 348.51 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47722/47780 [02:49<00:01, 42.67 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47762/47780 [02:49<00:00, 28.39 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47701/47780 [02:49<00:00, 84.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47771/47780 [02:49<00:00, 13.29 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47630/47780 [02:49<00:01, 75.79 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46520/47780 [02:49<00:03, 324.61 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [02:49<00:00, 30.89 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47714/47780 [02:49<00:00, 82.08 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46556/47780 [02:49<00:03, 327.53 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47728/47780 [02:49<00:01, 36.38 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47639/47780 [02:49<00:01, 72.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47771/47780 [02:49<00:00, 30.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46590/47780 [02:49<00:03, 306.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47648/47780 [02:49<00:01, 74.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47724/47780 [02:49<00:00, 74.93 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47734/47780 [02:49<00:01, 34.65 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47656/47780 [02:49<00:01, 73.50 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46626/47780 [02:49<00:03, 305.35 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47732/47780 [02:49<00:00, 68.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46659/47780 [02:49<00:03, 310.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47740/47780 [02:49<00:00, 65.19 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46695/47780 [02:49<00:03, 311.05 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47739/47780 [02:49<00:01, 28.38 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47664/47780 [02:49<00:02, 53.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47748/47780 [02:49<00:00, 65.17 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46739/47780 [02:49<00:03, 338.20 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47743/47780 [02:49<00:01, 28.87 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46775/47780 [02:49<00:03, 325.77 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [02:50<00:00, 59.32 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47747/47780 [02:50<00:01, 28.20 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46814/47780 [02:50<00:02, 340.60 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47672/47780 [02:50<00:02, 39.91 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46850/47780 [02:50<00:02, 341.47 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47764/47780 [02:50<00:00, 51.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47751/47780 [02:50<00:01, 27.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46886/47780 [02:50<00:02, 341.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47755/47780 [02:50<00:00, 26.48 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47678/47780 [02:50<00:02, 35.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46922/47780 [02:50<00:02, 342.07 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46957/47780 [02:50<00:02, 340.10 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47759/47780 [02:50<00:00, 27.57 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47684/47780 [02:50<00:02, 33.57 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47762/47780 [02:50<00:00, 27.05 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46993/47780 [02:50<00:02, 319.29 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47689/47780 [02:50<00:02, 34.48 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47026/47780 [02:50<00:02, 295.11 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [02:50<00:00, 29.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47694/47780 [02:50<00:02, 36.68 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47771/47780 [02:50<00:00, 31.03 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47059/47780 [02:50<00:02, 284.96 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47700/47780 [02:50<00:02, 38.69 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47089/47780 [02:51<00:02, 269.28 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47705/47780 [02:51<00:01, 38.86 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47119/47780 [02:51<00:02, 251.90 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47711/47780 [02:51<00:01, 37.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47146/47780 [02:51<00:02, 248.13 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47176/47780 [02:51<00:02, 257.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47717/47780 [02:51<00:01, 40.15 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47203/47780 [02:51<00:02, 247.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47723/47780 [02:51<00:01, 42.91 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47728/47780 [02:51<00:01, 42.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47229/47780 [02:51<00:02, 226.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47253/47780 [02:51<00:02, 184.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47734/47780 [02:51<00:01, 35.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47274/47780 [02:52<00:03, 158.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47738/47780 [02:52<00:01, 31.71 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47742/47780 [02:52<00:01, 28.89 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47294/47780 [02:52<00:03, 139.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47772/47780 [02:52<00:01,  7.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47746/47780 [02:52<00:01, 29.26 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47311/47780 [02:52<00:03, 129.70 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47750/47780 [02:52<00:01, 29.01 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47329/47780 [02:52<00:03, 129.79 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47754/47780 [02:52<00:00, 30.78 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47343/47780 [02:52<00:03, 126.82 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47759/47780 [02:52<00:00, 32.84 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47356/47780 [02:52<00:03, 115.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47763/47780 [02:52<00:00, 33.13 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47372/47780 [02:52<00:03, 121.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [02:52<00:00, 33.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47385/47780 [02:53<00:03, 115.76 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47399/47780 [02:53<00:03, 115.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47411/47780 [02:53<00:03, 110.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47425/47780 [02:53<00:03, 112.49 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47440/47780 [02:53<00:02, 116.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47454/47780 [02:53<00:02, 114.07 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47770/47780 [02:53<00:01,  6.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47468/47780 [02:53<00:02, 120.27 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47482/47780 [02:53<00:02, 118.58 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47494/47780 [02:53<00:02, 114.83 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47507/47780 [02:54<00:02, 111.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47519/47780 [02:54<00:02, 88.82 examples/s] 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47530/47780 [02:54<00:02, 83.45 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47540/47780 [02:54<00:02, 83.14 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47549/47780 [02:54<00:02, 78.84 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47558/47780 [02:54<00:03, 73.93 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47567/47780 [02:54<00:02, 74.70 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [02:55<00:00,  1.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47577/47780 [02:55<00:02, 74.25 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47585/47780 [02:55<00:02, 74.94 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [02:55<00:00, 272.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47598/47780 [02:55<00:02, 81.10 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47608/47780 [02:55<00:02, 65.40 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47616/47780 [02:55<00:03, 51.32 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47622/47780 [02:56<00:03, 45.17 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:25, 1832.81 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47629/47780 [02:56<00:03, 39.62 examples/s]
Truncating train dataset (num_proc=32):  15%|█▍        | 7000/47780 [00:00<00:04, 9538.52 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47637/47780 [02:56<00:03, 44.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  42%|████▏     | 19961/47780 [00:00<00:00, 29792.97 examples/s]
Truncating train dataset (num_proc=32):  85%|████████▍ | 40385/47780 [00:01<00:00, 63543.38 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47643/47780 [02:56<00:03, 38.01 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47651/47780 [02:56<00:03, 42.36 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47775/47780 [02:56<00:02,  2.22 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47659/47780 [02:56<00:02, 46.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47665/47780 [02:57<00:02, 41.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47671/47780 [02:57<00:02, 37.80 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47677/47780 [02:57<00:02, 35.95 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47681/47780 [02:57<00:02, 34.97 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47685/47780 [02:57<00:02, 34.45 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47690/47780 [02:57<00:02, 36.53 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47697/47780 [02:57<00:01, 41.51 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47703/47780 [02:58<00:01, 45.73 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [02:58<00:02,  1.68 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47709/47780 [02:58<00:01, 45.85 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47715/47780 [02:58<00:01, 46.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47723/47780 [02:58<00:01, 52.24 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47729/47780 [02:58<00:01, 50.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47775/47780 [02:58<00:01,  3.02 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47735/47780 [02:58<00:01, 43.01 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47742/47780 [02:58<00:00, 45.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47748/47780 [02:59<00:00, 39.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47754/47780 [02:59<00:00, 37.23 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47763/47780 [02:59<00:00, 44.78 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47768/47780 [02:59<00:00, 43.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47773/47780 [02:59<00:03,  2.30 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [02:59<00:00, 40.70 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [03:00<00:00,  1.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [03:01<00:00, 13.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47777/47780 [03:01<00:01,  2.20 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:01<00:00,  8.67 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:01<00:00, 262.66 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:02<00:00,  2.39 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [03:02<00:02,  1.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:02<00:00,  2.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:28, 1618.98 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  13%|█▎        | 6000/47780 [00:00<00:03, 10576.46 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  43%|████▎     | 20482/47780 [00:00<00:00, 37223.95 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:03<00:00, 261.01 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  89%|████████▊ | 42357/47780 [00:00<00:00, 77432.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:03<00:00,  2.07 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:36, 1268.17 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [03:04<00:00,  1.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  17%|█▋        | 8000/47780 [00:00<00:03, 11553.69 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  39%|███▊      | 18469/47780 [00:01<00:01, 27963.83 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:04<00:00, 259.03 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  83%|████████▎ | 39878/47780 [00:01<00:00, 64697.55 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):   9%|▉         | 4479/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:04<00:00, 258.63 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  16%|█▌        | 7465/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  11%|█▏        | 5479/47780 [00:00<00:22, 1906.64 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  26%|██▌       | 12479/47780 [00:00<00:02, 16104.18 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  78%|███████▊  | 37426/47780 [00:00<00:00, 67175.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [03:05<00:00,  1.74 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  18%|█▊        | 8465/47780 [00:00<00:26, 1461.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  39%|███▊      | 18465/47780 [00:00<00:01, 18443.37 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  80%|████████  | 38399/47780 [00:00<00:00, 53481.77 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:12<00:00, 63543.38 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:13<00:00, 2321.05 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:09<00:00, 252.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  34%|███▍      | 16424/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  36%|███▋      | 17424/47780 [00:01<00:47, 637.47 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  61%|██████    | 28918/47780 [00:01<00:01, 10163.35 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  92%|█████████▏| 43823/47780 [00:01<00:00, 24844.08 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:12<00:00,  1.15 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:13<00:00, 247.22 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  62%|██████▏   | 29862/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  65%|██████▍   | 30862/47780 [00:00<00:09, 1867.75 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  93%|█████████▎| 44330/47780 [00:00<00:00, 29577.45 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:15<00:00,  8.67 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:13<00:00, 64697.55 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:12<00:00, 67175.15 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:14<00:00, 77432.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  97%|█████████▋| 46287/47780 [00:12<00:00, 53481.77 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:23<00:00, 2069.16 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m [2025-08-02 00:46:53,631] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m df: /root/.triton/autotune: No such file or directory
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  97%|█████████▋| 46287/47780 [00:15<00:00, 1789.21 examples/s] 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32):  97%|█████████▋| 46288/47780 [00:12<00:00, 24844.08 examples/s][2025-08-02 00:46:57,325] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:20<00:00, 1544.94 examples/s] 
Truncating train dataset (num_proc=32):  97%|█████████▋| 46287/47780 [00:20<00:00, 1877.12 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:23<00:00, 1374.91 examples/s] 
Truncating train dataset (num_proc=32): 47782 examples [00:13, 29577.45 examples/s]                    backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m [2025-08-02 00:47:00,686] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:28<00:00, 229.29 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m [2025-08-02 00:47:02,178] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Truncating train dataset (num_proc=32):  97%|█████████▋| 46288/47780 [00:19<00:01, 1037.85 examples/s] backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m [2025-08-02 00:47:02,572] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:28<00:00, 1082.54 examples/s] [2025-08-02 00:47:04,273] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:29<00:00, 1480.48 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Truncating train dataset (num_proc=32): 47782 examples [00:20, 665.47 examples/s]  
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:32<00:00, 1483.85 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:31<00:00, 1516.79 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m [2025-08-02 00:47:08,294] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Truncating train dataset (num_proc=32):  97%|█████████▋| 46288/47780 [00:25<00:01, 1183.09 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
Truncating train dataset (num_proc=32): 47782 examples [00:21, 835.94 examples/s]
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m [2025-08-02 00:47:08,916] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m [2025-08-02 00:47:09,368] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m [2025-08-02 00:47:09,376] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m [2025-08-02 00:47:09,389] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m [2025-08-02 00:47:09,503] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m [2025-08-02 00:47:10,152] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m [2025-08-02 00:47:10,601] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m [2025-08-02 00:47:10,659] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m [2025-08-02 00:47:10,800] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   0%|          | 0/10 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3097)[0m  10%|█         | 1/10 [00:44<06:43, 44.80s/it]
[36m(head, rank=0, pid=3097)[0m  20%|██        | 2/10 [01:24<05:34, 41.76s/it]
[36m(head, rank=0, pid=3097)[0m  30%|███       | 3/10 [02:03<04:43, 40.56s/it]
[36m(head, rank=0, pid=3097)[0m  40%|████      | 4/10 [02:42<04:00, 40.04s/it]
[36m(head, rank=0, pid=3097)[0m  50%|█████     | 5/10 [03:22<03:19, 39.89s/it]
[36m(head, rank=0, pid=3097)[0m  60%|██████    | 6/10 [04:00<02:37, 39.34s/it]
[36m(head, rank=0, pid=3097)[0m  70%|███████   | 7/10 [04:40<01:58, 39.44s/it]
[36m(head, rank=0, pid=3097)[0m  80%|████████  | 8/10 [05:20<01:19, 39.54s/it]
[36m(head, rank=0, pid=3097)[0m  90%|█████████ | 9/10 [05:58<00:39, 39.16s/it]
100%|██████████| 10/10 [06:35<00:00, 38.41s/it]
                                               
{'loss': 124.4492, 'grad_norm': 35.656002044677734, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3097)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m TRAINING TIME STATISTICS
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Total training steps: 80
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Total training time: 355.07 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Average time per step: 4.438 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Fastest step: 3.661 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Slowest step: 8.934 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Time variance: 5.273 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Step time distribution:
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 1: 8.934s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 2: 4.380s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 3: 5.114s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 4: 4.069s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 5: 5.097s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 6: 3.858s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 7: 4.259s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 8: 4.112s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 9: 4.254s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 10: 5.106s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 11: 4.136s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 12: 4.165s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 13: 4.012s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 14: 5.385s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 15: 4.013s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 16: 4.589s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 17: 4.824s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 18: 4.382s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 19: 4.126s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 20: 4.112s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 21: 4.654s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 22: 4.102s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 23: 5.000s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 24: 4.503s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 25: 5.345s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 26: 4.469s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 27: 4.257s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 28: 4.155s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 29: 4.017s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 30: 4.100s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 31: 4.272s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 32: 4.831s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 33: 5.118s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 34: 4.288s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 35: 4.469s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 36: 4.485s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 37: 4.582s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 38: 4.588s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 39: 3.661s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 40: 4.169s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 41: 3.903s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 42: 4.185s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 43: 5.445s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 44: 4.396s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 45: 4.440s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 46: 4.097s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 47: 3.982s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 48: 4.109s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 49: 5.136s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 50: 5.090s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 51: 4.101s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 52: 4.130s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 53: 4.431s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 54: 4.348s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 55: 4.587s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 56: 3.749s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 57: 5.363s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 58: 4.466s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 59: 4.296s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 60: 4.543s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 61: 4.098s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 62: 4.138s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 63: 3.724s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 64: 4.788s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 65: 4.005s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 66: 3.956s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 67: 4.113s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 68: 4.013s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 69: 4.510s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 70: 5.405s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 71: 4.227s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 72: 4.248s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 73: 3.845s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 74: 4.499s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 75: 4.087s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 76: 4.155s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 77: 4.343s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 78: 4.119s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 79: 3.919s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 80: 4.094s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m TRAINING TIME STATISTICS
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Total training steps: 80
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Total training time: 355.73 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Average time per step: 4.447 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Fastest step: 3.665 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Slowest step: 8.927 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Time variance: 5.262 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Step time distribution:
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 1: 8.927s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 2: 4.381s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 3: 5.198s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 4: 4.212s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 5: 5.193s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 6: 3.979s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 7: 4.266s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 8: 4.118s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 9: 4.239s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 10: 5.106s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 11: 4.139s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 12: 4.166s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 13: 4.013s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 14: 5.385s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 15: 4.102s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 16: 4.677s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 17: 4.843s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 18: 4.388s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 19: 4.068s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 20: 4.117s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 21: 4.612s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 22: 4.106s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 23: 5.041s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 24: 4.113s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 25: 5.998s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 26: 4.386s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 27: 4.260s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 28: 4.125s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 29: 4.020s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 30: 3.956s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 31: 4.151s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 32: 4.855s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 33: 5.133s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 34: 4.277s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 35: 4.470s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 36: 4.392s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 37: 4.699s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 38: 4.590s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 39: 3.665s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 40: 4.081s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 41: 3.911s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 42: 4.119s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 43: 5.474s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 44: 4.394s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 45: 4.421s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 46: 4.100s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 47: 3.896s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 48: 4.207s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 49: 5.134s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 50: 5.053s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 51: 4.104s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 52: 4.133s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 53: 4.432s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 54: 4.348s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 55: 4.587s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 56: 3.896s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 57: 5.357s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 58: 4.468s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 59: 4.356s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 60: 4.558s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 61: 4.195s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 62: 4.144s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 63: 3.874s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 64: 4.790s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 65: 4.006s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 66: 3.960s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 67: 4.115s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 68: 4.017s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 69: 4.555s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 70: 5.407s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 71: 4.099s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 72: 4.300s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 73: 3.911s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 74: 4.364s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 75: 4.091s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 76: 4.158s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 77: 4.345s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 78: 4.122s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 79: 3.922s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 80: 3.964s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m TRAINING TIME STATISTICS
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Total training steps: 80
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Total training time: 355.64 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Average time per step: 4.445 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Fastest step: 3.665 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Slowest step: 8.933 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Time variance: 5.268 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Step time distribution:
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 1: 8.933s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 2: 4.380s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 3: 5.223s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 4: 4.204s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 5: 5.143s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 6: 3.856s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 7: 4.201s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 8: 4.117s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 9: 4.335s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 10: 5.105s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 11: 4.140s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 12: 4.167s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 13: 4.013s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 14: 5.387s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 15: 4.102s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 16: 4.678s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 17: 4.821s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 18: 4.389s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 19: 4.131s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 20: 4.117s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 21: 4.695s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 22: 4.108s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 23: 5.040s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 24: 4.111s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 25: 5.384s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 26: 4.472s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 27: 4.264s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 28: 4.158s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 29: 4.022s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 30: 4.104s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 31: 4.279s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 32: 4.830s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 33: 5.200s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 34: 4.749s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 35: 4.351s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 36: 4.485s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 37: 4.598s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 38: 4.590s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 39: 3.665s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 40: 4.173s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 41: 3.909s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 42: 4.064s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 43: 5.443s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 44: 4.397s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 45: 4.440s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 46: 4.020s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 47: 3.986s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 48: 4.208s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 49: 5.045s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 50: 4.931s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 51: 4.103s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 52: 4.133s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 53: 4.431s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 54: 4.347s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 55: 4.589s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 56: 3.812s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 57: 5.364s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 58: 4.469s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 59: 4.308s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 60: 4.446s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 61: 4.194s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 62: 4.015s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 63: 3.873s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 64: 4.816s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 65: 4.007s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 66: 3.833s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 67: 4.113s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 68: 4.013s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 69: 4.552s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 70: 5.439s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 71: 4.229s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 72: 4.300s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 73: 3.995s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 74: 4.366s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 75: 4.089s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 76: 4.156s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 77: 4.344s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 78: 4.122s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 79: 3.921s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 80: 4.096s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m TRAINING TIME STATISTICS
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Total training steps: 80
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Total training time: 354.43 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Average time per step: 4.430 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Fastest step: 3.661 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Slowest step: 7.851 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Time variance: 4.190 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Step time distribution:
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 1: 7.851s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 2: 4.382s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 3: 5.202s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 4: 4.202s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 5: 5.225s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 6: 3.978s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 7: 4.264s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 8: 4.116s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 9: 4.126s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 10: 5.106s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 11: 4.139s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 12: 4.165s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 13: 4.012s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 14: 5.385s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 15: 4.101s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 16: 5.178s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 17: 4.769s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 18: 4.388s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 19: 4.077s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 20: 4.115s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 21: 4.717s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 22: 4.105s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 23: 5.041s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 24: 4.110s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 25: 5.338s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 26: 4.470s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 27: 4.260s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 28: 4.155s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 29: 3.870s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 30: 4.103s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 31: 4.251s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 32: 4.830s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 33: 5.233s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 34: 4.279s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 35: 4.464s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 36: 4.483s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 37: 4.698s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 38: 4.545s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 39: 3.661s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 40: 4.169s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 41: 3.817s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================  Step 42: 4.184s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 43: 5.441s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 44: 4.394s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 45: 4.425s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m TRAINING TIME STATISTICS  Step 46: 4.101s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 47: 3.983s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 48: 4.204sTotal training steps: 80
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 49: 5.123s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 50: 5.058s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 51: 3.979s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 52: 4.130s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 53: 4.431s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 54: 4.260s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 55: 4.589s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 56: 3.896s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 57: 5.362s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 58: 4.469sTotal training time: 355.19 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 59: 4.352s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Average time per step: 4.440 seconds  Step 60: 4.551s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Fastest step: 3.661 seconds  Step 61: 4.047s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 62: 4.139s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Slowest step: 8.943 seconds  Step 63: 3.870s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 64: 4.691s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Time variance: 5.282 seconds  Step 65: 4.001s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Step time distribution:  Step 66: 3.873s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m TRAINING TIME STATISTICS
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================  Step 67: 4.115s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 1: 8.943s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 68: 3.967s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Total training steps: 80  Step 2: 4.294s  Step 69: 4.553s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 3: 5.199s  Step 70: 5.408s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 4: 4.130s  Step 71: 4.229s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 5: 5.195s  Step 72: 4.301s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 6: 3.975s  Step 73: 3.983s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 7: 4.264s  Step 74: 4.477s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Total training time: 355.54 seconds  Step 8: 4.115s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 75: 3.947s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Average time per step: 4.444 seconds  Step 9: 4.250s  Step 76: 4.153s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Fastest step: 3.662 seconds  Step 10: 5.106s  Step 77: 4.259s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 11: 4.527sSlowest step: 8.946 seconds  Step 78: 4.093s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 12: 4.164s  Step 79: 3.922sTime variance: 5.285 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 13: 3.887s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 80: 4.094s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Step time distribution:  Step 14: 5.418s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================  Step 15: 4.008s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 1: 8.946sTRAINING TIME STATISTICS
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================  Step 16: 4.679s  Step 2: 4.380s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 17: 4.818s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 3: 5.200sTotal training steps: 80
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 18: 4.385s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 4: 4.198s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 19: 4.044s  Step 5: 5.152s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 20: 4.114s  Step 6: 3.977s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 21: 4.652s  Step 7: 4.260s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 22: 4.104s  Step 8: 4.116s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 23: 5.041s  Step 9: 4.260s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Total training time: 355.81 seconds  Step 24: 4.076s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 10: 5.104s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 25: 5.335sAverage time per step: 4.448 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 11: 4.137s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 26: 4.380sFastest step: 3.663 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 12: 4.163s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 27: 4.255s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 13: 4.010sSlowest step: 8.932 seconds  Step 28: 4.156s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 14: 5.385s  Step 29: 4.017sTime variance: 5.269 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 15: 4.099s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Step time distribution:
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 30: 4.100s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 16: 4.677s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 31: 4.263s  Step 17: 4.822s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 1: 8.932s  Step 32: 4.828s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 18: 4.385s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 2: 4.380s  Step 33: 5.233s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 19: 4.127s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 3: 5.198s  Step 34: 4.279s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 20: 4.112s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 4: 4.201s  Step 35: 4.466s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 21: 4.694s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 5: 5.195s  Step 36: 4.391s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 22: 4.495s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 6: 3.980s  Step 37: 4.698s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 23: 5.041s  Step 7: 4.266s  Step 38: 4.587s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 24: 4.110s  Step 39: 3.661s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 8: 4.119s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 25: 5.337s  Step 40: 4.174s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 9: 4.232s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 26: 4.468s  Step 41: 3.907s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 10: 5.699s  Step 27: 4.200s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 42: 4.184s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 11: 4.140s  Step 28: 4.156s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 43: 5.443s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 12: 4.077s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 29: 4.018s  Step 44: 4.394s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 13: 4.012s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 30: 4.100s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 45: 4.440s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 14: 5.257s  Step 31: 4.165s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 46: 4.100s  Step 15: 4.099s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 32: 4.778s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 47: 3.838s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 16: 4.695s  Step 33: 5.263s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 48: 4.203s  Step 17: 4.825s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 34: 4.281s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 49: 5.135s  Step 18: 4.388s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 35: 4.468s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 50: 5.055s  Step 19: 4.127s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 36: 4.485s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 51: 3.953s  Step 20: 4.030s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 37: 4.700s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 52: 4.131s  Step 21: 4.694s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 38: 4.537s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 53: 4.388s  Step 22: 4.103s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 39: 3.662s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 54: 4.345s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 23: 5.041s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 40: 4.171s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 55: 4.589s  Step 24: 3.978s  Step 41: 3.779s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 56: 3.897s  Step 25: 5.208s  Step 42: 4.182s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 57: 5.362s  Step 26: 4.469s  Step 43: 5.400s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 58: 4.467s  Step 27: 4.134s  Step 44: 4.313s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 59: 4.311s  Step 28: 4.157s  Step 45: 4.440s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 60: 4.559s  Step 29: 4.021s  Step 46: 4.004s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 61: 4.195s  Step 30: 4.100s  Step 47: 3.984s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 62: 4.003s  Step 31: 4.176s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 48: 4.201s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 63: 3.871s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 32: 4.788s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 49: 5.091s  Step 64: 4.790s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 33: 5.231s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 50: 5.056s  Step 65: 3.908s  Step 34: 4.281s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 51: 4.099s  Step 66: 3.811s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 35: 4.467s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 52: 4.009s  Step 67: 4.114s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 36: 4.484s  Step 53: 4.430s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 68: 4.014s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 37: 4.701s  Step 54: 4.346s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 69: 4.553s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 38: 4.590s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 55: 4.589s  Step 70: 5.407s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 39: 3.663s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 56: 3.896s  Step 71: 4.230s  Step 40: 4.176s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 57: 5.357s  Step 72: 4.203s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 41: 3.906s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 58: 4.468s  Step 73: 3.985s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 42: 4.184s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 59: 4.351s  Step 74: 4.478s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 43: 5.440s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 60: 4.515s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 75: 4.089s  Step 44: 4.393s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 61: 4.192s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 76: 4.154s  Step 45: 4.433s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 62: 4.135s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 77: 4.343s  Step 46: 4.012s  Step 63: 3.870s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 47: 3.984s  Step 78: 4.120s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 64: 4.790s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 48: 4.110s  Step 79: 3.923s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 65: 3.999s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 49: 5.132s  Step 80: 4.092s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 66: 3.957s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 50: 5.056s============================================================  Step 67: 4.112s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 51: 4.102s  Step 68: 3.923s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 52: 4.131s  Step 69: 4.577s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 53: 4.431s  Step 70: 5.364s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 54: 4.346s  Step 71: 4.229s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 55: 4.588s  Step 72: 4.300s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 56: 3.900s  Step 73: 3.982s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 57: 5.354s  Step 74: 4.478s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 58: 4.466s  Step 75: 3.938s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 59: 4.353s  Step 76: 4.154s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 60: 4.558s  Step 77: 4.343s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 61: 4.193s  Step 78: 4.118s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 62: 4.141s  Step 79: 3.834s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 63: 3.873s  Step 80: 4.093s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 64: 4.789s============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 65: 3.999s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 66: 3.957s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 67: 4.113s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 68: 4.013s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 69: 4.511s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 70: 5.406s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 71: 4.229s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 72: 4.299s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 73: 3.984s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 74: 4.477s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 75: 3.999s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 76: 4.156s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 77: 4.339s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 78: 4.122s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 79: 3.921s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 80: 4.095s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m TRAINING TIME STATISTICS
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Total training steps: 80
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Total training time: 355.56 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Average time per step: 4.444 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Fastest step: 3.664 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Slowest step: 8.934 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Time variance: 5.270 seconds
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m 
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m Step time distribution:
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 1: 8.934s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 2: 4.384s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 3: 5.199s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 4: 4.205s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 5: 5.147s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 6: 3.983s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 7: 4.265s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 8: 4.117s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 9: 4.698s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 10: 5.106s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 11: 4.140s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 12: 4.164s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 13: 4.013s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 14: 5.386s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 15: 4.102s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 16: 4.679s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 17: 4.786s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 18: 4.389s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 19: 4.129s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 20: 4.028s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 21: 4.655s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 22: 4.105s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 23: 5.041s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 24: 4.109s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 25: 5.347s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 26: 4.473s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 27: 4.140s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 28: 4.073s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 29: 3.934s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 30: 4.104s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 31: 4.276s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 32: 4.832s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 33: 5.234s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 34: 4.285s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 35: 4.470s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 36: 4.486s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 37: 4.602s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 38: 4.591s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 39: 3.664s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 40: 4.173s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 41: 3.908s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 42: 4.187s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 43: 5.441s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 44: 4.308s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 45: 4.439s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 46: 3.963s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 47: 3.984s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 48: 4.204s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 49: 5.138s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 50: 5.055s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 51: 4.013s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 52: 4.130s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 53: 4.432s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 54: 4.250s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 55: 4.589s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 56: 3.899s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 57: 5.307s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 58: 4.465s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 59: 4.360s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 60: 4.560s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 61: 4.144s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 62: 4.143s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 63: 3.875s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 64: 4.750s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 65: 4.002s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 66: 3.811s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 67: 4.116s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 68: 4.017s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 69: 4.554s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 70: 5.408s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 71: 4.233s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 72: 4.302s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 73: 3.996s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 74: 4.481s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 75: 4.090s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 76: 4.064s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 77: 4.354s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 78: 4.121s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 79: 3.922s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m   Step 80: 4.095s
[36m(worker1, rank=1, pid=2318, ip=10.113.50.48)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m 100%|██████████| 10/10 [06:35<00:00, 38.41s/it]
                                               
{'train_runtime': 706.4241, 'train_samples_per_second': 1.812, 'train_steps_per_second': 0.014, 'train_loss': 124.44921875, 'epoch': 0.03}
[36m(head, rank=0, pid=3097)[0m 
100%|██████████| 10/10 [11:46<00:00, 38.41s/it]
100%|██████████| 10/10 [11:46<00:00, 70.64s/it]
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m TRAINING TIME STATISTICS
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m Total training steps: 80
[36m(head, rank=0, pid=3097)[0m Total training time: 354.44 seconds
[36m(head, rank=0, pid=3097)[0m Average time per step: 4.431 seconds
[36m(head, rank=0, pid=3097)[0m Fastest step: 3.665 seconds
[36m(head, rank=0, pid=3097)[0m Slowest step: 7.913 seconds
[36m(head, rank=0, pid=3097)[0m Time variance: 4.249 seconds
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m Step time distribution:
[36m(head, rank=0, pid=3097)[0m   Step 1: 7.913s
[36m(head, rank=0, pid=3097)[0m   Step 2: 4.291s
[36m(head, rank=0, pid=3097)[0m   Step 3: 5.198s
[36m(head, rank=0, pid=3097)[0m   Step 4: 4.205s
[36m(head, rank=0, pid=3097)[0m   Step 5: 5.193s
[36m(head, rank=0, pid=3097)[0m   Step 6: 3.978s
[36m(head, rank=0, pid=3097)[0m   Step 7: 4.116s
[36m(head, rank=0, pid=3097)[0m   Step 8: 4.116s
[36m(head, rank=0, pid=3097)[0m   Step 9: 4.229s
[36m(head, rank=0, pid=3097)[0m   Step 10: 5.132s
[36m(head, rank=0, pid=3097)[0m   Step 11: 4.141s
[36m(head, rank=0, pid=3097)[0m   Step 12: 4.166s
[36m(head, rank=0, pid=3097)[0m   Step 13: 4.014s
[36m(head, rank=0, pid=3097)[0m   Step 14: 5.385s
[36m(head, rank=0, pid=3097)[0m   Step 15: 4.103s
[36m(head, rank=0, pid=3097)[0m   Step 16: 4.678s
[36m(head, rank=0, pid=3097)[0m   Step 17: 4.815s
[36m(head, rank=0, pid=3097)[0m   Step 18: 4.389s
[36m(head, rank=0, pid=3097)[0m   Step 19: 4.008s
[36m(head, rank=0, pid=3097)[0m   Step 20: 4.117s
[36m(head, rank=0, pid=3097)[0m   Step 21: 4.697s
[36m(head, rank=0, pid=3097)[0m   Step 22: 4.106s
[36m(head, rank=0, pid=3097)[0m   Step 23: 5.041s
[36m(head, rank=0, pid=3097)[0m   Step 24: 4.112s
[36m(head, rank=0, pid=3097)[0m   Step 25: 5.342s
[36m(head, rank=0, pid=3097)[0m   Step 26: 4.377s
[36m(head, rank=0, pid=3097)[0m   Step 27: 4.263s
[36m(head, rank=0, pid=3097)[0m   Step 28: 4.157s
[36m(head, rank=0, pid=3097)[0m   Step 29: 4.020s
[36m(head, rank=0, pid=3097)[0m   Step 30: 4.102s
[36m(head, rank=0, pid=3097)[0m   Step 31: 4.275s
[36m(head, rank=0, pid=3097)[0m   Step 32: 4.826s
[36m(head, rank=0, pid=3097)[0m   Step 33: 5.182s
[36m(head, rank=0, pid=3097)[0m   Step 34: 4.281s
[36m(head, rank=0, pid=3097)[0m   Step 35: 4.468s
[36m(head, rank=0, pid=3097)[0m   Step 36: 4.485s
[36m(head, rank=0, pid=3097)[0m   Step 37: 4.700s
[36m(head, rank=0, pid=3097)[0m   Step 38: 4.589s
[36m(head, rank=0, pid=3097)[0m   Step 39: 3.665s
[36m(head, rank=0, pid=3097)[0m   Step 40: 4.174s
[36m(head, rank=0, pid=3097)[0m   Step 41: 3.908s
[36m(head, rank=0, pid=3097)[0m   Step 42: 4.041s
[36m(head, rank=0, pid=3097)[0m   Step 43: 5.442s
[36m(head, rank=0, pid=3097)[0m   Step 44: 4.395s
[36m(head, rank=0, pid=3097)[0m   Step 45: 4.401s
[36m(head, rank=0, pid=3097)[0m   Step 46: 4.100s
[36m(head, rank=0, pid=3097)[0m   Step 47: 3.985s
[36m(head, rank=0, pid=3097)[0m   Step 48: 4.205s
[36m(head, rank=0, pid=3097)[0m   Step 49: 5.137s
[36m(head, rank=0, pid=3097)[0m   Step 50: 5.054s
[36m(head, rank=0, pid=3097)[0m   Step 51: 4.102s
[36m(head, rank=0, pid=3097)[0m   Step 52: 4.132s
[36m(head, rank=0, pid=3097)[0m   Step 53: 4.431s
[36m(head, rank=0, pid=3097)[0m   Step 54: 4.347s
[36m(head, rank=0, pid=3097)[0m   Step 55: 4.613s
[36m(head, rank=0, pid=3097)[0m   Step 56: 3.899s
[36m(head, rank=0, pid=3097)[0m   Step 57: 5.354s
[36m(head, rank=0, pid=3097)[0m   Step 58: 4.467s
[36m(head, rank=0, pid=3097)[0m   Step 59: 4.356s
[36m(head, rank=0, pid=3097)[0m   Step 60: 4.573s
[36m(head, rank=0, pid=3097)[0m   Step 61: 4.192s
[36m(head, rank=0, pid=3097)[0m   Step 62: 4.140s
[36m(head, rank=0, pid=3097)[0m   Step 63: 3.870s
[36m(head, rank=0, pid=3097)[0m   Step 64: 4.787s
[36m(head, rank=0, pid=3097)[0m   Step 65: 4.005s
[36m(head, rank=0, pid=3097)[0m   Step 66: 3.957s
[36m(head, rank=0, pid=3097)[0m   Step 67: 4.114s
[36m(head, rank=0, pid=3097)[0m   Step 68: 3.882s
[36m(head, rank=0, pid=3097)[0m   Step 69: 4.554s
[36m(head, rank=0, pid=3097)[0m   Step 70: 5.407s
[36m(head, rank=0, pid=3097)[0m   Step 71: 4.230s
[36m(head, rank=0, pid=3097)[0m   Step 72: 4.302s
[36m(head, rank=0, pid=3097)[0m   Step 73: 3.851s
[36m(head, rank=0, pid=3097)[0m   Step 74: 4.438s
[36m(head, rank=0, pid=3097)[0m   Step 75: 4.088s
[36m(head, rank=0, pid=3097)[0m   Step 76: 4.158s
[36m(head, rank=0, pid=3097)[0m   Step 77: 4.344s
[36m(head, rank=0, pid=3097)[0m   Step 78: 4.122s
[36m(head, rank=0, pid=3097)[0m   Step 79: 3.920s
[36m(head, rank=0, pid=3097)[0m   Step 80: 4.095s
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m TRAINING TIME STATISTICS
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m Total training steps: 80
[36m(head, rank=0, pid=3097)[0m Total training time: 354.95 seconds
[36m(head, rank=0, pid=3097)[0m Average time per step: 4.437 seconds
[36m(head, rank=0, pid=3097)[0m Fastest step: 3.663 seconds
[36m(head, rank=0, pid=3097)[0m Slowest step: 8.945 seconds
[36m(head, rank=0, pid=3097)[0m Time variance: 5.283 seconds
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m Step time distribution:
[36m(head, rank=0, pid=3097)[0m   Step 1: 8.945s
[36m(head, rank=0, pid=3097)[0m   Step 2: 4.378s
[36m(head, rank=0, pid=3097)[0m   Step 3: 5.197s
[36m(head, rank=0, pid=3097)[0m   Step 4: 4.201s
[36m(head, rank=0, pid=3097)[0m   Step 5: 5.194s
[36m(head, rank=0, pid=3097)[0m   Step 6: 3.979s
[36m(head, rank=0, pid=3097)[0m   Step 7: 4.263s
[36m(head, rank=0, pid=3097)[0m   Step 8: 4.508s
[36m(head, rank=0, pid=3097)[0m   Step 9: 4.268s
[36m(head, rank=0, pid=3097)[0m   Step 10: 5.015s
[36m(head, rank=0, pid=3097)[0m   Step 11: 4.136s
[36m(head, rank=0, pid=3097)[0m   Step 12: 4.016s
[36m(head, rank=0, pid=3097)[0m   Step 13: 4.011s
[36m(head, rank=0, pid=3097)[0m   Step 14: 5.384s
[36m(head, rank=0, pid=3097)[0m   Step 15: 4.099s
[36m(head, rank=0, pid=3097)[0m   Step 16: 4.634s
[36m(head, rank=0, pid=3097)[0m   Step 17: 4.811s
[36m(head, rank=0, pid=3097)[0m   Step 18: 4.350s
[36m(head, rank=0, pid=3097)[0m   Step 19: 4.127s
[36m(head, rank=0, pid=3097)[0m   Step 20: 4.115s
[36m(head, rank=0, pid=3097)[0m   Step 21: 4.695s
[36m(head, rank=0, pid=3097)[0m   Step 22: 4.103s
[36m(head, rank=0, pid=3097)[0m   Step 23: 5.040s
[36m(head, rank=0, pid=3097)[0m   Step 24: 4.107s
[36m(head, rank=0, pid=3097)[0m   Step 25: 5.339s
[36m(head, rank=0, pid=3097)[0m   Step 26: 4.468s
[36m(head, rank=0, pid=3097)[0m   Step 27: 4.135s
[36m(head, rank=0, pid=3097)[0m   Step 28: 4.034s
[36m(head, rank=0, pid=3097)[0m   Step 29: 4.019s
[36m(head, rank=0, pid=3097)[0m   Step 30: 4.102s
[36m(head, rank=0, pid=3097)[0m   Step 31: 4.272s
[36m(head, rank=0, pid=3097)[0m   Step 32: 4.829s
[36m(head, rank=0, pid=3097)[0m   Step 33: 5.231s
[36m(head, rank=0, pid=3097)[0m   Step 34: 4.280s
[36m(head, rank=0, pid=3097)[0m   Step 35: 4.320s
[36m(head, rank=0, pid=3097)[0m   Step 36: 4.484s
[36m(head, rank=0, pid=3097)[0m   Step 37: 4.598s
[36m(head, rank=0, pid=3097)[0m   Step 38: 4.589s
[36m(head, rank=0, pid=3097)[0m   Step 39: 3.663s
[36m(head, rank=0, pid=3097)[0m   Step 40: 4.172s
[36m(head, rank=0, pid=3097)[0m   Step 41: 3.905s
[36m(head, rank=0, pid=3097)[0m   Step 42: 4.184s
[36m(head, rank=0, pid=3097)[0m   Step 43: 5.442s
[36m(head, rank=0, pid=3097)[0m   Step 44: 4.393s
[36m(head, rank=0, pid=3097)[0m   Step 45: 4.395s
[36m(head, rank=0, pid=3097)[0m   Step 46: 4.099s
[36m(head, rank=0, pid=3097)[0m   Step 47: 3.900s
[36m(head, rank=0, pid=3097)[0m   Step 48: 4.139s
[36m(head, rank=0, pid=3097)[0m   Step 49: 5.093s
[36m(head, rank=0, pid=3097)[0m   Step 50: 5.054s
[36m(head, rank=0, pid=3097)[0m   Step 51: 4.100s
[36m(head, rank=0, pid=3097)[0m   Step 52: 4.003s
[36m(head, rank=0, pid=3097)[0m   Step 53: 4.431s
[36m(head, rank=0, pid=3097)[0m   Step 54: 4.261s
[36m(head, rank=0, pid=3097)[0m   Step 55: 4.589s
[36m(head, rank=0, pid=3097)[0m   Step 56: 3.897s
[36m(head, rank=0, pid=3097)[0m   Step 57: 5.359s
[36m(head, rank=0, pid=3097)[0m   Step 58: 4.464s
[36m(head, rank=0, pid=3097)[0m   Step 59: 4.343s
[36m(head, rank=0, pid=3097)[0m   Step 60: 4.556s
[36m(head, rank=0, pid=3097)[0m   Step 61: 4.188s
[36m(head, rank=0, pid=3097)[0m   Step 62: 4.137s
[36m(head, rank=0, pid=3097)[0m   Step 63: 3.868s
[36m(head, rank=0, pid=3097)[0m   Step 64: 4.669s
[36m(head, rank=0, pid=3097)[0m   Step 65: 4.004s
[36m(head, rank=0, pid=3097)[0m   Step 66: 3.957s
[36m(head, rank=0, pid=3097)[0m   Step 67: 3.964s
[36m(head, rank=0, pid=3097)[0m   Step 68: 4.013s
[36m(head, rank=0, pid=3097)[0m   Step 69: 4.553s
[36m(head, rank=0, pid=3097)[0m   Step 70: 5.407s
[36m(head, rank=0, pid=3097)[0m   Step 71: 4.230s
[36m(head, rank=0, pid=3097)[0m   Step 72: 4.301s
[36m(head, rank=0, pid=3097)[0m   Step 73: 3.991s
[36m(head, rank=0, pid=3097)[0m   Step 74: 4.479s
[36m(head, rank=0, pid=3097)[0m   Step 75: 4.087s
[36m(head, rank=0, pid=3097)[0m   Step 76: 4.156s
[36m(head, rank=0, pid=3097)[0m   Step 77: 4.344s
[36m(head, rank=0, pid=3097)[0m   Step 78: 3.999s
[36m(head, rank=0, pid=3097)[0m   Step 79: 3.918s
[36m(head, rank=0, pid=3097)[0m   Step 80: 3.961s
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m TRAINING TIME STATISTICS
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m Total training steps: 80
[36m(head, rank=0, pid=3097)[0m Total training time: 355.33 seconds
[36m(head, rank=0, pid=3097)[0m Average time per step: 4.442 seconds
[36m(head, rank=0, pid=3097)[0m Fastest step: 3.665 seconds
[36m(head, rank=0, pid=3097)[0m Slowest step: 8.941 seconds
[36m(head, rank=0, pid=3097)[0m Time variance: 5.276 seconds
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m Step time distribution:
[36m(head, rank=0, pid=3097)[0m   Step 1: 8.941s
[36m(head, rank=0, pid=3097)[0m   Step 2: 4.380s
[36m(head, rank=0, pid=3097)[0m   Step 3: 5.199s
[36m(head, rank=0, pid=3097)[0m   Step 4: 4.205s
[36m(head, rank=0, pid=3097)[0m   Step 5: 5.196s
[36m(head, rank=0, pid=3097)[0m   Step 6: 3.979s
[36m(head, rank=0, pid=3097)[0m   Step 7: 4.268s
[36m(head, rank=0, pid=3097)[0m   Step 8: 3.993s
[36m(head, rank=0, pid=3097)[0m   Step 9: 4.223s
[36m(head, rank=0, pid=3097)[0m   Step 10: 5.699s
[36m(head, rank=0, pid=3097)[0m   Step 11: 4.043s
[36m(head, rank=0, pid=3097)[0m   Step 12: 4.018s
[36m(head, rank=0, pid=3097)[0m   Step 13: 4.016s
[36m(head, rank=0, pid=3097)[0m   Step 14: 5.386s
[36m(head, rank=0, pid=3097)[0m   Step 15: 4.101s
[36m(head, rank=0, pid=3097)[0m   Step 16: 4.679s
[36m(head, rank=0, pid=3097)[0m   Step 17: 4.815s
[36m(head, rank=0, pid=3097)[0m   Step 18: 4.386s
[36m(head, rank=0, pid=3097)[0m   Step 19: 4.134s
[36m(head, rank=0, pid=3097)[0m   Step 20: 4.113s
[36m(head, rank=0, pid=3097)[0m   Step 21: 4.693s
[36m(head, rank=0, pid=3097)[0m   Step 22: 3.975s
[36m(head, rank=0, pid=3097)[0m   Step 23: 5.041s
[36m(head, rank=0, pid=3097)[0m   Step 24: 4.111s
[36m(head, rank=0, pid=3097)[0m   Step 25: 5.345s
[36m(head, rank=0, pid=3097)[0m   Step 26: 4.472s
[36m(head, rank=0, pid=3097)[0m   Step 27: 4.265s
[36m(head, rank=0, pid=3097)[0m   Step 28: 4.156s
[36m(head, rank=0, pid=3097)[0m   Step 29: 4.019s
[36m(head, rank=0, pid=3097)[0m   Step 30: 4.099s
[36m(head, rank=0, pid=3097)[0m   Step 31: 4.164s
[36m(head, rank=0, pid=3097)[0m   Step 32: 4.831s
[36m(head, rank=0, pid=3097)[0m   Step 33: 5.189s
[36m(head, rank=0, pid=3097)[0m   Step 34: 4.280s
[36m(head, rank=0, pid=3097)[0m   Step 35: 4.472s
[36m(head, rank=0, pid=3097)[0m   Step 36: 4.484s
[36m(head, rank=0, pid=3097)[0m   Step 37: 4.607s
[36m(head, rank=0, pid=3097)[0m   Step 38: 4.590s
[36m(head, rank=0, pid=3097)[0m   Step 39: 3.665s
[36m(head, rank=0, pid=3097)[0m   Step 40: 4.173s
[36m(head, rank=0, pid=3097)[0m   Step 41: 3.907s
[36m(head, rank=0, pid=3097)[0m   Step 42: 4.090s
[36m(head, rank=0, pid=3097)[0m   Step 43: 5.444s
[36m(head, rank=0, pid=3097)[0m   Step 44: 4.395s
[36m(head, rank=0, pid=3097)[0m   Step 45: 4.441s
[36m(head, rank=0, pid=3097)[0m   Step 46: 4.100s
[36m(head, rank=0, pid=3097)[0m   Step 47: 3.985s
[36m(head, rank=0, pid=3097)[0m   Step 48: 4.204s
[36m(head, rank=0, pid=3097)[0m   Step 49: 5.141s
[36m(head, rank=0, pid=3097)[0m   Step 50: 5.056s
[36m(head, rank=0, pid=3097)[0m   Step 51: 4.103s
[36m(head, rank=0, pid=3097)[0m   Step 52: 3.982s
[36m(head, rank=0, pid=3097)[0m   Step 53: 4.343s
[36m(head, rank=0, pid=3097)[0m   Step 54: 4.347s
[36m(head, rank=0, pid=3097)[0m   Step 55: 4.589s
[36m(head, rank=0, pid=3097)[0m   Step 56: 3.898s
[36m(head, rank=0, pid=3097)[0m   Step 57: 5.361s
[36m(head, rank=0, pid=3097)[0m   Step 58: 4.467s
[36m(head, rank=0, pid=3097)[0m   Step 59: 4.356s
[36m(head, rank=0, pid=3097)[0m   Step 60: 4.556s
[36m(head, rank=0, pid=3097)[0m   Step 61: 4.194s
[36m(head, rank=0, pid=3097)[0m   Step 62: 4.141s
[36m(head, rank=0, pid=3097)[0m   Step 63: 3.872s
[36m(head, rank=0, pid=3097)[0m   Step 64: 4.791s
[36m(head, rank=0, pid=3097)[0m   Step 65: 3.998s
[36m(head, rank=0, pid=3097)[0m   Step 66: 3.828s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m ============================================================  Step 67: 4.113s
[36m(head, rank=0, pid=3097)[0m   Step 68: 4.016s
[36m(head, rank=0, pid=3097)[0m   Step 69: 4.554s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 70: 5.299s
[36m(head, rank=0, pid=3097)[0m TRAINING TIME STATISTICS  Step 71: 4.229s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m ============================================================  Step 72: 4.207s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 73: 3.929s
[36m(head, rank=0, pid=3097)[0m Total training steps: 80  Step 74: 4.477s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 75: 3.999s
[36m(head, rank=0, pid=3097)[0m   Step 76: 4.158s
[36m(head, rank=0, pid=3097)[0m   Step 77: 4.343s
[36m(head, rank=0, pid=3097)[0m   Step 78: 4.119s
[36m(head, rank=0, pid=3097)[0m   Step 79: 3.919s
[36m(head, rank=0, pid=3097)[0m   Step 80: 3.975s
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m Total training time: 355.52 seconds
[36m(head, rank=0, pid=3097)[0m Average time per step: 4.444 seconds
[36m(head, rank=0, pid=3097)[0m Fastest step: 3.666 seconds
[36m(head, rank=0, pid=3097)[0m Slowest step: 8.945 seconds
[36m(head, rank=0, pid=3097)[0m Time variance: 5.279 seconds
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m Step time distribution:
[36m(head, rank=0, pid=3097)[0m   Step 1: 8.945s
[36m(head, rank=0, pid=3097)[0m   Step 2: 4.389s
[36m(head, rank=0, pid=3097)[0m   Step 3: 5.192s
[36m(head, rank=0, pid=3097)[0m   Step 4: 4.121s
[36m(head, rank=0, pid=3097)[0m   Step 5: 5.194s
[36m(head, rank=0, pid=3097)[0m   Step 6: 3.979s
[36m(head, rank=0, pid=3097)[0m   Step 7: 4.149s
[36m(head, rank=0, pid=3097)[0m   Step 8: 4.119s
[36m(head, rank=0, pid=3097)[0m   Step 9: 4.183s
[36m(head, rank=0, pid=3097)[0m   Step 10: 5.111s
[36m(head, rank=0, pid=3097)[0m   Step 11: 4.137s
[36m(head, rank=0, pid=3097)[0m   Step 12: 4.049s
[36m(head, rank=0, pid=3097)[0m   Step 13: 4.014s
[36m(head, rank=0, pid=3097)[0m   Step 14: 5.346s
[36m(head, rank=0, pid=3097)[0m   Step 15: 4.100s
[36m(head, rank=0, pid=3097)[0m   Step 16: 4.679s
[36m(head, rank=0, pid=3097)[0m   Step 17: 4.809s
[36m(head, rank=0, pid=3097)[0m   Step 18: 4.394s
[36m(head, rank=0, pid=3097)[0m   Step 19: 4.134s
[36m(head, rank=0, pid=3097)[0m   Step 20: 4.116s
[36m(head, rank=0, pid=3097)[0m   Step 21: 4.655s
[36m(head, rank=0, pid=3097)[0m   Step 22: 4.107s
[36m(head, rank=0, pid=3097)[0m   Step 23: 5.041s
[36m(head, rank=0, pid=3097)[0m   Step 24: 4.115s
[36m(head, rank=0, pid=3097)[0m   Step 25: 5.342s
[36m(head, rank=0, pid=3097)[0m   Step 26: 4.474s
[36m(head, rank=0, pid=3097)[0m   Step 27: 4.267s
[36m(head, rank=0, pid=3097)[0m   Step 28: 4.161s
[36m(head, rank=0, pid=3097)[0m   Step 29: 4.409s
[36m(head, rank=0, pid=3097)[0m   Step 30: 4.106s
[36m(head, rank=0, pid=3097)[0m   Step 31: 4.280s
[36m(head, rank=0, pid=3097)[0m   Step 32: 4.737s
[36m(head, rank=0, pid=3097)[0m   Step 33: 5.233s
[36m(head, rank=0, pid=3097)[0m   Step 34: 4.280s
[36m(head, rank=0, pid=3097)[0m   Step 35: 4.472s
[36m(head, rank=0, pid=3097)[0m   Step 36: 4.505s
[36m(head, rank=0, pid=3097)[0m   Step 37: 4.698s
[36m(head, rank=0, pid=3097)[0m   Step 38: 4.588s
[36m(head, rank=0, pid=3097)[0m   Step 39: 3.666s
[36m(head, rank=0, pid=3097)[0m   Step 40: 4.175s
[36m(head, rank=0, pid=3097)[0m   Step 41: 3.910s
[36m(head, rank=0, pid=3097)[0m   Step 42: 4.190s
[36m(head, rank=0, pid=3097)[0m   Step 43: 5.445s
[36m(head, rank=0, pid=3097)[0m   Step 44: 4.397s
[36m(head, rank=0, pid=3097)[0m   Step 45: 4.439s
[36m(head, rank=0, pid=3097)[0m   Step 46: 4.103s
[36m(head, rank=0, pid=3097)[0m   Step 47: 3.986s
[36m(head, rank=0, pid=3097)[0m   Step 48: 4.210s
[36m(head, rank=0, pid=3097)[0m   Step 49: 5.011s
[36m(head, rank=0, pid=3097)[0m   Step 50: 5.016s
[36m(head, rank=0, pid=3097)[0m   Step 51: 4.104s
[36m(head, rank=0, pid=3097)[0m   Step 52: 4.134s
[36m(head, rank=0, pid=3097)[0m   Step 53: 4.432s
[36m(head, rank=0, pid=3097)[0m   Step 54: 4.348s
[36m(head, rank=0, pid=3097)[0m   Step 55: 4.588s
[36m(head, rank=0, pid=3097)[0m   Step 56: 3.899s
[36m(head, rank=0, pid=3097)[0m   Step 57: 5.312s
[36m(head, rank=0, pid=3097)[0m   Step 58: 4.375s
[36m(head, rank=0, pid=3097)[0m   Step 59: 4.360s
[36m(head, rank=0, pid=3097)[0m   Step 60: 4.444s
[36m(head, rank=0, pid=3097)[0m   Step 61: 4.195s
[36m(head, rank=0, pid=3097)[0m   Step 62: 4.145s
[36m(head, rank=0, pid=3097)[0m   Step 63: 3.873s
[36m(head, rank=0, pid=3097)[0m   Step 64: 4.692s
[36m(head, rank=0, pid=3097)[0m   Step 65: 3.997s
[36m(head, rank=0, pid=3097)[0m   Step 66: 3.959s
[36m(head, rank=0, pid=3097)[0m   Step 67: 4.024s
[36m(head, rank=0, pid=3097)[0m   Step 68: 4.016s
[36m(head, rank=0, pid=3097)[0m   Step 69: 4.552s
[36m(head, rank=0, pid=3097)[0m   Step 70: 5.406s
[36m(head, rank=0, pid=3097)[0m   Step 71: 4.231s
[36m(head, rank=0, pid=3097)[0m   Step 72: 4.316s
[36m(head, rank=0, pid=3097)[0m   Step 73: 3.998s
[36m(head, rank=0, pid=3097)[0m   Step 74: 4.480s
[36m(head, rank=0, pid=3097)[0m   Step 75: 4.023s
[36m(head, rank=0, pid=3097)[0m   Step 76: 4.160s
[36m(head, rank=0, pid=3097)[0m   Step 77: 4.345s
[36m(head, rank=0, pid=3097)[0m   Step 78: 3.992s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m ============================================================  Step 79: 3.921s
[36m(head, rank=0, pid=3097)[0m   Step 80: 4.025s
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m TRAINING TIME STATISTICS
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m Total training steps: 80
[36m(head, rank=0, pid=3097)[0m Total training time: 354.58 seconds
[36m(head, rank=0, pid=3097)[0m Average time per step: 4.432 seconds
[36m(head, rank=0, pid=3097)[0m Fastest step: 3.662 seconds
[36m(head, rank=0, pid=3097)[0m Slowest step: 8.930 seconds
[36m(head, rank=0, pid=3097)[0m Time variance: 5.267 seconds
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m Step time distribution:
[36m(head, rank=0, pid=3097)[0m   Step 1: 8.930s
[36m(head, rank=0, pid=3097)[0m   Step 2: 4.380s
[36m(head, rank=0, pid=3097)[0m   Step 3: 5.197s
[36m(head, rank=0, pid=3097)[0m   Step 4: 4.202s
[36m(head, rank=0, pid=3097)[0m   Step 5: 5.195s
[36m(head, rank=0, pid=3097)[0m   Step 6: 3.978s
[36m(head, rank=0, pid=3097)[0m   Step 7: 4.263s
[36m(head, rank=0, pid=3097)[0m   Step 8: 4.000s
[36m(head, rank=0, pid=3097)[0m   Step 9: 4.247s
[36m(head, rank=0, pid=3097)[0m   Step 10: 5.106s
[36m(head, rank=0, pid=3097)[0m   Step 11: 4.139s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m ============================================================  Step 12: 4.165s
[36m(head, rank=0, pid=3097)[0m   Step 13: 4.011s
[36m(head, rank=0, pid=3097)[0m   Step 14: 5.332s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 15: 4.004s
[36m(head, rank=0, pid=3097)[0m TRAINING TIME STATISTICS
[36m(head, rank=0, pid=3097)[0m   Step 16: 4.677s
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m   Step 17: 4.821s
[36m(head, rank=0, pid=3097)[0m   Step 18: 4.383sTotal training steps: 80
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 19: 4.518s
[36m(head, rank=0, pid=3097)[0m   Step 20: 4.113s
[36m(head, rank=0, pid=3097)[0m   Step 21: 4.607s
[36m(head, rank=0, pid=3097)[0m   Step 22: 4.103s
[36m(head, rank=0, pid=3097)[0m   Step 23: 4.999s
[36m(head, rank=0, pid=3097)[0m   Step 24: 4.031s
[36m(head, rank=0, pid=3097)[0m   Step 25: 5.305s
[36m(head, rank=0, pid=3097)[0m   Step 26: 4.352s
[36m(head, rank=0, pid=3097)[0m   Step 27: 4.254s
[36m(head, rank=0, pid=3097)[0m Total training time: 355.12 seconds  Step 28: 4.079s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 29: 4.018sAverage time per step: 4.439 seconds
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 30: 4.071sFastest step: 3.662 seconds
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 31: 4.272s
[36m(head, rank=0, pid=3097)[0m   Step 32: 4.788sSlowest step: 8.940 seconds
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 33: 5.111s
[36m(head, rank=0, pid=3097)[0m Time variance: 5.278 seconds
[36m(head, rank=0, pid=3097)[0m   Step 34: 4.279s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m Step time distribution:
[36m(head, rank=0, pid=3097)[0m   Step 35: 4.466s
[36m(head, rank=0, pid=3097)[0m   Step 36: 4.483s
[36m(head, rank=0, pid=3097)[0m   Step 37: 4.723s  Step 1: 8.940s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 38: 4.590s
[36m(head, rank=0, pid=3097)[0m   Step 2: 4.300s  Step 39: 3.662s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 40: 4.171s
[36m(head, rank=0, pid=3097)[0m   Step 3: 5.197s
[36m(head, rank=0, pid=3097)[0m   Step 41: 3.906s
[36m(head, rank=0, pid=3097)[0m   Step 4: 4.203s
[36m(head, rank=0, pid=3097)[0m   Step 42: 4.185s
[36m(head, rank=0, pid=3097)[0m   Step 5: 5.194s
[36m(head, rank=0, pid=3097)[0m   Step 43: 5.444s  Step 6: 3.978s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 44: 4.395s  Step 7: 4.263s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 45: 4.349s  Step 8: 4.116s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 46: 4.098s  Step 9: 4.169s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 47: 3.984s  Step 10: 5.105s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 48: 4.202s  Step 11: 4.136s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 49: 5.175s  Step 12: 4.071s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 50: 4.944s  Step 13: 4.011s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 51: 4.101s  Step 14: 5.384s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 52: 4.128s  Step 15: 4.008s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 53: 4.322s  Step 16: 4.677s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 54: 4.217s  Step 17: 4.822s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 55: 4.589s  Step 18: 4.781s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 56: 3.897s  Step 19: 4.129s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 57: 5.367s  Step 20: 4.116s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 58: 4.354s  Step 21: 4.596s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 59: 4.354s  Step 22: 4.101s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 60: 4.478s  Step 23: 4.930s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 61: 4.193s  Step 24: 4.108s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 62: 4.025s  Step 25: 5.341s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 63: 3.872s  Step 26: 4.358s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 64: 4.693s  Step 27: 4.257s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 65: 3.999s  Step 28: 4.156s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 66: 3.825s  Step 29: 4.018s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 67: 4.110s  Step 30: 4.099s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 68: 3.877s  Step 31: 4.272s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 69: 4.552s  Step 32: 4.830s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 70: 5.405s  Step 33: 5.236s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 71: 4.142s  Step 34: 4.189s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 72: 4.191s  Step 35: 4.469s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 73: 3.989s  Step 36: 4.484s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 74: 4.479s  Step 37: 4.699s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 75: 4.087s  Step 38: 4.489s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 76: 4.154s  Step 39: 3.662s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 77: 4.341s  Step 40: 4.172s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 78: 4.116s  Step 41: 3.908s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 79: 3.918s  Step 42: 4.062s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 80: 4.092s  Step 43: 5.401s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m ============================================================  Step 44: 4.249s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 45: 4.440s
[36m(head, rank=0, pid=3097)[0m   Step 46: 4.099s
[36m(head, rank=0, pid=3097)[0m   Step 47: 3.984s
[36m(head, rank=0, pid=3097)[0m   Step 48: 4.203s
[36m(head, rank=0, pid=3097)[0m   Step 49: 5.136s
[36m(head, rank=0, pid=3097)[0m   Step 50: 5.053s
[36m(head, rank=0, pid=3097)[0m   Step 51: 4.098s
[36m(head, rank=0, pid=3097)[0m   Step 52: 4.128s
[36m(head, rank=0, pid=3097)[0m   Step 53: 4.428s
[36m(head, rank=0, pid=3097)[0m   Step 54: 4.286s
[36m(head, rank=0, pid=3097)[0m   Step 55: 4.589s
[36m(head, rank=0, pid=3097)[0m   Step 56: 3.750s
[36m(head, rank=0, pid=3097)[0m   Step 57: 5.360s
[36m(head, rank=0, pid=3097)[0m   Step 58: 4.486s
[36m(head, rank=0, pid=3097)[0m   Step 59: 4.351s
[36m(head, rank=0, pid=3097)[0m   Step 60: 4.556s
[36m(head, rank=0, pid=3097)[0m   Step 61: 4.191s
[36m(head, rank=0, pid=3097)[0m   Step 62: 4.113s
[36m(head, rank=0, pid=3097)[0m   Step 63: 3.871s
[36m(head, rank=0, pid=3097)[0m   Step 64: 4.789s
[36m(head, rank=0, pid=3097)[0m   Step 65: 3.995s
[36m(head, rank=0, pid=3097)[0m   Step 66: 3.955s
[36m(head, rank=0, pid=3097)[0m   Step 67: 4.110s
[36m(head, rank=0, pid=3097)[0m   Step 68: 4.012s
[36m(head, rank=0, pid=3097)[0m   Step 69: 4.552s
[36m(head, rank=0, pid=3097)[0m   Step 70: 5.366s
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m   Step 71: 4.229s
[36m(head, rank=0, pid=3097)[0m   Step 72: 4.220s
[36m(head, rank=0, pid=3097)[0m   Step 73: 3.989s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 74: 4.479sTRAINING TIME STATISTICS
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 75: 3.998s============================================================
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 76: 4.152s
[36m(head, rank=0, pid=3097)[0m Total training steps: 80  Step 77: 4.340s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 78: 4.116s
[36m(head, rank=0, pid=3097)[0m   Step 79: 3.918s
[36m(head, rank=0, pid=3097)[0m   Step 80: 4.091s
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m Total training time: 355.88 seconds
[36m(head, rank=0, pid=3097)[0m Average time per step: 4.448 seconds
[36m(head, rank=0, pid=3097)[0m Fastest step: 3.664 seconds
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m Slowest step: 8.943 seconds
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m TRAINING TIME STATISTICSTime variance: 5.278 seconds
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m ============================================================
[36m(head, rank=0, pid=3097)[0m Step time distribution:
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m Total training steps: 80
[36m(head, rank=0, pid=3097)[0m   Step 1: 8.943s
[36m(head, rank=0, pid=3097)[0m   Step 2: 4.378s
[36m(head, rank=0, pid=3097)[0m   Step 3: 5.197s
[36m(head, rank=0, pid=3097)[0m   Step 4: 4.201s
[36m(head, rank=0, pid=3097)[0m   Step 5: 5.195s
[36m(head, rank=0, pid=3097)[0m   Step 6: 3.982sTotal training time: 355.84 seconds
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 7: 4.262sAverage time per step: 4.448 seconds
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 8: 4.116s
[36m(head, rank=0, pid=3097)[0m Fastest step: 3.662 seconds
[36m(head, rank=0, pid=3097)[0m   Step 9: 4.284s
[36m(head, rank=0, pid=3097)[0m Slowest step: 8.951 seconds
[36m(head, rank=0, pid=3097)[0m   Step 10: 5.105s
[36m(head, rank=0, pid=3097)[0m Time variance: 5.290 seconds  Step 11: 4.134s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m Step time distribution:  Step 12: 4.164s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 13: 4.012s
[36m(head, rank=0, pid=3097)[0m   Step 14: 5.343s
[36m(head, rank=0, pid=3097)[0m   Step 1: 8.951s
[36m(head, rank=0, pid=3097)[0m   Step 15: 4.099s
[36m(head, rank=0, pid=3097)[0m   Step 2: 4.772s
[36m(head, rank=0, pid=3097)[0m   Step 16: 4.678s
[36m(head, rank=0, pid=3097)[0m   Step 3: 5.198s  Step 17: 4.807s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 4: 4.201s  Step 18: 4.383s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 5: 5.193s  Step 19: 4.128s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 6: 3.978s  Step 20: 4.115s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 7: 4.113s  Step 21: 4.696s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 22: 4.104s  Step 8: 4.114s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 23: 5.070s  Step 9: 4.255s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 24: 3.993s  Step 10: 5.105s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 25: 5.339s  Step 11: 4.139s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 26: 4.469s  Step 12: 4.163s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 27: 4.253s
[36m(head, rank=0, pid=3097)[0m   Step 13: 4.012s
[36m(head, rank=0, pid=3097)[0m   Step 28: 4.156s
[36m(head, rank=0, pid=3097)[0m   Step 14: 5.384s
[36m(head, rank=0, pid=3097)[0m   Step 29: 4.019s
[36m(head, rank=0, pid=3097)[0m   Step 15: 4.099s
[36m(head, rank=0, pid=3097)[0m   Step 30: 4.017s
[36m(head, rank=0, pid=3097)[0m   Step 16: 4.677s
[36m(head, rank=0, pid=3097)[0m   Step 31: 4.272s
[36m(head, rank=0, pid=3097)[0m   Step 17: 4.815s
[36m(head, rank=0, pid=3097)[0m   Step 32: 4.733s
[36m(head, rank=0, pid=3097)[0m   Step 18: 4.385s
[36m(head, rank=0, pid=3097)[0m   Step 33: 5.227s
[36m(head, rank=0, pid=3097)[0m   Step 19: 4.125s
[36m(head, rank=0, pid=3097)[0m   Step 34: 4.278s
[36m(head, rank=0, pid=3097)[0m   Step 20: 4.113s  Step 35: 4.468s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 21: 4.693s  Step 36: 4.443s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 22: 4.017s  Step 37: 4.700s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 23: 4.938s  Step 38: 4.608s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 24: 4.110s  Step 39: 3.664s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 25: 5.340s  Step 40: 4.173s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 26: 4.468s  Step 41: 3.905s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 42: 4.189s  Step 27: 4.257s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 43: 5.402s  Step 28: 4.155s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 44: 4.260s  Step 29: 3.965s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 45: 4.452s  Step 30: 4.099s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 46: 4.098s  Step 31: 4.163s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 47: 3.984s  Step 32: 4.828s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 48: 4.189s  Step 33: 5.228s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 49: 5.139s  Step 34: 4.276s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 50: 5.057s  Step 35: 4.468s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 51: 4.101s  Step 36: 4.484s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 52: 4.130s  Step 37: 4.697s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 53: 4.430s  Step 38: 4.587s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 54: 4.345s  Step 39: 3.662s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 55: 5.133s  Step 40: 4.170s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 56: 3.897s  Step 41: 3.902s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 57: 5.314s  Step 42: 4.183s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 58: 4.382s  Step 43: 5.401s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 59: 4.264s  Step 44: 4.393s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 60: 4.557s  Step 45: 4.397s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 61: 4.192s  Step 46: 4.099s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 62: 4.138s  Step 47: 3.985s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 63: 3.871s  Step 48: 4.139s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 64: 4.777s  Step 49: 5.136s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 65: 4.006s  Step 50: 5.055s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 66: 3.954s  Step 51: 4.102s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 67: 3.963s  Step 52: 3.982s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 68: 3.917s  Step 53: 4.446s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 69: 4.551s  Step 54: 4.346s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 70: 5.407s
[36m(head, rank=0, pid=3097)[0m   Step 55: 4.589s
[36m(head, rank=0, pid=3097)[0m   Step 71: 4.227s
[36m(head, rank=0, pid=3097)[0m   Step 56: 3.898s
[36m(head, rank=0, pid=3097)[0m   Step 72: 4.258s  Step 57: 5.393s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 73: 3.987s  Step 58: 4.468s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 74: 4.479s  Step 59: 4.353s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 75: 4.086s  Step 60: 4.558s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 76: 4.155s
[36m(head, rank=0, pid=3097)[0m   Step 61: 4.192s
[36m(head, rank=0, pid=3097)[0m   Step 77: 4.343s
[36m(head, rank=0, pid=3097)[0m   Step 62: 4.139s
[36m(head, rank=0, pid=3097)[0m   Step 78: 4.120s
[36m(head, rank=0, pid=3097)[0m   Step 63: 3.871s  Step 79: 3.919s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 64: 4.789s  Step 80: 4.093s
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 65: 4.003s============================================================
[36m(head, rank=0, pid=3097)[0m 
[36m(head, rank=0, pid=3097)[0m   Step 66: 3.957s
[36m(head, rank=0, pid=3097)[0m   Step 67: 4.112s
[36m(head, rank=0, pid=3097)[0m   Step 68: 4.012s
[36m(head, rank=0, pid=3097)[0m   Step 69: 4.510s
[36m(head, rank=0, pid=3097)[0m   Step 70: 5.406s
[36m(head, rank=0, pid=3097)[0m   Step 71: 4.228s
[36m(head, rank=0, pid=3097)[0m   Step 72: 4.300s
[36m(head, rank=0, pid=3097)[0m   Step 73: 3.989s
[36m(head, rank=0, pid=3097)[0m   Step 74: 4.399s
[36m(head, rank=0, pid=3097)[0m   Step 75: 4.086s
[36m(head, rank=0, pid=3097)[0m   Step 76: 4.154s
[36m(head, rank=0, pid=3097)[0m   Step 77: 4.341s
[36m(head, rank=0, pid=3097)[0m   Step 78: 4.119s
[36m(head, rank=0, pid=3097)[0m   Step 79: 3.919s
[36m(head, rank=0, pid=3097)[0m   Step 80: 4.094s
[36m(head, rank=0, pid=3097)[0m ============================================================
[0m[32m✓ Job finished (status: SUCCEEDED).[0m[0m
