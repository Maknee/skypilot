[33mTailing logs of job 1 on cluster 'dd'...[0m
[2m├── [0m[2mWaiting for task resources on 2 nodes.[0m
[2m└── [0mJob started. Streaming logs... [2m(Ctrl-C to exit log streaming; job will not be killed)[0m
[36m(setup pid=3442)[0m Channels:
[36m(setup pid=3442)[0m  - nvidia
[36m(setup pid=3442)[0m  - defaults
[36m(setup pid=3442)[0m Platform: linux-64
[36m(setup pid=2531, ip=10.102.30.76)[0m Channels:
[36m(setup pid=2531, ip=10.102.30.76)[0m  - nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m  - defaults
[36m(setup pid=2531, ip=10.102.30.76)[0m Platform: linux-64
[36m(setup pid=3442)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=3442)[0m Solving environment: ...working... done
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m ## Package Plan ##
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m   environment location: /root/miniconda3
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m   added / updated specs:
[36m(setup pid=3442)[0m     - cuda
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m The following packages will be downloaded:
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m     package                    |            build
[36m(setup pid=3442)[0m     ---------------------------|-----------------
[36m(setup pid=3442)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=3442)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=3442)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=3442)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=3442)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=3442)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=3442)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=3442)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=3442)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=3442)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=3442)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=3442)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=3442)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=3442)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=3442)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=3442)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=3442)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=3442)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=3442)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=3442)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=3442)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=3442)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=3442)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=3442)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=3442)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=3442)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=3442)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=3442)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=3442)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=3442)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=3442)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=3442)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=3442)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=3442)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=3442)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=3442)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=3442)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=3442)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=3442)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=3442)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=3442)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=3442)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=3442)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=3442)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=3442)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=3442)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=3442)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=3442)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=3442)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=3442)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=3442)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=3442)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=3442)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=3442)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=3442)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=3442)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=3442)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=3442)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=3442)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=3442)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=3442)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=3442)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=3442)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=3442)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=3442)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=3442)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=3442)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=3442)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=3442)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=3442)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=3442)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=3442)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=3442)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=3442)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=3442)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=3442)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=3442)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=3442)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=3442)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=3442)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=3442)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=3442)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=3442)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=3442)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=3442)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=3442)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=3442)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=3442)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=3442)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=3442)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=3442)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=3442)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=3442)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=3442)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=3442)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=3442)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=3442)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=3442)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=3442)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=3442)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=3442)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=3442)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=3442)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=3442)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=3442)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=3442)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=3442)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=3442)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=3442)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=3442)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=3442)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=3442)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=3442)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=3442)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=3442)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=3442)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=3442)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=3442)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=3442)[0m     ------------------------------------------------------------
[36m(setup pid=3442)[0m                                            Total:        2.06 GB
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=3442)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=3442)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=3442)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=3442)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=3442)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=3442)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=3442)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=3442)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=3442)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=3442)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=3442)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=3442)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=3442)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=3442)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=3442)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=3442)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=3442)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=3442)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=3442)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=3442)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=3442)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=3442)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=3442)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=3442)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=3442)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=3442)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=3442)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=3442)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=3442)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=3442)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=3442)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=3442)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=3442)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=3442)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=3442)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=3442)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=3442)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=3442)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=3442)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=3442)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=3442)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=3442)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=3442)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=3442)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=3442)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=3442)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=3442)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=3442)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=3442)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=3442)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=3442)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=3442)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=3442)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=3442)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=3442)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=3442)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3442)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=3442)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=3442)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=3442)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=3442)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=3442)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3442)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=3442)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=3442)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=3442)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=3442)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=3442)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=3442)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=3442)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=3442)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=3442)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=3442)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=3442)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=3442)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=3442)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=3442)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=3442)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3442)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=3442)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=3442)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=3442)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=3442)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=3442)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=3442)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=3442)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=3442)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=3442)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=3442)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=3442)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3442)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=3442)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=3442)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=3442)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=3442)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=3442)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=3442)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=3442)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=3442)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=3442)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=3442)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=3442)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=3442)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=3442)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=3442)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=3442)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m The following packages will be UPDATED:
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=3442)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=3442)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=3442)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=3442)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=3442)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=3442)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=3442)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=3442)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=3442)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=3442)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m Proceed ([y]/n)? 
[36m(setup pid=3442)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=2531, ip=10.102.30.76)[0m Solving environment: ...working... done
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m ## Package Plan ##
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m   environment location: /root/miniconda3
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m   added / updated specs:
[36m(setup pid=2531, ip=10.102.30.76)[0m     - cuda
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m The following packages will be downloaded:
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m     package                    |            build
[36m(setup pid=2531, ip=10.102.30.76)[0m     ---------------------------|-----------------
[36m(setup pid=2531, ip=10.102.30.76)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=2531, ip=10.102.30.76)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=2531, ip=10.102.30.76)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=2531, ip=10.102.30.76)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=2531, ip=10.102.30.76)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=2531, ip=10.102.30.76)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=2531, ip=10.102.30.76)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=2531, ip=10.102.30.76)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=2531, ip=10.102.30.76)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=2531, ip=10.102.30.76)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=2531, ip=10.102.30.76)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=2531, ip=10.102.30.76)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=2531, ip=10.102.30.76)[0m     ------------------------------------------------------------
[36m(setup pid=2531, ip=10.102.30.76)[0m                                            Total:        2.06 GB
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=2531, ip=10.102.30.76)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=2531, ip=10.102.30.76)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=2531, ip=10.102.30.76)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=2531, ip=10.102.30.76)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=2531, ip=10.102.30.76)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m The following packages will be UPDATED:
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=2531, ip=10.102.30.76)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=2531, ip=10.102.30.76)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m Proceed ([y]/n)? 
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=3442)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=3442)[0m Preparing transaction: ...working... done
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing transaction: ...working... done
[36m(setup pid=3442)[0m Verifying transaction: ...working... done
[36m(setup pid=2531, ip=10.102.30.76)[0m Verifying transaction: ...working... done
[36m(setup pid=3442)[0m Executing transaction: ...working... done
[36m(setup pid=3442)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=3442)[0m Using CPython 3.10.12 interpreter at: /usr/bin/python3.10
[36m(setup pid=3442)[0m Creating virtual environment with seed packages at: /root/training
[36m(setup pid=3442)[0m  + pip==25.2
[36m(setup pid=3442)[0m  + setuptools==80.9.0
[36m(setup pid=3442)[0m  + wheel==0.45.1
[36m(setup pid=3442)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2531, ip=10.102.30.76)[0m Executing transaction: ...working... done
[36m(setup pid=3442)[0m Resolved 29 packages in 138ms
[36m(setup pid=3442)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=3442)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=3442)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=3442)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=3442)[0m Downloading triton (148.4MiB)
[36m(setup pid=3442)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=3442)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=3442)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=3442)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=3442)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=3442)[0m Downloading sympy (6.0MiB)
[36m(setup pid=3442)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=3442)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=3442)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=3442)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=3442)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=3442)[0m Downloading pillow (6.3MiB)
[36m(setup pid=3442)[0m Downloading torch (783.1MiB)
[36m(setup pid=3442)[0m  Downloading nvidia-cufile-cu12
[36m(setup pid=2531, ip=10.102.30.76)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=2531, ip=10.102.30.76)[0m Using CPython 3.10.12 interpreter at: /usr/bin/python3.10
[36m(setup pid=2531, ip=10.102.30.76)[0m Creating virtual environment with seed packages at: /root/training
[36m(setup pid=2531, ip=10.102.30.76)[0m  + pip==25.2
[36m(setup pid=2531, ip=10.102.30.76)[0m  + setuptools==80.9.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + wheel==0.45.1
[36m(setup pid=2531, ip=10.102.30.76)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3442)[0m  Downloading torchaudio
[36m(setup pid=2531, ip=10.102.30.76)[0m Resolved 29 packages in 86ms
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading pillow (6.3MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading torch (783.1MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading sympy (6.0MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading triton (148.4MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading nvidia-cufile-cu12
[36m(setup pid=3442)[0m  Downloading torchvision
[36m(setup pid=3442)[0m  Downloading pillow
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading torchaudio
[36m(setup pid=3442)[0m  Downloading nvidia-cuda-cupti-cu12
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading pillow
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading torchvision
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading nvidia-cuda-cupti-cu12
[36m(setup pid=3442)[0m  Downloading nvidia-nvjitlink-cu12
[36m(setup pid=3442)[0m  Downloading nvidia-cuda-nvrtc-cu12
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading nvidia-nvjitlink-cu12
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading nvidia-cuda-nvrtc-cu12
[36m(setup pid=3442)[0m  Downloading nvidia-curand-cu12
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading nvidia-curand-cu12
[36m(setup pid=3442)[0m  Downloading sympy
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading sympy
[36m(setup pid=3442)[0m  Downloading nvidia-cusparselt-cu12
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading nvidia-cusparselt-cu12
[36m(setup pid=3442)[0m  Downloading nvidia-cusolver-cu12
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading nvidia-cusolver-cu12
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading triton
[36m(setup pid=3442)[0m  Downloading triton
[36m(setup pid=3442)[0m  Downloading nvidia-nccl-cu12
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading nvidia-cufft-cu12
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading nvidia-nccl-cu12
[36m(setup pid=3442)[0m  Downloading nvidia-cufft-cu12
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading nvidia-cusparse-cu12
[36m(setup pid=3442)[0m  Downloading nvidia-cusparse-cu12
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading nvidia-cublas-cu12
[36m(setup pid=3442)[0m  Downloading nvidia-cublas-cu12
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading nvidia-cudnn-cu12
[36m(setup pid=3442)[0m  Downloading nvidia-cudnn-cu12
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading torch
[36m(setup pid=2531, ip=10.102.30.76)[0m Prepared 22 packages in 20.57s
[36m(setup pid=2531, ip=10.102.30.76)[0m Installed 28 packages in 167ms
[36m(setup pid=2531, ip=10.102.30.76)[0m  + filelock==3.18.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + fsspec==2025.7.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + jinja2==3.1.6
[36m(setup pid=2531, ip=10.102.30.76)[0m  + markupsafe==3.0.2
[36m(setup pid=2531, ip=10.102.30.76)[0m  + mpmath==1.3.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + networkx==3.4.2
[36m(setup pid=2531, ip=10.102.30.76)[0m  + numpy==2.2.6
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=2531, ip=10.102.30.76)[0m  + pillow==11.3.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + sympy==1.14.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + torch==2.7.1
[36m(setup pid=2531, ip=10.102.30.76)[0m  + torchaudio==2.7.1
[36m(setup pid=2531, ip=10.102.30.76)[0m  + torchvision==0.22.1
[36m(setup pid=2531, ip=10.102.30.76)[0m  + triton==3.3.1
[36m(setup pid=2531, ip=10.102.30.76)[0m  + typing-extensions==4.14.1
[36m(setup pid=2531, ip=10.102.30.76)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2531, ip=10.102.30.76)[0m Resolved 73 packages in 414ms
[36m(setup pid=2531, ip=10.102.30.76)[0m    Building deepspeed==0.17.4
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m Downloading transformers (10.7MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading tokenizers
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading hf-xet
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading pyarrow
[36m(setup pid=2531, ip=10.102.30.76)[0m  Downloading transformers
[36m(setup pid=3442)[0m  Downloading torch
[36m(setup pid=3442)[0m Prepared 22 packages in 22.65s
[36m(setup pid=3442)[0m Installed 28 packages in 159ms
[36m(setup pid=3442)[0m  + filelock==3.18.0
[36m(setup pid=3442)[0m  + fsspec==2025.7.0
[36m(setup pid=3442)[0m  + jinja2==3.1.6
[36m(setup pid=3442)[0m  + markupsafe==3.0.2
[36m(setup pid=3442)[0m  + mpmath==1.3.0
[36m(setup pid=3442)[0m  + networkx==3.4.2
[36m(setup pid=3442)[0m  + numpy==2.2.6
[36m(setup pid=3442)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=3442)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=3442)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=3442)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=3442)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=3442)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=3442)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=3442)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=3442)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=3442)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=3442)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=3442)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=3442)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=3442)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=3442)[0m  + pillow==11.3.0
[36m(setup pid=3442)[0m  + sympy==1.14.0
[36m(setup pid=3442)[0m  + torch==2.7.1
[36m(setup pid=3442)[0m  + torchaudio==2.7.1
[36m(setup pid=3442)[0m  + torchvision==0.22.1
[36m(setup pid=3442)[0m  + triton==3.3.1
[36m(setup pid=3442)[0m  + typing-extensions==4.14.1
[36m(setup pid=3442)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3442)[0m Resolved 73 packages in 255ms
[36m(setup pid=3442)[0m    Building deepspeed==0.17.4
[36m(setup pid=3442)[0m Downloading transformers (10.7MiB)
[36m(setup pid=3442)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=3442)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=3442)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=2531, ip=10.102.30.76)[0m       Built deepspeed==0.17.4
[36m(setup pid=2531, ip=10.102.30.76)[0m Prepared 21 packages in 1.46s
[36m(setup pid=2531, ip=10.102.30.76)[0m Uninstalled 1 package in 1ms
[36m(setup pid=2531, ip=10.102.30.76)[0m Installed 48 packages in 104ms
[36m(setup pid=2531, ip=10.102.30.76)[0m  + accelerate==1.9.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=2531, ip=10.102.30.76)[0m  + aiohttp==3.12.15
[36m(setup pid=2531, ip=10.102.30.76)[0m  + aiosignal==1.4.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + annotated-types==0.7.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + async-timeout==5.0.1
[36m(setup pid=2531, ip=10.102.30.76)[0m  + attrs==25.3.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + certifi==2025.8.3
[36m(setup pid=2531, ip=10.102.30.76)[0m  + charset-normalizer==3.4.2
[36m(setup pid=2531, ip=10.102.30.76)[0m  + datasets==4.0.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + deepspeed==0.17.4
[36m(setup pid=2531, ip=10.102.30.76)[0m  + dill==0.3.8
[36m(setup pid=2531, ip=10.102.30.76)[0m  + einops==0.8.1
[36m(setup pid=2531, ip=10.102.30.76)[0m  + frozenlist==1.7.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  - fsspec==2025.7.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + fsspec==2025.3.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + hf-xet==1.1.5
[36m(setup pid=2531, ip=10.102.30.76)[0m  + hjson==3.1.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + huggingface-hub==0.34.3
[36m(setup pid=2531, ip=10.102.30.76)[0m  + idna==3.10
[36m(setup pid=2531, ip=10.102.30.76)[0m  + liger-kernel==0.6.1
[36m(setup pid=2531, ip=10.102.30.76)[0m  + msgpack==1.1.1
[36m(setup pid=2531, ip=10.102.30.76)[0m  + multidict==6.6.3
[36m(setup pid=2531, ip=10.102.30.76)[0m  + multiprocess==0.70.16
[36m(setup pid=2531, ip=10.102.30.76)[0m  + ninja==1.11.1.4
[36m(setup pid=2531, ip=10.102.30.76)[0m  + packaging==25.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + pandas==2.3.1
[36m(setup pid=2531, ip=10.102.30.76)[0m  + propcache==0.3.2
[36m(setup pid=2531, ip=10.102.30.76)[0m  + psutil==7.0.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + pyarrow==21.0.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + pydantic==2.11.7
[36m(setup pid=2531, ip=10.102.30.76)[0m  + pydantic-core==2.33.2
[36m(setup pid=2531, ip=10.102.30.76)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + pytz==2025.2
[36m(setup pid=2531, ip=10.102.30.76)[0m  + pyyaml==6.0.2
[36m(setup pid=2531, ip=10.102.30.76)[0m  + regex==2025.7.34
[36m(setup pid=2531, ip=10.102.30.76)[0m  + requests==2.32.4
[36m(setup pid=2531, ip=10.102.30.76)[0m  + safetensors==0.5.3
[36m(setup pid=2531, ip=10.102.30.76)[0m  + six==1.17.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + tokenizers==0.21.4
[36m(setup pid=2531, ip=10.102.30.76)[0m  + tqdm==4.67.1
[36m(setup pid=2531, ip=10.102.30.76)[0m  + transformers==4.54.1
[36m(setup pid=2531, ip=10.102.30.76)[0m  + trl==0.20.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + typing-inspection==0.4.1
[36m(setup pid=2531, ip=10.102.30.76)[0m  + tzdata==2025.2
[36m(setup pid=2531, ip=10.102.30.76)[0m  + urllib3==2.5.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + xxhash==3.5.0
[36m(setup pid=2531, ip=10.102.30.76)[0m  + yarl==1.20.1
[36m(setup pid=3442)[0m  Downloading tokenizers
[36m(setup pid=3442)[0m  Downloading hf-xet
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=3442)[0m  Downloading pyarrow
[36m(setup pid=3442)[0m  Downloading transformers
[36m(setup pid=2531, ip=10.102.30.76)[0m Reading package lists...
[36m(setup pid=2531, ip=10.102.30.76)[0m Building dependency tree...
[36m(setup pid=2531, ip=10.102.30.76)[0m Reading state information...
[36m(setup pid=3442)[0m       Built deepspeed==0.17.4
[36m(setup pid=2531, ip=10.102.30.76)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2531, ip=10.102.30.76)[0m   libfuse2
[36m(setup pid=2531, ip=10.102.30.76)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2531, ip=10.102.30.76)[0m The following additional packages will be installed:
[36m(setup pid=2531, ip=10.102.30.76)[0m   vim-common vim-runtime
[36m(setup pid=2531, ip=10.102.30.76)[0m Suggested packages:
[36m(setup pid=2531, ip=10.102.30.76)[0m   ctags vim-doc vim-scripts
[36m(setup pid=2531, ip=10.102.30.76)[0m The following NEW packages will be installed:
[36m(setup pid=2531, ip=10.102.30.76)[0m   vmtouch
[36m(setup pid=2531, ip=10.102.30.76)[0m The following packages will be upgraded:
[36m(setup pid=2531, ip=10.102.30.76)[0m   vim vim-common vim-runtime
[36m(setup pid=3442)[0m Prepared 21 packages in 1.35s
[36m(setup pid=3442)[0m Uninstalled 1 package in 0.86ms
[36m(setup pid=3442)[0m Installed 48 packages in 53ms
[36m(setup pid=3442)[0m  + accelerate==1.9.0
[36m(setup pid=3442)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=3442)[0m  + aiohttp==3.12.15
[36m(setup pid=3442)[0m  + aiosignal==1.4.0
[36m(setup pid=3442)[0m  + annotated-types==0.7.0
[36m(setup pid=3442)[0m  + async-timeout==5.0.1
[36m(setup pid=3442)[0m  + attrs==25.3.0
[36m(setup pid=3442)[0m  + certifi==2025.8.3
[36m(setup pid=3442)[0m  + charset-normalizer==3.4.2
[36m(setup pid=3442)[0m  + datasets==4.0.0
[36m(setup pid=3442)[0m  + deepspeed==0.17.4
[36m(setup pid=3442)[0m  + dill==0.3.8
[36m(setup pid=3442)[0m  + einops==0.8.1
[36m(setup pid=3442)[0m  + frozenlist==1.7.0
[36m(setup pid=3442)[0m  - fsspec==2025.7.0
[36m(setup pid=3442)[0m  + fsspec==2025.3.0
[36m(setup pid=3442)[0m  + hf-xet==1.1.5
[36m(setup pid=3442)[0m  + hjson==3.1.0
[36m(setup pid=3442)[0m  + huggingface-hub==0.34.3
[36m(setup pid=3442)[0m  + idna==3.10
[36m(setup pid=3442)[0m  + liger-kernel==0.6.1
[36m(setup pid=3442)[0m  + msgpack==1.1.1
[36m(setup pid=3442)[0m  + multidict==6.6.3
[36m(setup pid=3442)[0m  + multiprocess==0.70.16
[36m(setup pid=3442)[0m  + ninja==1.11.1.4
[36m(setup pid=3442)[0m  + packaging==25.0
[36m(setup pid=3442)[0m  + pandas==2.3.1
[36m(setup pid=3442)[0m  + propcache==0.3.2
[36m(setup pid=3442)[0m  + psutil==7.0.0
[36m(setup pid=3442)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=3442)[0m  + pyarrow==21.0.0
[36m(setup pid=3442)[0m  + pydantic==2.11.7
[36m(setup pid=3442)[0m  + pydantic-core==2.33.2
[36m(setup pid=3442)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=3442)[0m  + pytz==2025.2
[36m(setup pid=3442)[0m  + pyyaml==6.0.2
[36m(setup pid=3442)[0m  + regex==2025.7.34
[36m(setup pid=3442)[0m  + requests==2.32.4
[36m(setup pid=3442)[0m  + safetensors==0.5.3
[36m(setup pid=3442)[0m  + six==1.17.0
[36m(setup pid=3442)[0m  + tokenizers==0.21.4
[36m(setup pid=3442)[0m  + tqdm==4.67.1
[36m(setup pid=3442)[0m  + transformers==4.54.1
[36m(setup pid=3442)[0m  + trl==0.20.0
[36m(setup pid=3442)[0m  + typing-inspection==0.4.1
[36m(setup pid=3442)[0m  + tzdata==2025.2
[36m(setup pid=3442)[0m  + urllib3==2.5.0
[36m(setup pid=3442)[0m  + xxhash==3.5.0
[36m(setup pid=3442)[0m  + yarl==1.20.1
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3442)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m 3 upgraded, 1 newly installed, 0 to remove and 84 not upgraded.
[36m(setup pid=2531, ip=10.102.30.76)[0m Need to get 8664 kB of archives.
[36m(setup pid=2531, ip=10.102.30.76)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 vmtouch amd64 1.3.1-2 [21.5 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim amd64 2:8.2.3995-1ubuntu2.24 [1728 kB]
[36m(setup pid=3442)[0m Reading package lists...
[36m(setup pid=3442)[0m Building dependency tree...
[36m(setup pid=3442)[0m Reading state information...
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-runtime all 2:8.2.3995-1ubuntu2.24 [6833 kB]
[36m(setup pid=3442)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3442)[0m   libfuse2
[36m(setup pid=3442)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3442)[0m The following additional packages will be installed:
[36m(setup pid=3442)[0m   vim-common vim-runtime
[36m(setup pid=3442)[0m Suggested packages:
[36m(setup pid=3442)[0m   ctags vim-doc vim-scripts
[36m(setup pid=3442)[0m The following NEW packages will be installed:
[36m(setup pid=3442)[0m   vmtouch
[36m(setup pid=3442)[0m The following packages will be upgraded:
[36m(setup pid=3442)[0m   vim vim-common vim-runtime
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-common all 2:8.2.3995-1ubuntu2.24 [81.5 kB]
[36m(setup pid=3442)[0m 3 upgraded, 1 newly installed, 0 to remove and 84 not upgraded.
[36m(setup pid=3442)[0m Need to get 8664 kB of archives.
[36m(setup pid=3442)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=3442)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 vmtouch amd64 1.3.1-2 [21.5 kB]
[36m(setup pid=3442)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim amd64 2:8.2.3995-1ubuntu2.24 [1728 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2531, ip=10.102.30.76)[0m Fetched 8664 kB in 1s (6462 kB/s)
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=2531, ip=10.102.30.76)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 23408 files and directories currently installed.)
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../vmtouch_1.3.1-2_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking vmtouch (1.3.1-2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../vim_2%3a8.2.3995-1ubuntu2.24_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking vim (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../vim-runtime_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking vim-runtime (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3442)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-runtime all 2:8.2.3995-1ubuntu2.24 [6833 kB]
[36m(setup pid=3442)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-common all 2:8.2.3995-1ubuntu2.24 [81.5 kB]
[36m(setup pid=3442)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3442)[0m Fetched 8664 kB in 1s (16.1 MB/s)
[36m(setup pid=3442)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=3442)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 23408 files and directories currently installed.)
[36m(setup pid=3442)[0m Preparing to unpack .../vmtouch_1.3.1-2_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking vmtouch (1.3.1-2) ...
[36m(setup pid=3442)[0m Preparing to unpack .../vim_2%3a8.2.3995-1ubuntu2.24_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking vim (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3442)[0m Preparing to unpack .../vim-runtime_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=3442)[0m Unpacking vim-runtime (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../vim-common_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking vim-common (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up vmtouch (1.3.1-2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=2531, ip=10.102.30.76)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up vim-common (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up vim-runtime (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up vim (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=3442)[0m Preparing to unpack .../vim-common_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=3442)[0m Unpacking vim-common (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3442)[0m Setting up vmtouch (1.3.1-2) ...
[36m(setup pid=3442)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=2531, ip=10.102.30.76)[0m Reading package lists...
[36m(setup pid=3442)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=3442)[0m Setting up vim-common (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3442)[0m Setting up vim-runtime (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3442)[0m Setting up vim (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3442)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m Building dependency tree...
[36m(setup pid=2531, ip=10.102.30.76)[0m Reading state information...
[36m(setup pid=2531, ip=10.102.30.76)[0m build-essential is already the newest version (12.9ubuntu3).
[36m(setup pid=2531, ip=10.102.30.76)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2531, ip=10.102.30.76)[0m   libfuse2
[36m(setup pid=2531, ip=10.102.30.76)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2531, ip=10.102.30.76)[0m The following additional packages will be installed:
[36m(setup pid=2531, ip=10.102.30.76)[0m   javascript-common libexpat1 libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=2531, ip=10.102.30.76)[0m   libjs-underscore libpython3-dev libpython3.10 libpython3.10-dev
[36m(setup pid=2531, ip=10.102.30.76)[0m   libpython3.10-minimal libpython3.10-stdlib python3-distutils python3-lib2to3
[36m(setup pid=2531, ip=10.102.30.76)[0m   python3.10 python3.10-minimal
[36m(setup pid=2531, ip=10.102.30.76)[0m Suggested packages:
[36m(setup pid=2531, ip=10.102.30.76)[0m   apache2 | lighttpd | httpd python3.10-venv python3.10-doc binfmt-support
[36m(setup pid=2531, ip=10.102.30.76)[0m The following NEW packages will be installed:
[36m(setup pid=2531, ip=10.102.30.76)[0m   javascript-common libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=2531, ip=10.102.30.76)[0m   libjs-underscore libpython3-dev libpython3.10-dev python3-dev
[36m(setup pid=2531, ip=10.102.30.76)[0m   python3-distutils python3-lib2to3 python3.10-dev
[36m(setup pid=2531, ip=10.102.30.76)[0m The following packages will be upgraded:
[36m(setup pid=2531, ip=10.102.30.76)[0m   libexpat1 libpython3.10 libpython3.10-minimal libpython3.10-stdlib
[36m(setup pid=2531, ip=10.102.30.76)[0m   python3.10 python3.10-minimal
[36m(setup pid=2531, ip=10.102.30.76)[0m 6 upgraded, 11 newly installed, 0 to remove and 78 not upgraded.
[36m(setup pid=2531, ip=10.102.30.76)[0m Need to get 13.7 MB of archives.
[36m(setup pid=2531, ip=10.102.30.76)[0m After this operation, 25.1 MB of additional disk space will be used.
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1 amd64 2.4.7-1ubuntu0.6 [92.1 kB]
[36m(setup pid=3442)[0m Reading package lists...
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.10 [1950 kB]
[36m(setup pid=3442)[0m Building dependency tree...
[36m(setup pid=3442)[0m Reading state information...
[36m(setup pid=3442)[0m build-essential is already the newest version (12.9ubuntu3).
[36m(setup pid=3442)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3442)[0m   libfuse2
[36m(setup pid=3442)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3442)[0m The following additional packages will be installed:
[36m(setup pid=3442)[0m   javascript-common libexpat1 libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=3442)[0m   libjs-underscore libpython3-dev libpython3.10 libpython3.10-dev
[36m(setup pid=3442)[0m   libpython3.10-minimal libpython3.10-stdlib python3-distutils python3-lib2to3
[36m(setup pid=3442)[0m   python3.10 python3.10-minimal
[36m(setup pid=3442)[0m Suggested packages:
[36m(setup pid=3442)[0m   apache2 | lighttpd | httpd python3.10-venv python3.10-doc binfmt-support
[36m(setup pid=3442)[0m The following NEW packages will be installed:
[36m(setup pid=3442)[0m   javascript-common libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=3442)[0m   libjs-underscore libpython3-dev libpython3.10-dev python3-dev
[36m(setup pid=3442)[0m   python3-distutils python3-lib2to3 python3.10-dev
[36m(setup pid=3442)[0m The following packages will be upgraded:
[36m(setup pid=3442)[0m   libexpat1 libpython3.10 libpython3.10-minimal libpython3.10-stdlib
[36m(setup pid=3442)[0m   python3.10 python3.10-minimal
[36m(setup pid=3442)[0m 6 upgraded, 11 newly installed, 0 to remove and 78 not upgraded.
[36m(setup pid=3442)[0m Need to get 13.7 MB of archives.
[36m(setup pid=3442)[0m After this operation, 25.1 MB of additional disk space will be used.
[36m(setup pid=3442)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1 amd64 2.4.7-1ubuntu0.6 [92.1 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=3442)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.10 [1950 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.10 [1850 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.10 [2277 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.10 [815 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5936 B]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1-dev amd64 2.4.7-1ubuntu0.6 [148 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-jquery all 3.6.0+dfsg+~3.5.13-1 [321 kB]
[36m(setup pid=3442)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=3442)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.10 [1850 kB]
[36m(setup pid=3442)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.10 [2277 kB]
[36m(setup pid=3442)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.10 [815 kB]
[36m(setup pid=3442)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5936 B]
[36m(setup pid=3442)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1-dev amd64 2.4.7-1ubuntu0.6 [148 kB]
[36m(setup pid=3442)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-jquery all 3.6.0+dfsg+~3.5.13-1 [321 kB]
[36m(setup pid=3442)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]
[36m(setup pid=3442)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]
[36m(setup pid=3442)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.10 [4763 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.10 [4763 kB]
[36m(setup pid=3442)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3-dev amd64 3.10.6-1~22.04.1 [7064 B]
[36m(setup pid=3442)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=3442)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-lib2to3 all 3.10.8-1~22.04 [77.6 kB]
[36m(setup pid=3442)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-distutils all 3.10.8-1~22.04 [139 kB]
[36m(setup pid=3442)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3-dev amd64 3.10.6-1~22.04.1 [7064 B]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-lib2to3 all 3.10.8-1~22.04 [77.6 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-distutils all 3.10.8-1~22.04 [139 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]
[36m(setup pid=3442)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3442)[0m Fetched 13.7 MB in 1s (25.5 MB/s)
[36m(setup pid=3442)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%
[36m(setup pid=3442)[0m (Reading database ... 85%(Reading database ... 90%
[36m(setup pid=3442)[0m (Reading database ... 95%(Reading database ... 100%(Reading database ... 23418 files and directories currently installed.)
[36m(setup pid=3442)[0m Preparing to unpack .../00-libexpat1_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3442)[0m Unpacking libexpat1:amd64 (2.4.7-1ubuntu0.6) over (2.4.7-1ubuntu0.4) ...
[36m(setup pid=3442)[0m Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libpython3.10:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Fetched 13.7 MB in 2s (8998 kB/s)
[36m(setup pid=2531, ip=10.102.30.76)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 23418 files and directories currently installed.)
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../00-libexpat1_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libexpat1:amd64 (2.4.7-1ubuntu0.6) over (2.4.7-1ubuntu0.4) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libpython3.10:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3442)[0m Preparing to unpack .../02-python3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking python3.10 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3442)[0m Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../02-python3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking python3.10 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3442)[0m Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking python3.10-minimal (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking python3.10-minimal (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3442)[0m Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package javascript-common.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../06-javascript-common_11+nmu1_all.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking javascript-common (11+nmu1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libexpat1-dev:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../07-libexpat1-dev_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libjs-jquery.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../08-libjs-jquery_3.6.0+dfsg+~3.5.13-1_all.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libjs-underscore.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libjs-sphinxdoc.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libpython3.10-dev:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../11-libpython3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libpython3-dev:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../12-libpython3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package python3.10-dev.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../13-python3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package python3-lib2to3.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../14-python3-lib2to3_3.10.8-1~22.04_all.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package python3-distutils.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../15-python3-distutils_3.10.8-1~22.04_all.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package python3-dev.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../16-python3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libexpat1:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up javascript-common (11+nmu1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up python3.10-minimal (3.10.12-1~22.04.10) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libpython3.10:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up python3.10 (3.10.12-1~22.04.10) ...
[36m(setup pid=3442)[0m Selecting previously unselected package javascript-common.
[36m(setup pid=3442)[0m Preparing to unpack .../06-javascript-common_11+nmu1_all.deb ...
[36m(setup pid=3442)[0m Unpacking javascript-common (11+nmu1) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libexpat1-dev:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../07-libexpat1-dev_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libjs-jquery.
[36m(setup pid=3442)[0m Preparing to unpack .../08-libjs-jquery_3.6.0+dfsg+~3.5.13-1_all.deb ...
[36m(setup pid=3442)[0m Unpacking libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libjs-underscore.
[36m(setup pid=3442)[0m Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...
[36m(setup pid=3442)[0m Unpacking libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libjs-sphinxdoc.
[36m(setup pid=3442)[0m Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...
[36m(setup pid=3442)[0m Unpacking libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libpython3.10-dev:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../11-libpython3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=3442)[0m Selecting previously unselected package libpython3-dev:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../12-libpython3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=3442)[0m Selecting previously unselected package python3.10-dev.
[36m(setup pid=3442)[0m Preparing to unpack .../13-python3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=3442)[0m Selecting previously unselected package python3-lib2to3.
[36m(setup pid=3442)[0m Preparing to unpack .../14-python3-lib2to3_3.10.8-1~22.04_all.deb ...
[36m(setup pid=3442)[0m Unpacking python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=3442)[0m Selecting previously unselected package python3-distutils.
[36m(setup pid=3442)[0m Preparing to unpack .../15-python3-distutils_3.10.8-1~22.04_all.deb ...
[36m(setup pid=3442)[0m Unpacking python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3442)[0m Selecting previously unselected package python3-dev.
[36m(setup pid=3442)[0m Preparing to unpack .../16-python3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=3442)[0m Setting up libexpat1:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3442)[0m Setting up javascript-common (11+nmu1) ...
[36m(setup pid=3442)[0m Setting up libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3442)[0m Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3442)[0m Setting up libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=3442)[0m Setting up python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=3442)[0m Setting up libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=3442)[0m Setting up python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3442)[0m Setting up python3.10-minimal (3.10.12-1~22.04.10) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Reading package lists...
[36m(setup pid=3442)[0m Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3442)[0m Setting up libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=3442)[0m Setting up libpython3.10:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3442)[0m Setting up python3.10 (3.10.12-1~22.04.10) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Building dependency tree...
[36m(setup pid=2531, ip=10.102.30.76)[0m Reading state information...
[36m(setup pid=2531, ip=10.102.30.76)[0m infiniband-diags is already the newest version (2410mlnx54-1.2410068).
[36m(setup pid=2531, ip=10.102.30.76)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2531, ip=10.102.30.76)[0m   libfuse2
[36m(setup pid=2531, ip=10.102.30.76)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2531, ip=10.102.30.76)[0m The following additional packages will be installed:
[36m(setup pid=2531, ip=10.102.30.76)[0m   dbus dmsetup gir1.2-glib-2.0 libapparmor1 libargon2-1 libatm1 libbpf0
[36m(setup pid=2531, ip=10.102.30.76)[0m   libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1 libgirepository-1.0-1
[36m(setup pid=2531, ip=10.102.30.76)[0m   libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5 libmnl0 libnl-genl-3-200
[36m(setup pid=2531, ip=10.102.30.76)[0m   libsensors-config libsensors5 libsystemd0 libxtables12 networkd-dispatcher
[36m(setup pid=2531, ip=10.102.30.76)[0m   python3-dbus python3-gi shared-mime-info systemd systemd-timesyncd
[36m(setup pid=2531, ip=10.102.30.76)[0m   xdg-user-dirs
[36m(setup pid=2531, ip=10.102.30.76)[0m Suggested packages:
[36m(setup pid=2531, ip=10.102.30.76)[0m   default-dbus-session-bus | dbus-session-bus lm-sensors lsof strace
[36m(setup pid=2531, ip=10.102.30.76)[0m   iproute2-doc iw | wireless-tools python-dbus-doc isag systemd-container
[36m(setup pid=2531, ip=10.102.30.76)[0m   libtss2-esys-3.0.2-0 libtss2-mu0 libtss2-rc0 policykit-1
[36m(setup pid=2531, ip=10.102.30.76)[0m The following NEW packages will be installed:
[36m(setup pid=2531, ip=10.102.30.76)[0m   dbus dmsetup gir1.2-glib-2.0 htop iproute2 libapparmor1 libargon2-1 libatm1
[36m(setup pid=2531, ip=10.102.30.76)[0m   libbpf0 libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1
[36m(setup pid=2531, ip=10.102.30.76)[0m   libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5
[36m(setup pid=2531, ip=10.102.30.76)[0m   libmnl0 libnl-genl-3-200 libsensors-config libsensors5 libxtables12
[36m(setup pid=2531, ip=10.102.30.76)[0m   networkd-dispatcher python3-dbus python3-gi shared-mime-info sysstat systemd
[36m(setup pid=2531, ip=10.102.30.76)[0m   systemd-timesyncd xdg-user-dirs
[36m(setup pid=2531, ip=10.102.30.76)[0m The following packages will be upgraded:
[36m(setup pid=2531, ip=10.102.30.76)[0m   libsystemd0 net-tools
[36m(setup pid=3442)[0m Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3442)[0m Setting up python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=3442)[0m Setting up libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=3442)[0m Setting up python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=3442)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3442)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m 2 upgraded, 31 newly installed, 0 to remove and 76 not upgraded.
[36m(setup pid=2531, ip=10.102.30.76)[0m Need to get 10.6 MB of archives.
[36m(setup pid=2531, ip=10.102.30.76)[0m After this operation, 35.4 MB of additional disk space will be used.
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsystemd0 amd64 249.11-0ubuntu3.16 [317 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapparmor1 amd64 3.0.4-2ubuntu2.4 [39.7 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libargon2-1 amd64 0~20171227-0.3 [19.5 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdevmapper1.02.1 amd64 2:1.02.175-2.1ubuntu5 [139 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjson-c5 amd64 0.15-3~ubuntu1.22.04.2 [33.5 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcryptsetup12 amd64 2:2.4.3-1ubuntu1.3 [211 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip4tc2 amd64 1.8.7-1ubuntu5.2 [19.9 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd amd64 249.11-0ubuntu3.16 [4581 kB]
[36m(setup pid=3442)[0m Reading package lists...
[36m(setup pid=3442)[0m Building dependency tree...
[36m(setup pid=3442)[0m Reading state information...
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-3 amd64 1.12.20-2ubuntu4.1 [189 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dbus amd64 1.12.20-2ubuntu4.1 [158 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dmsetup amd64 2:1.02.175-2.1ubuntu5 [81.7 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.5 [1466 kB]
[36m(setup pid=3442)[0m infiniband-diags is already the newest version (2410mlnx54-1.2410068).
[36m(setup pid=3442)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3442)[0m   libfuse2
[36m(setup pid=3442)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3442)[0m The following additional packages will be installed:
[36m(setup pid=3442)[0m   dbus dmsetup gir1.2-glib-2.0 libapparmor1 libargon2-1 libatm1 libbpf0
[36m(setup pid=3442)[0m   libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1 libgirepository-1.0-1
[36m(setup pid=3442)[0m   libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5 libmnl0 libnl-genl-3-200
[36m(setup pid=3442)[0m   libsensors-config libsensors5 libsystemd0 libxtables12 networkd-dispatcher
[36m(setup pid=3442)[0m   python3-dbus python3-gi shared-mime-info systemd systemd-timesyncd
[36m(setup pid=3442)[0m   xdg-user-dirs
[36m(setup pid=3442)[0m Suggested packages:
[36m(setup pid=3442)[0m   default-dbus-session-bus | dbus-session-bus lm-sensors lsof strace
[36m(setup pid=3442)[0m   iproute2-doc iw | wireless-tools python-dbus-doc isag systemd-container
[36m(setup pid=3442)[0m   libtss2-esys-3.0.2-0 libtss2-mu0 libtss2-rc0 policykit-1
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgirepository-1.0-1 amd64 1.72.0-1 [55.6 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-glib-2.0 amd64 1.72.0-1 [164 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libelf1 amd64 0.186-1ubuntu0.1 [51.1 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbpf0 amd64 1:0.5.0-1ubuntu22.04.1 [140 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmnl0 amd64 1.0.4-3build2 [13.2 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxtables12 amd64 1.8.7-1ubuntu5.2 [31.3 kB]
[36m(setup pid=3442)[0m The following NEW packages will be installed:
[36m(setup pid=3442)[0m   dbus dmsetup gir1.2-glib-2.0 htop iproute2 libapparmor1 libargon2-1 libatm1
[36m(setup pid=3442)[0m   libbpf0 libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1
[36m(setup pid=3442)[0m   libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5
[36m(setup pid=3442)[0m   libmnl0 libnl-genl-3-200 libsensors-config libsensors5 libxtables12
[36m(setup pid=3442)[0m   networkd-dispatcher python3-dbus python3-gi shared-mime-info sysstat systemd
[36m(setup pid=3442)[0m   systemd-timesyncd xdg-user-dirs
[36m(setup pid=3442)[0m The following packages will be upgraded:
[36m(setup pid=3442)[0m   libsystemd0 net-tools
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 iproute2 amd64 5.15.0-1ubuntu2 [1070 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatm1 amd64 1:2.5.1-4build2 [22.8 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.5 [4656 B]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-dbus amd64 1.2.18-3build1 [99.5 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-gi amd64 3.42.1-0ubuntu1 [229 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 networkd-dispatcher all 2.1-2ubuntu0.22.04.2 [15.8 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-timesyncd amd64 249.11-0ubuntu3.16 [31.2 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]
[36m(setup pid=3442)[0m 2 upgraded, 31 newly installed, 0 to remove and 76 not upgraded.
[36m(setup pid=3442)[0m Need to get 10.6 MB of archives.
[36m(setup pid=3442)[0m After this operation, 35.4 MB of additional disk space will be used.
[36m(setup pid=3442)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsystemd0 amd64 249.11-0ubuntu3.16 [317 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 htop amd64 3.0.5-7build2 [128 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 net-tools amd64 1.60+git20181103.0eebece-1ubuntu5.4 [204 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2531, ip=10.102.30.76)[0m Fetched 10.6 MB in 2s (6406 kB/s)
[36m(setup pid=2531, ip=10.102.30.76)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%
[36m(setup pid=2531, ip=10.102.30.76)[0m (Reading database ... 95%(Reading database ... 100%(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../libsystemd0_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libsystemd0:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libsystemd0:amd64 (249.11-0ubuntu3.16) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libapparmor1:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../00-libapparmor1_3.0.4-2ubuntu2.4_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libargon2-1:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../01-libargon2-1_0~20171227-0.3_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libdevmapper1.02.1:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../02-libdevmapper1.02.1_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libjson-c5:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../03-libjson-c5_0.15-3~ubuntu1.22.04.2_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libcryptsetup12:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../04-libcryptsetup12_2%3a2.4.3-1ubuntu1.3_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libip4tc2:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../05-libip4tc2_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package systemd.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../06-systemd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libdbus-1-3:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../07-libdbus-1-3_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package dbus.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../08-dbus_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package dmsetup.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../09-dmsetup_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libglib2.0-0:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../10-libglib2.0-0_2.72.4-0ubuntu2.5_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3442)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapparmor1 amd64 3.0.4-2ubuntu2.4 [39.7 kB]
[36m(setup pid=3442)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libargon2-1 amd64 0~20171227-0.3 [19.5 kB]
[36m(setup pid=3442)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdevmapper1.02.1 amd64 2:1.02.175-2.1ubuntu5 [139 kB]
[36m(setup pid=3442)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjson-c5 amd64 0.15-3~ubuntu1.22.04.2 [33.5 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libgirepository-1.0-1:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../11-libgirepository-1.0-1_1.72.0-1_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package gir1.2-glib-2.0:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../12-gir1.2-glib-2.0_1.72.0-1_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../13-libelf1_0.186-1ubuntu0.1_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libbpf0:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../14-libbpf0_1%3a0.5.0-1ubuntu22.04.1_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3442)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcryptsetup12 amd64 2:2.4.3-1ubuntu1.3 [211 kB]
[36m(setup pid=3442)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip4tc2 amd64 1.8.7-1ubuntu5.2 [19.9 kB]
[36m(setup pid=3442)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd amd64 249.11-0ubuntu3.16 [4581 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../15-libmnl0_1.0.4-3build2_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../16-libxtables12_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package iproute2.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../17-iproute2_5.15.0-1ubuntu2_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../18-libatm1_1%3a2.5.1-4build2_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libglib2.0-data.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../19-libglib2.0-data_2.72.4-0ubuntu2.5_all.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package python3-dbus.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../20-python3-dbus_1.2.18-3build1_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package python3-gi.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../21-python3-gi_3.42.1-0ubuntu1_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package networkd-dispatcher.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../22-networkd-dispatcher_2.1-2ubuntu0.22.04.2_all.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package shared-mime-info.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../23-shared-mime-info_2.1-2_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking shared-mime-info (2.1-2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package systemd-timesyncd.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../24-systemd-timesyncd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking systemd-timesyncd (249.11-0ubuntu3.16) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package xdg-user-dirs.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../25-xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libnl-genl-3-200:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../26-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=3442)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-3 amd64 1.12.20-2ubuntu4.1 [189 kB]
[36m(setup pid=3442)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dbus amd64 1.12.20-2ubuntu4.1 [158 kB]
[36m(setup pid=3442)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dmsetup amd64 2:1.02.175-2.1ubuntu5 [81.7 kB]
[36m(setup pid=3442)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.5 [1466 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package htop.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../27-htop_3.0.5-7build2_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking htop (3.0.5-7build2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../28-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../29-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3442)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgirepository-1.0-1 amd64 1.72.0-1 [55.6 kB]
[36m(setup pid=3442)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-glib-2.0 amd64 1.72.0-1 [164 kB]
[36m(setup pid=3442)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libelf1 amd64 0.186-1ubuntu0.1 [51.1 kB]
[36m(setup pid=3442)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbpf0 amd64 1:0.5.0-1ubuntu22.04.1 [140 kB]
[36m(setup pid=3442)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmnl0 amd64 1.0.4-3build2 [13.2 kB]
[36m(setup pid=3442)[0m Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxtables12 amd64 1.8.7-1ubuntu5.2 [31.3 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../30-net-tools_1.60+git20181103.0eebece-1ubuntu5.4_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking net-tools (1.60+git20181103.0eebece-1ubuntu5.4) over (1.60+git20181103.0eebece-1ubuntu5) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Selecting previously unselected package sysstat.
[36m(setup pid=2531, ip=10.102.30.76)[0m Preparing to unpack .../31-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Unpacking sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5.4) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3442)[0m Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 iproute2 amd64 5.15.0-1ubuntu2 [1070 kB]
[36m(setup pid=3442)[0m Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatm1 amd64 1:2.5.1-4build2 [22.8 kB]
[36m(setup pid=3442)[0m Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.5 [4656 B]
[36m(setup pid=3442)[0m Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-dbus amd64 1.2.18-3build1 [99.5 kB]
[36m(setup pid=3442)[0m Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-gi amd64 3.42.1-0ubuntu1 [229 kB]
[36m(setup pid=3442)[0m Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 networkd-dispatcher all 2.1-2ubuntu0.22.04.2 [15.8 kB]
[36m(setup pid=3442)[0m Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]
[36m(setup pid=3442)[0m Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-timesyncd amd64 249.11-0ubuntu3.16 [31.2 kB]
[36m(setup pid=3442)[0m Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m No schema files found: doing nothing.
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3442)[0m Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up shared-mime-info (2.1-2) ...
[36m(setup pid=3442)[0m Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 htop amd64 3.0.5-7build2 [128 kB]
[36m(setup pid=3442)[0m Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]
[36m(setup pid=3442)[0m Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]
[36m(setup pid=3442)[0m Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 net-tools amd64 1.60+git20181103.0eebece-1ubuntu5.4 [204 kB]
[36m(setup pid=3442)[0m Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]
[36m(setup pid=3442)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3442)[0m Fetched 10.6 MB in 2s (6346 kB/s)
[36m(setup pid=3442)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=3442)[0m Preparing to unpack .../libsystemd0_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libsystemd0:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...
[36m(setup pid=3442)[0m Setting up libsystemd0:amd64 (249.11-0ubuntu3.16) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libapparmor1:amd64.
[36m(setup pid=3442)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=3442)[0m Preparing to unpack .../00-libapparmor1_3.0.4-2ubuntu2.4_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libargon2-1:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../01-libargon2-1_0~20171227-0.3_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libdevmapper1.02.1:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../02-libdevmapper1.02.1_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libjson-c5:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../03-libjson-c5_0.15-3~ubuntu1.22.04.2_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libcryptsetup12:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../04-libcryptsetup12_2%3a2.4.3-1ubuntu1.3_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libip4tc2:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../05-libip4tc2_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3442)[0m Selecting previously unselected package systemd.
[36m(setup pid=3442)[0m Preparing to unpack .../06-systemd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libdbus-1-3:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../07-libdbus-1-3_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3442)[0m Selecting previously unselected package dbus.
[36m(setup pid=3442)[0m Preparing to unpack .../08-dbus_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3442)[0m Selecting previously unselected package dmsetup.
[36m(setup pid=3442)[0m Preparing to unpack .../09-dmsetup_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libglib2.0-0:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../10-libglib2.0-0_2.72.4-0ubuntu2.5_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libgirepository-1.0-1:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../11-libgirepository-1.0-1_1.72.0-1_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=3442)[0m Selecting previously unselected package gir1.2-glib-2.0:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../12-gir1.2-glib-2.0_1.72.0-1_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../13-libelf1_0.186-1ubuntu0.1_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libbpf0:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../14-libbpf0_1%3a0.5.0-1ubuntu22.04.1_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../15-libmnl0_1.0.4-3build2_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../16-libxtables12_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3442)[0m Selecting previously unselected package iproute2.
[36m(setup pid=3442)[0m Preparing to unpack .../17-iproute2_5.15.0-1ubuntu2_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../18-libatm1_1%3a2.5.1-4build2_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libglib2.0-data.
[36m(setup pid=3442)[0m Preparing to unpack .../19-libglib2.0-data_2.72.4-0ubuntu2.5_all.deb ...
[36m(setup pid=3442)[0m Unpacking libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=2531, ip=10.102.30.76)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=2531, ip=10.102.30.76)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=3442)[0m Selecting previously unselected package python3-dbus.
[36m(setup pid=3442)[0m Preparing to unpack .../20-python3-dbus_1.2.18-3build1_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /lib/systemd/system/sysstat-collect.timer.
[36m(setup pid=3442)[0m Selecting previously unselected package python3-gi.
[36m(setup pid=3442)[0m Preparing to unpack .../21-python3-gi_3.42.1-0ubuntu1_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=3442)[0m Selecting previously unselected package networkd-dispatcher.
[36m(setup pid=3442)[0m Preparing to unpack .../22-networkd-dispatcher_2.1-2ubuntu0.22.04.2_all.deb ...
[36m(setup pid=3442)[0m Unpacking networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=3442)[0m Selecting previously unselected package shared-mime-info.
[36m(setup pid=3442)[0m Preparing to unpack .../23-shared-mime-info_2.1-2_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking shared-mime-info (2.1-2) ...
[36m(setup pid=3442)[0m Selecting previously unselected package systemd-timesyncd.
[36m(setup pid=3442)[0m Preparing to unpack .../24-systemd-timesyncd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking systemd-timesyncd (249.11-0ubuntu3.16) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /lib/systemd/system/sysstat-summary.timer.
[36m(setup pid=3442)[0m Selecting previously unselected package xdg-user-dirs.
[36m(setup pid=3442)[0m Preparing to unpack .../25-xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libnl-genl-3-200:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../26-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=3442)[0m Selecting previously unselected package htop.
[36m(setup pid=3442)[0m Preparing to unpack .../27-htop_3.0.5-7build2_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking htop (3.0.5-7build2) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=3442)[0m Preparing to unpack .../28-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...
[36m(setup pid=3442)[0m Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up python3-dbus (1.2.18-3build1) ...
[36m(setup pid=3442)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=3442)[0m Preparing to unpack .../29-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3442)[0m Preparing to unpack .../30-net-tools_1.60+git20181103.0eebece-1ubuntu5.4_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking net-tools (1.60+git20181103.0eebece-1ubuntu5.4) over (1.60+git20181103.0eebece-1ubuntu5) ...
[36m(setup pid=3442)[0m Selecting previously unselected package sysstat.
[36m(setup pid=3442)[0m Preparing to unpack .../31-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...
[36m(setup pid=3442)[0m Unpacking sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up htop (3.0.5-7build2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=3442)[0m Setting up libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3442)[0m Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5.4) ...
[36m(setup pid=3442)[0m Setting up libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3442)[0m Setting up xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3442)[0m Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3442)[0m No schema files found: doing nothing.
[36m(setup pid=3442)[0m Setting up libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=3442)[0m Setting up libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3442)[0m Setting up libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=3442)[0m Setting up libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3442)[0m Setting up libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3442)[0m Setting up dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m Configuration file '/etc/systemd/system.conf'
[36m(setup pid=2531, ip=10.102.30.76)[0m  ==> File on system created by you or by a script.
[36m(setup pid=2531, ip=10.102.30.76)[0m  ==> File also in package provided by package maintainer.
[36m(setup pid=2531, ip=10.102.30.76)[0m    What would you like to do about it ?  Your options are:
[36m(setup pid=2531, ip=10.102.30.76)[0m     Y or I  : install the package maintainer's version
[36m(setup pid=2531, ip=10.102.30.76)[0m     N or O  : keep your currently-installed version
[36m(setup pid=2531, ip=10.102.30.76)[0m       D     : show the differences between the versions
[36m(setup pid=2531, ip=10.102.30.76)[0m       Z     : start a shell to examine the situation
[36m(setup pid=2531, ip=10.102.30.76)[0m  The default action is to keep your current version.
[36m(setup pid=2531, ip=10.102.30.76)[0m *** system.conf (Y/I/N/O/D/Z) [default=N] ? dpkg: error processing package systemd (--configure):
[36m(setup pid=2531, ip=10.102.30.76)[0m  end of file on stdin at conffile prompt
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=3442)[0m Setting up shared-mime-info (2.1-2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m dpkg: dependency problems prevent configuration of systemd-timesyncd:
[36m(setup pid=2531, ip=10.102.30.76)[0m  systemd-timesyncd depends on systemd (= 249.11-0ubuntu3.16); however:
[36m(setup pid=2531, ip=10.102.30.76)[0m   Package systemd is not configured yet.
[36m(setup pid=2531, ip=10.102.30.76)[0m 
[36m(setup pid=2531, ip=10.102.30.76)[0m dpkg: error processing package systemd-timesyncd (--configure):
[36m(setup pid=2531, ip=10.102.30.76)[0m  dependency problems - leaving unconfigured
[36m(setup pid=2531, ip=10.102.30.76)[0m Setting up networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Created symlink /etc/systemd/system/multi-user.target.wants/networkd-dispatcher.service → /lib/systemd/system/networkd-dispatcher.service.
[36m(setup pid=2531, ip=10.102.30.76)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2531, ip=10.102.30.76)[0m Errors were encountered while processing:
[36m(setup pid=2531, ip=10.102.30.76)[0m  systemd
[36m(setup pid=2531, ip=10.102.30.76)[0m  systemd-timesyncd
[36m(setup pid=2531, ip=10.102.30.76)[0m E: Sub-process /usr/bin/dpkg returned an error code (1)
[36m(setup pid=2531, ip=10.102.30.76)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2531, ip=10.102.30.76)[0m Resolved 3 packages in 146ms
[36m(setup pid=2531, ip=10.102.30.76)[0m Prepared 1 package in 9ms
[36m(setup pid=2531, ip=10.102.30.76)[0m Installed 2 packages in 17ms
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=2531, ip=10.102.30.76)[0m  + nvitop==1.5.2
[36m(setup pid=3442)[0m Setting up libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=3442)[0m Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3442)[0m Setting up libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3442)[0m Setting up libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3442)[0m Setting up dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3442)[0m Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=3442)[0m Setting up libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=3442)[0m Setting up libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=3442)[0m Setting up libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=3442)[0m Setting up sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=3442)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=3442)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=3442)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /lib/systemd/system/sysstat-collect.timer.
[36m(setup pid=3442)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /lib/systemd/system/sysstat-summary.timer.
[36m(setup pid=3442)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.
[36m(setup pid=3442)[0m Setting up python3-dbus (1.2.18-3build1) ...
[36m(setup pid=3442)[0m Setting up htop (3.0.5-7build2) ...
[36m(setup pid=3442)[0m Setting up gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=3442)[0m Setting up libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=3442)[0m Setting up libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3442)[0m Setting up iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=3442)[0m Setting up systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m Configuration file '/etc/systemd/system.conf'
[36m(setup pid=3442)[0m  ==> File on system created by you or by a script.
[36m(setup pid=3442)[0m  ==> File also in package provided by package maintainer.
[36m(setup pid=3442)[0m    What would you like to do about it ?  Your options are:
[36m(setup pid=3442)[0m     Y or I  : install the package maintainer's version
[36m(setup pid=3442)[0m     N or O  : keep your currently-installed version
[36m(setup pid=3442)[0m       D     : show the differences between the versions
[36m(setup pid=3442)[0m       Z     : start a shell to examine the situation
[36m(setup pid=3442)[0m  The default action is to keep your current version.
[36m(setup pid=3442)[0m *** system.conf (Y/I/N/O/D/Z) [default=N] ? dpkg: error processing package systemd (--configure):
[36m(setup pid=3442)[0m  end of file on stdin at conffile prompt
[36m(setup pid=3442)[0m Setting up python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=3442)[0m dpkg: dependency problems prevent configuration of systemd-timesyncd:
[36m(setup pid=3442)[0m  systemd-timesyncd depends on systemd (= 249.11-0ubuntu3.16); however:
[36m(setup pid=3442)[0m   Package systemd is not configured yet.
[36m(setup pid=3442)[0m 
[36m(setup pid=3442)[0m dpkg: error processing package systemd-timesyncd (--configure):
[36m(setup pid=3442)[0m  dependency problems - leaving unconfigured
[36m(setup pid=3442)[0m Setting up networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=3442)[0m Created symlink /etc/systemd/system/multi-user.target.wants/networkd-dispatcher.service → /lib/systemd/system/networkd-dispatcher.service.
[36m(setup pid=3442)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=3442)[0m Errors were encountered while processing:
[36m(setup pid=3442)[0m  systemd
[36m(setup pid=3442)[0m  systemd-timesyncd
[36m(setup pid=3442)[0m E: Sub-process /usr/bin/dpkg returned an error code (1)
[36m(setup pid=3442)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3442)[0m Resolved 3 packages in 31ms
[36m(setup pid=3442)[0m Prepared 1 package in 9ms
[36m(setup pid=3442)[0m Installed 2 packages in 16ms
[36m(setup pid=3442)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=3442)[0m  + nvitop==1.5.2
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Processing directory 1/2: /tmp/checkpoint ===
[36m(head, rank=0, pid=3442)[0m Preserving existing cache directories...
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Downloading and caching dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Processing directory 1/2: /tmp/checkpoint ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Preserving existing cache directories...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Downloading and caching dataset...
[36m(head, rank=0, pid=3442)[0m Setting num_proc from 128 to 10 for the train split as it only contains 10 shards.
[36m(head, rank=0, pid=3442)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Setting num_proc from 128 to 10 for the train split as it only contains 10 shards.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(head, rank=0, pid=3442)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3442)[0m Generating train split:   2%|▏         | 1000/47780 [00:00<00:24, 1891.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Generating train split:   2%|▏         | 1000/47780 [00:00<00:24, 1897.04 examples/s]
[36m(head, rank=0, pid=3442)[0m Generating train split:  19%|█▉        | 9000/47780 [00:00<00:02, 17215.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Generating train split:  13%|█▎        | 6000/47780 [00:00<00:03, 12060.01 examples/s]
[36m(head, rank=0, pid=3442)[0m Generating train split:  27%|██▋       | 13000/47780 [00:00<00:01, 19827.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Generating train split:  23%|██▎       | 11000/47780 [00:00<00:01, 20034.59 examples/s]
[36m(head, rank=0, pid=3442)[0m Generating train split:  44%|████▍     | 21000/47780 [00:00<00:00, 29474.96 examples/s]
[36m(head, rank=0, pid=3442)[0m Generating train split:  61%|██████    | 29000/47780 [00:01<00:00, 38520.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Generating train split:  31%|███▏      | 15000/47780 [00:00<00:01, 24562.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Generating train split:  44%|████▍     | 21000/47780 [00:00<00:00, 31579.33 examples/s]
[36m(head, rank=0, pid=3442)[0m Generating train split:  73%|███████▎  | 35000/47780 [00:01<00:00, 43230.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Generating train split:  54%|█████▍    | 26000/47780 [00:01<00:00, 36177.84 examples/s]
[36m(head, rank=0, pid=3442)[0m Generating train split:  97%|█████████▋| 46224/47780 [00:01<00:00, 58697.46 examples/s]Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 33728.39 examples/s]
[36m(head, rank=0, pid=3442)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(head, rank=0, pid=3442)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Generating train split:  69%|██████▊   | 32778/47780 [00:01<00:00, 42285.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Generating train split:  90%|████████▉ | 42890/47780 [00:01<00:00, 57781.35 examples/s]Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 33100.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3442)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3442)[0m vmtouch output: Files: 14
[36m(head, rank=0, pid=3442)[0m      Directories: 5
[36m(head, rank=0, pid=3442)[0m    Evicted Pages: 1212952 (4G)
[36m(head, rank=0, pid=3442)[0m          Elapsed: 3.6802 seconds
[36m(head, rank=0, pid=3442)[0m Downloading and caching model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m vmtouch output: Files: 14
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m      Directories: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m    Evicted Pages: 1212952 (4G)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m          Elapsed: 3.7807 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Downloading and caching model...
[36m(head, rank=0, pid=3442)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(head, rank=0, pid=3442)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3442)[0m Fetching 5 files:  20%|██        | 1/5 [00:18<01:15, 18.97s/it]
[36m(head, rank=0, pid=3442)[0m Fetching 5 files:  60%|██████    | 3/5 [00:20<00:10,  5.50s/it]Fetching 5 files:  80%|████████  | 4/5 [00:21<00:03,  3.76s/it]Fetching 5 files: 100%|██████████| 5/5 [00:21<00:00,  4.20s/it]
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Fetching 5 files:  20%|██        | 1/5 [00:26<01:47, 26.80s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Fetching 5 files:  40%|████      | 2/5 [00:26<00:33, 11.12s/it]Fetching 5 files:  80%|████████  | 4/5 [00:27<00:04,  4.36s/it]Fetching 5 files: 100%|██████████| 5/5 [00:27<00:00,  5.52s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:16,  4.16s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:08<00:12,  4.06s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:16,  4.24s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:12<00:08,  4.01s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:08<00:12,  4.20s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:16<00:04,  4.01s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.92s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.98s/it]
[36m(head, rank=0, pid=3442)[0m Model downloaded and cached at: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Flushing filesystem cache for: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:12<00:08,  4.19s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:16<00:04,  4.19s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:20<00:00,  4.07s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:20<00:00,  4.13s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model downloaded and cached at: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Flushing filesystem cache for: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3442)[0m vmtouch output: Files: 18
[36m(head, rank=0, pid=3442)[0m      Directories: 10
[36m(head, rank=0, pid=3442)[0m    Evicted Pages: 5950909 (22G)
[36m(head, rank=0, pid=3442)[0m          Elapsed: 25.568 seconds
[36m(head, rank=0, pid=3442)[0m Completed processing directory 1/2
[36m(head, rank=0, pid=3442)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache, /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3442)[0m vmtouch output: Files: 32
[36m(head, rank=0, pid=3442)[0m      Directories: 15
[36m(head, rank=0, pid=3442)[0m    Evicted Pages: 7163861 (27G)
[36m(head, rank=0, pid=3442)[0m          Elapsed: 0.001353 seconds
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Processing directory 2/2: /mnt/data ===
[36m(head, rank=0, pid=3442)[0m Preserving existing cache directories...
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Downloading and caching dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m vmtouch output: Files: 18
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m      Directories: 10
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m    Evicted Pages: 5950909 (22G)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m          Elapsed: 19.113 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed processing directory 1/2
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache, /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m vmtouch output: Files: 32
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m      Directories: 15
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m    Evicted Pages: 7163861 (27G)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m          Elapsed: 0.001307 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Processing directory 2/2: /mnt/data ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Preserving existing cache directories...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Downloading and caching dataset...
[36m(head, rank=0, pid=3442)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(head, rank=0, pid=3442)[0m Flushing filesystem cache for: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3442)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3442)[0m vmtouch output: Files: 78
[36m(head, rank=0, pid=3442)[0m      Directories: 5
[36m(head, rank=0, pid=3442)[0m    Evicted Pages: 4617819 (17G)
[36m(head, rank=0, pid=3442)[0m          Elapsed: 0.14351 seconds
[36m(head, rank=0, pid=3442)[0m Downloading and caching model...
[36m(head, rank=0, pid=3442)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Flushing filesystem cache for: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m vmtouch output: Files: 78
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m      Directories: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m    Evicted Pages: 4617819 (17G)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m          Elapsed: 0.14124 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Downloading and caching model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:21,  5.43s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:06<00:24,  6.15s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:10<00:15,  5.14s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:11<00:16,  5.51s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:15<00:10,  5.04s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:16<00:10,  5.47s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:20<00:04,  5.00s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:24<00:00,  4.85s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:24<00:00,  4.96s/it]
[36m(head, rank=0, pid=3442)[0m Model downloaded and cached at: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Flushing filesystem cache for: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3442)[0m vmtouch output: Files: 18
[36m(head, rank=0, pid=3442)[0m      Directories: 10
[36m(head, rank=0, pid=3442)[0m    Evicted Pages: 5950909 (22G)
[36m(head, rank=0, pid=3442)[0m          Elapsed: 1.0369 seconds
[36m(head, rank=0, pid=3442)[0m Completed processing directory 2/2
[36m(head, rank=0, pid=3442)[0m Flushing filesystem cache for: /mnt/data/dataset_cache, /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3442)[0m vmtouch output: Files: 96
[36m(head, rank=0, pid=3442)[0m      Directories: 15
[36m(head, rank=0, pid=3442)[0m    Evicted Pages: 10568728 (40G)
[36m(head, rank=0, pid=3442)[0m          Elapsed: 0.11607 seconds
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Copying cached data to S3 directories ===
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Copying to S3 directory 1/2: /checkpoints_s3
[36m(head, rank=0, pid=3442)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:22<00:05,  5.52s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:27<00:00,  5.42s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:27<00:00,  5.50s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model downloaded and cached at: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Flushing filesystem cache for: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m vmtouch output: Files: 18
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m      Directories: 10
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m    Evicted Pages: 5950909 (22G)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m          Elapsed: 1.4256 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed processing directory 2/2
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Flushing filesystem cache for: /mnt/data/dataset_cache, /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m vmtouch output: Files: 96
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m      Directories: 15
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m    Evicted Pages: 10568728 (40G)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m          Elapsed: 0.12061 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Copying cached data to S3 directories ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Copying to S3 directory 1/2: /checkpoints_s3
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3442)[0m Dataset cache copied successfully
[36m(head, rank=0, pid=3442)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache copied successfully
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Model cache copied successfully
[36m(head, rank=0, pid=3442)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3442)[0m Checkpoints copied successfully
[36m(head, rank=0, pid=3442)[0m Completed copying to S3 directory 1/2
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Copying to S3 directory 2/2: /checkpoints_s3_mount_cached
[36m(head, rank=0, pid=3442)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache copied successfully
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoints copied successfully
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed copying to S3 directory 1/2
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Copying to S3 directory 2/2: /checkpoints_s3_mount_cached
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3442)[0m Dataset cache copied successfully
[36m(head, rank=0, pid=3442)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache copied successfully
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Model cache copied successfully
[36m(head, rank=0, pid=3442)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3442)[0m Checkpoints copied successfully
[36m(head, rank=0, pid=3442)[0m Completed copying to S3 directory 2/2
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Download and caching completed ===
[36m(head, rank=0, pid=3442)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache copied successfully
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoints copied successfully
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed copying to S3 directory 2/2
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Download and caching completed ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.05 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.07 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.09 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.09 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.07 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.08 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.10 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.12 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.13 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.09 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.16 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.29 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.33 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.33 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.36 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.41 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 129.39it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 129.48it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 123.42it/s]
[36m(head, rank=0, pid=3442)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 128.56it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 130.68it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 130.77it/s]
[36m(head, rank=0, pid=3442)[0m Completed Load model in 0.92 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 0.91 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 129.80it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 128.35it/s]
[36m(head, rank=0, pid=3442)[0m Completed Load model in 0.95 seconds
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 1.02 seconds
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 129.82it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 127.44it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 138.42it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 0.97 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 0.99 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.01 seconds
[36m(head, rank=0, pid=3442)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.01 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 1.07 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 134.55it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 132.63it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 129.61it/s]
[36m(head, rank=0, pid=3442)[0m Completed Load model in 0.91 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 0.96 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.05 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.00 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 0.96 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:17,  4.33s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:20,  5.16s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:08<00:13,  4.36s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:14,  4.75s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:12<00:08,  4.23s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:09,  4.50s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:16<00:04,  4.17s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:20<00:00,  3.98s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:20<00:00,  4.10s/it]
[36m(head, rank=0, pid=3442)[0m Completed Load model in 21.33 seconds
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.52s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:22<00:00,  4.29s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:22<00:00,  4.45s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 23.16 seconds
[36m(head, rank=0, pid=3442)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:13<29:13:00,  2.20s/ examples]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   0%|          | 16/47780 [00:13<8:56:58,  1.48 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   0%|          | 41/47780 [00:13<2:40:47,  4.95 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   0%|          | 89/47780 [00:14<58:20, 13.63 examples/s]  
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   0%|          | 156/47780 [00:14<27:12, 29.18 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   0%|          | 226/47780 [00:14<16:23, 48.33 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   1%|          | 310/47780 [00:15<10:29, 75.42 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   1%|          | 388/47780 [00:15<07:55, 99.61 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   1%|          | 489/47780 [00:15<05:51, 134.65 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 673/47780 [00:16<03:38, 215.59 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 852/47780 [00:16<02:48, 278.21 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1029/47780 [00:17<02:18, 337.07 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1173/47780 [00:17<02:08, 362.34 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1355/47780 [00:17<01:52, 412.87 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1535/47780 [00:18<01:43, 447.71 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1742/47780 [00:18<01:34, 486.72 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1950/47780 [00:18<01:32, 496.48 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2235/47780 [00:19<01:21, 557.89 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2528/47780 [00:19<01:15, 600.77 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2854/47780 [00:20<01:10, 640.80 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3182/47780 [00:20<01:07, 658.47 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3587/47780 [00:20<00:59, 739.79 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3970/47780 [00:21<00:56, 772.28 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4344/47780 [00:21<00:54, 794.43 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4784/47780 [00:22<00:47, 899.50 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5109/47780 [00:22<00:47, 898.13 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5498/47780 [00:22<00:44, 942.71 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5824/47780 [00:23<00:45, 926.27 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6245/47780 [00:23<00:33, 1254.59 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6436/47780 [00:23<00:34, 1204.22 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6601/47780 [00:23<00:35, 1150.69 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6746/47780 [00:23<00:36, 1134.06 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6880/47780 [00:24<00:37, 1100.61 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7003/47780 [00:24<00:37, 1084.09 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7122/47780 [00:24<00:37, 1077.43 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7239/47780 [00:24<00:37, 1095.54 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7354/47780 [00:24<00:36, 1107.26 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7469/47780 [00:24<00:36, 1102.10 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7593/47780 [00:24<00:35, 1136.93 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7709/47780 [00:24<00:35, 1117.27 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7825/47780 [00:24<00:36, 1104.97 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7948/47780 [00:25<00:35, 1118.26 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8074/47780 [00:25<00:34, 1152.95 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8194/47780 [00:25<00:34, 1162.69 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8318/47780 [00:25<00:33, 1179.89 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8473/47780 [00:25<00:30, 1284.82 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8604/47780 [00:25<00:32, 1222.42 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8732/47780 [00:25<00:32, 1186.16 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8859/47780 [00:25<00:32, 1197.24 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 8980/47780 [00:25<00:33, 1146.86 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9098/47780 [00:26<00:34, 1136.61 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9213/47780 [00:26<00:33, 1134.67 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9328/47780 [00:26<00:35, 1096.40 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9446/47780 [00:26<00:34, 1117.23 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9573/47780 [00:26<00:32, 1160.87 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9692/47780 [00:26<00:32, 1160.50 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9809/47780 [00:26<00:33, 1121.31 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9924/47780 [00:26<00:35, 1077.87 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10035/47780 [00:26<00:35, 1068.06 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10144/47780 [00:26<00:35, 1069.47 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10253/47780 [00:27<00:34, 1073.29 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10381/47780 [00:27<00:33, 1127.31 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10494/47780 [00:27<00:34, 1092.73 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10642/47780 [00:27<00:30, 1203.04 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10764/47780 [00:27<00:32, 1143.59 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10887/47780 [00:27<00:31, 1155.49 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11004/47780 [00:27<00:31, 1152.80 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11128/47780 [00:27<00:31, 1152.46 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11251/47780 [00:27<00:31, 1174.70 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11370/47780 [00:28<00:31, 1149.87 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11497/47780 [00:28<00:30, 1182.49 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11623/47780 [00:28<00:30, 1200.76 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11746/47780 [00:28<00:30, 1170.10 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11866/47780 [00:28<00:31, 1155.64 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 11983/47780 [00:28<00:31, 1153.97 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12109/47780 [00:28<00:30, 1172.43 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12240/47780 [00:28<00:29, 1208.16 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12363/47780 [00:28<00:29, 1197.41 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12483/47780 [00:28<00:29, 1184.15 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12614/47780 [00:29<00:28, 1216.88 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12738/47780 [00:29<00:30, 1133.80 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12860/47780 [00:29<00:30, 1152.90 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12978/47780 [00:29<00:30, 1157.94 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13096/47780 [00:29<00:30, 1130.65 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13214/47780 [00:29<00:30, 1126.41 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13328/47780 [00:29<00:31, 1080.41 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13448/47780 [00:29<00:31, 1100.33 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13561/47780 [00:29<00:30, 1105.40 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13672/47780 [00:30<00:31, 1081.62 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13782/47780 [00:30<00:32, 1056.72 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13889/47780 [00:30<00:32, 1037.28 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14007/47780 [00:30<00:31, 1072.77 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14128/47780 [00:30<00:30, 1106.31 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14241/47780 [00:30<00:30, 1083.02 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14352/47780 [00:30<00:30, 1090.09 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14463/47780 [00:30<00:33, 996.10 examples/s] 
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14575/47780 [00:30<00:32, 1019.79 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14688/47780 [00:31<00:31, 1040.14 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14795/47780 [00:31<00:31, 1031.24 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14922/47780 [00:31<00:30, 1092.55 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 15032/47780 [00:31<00:29, 1092.79 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15145/47780 [00:31<00:29, 1101.87 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15256/47780 [00:31<00:30, 1064.61 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15374/47780 [00:31<00:29, 1093.25 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15494/47780 [00:31<00:29, 1109.26 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15612/47780 [00:31<00:28, 1124.50 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15725/47780 [00:31<00:29, 1091.30 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15851/47780 [00:32<00:28, 1135.49 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15965/47780 [00:32<00:29, 1063.64 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16080/47780 [00:32<00:29, 1062.96 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16196/47780 [00:32<00:29, 1086.99 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16317/47780 [00:32<00:28, 1113.71 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16462/47780 [00:32<00:26, 1170.10 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16585/47780 [00:32<00:26, 1186.60 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16705/47780 [00:32<00:26, 1185.45 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16825/47780 [00:32<00:26, 1181.92 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16944/47780 [00:33<00:26, 1150.56 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17073/47780 [00:33<00:26, 1176.27 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17192/47780 [00:33<00:26, 1140.00 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17307/47780 [00:33<00:27, 1125.26 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17435/47780 [00:33<00:25, 1168.73 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17553/47780 [00:33<00:26, 1135.49 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17686/47780 [00:33<00:25, 1181.58 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17805/47780 [00:33<00:26, 1145.48 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17934/47780 [00:33<00:25, 1173.99 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18064/47780 [00:33<00:24, 1209.13 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18187/47780 [00:34<00:26, 1134.85 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18306/47780 [00:34<00:25, 1148.50 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18429/47780 [00:34<00:25, 1167.46 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18548/47780 [00:34<00:25, 1149.05 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18665/47780 [00:34<00:25, 1120.60 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18791/47780 [00:34<00:25, 1156.21 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18909/47780 [00:34<00:25, 1139.75 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19046/47780 [00:34<00:23, 1197.64 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19169/47780 [00:34<00:23, 1192.39 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19289/47780 [00:35<00:25, 1126.82 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19406/47780 [00:35<00:24, 1137.24 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19521/47780 [00:35<00:25, 1111.15 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19645/47780 [00:35<00:24, 1141.72 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19778/47780 [00:35<00:23, 1181.18 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19907/47780 [00:35<00:23, 1207.68 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20036/47780 [00:35<00:22, 1225.24 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20159/47780 [00:35<00:23, 1170.77 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20290/47780 [00:35<00:22, 1203.41 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20413/47780 [00:36<00:23, 1153.66 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20536/47780 [00:36<00:23, 1151.87 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20656/47780 [00:36<00:23, 1145.95 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20771/47780 [00:36<00:23, 1132.62 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20887/47780 [00:36<00:24, 1111.06 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21007/47780 [00:36<00:23, 1134.41 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21122/47780 [00:36<00:23, 1123.85 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21239/47780 [00:36<00:23, 1130.59 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21359/47780 [00:36<00:23, 1142.26 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21480/47780 [00:36<00:22, 1158.57 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21604/47780 [00:37<00:22, 1182.41 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21724/47780 [00:37<00:22, 1173.13 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21844/47780 [00:37<00:22, 1174.41 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21977/47780 [00:37<00:21, 1218.14 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22125/47780 [00:37<00:19, 1286.94 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22260/47780 [00:37<00:20, 1253.77 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22386/47780 [00:37<00:21, 1164.43 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22506/47780 [00:37<00:21, 1149.04 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22623/47780 [00:37<00:22, 1137.41 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22739/47780 [00:38<00:22, 1134.46 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22864/47780 [00:38<00:21, 1148.85 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22992/47780 [00:38<00:21, 1179.64 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23117/47780 [00:38<00:21, 1159.11 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23236/47780 [00:38<00:21, 1142.86 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23352/47780 [00:38<00:21, 1129.16 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23471/47780 [00:38<00:21, 1143.73 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23607/47780 [00:38<00:20, 1203.62 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23733/47780 [00:38<00:19, 1204.88 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23858/47780 [00:38<00:20, 1170.11 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23976/47780 [00:39<00:21, 1114.86 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24090/47780 [00:39<00:21, 1111.17 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24203/47780 [00:39<00:22, 1064.04 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24324/47780 [00:39<00:21, 1098.16 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24437/47780 [00:39<00:21, 1084.62 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24549/47780 [00:39<00:22, 1043.92 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24658/47780 [00:39<00:21, 1053.23 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24764/47780 [00:39<00:22, 1038.80 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24878/47780 [00:39<00:21, 1065.68 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24989/47780 [00:40<00:21, 1070.69 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25110/47780 [00:40<00:20, 1109.49 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25239/47780 [00:40<00:19, 1161.57 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25362/47780 [00:40<00:19, 1177.27 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25480/47780 [00:40<00:19, 1159.19 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25597/47780 [00:40<00:19, 1114.92 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25712/47780 [00:40<00:19, 1109.56 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25825/47780 [00:40<00:20, 1096.27 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25939/47780 [00:40<00:19, 1098.10 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26050/47780 [00:40<00:19, 1097.50 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26162/47780 [00:41<00:19, 1102.29 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26274/47780 [00:41<00:19, 1098.18 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26391/47780 [00:41<00:19, 1116.30 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26504/47780 [00:41<00:20, 1033.05 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26610/47780 [00:41<00:21, 994.01 examples/s] 
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26728/47780 [00:41<00:20, 1043.91 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26835/47780 [00:41<00:20, 1027.28 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26941/47780 [00:41<00:21, 989.23 examples/s] 
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27064/47780 [00:41<00:19, 1053.00 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27207/47780 [00:42<00:17, 1158.40 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27325/47780 [00:42<00:18, 1092.17 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27444/47780 [00:42<00:18, 1111.01 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27561/47780 [00:42<00:18, 1121.88 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27678/47780 [00:42<00:17, 1117.25 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27801/47780 [00:42<00:17, 1140.01 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27916/47780 [00:42<00:17, 1113.48 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28031/47780 [00:42<00:17, 1122.94 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28145/47780 [00:42<00:18, 1033.71 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28261/47780 [00:43<00:18, 1058.44 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28370/47780 [00:43<00:18, 1032.34 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28476/47780 [00:43<00:19, 999.12 examples/s] 
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28578/47780 [00:43<00:20, 946.85 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28683/47780 [00:43<00:19, 973.28 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28782/47780 [00:43<00:19, 961.97 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28903/47780 [00:43<00:18, 1017.35 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29007/47780 [00:43<00:19, 985.78 examples/s] 
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29107/47780 [00:43<00:20, 925.23 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29205/47780 [00:44<00:20, 915.16 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29302/47780 [00:44<00:20, 923.66 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29419/47780 [00:44<00:18, 988.95 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29523/47780 [00:44<00:18, 965.32 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29652/47780 [00:44<00:17, 1042.55 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29757/47780 [00:44<00:17, 1013.13 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29861/47780 [00:44<00:17, 1011.11 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29968/47780 [00:44<00:17, 1014.31 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30073/47780 [00:44<00:17, 1022.73 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30179/47780 [00:44<00:17, 1027.00 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30282/47780 [00:45<00:17, 1000.61 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30410/47780 [00:45<00:16, 1039.57 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30521/47780 [00:45<00:16, 1056.25 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30648/47780 [00:45<00:15, 1112.93 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30778/47780 [00:45<00:14, 1164.57 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30897/47780 [00:45<00:14, 1151.77 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31019/47780 [00:45<00:14, 1158.05 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31135/47780 [00:45<00:14, 1155.47 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31253/47780 [00:45<00:14, 1140.38 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31373/47780 [00:46<00:14, 1152.86 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31490/47780 [00:46<00:14, 1109.12 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31604/47780 [00:46<00:15, 1077.09 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31727/47780 [00:46<00:14, 1116.47 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31842/47780 [00:46<00:14, 1113.28 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31954/47780 [00:46<00:15, 1046.49 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32127/47780 [00:46<00:12, 1220.94 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32255/47780 [00:46<00:12, 1233.04 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32384/47780 [00:46<00:12, 1243.42 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32512/47780 [00:46<00:12, 1245.86 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32639/47780 [00:47<00:12, 1212.11 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32761/47780 [00:47<00:12, 1162.09 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32878/47780 [00:47<00:12, 1154.28 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33014/47780 [00:47<00:12, 1211.21 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33137/47780 [00:47<00:12, 1169.03 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33262/47780 [00:47<00:12, 1188.62 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33388/47780 [00:47<00:11, 1203.84 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33509/47780 [00:47<00:12, 1135.01 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33625/47780 [00:47<00:12, 1107.76 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33738/47780 [00:48<00:13, 1016.63 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33852/47780 [00:48<00:13, 1036.65 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33962/47780 [00:48<00:13, 1047.30 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34072/47780 [00:48<00:12, 1055.91 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34185/47780 [00:48<00:12, 1076.95 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34296/47780 [00:48<00:12, 1039.96 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34401/47780 [00:48<00:13, 995.84 examples/s] 
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34506/47780 [00:48<00:13, 954.81 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34603/47780 [00:48<00:13, 951.14 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34704/47780 [00:49<00:14, 923.06 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34801/47780 [00:49<00:14, 914.68 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34894/47780 [00:49<00:14, 892.84 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34984/47780 [00:49<00:14, 886.41 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35073/47780 [00:49<00:14, 874.93 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35168/47780 [00:49<00:14, 892.73 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35268/47780 [00:49<00:13, 913.91 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35372/47780 [00:49<00:13, 945.08 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35468/47780 [00:49<00:13, 943.46 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35564/47780 [00:50<00:13, 911.33 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35656/47780 [00:50<00:13, 906.04 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35760/47780 [00:50<00:12, 932.39 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35888/47780 [00:50<00:11, 1032.10 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35993/47780 [00:50<00:11, 992.37 examples/s] 
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36097/47780 [00:50<00:12, 954.46 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36213/47780 [00:50<00:11, 999.46 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36315/47780 [00:50<00:11, 976.72 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36416/47780 [00:50<00:11, 984.83 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36516/47780 [00:51<00:11, 981.54 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36615/47780 [00:51<00:11, 948.00 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36716/47780 [00:51<00:11, 960.07 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36813/47780 [00:51<00:11, 953.82 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36924/47780 [00:51<00:10, 998.27 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37026/47780 [00:51<00:11, 975.30 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37125/47780 [00:51<00:10, 971.90 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37236/47780 [00:51<00:10, 1009.54 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37340/47780 [00:51<00:10, 983.52 examples/s] 
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37451/47780 [00:51<00:10, 1000.03 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37558/47780 [00:52<00:10, 1019.63 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37664/47780 [00:52<00:09, 1024.26 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37785/47780 [00:52<00:09, 1077.58 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37895/47780 [00:52<00:09, 1028.12 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38004/47780 [00:52<00:09, 1042.05 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38109/47780 [00:52<00:09, 1038.26 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38214/47780 [00:52<00:09, 1005.01 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38316/47780 [00:52<00:09, 982.30 examples/s] 
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38419/47780 [00:52<00:09, 995.68 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38527/47780 [00:53<00:09, 1012.39 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38631/47780 [00:53<00:09, 1006.34 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38744/47780 [00:53<00:08, 1025.58 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38852/47780 [00:53<00:08, 1039.26 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38957/47780 [00:53<00:08, 1026.53 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39060/47780 [00:53<00:08, 994.97 examples/s] 
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39164/47780 [00:53<00:08, 1000.77 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39265/47780 [00:53<00:08, 999.91 examples/s] 
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39367/47780 [00:53<00:08, 987.44 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39472/47780 [00:53<00:08, 982.56 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39588/47780 [00:54<00:07, 1030.46 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39696/47780 [00:54<00:07, 1029.00 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39802/47780 [00:54<00:07, 1034.85 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39926/47780 [00:54<00:07, 1085.39 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40035/47780 [00:54<00:07, 1064.21 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40143/47780 [00:54<00:07, 1045.72 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40249/47780 [00:54<00:07, 1005.56 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40356/47780 [00:54<00:07, 1018.64 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40460/47780 [00:54<00:07, 966.94 examples/s] 
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40569/47780 [00:55<00:07, 994.09 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40672/47780 [00:55<00:07, 1000.17 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40775/47780 [00:55<00:07, 978.50 examples/s] 
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40884/47780 [00:55<00:06, 1006.22 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41011/47780 [00:55<00:06, 1077.37 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41120/47780 [00:55<00:06, 1025.18 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41224/47780 [00:55<00:06, 1021.75 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41347/47780 [00:55<00:05, 1076.69 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41456/47780 [00:55<00:05, 1069.43 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41576/47780 [00:55<00:05, 1096.75 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41690/47780 [00:56<00:05, 1107.43 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41802/47780 [00:56<00:05, 1087.71 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41915/47780 [00:56<00:05, 1089.45 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42025/47780 [00:56<00:05, 1052.63 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42137/47780 [00:56<00:05, 1071.47 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42246/47780 [00:56<00:05, 1053.52 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42355/47780 [00:56<00:05, 1016.90 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42459/47780 [00:56<00:05, 1002.31 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42560/47780 [00:56<00:05, 981.39 examples/s] 
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42663/47780 [00:57<00:05, 980.55 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42763/47780 [00:57<00:05, 941.66 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42858/47780 [00:57<00:05, 873.73 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42947/47780 [00:57<00:05, 843.25 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43041/47780 [00:57<00:05, 867.49 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43131/47780 [00:57<00:05, 842.73 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43220/47780 [00:57<00:05, 829.16 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43306/47780 [00:57<00:05, 772.73 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43385/47780 [00:57<00:06, 725.84 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43459/47780 [00:58<00:06, 714.85 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43536/47780 [00:58<00:05, 724.58 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43625/47780 [00:58<00:05, 741.38 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43701/47780 [00:58<00:05, 698.99 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43789/47780 [00:58<00:05, 747.53 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43865/47780 [00:58<00:05, 714.50 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43943/47780 [00:58<00:05, 731.84 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44037/47780 [00:58<00:04, 790.05 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44118/47780 [00:58<00:04, 793.67 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44220/47780 [00:59<00:04, 839.72 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44306/47780 [00:59<00:04, 834.19 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44393/47780 [00:59<00:04, 841.23 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44479/47780 [00:59<00:04, 817.73 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44562/47780 [00:59<00:03, 815.03 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44645/47780 [00:59<00:03, 815.42 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44728/47780 [00:59<00:04, 762.66 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44806/47780 [00:59<00:04, 733.96 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44880/47780 [00:59<00:04, 678.61 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44950/47780 [01:00<00:04, 662.43 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45021/47780 [01:00<00:04, 655.43 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45091/47780 [01:00<00:04, 608.28 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45155/47780 [01:00<00:04, 582.70 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45216/47780 [01:00<00:04, 588.70 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45288/47780 [01:00<00:04, 615.49 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45351/47780 [01:00<00:04, 570.47 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45410/47780 [01:00<00:04, 558.88 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45491/47780 [01:00<00:03, 618.83 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45554/47780 [01:01<00:03, 590.08 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45626/47780 [01:01<00:03, 606.43 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45698/47780 [01:01<00:03, 630.64 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45762/47780 [01:01<00:03, 587.03 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45824/47780 [01:01<00:03, 593.72 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45885/47780 [01:01<00:03, 586.51 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45950/47780 [01:01<00:03, 598.05 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46020/47780 [01:01<00:02, 611.40 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46083/47780 [01:02<00:03, 543.16 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46140/47780 [01:02<00:03, 517.34 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46194/47780 [01:02<00:03, 491.06 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46244/47780 [01:02<00:03, 462.68 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46293/47780 [01:02<00:03, 443.50 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46339/47780 [01:02<00:03, 419.83 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46383/47780 [01:02<00:03, 393.67 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46427/47780 [01:02<00:03, 387.67 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46468/47780 [01:02<00:03, 381.78 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46514/47780 [01:03<00:03, 388.11 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46554/47780 [01:03<00:03, 390.21 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46597/47780 [01:03<00:03, 394.29 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46638/47780 [01:03<00:03, 374.00 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46678/47780 [01:03<00:02, 378.90 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46718/47780 [01:03<00:03, 351.97 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46766/47780 [01:03<00:02, 373.11 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46805/47780 [01:03<00:02, 364.02 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46842/47780 [01:04<00:02, 345.03 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46877/47780 [01:04<00:02, 345.89 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46914/47780 [01:04<00:02, 351.44 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46950/47780 [01:04<00:02, 336.69 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46985/47780 [01:04<00:02, 297.49 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47017/47780 [01:04<00:02, 294.71 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47051/47780 [01:04<00:02, 305.50 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47085/47780 [01:04<00:02, 283.80 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47122/47780 [01:04<00:02, 289.25 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47155/47780 [01:05<00:02, 296.91 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47186/47780 [01:05<00:02, 279.04 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47218/47780 [01:05<00:01, 286.76 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47250/47780 [01:05<00:01, 283.36 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47280/47780 [01:05<00:01, 250.24 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47306/47780 [01:05<00:02, 236.82 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47332/47780 [01:05<00:02, 210.95 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47355/47780 [01:05<00:02, 203.61 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47376/47780 [01:06<00:01, 203.69 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47398/47780 [01:06<00:01, 199.88 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47420/47780 [01:06<00:01, 194.26 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47442/47780 [01:06<00:01, 184.54 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47461/47780 [01:06<00:02, 153.67 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47478/47780 [01:06<00:02, 149.37 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47495/47780 [01:06<00:02, 142.11 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47512/47780 [01:07<00:01, 136.80 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47527/47780 [01:07<00:01, 138.34 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47549/47780 [01:07<00:01, 151.20 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47565/47780 [01:07<00:01, 138.96 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47581/47780 [01:07<00:01, 124.42 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47596/47780 [01:07<00:01, 121.37 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47610/47780 [01:07<00:01, 110.07 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47624/47780 [01:08<00:01, 106.52 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47639/47780 [01:08<00:01, 112.64 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47651/47780 [01:08<00:01, 110.97 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47663/47780 [01:08<00:01, 94.50 examples/s] 
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47673/47780 [01:08<00:01, 93.67 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47683/47780 [01:08<00:01, 89.11 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47694/47780 [01:08<00:00, 86.74 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47705/47780 [01:08<00:00, 88.31 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47714/47780 [01:09<00:00, 80.26 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47723/47780 [01:09<00:00, 72.64 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47733/47780 [01:09<00:00, 67.33 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47741/47780 [01:09<00:00, 63.57 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47748/47780 [01:09<00:00, 61.47 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47755/47780 [01:09<00:00, 61.92 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [01:09<00:00, 68.93 examples/s]
[36m(head, rank=0, pid=3442)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [01:10<00:00, 65.72 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [01:12<00:00, 655.26 examples/s]
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3442)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:11<08:51, 87.98 examples/s]
[36m(head, rank=0, pid=3442)[0m Truncating train dataset (num_proc=32):  21%|██        | 10000/47780 [00:11<00:31, 1203.90 examples/s]
[36m(head, rank=0, pid=3442)[0m Truncating train dataset (num_proc=32):  69%|██████▉   | 32974/47780 [00:11<00:02, 5184.55 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:18<00:00, 2621.90 examples/s]
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:41,237] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3442)[0m df: /root/.triton/autotune: No such file or directory
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:41,880] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:41,903] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:41,909] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:41,916] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:41,922] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:42,014] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:42,052] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:43,547] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:43,547] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:43,547] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:43,547] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:43,548] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:43,548] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:43,548] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 00:30:43,548] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<4:33:44,  2.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:12:26,  2.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 18/47780 [00:02<1:30:45,  8.77 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:34:33,  2.38 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:45:33,  2.30 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:46:10,  2.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:44:24,  2.31 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:55:10,  2.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 19/47780 [00:02<1:35:12,  8.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 47/47780 [00:02<33:20, 23.86 examples/s]  
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 19/47780 [00:02<1:39:31,  8.00 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 25/47780 [00:03<1:16:41, 10.38 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 30/47780 [00:02<1:02:28, 12.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 11/47780 [00:03<3:16:12,  4.06 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 19/47780 [00:03<1:44:37,  7.61 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 50/47780 [00:03<34:03, 23.36 examples/s]  
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 88/47780 [00:03<18:05, 43.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 49/47780 [00:03<36:30, 21.79 examples/s]  Tokenizing train dataset (num_proc=32):   0%|          | 48/47780 [00:03<41:25, 19.21 examples/s]  
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 51/47780 [00:03<37:56, 20.97 examples/s]  Tokenizing train dataset (num_proc=32):   0%|          | 39/47780 [00:03<46:32, 17.10 examples/s]  Tokenizing train dataset (num_proc=32):   0%|          | 41/47780 [00:03<46:32, 17.10 examples/s]  
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 93/47780 [00:03<18:22, 43.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 155/47780 [00:03<10:24, 76.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 77/47780 [00:03<24:26, 32.54 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 85/47780 [00:03<22:28, 35.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 77/47780 [00:03<23:40, 33.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 98/47780 [00:03<19:10, 41.44 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 224/47780 [00:04<07:45, 102.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 73/47780 [00:04<27:35, 28.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 162/47780 [00:04<11:55, 66.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 157/47780 [00:04<10:57, 72.43 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 164/47780 [00:04<10:51, 73.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 159/47780 [00:04<12:08, 65.41 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 146/47780 [00:04<13:09, 60.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 237/47780 [00:04<06:45, 117.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|          | 311/47780 [00:04<06:16, 125.92 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 191/47780 [00:04<09:45, 81.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|          | 280/47780 [00:04<06:53, 114.88 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 229/47780 [00:04<09:14, 85.73 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 249/47780 [00:04<07:25, 106.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   0%|          | 223/47780 [00:04<09:41, 81.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|          | 266/47780 [00:04<08:09, 97.07 examples/s] Tokenizing train dataset (num_proc=32):   1%|          | 275/47780 [00:05<07:24, 106.92 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|          | 352/47780 [00:05<04:48, 164.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|          | 407/47780 [00:05<05:44, 137.44 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 374/47780 [00:05<06:09, 128.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|          | 329/47780 [00:05<06:09, 128.43 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 357/47780 [00:05<06:26, 122.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|          | 343/47780 [00:05<06:46, 116.79 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 393/47780 [00:05<06:08, 128.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|          | 511/47780 [00:05<03:31, 223.86 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 475/47780 [00:05<04:03, 194.00 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|          | 586/47780 [00:05<04:10, 188.45 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 518/47780 [00:05<04:55, 159.77 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|          | 345/47780 [00:05<08:04, 97.83 examples/s] 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|          | 398/47780 [00:05<06:29, 121.55 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 500/47780 [00:06<05:11, 151.54 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|          | 569/47780 [00:06<04:20, 181.08 examples/s]Tokenizing train dataset (num_proc=32):   1%|▏         | 684/47780 [00:06<02:59, 261.69 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 520/47780 [00:06<05:30, 143.07 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 769/47780 [00:06<03:23, 230.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 674/47780 [00:06<03:52, 202.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|          | 528/47780 [00:06<04:58, 158.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|          | 545/47780 [00:06<04:58, 158.20 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 929/47780 [00:06<03:06, 251.47 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 832/47780 [00:06<03:20, 234.59 examples/s]Tokenizing train dataset (num_proc=32):   1%|▏         | 700/47780 [00:06<04:12, 186.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 647/47780 [00:06<04:39, 168.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 756/47780 [00:06<03:48, 205.95 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 1079/47780 [00:07<02:17, 340.68 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 967/47780 [00:07<02:29, 312.95 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 882/47780 [00:06<02:33, 306.15 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 718/47780 [00:07<03:37, 216.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 830/47780 [00:07<02:31, 309.52 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 667/47780 [00:07<04:24, 178.18 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1139/47780 [00:07<03:06, 250.53 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 958/47780 [00:07<03:15, 239.41 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 880/47780 [00:07<03:53, 200.62 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 1019/47780 [00:07<03:28, 224.13 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 904/47780 [00:07<03:22, 231.26 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 839/47780 [00:07<03:45, 208.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1015/47780 [00:07<02:27, 317.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 836/47780 [00:08<04:20, 180.21 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1235/47780 [00:08<03:35, 215.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1034/47780 [00:08<02:46, 279.94 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 1083/47780 [00:08<03:01, 256.72 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 1147/47780 [00:08<03:37, 214.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1422/47780 [00:08<02:15, 342.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1012/47780 [00:08<03:45, 207.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1065/47780 [00:08<03:26, 225.79 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 1048/47780 [00:08<03:59, 195.02 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1325/47780 [00:08<02:19, 332.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1183/47780 [00:08<02:22, 327.76 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1238/47780 [00:08<02:22, 326.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1218/47780 [00:08<02:31, 306.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1101/47780 [00:08<03:26, 225.51 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1502/47780 [00:08<02:55, 263.19 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1164/47780 [00:08<03:42, 209.17 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1402/47780 [00:08<02:55, 264.77 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1644/47780 [00:09<02:07, 361.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1352/47780 [00:08<02:16, 340.36 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1264/47780 [00:09<03:11, 242.90 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1301/47780 [00:08<03:17, 235.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1314/47780 [00:09<03:14, 238.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1229/47780 [00:09<03:42, 208.90 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1490/47780 [00:09<03:38, 212.26 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1435/47780 [00:09<02:56, 263.00 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1412/47780 [00:09<02:26, 315.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1725/47780 [00:09<02:57, 259.38 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 1889/47780 [00:09<02:00, 379.37 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1365/47780 [00:09<03:50, 201.32 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1414/47780 [00:09<03:45, 205.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1459/47780 [00:09<03:22, 228.75 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1560/47780 [00:09<02:20, 329.75 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1596/47780 [00:09<02:23, 322.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1640/47780 [00:09<02:18, 333.53 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1571/47780 [00:10<03:16, 235.59 examples/s]Tokenizing train dataset (num_proc=32):   4%|▎         | 1685/47780 [00:10<03:20, 230.01 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1492/47780 [00:10<03:23, 227.38 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 1978/47780 [00:10<02:49, 269.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1769/47780 [00:10<02:05, 367.26 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 1917/47780 [00:10<02:03, 371.64 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 2148/47780 [00:10<01:54, 399.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1647/47780 [00:10<03:06, 246.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1789/47780 [00:10<02:15, 340.45 examples/s]Tokenizing train dataset (num_proc=32):   4%|▎         | 1682/47780 [00:10<04:08, 185.80 examples/s]Tokenizing train dataset (num_proc=32):   5%|▍         | 2246/47780 [00:11<02:40, 283.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1925/47780 [00:11<02:20, 326.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1716/47780 [00:11<04:10, 183.72 examples/s]Tokenizing train dataset (num_proc=32):   5%|▌         | 2441/47780 [00:11<01:45, 429.18 examples/s]Tokenizing train dataset (num_proc=32):   4%|▎         | 1790/47780 [00:11<03:32, 216.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1876/47780 [00:11<03:07, 244.97 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 2010/47780 [00:11<03:11, 238.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2026/47780 [00:11<02:10, 349.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1859/47780 [00:11<03:38, 209.90 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1641/47780 [00:11<04:21, 176.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2174/47780 [00:11<01:53, 400.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1776/47780 [00:11<03:11, 240.02 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 2042/47780 [00:11<03:05, 247.19 examples/s]Tokenizing train dataset (num_proc=32):   5%|▌         | 2544/47780 [00:12<02:39, 282.77 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1852/47780 [00:11<04:41, 163.17 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 2146/47780 [00:12<02:31, 300.87 examples/s]Tokenizing train dataset (num_proc=32):   6%|▌         | 2763/47780 [00:12<01:41, 442.48 examples/s]Tokenizing train dataset (num_proc=32):   5%|▍         | 2157/47780 [00:12<02:06, 359.77 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2115/47780 [00:12<03:05, 246.63 examples/s]Tokenizing train dataset (num_proc=32):   5%|▍         | 2159/47780 [00:12<03:26, 221.17 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2283/47780 [00:12<02:04, 365.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2244/47780 [00:12<02:55, 258.75 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 1847/47780 [00:12<04:50, 158.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2293/47780 [00:12<02:55, 258.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1973/47780 [00:12<03:28, 219.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2306/47780 [00:13<04:29, 168.80 examples/s]Tokenizing train dataset (num_proc=32):   5%|▍         | 2374/47780 [00:13<02:53, 261.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2616/47780 [00:13<02:07, 353.95 examples/s]Tokenizing train dataset (num_proc=32):   5%|▍         | 2376/47780 [00:13<03:45, 201.25 examples/s]Tokenizing train dataset (num_proc=32):   5%|▌         | 2464/47780 [00:13<02:31, 298.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2310/47780 [00:13<03:54, 193.90 examples/s]Tokenizing train dataset (num_proc=32):   6%|▌         | 2674/47780 [00:13<01:56, 387.30 examples/s]Tokenizing train dataset (num_proc=32):   6%|▌         | 2864/47780 [00:13<01:41, 442.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2882/47780 [00:13<03:31, 212.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3144/47780 [00:13<02:06, 353.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2047/47780 [00:13<05:00, 152.39 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2739/47780 [00:14<02:39, 281.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2363/47780 [00:14<04:59, 151.81 examples/s]Tokenizing train dataset (num_proc=32):   5%|▌         | 2602/47780 [00:14<03:01, 249.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2484/47780 [00:14<03:38, 207.54 examples/s]Tokenizing train dataset (num_proc=32):   5%|▌         | 2556/47780 [00:14<03:05, 243.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2670/47780 [00:14<02:42, 276.93 examples/s]Tokenizing train dataset (num_proc=32):   6%|▌         | 2963/47780 [00:14<01:15, 589.88 examples/s]Tokenizing train dataset (num_proc=32):   6%|▌         | 2736/47780 [00:14<02:30, 299.08 examples/s]Tokenizing train dataset (num_proc=32):   6%|▋         | 3089/47780 [00:14<02:02, 366.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2807/47780 [00:14<02:51, 262.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 3027/47780 [00:14<01:56, 385.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3282/47780 [00:14<03:12, 230.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3578/47780 [00:15<01:55, 381.09 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2267/47780 [00:15<04:36, 164.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2795/47780 [00:15<01:49, 410.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 3075/47780 [00:15<01:19, 563.59 examples/s]Tokenizing train dataset (num_proc=32):   6%|▌         | 2845/47780 [00:15<04:12, 177.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2796/47780 [00:15<04:22, 171.39 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3260/47780 [00:15<01:56, 383.02 examples/s]Tokenizing train dataset (num_proc=32):   7%|▋         | 3154/47780 [00:15<02:45, 270.03 examples/s]Tokenizing train dataset (num_proc=32):   6%|▌         | 2911/47780 [00:15<03:04, 243.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3603/47780 [00:15<01:14, 592.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3363/47780 [00:15<01:54, 388.84 examples/s]Tokenizing train dataset (num_proc=32):   7%|▋         | 3488/47780 [00:16<02:02, 362.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3132/47780 [00:16<02:55, 254.42 examples/s]Tokenizing train dataset (num_proc=32):   7%|▋         | 3254/47780 [00:16<03:12, 231.07 examples/s]Tokenizing train dataset (num_proc=32):   8%|▊         | 3731/47780 [00:16<02:49, 259.26 examples/s]Tokenizing train dataset (num_proc=32):   6%|▌         | 2976/47780 [00:16<04:01, 185.19 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3551/47780 [00:16<01:34, 469.33 examples/s]Tokenizing train dataset (num_proc=32):   8%|▊         | 3651/47780 [00:16<01:55, 381.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3441/47780 [00:16<01:20, 551.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3854/47780 [00:16<01:41, 430.66 examples/s]Tokenizing train dataset (num_proc=32):   7%|▋         | 3287/47780 [00:16<02:18, 321.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3754/47780 [00:16<01:43, 423.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3946/47780 [00:16<02:38, 276.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3531/47780 [00:16<01:43, 427.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4207/47780 [00:17<01:46, 408.03 examples/s]Tokenizing train dataset (num_proc=32):   8%|▊         | 3825/47780 [00:17<02:41, 272.35 examples/s]Tokenizing train dataset (num_proc=32):   8%|▊         | 3584/47780 [00:17<04:05, 179.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3614/47780 [00:17<02:31, 291.14 examples/s]Tokenizing train dataset (num_proc=32):   8%|▊         | 3752/47780 [00:17<02:51, 257.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3793/47780 [00:17<01:55, 380.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3852/47780 [00:17<02:22, 307.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3906/47780 [00:17<02:26, 300.46 examples/s]Tokenizing train dataset (num_proc=32):   8%|▊         | 4019/47780 [00:17<02:39, 273.51 examples/s]Tokenizing train dataset (num_proc=32):   9%|▉         | 4344/47780 [00:18<02:32, 284.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4086/47780 [00:17<01:53, 385.07 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4326/47780 [00:18<01:46, 406.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3696/47780 [00:18<02:43, 270.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3863/47780 [00:18<02:09, 339.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3984/47780 [00:18<03:17, 221.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4440/47780 [00:18<01:48, 400.46 examples/s]Tokenizing train dataset (num_proc=32):  10%|█         | 4805/47780 [00:19<01:14, 580.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3951/47780 [00:19<03:58, 183.78 examples/s]Tokenizing train dataset (num_proc=32):   9%|▉         | 4458/47780 [00:19<01:31, 475.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4074/47780 [00:19<02:37, 277.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4350/47780 [00:19<01:46, 406.32 examples/s]Tokenizing train dataset (num_proc=32):   9%|▉         | 4444/47780 [00:19<03:49, 188.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4495/47780 [00:19<02:36, 275.89 examples/s]Tokenizing train dataset (num_proc=32):  10%|▉         | 4674/47780 [00:19<01:11, 599.12 examples/s]Tokenizing train dataset (num_proc=32):  10%|▉         | 4599/47780 [00:19<02:51, 252.07 examples/s]Tokenizing train dataset (num_proc=32):  10%|▉         | 4660/47780 [00:19<01:22, 521.16 examples/s]Tokenizing train dataset (num_proc=32):   9%|▉         | 4219/47780 [00:19<03:15, 222.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4710/47780 [00:19<01:57, 367.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4554/47780 [00:19<01:54, 376.14 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3995/47780 [00:19<03:29, 208.73 examples/s]Tokenizing train dataset (num_proc=32):  11%|█         | 5065/47780 [00:20<01:36, 443.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4246/47780 [00:20<02:18, 315.39 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5258/47780 [00:20<01:19, 531.57 examples/s]Tokenizing train dataset (num_proc=32):  10%|█         | 4824/47780 [00:20<02:15, 315.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4859/47780 [00:20<02:47, 256.83 examples/s]Tokenizing train dataset (num_proc=32):  11%|█         | 5150/47780 [00:20<01:26, 495.14 examples/s]Tokenizing train dataset (num_proc=32):  10%|█         | 4871/47780 [00:20<02:07, 335.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4696/47780 [00:20<04:22, 164.20 examples/s]Tokenizing train dataset (num_proc=32):  11%|█▏        | 5446/47780 [00:20<01:40, 420.08 examples/s]Tokenizing train dataset (num_proc=32):  11%|█         | 5032/47780 [00:20<01:45, 406.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5138/47780 [00:20<01:57, 364.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5539/47780 [00:21<01:12, 585.77 examples/s]Tokenizing train dataset (num_proc=32):   9%|▉         | 4387/47780 [00:21<03:33, 203.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4711/47780 [00:21<03:33, 201.96 examples/s]Tokenizing train dataset (num_proc=32):  10%|█         | 4806/47780 [00:21<01:52, 383.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5097/47780 [00:21<02:02, 348.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5144/47780 [00:21<01:16, 554.66 examples/s]Tokenizing train dataset (num_proc=32):  10%|█         | 4993/47780 [00:21<03:39, 194.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5586/47780 [00:22<02:26, 287.17 examples/s]Tokenizing train dataset (num_proc=32):  11%|█         | 5374/47780 [00:22<01:59, 353.84 examples/s]Tokenizing train dataset (num_proc=32):  11%|█         | 5332/47780 [00:22<02:19, 303.31 examples/s]Tokenizing train dataset (num_proc=32):  13%|█▎        | 5987/47780 [00:22<01:25, 490.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5181/47780 [00:22<02:41, 263.50 examples/s]Tokenizing train dataset (num_proc=32):  12%|█▏        | 5617/47780 [00:22<01:35, 440.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5520/47780 [00:22<01:37, 432.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5700/47780 [00:22<01:19, 528.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5286/47780 [00:22<02:36, 271.60 examples/s]Tokenizing train dataset (num_proc=32):  12%|█▏        | 5765/47780 [00:23<02:25, 289.53 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5634/47780 [00:22<01:40, 420.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6089/47780 [00:23<01:39, 419.18 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5559/47780 [00:23<02:50, 247.61 examples/s]Tokenizing train dataset (num_proc=32):  11%|█         | 5361/47780 [00:23<02:23, 296.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 5984/47780 [00:23<01:37, 427.52 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5605/47780 [00:23<01:46, 394.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5834/47780 [00:23<01:22, 509.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5873/47780 [00:23<02:37, 266.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6184/47780 [00:24<01:40, 414.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6290/47780 [00:24<02:11, 316.42 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6631/47780 [00:24<01:27, 467.62 examples/s]Tokenizing train dataset (num_proc=32):  12%|█▏        | 5789/47780 [00:24<03:17, 213.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6175/47780 [00:24<03:01, 228.84 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▍        | 6936/47780 [00:24<01:04, 638.09 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6033/47780 [00:24<02:18, 301.02 examples/s]Tokenizing train dataset (num_proc=32):  13%|█▎        | 6309/47780 [00:24<02:33, 269.82 examples/s]Tokenizing train dataset (num_proc=32):  12%|█▏        | 5834/47780 [00:24<02:31, 276.50 examples/s]Tokenizing train dataset (num_proc=32):  13%|█▎        | 6307/47780 [00:24<01:36, 430.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7163/47780 [00:24<00:53, 758.31 examples/s]Tokenizing train dataset (num_proc=32):  13%|█▎        | 6107/47780 [00:24<01:47, 386.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6437/47780 [00:24<02:11, 314.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6728/47780 [00:24<01:24, 485.97 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▌        | 7374/47780 [00:24<00:53, 756.71 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6896/47780 [00:24<01:09, 586.22 examples/s]Tokenizing train dataset (num_proc=32):  13%|█▎        | 6193/47780 [00:25<02:23, 289.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7055/47780 [00:25<01:06, 610.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6439/47780 [00:25<01:47, 385.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6022/47780 [00:25<02:20, 297.06 examples/s]Tokenizing train dataset (num_proc=32):  13%|█▎        | 6172/47780 [00:25<01:55, 360.14 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7544/47780 [00:25<01:09, 582.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7187/47780 [00:25<01:14, 541.72 examples/s]Tokenizing train dataset (num_proc=32):  13%|█▎        | 6360/47780 [00:25<02:46, 248.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7292/47780 [00:25<01:21, 496.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6678/47780 [00:25<01:47, 382.84 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7673/47780 [00:25<01:23, 481.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7377/47780 [00:25<01:23, 484.63 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7450/47780 [00:26<01:23, 481.33 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▋        | 7772/47780 [00:26<01:29, 445.68 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▎        | 6498/47780 [00:26<02:41, 255.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7515/47780 [00:26<01:27, 462.03 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6648/47780 [00:26<02:11, 312.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7575/47780 [00:26<01:24, 475.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7851/47780 [00:26<01:34, 422.36 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7632/47780 [00:26<01:28, 453.29 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6610/47780 [00:26<02:33, 267.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6285/47780 [00:26<03:05, 223.67 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 7917/47780 [00:26<01:37, 408.54 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6882/47780 [00:26<01:47, 380.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7683/47780 [00:26<01:31, 438.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7974/47780 [00:26<01:40, 396.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7731/47780 [00:26<01:44, 382.55 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8024/47780 [00:26<01:39, 397.58 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▋        | 7781/47780 [00:26<01:39, 401.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6312/47780 [00:26<03:13, 214.51 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8071/47780 [00:27<01:43, 384.36 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▎        | 6480/47780 [00:26<02:26, 282.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7827/47780 [00:27<01:40, 396.34 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6733/47780 [00:27<01:36, 423.88 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8115/47780 [00:27<01:48, 365.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7869/47780 [00:27<01:44, 383.56 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6859/47780 [00:27<02:36, 261.92 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7910/47780 [00:27<01:46, 374.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8155/47780 [00:27<01:51, 354.55 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▍        | 7110/47780 [00:27<01:50, 367.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8197/47780 [00:27<01:47, 368.14 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7949/47780 [00:27<01:52, 354.81 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 7985/47780 [00:27<01:55, 344.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8236/47780 [00:27<02:02, 323.64 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8020/47780 [00:27<02:00, 330.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8294/47780 [00:27<01:43, 380.37 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8054/47780 [00:27<01:59, 331.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8343/47780 [00:27<01:37, 406.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8089/47780 [00:27<02:01, 326.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8387/47780 [00:27<01:47, 366.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8123/47780 [00:27<02:01, 326.84 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8427/47780 [00:28<01:49, 360.55 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8172/47780 [00:28<01:46, 371.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6818/47780 [00:28<03:26, 198.75 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8465/47780 [00:28<01:50, 354.78 examples/s]Tokenizing train dataset (num_proc=32):  13%|█▎        | 6412/47780 [00:28<04:07, 167.09 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8210/47780 [00:28<01:46, 370.38 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▍        | 7100/47780 [00:28<02:11, 308.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7040/47780 [00:28<02:51, 237.69 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8502/47780 [00:28<01:50, 355.31 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6748/47780 [00:28<02:28, 276.38 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8248/47780 [00:28<01:46, 372.48 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▌        | 7258/47780 [00:28<01:47, 378.19 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7257/47780 [00:28<02:05, 323.38 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8542/47780 [00:28<01:46, 367.20 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8286/47780 [00:28<01:47, 366.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7442/47780 [00:28<01:37, 412.77 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8580/47780 [00:28<01:51, 351.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8323/47780 [00:28<01:52, 351.22 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8616/47780 [00:28<01:50, 352.92 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8361/47780 [00:28<01:49, 359.13 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8652/47780 [00:28<01:51, 351.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8399/47780 [00:28<01:48, 361.38 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8699/47780 [00:28<01:42, 381.18 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8438/47780 [00:28<01:51, 353.36 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7593/47780 [00:28<01:42, 390.89 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8744/47780 [00:28<01:37, 400.86 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8476/47780 [00:28<01:48, 360.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7278/47780 [00:28<02:56, 229.37 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8786/47780 [00:28<01:36, 404.70 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6892/47780 [00:28<03:11, 213.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8513/47780 [00:29<01:54, 343.72 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▌        | 7398/47780 [00:28<02:29, 269.52 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8832/47780 [00:29<01:34, 413.05 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▌        | 7289/47780 [00:29<01:44, 386.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8551/47780 [00:29<01:53, 346.25 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7709/47780 [00:29<01:43, 386.79 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7714/47780 [00:29<01:33, 428.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8876/47780 [00:29<01:36, 401.67 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8586/47780 [00:29<01:59, 328.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8917/47780 [00:29<01:38, 395.56 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8631/47780 [00:29<01:49, 358.28 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8957/47780 [00:29<01:39, 391.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7801/47780 [00:29<01:46, 377.03 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8668/47780 [00:29<01:55, 338.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 8997/47780 [00:29<01:42, 377.45 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8703/47780 [00:29<02:04, 314.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9039/47780 [00:29<01:40, 384.90 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▋        | 7877/47780 [00:29<01:51, 358.76 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8735/47780 [00:29<02:07, 305.97 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9078/47780 [00:29<01:43, 373.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6910/47780 [00:29<03:18, 205.60 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8770/47780 [00:29<02:05, 311.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7234/47780 [00:29<02:05, 323.55 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9116/47780 [00:29<01:48, 355.12 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 7939/47780 [00:29<01:57, 338.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8805/47780 [00:29<02:01, 321.85 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9152/47780 [00:29<01:53, 341.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8842/47780 [00:30<01:58, 328.05 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7407/47780 [00:30<03:17, 204.56 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9188/47780 [00:30<01:52, 343.08 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 7990/47780 [00:30<02:01, 327.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8878/47780 [00:30<01:59, 325.95 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▋        | 7792/47780 [00:30<01:48, 368.84 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9223/47780 [00:30<01:55, 332.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8911/47780 [00:30<01:58, 327.03 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8034/47780 [00:30<02:05, 315.52 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9263/47780 [00:30<01:50, 348.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8944/47780 [00:30<01:59, 324.33 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8075/47780 [00:30<02:01, 327.75 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9299/47780 [00:30<01:59, 322.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 8977/47780 [00:30<02:02, 317.97 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8115/47780 [00:30<01:57, 336.67 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9342/47780 [00:30<01:51, 344.32 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▋        | 7863/47780 [00:30<02:32, 261.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9016/47780 [00:30<01:56, 331.66 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7488/47780 [00:30<02:35, 259.72 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8154/47780 [00:30<02:03, 320.85 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8162/47780 [00:30<01:38, 404.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9378/47780 [00:30<01:57, 326.74 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9056/47780 [00:30<01:51, 347.23 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7728/47780 [00:30<01:52, 356.16 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8192/47780 [00:30<01:58, 333.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9425/47780 [00:30<01:46, 361.75 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9095/47780 [00:30<01:48, 355.42 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8229/47780 [00:30<02:04, 317.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9462/47780 [00:30<01:49, 348.64 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9139/47780 [00:30<01:41, 379.62 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8326/47780 [00:30<01:32, 425.05 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8270/47780 [00:30<01:59, 330.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9502/47780 [00:30<01:45, 362.41 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9178/47780 [00:30<01:44, 369.56 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8306/47780 [00:31<01:56, 337.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9546/47780 [00:31<01:39, 384.03 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9220/47780 [00:31<01:41, 380.09 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8342/47780 [00:31<01:55, 340.23 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9586/47780 [00:31<01:43, 368.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9259/47780 [00:31<01:44, 370.04 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9624/47780 [00:31<01:44, 366.85 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8377/47780 [00:31<02:04, 315.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7499/47780 [00:31<02:37, 255.17 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8456/47780 [00:31<01:40, 391.29 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9301/47780 [00:31<02:06, 304.61 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8410/47780 [00:31<02:05, 312.73 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9664/47780 [00:31<01:46, 356.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7738/47780 [00:31<01:56, 343.17 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9708/47780 [00:31<01:40, 379.36 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8442/47780 [00:31<02:16, 287.27 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8099/47780 [00:31<01:16, 521.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9334/47780 [00:31<02:29, 257.93 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9747/47780 [00:31<01:46, 358.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8482/47780 [00:31<02:05, 313.01 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9363/47780 [00:31<02:37, 243.18 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8556/47780 [00:31<01:45, 370.59 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9787/47780 [00:31<01:46, 357.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8515/47780 [00:31<02:04, 314.25 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 7982/47780 [00:31<02:46, 238.80 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9493/47780 [00:31<01:19, 482.73 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9827/47780 [00:31<01:43, 365.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8550/47780 [00:31<02:01, 323.67 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8360/47780 [00:31<01:41, 389.42 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9867/47780 [00:31<01:42, 370.96 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8589/47780 [00:31<01:56, 335.19 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8635/47780 [00:31<01:47, 362.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9551/47780 [00:31<01:25, 447.02 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8626/47780 [00:32<01:54, 343.35 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9905/47780 [00:32<01:47, 353.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9603/47780 [00:32<01:27, 433.95 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9941/47780 [00:32<01:46, 355.05 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8661/47780 [00:32<01:59, 328.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8703/47780 [00:32<01:51, 349.28 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9651/47780 [00:32<01:29, 428.37 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9980/47780 [00:32<01:44, 361.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8695/47780 [00:32<01:59, 327.82 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9702/47780 [00:32<01:26, 440.75 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8563/47780 [00:32<01:35, 408.60 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8758/47780 [00:32<01:53, 342.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10017/47780 [00:32<01:46, 355.62 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8728/47780 [00:32<02:11, 298.01 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9749/47780 [00:32<01:30, 421.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10056/47780 [00:32<01:45, 357.29 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8806/47780 [00:32<01:55, 337.55 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8770/47780 [00:32<02:00, 323.74 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9793/47780 [00:32<01:34, 402.86 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 7900/47780 [00:32<03:09, 210.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10092/47780 [00:32<01:46, 354.85 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8849/47780 [00:32<01:51, 347.99 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8803/47780 [00:32<02:04, 312.54 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9840/47780 [00:32<01:30, 419.13 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8132/47780 [00:32<02:15, 292.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10128/47780 [00:32<01:50, 339.59 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8892/47780 [00:32<01:50, 351.50 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8842/47780 [00:32<01:56, 332.96 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8354/47780 [00:32<01:39, 396.09 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9883/47780 [00:32<01:32, 408.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8721/47780 [00:32<01:40, 387.06 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10169/47780 [00:32<01:46, 351.76 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8933/47780 [00:32<01:48, 357.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8876/47780 [00:32<01:57, 330.46 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10205/47780 [00:32<01:47, 349.35 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8910/47780 [00:32<01:59, 326.09 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9925/47780 [00:32<01:52, 335.66 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 8973/47780 [00:32<01:52, 345.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8310/47780 [00:32<02:02, 323.26 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10248/47780 [00:33<01:41, 368.81 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9974/47780 [00:33<01:41, 372.32 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8943/47780 [00:33<02:06, 306.34 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9011/47780 [00:33<01:51, 347.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8496/47780 [00:33<01:38, 399.26 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10285/47780 [00:33<01:41, 368.65 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8841/47780 [00:33<01:43, 376.71 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 8985/47780 [00:33<01:58, 327.19 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10014/47780 [00:33<01:47, 350.37 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9048/47780 [00:33<01:55, 336.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8656/47780 [00:33<01:22, 475.56 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10322/47780 [00:33<01:43, 361.33 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9086/47780 [00:33<01:53, 340.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8887/47780 [00:33<01:01, 634.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10051/47780 [00:33<01:54, 329.30 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9018/47780 [00:33<02:15, 285.56 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10359/47780 [00:33<01:47, 347.24 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9123/47780 [00:33<01:51, 345.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8935/47780 [00:33<01:43, 375.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10095/47780 [00:33<01:47, 349.94 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9065/47780 [00:33<01:58, 327.42 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10398/47780 [00:33<01:45, 355.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9160/47780 [00:33<01:52, 342.03 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10137/47780 [00:33<01:43, 364.42 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9100/47780 [00:33<01:56, 332.91 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10438/47780 [00:33<01:42, 364.13 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9064/47780 [00:33<01:02, 620.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9195/47780 [00:33<01:53, 338.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9012/47780 [00:33<01:44, 371.44 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9142/47780 [00:33<01:49, 353.44 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10175/47780 [00:33<01:46, 352.60 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10475/47780 [00:33<01:43, 361.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9232/47780 [00:33<01:50, 347.40 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10211/47780 [00:33<01:47, 348.04 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9179/47780 [00:33<01:51, 345.07 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10513/47780 [00:33<01:45, 354.27 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9270/47780 [00:33<01:56, 331.81 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9078/47780 [00:33<01:49, 354.22 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9229/47780 [00:33<01:42, 377.21 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10549/47780 [00:33<01:47, 344.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10247/47780 [00:33<01:53, 329.56 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9305/47780 [00:33<01:54, 335.43 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9277/47780 [00:33<01:34, 405.59 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10584/47780 [00:34<01:48, 342.40 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10282/47780 [00:34<01:58, 317.68 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9206/47780 [00:33<01:12, 530.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9132/47780 [00:34<01:51, 347.02 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9320/47780 [00:34<01:36, 397.38 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10619/47780 [00:34<01:50, 336.96 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9339/47780 [00:34<02:12, 290.14 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10315/47780 [00:34<02:00, 311.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9179/47780 [00:34<01:46, 363.02 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9361/47780 [00:34<01:36, 397.97 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9397/47780 [00:34<01:46, 361.86 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10353/47780 [00:34<01:53, 329.64 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10653/47780 [00:34<01:58, 312.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9228/47780 [00:34<01:42, 376.39 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9316/47780 [00:34<01:17, 496.95 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9403/47780 [00:34<01:35, 403.91 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10391/47780 [00:34<01:49, 340.26 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10688/47780 [00:34<01:56, 319.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9436/47780 [00:34<01:52, 339.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9276/47780 [00:34<01:38, 389.66 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9444/47780 [00:34<01:44, 367.39 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10426/47780 [00:34<01:51, 335.48 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10724/47780 [00:34<01:53, 327.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9472/47780 [00:34<01:51, 344.93 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9322/47780 [00:34<01:36, 396.83 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9406/47780 [00:34<01:21, 470.20 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10461/47780 [00:34<01:51, 335.44 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10758/47780 [00:34<01:53, 327.23 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9509/47780 [00:34<01:49, 348.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8527/47780 [00:34<02:55, 223.25 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9369/47780 [00:34<01:33, 410.15 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10791/47780 [00:34<01:52, 327.89 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10495/47780 [00:34<01:54, 325.26 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9546/47780 [00:34<01:51, 343.09 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9482/47780 [00:34<02:30, 254.78 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9414/47780 [00:34<01:35, 400.58 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9481/47780 [00:34<01:24, 455.21 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10824/47780 [00:34<01:52, 327.17 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8651/47780 [00:34<02:31, 258.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9581/47780 [00:34<01:51, 341.27 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10528/47780 [00:34<02:05, 296.74 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9457/47780 [00:34<01:35, 403.38 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10863/47780 [00:34<01:47, 342.93 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8944/47780 [00:34<01:34, 410.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9618/47780 [00:34<01:50, 345.56 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10588/47780 [00:34<01:40, 370.52 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9513/47780 [00:34<02:53, 220.04 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9545/47780 [00:34<01:29, 428.64 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9501/47780 [00:34<01:33, 409.10 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10902/47780 [00:34<01:44, 352.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9122/47780 [00:34<01:15, 512.04 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9653/47780 [00:34<01:54, 331.68 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9600/47780 [00:34<01:25, 446.54 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10626/47780 [00:35<01:42, 360.76 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9551/47780 [00:34<01:30, 424.32 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9539/47780 [00:34<03:01, 210.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10939/47780 [00:35<01:44, 353.64 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9691/47780 [00:35<01:51, 341.25 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10673/47780 [00:35<01:34, 390.67 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9601/47780 [00:35<01:26, 440.27 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9671/47780 [00:35<01:26, 438.90 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10981/47780 [00:35<01:41, 363.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9655/47780 [00:35<01:31, 418.02 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9734/47780 [00:35<01:44, 365.58 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10730/47780 [00:35<01:24, 436.76 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9646/47780 [00:35<01:29, 426.75 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11018/47780 [00:35<01:42, 358.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9704/47780 [00:35<01:29, 424.16 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9774/47780 [00:35<01:43, 367.84 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9284/47780 [00:35<01:17, 497.77 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9726/47780 [00:35<01:39, 380.62 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10775/47780 [00:35<01:33, 395.57 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11062/47780 [00:35<01:37, 377.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9690/47780 [00:35<01:38, 385.12 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9821/47780 [00:35<01:37, 388.40 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9752/47780 [00:35<01:36, 393.79 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11102/47780 [00:35<01:36, 379.59 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10816/47780 [00:35<01:40, 367.97 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9730/47780 [00:35<01:40, 376.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9773/47780 [00:35<01:45, 360.22 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9862/47780 [00:35<01:39, 381.45 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9795/47780 [00:35<01:40, 376.60 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11146/47780 [00:35<01:33, 392.57 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10856/47780 [00:35<01:38, 376.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9769/47780 [00:35<01:41, 374.85 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9904/47780 [00:35<01:36, 392.19 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9816/47780 [00:35<01:53, 335.05 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9411/47780 [00:35<01:22, 463.12 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9838/47780 [00:35<01:38, 385.02 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10895/47780 [00:35<01:40, 368.06 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11187/47780 [00:35<01:36, 379.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9809/47780 [00:35<01:41, 374.40 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9944/47780 [00:35<01:38, 384.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9854/47780 [00:35<01:56, 325.70 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10933/47780 [00:35<01:43, 355.78 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9879/47780 [00:35<01:48, 347.86 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11227/47780 [00:35<01:40, 363.88 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9983/47780 [00:35<01:45, 357.23 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9847/47780 [00:35<01:59, 316.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9890/47780 [00:35<01:59, 315.83 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9511/47780 [00:35<01:25, 447.26 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9916/47780 [00:35<01:48, 349.88 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10969/47780 [00:35<01:47, 341.46 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11264/47780 [00:35<01:47, 340.31 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9894/47780 [00:35<01:47, 352.25 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10021/47780 [00:35<01:48, 349.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9925/47780 [00:35<01:58, 320.69 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9953/47780 [00:35<01:47, 351.39 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11004/47780 [00:36<01:47, 342.28 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11300/47780 [00:36<01:46, 342.69 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10058/47780 [00:36<01:48, 347.48 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9931/47780 [00:36<01:50, 342.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9593/47780 [00:36<01:25, 445.13 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9959/47780 [00:36<01:58, 319.28 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9991/47780 [00:36<01:46, 355.22 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11039/47780 [00:36<01:51, 328.05 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11341/47780 [00:36<01:44, 348.89 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10093/47780 [00:36<01:48, 347.71 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9967/47780 [00:36<01:53, 332.56 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10042/47780 [00:36<01:36, 392.40 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9992/47780 [00:36<02:04, 303.27 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11073/47780 [00:36<01:53, 324.40 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11377/47780 [00:36<01:44, 348.12 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9667/47780 [00:36<01:28, 431.97 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10128/47780 [00:36<01:53, 330.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10002/47780 [00:36<01:55, 327.44 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10024/47780 [00:36<02:06, 298.31 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10082/47780 [00:36<01:42, 366.73 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11107/47780 [00:36<01:52, 325.22 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11412/47780 [00:36<01:44, 347.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10162/47780 [00:36<01:55, 325.37 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10037/47780 [00:36<01:59, 316.51 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10056/47780 [00:36<02:05, 300.91 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11143/47780 [00:36<01:49, 334.85 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9728/47780 [00:36<01:31, 415.03 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10128/47780 [00:36<01:37, 387.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11451/47780 [00:36<01:44, 348.77 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10195/47780 [00:36<02:01, 310.50 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10070/47780 [00:36<01:57, 319.99 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10093/47780 [00:36<01:58, 316.92 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10173/47780 [00:36<01:33, 404.24 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11177/47780 [00:36<01:52, 324.58 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11493/47780 [00:36<01:38, 368.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9783/47780 [00:36<01:32, 412.55 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10103/47780 [00:36<01:58, 319.16 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10129/47780 [00:36<01:54, 328.08 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10229/47780 [00:36<02:09, 289.07 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11215/47780 [00:36<01:48, 337.33 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11531/47780 [00:36<01:38, 367.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10215/47780 [00:36<01:37, 386.58 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9833/47780 [00:36<01:33, 405.72 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10143/47780 [00:36<01:51, 338.27 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10170/47780 [00:36<01:48, 347.33 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10284/47780 [00:36<01:46, 353.74 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11570/47780 [00:36<01:37, 370.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10259/47780 [00:36<01:34, 397.41 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9879/47780 [00:36<01:33, 406.48 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10206/47780 [00:36<01:49, 344.01 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10178/47780 [00:36<01:58, 316.37 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10321/47780 [00:36<01:45, 356.11 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11616/47780 [00:36<01:32, 390.91 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11249/47780 [00:36<02:27, 247.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10301/47780 [00:36<01:39, 376.95 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9924/47780 [00:36<01:32, 408.15 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10242/47780 [00:36<01:48, 347.47 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10359/47780 [00:36<01:44, 356.96 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10211/47780 [00:36<02:02, 306.26 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11661/47780 [00:37<01:29, 404.21 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11333/47780 [00:37<01:35, 380.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10341/47780 [00:36<01:42, 364.10 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10279/47780 [00:37<01:47, 350.08 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9968/47780 [00:37<01:39, 381.60 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11703/47780 [00:37<01:28, 408.40 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10249/47780 [00:37<01:58, 316.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10396/47780 [00:37<01:50, 337.86 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10378/47780 [00:37<01:45, 354.48 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11377/47780 [00:37<01:41, 359.58 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10316/47780 [00:37<01:47, 347.59 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10285/47780 [00:37<01:55, 324.77 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11744/47780 [00:37<01:35, 377.99 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10008/47780 [00:37<01:45, 357.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10431/47780 [00:37<01:56, 319.99 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10414/47780 [00:37<01:48, 344.90 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11418/47780 [00:37<01:44, 348.22 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10318/47780 [00:37<01:56, 322.28 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10351/47780 [00:37<01:58, 315.60 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10057/47780 [00:37<01:37, 386.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10464/47780 [00:37<01:58, 315.81 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11783/47780 [00:37<01:43, 346.38 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10451/47780 [00:37<01:48, 344.03 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11456/47780 [00:37<01:47, 339.16 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10351/47780 [00:37<01:56, 321.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10098/47780 [00:37<01:35, 392.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10384/47780 [00:37<02:07, 293.51 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10496/47780 [00:37<02:04, 300.19 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10487/47780 [00:37<01:47, 345.65 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11819/47780 [00:37<01:46, 339.06 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10385/47780 [00:37<01:57, 319.33 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11492/47780 [00:37<01:53, 318.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10145/47780 [00:37<01:32, 408.70 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10414/47780 [00:37<02:11, 283.94 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10533/47780 [00:37<01:59, 312.91 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10524/47780 [00:37<01:47, 347.82 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11855/47780 [00:37<01:46, 337.81 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11541/47780 [00:37<01:41, 358.11 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10417/47780 [00:37<02:01, 308.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10189/47780 [00:37<01:31, 412.93 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10446/47780 [00:37<02:07, 293.45 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10565/47780 [00:37<01:59, 311.48 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10559/47780 [00:37<01:47, 344.75 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11892/47780 [00:37<01:46, 335.66 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11590/47780 [00:37<01:32, 392.41 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10232/47780 [00:37<01:29, 417.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10448/47780 [00:37<02:03, 302.53 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10480/47780 [00:37<02:03, 302.85 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10597/47780 [00:37<02:07, 291.10 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11930/47780 [00:37<01:44, 344.01 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10594/47780 [00:37<01:58, 313.93 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10276/47780 [00:37<01:28, 423.41 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11631/47780 [00:37<01:33, 388.39 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10481/47780 [00:37<02:01, 306.81 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10513/47780 [00:37<02:00, 310.20 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11965/47780 [00:37<01:43, 345.65 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10627/47780 [00:37<02:09, 287.03 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10634/47780 [00:37<01:51, 333.44 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11673/47780 [00:37<01:31, 392.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10520/47780 [00:37<01:52, 330.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10319/47780 [00:37<01:34, 398.23 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10554/47780 [00:37<01:52, 331.49 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12001/47780 [00:38<01:42, 349.56 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10661/47780 [00:37<02:04, 298.60 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10673/47780 [00:37<01:47, 345.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10555/47780 [00:38<01:50, 335.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10362/47780 [00:38<01:32, 402.65 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11714/47780 [00:38<01:38, 367.80 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10589/47780 [00:38<01:51, 332.98 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12039/47780 [00:38<01:39, 358.10 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10692/47780 [00:38<02:05, 295.46 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10709/47780 [00:38<01:46, 349.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10592/47780 [00:38<01:50, 337.61 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11752/47780 [00:38<01:43, 349.63 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12079/47780 [00:38<01:37, 366.57 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10630/47780 [00:38<01:53, 328.57 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10725/47780 [00:38<02:01, 304.83 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10745/47780 [00:38<01:45, 352.12 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10404/47780 [00:38<01:50, 338.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10626/47780 [00:38<01:50, 335.44 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11789/47780 [00:38<01:41, 354.55 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12116/47780 [00:38<01:39, 359.12 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10672/47780 [00:38<01:44, 353.68 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10761/47780 [00:38<01:55, 320.59 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10781/47780 [00:38<01:45, 350.17 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10451/47780 [00:38<01:41, 366.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10660/47780 [00:38<01:51, 332.80 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12152/47780 [00:38<01:40, 354.98 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10794/47780 [00:38<01:55, 319.25 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11825/47780 [00:38<01:47, 334.05 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10708/47780 [00:38<01:52, 329.53 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10817/47780 [00:38<01:49, 337.42 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10490/47780 [00:38<01:44, 355.26 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 1/47780 [00:38<509:36:48, 38.40s/ examples]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10697/47780 [00:38<01:50, 335.75 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12188/47780 [00:38<01:41, 352.31 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10827/47780 [00:38<01:55, 318.78 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10871/47780 [00:38<01:34, 390.96 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10742/47780 [00:38<01:53, 325.22 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11859/47780 [00:38<01:53, 315.26 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10532/47780 [00:38<01:40, 372.17 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10745/47780 [00:38<01:38, 374.67 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 25/47780 [00:38<14:30:53,  1.09s/ examples]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10867/47780 [00:38<01:47, 341.95 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12224/47780 [00:38<01:46, 334.94 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10776/47780 [00:38<01:53, 325.68 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11895/47780 [00:38<01:51, 320.72 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10911/47780 [00:38<01:35, 384.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10571/47780 [00:38<01:40, 368.98 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10783/47780 [00:38<01:41, 364.37 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10902/47780 [00:38<01:52, 328.94 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10828/47780 [00:38<01:38, 375.97 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11934/47780 [00:38<01:47, 332.27 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10950/47780 [00:38<01:38, 372.89 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12258/47780 [00:38<01:55, 308.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10609/47780 [00:38<01:40, 371.68 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10831/47780 [00:38<01:33, 394.96 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10939/47780 [00:38<01:49, 337.60 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10872/47780 [00:38<01:33, 393.91 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11971/47780 [00:38<01:44, 342.51 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12296/47780 [00:38<01:49, 324.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10653/47780 [00:38<01:35, 387.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10871/47780 [00:38<01:33, 395.92 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10988/47780 [00:38<01:45, 347.85 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10973/47780 [00:38<01:50, 332.30 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10912/47780 [00:38<01:36, 382.82 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12006/47780 [00:38<01:44, 340.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12329/47780 [00:38<01:49, 322.65 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10912/47780 [00:38<01:37, 378.77 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10693/47780 [00:38<01:43, 358.39 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11025/47780 [00:38<01:48, 338.96 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11011/47780 [00:38<01:48, 340.33 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12044/47780 [00:39<01:42, 348.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10951/47780 [00:39<01:38, 372.11 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12362/47780 [00:39<01:56, 304.21 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11064/47780 [00:39<01:44, 352.02 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10735/47780 [00:39<01:41, 363.28 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10951/47780 [00:39<01:40, 365.15 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12082/47780 [00:39<01:41, 353.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11047/47780 [00:39<01:55, 316.76 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12405/47780 [00:39<01:45, 334.89 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10989/47780 [00:39<01:46, 346.66 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10772/47780 [00:39<01:42, 360.76 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11100/47780 [00:39<01:51, 329.46 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10992/47780 [00:39<01:43, 353.87 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12123/47780 [00:39<01:38, 361.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11084/47780 [00:39<01:50, 331.11 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12443/47780 [00:39<01:41, 347.22 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11032/47780 [00:39<01:43, 354.12 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10809/47780 [00:39<01:42, 359.78 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11029/47780 [00:39<01:43, 354.45 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11134/47780 [00:39<01:53, 321.87 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12160/47780 [00:39<01:39, 359.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11118/47780 [00:39<01:49, 333.55 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12482/47780 [00:39<01:39, 355.59 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10854/47780 [00:39<01:36, 382.52 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11068/47780 [00:39<01:46, 343.42 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11167/47780 [00:39<01:55, 316.79 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11065/47780 [00:39<01:47, 340.85 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11156/47780 [00:39<01:46, 343.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12197/47780 [00:39<01:42, 346.70 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12534/47780 [00:39<01:30, 389.35 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11106/47780 [00:39<01:45, 346.97 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10893/47780 [00:39<01:43, 357.64 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11201/47780 [00:39<01:54, 320.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11100/47780 [00:39<01:58, 309.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11191/47780 [00:39<01:49, 332.81 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12574/47780 [00:39<01:30, 387.38 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12232/47780 [00:39<01:50, 322.19 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11141/47780 [00:39<01:46, 344.00 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10932/47780 [00:39<01:42, 359.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11235/47780 [00:39<01:56, 314.95 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11133/47780 [00:39<01:57, 311.43 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11227/47780 [00:39<01:51, 326.56 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12272/47780 [00:39<01:44, 339.55 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12613/47780 [00:39<01:35, 367.08 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11176/47780 [00:39<01:51, 327.32 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11270/47780 [00:39<01:52, 324.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10971/47780 [00:39<01:44, 352.61 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11168/47780 [00:39<01:56, 315.00 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11261/47780 [00:39<01:50, 330.28 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12310/47780 [00:39<01:42, 346.88 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12652/47780 [00:39<01:34, 370.00 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11213/47780 [00:39<01:48, 335.64 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11015/47780 [00:39<01:37, 376.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11310/47780 [00:39<01:48, 337.38 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11314/47780 [00:39<01:34, 387.06 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11200/47780 [00:39<01:59, 305.74 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12358/47780 [00:39<01:33, 378.19 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12694/47780 [00:39<01:31, 384.14 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11250/47780 [00:39<01:45, 345.15 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11055/47780 [00:39<01:36, 378.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11351/47780 [00:39<01:42, 355.44 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11235/47780 [00:39<01:55, 315.06 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12397/47780 [00:40<01:34, 374.98 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11354/47780 [00:39<01:41, 357.93 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11289/47780 [00:40<01:43, 353.71 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12733/47780 [00:40<01:38, 356.71 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11094/47780 [00:40<01:36, 381.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11387/47780 [00:40<01:44, 348.59 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11279/47780 [00:40<01:44, 349.82 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11391/47780 [00:40<01:42, 354.16 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11326/47780 [00:40<01:41, 358.19 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12437/47780 [00:40<01:40, 351.92 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12770/47780 [00:40<01:40, 349.22 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11426/47780 [00:40<01:40, 360.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11133/47780 [00:40<01:43, 355.57 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11315/47780 [00:40<01:43, 352.61 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11428/47780 [00:40<01:43, 349.93 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11371/47780 [00:40<01:36, 376.44 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12812/47780 [00:40<01:35, 364.68 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11465/47780 [00:40<01:38, 368.74 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12473/47780 [00:40<01:45, 333.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11170/47780 [00:40<01:41, 358.92 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11351/47780 [00:40<01:46, 342.91 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11466/47780 [00:40<01:41, 358.00 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11409/47780 [00:40<01:39, 364.50 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11503/47780 [00:40<01:37, 372.04 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12849/47780 [00:40<01:36, 362.20 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12517/47780 [00:40<01:37, 360.54 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11215/47780 [00:40<01:37, 376.86 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11386/47780 [00:40<01:47, 337.18 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11541/47780 [00:40<01:37, 370.52 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11503/47780 [00:40<01:48, 334.98 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11446/47780 [00:40<01:41, 357.87 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12554/47780 [00:40<01:37, 361.06 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12888/47780 [00:40<01:39, 350.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11254/47780 [00:40<01:38, 372.14 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11424/47780 [00:40<01:45, 345.84 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 45/47780 [00:40<7:25:10,  1.79 examples/s] Tokenizing train dataset (num_proc=32):  24%|██▍       | 11539/47780 [00:40<01:46, 341.59 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11482/47780 [00:40<01:43, 350.41 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12591/47780 [00:40<01:39, 352.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12930/47780 [00:40<01:34, 369.24 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11579/47780 [00:40<01:46, 340.45 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11292/47780 [00:40<01:39, 366.05 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11468/47780 [00:40<01:41, 356.27 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11518/47780 [00:40<01:43, 349.59 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12628/47780 [00:40<01:38, 357.07 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11574/47780 [00:40<01:51, 325.92 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12970/47780 [00:40<01:35, 365.34 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11619/47780 [00:40<01:42, 353.70 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 68/47780 [00:40<3:59:23,  3.32 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11330/47780 [00:40<01:39, 365.68 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11509/47780 [00:40<01:39, 363.32 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11553/47780 [00:40<01:46, 338.95 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11608/47780 [00:40<01:52, 322.70 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12664/47780 [00:40<01:41, 346.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13026/47780 [00:40<01:23, 416.07 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11655/47780 [00:40<01:43, 348.45 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11367/47780 [00:40<01:41, 358.36 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11554/47780 [00:40<01:34, 383.63 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11589/47780 [00:40<01:45, 344.02 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11642/47780 [00:40<01:53, 317.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12713/47780 [00:40<01:32, 377.15 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13068/47780 [00:40<01:27, 398.54 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11693/47780 [00:40<01:44, 344.50 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11403/47780 [00:40<01:44, 347.03 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 78/47780 [00:40<3:09:50,  4.19 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11596/47780 [00:40<01:32, 389.55 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11629/47780 [00:40<01:40, 359.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11676/47780 [00:40<01:51, 323.27 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12751/47780 [00:41<01:35, 366.63 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11733/47780 [00:40<01:40, 359.93 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11441/47780 [00:41<01:43, 352.73 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13109/47780 [00:41<01:32, 376.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11636/47780 [00:41<01:38, 367.14 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11709/47780 [00:41<01:57, 307.68 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12789/47780 [00:41<01:37, 358.30 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11481/47780 [00:41<01:39, 365.99 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11770/47780 [00:41<01:48, 332.90 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13148/47780 [00:41<01:34, 368.13 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11669/47780 [00:41<01:56, 310.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11673/47780 [00:41<01:42, 352.35 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11519/47780 [00:41<01:38, 369.90 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12825/47780 [00:41<01:40, 347.22 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11741/47780 [00:41<02:02, 294.86 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11804/47780 [00:41<01:47, 334.33 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13188/47780 [00:41<01:35, 361.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11711/47780 [00:41<01:41, 356.06 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11560/47780 [00:41<01:35, 377.58 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12870/47780 [00:41<01:32, 375.75 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11775/47780 [00:41<01:57, 306.97 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11702/47780 [00:41<02:21, 254.94 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11838/47780 [00:41<01:50, 325.02 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13227/47780 [00:41<01:33, 368.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11757/47780 [00:41<01:34, 380.93 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11599/47780 [00:41<01:35, 376.98 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11807/47780 [00:41<01:57, 307.31 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11781/47780 [00:41<01:36, 374.16 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12911/47780 [00:41<01:38, 353.27 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13265/47780 [00:41<01:35, 360.11 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11871/47780 [00:41<02:04, 288.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11796/47780 [00:41<01:37, 368.10 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11843/47780 [00:41<01:53, 318.02 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11638/47780 [00:41<01:40, 359.16 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11824/47780 [00:41<01:39, 363.06 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12947/47780 [00:41<01:41, 343.71 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11920/47780 [00:41<01:45, 340.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13302/47780 [00:41<01:44, 329.75 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11835/47780 [00:41<01:43, 345.90 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11676/47780 [00:41<01:38, 364.70 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12984/47780 [00:41<01:40, 347.23 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11864/47780 [00:41<01:42, 351.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13341/47780 [00:41<01:41, 338.61 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11875/47780 [00:41<02:19, 257.38 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11956/47780 [00:41<01:52, 318.45 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11870/47780 [00:41<01:44, 343.33 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11714/47780 [00:41<01:38, 365.89 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13028/47780 [00:41<01:34, 369.07 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13377/47780 [00:41<01:40, 340.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11902/47780 [00:41<01:45, 341.36 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11936/47780 [00:41<01:43, 344.69 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11995/47780 [00:41<01:48, 330.18 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11906/47780 [00:41<01:44, 343.80 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11759/47780 [00:41<01:33, 385.68 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13066/47780 [00:41<01:39, 348.52 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13426/47780 [00:41<01:29, 382.05 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11974/47780 [00:41<01:43, 346.87 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11938/47780 [00:41<01:54, 314.25 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11941/47780 [00:41<01:47, 334.29 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11801/47780 [00:41<01:34, 382.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12029/47780 [00:41<01:55, 309.21 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13465/47780 [00:42<01:31, 375.80 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12012/47780 [00:42<01:41, 351.89 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13103/47780 [00:42<01:47, 321.92 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11973/47780 [00:42<01:51, 319.91 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11975/47780 [00:42<01:50, 324.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12061/47780 [00:42<01:57, 305.07 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13504/47780 [00:42<01:30, 379.62 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11840/47780 [00:42<01:51, 321.69 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13137/47780 [00:42<01:46, 326.62 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12050/47780 [00:42<01:42, 347.76 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12011/47780 [00:42<01:46, 334.58 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12006/47780 [00:42<01:55, 309.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12093/47780 [00:42<01:58, 300.90 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13176/47780 [00:42<01:41, 340.95 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11897/47780 [00:42<01:36, 372.72 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13543/47780 [00:42<01:35, 358.17 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12038/47780 [00:42<01:54, 312.15 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12086/47780 [00:42<01:50, 321.59 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12045/47780 [00:42<01:51, 321.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12125/47780 [00:42<01:56, 305.52 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13583/47780 [00:42<01:32, 369.76 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13211/47780 [00:42<01:45, 328.92 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11936/47780 [00:42<01:39, 361.66 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12070/47780 [00:42<01:54, 311.03 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12121/47780 [00:42<01:48, 327.43 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12078/47780 [00:42<01:51, 320.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12156/47780 [00:42<02:01, 293.32 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13626/47780 [00:42<01:29, 382.55 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11979/47780 [00:42<01:34, 377.38 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13246/47780 [00:42<01:45, 327.16 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12111/47780 [00:42<01:51, 320.91 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12155/47780 [00:42<01:52, 317.79 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12102/47780 [00:42<02:00, 297.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12186/47780 [00:42<02:04, 285.21 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13665/47780 [00:42<01:33, 363.89 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13279/47780 [00:42<01:46, 324.53 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12019/47780 [00:42<01:36, 371.32 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12145/47780 [00:42<01:52, 317.74 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12188/47780 [00:42<01:54, 310.00 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12230/47780 [00:42<01:49, 325.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12133/47780 [00:42<02:06, 280.96 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13313/47780 [00:42<01:45, 325.18 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13702/47780 [00:42<01:36, 352.84 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12061/47780 [00:42<01:38, 364.01 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12177/47780 [00:42<01:53, 314.70 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 86/47780 [00:42<3:06:55,  4.25 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12269/47780 [00:42<01:43, 343.34 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12222/47780 [00:42<01:54, 311.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12169/47780 [00:42<01:59, 296.95 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13353/47780 [00:42<01:39, 346.36 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12098/47780 [00:42<01:38, 360.87 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12216/47780 [00:42<01:49, 325.19 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13738/47780 [00:42<01:45, 323.26 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12262/47780 [00:42<01:46, 332.20 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12304/47780 [00:42<01:44, 340.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12208/47780 [00:42<01:50, 321.98 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 145/47780 [00:42<1:00:28, 13.13 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13388/47780 [00:42<01:43, 331.81 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12136/47780 [00:42<01:37, 363.88 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12255/47780 [00:42<01:44, 339.97 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12343/47780 [00:42<01:39, 355.00 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13771/47780 [00:42<01:46, 320.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12247/47780 [00:42<01:45, 337.84 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12296/47780 [00:42<01:55, 306.13 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13432/47780 [00:43<01:36, 354.85 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12173/47780 [00:43<01:37, 365.18 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12293/47780 [00:43<01:40, 351.37 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13808/47780 [00:43<01:42, 331.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12380/47780 [00:42<01:39, 355.80 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12282/47780 [00:43<01:48, 326.38 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12328/47780 [00:43<01:57, 300.96 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13475/47780 [00:43<01:31, 376.00 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12210/47780 [00:43<01:39, 359.21 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13847/47780 [00:43<01:37, 347.70 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12416/47780 [00:43<01:39, 354.71 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12341/47780 [00:43<01:34, 375.47 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12318/47780 [00:43<01:46, 331.96 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12360/47780 [00:43<01:55, 306.09 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12247/47780 [00:43<01:39, 357.29 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13513/47780 [00:43<01:38, 349.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12379/47780 [00:43<01:36, 366.69 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12452/47780 [00:43<01:44, 338.23 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12353/47780 [00:43<01:45, 335.94 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13884/47780 [00:43<01:45, 321.36 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12391/47780 [00:43<01:59, 297.24 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13554/47780 [00:43<01:34, 362.09 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12283/47780 [00:43<01:44, 338.71 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12491/47780 [00:43<01:41, 348.04 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12387/47780 [00:43<01:45, 334.14 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13928/47780 [00:43<01:37, 345.78 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12416/47780 [00:43<01:44, 338.42 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12421/47780 [00:43<02:05, 281.88 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12322/47780 [00:43<01:40, 352.92 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12529/47780 [00:43<01:41, 346.05 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13592/47780 [00:43<01:41, 336.15 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12421/47780 [00:43<01:47, 329.42 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13964/47780 [00:43<01:37, 345.92 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12451/47780 [00:43<01:46, 331.89 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12454/47780 [00:43<02:06, 280.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12358/47780 [00:43<01:39, 354.93 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12569/47780 [00:43<01:39, 354.04 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12464/47780 [00:43<01:39, 353.50 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13627/47780 [00:43<01:43, 329.80 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12485/47780 [00:43<01:49, 321.91 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13999/47780 [00:43<01:44, 321.86 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12484/47780 [00:43<02:04, 282.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12399/47780 [00:43<01:36, 367.06 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12606/47780 [00:43<01:39, 353.48 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13666/47780 [00:43<01:40, 338.92 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12500/47780 [00:43<01:42, 342.98 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14037/47780 [00:43<01:41, 333.90 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12518/47780 [00:43<01:56, 302.68 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12520/47780 [00:43<01:56, 303.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12438/47780 [00:43<01:35, 369.44 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12644/47780 [00:43<01:38, 356.49 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13710/47780 [00:43<01:33, 362.75 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12541/47780 [00:43<01:40, 350.57 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14074/47780 [00:43<01:39, 340.20 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12552/47780 [00:43<01:55, 305.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12476/47780 [00:43<01:38, 360.08 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12577/47780 [00:43<01:40, 349.21 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12680/47780 [00:43<01:43, 337.61 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13747/47780 [00:43<01:38, 345.12 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14110/47780 [00:43<01:38, 340.18 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12549/47780 [00:43<02:29, 235.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12583/47780 [00:43<02:02, 286.52 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12513/47780 [00:43<01:39, 353.28 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12717/47780 [00:43<01:42, 340.89 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12612/47780 [00:44<01:44, 338.02 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14151/47780 [00:44<01:34, 356.52 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13782/47780 [00:44<01:44, 324.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12615/47780 [00:44<02:00, 292.80 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12549/47780 [00:44<01:43, 341.03 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12649/47780 [00:44<01:41, 346.80 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12752/47780 [00:44<01:46, 328.29 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14187/47780 [00:44<01:36, 349.00 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12575/47780 [00:44<03:00, 194.91 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13818/47780 [00:44<01:43, 327.63 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12645/47780 [00:44<02:03, 285.31 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12584/47780 [00:44<01:43, 339.81 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12684/47780 [00:44<01:42, 343.52 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12680/47780 [00:44<01:34, 371.29 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12787/47780 [00:44<01:49, 320.48 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14223/47780 [00:44<01:39, 338.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13854/47780 [00:44<01:45, 321.90 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12674/47780 [00:44<02:06, 277.13 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12619/47780 [00:44<01:54, 306.88 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12821/47780 [00:44<01:49, 318.97 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12719/47780 [00:44<01:55, 303.50 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14258/47780 [00:44<01:44, 319.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13888/47780 [00:44<01:47, 316.62 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12717/47780 [00:44<01:50, 316.39 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12729/47780 [00:44<01:38, 354.66 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12658/47780 [00:44<01:47, 326.42 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 162/47780 [00:44<1:03:20, 12.53 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12868/47780 [00:44<01:36, 360.84 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12753/47780 [00:44<01:51, 313.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13927/47780 [00:44<01:41, 333.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14294/47780 [00:44<01:43, 323.89 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12757/47780 [00:44<01:43, 339.62 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12772/47780 [00:44<01:36, 361.10 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12694/47780 [00:44<01:44, 334.82 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 249/47780 [00:44<24:51, 31.87 examples/s]  Tokenizing train dataset (num_proc=32):  27%|██▋       | 12905/47780 [00:44<01:38, 355.32 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13961/47780 [00:44<01:41, 331.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14328/47780 [00:44<01:41, 328.12 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12787/47780 [00:44<01:56, 300.98 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12797/47780 [00:44<01:40, 349.34 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12813/47780 [00:44<01:40, 349.29 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12728/47780 [00:44<01:47, 325.39 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12946/47780 [00:44<01:36, 362.66 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13995/47780 [00:44<01:41, 334.00 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14363/47780 [00:44<01:39, 334.30 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12833/47780 [00:44<01:39, 350.18 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12818/47780 [00:44<02:02, 284.50 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12856/47780 [00:44<01:36, 362.76 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12767/47780 [00:44<01:42, 342.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12983/47780 [00:44<01:37, 356.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14029/47780 [00:44<01:45, 320.89 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12869/47780 [00:44<01:39, 350.79 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12850/47780 [00:44<01:59, 291.27 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14397/47780 [00:44<02:01, 275.00 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12802/47780 [00:44<01:49, 320.68 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12895/47780 [00:44<01:40, 345.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13019/47780 [00:44<01:38, 352.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14066/47780 [00:44<01:40, 334.67 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12905/47780 [00:44<01:39, 349.32 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12881/47780 [00:44<01:57, 296.24 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14446/47780 [00:45<01:42, 326.71 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12835/47780 [00:44<01:49, 319.40 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12932/47780 [00:44<01:42, 341.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13057/47780 [00:44<01:38, 353.51 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14107/47780 [00:45<01:37, 344.51 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12946/47780 [00:44<01:36, 359.24 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12923/47780 [00:45<01:50, 315.70 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12868/47780 [00:45<01:49, 318.65 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14481/47780 [00:45<01:47, 309.63 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12968/47780 [00:45<01:41, 341.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13093/47780 [00:45<01:38, 351.09 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14146/47780 [00:45<01:36, 349.54 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12982/47780 [00:45<01:38, 354.79 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12955/47780 [00:45<01:51, 311.24 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14523/47780 [00:45<01:39, 335.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13005/47780 [00:45<01:41, 342.95 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12901/47780 [00:45<01:57, 295.60 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14196/47780 [00:45<01:25, 392.26 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13130/47780 [00:45<01:45, 328.52 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13018/47780 [00:45<01:43, 337.30 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12997/47780 [00:45<01:42, 337.80 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13040/47780 [00:45<01:41, 340.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14558/47780 [00:45<01:41, 327.39 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12950/47780 [00:45<01:40, 348.13 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13164/47780 [00:45<01:44, 329.86 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13055/47780 [00:45<01:40, 346.22 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13039/47780 [00:45<01:38, 352.96 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14236/47780 [00:45<01:36, 345.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13078/47780 [00:45<01:39, 348.53 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14604/47780 [00:45<01:32, 356.94 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13202/47780 [00:45<01:40, 343.83 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13097/47780 [00:45<01:35, 363.57 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12986/47780 [00:45<01:46, 326.02 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14273/47780 [00:45<01:35, 349.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13075/47780 [00:45<01:45, 329.01 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14641/47780 [00:45<01:34, 349.04 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13240/47780 [00:45<01:37, 354.09 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13026/47780 [00:45<01:42, 338.78 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13114/47780 [00:45<01:53, 306.52 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13134/47780 [00:45<01:41, 341.66 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14309/47780 [00:45<01:36, 348.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13111/47780 [00:45<01:43, 333.77 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14679/47780 [00:45<01:32, 357.54 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13283/47780 [00:45<01:32, 372.08 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13071/47780 [00:45<01:34, 368.92 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13148/47780 [00:45<01:49, 315.08 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14345/47780 [00:45<01:36, 345.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13169/47780 [00:45<01:51, 309.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13145/47780 [00:45<01:52, 308.13 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14716/47780 [00:45<01:31, 360.85 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13321/47780 [00:45<01:34, 365.72 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13190/47780 [00:45<01:41, 339.77 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13109/47780 [00:45<01:38, 351.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14381/47780 [00:45<01:38, 340.35 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13177/47780 [00:45<01:57, 295.55 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 284/47780 [00:45<26:02, 30.39 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13358/47780 [00:45<01:37, 354.63 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14753/47780 [00:45<01:38, 336.64 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13202/47780 [00:45<02:03, 278.98 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13148/47780 [00:45<01:36, 358.98 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13225/47780 [00:45<01:45, 327.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14416/47780 [00:45<01:43, 320.95 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13394/47780 [00:45<01:37, 351.44 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13269/47780 [00:45<01:32, 373.93 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14793/47780 [00:46<01:35, 345.27 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13186/47780 [00:45<01:38, 352.71 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13261/47780 [00:45<01:45, 327.36 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 352/47780 [00:45<15:46, 50.09 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13207/47780 [00:45<02:12, 260.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14459/47780 [00:46<01:35, 347.35 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13309/47780 [00:46<01:30, 379.65 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13435/47780 [00:46<01:35, 360.73 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14837/47780 [00:46<01:29, 368.82 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13248/47780 [00:46<01:55, 298.05 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13233/47780 [00:46<01:31, 377.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13295/47780 [00:46<01:51, 309.37 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14495/47780 [00:46<01:42, 325.30 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13481/47780 [00:46<01:30, 380.35 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14875/47780 [00:46<01:32, 355.64 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13272/47780 [00:46<01:32, 372.58 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13349/47780 [00:46<01:41, 338.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13280/47780 [00:46<02:00, 285.40 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13328/47780 [00:46<01:56, 295.72 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14534/47780 [00:46<01:40, 331.85 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14914/47780 [00:46<01:30, 361.31 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13520/47780 [00:46<01:34, 364.01 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13310/47780 [00:46<01:33, 369.63 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13385/47780 [00:46<01:42, 336.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13310/47780 [00:46<02:06, 271.75 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13358/47780 [00:46<02:04, 276.39 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14568/47780 [00:46<01:43, 320.16 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14953/47780 [00:46<01:28, 369.19 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13557/47780 [00:46<01:34, 364.02 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13348/47780 [00:46<01:36, 356.92 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13442/47780 [00:46<01:28, 386.07 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13353/47780 [00:46<01:55, 298.19 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13386/47780 [00:46<02:04, 275.37 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14611/47780 [00:46<01:35, 346.56 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13599/47780 [00:46<01:29, 379.94 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14991/47780 [00:46<01:35, 344.72 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13386/47780 [00:46<01:35, 359.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13482/47780 [00:46<01:30, 377.78 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13385/47780 [00:46<01:55, 297.71 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13414/47780 [00:46<02:09, 265.42 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13649/47780 [00:46<01:23, 409.95 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14647/47780 [00:46<01:40, 328.11 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15027/47780 [00:46<01:36, 340.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13423/47780 [00:46<01:35, 361.11 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13521/47780 [00:46<01:39, 343.84 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13442/47780 [00:46<02:09, 265.06 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13691/47780 [00:46<01:29, 380.68 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14682/47780 [00:46<01:45, 313.72 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13416/47780 [00:46<02:14, 254.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15062/47780 [00:46<01:40, 325.73 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13469/47780 [00:46<02:08, 266.37 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13557/47780 [00:46<01:45, 324.02 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13461/47780 [00:46<01:57, 293.14 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13469/47780 [00:46<01:48, 315.72 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13730/47780 [00:46<01:34, 360.60 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14714/47780 [00:46<01:50, 298.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15095/47780 [00:46<01:43, 317.00 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13496/47780 [00:46<02:11, 261.52 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13523/47780 [00:46<01:33, 367.10 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13591/47780 [00:46<01:54, 298.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14747/47780 [00:46<01:49, 301.76 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15127/47780 [00:47<01:45, 310.81 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13769/47780 [00:46<01:36, 353.17 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13503/47780 [00:46<01:57, 292.21 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13524/47780 [00:47<02:09, 263.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13563/47780 [00:47<01:32, 368.02 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13622/47780 [00:47<01:56, 294.04 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15161/47780 [00:47<01:42, 318.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13814/47780 [00:47<01:29, 379.24 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14778/47780 [00:47<01:54, 288.08 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13539/47780 [00:47<01:50, 308.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13602/47780 [00:47<01:34, 361.03 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13658/47780 [00:47<01:51, 306.12 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15198/47780 [00:47<01:38, 329.39 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13582/47780 [00:47<01:40, 340.62 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13853/47780 [00:47<01:34, 358.12 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14808/47780 [00:47<01:59, 276.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13551/47780 [00:47<02:49, 201.38 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15234/47780 [00:47<01:37, 334.63 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13690/47780 [00:47<01:53, 299.11 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13641/47780 [00:47<01:43, 330.63 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13627/47780 [00:47<01:33, 366.37 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14836/47780 [00:47<01:58, 277.39 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13891/47780 [00:47<01:39, 341.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13615/47780 [00:47<01:52, 304.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15270/47780 [00:47<01:35, 341.63 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 384/47780 [00:47<19:51, 39.78 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13721/47780 [00:47<01:54, 297.04 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14869/47780 [00:47<01:53, 288.82 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13665/47780 [00:47<01:34, 362.23 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13935/47780 [00:47<01:32, 367.40 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13676/47780 [00:47<01:53, 299.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13650/47780 [00:47<01:56, 292.61 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13751/47780 [00:47<01:55, 294.35 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 443/47780 [00:47<13:07, 60.10 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14912/47780 [00:47<01:41, 324.86 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15305/47780 [00:47<01:45, 307.21 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13705/47780 [00:47<01:38, 345.72 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13974/47780 [00:47<01:35, 355.22 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13709/47780 [00:47<01:51, 306.53 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13683/47780 [00:47<01:57, 290.51 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13781/47780 [00:47<01:55, 295.52 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13741/47780 [00:47<01:37, 349.48 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14945/47780 [00:47<01:48, 301.41 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14010/47780 [00:47<01:36, 348.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13741/47780 [00:47<01:56, 292.14 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13715/47780 [00:47<02:00, 283.52 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15337/47780 [00:47<02:06, 255.69 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13815/47780 [00:47<01:51, 304.92 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14991/47780 [00:47<01:36, 338.47 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13777/47780 [00:47<01:40, 336.86 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14047/47780 [00:47<01:36, 349.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13772/47780 [00:47<01:55, 293.63 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13749/47780 [00:47<01:55, 294.96 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15397/47780 [00:47<01:37, 333.02 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13853/47780 [00:47<01:45, 322.91 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15026/47780 [00:47<01:36, 337.79 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14089/47780 [00:47<01:31, 369.27 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13812/47780 [00:47<01:41, 333.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13805/47780 [00:47<01:53, 300.23 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13894/47780 [00:47<01:37, 348.03 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15434/47780 [00:47<01:35, 338.81 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13780/47780 [00:47<02:03, 275.39 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15063/47780 [00:47<01:34, 345.65 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13846/47780 [00:47<01:43, 327.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14129/47780 [00:47<01:33, 358.77 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13836/47780 [00:47<01:58, 287.16 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15473/47780 [00:48<01:31, 352.06 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13929/47780 [00:47<01:40, 336.79 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13811/47780 [00:48<02:01, 278.72 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15098/47780 [00:48<01:37, 336.37 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13883/47780 [00:48<01:39, 339.54 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14176/47780 [00:48<01:26, 389.51 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13867/47780 [00:48<02:00, 281.10 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15510/47780 [00:48<01:33, 346.18 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13963/47780 [00:48<01:41, 334.09 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13840/47780 [00:48<02:02, 276.64 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15142/47780 [00:48<01:29, 365.57 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14216/47780 [00:48<01:25, 392.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13919/47780 [00:48<01:41, 333.77 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15550/47780 [00:48<01:29, 360.78 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13999/47780 [00:48<01:38, 341.41 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13896/47780 [00:48<02:04, 271.91 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13869/47780 [00:48<02:04, 273.28 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14256/47780 [00:48<01:25, 390.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13953/47780 [00:48<01:45, 321.48 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15180/47780 [00:48<01:42, 318.18 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13940/47780 [00:48<01:46, 317.32 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14034/47780 [00:48<01:41, 332.33 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15587/47780 [00:48<01:32, 347.51 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13908/47780 [00:48<01:52, 302.40 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14299/47780 [00:48<01:23, 401.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13986/47780 [00:48<01:45, 320.31 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13973/47780 [00:48<01:46, 316.70 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14068/47780 [00:48<01:46, 316.36 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13939/47780 [00:48<01:51, 304.22 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15214/47780 [00:48<01:50, 293.51 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15623/47780 [00:48<01:39, 322.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14342/47780 [00:48<01:21, 409.89 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14020/47780 [00:48<01:50, 304.96 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14012/47780 [00:48<01:41, 334.30 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13971/47780 [00:48<01:53, 298.66 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14100/47780 [00:48<01:49, 306.91 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15245/47780 [00:48<01:54, 283.45 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15656/47780 [00:48<01:44, 307.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14384/47780 [00:48<01:28, 377.19 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14052/47780 [00:48<01:49, 308.97 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14048/47780 [00:48<01:39, 337.95 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14013/47780 [00:48<01:42, 329.41 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15281/47780 [00:48<01:47, 302.85 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14131/47780 [00:48<01:55, 290.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15692/47780 [00:48<01:40, 318.58 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14426/47780 [00:48<01:27, 380.92 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14084/47780 [00:48<01:52, 299.24 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14083/47780 [00:48<01:42, 329.35 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14047/47780 [00:48<01:46, 317.90 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15314/47780 [00:48<01:49, 297.58 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14161/47780 [00:48<01:56, 287.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15726/47780 [00:48<01:39, 320.94 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14471/47780 [00:48<01:25, 391.52 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14115/47780 [00:48<01:54, 295.01 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14119/47780 [00:48<01:40, 334.79 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14083/47780 [00:48<01:43, 326.03 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15346/47780 [00:48<01:47, 301.18 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14192/47780 [00:48<01:55, 290.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15760/47780 [00:48<01:38, 326.06 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14513/47780 [00:48<01:23, 399.49 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14146/47780 [00:48<01:53, 296.33 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14158/47780 [00:48<01:37, 343.44 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15377/47780 [00:49<01:47, 302.60 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15796/47780 [00:49<01:36, 332.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14116/47780 [00:48<01:46, 316.35 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14555/47780 [00:48<01:23, 395.93 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14222/47780 [00:48<02:04, 268.83 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14176/47780 [00:49<01:54, 294.01 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14195/47780 [00:49<01:36, 346.46 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15410/47780 [00:49<01:45, 307.20 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14152/47780 [00:49<01:43, 326.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15833/47780 [00:49<01:34, 339.10 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14602/47780 [00:49<01:20, 412.84 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14258/47780 [00:49<01:56, 287.61 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14206/47780 [00:49<01:57, 284.65 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14236/47780 [00:49<01:35, 352.34 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15868/47780 [00:49<01:33, 341.91 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15441/47780 [00:49<01:46, 303.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14185/47780 [00:49<01:44, 322.43 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14289/47780 [00:49<01:56, 287.44 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14645/47780 [00:49<01:22, 403.79 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14279/47780 [00:49<01:29, 374.01 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14235/47780 [00:49<02:03, 272.02 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14219/47780 [00:49<01:42, 327.11 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15909/47780 [00:49<01:31, 349.88 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15472/47780 [00:49<01:49, 295.89 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14323/47780 [00:49<01:52, 298.67 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14686/47780 [00:49<01:23, 396.14 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 474/47780 [00:49<20:38, 38.18 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14263/47780 [00:49<02:06, 265.37 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14317/47780 [00:49<01:35, 348.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15950/47780 [00:49<01:27, 362.91 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14252/47780 [00:49<01:48, 309.87 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15503/47780 [00:49<01:54, 280.82 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14365/47780 [00:49<01:41, 329.13 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14727/47780 [00:49<01:25, 387.16 examples/s]Tokenizing train dataset (num_proc=32):   1%|▏         | 617/47780 [00:49<08:50, 88.84 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14297/47780 [00:49<01:59, 279.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14353/47780 [00:49<01:38, 339.97 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14287/47780 [00:49<01:45, 318.03 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15987/47780 [00:49<01:30, 351.61 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15543/47780 [00:49<01:45, 306.90 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14399/47780 [00:49<01:40, 332.20 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14766/47780 [00:49<01:25, 387.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14326/47780 [00:49<01:59, 279.38 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14323/47780 [00:49<01:41, 329.98 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16026/47780 [00:49<01:28, 357.76 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14388/47780 [00:49<01:44, 321.00 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15580/47780 [00:49<01:40, 320.91 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14805/47780 [00:49<01:25, 383.99 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14433/47780 [00:49<01:45, 316.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14359/47780 [00:49<01:57, 284.29 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16075/47780 [00:49<01:20, 392.81 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14357/47780 [00:49<01:45, 317.54 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15620/47780 [00:49<01:33, 342.94 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14421/47780 [00:49<01:49, 303.85 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14847/47780 [00:49<01:23, 394.15 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14465/47780 [00:49<01:45, 315.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14390/47780 [00:49<01:55, 288.32 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16116/47780 [00:49<01:20, 393.65 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14391/47780 [00:49<01:47, 310.27 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14452/47780 [00:49<01:50, 301.89 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14887/47780 [00:49<01:23, 391.69 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14507/47780 [00:49<01:36, 343.33 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15655/47780 [00:49<01:39, 322.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14430/47780 [00:49<01:46, 313.34 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16158/47780 [00:50<01:22, 383.09 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14491/47780 [00:49<01:43, 323.15 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14935/47780 [00:49<01:18, 417.17 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14542/47780 [00:49<01:38, 337.65 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15688/47780 [00:50<01:42, 314.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14423/47780 [00:49<01:56, 287.49 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14462/47780 [00:50<01:57, 282.81 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14524/47780 [00:50<01:44, 319.00 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16198/47780 [00:50<01:27, 361.83 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14977/47780 [00:50<01:22, 399.52 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14576/47780 [00:50<01:41, 326.96 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14455/47780 [00:50<01:53, 293.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15729/47780 [00:50<01:38, 326.60 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14508/47780 [00:50<01:40, 330.14 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14557/47780 [00:50<01:48, 307.14 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14612/47780 [00:50<01:39, 332.52 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15018/47780 [00:50<01:25, 385.08 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14485/47780 [00:50<01:54, 291.67 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16238/47780 [00:50<01:29, 354.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15769/47780 [00:50<01:34, 339.51 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14542/47780 [00:50<01:42, 325.68 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15059/47780 [00:50<01:23, 392.05 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14590/47780 [00:50<01:48, 306.77 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16275/47780 [00:50<01:28, 355.02 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14515/47780 [00:50<01:54, 290.72 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14646/47780 [00:50<01:42, 323.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15804/47780 [00:50<01:38, 324.16 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14576/47780 [00:50<01:45, 315.32 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14551/47780 [00:50<01:48, 306.96 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15099/47780 [00:50<01:25, 380.84 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14691/47780 [00:50<01:35, 347.58 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16311/47780 [00:50<01:33, 338.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15850/47780 [00:50<01:31, 349.81 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14621/47780 [00:50<02:06, 261.14 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14617/47780 [00:50<01:40, 329.23 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14587/47780 [00:50<01:44, 318.39 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14730/47780 [00:50<01:32, 358.00 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15138/47780 [00:50<01:29, 363.26 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15893/47780 [00:50<01:25, 371.65 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16346/47780 [00:50<01:39, 316.58 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14681/47780 [00:50<01:36, 343.21 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14655/47780 [00:50<01:37, 341.00 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14621/47780 [00:50<01:43, 321.08 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14775/47780 [00:50<01:26, 381.66 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15175/47780 [00:50<01:30, 361.13 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15936/47780 [00:50<01:22, 387.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16378/47780 [00:50<01:39, 317.18 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14726/47780 [00:50<01:29, 371.06 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14655/47780 [00:50<01:41, 326.46 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14690/47780 [00:50<01:42, 321.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14814/47780 [00:50<01:27, 374.95 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16422/47780 [00:50<01:30, 347.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15977/47780 [00:50<01:24, 375.11 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14765/47780 [00:50<01:28, 372.16 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15214/47780 [00:50<01:44, 312.46 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14688/47780 [00:50<01:44, 316.44 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14724/47780 [00:50<01:41, 326.77 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14863/47780 [00:50<01:22, 399.18 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16461/47780 [00:50<01:29, 351.58 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16015/47780 [00:50<01:26, 366.54 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14804/47780 [00:50<01:31, 360.68 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15251/47780 [00:50<01:41, 320.94 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14729/47780 [00:50<01:38, 337.18 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14757/47780 [00:50<01:41, 324.00 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14903/47780 [00:50<01:25, 385.91 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16055/47780 [00:51<01:24, 375.50 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16497/47780 [00:51<01:31, 343.51 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14841/47780 [00:50<01:33, 351.94 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15285/47780 [00:50<01:39, 325.75 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14767/47780 [00:51<01:35, 347.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14790/47780 [00:51<01:47, 308.19 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16095/47780 [00:51<01:23, 378.67 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14942/47780 [00:51<01:29, 366.28 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16532/47780 [00:51<01:32, 336.16 examples/s]Tokenizing train dataset (num_proc=32):   1%|▏         | 674/47780 [00:51<12:06, 64.83 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14879/47780 [00:51<01:32, 356.03 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15325/47780 [00:51<01:33, 345.90 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14802/47780 [00:51<01:40, 329.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14823/47780 [00:51<01:47, 307.48 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14981/47780 [00:51<01:28, 369.21 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16134/47780 [00:51<01:30, 349.74 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 748/47780 [00:51<08:39, 90.61 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15362/47780 [00:51<01:31, 352.52 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16566/47780 [00:51<01:42, 303.58 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14916/47780 [00:51<01:37, 336.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14859/47780 [00:51<01:42, 322.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14836/47780 [00:51<01:43, 318.08 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15020/47780 [00:51<01:33, 351.05 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16176/47780 [00:51<01:25, 368.88 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16600/47780 [00:51<01:40, 310.00 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14957/47780 [00:51<01:33, 349.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15399/47780 [00:51<01:40, 320.88 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14892/47780 [00:51<01:45, 311.44 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14872/47780 [00:51<01:42, 322.50 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16216/47780 [00:51<01:24, 373.52 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16632/47780 [00:51<01:41, 305.55 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15056/47780 [00:51<01:42, 318.54 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15433/47780 [00:51<01:40, 322.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14995/47780 [00:51<01:36, 339.17 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14924/47780 [00:51<01:47, 305.72 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14905/47780 [00:51<01:43, 317.59 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16255/47780 [00:51<01:24, 373.99 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15089/47780 [00:51<01:43, 315.36 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16663/47780 [00:51<01:46, 291.34 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15472/47780 [00:51<01:35, 337.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 15030/47780 [00:51<01:40, 324.33 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14957/47780 [00:51<01:47, 305.65 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14937/47780 [00:51<01:47, 304.64 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16298/47780 [00:51<01:20, 389.96 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15123/47780 [00:51<01:41, 321.85 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16693/47780 [00:51<01:47, 287.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15507/47780 [00:51<01:38, 326.24 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15063/47780 [00:51<01:45, 309.51 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14989/47780 [00:51<01:48, 303.02 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14968/47780 [00:51<01:50, 298.27 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16348/47780 [00:51<01:15, 417.14 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16727/47780 [00:51<01:42, 301.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15156/47780 [00:51<01:49, 297.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15543/47780 [00:51<01:39, 324.98 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15096/47780 [00:51<01:43, 314.78 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15021/47780 [00:51<01:53, 287.45 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16390/47780 [00:51<01:20, 389.69 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14998/47780 [00:51<02:01, 269.71 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16763/47780 [00:51<01:38, 314.54 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15578/47780 [00:51<01:37, 331.66 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15189/47780 [00:51<01:49, 297.72 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15128/47780 [00:51<01:46, 306.37 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15059/47780 [00:51<01:45, 310.19 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16433/47780 [00:51<01:18, 397.64 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15026/47780 [00:51<02:01, 269.66 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16796/47780 [00:52<01:37, 318.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15617/47780 [00:51<01:33, 344.60 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15222/47780 [00:51<01:48, 299.09 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15159/47780 [00:52<01:47, 303.28 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15091/47780 [00:52<01:46, 307.25 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16476/47780 [00:52<01:22, 380.46 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16834/47780 [00:52<01:34, 328.91 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15054/47780 [00:52<02:06, 257.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15663/47780 [00:52<01:25, 377.39 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15204/47780 [00:52<01:35, 341.46 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15253/47780 [00:52<01:52, 288.80 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15122/47780 [00:52<01:50, 296.60 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16868/47780 [00:52<01:33, 332.01 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15702/47780 [00:52<01:25, 376.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15081/47780 [00:52<02:10, 250.78 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16515/47780 [00:52<01:27, 355.74 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15240/47780 [00:52<01:36, 338.41 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15283/47780 [00:52<02:02, 266.34 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15156/47780 [00:52<01:46, 305.62 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16903/47780 [00:52<01:32, 333.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15745/47780 [00:52<01:22, 390.47 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15107/47780 [00:52<02:20, 233.16 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16552/47780 [00:52<01:34, 331.51 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15281/47780 [00:52<01:33, 347.47 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15312/47780 [00:52<02:02, 265.85 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16940/47780 [00:52<01:31, 338.07 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15785/47780 [00:52<01:22, 385.81 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15187/47780 [00:52<02:07, 254.95 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15135/47780 [00:52<02:14, 242.90 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16598/47780 [00:52<01:26, 361.27 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15328/47780 [00:52<01:25, 377.76 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15349/47780 [00:52<01:53, 285.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15829/47780 [00:52<01:19, 401.18 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 16974/47780 [00:52<01:35, 322.02 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16635/47780 [00:52<01:25, 363.58 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15160/47780 [00:52<02:20, 232.21 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15367/47780 [00:52<01:27, 371.78 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15378/47780 [00:52<01:54, 283.82 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15214/47780 [00:52<02:24, 224.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15876/47780 [00:52<01:16, 417.31 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17013/47780 [00:52<01:31, 336.71 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15189/47780 [00:52<02:12, 245.10 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15405/47780 [00:52<01:32, 351.22 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15417/47780 [00:52<01:43, 312.93 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15265/47780 [00:52<01:51, 292.40 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16672/47780 [00:52<01:39, 313.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15920/47780 [00:52<01:16, 418.87 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17051/47780 [00:52<01:28, 345.84 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15217/47780 [00:52<02:07, 254.60 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15326/47780 [00:52<01:28, 365.40 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15449/47780 [00:52<01:50, 291.72 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16705/47780 [00:52<01:41, 305.04 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15441/47780 [00:52<01:40, 321.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15962/47780 [00:52<01:15, 419.18 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17086/47780 [00:52<01:34, 324.27 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15246/47780 [00:52<02:04, 261.67 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 795/47780 [00:52<12:55, 60.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15366/47780 [00:52<01:27, 369.26 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15474/47780 [00:52<01:40, 321.27 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16738/47780 [00:52<01:43, 299.13 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 16004/47780 [00:52<01:20, 396.03 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15479/47780 [00:52<01:59, 270.70 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17119/47780 [00:52<01:34, 322.76 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15273/47780 [00:52<02:03, 263.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 909/47780 [00:52<07:35, 102.94 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16773/47780 [00:53<01:40, 309.24 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15405/47780 [00:53<01:33, 346.61 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15507/47780 [00:53<01:46, 303.13 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15508/47780 [00:53<01:58, 272.96 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17154/47780 [00:53<01:32, 329.73 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16044/47780 [00:53<01:26, 368.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15305/47780 [00:53<01:58, 274.13 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16806/47780 [00:53<01:38, 314.82 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15538/47780 [00:53<01:47, 301.21 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15546/47780 [00:53<01:49, 295.58 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15442/47780 [00:53<01:35, 338.46 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17188/47780 [00:53<01:37, 315.24 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16090/47780 [00:53<01:23, 381.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15338/47780 [00:53<01:53, 286.94 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16840/47780 [00:53<01:39, 311.10 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15571/47780 [00:53<01:45, 306.16 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15577/47780 [00:53<01:47, 299.54 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17220/47780 [00:53<01:36, 316.56 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15371/47780 [00:53<01:49, 296.33 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16129/47780 [00:53<01:24, 374.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15477/47780 [00:53<01:43, 311.84 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16872/47780 [00:53<01:40, 308.04 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15606/47780 [00:53<01:42, 315.09 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15612/47780 [00:53<01:42, 313.77 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17262/47780 [00:53<01:30, 338.32 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16167/47780 [00:53<01:24, 372.27 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15402/47780 [00:53<01:51, 289.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15510/47780 [00:53<01:43, 311.62 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16916/47780 [00:53<01:29, 343.97 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15647/47780 [00:53<01:40, 320.60 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15656/47780 [00:53<01:29, 359.13 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17298/47780 [00:53<01:30, 336.85 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15432/47780 [00:53<01:50, 292.28 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16206/47780 [00:53<01:25, 368.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15543/47780 [00:53<01:42, 314.91 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16958/47780 [00:53<01:25, 361.47 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15681/47780 [00:53<01:40, 318.76 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15694/47780 [00:53<01:31, 349.00 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17337/47780 [00:53<01:28, 344.07 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16244/47780 [00:53<01:24, 371.88 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15462/47780 [00:53<01:52, 288.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15576/47780 [00:53<01:43, 312.07 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15714/47780 [00:53<01:42, 311.33 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15730/47780 [00:53<01:32, 347.22 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 16995/47780 [00:53<01:31, 337.79 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15491/47780 [00:53<01:53, 285.56 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17372/47780 [00:53<01:30, 334.43 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16284/47780 [00:53<01:25, 367.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15610/47780 [00:53<01:41, 315.62 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15765/47780 [00:53<01:32, 345.31 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17031/47780 [00:53<01:34, 324.80 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15746/47780 [00:53<01:51, 287.72 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15520/47780 [00:53<01:56, 276.14 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16321/47780 [00:53<01:28, 355.96 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17406/47780 [00:53<01:36, 314.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15642/47780 [00:53<01:45, 303.86 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15800/47780 [00:53<01:33, 342.66 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15779/47780 [00:53<01:47, 299.04 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15563/47780 [00:53<01:41, 317.86 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16361/47780 [00:53<01:25, 368.35 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17065/47780 [00:53<01:36, 318.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17440/47780 [00:53<01:34, 321.44 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15673/47780 [00:53<01:50, 289.70 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15595/47780 [00:54<01:41, 317.99 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16398/47780 [00:53<01:26, 364.64 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17098/47780 [00:54<01:37, 315.13 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17473/47780 [00:54<01:34, 320.33 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15835/47780 [00:54<01:43, 309.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15810/47780 [00:53<01:51, 285.76 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15705/47780 [00:54<01:47, 297.93 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15636/47780 [00:54<01:34, 340.79 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17130/47780 [00:54<01:37, 312.97 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16447/47780 [00:54<01:19, 391.68 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17516/47780 [00:54<01:26, 351.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15839/47780 [00:54<01:53, 280.97 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15736/47780 [00:54<01:46, 301.06 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15867/47780 [00:54<01:49, 290.14 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15671/47780 [00:54<01:34, 338.51 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17556/47780 [00:54<01:24, 357.40 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15871/47780 [00:54<01:50, 288.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17170/47780 [00:54<01:34, 325.04 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15768/47780 [00:54<01:46, 299.81 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16487/47780 [00:54<01:24, 368.50 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15902/47780 [00:54<01:45, 302.93 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15705/47780 [00:54<01:38, 324.85 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17203/47780 [00:54<01:34, 324.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15901/47780 [00:54<01:50, 288.60 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17592/47780 [00:54<01:29, 338.59 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16529/47780 [00:54<01:22, 377.13 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15934/47780 [00:54<01:43, 307.55 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15799/47780 [00:54<01:49, 292.68 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17236/47780 [00:54<01:33, 325.61 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15746/47780 [00:54<01:33, 341.58 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15931/47780 [00:54<01:51, 285.57 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15829/47780 [00:54<01:49, 291.26 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17627/47780 [00:54<01:31, 329.37 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16567/47780 [00:54<01:25, 363.21 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15970/47780 [00:54<01:45, 301.88 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15783/47780 [00:54<01:31, 349.52 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15966/47780 [00:54<01:44, 303.79 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17269/47780 [00:54<01:36, 316.20 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15861/47780 [00:54<01:47, 296.23 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16611/47780 [00:54<01:21, 384.22 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16013/47780 [00:54<01:35, 333.18 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17662/47780 [00:54<01:37, 308.53 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15819/47780 [00:54<01:32, 343.74 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15999/47780 [00:54<01:44, 304.18 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17301/47780 [00:54<01:38, 309.95 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16651/47780 [00:54<01:20, 388.64 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15895/47780 [00:54<01:44, 304.88 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16061/47780 [00:54<01:26, 365.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17704/47780 [00:54<01:31, 329.35 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15854/47780 [00:54<01:34, 338.35 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16030/47780 [00:54<01:45, 301.20 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17335/47780 [00:54<01:36, 315.19 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15932/47780 [00:54<01:39, 320.55 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16098/47780 [00:54<01:28, 357.97 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16691/47780 [00:54<01:27, 355.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17741/47780 [00:54<01:29, 335.79 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15888/47780 [00:54<01:36, 331.37 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16068/47780 [00:54<01:39, 317.88 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17374/47780 [00:54<01:34, 321.88 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15966/47780 [00:54<01:38, 321.70 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16728/47780 [00:54<01:26, 359.36 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16137/47780 [00:54<01:28, 358.90 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17780/47780 [00:54<01:29, 335.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 964/47780 [00:54<12:14, 63.71 examples/s] Tokenizing train dataset (num_proc=32):  33%|███▎      | 15923/47780 [00:54<01:34, 336.47 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16100/47780 [00:54<01:40, 314.91 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 16002/47780 [00:54<01:36, 329.53 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17407/47780 [00:55<01:34, 319.79 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16768/47780 [00:54<01:23, 370.67 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16178/47780 [00:55<01:26, 366.11 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17820/47780 [00:55<01:25, 349.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1122/47780 [00:55<06:31, 119.28 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16137/47780 [00:55<01:36, 328.50 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15957/47780 [00:55<01:38, 323.74 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17449/47780 [00:55<01:27, 345.10 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16043/47780 [00:55<01:33, 341.16 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16806/47780 [00:55<01:23, 372.70 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16216/47780 [00:55<01:26, 366.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17856/47780 [00:55<01:25, 348.43 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16170/47780 [00:55<01:36, 327.58 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17484/47780 [00:55<01:28, 342.21 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16081/47780 [00:55<01:30, 351.07 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15990/47780 [00:55<01:43, 307.12 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16844/47780 [00:55<01:23, 370.83 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17892/47780 [00:55<01:25, 351.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16253/47780 [00:55<01:30, 347.29 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16215/47780 [00:55<01:27, 360.77 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16117/47780 [00:55<01:30, 351.03 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17524/47780 [00:55<01:27, 347.29 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16028/47780 [00:55<01:40, 316.81 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16883/47780 [00:55<01:25, 360.07 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16297/47780 [00:55<01:26, 364.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17928/47780 [00:55<01:33, 320.89 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16252/47780 [00:55<01:30, 349.59 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16153/47780 [00:55<01:31, 345.60 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17560/47780 [00:55<01:31, 328.55 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16923/47780 [00:55<01:23, 367.38 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16060/47780 [00:55<01:45, 301.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16334/47780 [00:55<01:28, 354.52 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17969/47780 [00:55<01:27, 342.61 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16288/47780 [00:55<01:31, 344.68 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16193/47780 [00:55<01:27, 361.21 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17594/47780 [00:55<01:35, 317.49 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16380/47780 [00:55<01:21, 383.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16960/47780 [00:55<01:32, 333.76 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18004/47780 [00:55<01:28, 335.89 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16230/47780 [00:55<01:26, 363.77 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16091/47780 [00:55<02:06, 251.45 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16325/47780 [00:55<01:34, 332.83 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17627/47780 [00:55<01:36, 314.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16419/47780 [00:55<01:21, 384.92 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18045/47780 [00:55<01:24, 353.90 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16125/47780 [00:55<01:57, 270.42 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16359/47780 [00:55<01:34, 330.84 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16267/47780 [00:55<01:38, 320.35 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17664/47780 [00:55<01:33, 322.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16465/47780 [00:55<01:17, 402.39 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 16995/47780 [00:55<02:01, 252.96 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18081/47780 [00:55<01:26, 344.44 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16154/47780 [00:55<01:56, 272.43 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16393/47780 [00:55<01:37, 322.45 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17701/47780 [00:55<01:30, 332.07 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16301/47780 [00:55<01:42, 305.83 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17079/47780 [00:55<01:20, 381.52 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16507/47780 [00:55<01:24, 369.20 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18116/47780 [00:55<01:29, 333.08 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16189/47780 [00:55<01:48, 290.24 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16435/47780 [00:55<01:30, 345.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17743/47780 [00:56<01:25, 352.94 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16545/47780 [00:56<01:24, 368.12 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16333/47780 [00:55<01:48, 290.76 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17124/47780 [00:55<01:22, 372.68 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18150/47780 [00:56<01:32, 320.11 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16472/47780 [00:56<01:30, 345.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17779/47780 [00:56<01:24, 354.91 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16366/47780 [00:56<01:47, 292.18 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16219/47780 [00:56<02:16, 231.99 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16583/47780 [00:56<01:27, 355.81 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17166/47780 [00:56<01:25, 359.81 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16509/47780 [00:56<01:29, 348.32 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18184/47780 [00:56<01:37, 303.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17817/47780 [00:56<01:23, 360.89 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16401/47780 [00:56<01:42, 304.73 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16620/47780 [00:56<01:26, 359.62 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16245/47780 [00:56<02:17, 229.53 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17206/47780 [00:56<01:22, 369.64 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16544/47780 [00:56<01:30, 345.05 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18219/47780 [00:56<01:33, 315.53 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17855/47780 [00:56<01:24, 355.07 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16439/47780 [00:56<01:36, 325.04 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16667/47780 [00:56<01:19, 390.70 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16297/47780 [00:56<01:45, 298.27 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17246/47780 [00:56<01:22, 371.24 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18251/47780 [00:56<01:33, 316.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16580/47780 [00:56<01:31, 341.22 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17892/47780 [00:56<01:29, 332.77 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16472/47780 [00:56<01:42, 305.81 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16709/47780 [00:56<01:23, 373.01 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17285/47780 [00:56<01:22, 370.84 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18284/47780 [00:56<01:35, 309.95 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16615/47780 [00:56<01:31, 339.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16330/47780 [00:56<01:50, 285.10 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17928/47780 [00:56<01:28, 336.65 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16506/47780 [00:56<01:40, 311.70 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16747/47780 [00:56<01:23, 370.66 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17326/47780 [00:56<01:20, 377.49 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18321/47780 [00:56<01:31, 323.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16362/47780 [00:56<01:49, 285.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16650/47780 [00:56<01:40, 310.76 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17962/47780 [00:56<01:34, 316.28 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16541/47780 [00:56<01:36, 322.28 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16791/47780 [00:56<01:20, 386.37 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18354/47780 [00:56<01:32, 317.78 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17367/47780 [00:56<01:23, 362.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16392/47780 [00:56<01:50, 283.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16686/47780 [00:56<01:35, 324.09 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 1194/47780 [00:56<09:19, 83.30 examples/s] Tokenizing train dataset (num_proc=32):  38%|███▊      | 18003/47780 [00:56<01:27, 341.63 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16842/47780 [00:56<01:14, 416.96 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16574/47780 [00:56<01:38, 317.13 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18387/47780 [00:56<01:32, 318.79 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17408/47780 [00:56<01:21, 374.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16725/47780 [00:56<01:30, 342.49 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16422/47780 [00:56<01:57, 267.58 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1329/47780 [00:56<05:52, 131.70 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18038/47780 [00:56<01:32, 322.40 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16606/47780 [00:56<01:40, 311.08 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16884/47780 [00:56<01:16, 406.00 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18421/47780 [00:56<01:31, 320.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17448/47780 [00:56<01:20, 374.57 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16452/47780 [00:56<01:54, 273.78 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16761/47780 [00:56<01:35, 325.89 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18073/47780 [00:57<01:30, 326.60 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16638/47780 [00:56<01:42, 303.12 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18454/47780 [00:57<01:31, 319.33 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16925/47780 [00:56<01:22, 375.17 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17487/47780 [00:56<01:20, 374.05 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16795/47780 [00:57<01:38, 314.93 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16480/47780 [00:57<02:03, 253.55 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18108/47780 [00:57<01:35, 312.11 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18487/47780 [00:57<01:32, 315.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 16964/47780 [00:57<01:22, 372.89 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17525/47780 [00:57<01:25, 355.56 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16669/47780 [00:57<01:54, 270.71 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16828/47780 [00:57<01:37, 317.96 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16515/47780 [00:57<01:54, 272.82 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18523/47780 [00:57<01:29, 328.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18141/47780 [00:57<01:36, 306.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17002/47780 [00:57<01:25, 361.14 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16706/47780 [00:57<01:45, 294.82 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17561/47780 [00:57<01:28, 343.36 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16544/47780 [00:57<01:52, 277.38 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16861/47780 [00:57<01:41, 303.75 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18559/47780 [00:57<01:26, 337.13 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18173/47780 [00:57<01:38, 300.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17039/47780 [00:57<01:24, 363.51 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17598/47780 [00:57<01:29, 337.88 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16582/47780 [00:57<01:42, 304.82 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16737/47780 [00:57<01:55, 269.61 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16893/47780 [00:57<01:44, 296.92 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18602/47780 [00:57<01:20, 360.32 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18209/47780 [00:57<01:35, 311.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17078/47780 [00:57<01:23, 366.88 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17642/47780 [00:57<01:23, 361.89 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16783/47780 [00:57<01:37, 318.91 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16616/47780 [00:57<01:40, 309.21 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16927/47780 [00:57<01:42, 302.13 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18639/47780 [00:57<01:23, 350.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17120/47780 [00:57<01:21, 377.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18241/47780 [00:57<01:36, 305.95 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17679/47780 [00:57<01:24, 357.08 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16648/47780 [00:57<01:40, 308.47 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16818/47780 [00:57<01:37, 317.11 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18676/47780 [00:57<01:23, 347.19 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16958/47780 [00:57<01:51, 275.75 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17159/47780 [00:57<01:21, 376.39 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18272/47780 [00:57<01:36, 306.22 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17715/47780 [00:57<01:26, 349.14 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16861/47780 [00:57<01:28, 347.78 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16681/47780 [00:57<01:43, 301.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 16999/47780 [00:57<01:40, 307.43 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17204/47780 [00:57<01:18, 391.41 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18303/47780 [00:57<01:41, 291.51 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18711/47780 [00:57<01:30, 319.92 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17751/47780 [00:57<01:27, 343.98 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16712/47780 [00:57<01:42, 303.07 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16897/47780 [00:57<01:31, 336.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17043/47780 [00:57<01:29, 341.63 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18335/47780 [00:57<01:38, 299.42 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17245/47780 [00:57<01:23, 365.19 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18744/47780 [00:57<01:32, 312.22 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17786/47780 [00:57<01:28, 338.49 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16747/47780 [00:57<01:40, 309.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16932/47780 [00:57<01:37, 315.45 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17078/47780 [00:57<01:33, 329.35 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18366/47780 [00:57<01:39, 295.72 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18777/47780 [00:58<01:32, 313.85 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17282/47780 [00:57<01:29, 340.31 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17833/47780 [00:57<01:21, 367.31 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16789/47780 [00:57<01:30, 340.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 16965/47780 [00:58<01:37, 315.48 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17120/47780 [00:58<01:28, 346.71 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18397/47780 [00:58<01:42, 286.74 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18813/47780 [00:58<01:31, 316.09 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17875/47780 [00:58<01:18, 382.09 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17318/47780 [00:58<01:29, 341.41 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16826/47780 [00:58<01:29, 346.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 16998/47780 [00:58<01:37, 316.56 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17156/47780 [00:58<01:32, 331.65 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18429/47780 [00:58<01:40, 292.23 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18848/47780 [00:58<01:29, 324.19 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17354/47780 [00:58<01:31, 332.41 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17915/47780 [00:58<01:25, 347.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17030/47780 [00:58<01:39, 310.14 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16861/47780 [00:58<01:41, 303.16 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17190/47780 [00:58<01:34, 323.26 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18471/47780 [00:58<01:34, 311.36 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18881/47780 [00:58<01:31, 315.90 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17389/47780 [00:58<01:30, 336.95 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17961/47780 [00:58<01:18, 377.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17065/47780 [00:58<01:36, 318.19 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16921/47780 [00:58<01:21, 379.85 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17223/47780 [00:58<01:35, 321.62 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18508/47780 [00:58<01:30, 323.96 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18913/47780 [00:58<01:34, 307.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17423/47780 [00:58<01:35, 316.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17103/47780 [00:58<01:34, 324.55 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18001/47780 [00:58<01:27, 341.70 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16961/47780 [00:58<01:26, 357.77 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17257/47780 [00:58<01:35, 319.78 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18944/47780 [00:58<01:36, 297.99 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17459/47780 [00:58<01:34, 321.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17137/47780 [00:58<01:34, 325.34 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18541/47780 [00:58<01:50, 263.52 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18037/47780 [00:58<01:27, 339.77 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 16999/47780 [00:58<01:30, 341.85 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17290/47780 [00:58<01:35, 319.02 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18978/47780 [00:58<01:33, 309.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17498/47780 [00:58<01:29, 340.18 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17172/47780 [00:58<01:34, 325.18 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18596/47780 [00:58<01:27, 333.64 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18072/47780 [00:58<01:31, 325.14 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17043/47780 [00:58<01:24, 363.76 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1405/47780 [00:58<09:02, 85.53 examples/s] Tokenizing train dataset (num_proc=32):  36%|███▋      | 17322/47780 [00:58<01:37, 312.28 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19011/47780 [00:58<01:32, 312.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17536/47780 [00:58<01:26, 347.83 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17209/47780 [00:58<01:30, 337.68 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17085/47780 [00:58<01:22, 371.08 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18633/47780 [00:58<01:33, 311.64 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17354/47780 [00:58<01:43, 294.50 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19043/47780 [00:58<01:36, 297.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18106/47780 [00:58<01:42, 288.91 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1460/47780 [00:58<07:40, 100.56 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17572/47780 [00:58<01:31, 328.52 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17243/47780 [00:58<01:32, 330.44 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17132/47780 [00:58<01:17, 397.98 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17385/47780 [00:58<01:42, 295.41 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19074/47780 [00:58<01:35, 300.36 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18667/47780 [00:58<01:39, 293.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18136/47780 [00:58<01:42, 288.42 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17606/47780 [00:58<01:31, 328.36 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17279/47780 [00:58<01:30, 335.41 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17173/47780 [00:59<01:17, 392.85 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17415/47780 [00:59<01:44, 289.77 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19105/47780 [00:59<01:37, 293.56 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17315/47780 [00:59<01:28, 342.50 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18698/47780 [00:59<01:42, 283.89 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18166/47780 [00:59<01:46, 279.29 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17640/47780 [00:59<01:31, 327.90 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17214/47780 [00:59<01:20, 380.49 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17445/47780 [00:59<01:45, 286.77 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19135/47780 [00:59<01:38, 291.28 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17352/47780 [00:59<01:26, 350.31 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18728/47780 [00:59<01:41, 287.16 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18200/47780 [00:59<01:41, 290.21 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17675/47780 [00:59<01:31, 330.36 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17475/47780 [00:59<01:44, 290.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17253/47780 [00:59<01:25, 359.03 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18763/47780 [00:59<01:36, 301.84 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17389/47780 [00:59<01:28, 343.93 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19165/47780 [00:59<01:46, 269.46 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17709/47780 [00:59<01:33, 322.07 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18234/47780 [00:59<01:40, 294.10 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17507/47780 [00:59<01:43, 292.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17302/47780 [00:59<01:17, 394.49 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18264/47780 [00:59<01:39, 295.43 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19199/47780 [00:59<01:40, 284.94 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17742/47780 [00:59<01:36, 311.05 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17425/47780 [00:59<01:34, 322.80 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18794/47780 [00:59<01:47, 268.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17538/47780 [00:59<01:42, 293.99 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18294/47780 [00:59<01:43, 284.30 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17343/47780 [00:59<01:26, 351.61 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17461/47780 [00:59<01:31, 333.04 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19228/47780 [00:59<01:46, 268.04 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18836/47780 [00:59<01:34, 307.35 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17774/47780 [00:59<01:43, 289.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17571/47780 [00:59<01:40, 300.76 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17390/47780 [00:59<01:20, 378.72 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18327/47780 [00:59<01:42, 287.38 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17495/47780 [00:59<01:32, 327.45 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18870/47780 [00:59<01:32, 313.07 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19266/47780 [00:59<01:38, 288.12 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17814/47780 [00:59<01:34, 316.63 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17602/47780 [00:59<01:40, 299.63 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18365/47780 [00:59<01:36, 306.23 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19299/47780 [00:59<01:35, 298.63 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18908/47780 [00:59<01:29, 324.32 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17849/47780 [00:59<01:32, 322.31 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17431/47780 [00:59<01:25, 355.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17529/47780 [00:59<01:38, 306.67 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17639/47780 [00:59<01:37, 309.66 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18396/47780 [00:59<01:35, 307.27 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19330/47780 [00:59<01:34, 301.57 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17475/47780 [00:59<01:20, 376.44 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18947/47780 [00:59<01:26, 331.51 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17563/47780 [00:59<01:36, 312.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17883/47780 [00:59<01:35, 312.84 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17671/47780 [00:59<01:39, 302.41 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19363/47780 [00:59<01:32, 307.00 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18433/47780 [00:59<01:32, 317.91 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18981/47780 [00:59<01:28, 326.67 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17595/47780 [00:59<01:37, 310.29 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17915/47780 [00:59<01:37, 305.04 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17514/47780 [00:59<01:26, 351.71 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19398/47780 [01:00<01:30, 315.19 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17702/47780 [01:00<01:52, 268.03 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17634/47780 [01:00<01:31, 329.94 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19015/47780 [01:00<01:31, 312.89 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17946/47780 [01:00<01:39, 299.44 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18465/47780 [01:00<01:44, 280.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17551/47780 [01:00<01:26, 349.00 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19430/47780 [01:00<01:29, 316.20 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1556/47780 [01:00<08:32, 90.25 examples/s] Tokenizing train dataset (num_proc=32):  37%|███▋      | 17672/47780 [01:00<01:27, 344.05 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17730/47780 [01:00<01:57, 256.63 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19047/47780 [01:00<01:31, 312.97 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17977/47780 [01:00<01:39, 299.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18513/47780 [01:00<01:28, 329.50 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17589/47780 [01:00<01:26, 349.72 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19463/47780 [01:00<01:29, 317.41 examples/s]Tokenizing train dataset (num_proc=32):   4%|▎         | 1785/47780 [01:00<04:10, 183.30 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17814/47780 [01:00<01:13, 406.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17707/47780 [01:00<01:35, 315.95 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17628/47780 [01:00<01:24, 357.14 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19080/47780 [01:00<01:34, 302.24 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18008/47780 [01:00<01:44, 286.18 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18548/47780 [01:00<01:34, 309.92 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19495/47780 [01:00<01:32, 306.72 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17667/47780 [01:00<01:22, 365.83 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19111/47780 [01:00<01:35, 300.29 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18043/47780 [01:00<01:37, 303.80 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18588/47780 [01:00<01:27, 333.68 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17740/47780 [01:00<01:41, 297.21 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17858/47780 [01:00<01:23, 357.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19526/47780 [01:00<01:34, 297.59 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19142/47780 [01:00<01:35, 299.70 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18075/47780 [01:00<01:36, 306.29 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17704/47780 [01:00<01:24, 355.25 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17901/47780 [01:00<01:21, 368.58 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17771/47780 [01:00<01:45, 285.41 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18626/47780 [01:00<01:29, 325.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19556/47780 [01:00<01:38, 285.12 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18109/47780 [01:00<01:34, 314.52 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17747/47780 [01:00<01:20, 372.14 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19173/47780 [01:00<01:37, 293.76 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17941/47780 [01:00<01:19, 376.65 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17800/47780 [01:00<01:46, 281.02 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18683/47780 [01:00<01:17, 376.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19585/47780 [01:00<01:38, 286.41 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17789/47780 [01:00<01:17, 385.76 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18146/47780 [01:00<01:30, 326.56 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19203/47780 [01:00<01:36, 295.43 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17981/47780 [01:00<01:19, 374.79 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18722/47780 [01:00<01:20, 360.29 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17829/47780 [01:00<01:57, 255.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19614/47780 [01:00<01:39, 283.86 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19240/47780 [01:00<01:30, 316.57 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17828/47780 [01:00<01:18, 381.96 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18186/47780 [01:00<01:26, 340.17 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18020/47780 [01:00<01:25, 348.17 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18759/47780 [01:00<01:20, 359.08 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17882/47780 [01:00<01:32, 323.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19651/47780 [01:00<01:32, 305.73 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18222/47780 [01:00<01:25, 345.01 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19272/47780 [01:00<01:31, 310.33 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17867/47780 [01:00<01:21, 367.80 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18056/47780 [01:00<01:25, 347.79 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18796/47780 [01:00<01:22, 350.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19687/47780 [01:01<01:28, 317.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17916/47780 [01:00<01:35, 311.14 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18257/47780 [01:01<01:25, 343.43 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19309/47780 [01:01<01:26, 327.55 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17904/47780 [01:01<01:23, 359.73 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18092/47780 [01:01<01:25, 348.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19730/47780 [01:01<01:22, 339.13 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18832/47780 [01:01<01:28, 328.65 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17950/47780 [01:01<01:35, 311.89 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18292/47780 [01:01<01:26, 341.51 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19342/47780 [01:01<01:27, 324.52 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17945/47780 [01:01<01:21, 366.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18128/47780 [01:01<01:25, 346.49 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19764/47780 [01:01<01:24, 331.02 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18876/47780 [01:01<01:20, 357.63 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17982/47780 [01:01<01:35, 310.62 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19375/47780 [01:01<01:29, 319.05 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18327/47780 [01:01<01:28, 331.50 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17985/47780 [01:01<01:21, 367.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18163/47780 [01:01<01:29, 330.89 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18017/47780 [01:01<01:33, 318.59 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19798/47780 [01:01<01:29, 312.53 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18913/47780 [01:01<01:24, 341.61 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18361/47780 [01:01<01:28, 332.43 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19407/47780 [01:01<01:30, 312.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18022/47780 [01:01<01:23, 355.63 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18197/47780 [01:01<01:33, 317.00 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18395/47780 [01:01<01:28, 332.58 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19439/47780 [01:01<01:30, 311.61 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19830/47780 [01:01<01:30, 307.78 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18050/47780 [01:01<01:37, 304.41 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18948/47780 [01:01<01:26, 333.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18058/47780 [01:01<01:25, 345.64 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18236/47780 [01:01<01:27, 336.95 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19862/47780 [01:01<01:29, 311.08 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19476/47780 [01:01<01:27, 323.77 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18984/47780 [01:01<01:24, 340.04 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18085/47780 [01:01<01:35, 310.34 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18429/47780 [01:01<01:31, 319.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18096/47780 [01:01<01:24, 351.36 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18272/47780 [01:01<01:31, 322.43 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18117/47780 [01:01<01:35, 309.29 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19019/47780 [01:01<01:26, 333.56 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19895/47780 [01:01<01:33, 299.54 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19509/47780 [01:01<01:30, 311.07 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18462/47780 [01:01<01:33, 312.04 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18132/47780 [01:01<01:24, 349.34 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18150/47780 [01:01<01:36, 308.49 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19933/47780 [01:01<01:26, 321.70 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18497/47780 [01:01<01:31, 320.16 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19541/47780 [01:01<01:32, 306.85 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18306/47780 [01:01<01:39, 295.04 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18167/47780 [01:01<01:25, 345.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19053/47780 [01:01<01:32, 309.63 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18181/47780 [01:01<01:43, 286.17 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19572/47780 [01:01<01:38, 287.68 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19966/47780 [01:01<01:37, 285.35 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19085/47780 [01:01<01:37, 293.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18202/47780 [01:01<01:34, 314.44 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18530/47780 [01:01<01:54, 255.48 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18337/47780 [01:01<02:03, 238.70 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18213/47780 [01:01<01:40, 295.26 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19613/47780 [01:02<01:28, 318.30 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19126/47780 [01:01<01:30, 317.94 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19996/47780 [01:02<01:38, 282.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18238/47780 [01:02<01:31, 323.46 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18587/47780 [01:02<01:27, 332.18 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18421/47780 [01:02<01:18, 374.69 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19648/47780 [01:02<01:26, 323.57 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18243/47780 [01:02<01:43, 284.09 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20029/47780 [01:02<01:34, 292.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19159/47780 [01:02<01:31, 314.40 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18276/47780 [01:02<01:27, 335.53 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18624/47780 [01:02<01:30, 321.94 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18273/47780 [01:02<01:43, 285.27 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18464/47780 [01:02<01:22, 355.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19681/47780 [01:02<01:33, 301.41 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19195/47780 [01:02<01:30, 316.26 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18310/47780 [01:02<01:31, 322.23 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20059/47780 [01:02<01:43, 266.61 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18659/47780 [01:02<01:31, 319.08 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 1874/47780 [01:02<07:14, 105.63 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18302/47780 [01:02<01:46, 276.73 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18505/47780 [01:02<01:23, 351.84 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19712/47780 [01:02<01:34, 297.06 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19233/47780 [01:02<01:25, 333.55 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18343/47780 [01:02<01:35, 307.45 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20087/47780 [01:02<01:46, 260.42 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 2083/47780 [01:02<04:15, 179.18 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18693/47780 [01:02<01:32, 314.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18330/47780 [01:02<01:48, 272.13 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19750/47780 [01:02<01:28, 316.78 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18543/47780 [01:02<01:24, 344.95 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19270/47780 [01:02<01:27, 325.95 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18379/47780 [01:02<01:34, 311.45 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20126/47780 [01:02<01:35, 289.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18358/47780 [01:02<01:48, 271.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18726/47780 [01:02<01:37, 296.61 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19782/47780 [01:02<01:32, 303.55 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19304/47780 [01:02<01:27, 326.23 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18580/47780 [01:02<01:26, 337.20 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18412/47780 [01:02<01:32, 316.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20171/47780 [01:02<01:23, 329.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18761/47780 [01:02<01:34, 307.46 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18386/47780 [01:02<01:51, 264.69 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19340/47780 [01:02<01:24, 334.64 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19821/47780 [01:02<01:27, 320.83 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18446/47780 [01:02<01:31, 319.65 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20205/47780 [01:02<01:24, 324.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18615/47780 [01:02<01:31, 317.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18802/47780 [01:02<01:27, 331.56 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18424/47780 [01:02<01:39, 293.81 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19375/47780 [01:02<01:24, 336.40 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19854/47780 [01:02<01:27, 319.28 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18479/47780 [01:02<01:34, 310.79 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18655/47780 [01:02<01:27, 332.55 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20238/47780 [01:02<01:29, 307.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18836/47780 [01:02<01:26, 333.55 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18459/47780 [01:02<01:36, 302.93 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19416/47780 [01:02<01:20, 353.45 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19893/47780 [01:02<01:23, 335.92 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18515/47780 [01:02<01:32, 317.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20270/47780 [01:02<01:30, 303.50 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18870/47780 [01:02<01:30, 320.80 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18506/47780 [01:02<01:25, 342.68 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18690/47780 [01:02<01:40, 288.37 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19931/47780 [01:03<01:20, 344.74 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19452/47780 [01:02<01:21, 346.82 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18552/47780 [01:03<01:28, 329.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20304/47780 [01:03<01:27, 313.01 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18903/47780 [01:03<01:30, 319.93 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18739/47780 [01:03<01:26, 334.24 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18542/47780 [01:03<01:27, 335.53 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19968/47780 [01:03<01:19, 348.05 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19488/47780 [01:03<01:26, 328.02 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18587/47780 [01:03<01:29, 324.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20336/47780 [01:03<01:32, 298.17 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18939/47780 [01:03<01:29, 323.91 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18576/47780 [01:03<01:29, 326.55 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18775/47780 [01:03<01:29, 323.87 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20009/47780 [01:03<01:19, 349.71 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19522/47780 [01:03<01:25, 329.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18621/47780 [01:03<01:29, 325.02 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20367/47780 [01:03<01:36, 282.64 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18614/47780 [01:03<01:27, 333.98 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20045/47780 [01:03<01:19, 348.31 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19556/47780 [01:03<01:25, 331.32 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18972/47780 [01:03<01:36, 298.50 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18809/47780 [01:03<01:31, 315.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18654/47780 [01:03<01:32, 315.67 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20401/47780 [01:03<01:35, 285.77 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20082/47780 [01:03<01:18, 351.05 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19003/47780 [01:03<01:37, 295.00 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18842/47780 [01:03<01:34, 306.32 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18686/47780 [01:03<01:31, 316.89 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18648/47780 [01:03<01:35, 304.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19591/47780 [01:03<01:30, 310.40 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20125/47780 [01:03<01:14, 373.67 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20430/47780 [01:03<01:41, 269.91 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19033/47780 [01:03<01:39, 290.24 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18874/47780 [01:03<01:34, 306.80 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18720/47780 [01:03<01:29, 323.52 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18681/47780 [01:03<01:35, 304.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19623/47780 [01:03<01:33, 300.71 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20458/47780 [01:03<01:43, 263.75 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20163/47780 [01:03<01:17, 354.81 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18758/47780 [01:03<01:25, 339.81 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19063/47780 [01:03<01:42, 280.72 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18712/47780 [01:03<01:37, 299.46 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19655/47780 [01:03<01:33, 299.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18906/47780 [01:03<01:40, 288.50 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20491/47780 [01:03<01:36, 281.57 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20200/47780 [01:03<01:18, 351.21 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18797/47780 [01:03<01:22, 350.59 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19095/47780 [01:03<01:38, 291.39 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18744/47780 [01:03<01:35, 302.61 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18940/47780 [01:03<01:35, 302.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19691/47780 [01:03<01:28, 315.86 examples/s]Tokenizing train dataset (num_proc=32):   5%|▍         | 2189/47780 [01:03<05:38, 134.80 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20520/47780 [01:03<01:36, 283.84 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20237/47780 [01:03<01:17, 356.14 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19129/47780 [01:03<01:36, 297.36 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18833/47780 [01:03<01:25, 337.54 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18981/47780 [01:03<01:26, 331.74 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19730/47780 [01:03<01:26, 326.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18776/47780 [01:03<01:38, 293.57 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20554/47780 [01:03<01:30, 299.60 examples/s]Tokenizing train dataset (num_proc=32):   5%|▍         | 2266/47780 [01:03<04:42, 161.16 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18871/47780 [01:03<01:23, 345.73 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20273/47780 [01:04<01:23, 330.96 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19015/47780 [01:03<01:29, 323.06 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19769/47780 [01:03<01:21, 343.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18815/47780 [01:03<01:30, 320.19 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19159/47780 [01:03<01:44, 274.65 examples/s]Tokenizing train dataset (num_proc=32):   5%|▌         | 2413/47780 [01:04<03:14, 232.98 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20589/47780 [01:04<01:31, 297.21 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18906/47780 [01:04<01:24, 342.96 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18851/47780 [01:04<01:28, 328.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20307/47780 [01:04<01:26, 319.34 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19190/47780 [01:04<01:41, 281.19 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19804/47780 [01:04<01:25, 326.75 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19048/47780 [01:04<01:37, 295.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20619/47780 [01:04<01:33, 291.52 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18941/47780 [01:04<01:28, 327.09 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20340/47780 [01:04<01:27, 315.33 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19845/47780 [01:04<01:19, 349.91 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18885/47780 [01:04<01:35, 303.84 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19219/47780 [01:04<01:48, 264.39 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19079/47780 [01:04<01:40, 286.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20650/47780 [01:04<01:32, 293.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18974/47780 [01:04<01:28, 326.88 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20372/47780 [01:04<01:30, 303.13 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19882/47780 [01:04<01:23, 335.91 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19246/47780 [01:04<01:48, 261.83 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19116/47780 [01:04<01:33, 305.76 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18916/47780 [01:04<01:42, 280.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20681/47780 [01:04<01:31, 297.44 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19007/47780 [01:04<01:29, 320.35 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20403/47780 [01:04<01:30, 301.26 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19276/47780 [01:04<01:44, 272.26 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19916/47780 [01:04<01:23, 334.54 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18947/47780 [01:04<01:39, 288.61 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19148/47780 [01:04<01:36, 296.61 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20711/47780 [01:04<01:32, 292.09 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19040/47780 [01:04<01:33, 308.87 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19310/47780 [01:04<01:38, 288.12 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19951/47780 [01:04<01:23, 335.01 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20434/47780 [01:04<01:37, 279.33 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18977/47780 [01:04<01:39, 288.09 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19179/47780 [01:04<01:38, 290.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20758/47780 [01:04<01:22, 328.16 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19985/47780 [01:04<01:22, 336.15 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19072/47780 [01:04<01:36, 296.60 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19341/47780 [01:04<01:39, 284.65 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20475/47780 [01:04<01:26, 314.33 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19014/47780 [01:04<01:33, 307.90 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19211/47780 [01:04<01:36, 295.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20792/47780 [01:04<01:21, 331.22 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20019/47780 [01:04<01:24, 329.56 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19376/47780 [01:04<01:34, 299.70 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20508/47780 [01:04<01:27, 311.77 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19054/47780 [01:04<01:27, 326.46 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19102/47780 [01:04<01:47, 267.17 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19241/47780 [01:04<01:39, 286.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20826/47780 [01:04<01:21, 331.38 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20053/47780 [01:04<01:26, 321.78 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19413/47780 [01:04<01:29, 316.13 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20549/47780 [01:04<01:20, 339.11 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19088/47780 [01:04<01:27, 326.89 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19278/47780 [01:04<01:32, 307.06 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19130/47780 [01:04<01:49, 262.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20860/47780 [01:04<01:23, 321.58 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19446/47780 [01:04<01:28, 319.41 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20087/47780 [01:04<01:26, 319.00 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20584/47780 [01:04<01:20, 338.46 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19157/47780 [01:04<01:50, 258.91 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19309/47780 [01:04<01:36, 293.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20894/47780 [01:05<01:22, 326.55 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19121/47780 [01:05<01:40, 284.63 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20619/47780 [01:05<01:19, 341.21 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19479/47780 [01:05<01:31, 308.97 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20119/47780 [01:05<01:35, 290.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19186/47780 [01:05<01:46, 267.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19342/47780 [01:05<01:38, 289.87 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19177/47780 [01:05<01:20, 353.95 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20927/47780 [01:05<01:31, 294.64 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20654/47780 [01:05<01:20, 336.52 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19512/47780 [01:05<01:30, 311.22 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19213/47780 [01:05<01:47, 264.72 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20149/47780 [01:05<01:39, 277.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19376/47780 [01:05<01:33, 302.28 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19214/47780 [01:05<01:25, 335.99 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20961/47780 [01:05<01:29, 299.33 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20688/47780 [01:05<01:23, 326.15 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19545/47780 [01:05<01:36, 292.68 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19246/47780 [01:05<01:42, 277.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20186/47780 [01:05<01:31, 300.95 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19407/47780 [01:05<01:35, 296.72 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19249/47780 [01:05<01:28, 322.90 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20992/47780 [01:05<01:34, 283.86 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20727/47780 [01:05<01:21, 332.95 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19580/47780 [01:05<01:33, 302.26 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19276/47780 [01:05<01:40, 283.46 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19445/47780 [01:05<01:28, 319.80 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20218/47780 [01:05<01:37, 282.58 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21030/47780 [01:05<01:26, 308.49 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19283/47780 [01:05<01:30, 316.61 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20764/47780 [01:05<01:19, 339.75 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19305/47780 [01:05<01:40, 284.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19612/47780 [01:05<01:33, 300.59 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19481/47780 [01:05<01:28, 318.39 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20247/47780 [01:05<01:37, 281.38 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19316/47780 [01:05<01:29, 319.81 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21067/47780 [01:05<01:23, 319.66 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20799/47780 [01:05<01:20, 334.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19654/47780 [01:05<01:25, 330.14 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19334/47780 [01:05<01:50, 257.16 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20276/47780 [01:05<01:37, 281.08 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19514/47780 [01:05<01:32, 304.48 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19357/47780 [01:05<01:23, 342.30 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21100/47780 [01:05<01:25, 311.79 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19691/47780 [01:05<01:22, 341.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20834/47780 [01:05<01:24, 317.39 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20306/47780 [01:05<01:35, 286.28 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19367/47780 [01:05<01:45, 268.16 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19546/47780 [01:05<01:33, 302.07 examples/s]Tokenizing train dataset (num_proc=32):   5%|▌         | 2508/47780 [01:05<05:50, 129.02 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19392/47780 [01:05<01:26, 329.30 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21137/47780 [01:05<01:24, 315.14 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19728/47780 [01:05<01:21, 345.84 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20866/47780 [01:05<01:28, 304.64 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20341/47780 [01:05<01:30, 304.26 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19396/47780 [01:05<01:44, 271.18 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19589/47780 [01:05<01:23, 336.81 examples/s]Tokenizing train dataset (num_proc=32):   6%|▌         | 2796/47780 [01:05<02:57, 253.05 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21173/47780 [01:05<01:21, 326.77 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19426/47780 [01:05<01:31, 311.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19763/47780 [01:05<01:25, 329.56 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20899/47780 [01:05<01:26, 310.40 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19429/47780 [01:05<01:41, 278.31 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20372/47780 [01:05<01:38, 277.39 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19624/47780 [01:05<01:26, 326.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21206/47780 [01:06<01:23, 320.07 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20938/47780 [01:06<01:20, 332.19 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19797/47780 [01:06<01:27, 320.13 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19458/47780 [01:06<01:38, 286.50 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19468/47780 [01:06<01:34, 299.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19658/47780 [01:06<01:26, 326.77 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21239/47780 [01:06<01:28, 298.59 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19494/47780 [01:06<01:33, 302.23 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19830/47780 [01:06<01:31, 305.67 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20402/47780 [01:06<01:59, 228.72 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20972/47780 [01:06<01:27, 305.07 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19697/47780 [01:06<01:21, 344.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19499/47780 [01:06<01:34, 298.75 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19530/47780 [01:06<01:28, 317.70 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21272/47780 [01:06<01:30, 292.10 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20482/47780 [01:06<01:15, 363.92 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21005/47780 [01:06<01:25, 311.81 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19864/47780 [01:06<01:31, 305.20 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19529/47780 [01:06<01:35, 296.39 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19732/47780 [01:06<01:29, 312.39 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21302/47780 [01:06<01:30, 291.15 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19563/47780 [01:06<01:29, 313.78 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19895/47780 [01:06<01:32, 302.43 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21037/47780 [01:06<01:30, 294.28 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19559/47780 [01:06<01:38, 287.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20523/47780 [01:06<01:18, 348.64 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21332/47780 [01:06<01:30, 292.44 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19598/47780 [01:06<01:27, 320.84 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19934/47780 [01:06<01:25, 324.12 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19764/47780 [01:06<01:46, 264.20 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21068/47780 [01:06<01:29, 297.50 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20565/47780 [01:06<01:14, 366.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19588/47780 [01:06<01:42, 275.51 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19631/47780 [01:06<01:30, 311.91 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19973/47780 [01:06<01:21, 342.52 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21363/47780 [01:06<01:37, 271.05 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19804/47780 [01:06<01:35, 291.77 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21100/47780 [01:06<01:31, 291.36 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19618/47780 [01:06<01:39, 281.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20605/47780 [01:06<01:16, 356.53 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19664/47780 [01:06<01:29, 314.33 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20008/47780 [01:06<01:22, 336.27 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19836/47780 [01:06<01:35, 293.42 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21130/47780 [01:06<01:34, 281.76 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19647/47780 [01:06<01:43, 272.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20643/47780 [01:06<01:20, 337.76 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19696/47780 [01:06<01:29, 312.41 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21391/47780 [01:06<02:00, 219.26 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20046/47780 [01:06<01:21, 342.35 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19867/47780 [01:06<01:33, 297.10 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19680/47780 [01:06<01:37, 288.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21159/47780 [01:06<01:37, 272.10 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20679/47780 [01:06<01:27, 311.17 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19729/47780 [01:06<01:28, 317.12 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21469/47780 [01:06<01:15, 347.78 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19898/47780 [01:06<01:34, 293.92 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20081/47780 [01:06<01:27, 315.08 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19715/47780 [01:06<01:31, 305.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21188/47780 [01:06<01:36, 274.26 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20716/47780 [01:06<01:23, 325.97 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19763/47780 [01:06<01:27, 320.28 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21508/47780 [01:07<01:17, 336.99 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19928/47780 [01:07<01:37, 286.10 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19746/47780 [01:07<01:31, 306.66 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20120/47780 [01:07<01:23, 331.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21217/47780 [01:07<01:36, 275.17 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20752/47780 [01:07<01:21, 331.49 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19797/47780 [01:07<01:25, 325.86 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19957/47780 [01:07<01:37, 284.54 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19777/47780 [01:07<01:36, 291.38 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21248/47780 [01:07<01:34, 281.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20154/47780 [01:07<01:28, 312.96 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21545/47780 [01:07<01:24, 311.70 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19834/47780 [01:07<01:23, 335.23 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20786/47780 [01:07<01:26, 312.70 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19990/47780 [01:07<01:34, 292.95 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19814/47780 [01:07<01:29, 313.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21277/47780 [01:07<01:34, 281.06 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20186/47780 [01:07<01:29, 307.55 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19868/47780 [01:07<01:24, 328.81 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21579/47780 [01:07<01:32, 282.46 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20821/47780 [01:07<01:24, 319.88 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20026/47780 [01:07<01:29, 309.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21309/47780 [01:07<01:31, 288.96 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19846/47780 [01:07<01:33, 298.22 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20218/47780 [01:07<01:32, 298.64 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19901/47780 [01:07<01:26, 321.72 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21614/47780 [01:07<01:28, 295.83 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20058/47780 [01:07<01:31, 302.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21350/47780 [01:07<01:22, 319.97 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19877/47780 [01:07<01:34, 294.88 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20249/47780 [01:07<01:34, 292.46 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20854/47780 [01:07<01:45, 255.29 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21646/47780 [01:07<01:29, 290.43 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19934/47780 [01:07<01:32, 299.88 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20089/47780 [01:07<01:33, 297.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21384/47780 [01:07<01:21, 322.16 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19907/47780 [01:07<01:37, 286.38 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20281/47780 [01:07<01:31, 299.81 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20909/47780 [01:07<01:23, 322.28 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21682/47780 [01:07<01:27, 299.11 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19966/47780 [01:07<01:33, 298.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20120/47780 [01:07<01:31, 300.80 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21422/47780 [01:07<01:19, 333.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2924/47780 [01:07<04:47, 155.87 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20313/47780 [01:07<01:30, 302.39 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19937/47780 [01:07<01:39, 280.78 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20003/47780 [01:07<01:28, 315.28 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20945/47780 [01:07<01:30, 295.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21713/47780 [01:07<01:32, 281.13 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20151/47780 [01:07<01:37, 282.06 examples/s]Tokenizing train dataset (num_proc=32):   7%|▋         | 3107/47780 [01:07<03:19, 223.39 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21456/47780 [01:07<01:25, 307.85 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20344/47780 [01:07<01:32, 297.66 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19966/47780 [01:07<01:40, 277.45 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20035/47780 [01:07<01:30, 308.13 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20981/47780 [01:07<01:27, 305.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21749/47780 [01:07<01:26, 301.50 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20180/47780 [01:07<01:38, 279.09 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21496/47780 [01:07<01:20, 326.63 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19994/47780 [01:07<01:43, 269.05 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20374/47780 [01:07<01:48, 252.18 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21018/47780 [01:07<01:23, 321.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20066/47780 [01:07<01:34, 293.54 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21780/47780 [01:08<01:27, 297.32 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20209/47780 [01:07<01:38, 280.10 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21530/47780 [01:08<01:20, 325.83 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20025/47780 [01:08<01:40, 277.45 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20422/47780 [01:08<01:28, 307.57 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20100/47780 [01:08<01:30, 306.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21054/47780 [01:08<01:21, 328.53 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21812/47780 [01:08<01:27, 297.31 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20240/47780 [01:08<01:36, 285.42 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21563/47780 [01:08<01:23, 313.76 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20058/47780 [01:08<01:36, 285.81 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21090/47780 [01:08<01:19, 337.09 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20457/47780 [01:08<01:27, 313.09 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20131/47780 [01:08<01:33, 294.19 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21856/47780 [01:08<01:17, 333.18 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20269/47780 [01:08<01:39, 277.24 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20095/47780 [01:08<01:30, 306.96 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21596/47780 [01:08<01:24, 311.33 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21125/47780 [01:08<01:18, 339.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20490/47780 [01:08<01:26, 315.01 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20161/47780 [01:08<01:35, 288.73 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21891/47780 [01:08<01:19, 326.87 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20133/47780 [01:08<01:25, 323.26 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20297/47780 [01:08<01:47, 254.70 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21628/47780 [01:08<01:23, 313.04 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21160/47780 [01:08<01:18, 341.23 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21929/47780 [01:08<01:15, 341.57 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20195/47780 [01:08<01:31, 300.21 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20523/47780 [01:08<01:33, 291.65 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20166/47780 [01:08<01:25, 321.66 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20342/47780 [01:08<01:30, 304.44 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21662/47780 [01:08<01:23, 314.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21203/47780 [01:08<01:12, 365.50 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20226/47780 [01:08<01:32, 299.25 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21964/47780 [01:08<01:19, 325.40 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21698/47780 [01:08<01:20, 323.72 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20374/47780 [01:08<01:31, 298.53 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20199/47780 [01:08<01:30, 306.33 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20554/47780 [01:08<01:50, 247.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21240/47780 [01:08<01:15, 350.50 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20259/47780 [01:08<01:30, 305.07 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21997/47780 [01:08<01:20, 319.73 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20410/47780 [01:08<01:28, 309.07 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20233/47780 [01:08<01:28, 312.22 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21733/47780 [01:08<01:22, 314.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20588/47780 [01:08<01:41, 268.99 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21276/47780 [01:08<01:22, 320.31 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20290/47780 [01:08<01:39, 277.37 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22030/47780 [01:08<01:24, 305.10 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20442/47780 [01:08<01:28, 308.26 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21769/47780 [01:08<01:20, 322.03 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20276/47780 [01:08<01:25, 323.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20625/47780 [01:08<01:34, 288.77 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20321/47780 [01:08<01:36, 283.41 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21309/47780 [01:08<01:29, 296.85 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22061/47780 [01:08<01:27, 293.85 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21802/47780 [01:08<01:21, 320.20 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20474/47780 [01:08<01:34, 290.06 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20310/47780 [01:08<01:26, 317.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20657/47780 [01:08<01:32, 293.94 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20360/47780 [01:08<01:27, 312.74 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22094/47780 [01:09<01:24, 303.39 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21359/47780 [01:08<01:17, 339.77 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20513/47780 [01:08<01:26, 316.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21837/47780 [01:09<01:25, 304.94 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20688/47780 [01:09<01:32, 292.48 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20342/47780 [01:09<01:30, 304.86 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20392/47780 [01:09<01:31, 297.90 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22125/47780 [01:09<01:25, 298.97 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21394/47780 [01:09<01:17, 342.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20559/47780 [01:09<01:19, 341.25 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21868/47780 [01:09<01:26, 299.31 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20379/47780 [01:09<01:25, 319.24 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20718/47780 [01:09<01:37, 278.06 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22161/47780 [01:09<01:21, 312.62 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21429/47780 [01:09<01:19, 330.17 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20423/47780 [01:09<01:36, 284.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21899/47780 [01:09<01:25, 302.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20597/47780 [01:09<01:18, 344.17 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20412/47780 [01:09<01:25, 318.92 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20750/47780 [01:09<01:34, 286.99 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22193/47780 [01:09<01:22, 310.81 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20452/47780 [01:09<01:39, 274.16 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21931/47780 [01:09<01:24, 307.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21463/47780 [01:09<01:25, 309.16 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20780/47780 [01:09<01:39, 272.46 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20632/47780 [01:09<01:27, 311.03 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22225/47780 [01:09<01:21, 313.35 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20444/47780 [01:09<01:39, 273.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20481/47780 [01:09<01:38, 276.66 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21498/47780 [01:09<01:23, 313.40 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21967/47780 [01:09<01:22, 312.22 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20811/47780 [01:09<01:35, 282.60 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20664/47780 [01:09<01:27, 310.36 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20490/47780 [01:09<01:25, 320.61 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22257/47780 [01:09<01:25, 297.93 examples/s]Tokenizing train dataset (num_proc=32):   7%|▋         | 3220/47780 [01:09<05:09, 144.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20511/47780 [01:09<01:37, 280.02 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21534/47780 [01:09<01:21, 323.91 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22008/47780 [01:09<01:17, 332.42 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20840/47780 [01:09<01:40, 266.80 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20528/47780 [01:09<01:20, 336.52 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22291/47780 [01:09<01:22, 308.00 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3398/47780 [01:09<03:31, 209.46 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20540/47780 [01:09<01:40, 270.60 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21567/47780 [01:09<01:26, 304.04 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22042/47780 [01:09<01:21, 316.00 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20696/47780 [01:09<01:55, 235.18 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20873/47780 [01:09<01:36, 277.90 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20563/47780 [01:09<01:22, 329.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22322/47780 [01:09<01:27, 290.43 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20568/47780 [01:09<01:47, 253.57 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21612/47780 [01:09<01:17, 339.72 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22074/47780 [01:09<01:24, 303.70 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20602/47780 [01:09<01:19, 342.19 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22360/47780 [01:09<01:21, 312.27 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20902/47780 [01:09<01:45, 255.31 examples/s]Tokenizing train dataset (num_proc=32):   7%|▋         | 3508/47780 [01:09<03:04, 239.96 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20723/47780 [01:09<02:10, 206.59 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21650/47780 [01:09<01:16, 343.23 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20594/47780 [01:09<01:51, 244.12 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22105/47780 [01:09<01:26, 296.18 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20637/47780 [01:09<01:21, 333.33 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20931/47780 [01:09<01:42, 262.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22396/47780 [01:09<01:18, 324.72 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21694/47780 [01:09<01:11, 363.83 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20649/47780 [01:09<01:23, 323.73 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22137/47780 [01:10<01:25, 299.49 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20746/47780 [01:09<02:20, 192.47 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20672/47780 [01:10<01:22, 326.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20959/47780 [01:10<01:40, 266.97 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22431/47780 [01:10<01:24, 300.21 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21731/47780 [01:10<01:13, 355.87 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22174/47780 [01:10<01:21, 312.37 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20683/47780 [01:10<01:29, 304.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20706/47780 [01:10<01:22, 327.38 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20767/47780 [01:10<02:26, 184.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20987/47780 [01:10<01:41, 264.67 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21772/47780 [01:10<01:10, 369.73 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22207/47780 [01:10<01:20, 317.30 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22462/47780 [01:10<01:29, 283.00 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20715/47780 [01:10<01:34, 286.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20872/47780 [01:10<01:10, 380.31 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21023/47780 [01:10<01:32, 288.42 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20739/47780 [01:10<01:30, 300.07 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21810/47780 [01:10<01:10, 369.99 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22241/47780 [01:10<01:19, 322.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22491/47780 [01:10<01:34, 267.78 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20745/47780 [01:10<01:37, 276.78 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21053/47780 [01:10<01:35, 279.13 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20772/47780 [01:10<01:27, 308.02 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21852/47780 [01:10<01:08, 379.73 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22285/47780 [01:10<01:12, 352.93 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20918/47780 [01:10<01:20, 331.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22522/47780 [01:10<01:34, 266.72 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20774/47780 [01:10<01:40, 269.73 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20805/47780 [01:10<01:27, 307.99 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22322/47780 [01:10<01:11, 354.63 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21891/47780 [01:10<01:13, 354.41 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22552/47780 [01:10<01:32, 273.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21083/47780 [01:10<01:56, 228.67 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20959/47780 [01:10<01:21, 328.70 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20837/47780 [01:10<01:26, 310.67 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20802/47780 [01:10<01:42, 262.77 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22361/47780 [01:10<01:10, 360.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22581/47780 [01:10<01:33, 269.21 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20996/47780 [01:10<01:20, 332.10 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21927/47780 [01:10<01:23, 307.99 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20829/47780 [01:10<01:44, 258.39 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20869/47780 [01:10<01:31, 293.16 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22405/47780 [01:10<01:06, 383.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21108/47780 [01:10<02:15, 197.41 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22610/47780 [01:10<01:34, 266.31 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21035/47780 [01:10<01:19, 336.39 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21975/47780 [01:10<01:14, 348.32 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20855/47780 [01:10<01:45, 254.89 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22444/47780 [01:10<01:07, 376.61 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20899/47780 [01:10<01:42, 263.35 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21076/47780 [01:10<01:15, 354.96 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21130/47780 [01:10<02:25, 182.56 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22637/47780 [01:10<01:41, 248.31 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22012/47780 [01:10<01:16, 336.42 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20881/47780 [01:10<01:47, 249.69 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22482/47780 [01:10<01:07, 373.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20947/47780 [01:10<01:24, 316.76 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21115/47780 [01:10<01:14, 356.93 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21252/47780 [01:10<01:04, 409.55 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22062/47780 [01:10<01:07, 379.60 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20919/47780 [01:11<01:36, 276.98 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20980/47780 [01:11<01:24, 316.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22520/47780 [01:11<01:15, 336.27 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22663/47780 [01:11<02:03, 203.39 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21152/47780 [01:11<01:17, 341.88 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22102/47780 [01:11<01:09, 368.41 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20955/47780 [01:11<01:31, 293.37 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21300/47780 [01:11<01:12, 366.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21016/47780 [01:11<01:22, 325.33 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22555/47780 [01:11<01:19, 318.83 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22730/47780 [01:11<01:22, 302.24 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22143/47780 [01:11<01:08, 376.15 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20986/47780 [01:11<01:30, 294.86 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21188/47780 [01:11<01:23, 319.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21051/47780 [01:11<01:22, 324.69 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21342/47780 [01:11<01:13, 359.00 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22589/47780 [01:11<01:18, 321.54 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22763/47780 [01:11<01:21, 306.10 examples/s]Tokenizing train dataset (num_proc=32):   8%|▊         | 3599/47780 [01:11<05:01, 146.59 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21095/47780 [01:11<01:14, 357.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21016/47780 [01:11<01:37, 274.03 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21221/47780 [01:11<01:31, 291.55 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22183/47780 [01:11<01:17, 330.68 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21382/47780 [01:11<01:13, 358.84 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22626/47780 [01:11<01:16, 328.76 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22796/47780 [01:11<01:20, 308.80 examples/s]Tokenizing train dataset (num_proc=32):   8%|▊         | 3823/47780 [01:11<02:59, 244.37 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21049/47780 [01:11<01:33, 286.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21132/47780 [01:11<01:15, 354.09 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21255/47780 [01:11<01:28, 300.84 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22218/47780 [01:11<01:16, 332.58 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21421/47780 [01:11<01:12, 362.55 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22660/47780 [01:11<01:19, 316.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22829/47780 [01:11<01:22, 301.84 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21078/47780 [01:11<01:36, 275.35 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22254/47780 [01:11<01:16, 332.97 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21460/47780 [01:11<01:11, 369.65 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21169/47780 [01:11<01:18, 337.86 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22863/47780 [01:11<01:20, 310.03 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22692/47780 [01:11<01:26, 289.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21286/47780 [01:11<01:48, 244.17 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21110/47780 [01:11<01:32, 287.41 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21204/47780 [01:11<01:20, 330.78 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22290/47780 [01:11<01:17, 329.71 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21499/47780 [01:11<01:13, 356.23 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22898/47780 [01:11<01:19, 312.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22725/47780 [01:11<01:24, 296.52 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21140/47780 [01:11<01:32, 287.73 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21238/47780 [01:11<01:20, 329.68 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21313/47780 [01:11<01:57, 225.05 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22324/47780 [01:11<01:23, 304.98 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22931/47780 [01:11<01:19, 313.95 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21536/47780 [01:11<01:19, 331.14 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22758/47780 [01:11<01:23, 299.10 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21169/47780 [01:11<01:41, 261.84 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22356/47780 [01:11<01:23, 306.09 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21337/47780 [01:11<02:02, 216.03 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21272/47780 [01:11<01:28, 298.82 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22963/47780 [01:12<01:21, 305.36 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21573/47780 [01:11<01:19, 330.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22799/47780 [01:12<01:17, 322.69 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21209/47780 [01:12<01:28, 298.96 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22391/47780 [01:12<01:22, 308.15 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21422/47780 [01:12<01:13, 356.93 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21303/47780 [01:12<01:30, 292.53 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21607/47780 [01:12<01:20, 326.37 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22838/47780 [01:12<01:13, 341.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22994/47780 [01:12<01:27, 284.60 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21240/47780 [01:12<01:32, 285.68 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21336/47780 [01:12<01:27, 300.73 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21464/47780 [01:12<01:12, 365.31 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22423/47780 [01:12<01:24, 300.94 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21641/47780 [01:12<01:20, 326.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23025/47780 [01:12<01:25, 288.23 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22874/47780 [01:12<01:17, 321.31 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21279/47780 [01:12<01:25, 311.42 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22454/47780 [01:12<01:24, 298.45 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21367/47780 [01:12<01:30, 291.94 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21674/47780 [01:12<01:23, 313.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23058/47780 [01:12<01:25, 290.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22910/47780 [01:12<01:15, 328.12 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21503/47780 [01:12<01:18, 333.74 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22485/47780 [01:12<01:24, 300.90 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21399/47780 [01:12<01:29, 293.43 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21708/47780 [01:12<01:22, 317.70 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23089/47780 [01:12<01:24, 292.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22944/47780 [01:12<01:14, 331.25 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21539/47780 [01:12<01:27, 300.08 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21311/47780 [01:12<01:53, 233.19 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21430/47780 [01:12<01:29, 294.87 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21745/47780 [01:12<01:20, 324.14 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22516/47780 [01:12<01:29, 281.20 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22981/47780 [01:12<01:13, 338.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23120/47780 [01:12<01:24, 290.86 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21358/47780 [01:12<01:34, 279.50 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21460/47780 [01:12<01:29, 292.75 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21571/47780 [01:12<01:32, 282.06 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21779/47780 [01:12<01:19, 325.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22545/47780 [01:12<01:31, 277.18 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23153/47780 [01:12<01:22, 298.53 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23016/47780 [01:12<01:17, 321.22 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21393/47780 [01:12<01:29, 295.67 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21500/47780 [01:12<01:23, 316.35 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21601/47780 [01:12<01:33, 280.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22588/47780 [01:12<01:19, 316.28 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23183/47780 [01:12<01:26, 284.03 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21812/47780 [01:12<01:28, 293.77 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23052/47780 [01:12<01:18, 313.19 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21426/47780 [01:12<01:29, 293.08 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21532/47780 [01:12<01:23, 315.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21631/47780 [01:12<01:33, 279.88 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22620/47780 [01:12<01:20, 313.22 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23227/47780 [01:12<01:16, 322.42 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21843/47780 [01:12<01:28, 291.93 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23093/47780 [01:12<01:12, 339.26 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21568/47780 [01:12<01:21, 322.84 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22654/47780 [01:12<01:19, 317.68 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21661/47780 [01:12<01:34, 276.03 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21458/47780 [01:12<01:35, 274.64 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23128/47780 [01:13<01:14, 331.47 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23260/47780 [01:13<01:22, 297.85 examples/s]Tokenizing train dataset (num_proc=32):   8%|▊         | 3935/47780 [01:12<04:36, 158.72 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21873/47780 [01:13<01:41, 255.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21601/47780 [01:13<01:22, 317.32 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21716/47780 [01:13<01:15, 345.68 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22686/47780 [01:13<01:22, 304.15 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21491/47780 [01:13<01:34, 277.39 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23163/47780 [01:13<01:13, 332.95 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23292/47780 [01:13<01:23, 294.23 examples/s]Tokenizing train dataset (num_proc=32):   9%|▉         | 4194/47780 [01:13<02:42, 267.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21907/47780 [01:13<01:33, 276.54 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21633/47780 [01:13<01:25, 304.30 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22721/47780 [01:13<01:21, 306.89 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21520/47780 [01:13<01:33, 280.40 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21752/47780 [01:13<01:21, 321.22 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23207/47780 [01:13<01:07, 362.91 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23323/47780 [01:13<01:22, 298.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21936/47780 [01:13<01:35, 271.61 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22755/47780 [01:13<01:20, 312.64 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21549/47780 [01:13<01:34, 277.03 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21664/47780 [01:13<01:38, 265.87 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23244/47780 [01:13<01:11, 341.13 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21786/47780 [01:13<01:27, 298.29 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23354/47780 [01:13<01:26, 282.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21968/47780 [01:13<01:32, 278.53 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22787/47780 [01:13<01:20, 311.05 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21580/47780 [01:13<01:34, 277.23 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21707/47780 [01:13<01:25, 306.46 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21829/47780 [01:13<01:18, 331.67 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23384/47780 [01:13<01:25, 285.60 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23279/47780 [01:13<01:14, 329.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22002/47780 [01:13<01:27, 295.25 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22819/47780 [01:13<01:22, 303.91 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23314/47780 [01:13<01:13, 331.63 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23413/47780 [01:13<01:26, 282.65 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21739/47780 [01:13<01:30, 288.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21609/47780 [01:13<01:45, 248.11 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21864/47780 [01:13<01:24, 306.93 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22033/47780 [01:13<01:28, 289.74 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22851/47780 [01:13<01:28, 282.13 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21770/47780 [01:13<01:29, 291.05 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21645/47780 [01:13<01:34, 276.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23356/47780 [01:13<01:10, 348.31 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22068/47780 [01:13<01:24, 303.28 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23442/47780 [01:13<01:36, 253.37 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21897/47780 [01:13<01:28, 292.07 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22880/47780 [01:13<01:31, 272.60 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21681/47780 [01:13<01:27, 299.16 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21801/47780 [01:13<01:29, 289.92 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23393/47780 [01:13<01:10, 346.08 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22101/47780 [01:13<01:28, 290.34 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21927/47780 [01:13<01:31, 282.49 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23469/47780 [01:13<01:47, 226.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23439/47780 [01:13<01:04, 374.95 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22908/47780 [01:13<01:38, 253.05 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21712/47780 [01:13<01:33, 277.43 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21831/47780 [01:13<01:35, 273.00 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22150/47780 [01:13<01:14, 343.92 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21956/47780 [01:13<01:34, 273.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23524/47780 [01:13<01:19, 306.50 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23477/47780 [01:13<01:06, 363.37 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22936/47780 [01:13<01:35, 259.96 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21745/47780 [01:13<01:30, 288.96 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21859/47780 [01:13<01:36, 269.91 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22186/47780 [01:13<01:15, 338.49 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21995/47780 [01:13<01:28, 291.54 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23558/47780 [01:14<01:21, 297.02 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22964/47780 [01:14<01:34, 262.76 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23514/47780 [01:14<01:09, 349.86 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21887/47780 [01:14<01:39, 259.25 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22222/47780 [01:14<01:15, 337.19 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21775/47780 [01:14<01:37, 267.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22025/47780 [01:14<01:27, 293.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23590/47780 [01:14<01:23, 291.24 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22994/47780 [01:14<01:30, 273.02 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23551/47780 [01:14<01:12, 334.80 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21918/47780 [01:14<01:36, 267.22 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22262/47780 [01:14<01:13, 347.25 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21805/47780 [01:14<01:34, 273.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22055/47780 [01:14<01:29, 288.26 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23023/47780 [01:14<01:30, 273.62 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23621/47780 [01:14<01:25, 281.34 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23585/47780 [01:14<01:13, 330.95 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21945/47780 [01:14<01:37, 265.19 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21835/47780 [01:14<01:32, 280.66 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22297/47780 [01:14<01:17, 329.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22084/47780 [01:14<01:36, 266.70 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23054/47780 [01:14<01:27, 281.78 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23656/47780 [01:14<01:21, 296.28 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21867/47780 [01:14<01:28, 291.18 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23619/47780 [01:14<01:14, 326.26 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21972/47780 [01:14<01:39, 260.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22331/47780 [01:14<01:18, 325.28 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23090/47780 [01:14<01:22, 300.88 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22111/47780 [01:14<01:40, 255.40 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23690/47780 [01:14<01:19, 304.83 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23652/47780 [01:14<01:16, 316.73 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21897/47780 [01:14<01:31, 281.39 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22005/47780 [01:14<01:37, 265.17 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22371/47780 [01:14<01:14, 338.95 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23132/47780 [01:14<01:13, 335.08 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22139/47780 [01:14<01:38, 259.95 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23722/47780 [01:14<01:19, 302.02 examples/s]Tokenizing train dataset (num_proc=32):   9%|▉         | 4320/47780 [01:14<04:06, 176.61 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21931/47780 [01:14<01:27, 294.69 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23684/47780 [01:14<01:17, 310.55 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22407/47780 [01:14<01:14, 340.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22040/47780 [01:14<01:32, 279.31 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22180/47780 [01:14<01:25, 298.00 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23753/47780 [01:14<01:20, 297.75 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23166/47780 [01:14<01:19, 311.24 examples/s]Tokenizing train dataset (num_proc=32):   9%|▉         | 4524/47780 [01:14<02:46, 259.03 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23718/47780 [01:14<01:15, 318.08 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21961/47780 [01:14<01:30, 286.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22072/47780 [01:14<01:29, 287.41 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22442/47780 [01:14<01:21, 311.04 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23792/47780 [01:14<01:15, 316.62 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23198/47780 [01:14<01:20, 306.72 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22211/47780 [01:14<01:34, 270.96 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23756/47780 [01:14<01:12, 332.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22101/47780 [01:14<01:35, 269.70 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21990/47780 [01:14<01:42, 250.51 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22474/47780 [01:14<01:24, 297.73 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23837/47780 [01:14<01:07, 354.00 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23235/47780 [01:14<01:16, 322.83 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22239/47780 [01:14<01:33, 273.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23791/47780 [01:14<01:12, 330.28 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22022/47780 [01:14<01:36, 266.20 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22129/47780 [01:14<01:39, 258.69 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22506/47780 [01:14<01:24, 300.19 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23879/47780 [01:15<01:05, 364.86 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22267/47780 [01:14<01:34, 269.37 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23828/47780 [01:15<01:10, 341.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23268/47780 [01:14<01:21, 299.12 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22156/47780 [01:15<01:40, 255.96 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22050/47780 [01:15<01:40, 255.97 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22537/47780 [01:15<01:27, 287.57 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23916/47780 [01:15<01:07, 354.10 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23299/47780 [01:15<01:25, 287.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22295/47780 [01:15<01:42, 247.44 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23863/47780 [01:15<01:20, 295.86 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22182/47780 [01:15<01:40, 254.52 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22080/47780 [01:15<01:37, 262.26 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23952/47780 [01:15<01:07, 355.61 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22567/47780 [01:15<01:30, 278.14 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22324/47780 [01:15<01:38, 258.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23329/47780 [01:15<01:26, 283.17 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22209/47780 [01:15<01:38, 258.79 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23894/47780 [01:15<01:22, 290.24 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22115/47780 [01:15<01:29, 286.08 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22602/47780 [01:15<01:25, 295.15 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23989/47780 [01:15<01:10, 338.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22353/47780 [01:15<01:39, 255.73 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23358/47780 [01:15<01:31, 267.82 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22242/47780 [01:15<01:31, 278.87 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22145/47780 [01:15<01:29, 286.28 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23924/47780 [01:15<01:29, 267.41 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22632/47780 [01:15<01:28, 283.87 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22383/47780 [01:15<01:35, 266.77 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24024/47780 [01:15<01:16, 308.90 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23386/47780 [01:15<01:31, 265.67 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22272/47780 [01:15<01:30, 282.00 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22175/47780 [01:15<01:29, 287.46 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23959/47780 [01:15<01:24, 282.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22670/47780 [01:15<01:21, 306.92 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23414/47780 [01:15<01:31, 266.47 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22411/47780 [01:15<01:40, 252.77 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22302/47780 [01:15<01:29, 283.69 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22206/47780 [01:15<01:28, 290.05 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24056/47780 [01:15<01:24, 279.21 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23995/47780 [01:15<01:19, 299.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22701/47780 [01:15<01:23, 300.66 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23445/47780 [01:15<01:27, 277.89 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22444/47780 [01:15<01:32, 273.15 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22331/47780 [01:15<01:30, 280.33 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24112/47780 [01:15<01:08, 346.83 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22237/47780 [01:15<01:30, 283.29 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24026/47780 [01:15<01:21, 290.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22732/47780 [01:15<01:22, 302.43 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22473/47780 [01:15<01:31, 277.71 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23475/47780 [01:15<01:27, 278.65 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22361/47780 [01:15<01:32, 275.53 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22268/47780 [01:15<01:27, 290.77 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24149/47780 [01:15<01:11, 328.63 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24061/47780 [01:15<01:17, 306.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22769/47780 [01:15<01:19, 315.89 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23511/47780 [01:15<01:22, 295.13 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22502/47780 [01:15<01:36, 263.09 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22389/47780 [01:15<01:32, 273.39 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22298/47780 [01:15<01:29, 283.77 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22801/47780 [01:15<01:20, 310.00 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24184/47780 [01:16<01:14, 317.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24093/47780 [01:16<01:21, 290.59 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23544/47780 [01:15<01:21, 298.37 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22535/47780 [01:16<01:30, 278.80 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22417/47780 [01:16<01:33, 272.13 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22338/47780 [01:16<01:20, 316.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22834/47780 [01:16<01:19, 315.63 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24217/47780 [01:16<01:18, 302.08 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24123/47780 [01:16<01:24, 281.09 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23575/47780 [01:16<01:21, 298.24 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22445/47780 [01:16<01:32, 274.37 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22565/47780 [01:16<01:28, 283.61 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22374/47780 [01:16<01:17, 328.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22868/47780 [01:16<01:17, 322.46 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24156/47780 [01:16<01:22, 285.05 examples/s]Tokenizing train dataset (num_proc=32):  10%|▉         | 4646/47780 [01:16<04:10, 171.87 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23606/47780 [01:16<01:21, 298.19 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22604/47780 [01:16<01:20, 313.31 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24248/47780 [01:16<01:23, 281.51 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22479/47780 [01:16<01:28, 287.01 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22413/47780 [01:16<01:13, 342.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22904/47780 [01:16<01:16, 326.11 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24193/47780 [01:16<01:18, 301.02 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23644/47780 [01:16<01:15, 321.48 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24279/47780 [01:16<01:21, 288.02 examples/s]Tokenizing train dataset (num_proc=32):  10%|█         | 4877/47780 [01:16<02:42, 264.46 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22636/47780 [01:16<01:22, 306.51 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22508/47780 [01:16<01:38, 255.47 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22448/47780 [01:16<01:23, 302.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22937/47780 [01:16<01:18, 315.56 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24224/47780 [01:16<01:18, 300.28 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23680/47780 [01:16<01:15, 318.12 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22667/47780 [01:16<01:24, 296.52 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24309/47780 [01:16<01:26, 270.90 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22543/47780 [01:16<01:30, 277.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22481/47780 [01:16<01:23, 303.53 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22969/47780 [01:16<01:22, 299.87 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24255/47780 [01:16<01:19, 296.65 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23715/47780 [01:16<01:13, 326.94 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24337/47780 [01:16<01:29, 261.77 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22697/47780 [01:16<01:34, 266.42 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22572/47780 [01:16<01:35, 263.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22513/47780 [01:16<01:22, 307.48 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23000/47780 [01:16<01:23, 295.97 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24289/47780 [01:16<01:18, 298.38 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23750/47780 [01:16<01:12, 330.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24366/47780 [01:16<01:28, 264.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22599/47780 [01:16<01:35, 262.70 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22725/47780 [01:16<01:38, 255.07 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22545/47780 [01:16<01:23, 301.40 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23030/47780 [01:16<01:24, 294.25 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24319/47780 [01:16<01:22, 283.38 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23784/47780 [01:16<01:16, 312.23 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24393/47780 [01:16<01:28, 265.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22751/47780 [01:16<01:37, 256.17 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22576/47780 [01:16<01:25, 293.97 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22639/47780 [01:16<01:28, 284.81 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23060/47780 [01:16<01:25, 288.89 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24355/47780 [01:16<01:17, 301.36 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23819/47780 [01:16<01:15, 318.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24428/47780 [01:16<01:22, 283.42 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22611/47780 [01:16<01:21, 309.56 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22671/47780 [01:16<01:26, 290.89 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23092/47780 [01:16<01:24, 291.62 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22777/47780 [01:16<01:44, 238.66 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24387/47780 [01:17<01:18, 296.42 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24457/47780 [01:17<01:22, 281.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23852/47780 [01:16<01:19, 302.25 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22702/47780 [01:17<01:26, 290.09 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23122/47780 [01:17<01:23, 293.72 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22806/47780 [01:17<01:39, 250.27 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22643/47780 [01:17<01:25, 292.57 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24486/47780 [01:17<01:23, 277.87 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23883/47780 [01:17<01:19, 299.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24417/47780 [01:17<01:24, 276.10 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22732/47780 [01:17<01:26, 289.65 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22832/47780 [01:17<01:39, 250.06 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23152/47780 [01:17<01:29, 276.15 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22673/47780 [01:17<01:30, 278.62 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23914/47780 [01:17<01:19, 299.44 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24517/47780 [01:17<01:22, 283.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24456/47780 [01:17<01:17, 300.29 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22762/47780 [01:17<01:26, 289.29 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22858/47780 [01:17<01:39, 250.25 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23180/47780 [01:17<01:29, 275.84 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22702/47780 [01:17<01:32, 270.50 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24550/47780 [01:17<01:20, 290.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24490/47780 [01:17<01:15, 307.86 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23945/47780 [01:17<01:24, 283.21 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22895/47780 [01:17<01:28, 280.87 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22792/47780 [01:17<01:27, 285.80 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23208/47780 [01:17<01:33, 263.90 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22736/47780 [01:17<01:28, 283.32 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24585/47780 [01:17<01:17, 300.46 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24522/47780 [01:17<01:17, 301.19 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23975/47780 [01:17<01:22, 287.50 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22927/47780 [01:17<01:27, 285.23 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22821/47780 [01:17<01:31, 271.36 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23237/47780 [01:17<01:32, 265.41 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22765/47780 [01:17<01:33, 267.04 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24617/47780 [01:17<01:16, 302.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24556/47780 [01:17<01:14, 311.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24011/47780 [01:17<01:17, 304.81 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22956/47780 [01:17<01:27, 283.65 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22849/47780 [01:17<01:34, 264.87 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23264/47780 [01:17<01:35, 257.90 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22800/47780 [01:17<01:27, 286.70 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24588/47780 [01:17<01:14, 310.30 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24043/47780 [01:17<01:16, 308.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24651/47780 [01:17<01:16, 302.98 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22985/47780 [01:17<01:27, 284.83 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22877/47780 [01:17<01:35, 260.59 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23295/47780 [01:17<01:29, 272.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24081/47780 [01:17<01:12, 326.05 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24685/47780 [01:17<01:15, 306.59 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22830/47780 [01:17<01:34, 263.94 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24620/47780 [01:17<01:20, 286.65 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23014/47780 [01:17<01:30, 274.24 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22908/47780 [01:17<01:31, 271.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23327/47780 [01:17<01:25, 285.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24114/47780 [01:17<01:13, 323.50 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24717/47780 [01:17<01:15, 306.94 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24653/47780 [01:17<01:18, 295.80 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22863/47780 [01:17<01:35, 261.20 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23043/47780 [01:17<01:30, 272.49 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22949/47780 [01:17<01:20, 310.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23359/47780 [01:17<01:23, 292.64 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24147/47780 [01:17<01:16, 307.44 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24683/47780 [01:18<01:19, 290.50 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24748/47780 [01:18<01:22, 278.74 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22892/47780 [01:17<01:33, 266.96 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23073/47780 [01:17<01:29, 277.21 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23389/47780 [01:18<01:27, 278.52 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22981/47780 [01:18<01:27, 283.79 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24719/47780 [01:18<01:14, 309.92 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22921/47780 [01:18<01:33, 267.20 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23105/47780 [01:18<01:27, 283.05 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24178/47780 [01:18<01:26, 271.41 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24777/47780 [01:18<01:28, 258.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23418/47780 [01:18<01:29, 271.99 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24761/47780 [01:18<01:08, 336.88 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23011/47780 [01:18<01:36, 255.37 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23134/47780 [01:18<01:26, 284.74 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22952/47780 [01:18<01:30, 273.19 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24211/47780 [01:18<01:23, 283.79 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23449/47780 [01:18<01:26, 279.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24804/47780 [01:18<01:34, 242.93 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24801/47780 [01:18<01:05, 351.62 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23038/47780 [01:18<01:37, 253.61 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23166/47780 [01:18<01:24, 291.70 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22985/47780 [01:18<01:27, 282.64 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24243/47780 [01:18<01:21, 290.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24833/47780 [01:18<01:30, 254.49 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23478/47780 [01:18<01:31, 264.97 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24837/47780 [01:18<01:06, 346.05 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23064/47780 [01:18<01:36, 254.99 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23196/47780 [01:18<01:24, 290.79 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23019/47780 [01:18<01:22, 298.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24274/47780 [01:18<01:19, 295.87 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24865/47780 [01:18<01:26, 263.48 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23505/47780 [01:18<01:35, 255.10 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24872/47780 [01:18<01:06, 344.13 examples/s]Tokenizing train dataset (num_proc=32):  10%|█         | 4998/47780 [01:18<04:56, 144.07 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23090/47780 [01:18<01:37, 253.83 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23230/47780 [01:18<01:20, 304.97 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23055/47780 [01:18<01:18, 313.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24305/47780 [01:18<01:20, 290.05 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24898/47780 [01:18<01:23, 275.59 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24909/47780 [01:18<01:05, 350.69 examples/s]Tokenizing train dataset (num_proc=32):  11%|█         | 5094/47780 [01:18<04:05, 173.89 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23117/47780 [01:18<01:36, 255.53 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23531/47780 [01:18<01:40, 240.64 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23261/47780 [01:18<01:21, 299.55 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23087/47780 [01:18<01:19, 310.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24336/47780 [01:18<01:20, 292.28 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24926/47780 [01:18<01:22, 276.51 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23145/47780 [01:18<01:34, 260.61 examples/s]Tokenizing train dataset (num_proc=32):  11%|█▏        | 5433/47780 [01:18<02:07, 332.09 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23563/47780 [01:18<01:33, 259.17 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23297/47780 [01:18<01:19, 309.89 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23119/47780 [01:18<01:20, 306.20 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24367/47780 [01:18<01:19, 294.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24945/47780 [01:18<01:16, 299.69 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24964/47780 [01:18<01:15, 302.54 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23590/47780 [01:18<01:32, 261.49 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23332/47780 [01:18<01:17, 314.15 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23153/47780 [01:18<01:19, 309.24 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23172/47780 [01:18<01:44, 235.44 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24397/47780 [01:18<01:23, 278.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24986/47780 [01:18<01:10, 322.99 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24999/47780 [01:18<01:12, 316.05 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23624/47780 [01:18<01:25, 281.14 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23365/47780 [01:18<01:20, 304.67 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23217/47780 [01:18<01:24, 289.10 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24426/47780 [01:18<01:25, 273.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23184/47780 [01:18<01:25, 286.33 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25034/47780 [01:19<01:12, 314.79 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25020/47780 [01:19<01:13, 310.27 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23662/47780 [01:19<01:18, 305.93 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23247/47780 [01:19<01:24, 289.54 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23397/47780 [01:19<01:19, 305.57 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24454/47780 [01:19<01:24, 274.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23215/47780 [01:19<01:24, 289.78 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25066/47780 [01:19<01:13, 309.39 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25052/47780 [01:19<01:17, 294.15 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23695/47780 [01:19<01:17, 310.83 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23280/47780 [01:19<01:22, 297.46 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23428/47780 [01:19<01:21, 299.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23245/47780 [01:19<01:23, 292.61 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25104/47780 [01:19<01:09, 325.78 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24482/47780 [01:19<01:30, 256.59 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25083/47780 [01:19<01:18, 289.65 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23731/47780 [01:19<01:15, 319.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23313/47780 [01:19<01:20, 303.26 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23459/47780 [01:19<01:25, 283.65 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23275/47780 [01:19<01:26, 281.92 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24513/47780 [01:19<01:26, 268.41 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25137/47780 [01:19<01:11, 316.08 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25113/47780 [01:19<01:18, 289.21 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23764/47780 [01:19<01:18, 306.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23344/47780 [01:19<01:21, 298.34 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23306/47780 [01:19<01:24, 289.71 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23488/47780 [01:19<01:26, 282.30 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24543/47780 [01:19<01:23, 277.14 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25171/47780 [01:19<01:15, 299.17 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23798/47780 [01:19<01:19, 300.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23377/47780 [01:19<01:19, 307.15 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23517/47780 [01:19<01:25, 284.21 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23336/47780 [01:19<01:26, 283.03 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24576/47780 [01:19<01:21, 285.66 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25202/47780 [01:19<01:15, 298.80 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25143/47780 [01:19<01:43, 218.11 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23832/47780 [01:19<01:17, 308.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23408/47780 [01:19<01:21, 300.44 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23365/47780 [01:19<01:25, 284.92 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23552/47780 [01:19<01:23, 289.97 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24613/47780 [01:19<01:14, 309.49 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25235/47780 [01:19<01:13, 305.88 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25198/47780 [01:19<01:17, 293.15 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23863/47780 [01:19<01:20, 295.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23439/47780 [01:19<01:22, 293.43 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23395/47780 [01:19<01:25, 283.87 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23582/47780 [01:19<01:23, 289.60 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24647/47780 [01:19<01:15, 307.84 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25233/47780 [01:19<01:13, 306.85 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25267/47780 [01:19<01:18, 288.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23895/47780 [01:19<01:19, 298.99 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23483/47780 [01:19<01:14, 328.16 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23618/47780 [01:19<01:18, 306.14 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23424/47780 [01:19<01:30, 269.14 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24679/47780 [01:19<01:16, 303.68 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25267/47780 [01:19<01:17, 291.61 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25297/47780 [01:19<01:19, 282.00 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23926/47780 [01:19<01:21, 292.25 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23516/47780 [01:19<01:14, 324.99 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23649/47780 [01:19<01:22, 293.76 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23452/47780 [01:19<01:36, 252.45 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24710/47780 [01:19<01:24, 273.95 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25302/47780 [01:20<01:13, 306.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25331/47780 [01:20<01:16, 292.01 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23963/47780 [01:20<01:16, 310.56 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23554/47780 [01:20<01:11, 336.85 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23686/47780 [01:20<01:16, 315.19 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23478/47780 [01:20<01:37, 248.88 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24755/47780 [01:20<01:13, 315.34 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25335/47780 [01:20<01:12, 308.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25361/47780 [01:20<01:17, 290.61 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23995/47780 [01:20<01:21, 293.08 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23588/47780 [01:20<01:16, 315.99 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23725/47780 [01:20<01:12, 332.79 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24788/47780 [01:20<01:12, 318.74 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23504/47780 [01:20<01:45, 229.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25369/47780 [01:20<01:13, 304.42 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25392/47780 [01:20<01:18, 283.67 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24025/47780 [01:20<01:22, 288.73 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23621/47780 [01:20<01:16, 315.63 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23759/47780 [01:20<01:15, 316.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24824/47780 [01:20<01:09, 328.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25404/47780 [01:20<01:11, 313.70 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25423/47780 [01:20<01:17, 287.85 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23529/47780 [01:20<01:47, 225.50 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24055/47780 [01:20<01:24, 279.57 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23795/47780 [01:20<01:12, 328.78 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23653/47780 [01:20<01:21, 297.45 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24863/47780 [01:20<01:07, 340.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25444/47780 [01:20<01:06, 334.04 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25452/47780 [01:20<01:18, 285.04 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23559/47780 [01:20<01:39, 242.57 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23684/47780 [01:20<01:22, 291.32 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24084/47780 [01:20<01:30, 261.96 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23829/47780 [01:20<01:17, 309.91 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24898/47780 [01:20<01:10, 324.92 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25479/47780 [01:20<01:05, 337.95 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23585/47780 [01:20<01:38, 244.70 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25481/47780 [01:20<01:22, 271.26 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23714/47780 [01:20<01:23, 287.15 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24115/47780 [01:20<01:26, 272.10 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23862/47780 [01:20<01:18, 302.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24940/47780 [01:20<01:05, 347.59 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23612/47780 [01:20<01:37, 247.82 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25516/47780 [01:20<01:15, 293.05 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25514/47780 [01:20<01:10, 316.50 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23745/47780 [01:20<01:24, 284.20 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24145/47780 [01:20<01:26, 273.53 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23893/47780 [01:20<01:19, 301.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24979/47780 [01:20<01:04, 351.73 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23640/47780 [01:20<01:34, 255.19 examples/s]Tokenizing train dataset (num_proc=32):  12%|█▏        | 5589/47780 [01:20<03:52, 181.76 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25546/47780 [01:20<01:19, 278.84 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25548/47780 [01:20<01:12, 305.60 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23781/47780 [01:20<01:19, 301.94 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24175/47780 [01:20<01:25, 275.00 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23924/47780 [01:20<01:21, 293.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25020/47780 [01:20<01:01, 367.97 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23667/47780 [01:20<01:35, 253.56 examples/s]Tokenizing train dataset (num_proc=32):  12%|█▏        | 5929/47780 [01:20<02:15, 309.59 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25575/47780 [01:20<01:20, 276.17 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25580/47780 [01:20<01:15, 292.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24218/47780 [01:20<01:14, 314.20 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25058/47780 [01:20<01:04, 351.88 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23954/47780 [01:20<01:26, 275.69 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23812/47780 [01:20<01:28, 270.67 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23699/47780 [01:20<01:29, 269.48 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25611/47780 [01:21<01:15, 292.22 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25603/47780 [01:21<01:27, 253.92 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24250/47780 [01:21<01:16, 309.55 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23843/47780 [01:21<01:26, 278.07 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23727/47780 [01:21<01:29, 269.16 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23985/47780 [01:21<01:26, 274.71 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25094/47780 [01:21<01:08, 331.57 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25641/47780 [01:21<01:19, 278.97 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25636/47780 [01:21<01:23, 266.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24283/47780 [01:21<01:16, 308.43 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23764/47780 [01:21<01:22, 291.84 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23872/47780 [01:21<01:26, 275.41 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24013/47780 [01:21<01:31, 258.99 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25128/47780 [01:21<01:13, 309.95 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25664/47780 [01:21<01:24, 261.52 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24314/47780 [01:21<01:16, 305.02 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23905/47780 [01:21<01:22, 290.40 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25670/47780 [01:21<01:30, 245.18 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23794/47780 [01:21<01:23, 286.24 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24045/47780 [01:21<01:27, 272.61 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25163/47780 [01:21<01:11, 315.63 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24346/47780 [01:21<01:17, 302.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25693/47780 [01:21<01:25, 257.98 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23942/47780 [01:21<01:17, 309.33 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23843/47780 [01:21<01:09, 342.05 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25696/47780 [01:21<01:33, 236.95 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24080/47780 [01:21<01:22, 287.54 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25204/47780 [01:21<01:07, 335.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24378/47780 [01:21<01:17, 300.68 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25727/47780 [01:21<01:21, 271.44 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23974/47780 [01:21<01:16, 312.05 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23878/47780 [01:21<01:11, 332.80 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25721/47780 [01:21<01:32, 237.80 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25238/47780 [01:21<01:08, 329.71 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24116/47780 [01:21<01:21, 291.47 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24411/47780 [01:21<01:19, 295.63 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24006/47780 [01:21<01:20, 294.25 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25755/47780 [01:21<01:28, 249.30 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25748/47780 [01:21<01:30, 243.77 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23914/47780 [01:21<01:14, 322.09 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24151/47780 [01:21<01:17, 304.17 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25272/47780 [01:21<01:11, 317.00 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24449/47780 [01:21<01:15, 308.88 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24036/47780 [01:21<01:21, 292.30 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25776/47780 [01:21<01:27, 251.00 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25781/47780 [01:21<01:29, 246.01 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23948/47780 [01:21<01:12, 326.75 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24186/47780 [01:21<01:15, 313.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25304/47780 [01:21<01:15, 299.03 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24487/47780 [01:21<01:12, 321.56 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25803/47780 [01:21<01:27, 250.64 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24066/47780 [01:21<01:27, 270.31 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25806/47780 [01:21<01:36, 228.71 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24218/47780 [01:21<01:16, 308.05 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23981/47780 [01:21<01:19, 300.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25338/47780 [01:21<01:12, 309.95 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24527/47780 [01:21<01:09, 332.40 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25830/47780 [01:21<01:27, 251.01 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24095/47780 [01:21<01:27, 269.70 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25835/47780 [01:21<01:30, 241.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24012/47780 [01:21<01:20, 296.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24249/47780 [01:21<01:23, 282.94 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25370/47780 [01:21<01:15, 296.36 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24566/47780 [01:22<01:07, 344.60 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25861/47780 [01:22<01:23, 261.09 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24127/47780 [01:22<01:24, 280.40 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25862/47780 [01:22<01:28, 246.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24042/47780 [01:22<01:20, 294.50 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24281/47780 [01:22<01:20, 290.12 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25409/47780 [01:22<01:11, 312.00 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24601/47780 [01:22<01:10, 327.69 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25888/47780 [01:22<01:23, 263.42 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25888/47780 [01:22<01:27, 250.42 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24156/47780 [01:22<01:26, 274.04 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24072/47780 [01:22<01:23, 283.28 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24311/47780 [01:22<01:23, 282.18 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25441/47780 [01:22<01:11, 310.56 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24634/47780 [01:22<01:12, 319.90 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25923/47780 [01:22<01:19, 275.47 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25915/47780 [01:22<01:28, 248.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24185/47780 [01:22<01:26, 273.77 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24102/47780 [01:22<01:23, 284.76 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24340/47780 [01:22<01:24, 276.50 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25473/47780 [01:22<01:14, 300.16 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24667/47780 [01:22<01:12, 316.84 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25957/47780 [01:22<01:14, 293.75 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25941/47780 [01:22<01:27, 251.00 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24220/47780 [01:22<01:22, 287.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24135/47780 [01:22<01:19, 297.22 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24368/47780 [01:22<01:29, 262.52 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25504/47780 [01:22<01:16, 293.08 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24699/47780 [01:22<01:14, 310.87 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25992/47780 [01:22<01:11, 306.67 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25967/47780 [01:22<01:30, 240.63 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24249/47780 [01:22<01:22, 284.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24165/47780 [01:22<01:20, 292.54 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24408/47780 [01:22<01:19, 293.94 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25534/47780 [01:22<01:22, 268.46 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24731/47780 [01:22<01:16, 303.09 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24282/47780 [01:22<01:18, 297.45 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26023/47780 [01:22<01:14, 290.46 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25993/47780 [01:22<01:29, 243.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24196/47780 [01:22<01:19, 296.54 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24450/47780 [01:22<01:13, 318.22 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25572/47780 [01:22<01:14, 297.82 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24315/47780 [01:22<01:17, 303.41 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26025/47780 [01:22<01:23, 261.98 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26054/47780 [01:22<01:15, 286.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24762/47780 [01:22<01:20, 285.83 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24226/47780 [01:22<01:21, 287.31 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24484/47780 [01:22<01:11, 324.06 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26052/47780 [01:22<01:23, 261.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24794/47780 [01:22<01:17, 295.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26084/47780 [01:22<01:15, 287.15 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24259/47780 [01:22<01:19, 296.47 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25603/47780 [01:22<01:21, 271.49 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24346/47780 [01:22<01:24, 277.23 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24517/47780 [01:22<01:20, 289.61 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26084/47780 [01:22<01:18, 278.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26118/47780 [01:22<01:11, 302.07 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25631/47780 [01:22<01:21, 271.83 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24289/47780 [01:22<01:21, 287.59 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24824/47780 [01:22<01:25, 268.94 examples/s]Tokenizing train dataset (num_proc=32):  13%|█▎        | 6108/47780 [01:22<03:41, 188.43 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24375/47780 [01:22<01:29, 262.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24547/47780 [01:22<01:21, 283.40 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26112/47780 [01:23<01:22, 262.94 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25664/47780 [01:22<01:18, 283.28 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26149/47780 [01:23<01:16, 281.63 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24852/47780 [01:23<01:25, 269.62 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24318/47780 [01:23<01:27, 269.52 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24403/47780 [01:23<01:29, 261.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6503/47780 [01:23<02:09, 319.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24576/47780 [01:23<01:22, 282.38 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26149/47780 [01:23<01:13, 293.07 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25695/47780 [01:23<01:16, 287.52 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26189/47780 [01:23<01:08, 314.07 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24891/47780 [01:23<01:16, 299.13 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24347/47780 [01:23<01:26, 269.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24433/47780 [01:23<01:27, 266.49 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24605/47780 [01:23<01:23, 278.32 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26185/47780 [01:23<01:09, 309.99 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26222/47780 [01:23<01:08, 315.34 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24935/47780 [01:23<01:08, 334.77 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25725/47780 [01:23<01:20, 272.81 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24375/47780 [01:23<01:28, 264.04 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24461/47780 [01:23<01:27, 267.25 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24634/47780 [01:23<01:23, 277.57 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26257/47780 [01:23<01:06, 321.38 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26217/47780 [01:23<01:13, 295.04 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24971/47780 [01:23<01:06, 341.89 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25760/47780 [01:23<01:14, 293.78 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24493/47780 [01:23<01:22, 282.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24420/47780 [01:23<01:17, 301.66 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24665/47780 [01:23<01:20, 285.88 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26247/47780 [01:23<01:12, 296.40 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25790/47780 [01:23<01:16, 285.87 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25006/47780 [01:23<01:09, 329.08 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26290/47780 [01:23<01:13, 292.24 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24522/47780 [01:23<01:25, 271.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24452/47780 [01:23<01:17, 300.23 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24696/47780 [01:23<01:20, 288.03 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26277/47780 [01:23<01:15, 284.39 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25823/47780 [01:23<01:13, 297.87 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25044/47780 [01:23<01:06, 339.73 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26320/47780 [01:23<01:14, 286.26 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24484/47780 [01:23<01:17, 302.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24550/47780 [01:23<01:28, 262.43 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24729/47780 [01:23<01:16, 300.02 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26309/47780 [01:23<01:13, 291.20 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25854/47780 [01:23<01:14, 294.89 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26350/47780 [01:23<01:13, 289.97 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25079/47780 [01:23<01:10, 323.83 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24577/47780 [01:23<01:28, 261.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24515/47780 [01:23<01:22, 282.21 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24764/47780 [01:23<01:14, 310.98 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26339/47780 [01:23<01:13, 293.30 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25887/47780 [01:23<01:12, 301.51 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25112/47780 [01:23<01:11, 318.22 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26380/47780 [01:23<01:18, 274.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24604/47780 [01:23<01:32, 249.89 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24796/47780 [01:23<01:15, 303.09 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24544/47780 [01:23<01:26, 269.71 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26372/47780 [01:23<01:12, 296.91 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25919/47780 [01:23<01:11, 306.77 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26414/47780 [01:23<01:14, 286.33 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25145/47780 [01:23<01:17, 292.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24635/47780 [01:23<01:28, 260.52 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24831/47780 [01:23<01:13, 312.69 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24572/47780 [01:23<01:27, 263.96 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26405/47780 [01:24<01:11, 299.93 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25952/47780 [01:23<01:10, 308.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26444/47780 [01:24<01:15, 283.68 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25177/47780 [01:24<01:15, 299.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24662/47780 [01:24<01:29, 257.45 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24874/47780 [01:24<01:07, 338.84 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24603/47780 [01:24<01:24, 273.50 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26436/47780 [01:24<01:10, 300.90 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25983/47780 [01:24<01:17, 280.81 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26476/47780 [01:24<01:12, 293.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25208/47780 [01:24<01:15, 299.42 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24691/47780 [01:24<01:27, 263.71 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24912/47780 [01:24<01:05, 346.73 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24633/47780 [01:24<01:23, 276.79 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26012/47780 [01:24<01:16, 283.04 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26467/47780 [01:24<01:20, 265.51 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26506/47780 [01:24<01:17, 276.28 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24718/47780 [01:24<01:29, 256.84 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25240/47780 [01:24<01:19, 282.74 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24661/47780 [01:24<01:26, 266.22 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24947/47780 [01:24<01:11, 317.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26496/47780 [01:24<01:19, 269.06 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26041/47780 [01:24<01:23, 259.41 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26544/47780 [01:24<01:11, 298.78 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24747/47780 [01:24<01:27, 263.23 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25278/47780 [01:24<01:13, 306.03 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24699/47780 [01:24<01:19, 291.74 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24980/47780 [01:24<01:18, 288.62 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26530/47780 [01:24<01:14, 285.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26070/47780 [01:24<01:21, 267.51 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24778/47780 [01:24<01:24, 273.41 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25310/47780 [01:24<01:13, 306.54 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26575/47780 [01:24<01:12, 292.20 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24729/47780 [01:24<01:18, 292.16 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25014/47780 [01:24<01:16, 297.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26098/47780 [01:24<01:20, 270.89 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26562/47780 [01:24<01:16, 276.31 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24809/47780 [01:24<01:20, 283.86 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26605/47780 [01:24<01:13, 287.93 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24759/47780 [01:24<01:19, 289.77 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25341/47780 [01:24<01:22, 271.00 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26132/47780 [01:24<01:15, 287.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25045/47780 [01:24<01:18, 289.31 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26593/47780 [01:24<01:18, 270.99 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26634/47780 [01:24<01:16, 276.67 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24849/47780 [01:24<01:18, 290.65 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24794/47780 [01:24<01:17, 296.81 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25384/47780 [01:24<01:11, 312.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26162/47780 [01:24<01:16, 284.19 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26665/47780 [01:24<01:13, 285.61 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24889/47780 [01:24<01:11, 320.74 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26621/47780 [01:24<01:20, 261.98 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25078/47780 [01:24<01:24, 269.76 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24830/47780 [01:24<01:12, 314.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25417/47780 [01:24<01:17, 288.89 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26191/47780 [01:24<01:16, 282.69 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25107/47780 [01:24<01:23, 272.60 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26648/47780 [01:24<01:21, 258.69 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26694/47780 [01:24<01:16, 274.20 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24869/47780 [01:24<01:08, 332.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24922/47780 [01:24<01:16, 299.05 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26228/47780 [01:24<01:10, 304.22 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25447/47780 [01:24<01:21, 274.73 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26677/47780 [01:25<01:19, 267.10 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25135/47780 [01:24<01:24, 268.87 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26722/47780 [01:25<01:17, 272.87 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24905/47780 [01:24<01:07, 340.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24954/47780 [01:25<01:20, 283.77 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25476/47780 [01:25<01:22, 270.25 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26259/47780 [01:25<01:14, 288.75 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26706/47780 [01:25<01:17, 273.53 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26767/47780 [01:25<01:05, 322.89 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24940/47780 [01:25<01:06, 343.15 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25163/47780 [01:25<01:33, 242.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24983/47780 [01:25<01:20, 283.13 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25509/47780 [01:25<01:18, 282.97 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26289/47780 [01:25<01:15, 282.81 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26800/47780 [01:25<01:05, 321.21 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26734/47780 [01:25<01:19, 266.26 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24977/47780 [01:25<01:07, 335.47 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25196/47780 [01:25<01:25, 262.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25012/47780 [01:25<01:21, 277.95 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25543/47780 [01:25<01:16, 292.12 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26833/47780 [01:25<01:04, 323.56 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26765/47780 [01:25<01:16, 276.27 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6683/47780 [01:25<03:33, 192.32 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26318/47780 [01:25<01:20, 267.22 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25011/47780 [01:25<01:11, 320.64 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25223/47780 [01:25<01:27, 258.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25040/47780 [01:25<01:23, 272.60 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25576/47780 [01:25<01:15, 296.00 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26350/47780 [01:25<01:16, 281.26 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▍        | 6973/47780 [01:25<02:25, 280.71 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26793/47780 [01:25<01:18, 267.29 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26866/47780 [01:25<01:07, 309.52 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25254/47780 [01:25<01:25, 264.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25069/47780 [01:25<01:22, 274.52 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25044/47780 [01:25<01:17, 294.38 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25606/47780 [01:25<01:16, 290.25 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26380/47780 [01:25<01:14, 285.84 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26902/47780 [01:25<01:04, 321.87 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26821/47780 [01:25<01:18, 266.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25098/47780 [01:25<01:21, 278.78 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25284/47780 [01:25<01:23, 268.10 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25075/47780 [01:25<01:20, 280.93 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26418/47780 [01:25<01:10, 303.01 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25636/47780 [01:25<01:19, 277.14 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26854/47780 [01:25<01:13, 283.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26935/47780 [01:25<01:06, 313.07 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25126/47780 [01:25<01:24, 267.62 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25322/47780 [01:25<01:16, 292.75 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25111/47780 [01:25<01:17, 292.91 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26450/47780 [01:25<01:09, 307.57 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26886/47780 [01:25<01:11, 293.55 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26971/47780 [01:25<01:04, 320.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25668/47780 [01:25<01:20, 274.21 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25161/47780 [01:25<01:17, 290.18 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25352/47780 [01:25<01:19, 281.95 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25149/47780 [01:25<01:12, 312.55 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26483/47780 [01:25<01:09, 306.78 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26919/47780 [01:25<01:10, 297.37 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25696/47780 [01:25<01:21, 270.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27004/47780 [01:25<01:10, 294.25 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25191/47780 [01:25<01:21, 277.17 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25182/47780 [01:25<01:12, 310.51 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25381/47780 [01:25<01:24, 265.72 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26949/47780 [01:25<01:10, 294.13 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25725/47780 [01:25<01:20, 275.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26514/47780 [01:25<01:14, 285.03 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27053/47780 [01:26<01:00, 341.03 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25223/47780 [01:26<01:18, 286.77 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25411/47780 [01:25<01:22, 270.16 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25215/47780 [01:26<01:16, 296.22 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26983/47780 [01:26<01:08, 304.54 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25753/47780 [01:26<01:21, 270.94 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27088/47780 [01:26<01:01, 335.70 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26543/47780 [01:26<01:22, 258.24 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25253/47780 [01:26<01:17, 289.71 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25440/47780 [01:26<01:21, 272.57 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27014/47780 [01:26<01:08, 302.50 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25245/47780 [01:26<01:18, 287.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25781/47780 [01:26<01:21, 270.35 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27122/47780 [01:26<01:02, 329.98 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25284/47780 [01:26<01:18, 286.75 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26570/47780 [01:26<01:28, 238.79 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25468/47780 [01:26<01:24, 262.93 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27046/47780 [01:26<01:08, 304.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25274/47780 [01:26<01:20, 278.97 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25809/47780 [01:26<01:32, 237.99 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27156/47780 [01:26<01:08, 302.34 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25313/47780 [01:26<01:23, 268.23 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25503/47780 [01:26<01:18, 283.82 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27079/47780 [01:26<01:07, 308.07 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26595/47780 [01:26<01:32, 227.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25304/47780 [01:26<01:21, 277.47 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25835/47780 [01:26<01:30, 242.02 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27187/47780 [01:26<01:09, 297.81 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25347/47780 [01:26<01:19, 281.72 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25541/47780 [01:26<01:12, 307.51 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27121/47780 [01:26<01:02, 332.96 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26619/47780 [01:26<01:36, 219.26 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25332/47780 [01:26<01:23, 267.86 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25864/47780 [01:26<01:26, 254.12 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25376/47780 [01:26<01:21, 274.69 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27218/47780 [01:26<01:11, 287.05 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25574/47780 [01:26<01:13, 303.44 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27157/47780 [01:26<01:03, 325.84 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26643/47780 [01:26<01:34, 222.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25360/47780 [01:26<01:23, 268.65 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25897/47780 [01:26<01:20, 272.08 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25404/47780 [01:26<01:21, 276.13 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27247/47780 [01:26<01:12, 283.48 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25605/47780 [01:26<01:13, 301.79 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27190/47780 [01:26<01:03, 326.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26666/47780 [01:26<01:34, 222.35 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25387/47780 [01:26<01:30, 246.52 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25937/47780 [01:26<01:11, 304.92 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25437/47780 [01:26<01:17, 288.40 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25636/47780 [01:26<01:14, 297.57 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27276/47780 [01:26<01:15, 273.27 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27226/47780 [01:26<01:02, 328.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26693/47780 [01:26<01:31, 230.29 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25970/47780 [01:26<01:09, 312.06 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25419/47780 [01:26<01:26, 257.86 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25466/47780 [01:26<01:20, 275.69 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27311/47780 [01:26<01:10, 291.21 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25667/47780 [01:26<01:15, 291.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26720/47780 [01:26<01:27, 241.11 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27259/47780 [01:26<01:06, 307.97 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26002/47780 [01:26<01:11, 303.78 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25446/47780 [01:26<01:30, 247.80 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27341/47780 [01:27<01:09, 293.17 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25494/47780 [01:26<01:24, 265.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25700/47780 [01:26<01:14, 297.98 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27295/47780 [01:27<01:03, 322.18 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26745/47780 [01:26<01:33, 225.97 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26037/47780 [01:27<01:08, 316.97 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▍        | 7158/47780 [01:27<03:15, 207.85 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25474/47780 [01:27<01:29, 248.27 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25730/47780 [01:27<01:14, 295.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27375/47780 [01:27<01:08, 296.68 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25521/47780 [01:27<01:28, 252.58 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26784/47780 [01:27<01:17, 270.69 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27329/47780 [01:27<01:05, 313.34 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26070/47780 [01:27<01:10, 309.79 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▌        | 7334/47780 [01:27<02:33, 263.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25499/47780 [01:27<01:29, 248.17 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25547/47780 [01:27<01:28, 252.13 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25760/47780 [01:27<01:20, 271.94 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27361/47780 [01:27<01:07, 301.57 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26104/47780 [01:27<01:08, 318.40 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7596/47780 [01:27<01:45, 380.26 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27405/47780 [01:27<01:20, 252.21 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25528/47780 [01:27<01:26, 257.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26812/47780 [01:27<01:31, 229.58 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25584/47780 [01:27<01:18, 281.85 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25796/47780 [01:27<01:15, 289.93 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27400/47780 [01:27<01:03, 322.42 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26137/47780 [01:27<01:08, 317.81 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25562/47780 [01:27<01:19, 278.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26854/47780 [01:27<01:16, 274.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25617/47780 [01:27<01:15, 295.43 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25828/47780 [01:27<01:13, 297.69 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27433/47780 [01:27<01:04, 315.18 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27432/47780 [01:27<01:38, 206.30 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26169/47780 [01:27<01:09, 311.33 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25591/47780 [01:27<01:23, 265.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26884/47780 [01:27<01:20, 259.48 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25650/47780 [01:27<01:13, 299.36 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25863/47780 [01:27<01:10, 310.82 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27467/47780 [01:27<01:03, 320.99 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27487/47780 [01:27<01:11, 283.95 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26201/47780 [01:27<01:11, 303.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25618/47780 [01:27<01:26, 255.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25687/47780 [01:27<01:09, 318.68 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25897/47780 [01:27<01:08, 317.97 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26915/47780 [01:27<01:21, 255.21 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26233/47780 [01:27<01:09, 308.28 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27500/47780 [01:27<01:06, 305.88 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27520/47780 [01:27<01:13, 275.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25645/47780 [01:27<01:28, 251.53 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25930/47780 [01:27<01:08, 317.37 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25721/47780 [01:27<01:15, 291.10 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26942/47780 [01:27<01:24, 246.06 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27532/47780 [01:27<01:06, 303.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26265/47780 [01:27<01:14, 288.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27551/47780 [01:27<01:20, 252.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25671/47780 [01:27<01:32, 240.30 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25962/47780 [01:27<01:09, 314.82 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25757/47780 [01:27<01:12, 303.17 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26297/47780 [01:27<01:13, 293.93 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27563/47780 [01:27<01:11, 283.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27588/47780 [01:28<01:13, 275.25 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25701/47780 [01:27<01:27, 253.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26003/47780 [01:27<01:03, 342.32 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26968/47780 [01:27<01:40, 206.43 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25788/47780 [01:27<01:13, 298.46 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27594/47780 [01:28<01:09, 290.28 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26327/47780 [01:28<01:16, 279.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25730/47780 [01:28<01:24, 262.24 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27618/47780 [01:28<01:16, 263.41 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26039/47780 [01:28<01:06, 324.80 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26990/47780 [01:28<01:50, 188.37 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26360/47780 [01:28<01:13, 290.70 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27624/47780 [01:28<01:11, 279.97 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25819/47780 [01:28<01:23, 263.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25759/47780 [01:28<01:21, 269.77 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27649/47780 [01:28<01:13, 274.71 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26072/47780 [01:28<01:07, 322.65 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27044/47780 [01:28<01:17, 267.29 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25847/47780 [01:28<01:21, 267.86 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26393/47780 [01:28<01:12, 295.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27653/47780 [01:28<01:12, 276.57 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25787/47780 [01:28<01:23, 262.88 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27678/47780 [01:28<01:12, 275.78 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26105/47780 [01:28<01:09, 310.43 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27074/47780 [01:28<01:16, 269.45 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25875/47780 [01:28<01:21, 267.90 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26423/47780 [01:28<01:13, 289.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27681/47780 [01:28<01:14, 270.33 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25814/47780 [01:28<01:26, 253.79 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26140/47780 [01:28<01:08, 318.18 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27707/47780 [01:28<01:17, 259.87 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27106/47780 [01:28<01:14, 277.75 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25904/47780 [01:28<01:21, 268.42 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27709/47780 [01:28<01:13, 271.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26453/47780 [01:28<01:13, 289.17 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25846/47780 [01:28<01:22, 266.24 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26175/47780 [01:28<01:06, 323.51 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27734/47780 [01:28<01:17, 259.75 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27136/47780 [01:28<01:18, 263.37 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25937/47780 [01:28<01:18, 279.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26490/47780 [01:28<01:10, 302.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27737/47780 [01:28<01:16, 262.08 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26208/47780 [01:28<01:07, 321.66 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25873/47780 [01:28<01:28, 247.87 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27766/47780 [01:28<01:13, 273.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27165/47780 [01:28<01:19, 259.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26521/47780 [01:28<01:11, 298.03 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25966/47780 [01:28<01:22, 264.26 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27764/47780 [01:28<01:20, 247.31 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▋        | 7772/47780 [01:28<02:40, 249.13 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26245/47780 [01:28<01:04, 331.73 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27798/47780 [01:28<01:10, 283.41 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25899/47780 [01:28<01:28, 248.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27196/47780 [01:28<01:16, 268.85 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26552/47780 [01:28<01:14, 284.97 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25993/47780 [01:28<01:24, 257.70 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27792/47780 [01:28<01:20, 248.43 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8058/47780 [01:28<01:46, 372.20 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25927/47780 [01:28<01:25, 257.09 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26281/47780 [01:28<01:05, 328.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27834/47780 [01:28<01:06, 298.00 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26581/47780 [01:28<01:14, 285.86 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26027/47780 [01:28<01:18, 277.22 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27224/47780 [01:28<01:20, 253.79 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27819/47780 [01:28<01:18, 254.29 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25960/47780 [01:28<01:18, 277.53 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26314/47780 [01:28<01:09, 307.92 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27865/47780 [01:29<01:16, 259.90 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26057/47780 [01:29<01:17, 280.42 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27256/47780 [01:28<01:16, 268.65 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26610/47780 [01:29<01:18, 269.18 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25989/47780 [01:29<01:19, 274.94 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27845/47780 [01:29<01:24, 235.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26348/47780 [01:29<01:07, 316.75 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27892/47780 [01:29<01:18, 252.53 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26088/47780 [01:29<01:15, 285.49 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26638/47780 [01:29<01:19, 264.34 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26022/47780 [01:29<01:15, 287.46 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27884/47780 [01:29<01:12, 273.67 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27285/47780 [01:29<01:22, 249.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26380/47780 [01:29<01:11, 297.47 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27921/47780 [01:29<01:16, 259.96 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26118/47780 [01:29<01:15, 286.48 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26051/47780 [01:29<01:16, 284.33 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26665/47780 [01:29<01:23, 253.77 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27913/47780 [01:29<01:12, 272.23 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27312/47780 [01:29<01:24, 241.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26411/47780 [01:29<01:12, 294.45 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27953/47780 [01:29<01:12, 272.77 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26153/47780 [01:29<01:11, 301.20 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26088/47780 [01:29<01:10, 306.33 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26691/47780 [01:29<01:22, 255.41 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27943/47780 [01:29<01:10, 279.88 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27346/47780 [01:29<01:16, 265.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26448/47780 [01:29<01:08, 311.98 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27984/47780 [01:29<01:09, 283.03 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8229/47780 [01:29<01:55, 343.86 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26184/47780 [01:29<01:15, 286.04 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26722/47780 [01:29<01:18, 267.90 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27980/47780 [01:29<01:04, 305.28 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26119/47780 [01:29<01:12, 297.17 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27382/47780 [01:29<01:10, 288.06 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26486/47780 [01:29<01:07, 316.86 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28022/47780 [01:29<01:05, 300.27 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26222/47780 [01:29<01:10, 306.74 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26749/47780 [01:29<01:20, 262.33 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26149/47780 [01:29<01:15, 287.98 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27412/47780 [01:29<01:10, 289.53 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28011/47780 [01:29<01:12, 272.34 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26518/47780 [01:29<01:11, 297.84 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28053/47780 [01:29<01:08, 286.94 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26254/47780 [01:29<01:10, 307.13 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26782/47780 [01:29<01:15, 278.66 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26178/47780 [01:29<01:15, 285.35 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27445/47780 [01:29<01:08, 298.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28041/47780 [01:29<01:12, 274.00 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26552/47780 [01:29<01:09, 305.97 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28084/47780 [01:29<01:08, 286.67 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26290/47780 [01:29<01:07, 318.43 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27476/47780 [01:29<01:10, 289.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26810/47780 [01:29<01:24, 247.53 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26207/47780 [01:29<01:26, 249.54 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28070/47780 [01:29<01:20, 246.12 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26583/47780 [01:29<01:12, 290.76 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26322/47780 [01:29<01:08, 314.52 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28113/47780 [01:29<01:10, 278.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27506/47780 [01:29<01:13, 275.76 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26842/47780 [01:29<01:20, 261.59 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26233/47780 [01:29<01:30, 237.40 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8357/47780 [01:29<02:03, 318.97 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28116/47780 [01:29<01:06, 297.76 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26613/47780 [01:29<01:15, 282.01 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26354/47780 [01:29<01:09, 309.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28141/47780 [01:30<01:11, 275.27 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27539/47780 [01:29<01:10, 285.98 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26872/47780 [01:30<01:17, 269.03 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26258/47780 [01:30<01:30, 238.18 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26642/47780 [01:30<01:14, 283.34 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26387/47780 [01:30<01:07, 315.50 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28148/47780 [01:30<01:08, 287.92 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28169/47780 [01:30<01:14, 262.48 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27570/47780 [01:30<01:09, 289.09 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26900/47780 [01:30<01:18, 266.22 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26419/47780 [01:30<01:08, 312.96 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26682/47780 [01:30<01:08, 309.10 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28182/47780 [01:30<01:05, 299.04 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28200/47780 [01:30<01:12, 270.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26283/47780 [01:30<01:44, 205.99 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26927/47780 [01:30<01:18, 264.30 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27600/47780 [01:30<01:12, 279.59 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26453/47780 [01:30<01:07, 313.76 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26714/47780 [01:30<01:09, 305.27 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8455/47780 [01:30<02:06, 310.83 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28213/47780 [01:30<01:10, 277.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26320/47780 [01:30<01:27, 246.41 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27637/47780 [01:30<01:06, 304.75 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28228/47780 [01:30<01:20, 241.51 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26954/47780 [01:30<01:21, 254.30 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26486/47780 [01:30<01:07, 316.33 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26745/47780 [01:30<01:08, 306.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28259/47780 [01:30<00:59, 325.80 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26348/47780 [01:30<01:29, 239.18 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27672/47780 [01:30<01:04, 314.14 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28259/47780 [01:30<01:16, 255.25 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26983/47780 [01:30<01:20, 257.13 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26518/47780 [01:30<01:09, 305.30 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26776/47780 [01:30<01:11, 295.46 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28293/47780 [01:30<01:00, 322.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8532/47780 [01:30<02:04, 316.15 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27705/47780 [01:30<01:03, 314.98 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26380/47780 [01:30<01:24, 254.56 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28309/47780 [01:30<01:01, 317.33 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27012/47780 [01:30<01:19, 261.99 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26549/47780 [01:30<01:09, 306.00 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26806/47780 [01:30<01:13, 285.80 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28327/47780 [01:30<01:04, 300.78 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26410/47780 [01:30<01:20, 265.13 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27737/47780 [01:30<01:05, 305.49 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27040/47780 [01:30<01:18, 264.09 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28342/47780 [01:30<01:06, 293.89 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26583/47780 [01:30<01:09, 305.76 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26839/47780 [01:30<01:11, 294.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8596/47780 [01:30<02:03, 316.39 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26442/47780 [01:30<01:16, 280.08 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28359/47780 [01:30<01:04, 301.94 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27067/47780 [01:30<01:18, 262.77 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28373/47780 [01:30<01:05, 296.18 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27768/47780 [01:30<01:11, 278.65 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26615/47780 [01:30<01:09, 306.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26869/47780 [01:30<01:13, 283.36 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26471/47780 [01:30<01:16, 279.99 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28390/47780 [01:30<01:07, 289.05 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27096/47780 [01:30<01:18, 264.61 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28404/47780 [01:30<01:04, 299.23 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27800/47780 [01:30<01:09, 286.62 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8651/47780 [01:30<02:06, 308.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26903/47780 [01:30<01:09, 298.85 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26646/47780 [01:30<01:15, 280.97 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26503/47780 [01:30<01:13, 287.53 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28420/47780 [01:31<01:09, 279.98 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27123/47780 [01:30<01:22, 251.05 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28437/47780 [01:31<01:05, 295.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27837/47780 [01:30<01:05, 306.22 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26934/47780 [01:31<01:14, 280.07 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26537/47780 [01:31<01:11, 299.13 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26675/47780 [01:31<01:20, 261.11 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8698/47780 [01:31<02:09, 301.78 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28467/47780 [01:31<01:05, 293.31 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27161/47780 [01:31<01:13, 281.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27869/47780 [01:31<01:09, 284.53 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26964/47780 [01:31<01:14, 280.14 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26568/47780 [01:31<01:11, 297.82 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28449/47780 [01:31<01:23, 232.49 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26702/47780 [01:31<01:25, 246.08 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8747/47780 [01:31<01:59, 325.89 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28500/47780 [01:31<01:04, 296.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27190/47780 [01:31<01:17, 265.87 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27898/47780 [01:31<01:13, 268.82 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28486/47780 [01:31<01:12, 265.50 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26993/47780 [01:31<01:16, 273.04 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26598/47780 [01:31<01:15, 280.67 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26727/47780 [01:31<01:30, 231.87 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8790/47780 [01:31<01:58, 329.67 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27217/47780 [01:31<01:18, 260.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28530/47780 [01:31<01:09, 275.99 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28520/47780 [01:31<01:07, 284.51 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27926/47780 [01:31<01:15, 263.22 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27021/47780 [01:31<01:19, 260.56 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26627/47780 [01:31<01:18, 270.43 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26751/47780 [01:31<01:34, 222.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28560/47780 [01:31<01:09, 275.64 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27244/47780 [01:31<01:24, 242.39 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8831/47780 [01:31<02:03, 314.52 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27953/47780 [01:31<01:18, 253.82 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28551/47780 [01:31<01:10, 271.10 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26656/47780 [01:31<01:16, 275.33 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27048/47780 [01:31<01:21, 254.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26781/47780 [01:31<01:26, 242.61 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28588/47780 [01:31<01:10, 271.70 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27275/47780 [01:31<01:19, 257.54 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8869/47780 [01:31<02:02, 317.54 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27989/47780 [01:31<01:13, 271.03 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28580/47780 [01:31<01:12, 264.94 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26692/47780 [01:31<01:12, 291.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27074/47780 [01:31<01:23, 248.04 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26806/47780 [01:31<01:32, 227.39 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28616/47780 [01:31<01:14, 256.91 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27303/47780 [01:31<01:20, 255.39 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8905/47780 [01:31<02:00, 323.61 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28018/47780 [01:31<01:12, 273.26 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27100/47780 [01:31<01:23, 248.73 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26723/47780 [01:31<01:12, 289.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28608/47780 [01:31<01:15, 252.82 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26830/47780 [01:31<01:33, 223.38 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28647/47780 [01:31<01:11, 267.10 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27334/47780 [01:31<01:16, 267.36 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28050/47780 [01:31<01:10, 280.12 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8940/47780 [01:31<02:03, 315.41 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27130/47780 [01:31<01:18, 261.88 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26761/47780 [01:31<01:10, 298.09 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28634/47780 [01:31<01:18, 244.52 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26855/47780 [01:31<01:31, 228.32 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28674/47780 [01:31<01:12, 263.43 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27363/47780 [01:31<01:17, 262.02 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 8975/47780 [01:31<02:01, 320.59 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27168/47780 [01:31<01:11, 290.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26791/47780 [01:31<01:12, 289.17 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28079/47780 [01:31<01:21, 242.28 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26879/47780 [01:31<01:31, 228.95 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28659/47780 [01:32<01:26, 220.27 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27390/47780 [01:32<01:17, 261.45 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28701/47780 [01:32<01:16, 248.33 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9009/47780 [01:32<02:03, 314.33 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27207/47780 [01:32<01:05, 315.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26820/47780 [01:32<01:13, 286.10 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28127/47780 [01:32<01:05, 299.63 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26904/47780 [01:32<01:30, 229.56 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28688/47780 [01:32<01:21, 233.69 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28728/47780 [01:32<01:15, 251.73 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27417/47780 [01:32<01:19, 255.05 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9042/47780 [01:32<02:02, 316.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26850/47780 [01:32<01:13, 283.40 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28159/47780 [01:32<01:05, 301.06 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27239/47780 [01:32<01:14, 273.96 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26929/47780 [01:32<01:29, 233.96 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28713/47780 [01:32<01:21, 234.99 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27443/47780 [01:32<01:19, 255.08 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28754/47780 [01:32<01:15, 252.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9075/47780 [01:32<02:06, 306.50 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26879/47780 [01:32<01:15, 276.22 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28192/47780 [01:32<01:03, 306.51 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27281/47780 [01:32<01:07, 304.25 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28742/47780 [01:32<01:16, 249.69 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28785/47780 [01:32<01:11, 267.49 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27470/47780 [01:32<01:18, 258.01 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26953/47780 [01:32<01:39, 208.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9109/47780 [01:32<02:05, 308.95 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26909/47780 [01:32<01:18, 265.07 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28771/47780 [01:32<01:13, 259.23 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28224/47780 [01:32<01:08, 284.98 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27313/47780 [01:32<01:10, 289.85 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27499/47780 [01:32<01:15, 267.20 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26977/47780 [01:32<01:37, 214.39 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9147/47780 [01:32<01:58, 325.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28812/47780 [01:32<01:21, 233.35 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26936/47780 [01:32<01:20, 260.36 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28798/47780 [01:32<01:15, 252.67 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28262/47780 [01:32<01:04, 303.67 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27526/47780 [01:32<01:18, 258.98 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27349/47780 [01:32<01:09, 295.80 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27004/47780 [01:32<01:32, 224.93 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9180/47780 [01:32<02:00, 321.00 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28842/47780 [01:32<01:15, 249.29 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28830/47780 [01:32<01:10, 268.55 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27552/47780 [01:32<01:18, 259.15 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28294/47780 [01:32<01:06, 291.92 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26963/47780 [01:32<01:32, 225.97 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9216/47780 [01:32<01:56, 330.49 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27380/47780 [01:32<01:14, 273.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27027/47780 [01:32<01:35, 216.70 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28868/47780 [01:32<01:21, 231.13 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27579/47780 [01:32<01:17, 259.40 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28859/47780 [01:32<01:12, 262.70 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28328/47780 [01:32<01:05, 298.83 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27003/47780 [01:32<01:17, 267.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9256/47780 [01:32<01:52, 342.48 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27053/47780 [01:32<01:36, 214.49 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27408/47780 [01:32<01:21, 249.38 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28897/47780 [01:32<01:18, 241.07 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27605/47780 [01:32<01:18, 255.72 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28888/47780 [01:32<01:11, 264.41 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28359/47780 [01:32<01:05, 295.20 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27035/47780 [01:32<01:13, 281.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9293/47780 [01:32<01:50, 348.05 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27077/47780 [01:32<01:34, 219.00 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28923/47780 [01:32<01:18, 241.45 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27434/47780 [01:32<01:23, 244.27 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27635/47780 [01:32<01:15, 266.37 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28920/47780 [01:32<01:07, 279.99 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28397/47780 [01:32<01:01, 315.70 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9330/47780 [01:32<01:50, 348.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27065/47780 [01:32<01:16, 271.59 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27102/47780 [01:33<01:30, 227.33 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28948/47780 [01:33<01:17, 243.77 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27464/47780 [01:33<01:19, 256.52 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27665/47780 [01:33<01:12, 276.13 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28429/47780 [01:33<01:02, 309.52 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28949/47780 [01:33<01:13, 256.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27097/47780 [01:33<01:12, 284.63 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27131/47780 [01:33<01:25, 242.56 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9365/47780 [01:33<01:57, 325.73 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27491/47780 [01:33<01:19, 254.53 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28973/47780 [01:33<01:20, 234.75 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27697/47780 [01:33<01:09, 288.18 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28461/47780 [01:33<01:05, 295.86 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27157/47780 [01:33<01:24, 244.65 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27130/47780 [01:33<01:12, 284.32 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9401/47780 [01:33<01:55, 332.37 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28976/47780 [01:33<01:19, 236.95 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27528/47780 [01:33<01:11, 283.05 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28998/47780 [01:33<01:23, 224.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27728/47780 [01:33<01:11, 279.06 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28491/47780 [01:33<01:08, 281.53 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27161/47780 [01:33<01:10, 291.31 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27194/47780 [01:33<01:13, 280.36 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29002/47780 [01:33<01:17, 240.90 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27561/47780 [01:33<01:09, 292.57 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9435/47780 [01:33<02:07, 300.27 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27758/47780 [01:33<01:10, 285.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29031/47780 [01:33<01:18, 238.70 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28523/47780 [01:33<01:06, 291.70 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27191/47780 [01:33<01:12, 284.46 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29036/47780 [01:33<01:10, 267.14 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27223/47780 [01:33<01:17, 264.82 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9468/47780 [01:33<02:05, 305.30 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27591/47780 [01:33<01:14, 270.56 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27787/47780 [01:33<01:15, 264.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29055/47780 [01:33<01:21, 230.19 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28554/47780 [01:33<01:05, 294.55 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27256/47780 [01:33<01:13, 280.14 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27220/47780 [01:33<01:15, 272.92 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29064/47780 [01:33<01:13, 253.84 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9501/47780 [01:33<02:05, 304.98 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27620/47780 [01:33<01:13, 275.79 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29082/47780 [01:33<01:18, 238.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27814/47780 [01:33<01:17, 257.27 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28586/47780 [01:33<01:04, 297.62 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27285/47780 [01:33<01:12, 282.91 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27255/47780 [01:33<01:10, 291.83 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29097/47780 [01:33<01:09, 268.66 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9532/47780 [01:33<02:10, 293.66 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27648/47780 [01:33<01:15, 265.10 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29106/47780 [01:33<01:18, 238.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27846/47780 [01:33<01:13, 272.26 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28616/47780 [01:33<01:06, 288.46 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27285/47780 [01:33<01:15, 272.53 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29126/47780 [01:33<01:10, 265.44 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27314/47780 [01:33<01:18, 260.07 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9562/47780 [01:33<02:16, 279.96 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27675/47780 [01:33<01:17, 257.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27884/47780 [01:33<01:06, 299.25 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29130/47780 [01:33<01:24, 219.42 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28645/47780 [01:33<01:09, 276.35 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27322/47780 [01:33<01:09, 295.83 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29153/47780 [01:33<01:11, 261.30 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27345/47780 [01:33<01:16, 268.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27702/47780 [01:33<01:19, 252.22 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27916/47780 [01:33<01:08, 291.95 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29154/47780 [01:34<01:25, 217.86 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28673/47780 [01:33<01:13, 259.71 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29183/47780 [01:34<01:09, 266.09 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27355/47780 [01:33<01:09, 295.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27374/47780 [01:33<01:18, 260.32 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9592/47780 [01:34<03:00, 211.44 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29181/47780 [01:34<01:20, 229.69 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27946/47780 [01:34<01:11, 275.56 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27728/47780 [01:34<01:27, 229.83 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29210/47780 [01:34<01:09, 266.82 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27394/47780 [01:34<01:04, 314.84 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28700/47780 [01:34<01:17, 246.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27401/47780 [01:34<01:20, 254.53 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9630/47780 [01:34<02:39, 239.62 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29205/47780 [01:34<01:20, 232.10 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27764/47780 [01:34<01:15, 263.88 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27991/47780 [01:34<01:04, 309.02 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27430/47780 [01:34<01:02, 327.18 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28725/47780 [01:34<01:17, 247.35 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29237/47780 [01:34<01:12, 255.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27428/47780 [01:34<01:21, 250.54 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9664/47780 [01:34<02:26, 260.05 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29229/47780 [01:34<01:22, 224.61 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27793/47780 [01:34<01:17, 259.26 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28024/47780 [01:34<01:04, 308.27 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27463/47780 [01:34<01:02, 327.41 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28756/47780 [01:34<01:13, 259.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27455/47780 [01:34<01:20, 252.67 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29263/47780 [01:34<01:18, 236.19 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9695/47780 [01:34<02:22, 267.13 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29256/47780 [01:34<01:19, 231.92 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27822/47780 [01:34<01:16, 262.25 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28786/47780 [01:34<01:10, 270.22 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27496/47780 [01:34<01:03, 318.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28056/47780 [01:34<01:09, 284.83 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27481/47780 [01:34<01:22, 246.79 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29288/47780 [01:34<01:22, 223.12 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9730/47780 [01:34<02:11, 288.32 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27849/47780 [01:34<01:20, 247.64 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29280/47780 [01:34<01:22, 224.17 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27528/47780 [01:34<01:04, 312.99 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28085/47780 [01:34<01:10, 278.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28814/47780 [01:34<01:14, 253.11 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27506/47780 [01:34<01:27, 232.27 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29311/47780 [01:34<01:24, 218.44 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9765/47780 [01:34<02:08, 295.55 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29307/47780 [01:34<01:18, 234.30 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27875/47780 [01:34<01:20, 246.10 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28845/47780 [01:34<01:10, 268.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27560/47780 [01:34<01:08, 296.57 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28114/47780 [01:34<01:15, 260.04 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27535/47780 [01:34<01:23, 242.63 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29335/47780 [01:34<01:22, 223.83 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9800/47780 [01:34<02:02, 310.04 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29331/47780 [01:34<01:21, 227.69 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27908/47780 [01:34<01:17, 257.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28875/47780 [01:34<01:09, 271.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27590/47780 [01:34<01:09, 290.74 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29359/47780 [01:34<01:21, 227.41 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9832/47780 [01:34<02:02, 309.78 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28141/47780 [01:34<01:19, 246.55 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29354/47780 [01:34<01:23, 221.42 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27935/47780 [01:34<01:16, 258.35 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28905/47780 [01:34<01:07, 277.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27560/47780 [01:34<01:38, 204.26 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27620/47780 [01:34<01:10, 284.08 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9879/47780 [01:34<01:47, 351.14 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28176/47780 [01:34<01:12, 270.56 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29382/47780 [01:34<01:24, 216.48 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27962/47780 [01:34<01:15, 261.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29377/47780 [01:35<01:27, 209.40 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27649/47780 [01:34<01:12, 279.44 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28933/47780 [01:34<01:14, 253.86 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28208/47780 [01:34<01:10, 278.31 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27582/47780 [01:34<01:50, 182.84 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29410/47780 [01:35<01:19, 231.86 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9916/47780 [01:34<01:58, 320.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27990/47780 [01:35<01:15, 263.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29405/47780 [01:35<01:20, 228.34 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27683/47780 [01:35<01:09, 289.84 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28241/47780 [01:35<01:07, 289.33 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27622/47780 [01:35<01:26, 232.00 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29438/47780 [01:35<01:15, 242.65 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28959/47780 [01:35<01:20, 233.99 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9949/47780 [01:35<02:03, 306.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28022/47780 [01:35<01:12, 273.74 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27716/47780 [01:35<01:08, 294.55 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29429/47780 [01:35<01:26, 211.76 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28272/47780 [01:35<01:07, 287.84 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29464/47780 [01:35<01:15, 242.04 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27648/47780 [01:35<01:26, 232.04 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28983/47780 [01:35<01:21, 232.05 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9986/47780 [01:35<01:58, 319.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28055/47780 [01:35<01:08, 286.42 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29451/47780 [01:35<01:26, 212.98 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27749/47780 [01:35<01:07, 297.78 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28302/47780 [01:35<01:09, 279.25 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29489/47780 [01:35<01:17, 236.37 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27673/47780 [01:35<01:31, 220.70 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29007/47780 [01:35<01:25, 219.91 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10022/47780 [01:35<01:54, 330.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28084/47780 [01:35<01:11, 277.27 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29473/47780 [01:35<01:26, 212.67 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27786/47780 [01:35<01:03, 314.74 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29515/47780 [01:35<01:16, 239.87 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28331/47780 [01:35<01:12, 267.68 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29031/47780 [01:35<01:24, 222.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27698/47780 [01:35<01:31, 219.17 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28112/47780 [01:35<01:12, 269.51 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10056/47780 [01:35<02:07, 296.02 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29502/47780 [01:35<01:19, 229.24 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27818/47780 [01:35<01:06, 299.12 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29541/47780 [01:35<01:14, 243.28 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29060/47780 [01:35<01:19, 235.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28358/47780 [01:35<01:15, 256.85 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27721/47780 [01:35<01:35, 209.12 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10092/47780 [01:35<02:01, 310.00 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28140/47780 [01:35<01:17, 254.93 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27850/47780 [01:35<01:06, 301.69 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29526/47780 [01:35<01:28, 206.71 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29566/47780 [01:35<01:17, 234.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29087/47780 [01:35<01:18, 237.54 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28384/47780 [01:35<01:20, 242.26 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27744/47780 [01:35<01:33, 214.43 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10124/47780 [01:35<02:04, 303.27 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28166/47780 [01:35<01:19, 245.23 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27882/47780 [01:35<01:06, 300.10 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29554/47780 [01:35<01:21, 223.70 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29593/47780 [01:35<01:16, 236.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29112/47780 [01:35<01:17, 240.81 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27770/47780 [01:35<01:28, 226.59 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28425/47780 [01:35<01:08, 280.99 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10157/47780 [01:35<02:02, 307.16 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28191/47780 [01:35<01:20, 244.58 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27913/47780 [01:35<01:10, 283.71 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29577/47780 [01:35<01:22, 220.40 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29626/47780 [01:35<01:09, 259.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29137/47780 [01:35<01:16, 243.18 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27798/47780 [01:35<01:25, 233.67 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28454/47780 [01:35<01:10, 274.45 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28219/47780 [01:35<01:17, 251.48 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10189/47780 [01:35<02:11, 285.29 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27943/47780 [01:35<01:10, 281.69 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29602/47780 [01:36<01:20, 225.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29163/47780 [01:35<01:15, 245.63 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29654/47780 [01:36<01:15, 240.86 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28482/47780 [01:36<01:10, 274.88 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27829/47780 [01:36<01:20, 246.61 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28245/47780 [01:36<01:20, 241.35 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10219/47780 [01:36<02:14, 280.03 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29627/47780 [01:36<01:20, 225.41 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27972/47780 [01:36<01:12, 271.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29190/47780 [01:36<01:15, 246.99 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29683/47780 [01:36<01:11, 252.44 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27859/47780 [01:36<01:17, 255.88 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28515/47780 [01:36<01:10, 273.00 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28277/47780 [01:36<01:14, 262.12 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10248/47780 [01:36<02:12, 282.64 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29655/47780 [01:36<01:15, 238.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28001/47780 [01:36<01:12, 271.17 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29215/47780 [01:36<01:20, 229.87 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29709/47780 [01:36<01:13, 245.16 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27888/47780 [01:36<01:16, 259.61 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28543/47780 [01:36<01:10, 271.80 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10278/47780 [01:36<02:14, 278.45 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28304/47780 [01:36<01:18, 247.23 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29689/47780 [01:36<01:07, 266.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28029/47780 [01:36<01:13, 267.89 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29239/47780 [01:36<01:20, 229.20 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29734/47780 [01:36<01:13, 245.63 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27916/47780 [01:36<01:17, 255.94 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28571/47780 [01:36<01:14, 256.94 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10309/47780 [01:36<02:10, 287.21 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29720/47780 [01:36<01:05, 277.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28330/47780 [01:36<01:20, 241.17 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29277/47780 [01:36<01:09, 265.95 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29759/47780 [01:36<01:14, 242.50 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28056/47780 [01:36<01:26, 228.85 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28603/47780 [01:36<01:10, 271.36 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27943/47780 [01:36<01:22, 239.06 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10356/47780 [01:36<01:51, 335.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29749/47780 [01:36<01:06, 272.18 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28355/47780 [01:36<01:26, 225.41 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29790/47780 [01:36<01:08, 261.56 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29304/47780 [01:36<01:12, 255.58 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28638/47780 [01:36<01:06, 289.87 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28080/47780 [01:36<01:32, 213.13 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27968/47780 [01:36<01:26, 229.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10390/47780 [01:36<01:57, 317.87 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29777/47780 [01:36<01:10, 254.30 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28378/47780 [01:36<01:27, 222.12 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29818/47780 [01:36<01:08, 263.81 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29331/47780 [01:36<01:13, 252.06 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28669/47780 [01:36<01:04, 295.39 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27992/47780 [01:36<01:26, 227.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10423/47780 [01:36<01:58, 314.11 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29804/47780 [01:36<01:10, 253.66 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28401/47780 [01:36<01:26, 224.07 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28107/47780 [01:36<01:36, 202.98 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29849/47780 [01:36<01:06, 270.95 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29370/47780 [01:36<01:05, 283.16 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28699/47780 [01:36<01:04, 295.90 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28015/47780 [01:36<01:26, 227.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10461/47780 [01:36<01:53, 329.75 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29830/47780 [01:36<01:10, 255.28 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28426/47780 [01:36<01:25, 226.46 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29880/47780 [01:36<01:03, 280.16 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29399/47780 [01:36<01:05, 281.48 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28729/47780 [01:36<01:06, 284.97 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28128/47780 [01:36<01:51, 176.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10496/47780 [01:36<01:51, 335.41 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28038/47780 [01:36<01:30, 219.28 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28454/47780 [01:36<01:20, 241.48 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29856/47780 [01:36<01:11, 249.21 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29909/47780 [01:36<01:03, 281.25 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29428/47780 [01:36<01:04, 283.63 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28758/47780 [01:36<01:07, 283.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28255/47780 [01:36<00:45, 425.10 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28061/47780 [01:37<01:28, 222.17 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10530/47780 [01:37<01:59, 311.23 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28479/47780 [01:37<01:21, 235.80 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29883/47780 [01:37<01:12, 245.84 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29939/47780 [01:37<01:05, 274.42 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29461/47780 [01:37<01:02, 294.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28787/47780 [01:37<01:09, 275.22 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28091/47780 [01:37<01:21, 241.58 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28305/47780 [01:37<00:46, 414.62 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28512/47780 [01:37<01:14, 259.53 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29911/47780 [01:37<01:10, 254.51 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10562/47780 [01:37<02:08, 288.52 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29493/47780 [01:37<01:01, 298.32 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29969/47780 [01:37<01:05, 272.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28817/47780 [01:37<01:07, 279.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28116/47780 [01:37<01:21, 241.17 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29947/47780 [01:37<01:03, 282.48 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29532/47780 [01:37<00:57, 317.59 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29997/47780 [01:37<01:05, 271.49 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10596/47780 [01:37<02:06, 292.84 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28352/47780 [01:37<00:51, 378.93 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28539/47780 [01:37<01:24, 228.56 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28852/47780 [01:37<01:03, 296.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28150/47780 [01:37<01:12, 269.43 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29976/47780 [01:37<01:03, 280.97 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29566/47780 [01:37<00:56, 323.75 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10626/47780 [01:37<02:09, 286.12 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30025/47780 [01:37<01:07, 261.70 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28570/47780 [01:37<01:18, 244.83 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28886/47780 [01:37<01:02, 301.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28394/47780 [01:37<00:54, 358.72 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28178/47780 [01:37<01:18, 249.18 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30007/47780 [01:37<01:02, 283.17 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10656/47780 [01:37<02:08, 289.46 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29599/47780 [01:37<00:59, 307.87 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30052/47780 [01:37<01:07, 261.20 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28597/47780 [01:37<01:17, 248.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28921/47780 [01:37<01:01, 306.30 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28211/47780 [01:37<01:13, 265.81 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30036/47780 [01:37<01:02, 281.69 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28434/47780 [01:37<00:59, 325.17 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10686/47780 [01:37<02:06, 292.29 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29630/47780 [01:37<00:59, 305.11 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30081/47780 [01:37<01:07, 263.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28956/47780 [01:37<00:59, 317.55 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28623/47780 [01:37<01:21, 236.38 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28241/47780 [01:37<01:11, 272.40 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30065/47780 [01:37<01:06, 267.46 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30111/47780 [01:37<01:04, 273.66 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28470/47780 [01:37<01:01, 312.72 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29661/47780 [01:37<01:01, 296.32 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10716/47780 [01:37<02:13, 278.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28992/47780 [01:37<00:58, 322.26 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28648/47780 [01:37<01:19, 239.78 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28271/47780 [01:37<01:10, 277.12 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30092/47780 [01:37<01:08, 257.94 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10752/47780 [01:37<02:04, 297.34 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30139/47780 [01:37<01:06, 264.31 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29691/47780 [01:37<01:04, 280.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29029/47780 [01:37<00:56, 332.20 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28673/47780 [01:37<01:24, 225.29 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28503/47780 [01:37<01:11, 270.95 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28299/47780 [01:37<01:14, 259.82 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30124/47780 [01:37<01:06, 266.25 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30166/47780 [01:37<01:06, 265.18 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10782/47780 [01:37<02:08, 288.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29065/47780 [01:37<00:56, 331.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29720/47780 [01:37<01:06, 273.18 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28696/47780 [01:37<01:25, 223.96 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28541/47780 [01:37<01:05, 292.82 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28329/47780 [01:38<01:14, 262.34 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30154/47780 [01:38<01:04, 275.11 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30198/47780 [01:38<01:02, 280.83 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10812/47780 [01:37<02:07, 288.88 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29101/47780 [01:38<00:55, 337.11 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28724/47780 [01:38<01:19, 239.33 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29748/47780 [01:38<01:10, 255.51 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28360/47780 [01:38<01:11, 272.68 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30184/47780 [01:38<01:03, 276.45 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30229/47780 [01:38<01:02, 282.81 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28573/47780 [01:38<01:12, 265.74 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10846/47780 [01:38<02:04, 296.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29135/47780 [01:38<00:55, 337.09 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29776/47780 [01:38<01:09, 258.24 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28749/47780 [01:38<01:21, 234.40 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28389/47780 [01:38<01:11, 271.42 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30213/47780 [01:38<01:02, 279.19 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30264/47780 [01:38<00:58, 298.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10884/47780 [01:38<01:57, 313.09 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28602/47780 [01:38<01:17, 246.35 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28781/47780 [01:38<01:14, 255.89 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29805/47780 [01:38<01:08, 263.72 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29169/47780 [01:38<01:03, 291.15 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28417/47780 [01:38<01:11, 270.84 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30294/47780 [01:38<00:58, 298.78 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30241/47780 [01:38<01:05, 267.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10921/47780 [01:38<01:53, 325.61 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28814/47780 [01:38<01:08, 276.77 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28628/47780 [01:38<01:21, 236.28 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29832/47780 [01:38<01:11, 250.98 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29201/47780 [01:38<01:05, 283.60 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30327/47780 [01:38<00:57, 304.65 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28445/47780 [01:38<01:13, 263.66 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30268/47780 [01:38<01:07, 259.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10957/47780 [01:38<01:51, 331.67 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28656/47780 [01:38<01:17, 246.63 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28843/47780 [01:38<01:11, 265.49 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29858/47780 [01:38<01:12, 245.64 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28476/47780 [01:38<01:11, 271.30 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29231/47780 [01:38<01:07, 273.05 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30358/47780 [01:38<01:01, 282.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30295/47780 [01:38<01:08, 255.09 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10991/47780 [01:38<01:57, 312.22 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28682/47780 [01:38<01:18, 242.45 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29883/47780 [01:38<01:13, 244.35 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28870/47780 [01:38<01:14, 252.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28505/47780 [01:38<01:10, 273.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30388/47780 [01:38<01:01, 284.29 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29259/47780 [01:38<01:12, 253.98 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30321/47780 [01:38<01:13, 237.07 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11023/47780 [01:38<02:08, 285.88 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28707/47780 [01:38<01:19, 239.63 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28896/47780 [01:38<01:14, 254.36 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28536/47780 [01:38<01:08, 280.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29908/47780 [01:38<01:19, 223.47 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29287/47780 [01:38<01:11, 258.08 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30418/47780 [01:38<01:04, 270.85 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30347/47780 [01:38<01:13, 238.07 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28732/47780 [01:38<01:19, 239.77 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11070/47780 [01:38<01:53, 324.50 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28923/47780 [01:38<01:14, 253.30 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28570/47780 [01:38<01:04, 297.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29933/47780 [01:38<01:19, 223.43 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29317/47780 [01:38<01:09, 266.40 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30373/47780 [01:38<01:11, 244.08 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30446/47780 [01:38<01:06, 261.65 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28952/47780 [01:38<01:11, 263.67 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11103/47780 [01:38<01:54, 319.29 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28759/47780 [01:38<01:20, 237.76 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28600/47780 [01:38<01:07, 285.00 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29957/47780 [01:38<01:19, 225.40 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29345/47780 [01:38<01:08, 267.72 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30398/47780 [01:39<01:11, 242.89 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30473/47780 [01:39<01:06, 258.45 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11137/47780 [01:39<01:54, 321.27 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28981/47780 [01:39<01:11, 262.15 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28783/47780 [01:39<01:25, 221.23 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28630/47780 [01:39<01:06, 289.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29982/47780 [01:39<01:16, 231.94 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29375/47780 [01:39<01:06, 276.27 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30506/47780 [01:39<01:03, 272.25 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30423/47780 [01:39<01:14, 231.83 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29008/47780 [01:39<01:11, 261.35 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11170/47780 [01:39<01:57, 312.59 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28809/47780 [01:39<01:22, 228.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30006/47780 [01:39<01:15, 234.20 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29403/47780 [01:39<01:06, 275.09 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28660/47780 [01:39<01:09, 273.63 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30534/47780 [01:39<01:02, 274.41 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30452/47780 [01:39<01:11, 242.60 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29039/47780 [01:39<01:08, 275.20 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11215/47780 [01:39<01:47, 340.24 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30032/47780 [01:39<01:14, 239.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28838/47780 [01:39<01:18, 241.88 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28692/47780 [01:39<01:07, 283.46 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29431/47780 [01:39<01:07, 272.37 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30479/47780 [01:39<01:09, 247.47 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30562/47780 [01:39<01:07, 255.53 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11251/47780 [01:39<01:48, 338.21 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29067/47780 [01:39<01:12, 258.66 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28865/47780 [01:39<01:16, 248.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30057/47780 [01:39<01:15, 234.04 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28722/47780 [01:39<01:07, 281.69 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29459/47780 [01:39<01:11, 256.97 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30511/47780 [01:39<01:05, 262.10 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30593/47780 [01:39<01:06, 256.57 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11287/47780 [01:39<01:45, 344.28 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29099/47780 [01:39<01:08, 272.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30081/47780 [01:39<01:15, 235.32 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28891/47780 [01:39<01:22, 228.53 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28751/47780 [01:39<01:09, 274.15 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30538/47780 [01:39<01:05, 264.15 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11324/47780 [01:39<01:44, 347.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29485/47780 [01:39<01:23, 218.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30112/47780 [01:39<01:09, 253.13 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29128/47780 [01:39<01:12, 256.94 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28915/47780 [01:39<01:21, 231.59 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30619/47780 [01:39<01:14, 229.60 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28779/47780 [01:39<01:10, 270.32 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30570/47780 [01:39<01:02, 277.27 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11360/47780 [01:39<01:45, 346.61 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29525/47780 [01:39<01:09, 261.91 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30138/47780 [01:39<01:10, 250.35 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29155/47780 [01:39<01:14, 248.92 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30659/47780 [01:39<01:04, 265.64 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28939/47780 [01:39<01:24, 223.34 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28808/47780 [01:39<01:12, 260.82 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30598/47780 [01:39<01:02, 274.38 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29559/47780 [01:39<01:04, 282.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11400/47780 [01:39<01:43, 350.37 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30170/47780 [01:39<01:05, 267.74 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29181/47780 [01:39<01:15, 246.02 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30692/47780 [01:39<01:02, 273.97 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28835/47780 [01:39<01:13, 257.97 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30635/47780 [01:39<00:57, 299.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28962/47780 [01:39<01:30, 207.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11436/47780 [01:39<01:46, 341.51 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30197/47780 [01:39<01:08, 256.63 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29589/47780 [01:39<01:08, 264.14 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29206/47780 [01:39<01:18, 235.80 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28864/47780 [01:39<01:10, 266.88 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30720/47780 [01:39<01:05, 261.54 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28992/47780 [01:39<01:24, 223.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30666/47780 [01:40<01:00, 280.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11475/47780 [01:39<01:42, 354.28 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30223/47780 [01:39<01:09, 254.24 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29617/47780 [01:40<01:10, 257.43 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29237/47780 [01:40<01:12, 255.98 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28896/47780 [01:40<01:08, 275.74 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30747/47780 [01:40<01:06, 255.32 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29015/47780 [01:40<01:28, 213.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30695/47780 [01:40<01:03, 267.26 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30249/47780 [01:40<01:08, 255.84 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29644/47780 [01:40<01:09, 260.45 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11516/47780 [01:40<01:47, 336.63 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29263/47780 [01:40<01:12, 254.34 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28924/47780 [01:40<01:11, 265.00 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30773/47780 [01:40<01:07, 251.53 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29040/47780 [01:40<01:24, 222.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30722/47780 [01:40<01:05, 261.87 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29674/47780 [01:40<01:07, 270.01 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30275/47780 [01:40<01:10, 248.82 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11550/47780 [01:40<01:52, 323.37 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29289/47780 [01:40<01:13, 252.64 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30805/47780 [01:40<01:04, 261.61 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28951/47780 [01:40<01:16, 246.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29063/47780 [01:40<01:26, 215.99 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30752/47780 [01:40<01:05, 259.34 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29702/47780 [01:40<01:06, 271.36 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30308/47780 [01:40<01:04, 268.97 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11584/47780 [01:40<01:50, 327.63 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29318/47780 [01:40<01:11, 257.63 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30838/47780 [01:40<01:01, 277.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29088/47780 [01:40<01:24, 222.19 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28976/47780 [01:40<01:22, 228.04 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29730/47780 [01:40<01:07, 269.35 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30335/47780 [01:40<01:07, 257.48 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29345/47780 [01:40<01:10, 261.04 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11621/47780 [01:40<01:48, 332.27 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30779/47780 [01:40<01:12, 235.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30868/47780 [01:40<01:00, 277.43 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29111/47780 [01:40<01:24, 219.73 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29000/47780 [01:40<01:22, 228.73 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29761/47780 [01:40<01:05, 276.06 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30369/47780 [01:40<01:03, 274.43 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11655/47780 [01:40<01:48, 334.03 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30808/47780 [01:40<01:08, 247.27 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29372/47780 [01:40<01:18, 234.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30896/47780 [01:40<01:02, 268.91 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29036/47780 [01:40<01:11, 261.45 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29789/47780 [01:40<01:07, 267.68 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29134/47780 [01:40<01:33, 200.04 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30397/47780 [01:40<01:03, 272.44 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11691/47780 [01:40<01:48, 333.39 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29413/47780 [01:40<01:07, 272.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30923/47780 [01:40<01:04, 261.19 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30834/47780 [01:40<01:17, 220.00 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29075/47780 [01:40<01:03, 293.73 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29169/47780 [01:40<01:18, 238.34 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29816/47780 [01:40<01:08, 262.56 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11726/47780 [01:40<01:50, 327.21 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30425/47780 [01:40<01:12, 239.58 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30951/47780 [01:40<01:03, 263.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30859/47780 [01:40<01:15, 225.31 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29195/47780 [01:40<01:16, 243.00 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29441/47780 [01:40<01:16, 240.67 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29843/47780 [01:40<01:09, 259.17 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29106/47780 [01:40<01:08, 271.52 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30455/47780 [01:40<01:07, 255.38 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30884/47780 [01:40<01:13, 229.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30986/47780 [01:40<00:59, 284.01 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11759/47780 [01:40<02:11, 273.02 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29494/47780 [01:40<00:58, 313.90 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29869/47780 [01:40<01:09, 259.23 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29220/47780 [01:40<01:19, 234.43 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29137/47780 [01:40<01:07, 275.28 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30488/47780 [01:40<01:04, 269.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30910/47780 [01:41<01:11, 235.54 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11799/47780 [01:41<01:59, 301.80 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31015/47780 [01:41<01:04, 261.89 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29897/47780 [01:41<01:08, 259.17 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29249/47780 [01:41<01:14, 247.54 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29166/47780 [01:41<01:06, 278.52 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29528/47780 [01:41<01:00, 302.61 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30516/47780 [01:41<01:04, 266.90 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30936/47780 [01:41<01:10, 240.41 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11831/47780 [01:41<01:59, 300.64 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29926/47780 [01:41<01:06, 267.78 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31043/47780 [01:41<01:07, 248.82 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29564/47780 [01:41<00:57, 316.59 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29195/47780 [01:41<01:08, 273.26 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29275/47780 [01:41<01:19, 232.06 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30544/47780 [01:41<01:06, 258.62 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30963/47780 [01:41<01:11, 234.32 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29953/47780 [01:41<01:07, 265.43 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11863/47780 [01:41<02:08, 278.52 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29224/47780 [01:41<01:08, 271.91 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29301/47780 [01:41<01:17, 239.58 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29597/47780 [01:41<01:01, 297.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31069/47780 [01:41<01:11, 233.50 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30990/47780 [01:41<01:09, 241.51 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29983/47780 [01:41<01:05, 272.63 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30571/47780 [01:41<01:15, 227.14 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29253/47780 [01:41<01:07, 273.98 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11892/47780 [01:41<02:14, 267.61 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31093/47780 [01:41<01:12, 230.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29326/47780 [01:41<01:18, 234.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29628/47780 [01:41<01:04, 279.97 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31021/47780 [01:41<01:05, 257.79 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30595/47780 [01:41<01:16, 223.55 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29286/47780 [01:41<01:05, 280.30 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30016/47780 [01:41<01:07, 264.60 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31118/47780 [01:41<01:10, 235.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29661/47780 [01:41<01:01, 292.89 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29350/47780 [01:41<01:24, 219.24 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11920/47780 [01:41<02:26, 245.38 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31049/47780 [01:41<01:04, 259.53 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30638/47780 [01:41<01:02, 274.04 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31142/47780 [01:41<01:11, 234.21 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30051/47780 [01:41<01:04, 276.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29315/47780 [01:41<01:08, 270.52 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11958/47780 [01:41<02:09, 276.36 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29373/47780 [01:41<01:24, 217.02 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31080/47780 [01:41<01:01, 269.42 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29692/47780 [01:41<01:06, 273.65 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31173/47780 [01:41<01:05, 252.90 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29345/47780 [01:41<01:06, 275.99 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30084/47780 [01:41<01:01, 287.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30667/47780 [01:41<01:06, 259.26 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11990/47780 [01:41<02:04, 286.53 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29397/47780 [01:41<01:22, 222.01 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31108/47780 [01:41<01:04, 260.02 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29721/47780 [01:41<01:09, 261.71 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29373/47780 [01:41<01:06, 276.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31199/47780 [01:41<01:09, 238.72 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30695/47780 [01:41<01:07, 252.88 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30113/47780 [01:41<01:06, 267.21 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29421/47780 [01:41<01:22, 223.50 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12023/47780 [01:41<02:04, 287.30 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29758/47780 [01:41<01:04, 281.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31135/47780 [01:41<01:07, 246.65 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31232/47780 [01:42<01:04, 258.17 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30723/47780 [01:41<01:06, 255.82 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30150/47780 [01:41<01:00, 292.77 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12056/47780 [01:41<02:00, 295.67 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29401/47780 [01:41<01:14, 246.75 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29464/47780 [01:41<01:09, 264.24 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31162/47780 [01:42<01:07, 247.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29788/47780 [01:42<01:06, 271.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31261/47780 [01:42<01:01, 266.98 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30749/47780 [01:42<01:06, 254.23 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29438/47780 [01:42<01:05, 279.57 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29498/47780 [01:42<01:04, 284.85 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30181/47780 [01:42<01:03, 277.73 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12087/47780 [01:42<02:05, 283.76 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31191/47780 [01:42<01:05, 252.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29816/47780 [01:42<01:06, 269.95 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31294/47780 [01:42<00:59, 278.50 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29467/47780 [01:42<01:07, 271.61 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30212/47780 [01:42<01:03, 277.80 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12116/47780 [01:42<02:11, 270.82 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29527/47780 [01:42<01:09, 262.92 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30775/47780 [01:42<01:17, 219.43 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31217/47780 [01:42<01:05, 253.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29845/47780 [01:42<01:06, 267.91 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31323/47780 [01:42<01:01, 266.30 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29495/47780 [01:42<01:09, 264.75 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30245/47780 [01:42<01:00, 288.34 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12147/47780 [01:42<02:06, 281.34 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29554/47780 [01:42<01:08, 264.80 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31244/47780 [01:42<01:04, 258.01 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30801/47780 [01:42<01:14, 227.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29877/47780 [01:42<01:04, 276.08 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31350/47780 [01:42<01:04, 253.61 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29524/47780 [01:42<01:08, 268.37 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30276/47780 [01:42<00:59, 291.75 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12176/47780 [01:42<02:11, 271.69 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31270/47780 [01:42<01:05, 252.80 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30834/47780 [01:42<01:08, 249.10 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29581/47780 [01:42<01:15, 242.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29905/47780 [01:42<01:06, 267.95 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31376/47780 [01:42<01:05, 249.89 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29552/47780 [01:42<01:08, 265.57 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30309/47780 [01:42<00:59, 292.52 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12208/47780 [01:42<02:06, 282.00 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31303/47780 [01:42<00:59, 274.88 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30860/47780 [01:42<01:08, 246.76 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29607/47780 [01:42<01:15, 240.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29933/47780 [01:42<01:07, 262.81 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30344/47780 [01:42<00:57, 305.27 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30890/47780 [01:42<01:04, 261.26 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31335/47780 [01:42<00:59, 278.32 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29579/47780 [01:42<01:14, 244.86 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12237/47780 [01:42<02:12, 269.03 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31402/47780 [01:42<01:12, 225.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29635/47780 [01:42<01:12, 249.58 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29960/47780 [01:42<01:10, 252.69 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30921/47780 [01:42<01:01, 272.02 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31366/47780 [01:42<00:57, 287.00 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30375/47780 [01:42<01:01, 283.70 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12265/47780 [01:42<02:11, 270.71 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29604/47780 [01:42<01:16, 238.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31435/47780 [01:42<01:06, 247.46 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29664/47780 [01:42<01:13, 246.26 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29995/47780 [01:42<01:04, 277.38 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30952/47780 [01:42<00:59, 282.57 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31396/47780 [01:42<00:57, 284.60 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29630/47780 [01:42<01:14, 244.26 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12294/47780 [01:42<02:11, 269.74 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30404/47780 [01:42<01:02, 276.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31464/47780 [01:42<01:05, 250.73 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29693/47780 [01:42<01:11, 254.46 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30023/47780 [01:42<01:05, 271.72 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30984/47780 [01:42<00:57, 290.24 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29658/47780 [01:42<01:11, 254.09 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12322/47780 [01:42<02:10, 271.37 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30432/47780 [01:42<01:03, 274.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31425/47780 [01:43<00:59, 275.96 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31502/47780 [01:43<00:58, 279.98 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29719/47780 [01:42<01:12, 249.29 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30051/47780 [01:43<01:10, 251.61 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29690/47780 [01:43<01:06, 271.78 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31014/47780 [01:43<00:58, 284.53 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12353/47780 [01:43<02:05, 281.32 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30460/47780 [01:43<01:03, 274.47 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31457/47780 [01:43<00:57, 282.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31531/47780 [01:43<00:57, 282.19 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29745/47780 [01:43<01:17, 231.79 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30077/47780 [01:43<01:10, 250.80 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31044/47780 [01:43<00:58, 288.53 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12384/47780 [01:43<02:04, 284.07 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29718/47780 [01:43<01:08, 262.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30488/47780 [01:43<01:03, 273.63 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31486/47780 [01:43<01:03, 258.24 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31560/47780 [01:43<01:02, 261.03 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29774/47780 [01:43<01:14, 242.19 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30103/47780 [01:43<01:13, 240.55 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12415/47780 [01:43<02:02, 288.36 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31073/47780 [01:43<01:00, 275.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30521/47780 [01:43<01:01, 281.13 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29745/47780 [01:43<01:11, 252.89 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31517/47780 [01:43<00:59, 272.10 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31587/47780 [01:43<01:03, 253.21 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29799/47780 [01:43<01:14, 241.70 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12452/47780 [01:43<01:53, 311.91 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30128/47780 [01:43<01:18, 223.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30553/47780 [01:43<00:59, 288.99 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29776/47780 [01:43<01:07, 267.00 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31101/47780 [01:43<01:03, 264.50 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31550/47780 [01:43<00:57, 282.13 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31613/47780 [01:43<01:08, 237.65 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29825/47780 [01:43<01:16, 236.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30586/47780 [01:43<00:57, 300.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12484/47780 [01:43<01:57, 299.96 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31128/47780 [01:43<01:03, 261.68 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30151/47780 [01:43<01:19, 222.67 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29803/47780 [01:43<01:12, 248.18 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31579/47780 [01:43<00:58, 275.43 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29849/47780 [01:43<01:16, 234.80 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31640/47780 [01:43<01:07, 237.46 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30618/47780 [01:43<00:56, 301.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30175/47780 [01:43<01:18, 225.21 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12515/47780 [01:43<02:00, 292.02 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31614/47780 [01:43<00:54, 295.84 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31155/47780 [01:43<01:11, 233.54 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29829/47780 [01:43<01:18, 228.87 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31668/47780 [01:43<01:05, 246.25 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29873/47780 [01:43<01:19, 224.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30660/47780 [01:43<00:51, 333.46 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30198/47780 [01:43<01:19, 220.48 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12545/47780 [01:43<02:03, 285.32 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31647/47780 [01:43<00:53, 301.98 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31181/47780 [01:43<01:09, 238.23 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29856/47780 [01:43<01:15, 237.20 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31694/47780 [01:43<01:05, 247.30 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29896/47780 [01:43<01:19, 225.14 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30699/47780 [01:43<00:48, 349.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30225/47780 [01:43<01:15, 232.93 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12574/47780 [01:43<02:11, 267.45 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31678/47780 [01:43<00:54, 294.03 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31208/47780 [01:43<01:07, 246.74 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31720/47780 [01:43<01:04, 250.83 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29881/47780 [01:43<01:18, 228.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29919/47780 [01:43<01:22, 216.67 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30735/47780 [01:43<00:50, 336.85 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30249/47780 [01:43<01:16, 229.78 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12601/47780 [01:43<02:16, 258.28 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31235/47780 [01:43<01:06, 250.65 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31708/47780 [01:44<00:56, 283.18 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31751/47780 [01:44<00:59, 267.53 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29907/47780 [01:43<01:16, 234.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29951/47780 [01:43<01:13, 242.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30770/47780 [01:44<00:50, 338.40 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30277/47780 [01:44<01:13, 238.63 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12635/47780 [01:44<02:05, 280.27 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31266/47780 [01:44<01:03, 261.48 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31737/47780 [01:44<01:00, 267.18 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29939/47780 [01:44<01:09, 255.06 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29979/47780 [01:44<01:10, 253.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31778/47780 [01:44<01:04, 249.60 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30301/47780 [01:44<01:13, 238.97 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30804/47780 [01:44<00:52, 322.47 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12666/47780 [01:44<02:02, 285.64 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31302/47780 [01:44<00:57, 286.05 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31766/47780 [01:44<00:59, 267.51 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29967/47780 [01:44<01:09, 256.26 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31808/47780 [01:44<01:00, 262.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30011/47780 [01:44<01:08, 260.37 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30329/47780 [01:44<01:12, 242.31 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30837/47780 [01:44<00:54, 310.65 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12695/47780 [01:44<02:03, 283.77 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31334/47780 [01:44<00:55, 295.59 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29995/47780 [01:44<01:08, 260.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31793/47780 [01:44<01:01, 259.31 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30039/47780 [01:44<01:08, 260.33 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31835/47780 [01:44<01:04, 247.30 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30357/47780 [01:44<01:09, 250.43 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31364/47780 [01:44<00:56, 291.00 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12724/47780 [01:44<02:08, 272.83 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30870/47780 [01:44<00:59, 284.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30022/47780 [01:44<01:08, 259.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31820/47780 [01:44<01:03, 251.48 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30066/47780 [01:44<01:08, 257.06 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30386/47780 [01:44<01:06, 261.68 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31861/47780 [01:44<01:06, 240.14 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31396/47780 [01:44<00:55, 295.34 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12758/47780 [01:44<02:02, 285.53 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30050/47780 [01:44<01:08, 259.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30899/47780 [01:44<01:04, 261.07 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31849/47780 [01:44<01:02, 256.37 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30092/47780 [01:44<01:12, 244.07 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31888/47780 [01:44<01:05, 240.82 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12795/47780 [01:44<01:54, 305.90 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31426/47780 [01:44<01:00, 271.55 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30413/47780 [01:44<01:19, 218.44 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30077/47780 [01:44<01:07, 262.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30927/47780 [01:44<01:04, 260.65 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31881/47780 [01:44<00:58, 270.97 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30118/47780 [01:44<01:11, 245.82 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31913/47780 [01:44<01:05, 243.30 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12827/47780 [01:44<01:55, 303.13 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31457/47780 [01:44<00:58, 279.25 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30461/47780 [01:44<01:01, 282.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30104/47780 [01:44<01:09, 253.26 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30959/47780 [01:44<01:01, 273.61 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31910/47780 [01:44<00:57, 275.68 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30151/47780 [01:44<01:06, 267.02 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31940/47780 [01:44<01:04, 245.27 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12860/47780 [01:44<01:54, 303.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31486/47780 [01:44<00:58, 278.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30491/47780 [01:44<01:03, 272.10 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31938/47780 [01:44<00:58, 271.06 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30987/47780 [01:44<01:03, 263.64 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30130/47780 [01:44<01:15, 233.86 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31967/47780 [01:44<01:03, 249.49 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30178/47780 [01:44<01:07, 261.00 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12894/47780 [01:44<01:52, 310.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31521/47780 [01:44<00:54, 295.63 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31967/47780 [01:45<00:57, 273.74 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30520/47780 [01:44<01:04, 268.58 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31023/47780 [01:44<00:57, 289.73 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30206/47780 [01:44<01:06, 263.76 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31993/47780 [01:45<01:05, 240.71 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30155/47780 [01:45<01:19, 221.44 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12926/47780 [01:45<01:58, 293.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31556/47780 [01:45<00:53, 302.80 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32000/47780 [01:45<00:55, 284.55 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30548/47780 [01:45<01:05, 263.35 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31055/47780 [01:45<00:57, 291.75 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30234/47780 [01:45<01:06, 265.41 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30180/47780 [01:45<01:18, 224.24 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32018/47780 [01:45<01:08, 228.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31592/47780 [01:45<00:51, 315.45 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12956/47780 [01:45<02:02, 285.29 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32032/47780 [01:45<00:55, 283.66 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30575/47780 [01:45<01:06, 258.36 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31086/47780 [01:45<00:58, 287.26 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30264/47780 [01:45<01:04, 272.24 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30206/47780 [01:45<01:16, 228.86 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32044/47780 [01:45<01:08, 229.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31625/47780 [01:45<00:50, 317.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12998/47780 [01:45<01:47, 322.44 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32065/47780 [01:45<00:54, 290.29 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31118/47780 [01:45<00:57, 290.00 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30603/47780 [01:45<01:09, 248.76 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30292/47780 [01:45<01:07, 259.53 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30230/47780 [01:45<01:17, 226.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32068/47780 [01:45<01:08, 229.87 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31657/47780 [01:45<00:54, 297.66 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31151/47780 [01:45<00:55, 297.86 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13031/47780 [01:45<01:58, 292.80 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32099/47780 [01:45<00:53, 294.19 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30629/47780 [01:45<01:09, 248.42 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30332/47780 [01:45<00:59, 295.51 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30253/47780 [01:45<01:18, 222.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32092/47780 [01:45<01:11, 220.58 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31688/47780 [01:45<00:53, 298.81 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32132/47780 [01:45<00:51, 301.10 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30656/47780 [01:45<01:07, 252.66 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31182/47780 [01:45<00:57, 288.20 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30373/47780 [01:45<00:53, 324.40 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13062/47780 [01:45<02:07, 272.16 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30277/47780 [01:45<01:17, 225.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32115/47780 [01:45<01:10, 221.40 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31721/47780 [01:45<00:52, 303.87 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32163/47780 [01:45<00:51, 302.74 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31214/47780 [01:45<00:56, 293.84 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30682/47780 [01:45<01:10, 241.08 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13097/47780 [01:45<01:59, 289.13 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30406/47780 [01:45<00:56, 308.34 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30301/47780 [01:45<01:17, 226.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32144/47780 [01:45<01:05, 239.86 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31756/47780 [01:45<00:50, 316.24 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32194/47780 [01:45<00:53, 292.26 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31249/47780 [01:45<00:55, 296.03 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30709/47780 [01:45<01:09, 246.33 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13129/47780 [01:45<01:57, 295.32 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30325/47780 [01:45<01:18, 223.03 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30447/47780 [01:45<00:53, 325.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32169/47780 [01:45<01:05, 240.06 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31789/47780 [01:45<00:51, 312.53 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32225/47780 [01:45<00:52, 293.65 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30735/47780 [01:45<01:08, 247.47 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13165/47780 [01:45<01:52, 307.78 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30352/47780 [01:45<01:14, 234.35 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31279/47780 [01:45<01:00, 273.04 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30480/47780 [01:45<00:54, 319.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32204/47780 [01:45<00:57, 269.68 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31825/47780 [01:45<00:48, 326.13 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32260/47780 [01:45<00:51, 299.75 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30762/47780 [01:45<01:07, 253.66 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13197/47780 [01:45<01:54, 301.41 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30376/47780 [01:45<01:15, 230.32 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31307/47780 [01:45<01:00, 271.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32232/47780 [01:46<00:59, 262.42 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31859/47780 [01:45<00:49, 324.86 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30513/47780 [01:45<00:58, 293.19 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30796/47780 [01:46<01:00, 278.51 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32294/47780 [01:46<00:52, 294.19 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13228/47780 [01:46<01:54, 302.05 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30403/47780 [01:46<01:12, 241.34 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31338/47780 [01:46<01:00, 272.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32261/47780 [01:46<00:58, 266.99 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30546/47780 [01:46<00:56, 302.65 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31893/47780 [01:46<00:49, 323.79 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30825/47780 [01:46<01:02, 270.86 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32324/47780 [01:46<00:55, 280.48 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13261/47780 [01:46<02:00, 287.13 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32293/47780 [01:46<00:55, 280.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30428/47780 [01:46<01:16, 227.94 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30577/47780 [01:46<00:57, 301.77 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31366/47780 [01:46<01:03, 258.70 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31927/47780 [01:46<00:48, 328.46 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30853/47780 [01:46<01:02, 269.05 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32354/47780 [01:46<00:54, 282.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30452/47780 [01:46<01:15, 228.80 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31395/47780 [01:46<01:01, 267.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30608/47780 [01:46<00:56, 304.06 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31961/47780 [01:46<00:48, 328.09 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13291/47780 [01:46<02:08, 267.39 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32322/47780 [01:46<01:01, 252.77 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30884/47780 [01:46<01:00, 277.52 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32385/47780 [01:46<00:53, 287.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30645/47780 [01:46<00:53, 322.82 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31424/47780 [01:46<01:00, 270.19 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30476/47780 [01:46<01:19, 217.22 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31994/47780 [01:46<00:49, 320.71 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13319/47780 [01:46<02:08, 267.92 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32356/47780 [01:46<00:57, 270.29 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30912/47780 [01:46<01:01, 275.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32414/47780 [01:46<00:55, 278.72 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30688/47780 [01:46<00:49, 345.94 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31452/47780 [01:46<01:00, 268.31 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30499/47780 [01:46<01:18, 220.57 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13347/47780 [01:46<02:07, 270.71 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32027/47780 [01:46<00:53, 296.26 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32384/47780 [01:46<01:00, 256.24 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30942/47780 [01:46<00:59, 280.71 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32447/47780 [01:46<00:53, 285.46 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31490/47780 [01:46<00:55, 295.38 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30525/47780 [01:46<01:16, 224.52 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13375/47780 [01:46<02:12, 258.94 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32064/47780 [01:46<00:50, 313.15 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30972/47780 [01:46<00:59, 284.75 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30724/47780 [01:46<00:57, 295.10 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32414/47780 [01:46<01:01, 250.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32480/47780 [01:46<00:51, 295.84 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31520/47780 [01:46<00:56, 286.86 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30549/47780 [01:46<01:16, 226.07 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32096/47780 [01:46<00:52, 298.24 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13402/47780 [01:46<02:24, 238.64 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30773/47780 [01:46<00:49, 342.15 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31001/47780 [01:46<01:00, 279.37 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32444/47780 [01:46<00:58, 263.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32514/47780 [01:46<00:50, 304.95 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30573/47780 [01:46<01:16, 224.90 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31549/47780 [01:46<00:59, 275.09 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32129/47780 [01:46<00:51, 305.26 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13428/47780 [01:46<02:21, 242.45 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32475/47780 [01:46<00:55, 275.61 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30809/47780 [01:46<00:51, 332.72 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31029/47780 [01:46<01:03, 264.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32548/47780 [01:46<00:48, 311.35 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30601/47780 [01:46<01:11, 240.41 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31581/47780 [01:46<00:56, 285.16 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32162/47780 [01:46<00:50, 307.00 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13461/47780 [01:46<02:09, 265.64 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32503/47780 [01:47<00:57, 267.11 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31060/47780 [01:46<01:01, 271.37 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32587/47780 [01:47<00:45, 330.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30844/47780 [01:47<00:53, 317.10 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31610/47780 [01:47<01:00, 267.49 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30626/47780 [01:47<01:17, 220.06 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13492/47780 [01:47<02:03, 277.89 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32199/47780 [01:47<00:48, 321.45 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32537/47780 [01:47<00:53, 287.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32622/47780 [01:47<00:45, 333.72 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31089/47780 [01:47<01:03, 261.72 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30877/47780 [01:47<00:54, 307.53 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30651/47780 [01:47<01:15, 227.05 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32240/47780 [01:47<00:44, 346.60 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31638/47780 [01:47<01:02, 256.99 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13522/47780 [01:47<02:07, 268.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32570/47780 [01:47<00:51, 292.86 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32656/47780 [01:47<00:46, 325.22 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31118/47780 [01:47<01:02, 265.18 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30909/47780 [01:47<00:54, 306.91 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30675/47780 [01:47<01:14, 229.71 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32277/47780 [01:47<00:45, 341.50 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31673/47780 [01:47<00:57, 279.31 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13550/47780 [01:47<02:05, 271.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32602/47780 [01:47<00:51, 293.97 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32689/47780 [01:47<00:46, 322.34 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30941/47780 [01:47<00:55, 304.34 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31145/47780 [01:47<01:08, 243.33 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30702/47780 [01:47<01:11, 238.46 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31709/47780 [01:47<00:53, 298.42 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32312/47780 [01:47<00:46, 332.21 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32632/47780 [01:47<00:51, 292.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13578/47780 [01:47<02:11, 259.54 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32722/47780 [01:47<00:48, 312.57 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31170/47780 [01:47<01:07, 245.01 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30972/47780 [01:47<00:58, 286.76 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30729/47780 [01:47<01:09, 244.52 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31747/47780 [01:47<00:50, 315.69 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32346/47780 [01:47<00:46, 330.43 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32662/47780 [01:47<00:51, 294.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13607/47780 [01:47<02:08, 265.12 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32754/47780 [01:47<00:48, 306.68 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31195/47780 [01:47<01:08, 240.46 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31001/47780 [01:47<01:00, 275.94 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30761/47780 [01:47<01:04, 265.84 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31786/47780 [01:47<00:48, 331.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32380/47780 [01:47<00:48, 318.07 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32693/47780 [01:47<00:53, 279.55 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32785/47780 [01:47<00:49, 304.03 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31223/47780 [01:47<01:07, 246.85 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30794/47780 [01:47<01:00, 281.78 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31821/47780 [01:47<00:47, 334.95 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32413/47780 [01:47<00:48, 318.97 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13634/47780 [01:47<02:45, 205.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31029/47780 [01:47<01:08, 245.18 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32722/47780 [01:47<00:53, 279.40 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32816/47780 [01:47<00:52, 283.33 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30823/47780 [01:47<01:01, 277.62 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31252/47780 [01:47<01:07, 244.38 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31855/47780 [01:47<00:48, 330.57 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31074/47780 [01:47<00:56, 294.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13678/47780 [01:47<02:13, 254.59 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32755/47780 [01:47<00:51, 293.70 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32446/47780 [01:47<00:51, 296.90 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32845/47780 [01:47<00:54, 275.98 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31282/47780 [01:47<01:04, 254.89 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30851/47780 [01:47<01:02, 269.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31891/47780 [01:47<00:47, 335.19 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32789/47780 [01:47<00:48, 306.27 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13706/47780 [01:47<02:15, 250.88 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32480/47780 [01:47<00:50, 303.56 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31105/47780 [01:47<01:00, 275.26 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32873/47780 [01:48<00:54, 271.14 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30879/47780 [01:48<01:02, 269.17 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31308/47780 [01:47<01:06, 248.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31927/47780 [01:48<00:46, 342.17 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32821/47780 [01:48<00:48, 307.74 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13737/47780 [01:48<02:09, 263.26 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31134/47780 [01:48<01:00, 273.13 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32512/47780 [01:48<00:51, 294.90 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32901/47780 [01:48<00:55, 267.85 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31335/47780 [01:48<01:04, 254.18 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30908/47780 [01:48<01:02, 271.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31966/47780 [01:48<00:45, 344.22 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32853/47780 [01:48<00:48, 307.37 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13766/47780 [01:48<02:08, 264.58 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31165/47780 [01:48<00:59, 280.18 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32545/47780 [01:48<00:50, 302.32 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31363/47780 [01:48<01:02, 261.46 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32932/47780 [01:48<00:53, 276.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30936/47780 [01:48<01:04, 262.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32001/47780 [01:48<00:47, 330.63 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32889/47780 [01:48<00:46, 322.40 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13808/47780 [01:48<01:53, 300.17 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31194/47780 [01:48<00:59, 276.82 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32580/47780 [01:48<00:48, 311.03 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31390/47780 [01:48<01:02, 260.98 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32974/47780 [01:48<00:47, 310.23 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30963/47780 [01:48<01:05, 258.54 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32039/47780 [01:48<00:46, 340.80 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32923/47780 [01:48<00:48, 308.47 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31223/47780 [01:48<00:59, 277.30 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32612/47780 [01:48<00:50, 300.12 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13839/47780 [01:48<02:01, 278.43 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33006/47780 [01:48<00:47, 312.98 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31417/47780 [01:48<01:04, 254.71 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30992/47780 [01:48<01:03, 262.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32074/47780 [01:48<00:46, 339.51 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32955/47780 [01:48<00:48, 307.71 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31251/47780 [01:48<01:01, 267.95 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13869/47780 [01:48<02:00, 281.46 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32644/47780 [01:48<00:50, 299.16 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31449/47780 [01:48<01:00, 270.18 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33038/47780 [01:48<00:50, 290.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32109/47780 [01:48<00:46, 338.28 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31019/47780 [01:48<01:06, 252.15 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32997/47780 [01:48<00:44, 330.44 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31279/47780 [01:48<01:01, 269.61 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13903/47780 [01:48<01:55, 293.89 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32676/47780 [01:48<00:50, 298.19 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31479/47780 [01:48<00:59, 272.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33072/47780 [01:48<00:48, 301.90 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32143/47780 [01:48<00:46, 338.72 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31046/47780 [01:48<01:09, 240.92 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31313/47780 [01:48<00:58, 282.95 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32707/47780 [01:48<00:50, 298.57 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33031/47780 [01:48<00:48, 302.05 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31512/47780 [01:48<00:56, 288.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13933/47780 [01:48<02:07, 266.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32179/47780 [01:48<00:45, 341.39 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33104/47780 [01:48<00:50, 290.51 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31076/47780 [01:48<01:05, 255.65 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31342/47780 [01:48<00:58, 281.78 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32742/47780 [01:48<00:48, 312.85 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33062/47780 [01:48<00:49, 297.96 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31546/47780 [01:48<00:55, 293.84 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13962/47780 [01:48<02:08, 263.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32214/47780 [01:48<00:45, 342.12 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33138/47780 [01:48<00:48, 301.05 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31374/47780 [01:48<00:56, 292.40 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31102/47780 [01:48<01:11, 232.43 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32774/47780 [01:48<00:49, 304.35 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33093/47780 [01:48<00:50, 288.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31580/47780 [01:48<00:52, 306.78 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13994/47780 [01:48<02:05, 268.22 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33175/47780 [01:49<00:45, 320.22 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32249/47780 [01:48<00:45, 337.93 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31408/47780 [01:49<00:53, 304.43 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31126/47780 [01:49<01:12, 228.94 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32805/47780 [01:49<00:50, 294.95 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33124/47780 [01:49<00:51, 285.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31611/47780 [01:49<00:53, 299.66 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14030/47780 [01:49<01:59, 282.86 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33208/47780 [01:49<00:48, 301.47 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32284/47780 [01:49<00:51, 303.13 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31443/47780 [01:49<00:51, 315.85 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31150/47780 [01:49<01:12, 229.99 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32840/47780 [01:49<00:49, 304.19 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33158/47780 [01:49<00:50, 290.61 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31643/47780 [01:49<00:55, 290.18 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33239/47780 [01:49<00:48, 301.05 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32327/47780 [01:49<00:46, 333.62 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31478/47780 [01:49<00:50, 322.61 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14060/47780 [01:49<02:07, 264.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31174/47780 [01:49<01:17, 213.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33188/47780 [01:49<00:51, 284.26 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31674/47780 [01:49<00:55, 289.19 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32871/47780 [01:49<00:56, 264.34 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33273/47780 [01:49<00:46, 308.92 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14092/47780 [01:49<02:00, 279.24 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32363/47780 [01:49<00:46, 329.72 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31511/47780 [01:49<00:51, 313.22 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31196/47780 [01:49<01:17, 215.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33219/47780 [01:49<00:50, 290.89 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31706/47780 [01:49<00:56, 285.05 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32905/47780 [01:49<00:52, 283.81 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33305/47780 [01:49<00:47, 301.84 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14121/47780 [01:49<02:00, 279.21 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31543/47780 [01:49<00:51, 315.05 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32397/47780 [01:49<00:47, 322.11 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31218/47780 [01:49<01:16, 216.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33249/47780 [01:49<00:49, 292.17 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31743/47780 [01:49<00:52, 305.28 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33339/47780 [01:49<00:46, 312.57 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32935/47780 [01:49<00:53, 276.28 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14156/47780 [01:49<01:54, 292.46 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32430/47780 [01:49<00:48, 317.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31575/47780 [01:49<00:55, 290.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31240/47780 [01:49<01:19, 208.26 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31774/47780 [01:49<00:52, 302.88 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33279/47780 [01:49<00:53, 269.63 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33372/47780 [01:49<00:45, 313.66 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32970/47780 [01:49<00:51, 289.89 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14186/47780 [01:49<01:55, 291.19 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32463/47780 [01:49<00:48, 316.80 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31607/47780 [01:49<00:54, 298.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31262/47780 [01:49<01:18, 211.32 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31811/47780 [01:49<00:50, 318.68 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33314/47780 [01:49<00:50, 286.57 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33006/47780 [01:49<00:48, 305.79 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33408/47780 [01:49<00:46, 309.24 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14224/47780 [01:49<01:49, 305.93 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32495/47780 [01:49<00:49, 306.39 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31290/47780 [01:49<01:12, 226.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31638/47780 [01:49<00:57, 279.31 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33040/47780 [01:49<00:47, 311.87 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33343/47780 [01:49<00:52, 272.61 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31843/47780 [01:49<00:53, 295.31 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14261/47780 [01:49<01:44, 321.30 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33440/47780 [01:49<00:46, 305.64 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32526/47780 [01:49<00:52, 289.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31670/47780 [01:49<00:55, 288.04 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31313/47780 [01:49<01:15, 219.53 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33072/47780 [01:49<00:46, 313.16 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33371/47780 [01:50<00:54, 265.98 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33471/47780 [01:50<00:48, 293.36 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14294/47780 [01:49<01:48, 307.68 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31873/47780 [01:49<01:00, 262.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31702/47780 [01:49<00:54, 296.28 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31339/47780 [01:50<01:13, 223.45 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32556/47780 [01:50<00:58, 262.44 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33399/47780 [01:50<00:53, 266.73 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33502/47780 [01:50<00:50, 282.11 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31732/47780 [01:50<00:54, 296.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33104/47780 [01:50<00:55, 266.53 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14325/47780 [01:50<01:59, 280.00 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31902/47780 [01:50<01:03, 249.83 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31362/47780 [01:50<01:20, 204.47 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32583/47780 [01:50<01:01, 248.30 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33434/47780 [01:50<00:49, 289.74 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31762/47780 [01:50<00:54, 291.54 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33531/47780 [01:50<00:52, 272.75 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33132/47780 [01:50<00:55, 264.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14354/47780 [01:50<01:59, 279.43 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31933/47780 [01:50<01:00, 263.83 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31386/47780 [01:50<01:17, 211.99 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32609/47780 [01:50<01:01, 245.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33464/47780 [01:50<00:53, 268.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33561/47780 [01:50<00:51, 274.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14389/47780 [01:50<01:53, 293.79 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33160/47780 [01:50<00:56, 259.84 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31961/47780 [01:50<00:59, 267.70 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31792/47780 [01:50<00:57, 277.28 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31412/47780 [01:50<01:12, 224.95 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32637/47780 [01:50<00:59, 254.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33499/47780 [01:50<00:49, 287.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33589/47780 [01:50<00:52, 272.18 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31822/47780 [01:50<00:56, 283.26 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31991/47780 [01:50<00:58, 270.99 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33187/47780 [01:50<00:59, 244.82 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14419/47780 [01:50<02:05, 265.99 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31439/47780 [01:50<01:10, 232.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32667/47780 [01:50<00:56, 266.82 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33618/47780 [01:50<00:52, 272.31 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31853/47780 [01:50<00:55, 288.74 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33529/47780 [01:50<00:53, 264.10 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32020/47780 [01:50<00:57, 276.26 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33212/47780 [01:50<00:59, 243.47 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31466/47780 [01:50<01:07, 243.07 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32695/47780 [01:50<00:55, 270.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14447/47780 [01:50<02:19, 239.54 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32048/47780 [01:50<00:58, 268.26 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33646/47780 [01:50<00:54, 258.96 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33242/47780 [01:50<00:56, 256.82 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31883/47780 [01:50<00:59, 267.47 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31495/47780 [01:50<01:03, 256.41 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33557/47780 [01:50<00:58, 245.04 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32730/47780 [01:50<00:52, 286.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14474/47780 [01:50<02:14, 247.02 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33679/47780 [01:50<00:51, 275.75 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32080/47780 [01:50<00:56, 279.76 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33269/47780 [01:50<00:56, 257.08 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31916/47780 [01:50<00:56, 281.47 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33583/47780 [01:50<00:57, 245.48 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32763/47780 [01:50<00:50, 296.19 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31522/47780 [01:50<01:07, 239.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14500/47780 [01:50<02:21, 235.54 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33711/47780 [01:50<00:48, 287.96 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32109/47780 [01:50<00:57, 273.86 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31945/47780 [01:50<00:55, 283.35 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33295/47780 [01:50<00:59, 244.22 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32800/47780 [01:50<00:47, 313.81 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33608/47780 [01:50<00:59, 238.45 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31553/47780 [01:50<01:02, 257.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14525/47780 [01:50<02:21, 234.46 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33741/47780 [01:51<00:49, 281.93 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32138/47780 [01:50<00:59, 263.05 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31975/47780 [01:50<00:57, 275.90 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33636/47780 [01:51<00:56, 249.00 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32843/47780 [01:50<00:43, 342.90 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33321/47780 [01:50<00:58, 245.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31582/47780 [01:51<01:01, 263.89 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14549/47780 [01:51<02:31, 218.90 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33770/47780 [01:51<00:52, 268.97 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33663/47780 [01:51<00:56, 249.31 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33347/47780 [01:51<00:59, 244.44 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32166/47780 [01:51<01:00, 256.31 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32003/47780 [01:51<01:00, 262.38 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31609/47780 [01:51<01:02, 256.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32878/47780 [01:51<00:49, 301.35 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14572/47780 [01:51<02:33, 215.75 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33800/47780 [01:51<00:51, 271.55 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33694/47780 [01:51<00:54, 260.36 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32193/47780 [01:51<01:01, 254.53 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32031/47780 [01:51<00:59, 264.19 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31636/47780 [01:51<01:02, 257.71 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33379/47780 [01:51<00:57, 248.85 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14603/47780 [01:51<02:17, 240.80 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32910/47780 [01:51<00:53, 275.78 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33835/47780 [01:51<00:47, 293.42 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33724/47780 [01:51<00:51, 271.40 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32219/47780 [01:51<01:00, 255.44 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32058/47780 [01:51<01:00, 259.96 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31664/47780 [01:51<01:01, 263.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33404/47780 [01:51<00:58, 246.48 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14628/47780 [01:51<02:17, 240.83 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32943/47780 [01:51<00:51, 286.82 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33763/47780 [01:51<00:45, 305.23 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32253/47780 [01:51<00:56, 276.89 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33432/47780 [01:51<00:56, 255.73 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32087/47780 [01:51<01:01, 256.94 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33866/47780 [01:51<00:52, 267.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31691/47780 [01:51<01:04, 248.58 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14656/47780 [01:51<02:12, 250.65 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32973/47780 [01:51<00:51, 286.18 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32282/47780 [01:51<00:55, 280.56 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33794/47780 [01:51<00:47, 296.48 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32117/47780 [01:51<00:58, 265.97 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33894/47780 [01:51<00:52, 265.29 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33458/47780 [01:51<00:58, 245.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31719/47780 [01:51<01:03, 251.74 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33003/47780 [01:51<00:51, 287.48 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14683/47780 [01:51<02:13, 248.71 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32311/47780 [01:51<00:54, 283.10 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32144/47780 [01:51<00:58, 266.82 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33824/47780 [01:51<00:50, 278.28 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33484/47780 [01:51<00:57, 249.73 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33921/47780 [01:51<00:53, 260.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31748/47780 [01:51<01:01, 259.46 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14712/47780 [01:51<02:07, 260.20 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33033/47780 [01:51<00:53, 275.78 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32340/47780 [01:51<00:57, 266.75 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31779/47780 [01:51<00:59, 270.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33510/47780 [01:51<00:59, 239.05 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32171/47780 [01:51<01:03, 245.12 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33948/47780 [01:51<00:55, 247.36 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33853/47780 [01:51<00:55, 251.53 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14739/47780 [01:51<02:09, 254.45 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33071/47780 [01:51<00:48, 301.38 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32369/47780 [01:51<00:57, 268.14 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33539/47780 [01:51<00:56, 253.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31810/47780 [01:51<00:57, 278.75 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32215/47780 [01:51<00:53, 292.37 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33973/47780 [01:51<00:56, 245.00 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33879/47780 [01:51<00:57, 243.72 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33105/47780 [01:51<00:47, 311.43 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14774/47780 [01:51<02:01, 272.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32396/47780 [01:51<00:58, 261.80 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31847/47780 [01:51<00:54, 291.56 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32245/47780 [01:51<00:53, 288.35 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33998/47780 [01:52<00:58, 236.23 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33907/47780 [01:52<00:54, 252.66 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33565/47780 [01:51<01:04, 220.23 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14803/47780 [01:51<01:58, 277.34 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33138/47780 [01:52<00:48, 300.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32423/47780 [01:52<00:58, 261.25 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31880/47780 [01:52<00:53, 299.10 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32275/47780 [01:52<00:54, 286.09 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33933/47780 [01:52<00:56, 246.34 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34022/47780 [01:52<01:01, 222.55 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33589/47780 [01:52<01:03, 222.95 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14834/47780 [01:52<01:56, 283.59 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33172/47780 [01:52<00:46, 311.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32450/47780 [01:52<01:01, 250.58 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32304/47780 [01:52<00:57, 267.69 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31910/47780 [01:52<00:59, 268.76 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14869/47780 [01:52<01:49, 299.33 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33958/47780 [01:52<01:00, 227.37 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34045/47780 [01:52<01:07, 203.74 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33204/47780 [01:52<00:48, 299.49 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33612/47780 [01:52<01:09, 203.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32476/47780 [01:52<01:00, 252.20 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31939/47780 [01:52<00:58, 271.47 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14900/47780 [01:52<01:50, 298.77 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32332/47780 [01:52<01:01, 253.03 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34066/47780 [01:52<01:07, 202.32 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33982/47780 [01:52<01:02, 219.09 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33635/47780 [01:52<01:07, 209.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33235/47780 [01:52<00:50, 289.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32509/47780 [01:52<00:56, 269.26 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14930/47780 [01:52<01:53, 289.03 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31968/47780 [01:52<01:01, 256.87 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32358/47780 [01:52<01:03, 243.73 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34087/47780 [01:52<01:07, 204.20 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34005/47780 [01:52<01:03, 217.61 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33657/47780 [01:52<01:09, 203.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33265/47780 [01:52<00:51, 284.29 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32540/47780 [01:52<00:55, 276.49 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34109/47780 [01:52<01:06, 206.46 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14959/47780 [01:52<02:01, 270.86 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31997/47780 [01:52<01:01, 254.84 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32383/47780 [01:52<01:06, 232.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33680/47780 [01:52<01:08, 204.94 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34027/47780 [01:52<01:05, 209.25 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33294/47780 [01:52<00:51, 279.02 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32575/47780 [01:52<00:51, 294.45 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34131/47780 [01:52<01:05, 207.92 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14987/47780 [01:52<02:01, 269.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32023/47780 [01:52<01:02, 253.54 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32410/47780 [01:52<01:05, 235.20 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32605/47780 [01:52<00:52, 290.21 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34049/47780 [01:52<01:07, 203.18 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33702/47780 [01:52<01:12, 195.48 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33323/47780 [01:52<00:58, 248.90 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34154/47780 [01:52<01:04, 211.74 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15015/47780 [01:52<02:01, 270.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32049/47780 [01:52<01:03, 247.15 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32637/47780 [01:52<00:50, 297.80 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34076/47780 [01:52<01:03, 216.74 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32434/47780 [01:52<01:09, 220.00 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33729/47780 [01:52<01:09, 202.50 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33356/47780 [01:52<00:54, 267.06 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34176/47780 [01:52<01:04, 211.69 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15043/47780 [01:52<02:02, 267.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32077/47780 [01:52<01:01, 256.09 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32667/47780 [01:52<00:51, 294.84 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34106/47780 [01:52<00:57, 239.52 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32457/47780 [01:52<01:11, 213.67 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33757/47780 [01:52<01:03, 222.12 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33386/47780 [01:52<00:52, 272.31 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34200/47780 [01:53<01:01, 219.25 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15070/47780 [01:52<02:03, 264.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32104/47780 [01:52<01:00, 259.91 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32698/47780 [01:52<00:52, 289.21 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32482/47780 [01:53<01:08, 223.27 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34134/47780 [01:53<00:58, 232.67 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33414/47780 [01:53<00:57, 250.39 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34228/47780 [01:53<00:57, 234.85 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33780/47780 [01:53<01:10, 199.04 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15098/47780 [01:53<02:02, 266.00 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32131/47780 [01:53<01:02, 248.67 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32727/47780 [01:53<00:52, 289.08 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32506/47780 [01:53<01:07, 227.56 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34165/47780 [01:53<00:53, 253.64 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34253/47780 [01:53<00:56, 239.22 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33803/47780 [01:53<01:07, 206.92 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15127/47780 [01:53<02:00, 269.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32157/47780 [01:53<01:02, 251.62 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32756/47780 [01:53<00:52, 286.24 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33440/47780 [01:53<01:05, 220.34 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34191/47780 [01:53<00:54, 251.63 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32532/47780 [01:53<01:06, 229.24 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34279/47780 [01:53<00:56, 239.71 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33828/47780 [01:53<01:05, 213.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15165/47780 [01:53<01:48, 301.66 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32184/47780 [01:53<01:02, 251.42 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32785/47780 [01:53<00:55, 268.67 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33463/47780 [01:53<01:06, 216.33 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32566/47780 [01:53<00:59, 255.44 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34218/47780 [01:53<00:54, 249.21 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34307/47780 [01:53<00:54, 248.47 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33852/47780 [01:53<01:04, 217.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15200/47780 [01:53<01:44, 312.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32212/47780 [01:53<01:00, 259.36 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32813/47780 [01:53<00:55, 268.42 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33486/47780 [01:53<01:05, 217.19 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34244/47780 [01:53<00:53, 252.07 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33878/47780 [01:53<01:00, 228.10 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15235/47780 [01:53<01:40, 323.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32592/47780 [01:53<01:07, 223.71 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34332/47780 [01:53<00:57, 232.76 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32239/47780 [01:53<01:01, 253.87 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32845/47780 [01:53<00:53, 280.37 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34273/47780 [01:53<00:51, 260.22 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33509/47780 [01:53<01:09, 204.02 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15268/47780 [01:53<01:42, 317.83 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33902/47780 [01:53<01:02, 221.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34356/47780 [01:53<00:57, 233.02 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32271/47780 [01:53<00:57, 269.67 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32875/47780 [01:53<00:52, 282.58 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34300/47780 [01:53<00:53, 254.11 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32616/47780 [01:53<01:20, 188.43 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33530/47780 [01:53<01:13, 195.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33928/47780 [01:53<00:59, 232.18 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15300/47780 [01:53<01:50, 294.44 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34380/47780 [01:53<00:59, 223.92 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32300/47780 [01:53<00:57, 269.27 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32904/47780 [01:53<00:52, 281.28 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34327/47780 [01:53<00:54, 247.56 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33583/47780 [01:53<00:50, 279.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32637/47780 [01:53<01:24, 178.42 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34410/47780 [01:53<00:55, 242.50 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32330/47780 [01:53<00:55, 277.82 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15331/47780 [01:53<01:51, 291.66 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33952/47780 [01:53<01:05, 212.21 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34355/47780 [01:53<00:53, 250.99 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32933/47780 [01:53<00:58, 251.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33621/47780 [01:53<00:47, 299.90 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34443/47780 [01:54<00:50, 264.23 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15362/47780 [01:53<01:51, 290.91 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32358/47780 [01:53<00:57, 266.28 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32656/47780 [01:53<01:30, 167.26 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33980/47780 [01:53<01:01, 223.70 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34384/47780 [01:54<00:52, 256.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32959/47780 [01:53<00:58, 253.79 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33653/47780 [01:54<00:49, 286.40 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34470/47780 [01:54<00:50, 262.85 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32674/47780 [01:54<01:28, 169.94 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15392/47780 [01:54<01:55, 280.39 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34010/47780 [01:54<00:58, 236.73 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32392/47780 [01:54<00:56, 271.76 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32986/47780 [01:54<00:57, 257.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34415/47780 [01:54<00:49, 268.40 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34500/47780 [01:54<00:49, 266.05 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32692/47780 [01:54<01:28, 170.75 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32424/47780 [01:54<00:53, 285.04 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33683/47780 [01:54<00:53, 264.53 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34042/47780 [01:54<00:55, 245.92 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15421/47780 [01:54<02:04, 260.36 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34448/47780 [01:54<00:46, 285.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33013/47780 [01:54<00:58, 253.73 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32801/47780 [01:54<00:36, 408.60 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32453/47780 [01:54<00:53, 286.34 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33712/47780 [01:54<00:52, 268.61 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34067/47780 [01:54<00:56, 243.11 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15457/47780 [01:54<01:53, 283.93 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34527/47780 [01:54<00:56, 233.84 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33039/47780 [01:54<00:58, 249.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34478/47780 [01:54<00:48, 274.17 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33740/47780 [01:54<00:53, 260.01 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32482/47780 [01:54<00:57, 265.86 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34564/47780 [01:54<00:49, 266.58 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34092/47780 [01:54<00:57, 236.11 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32845/47780 [01:54<00:41, 361.84 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33066/47780 [01:54<00:57, 255.38 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34507/47780 [01:54<00:48, 275.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15486/47780 [01:54<02:01, 265.15 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32509/47780 [01:54<00:57, 264.25 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34597/47780 [01:54<00:46, 280.85 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34117/47780 [01:54<00:56, 239.78 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33768/47780 [01:54<00:55, 251.45 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34538/47780 [01:54<00:46, 285.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15519/47780 [01:54<01:55, 279.46 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32884/47780 [01:54<00:43, 341.59 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33092/47780 [01:54<01:07, 219.18 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32536/47780 [01:54<00:58, 260.24 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33801/47780 [01:54<00:52, 267.53 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34626/47780 [01:54<00:49, 267.21 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34567/47780 [01:54<00:47, 280.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15559/47780 [01:54<01:46, 302.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34142/47780 [01:54<01:01, 220.37 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33133/47780 [01:54<00:54, 268.68 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32923/47780 [01:54<00:48, 307.61 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32565/47780 [01:54<00:58, 261.10 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33829/47780 [01:54<00:52, 264.79 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34605/47780 [01:54<00:42, 308.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34655/47780 [01:54<00:48, 268.45 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34165/47780 [01:54<01:01, 220.45 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15591/47780 [01:54<01:56, 276.97 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32606/47780 [01:54<00:50, 298.10 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34643/47780 [01:54<00:39, 329.35 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32957/47780 [01:54<00:50, 293.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34683/47780 [01:54<00:48, 268.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33856/47780 [01:54<00:56, 247.43 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33162/47780 [01:54<01:05, 223.50 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34188/47780 [01:54<01:05, 206.11 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15620/47780 [01:54<01:59, 269.06 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34677/47780 [01:54<00:39, 328.67 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32636/47780 [01:54<00:54, 279.63 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34713/47780 [01:55<00:48, 269.04 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33886/47780 [01:54<00:53, 258.38 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33194/47780 [01:54<00:59, 244.41 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32988/47780 [01:54<00:55, 264.22 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15648/47780 [01:54<01:58, 271.87 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34211/47780 [01:54<01:07, 201.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34711/47780 [01:55<00:41, 317.01 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33914/47780 [01:55<00:52, 261.92 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32665/47780 [01:55<00:55, 273.56 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34741/47780 [01:55<00:50, 257.73 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33222/47780 [01:55<01:01, 236.65 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15677/47780 [01:55<01:56, 276.72 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33016/47780 [01:55<00:56, 263.06 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34238/47780 [01:55<01:02, 216.42 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33945/47780 [01:55<00:50, 274.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32696/47780 [01:55<00:53, 280.93 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34743/47780 [01:55<00:42, 303.81 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34767/47780 [01:55<00:50, 255.54 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15708/47780 [01:55<01:52, 286.04 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34264/47780 [01:55<00:59, 226.63 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33250/47780 [01:55<01:01, 235.69 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32726/47780 [01:55<00:53, 282.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33044/47780 [01:55<01:04, 228.79 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34774/47780 [01:55<00:43, 298.76 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34793/47780 [01:55<00:50, 255.12 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33973/47780 [01:55<00:54, 252.94 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34299/47780 [01:55<00:52, 259.01 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33276/47780 [01:55<01:00, 239.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15737/47780 [01:55<02:00, 265.85 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33070/47780 [01:55<01:02, 233.96 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34805/47780 [01:55<00:43, 299.14 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34821/47780 [01:55<00:49, 260.93 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33999/47780 [01:55<00:55, 247.10 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34335/47780 [01:55<00:47, 282.28 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33305/47780 [01:55<00:57, 249.98 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15768/47780 [01:55<01:55, 277.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32755/47780 [01:55<01:03, 236.33 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34860/47780 [01:55<00:43, 298.05 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34838/47780 [01:55<00:42, 307.89 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33095/47780 [01:55<01:06, 222.38 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34377/47780 [01:55<00:42, 317.79 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34025/47780 [01:55<00:57, 237.58 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15797/47780 [01:55<01:53, 280.99 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33331/47780 [01:55<00:59, 241.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32810/47780 [01:55<00:48, 309.13 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34874/47780 [01:55<00:40, 315.62 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34891/47780 [01:55<00:44, 291.04 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33127/47780 [01:55<00:59, 244.34 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34050/47780 [01:55<00:58, 236.39 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34410/47780 [01:55<00:42, 313.80 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33356/47780 [01:55<01:01, 234.36 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15826/47780 [01:55<02:05, 254.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32843/47780 [01:55<00:49, 301.95 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34906/47780 [01:55<00:41, 313.34 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34923/47780 [01:55<00:43, 292.29 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33156/47780 [01:55<00:57, 253.53 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34074/47780 [01:55<00:58, 234.64 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34442/47780 [01:55<00:45, 294.85 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33382/47780 [01:55<01:00, 238.85 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15853/47780 [01:55<02:04, 256.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32876/47780 [01:55<00:49, 299.69 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34960/47780 [01:55<00:40, 314.28 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34938/47780 [01:55<00:42, 304.52 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33183/47780 [01:55<00:59, 247.32 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34098/47780 [01:55<00:58, 233.48 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33407/47780 [01:55<00:59, 241.69 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34472/47780 [01:55<00:47, 280.51 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15884/47780 [01:55<02:00, 265.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32909/47780 [01:55<00:48, 304.81 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34992/47780 [01:55<00:41, 306.27 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33209/47780 [01:55<01:00, 241.54 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34969/47780 [01:55<00:46, 277.17 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34125/47780 [01:55<00:56, 241.24 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33434/47780 [01:55<00:58, 247.04 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34506/47780 [01:55<00:46, 288.26 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32945/47780 [01:56<00:47, 312.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15919/47780 [01:55<01:54, 278.91 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35023/47780 [01:56<00:43, 293.67 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34150/47780 [01:56<00:55, 243.67 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33234/47780 [01:56<01:00, 239.70 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34998/47780 [01:56<00:47, 266.76 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33464/47780 [01:56<00:54, 262.14 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32977/47780 [01:56<00:47, 312.81 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34536/47780 [01:56<00:50, 262.51 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15948/47780 [01:56<02:05, 254.33 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35054/47780 [01:56<00:43, 295.07 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34176/47780 [01:56<00:56, 242.82 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33262/47780 [01:56<00:59, 244.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33491/47780 [01:56<00:55, 255.50 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33010/47780 [01:56<00:48, 306.40 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35026/47780 [01:56<00:52, 241.93 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34563/47780 [01:56<00:50, 261.94 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15978/47780 [01:56<02:00, 263.62 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35087/47780 [01:56<00:41, 304.80 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33292/47780 [01:56<00:56, 258.34 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34203/47780 [01:56<00:56, 242.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33517/47780 [01:56<01:00, 237.49 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33041/47780 [01:56<00:48, 303.67 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35074/47780 [01:56<00:43, 290.76 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34590/47780 [01:56<00:53, 247.71 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34229/47780 [01:56<00:55, 244.55 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35118/47780 [01:56<00:45, 277.60 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33320/47780 [01:56<00:59, 242.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33546/47780 [01:56<00:57, 249.59 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33073/47780 [01:56<00:48, 304.84 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 16005/47780 [01:56<02:25, 218.05 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35109/47780 [01:56<00:41, 306.10 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34616/47780 [01:56<00:54, 243.35 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35148/47780 [01:56<00:44, 283.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34254/47780 [01:56<00:55, 242.93 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33572/47780 [01:56<00:57, 246.99 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16054/47780 [01:56<01:51, 283.66 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33104/47780 [01:56<00:49, 299.33 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33345/47780 [01:56<01:05, 220.79 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35141/47780 [01:56<00:44, 281.01 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34281/47780 [01:56<00:55, 245.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35177/47780 [01:56<00:46, 272.51 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33599/47780 [01:56<00:56, 250.61 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33140/47780 [01:56<00:46, 313.07 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16085/47780 [01:56<01:53, 278.90 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33370/47780 [01:56<01:03, 225.99 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34641/47780 [01:56<01:04, 203.82 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35170/47780 [01:56<00:45, 279.55 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34306/47780 [01:56<00:55, 243.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35205/47780 [01:56<00:46, 269.51 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33627/47780 [01:56<00:55, 256.20 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16115/47780 [01:56<01:53, 278.39 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33172/47780 [01:56<00:47, 304.92 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34702/47780 [01:56<00:43, 302.03 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33394/47780 [01:56<01:07, 213.64 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35199/47780 [01:56<00:46, 272.71 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35238/47780 [01:56<00:44, 283.17 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34331/47780 [01:56<00:58, 229.75 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33655/47780 [01:56<00:53, 262.89 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33203/47780 [01:56<00:49, 296.01 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16145/47780 [01:56<01:59, 264.52 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33418/47780 [01:56<01:06, 216.09 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34736/47780 [01:56<00:44, 290.78 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35233/47780 [01:56<00:44, 284.37 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35267/47780 [01:56<00:44, 278.61 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34364/47780 [01:56<00:52, 257.61 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33682/47780 [01:56<00:56, 247.77 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16177/47780 [01:56<01:54, 276.29 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33444/47780 [01:56<01:04, 223.12 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33233/47780 [01:57<00:55, 264.24 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34768/47780 [01:56<00:47, 275.88 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35297/47780 [01:57<00:44, 281.71 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34391/47780 [01:57<00:52, 255.47 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35262/47780 [01:57<00:48, 259.75 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33708/47780 [01:57<00:57, 243.60 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33477/47780 [01:57<00:56, 251.49 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16206/47780 [01:57<01:56, 270.89 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34801/47780 [01:57<00:45, 286.48 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35329/47780 [01:57<00:43, 289.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33261/47780 [01:57<00:57, 252.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34417/47780 [01:57<00:53, 251.82 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35291/47780 [01:57<00:48, 258.00 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33748/47780 [01:57<00:48, 286.47 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33513/47780 [01:57<00:51, 279.63 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16234/47780 [01:57<01:57, 267.78 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35365/47780 [01:57<00:40, 309.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33289/47780 [01:57<00:56, 254.52 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34831/47780 [01:57<00:47, 275.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34445/47780 [01:57<00:52, 253.26 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35319/47780 [01:57<00:47, 261.01 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33778/47780 [01:57<00:48, 287.06 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33542/47780 [01:57<00:54, 262.84 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16262/47780 [01:57<02:06, 248.66 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33321/47780 [01:57<00:53, 269.24 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35397/47780 [01:57<00:41, 295.52 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34862/47780 [01:57<00:46, 278.75 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35348/47780 [01:57<00:46, 267.24 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34476/47780 [01:57<00:51, 260.47 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33809/47780 [01:57<00:48, 289.98 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33569/47780 [01:57<00:54, 260.86 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16291/47780 [01:57<02:02, 257.54 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35432/47780 [01:57<00:40, 303.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34891/47780 [01:57<00:46, 275.70 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35382/47780 [01:57<00:43, 286.20 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33349/47780 [01:57<00:55, 259.91 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34503/47780 [01:57<00:55, 241.34 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33839/47780 [01:57<00:51, 271.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16323/47780 [01:57<01:55, 271.74 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34922/47780 [01:57<00:45, 282.30 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35413/47780 [01:57<00:43, 286.46 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33596/47780 [01:57<01:00, 234.56 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35463/47780 [01:57<00:43, 282.74 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33377/47780 [01:57<00:58, 247.39 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34532/47780 [01:57<00:52, 254.25 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33867/47780 [01:57<00:54, 256.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16351/47780 [01:57<01:58, 264.85 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34958/47780 [01:57<00:42, 300.55 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35442/47780 [01:57<00:43, 284.29 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33621/47780 [01:57<01:01, 231.46 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33412/47780 [01:57<00:52, 274.62 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35493/47780 [01:57<00:43, 281.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34562/47780 [01:57<00:51, 258.62 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35473/47780 [01:57<00:42, 291.63 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16378/47780 [01:57<02:03, 255.16 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33894/47780 [01:57<00:59, 234.98 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33647/47780 [01:57<00:59, 237.54 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35522/47780 [01:57<00:43, 280.65 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33443/47780 [01:57<00:52, 275.18 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34591/47780 [01:57<00:50, 261.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34989/47780 [01:57<00:49, 256.71 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35504/47780 [01:57<00:41, 293.74 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33919/47780 [01:57<00:59, 233.87 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35552/47780 [01:57<00:42, 285.27 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16412/47780 [01:57<02:01, 258.50 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33471/47780 [01:57<00:52, 273.63 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34618/47780 [01:57<00:50, 260.96 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35027/47780 [01:57<00:44, 288.07 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33672/47780 [01:57<01:05, 214.00 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33952/47780 [01:57<00:53, 259.33 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35534/47780 [01:58<00:43, 282.58 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33503/47780 [01:58<00:50, 283.43 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16439/47780 [01:57<02:03, 254.47 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35581/47780 [01:58<00:45, 269.07 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34645/47780 [01:58<00:51, 257.48 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35059/47780 [01:57<00:43, 290.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33695/47780 [01:58<01:07, 209.64 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33981/47780 [01:58<00:52, 265.11 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35563/47780 [01:58<00:44, 277.51 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16465/47780 [01:58<02:06, 246.98 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34671/47780 [01:58<00:50, 257.86 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33533/47780 [01:58<00:52, 269.70 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35609/47780 [01:58<00:47, 257.69 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35090/47780 [01:58<00:45, 280.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33717/47780 [01:58<01:08, 205.26 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34008/47780 [01:58<00:53, 259.83 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35591/47780 [01:58<00:44, 272.56 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34706/47780 [01:58<00:46, 281.84 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16492/47780 [01:58<02:06, 247.90 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33561/47780 [01:58<00:52, 272.24 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35636/47780 [01:58<00:46, 260.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33743/47780 [01:58<01:06, 211.49 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35119/47780 [01:58<00:47, 265.96 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34035/47780 [01:58<00:53, 254.88 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35619/47780 [01:58<00:44, 271.59 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34738/47780 [01:58<00:44, 292.85 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16522/47780 [01:58<02:00, 259.31 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33601/47780 [01:58<00:47, 298.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35663/47780 [01:58<00:48, 249.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33769/47780 [01:58<01:02, 224.34 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35147/47780 [01:58<00:48, 261.34 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34062/47780 [01:58<00:53, 256.13 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35647/47780 [01:58<00:45, 267.49 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16554/47780 [01:58<01:53, 276.30 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34768/47780 [01:58<00:45, 286.21 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33637/47780 [01:58<00:45, 312.29 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35689/47780 [01:58<00:47, 252.61 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33792/47780 [01:58<01:03, 221.57 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35181/47780 [01:58<00:45, 278.13 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34091/47780 [01:58<00:52, 260.11 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35676/47780 [01:58<00:45, 268.20 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35723/47780 [01:58<00:43, 274.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16582/47780 [01:58<02:06, 245.90 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33669/47780 [01:58<00:49, 282.42 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34797/47780 [01:58<00:52, 246.33 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33815/47780 [01:58<01:05, 211.72 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35216/47780 [01:58<00:42, 292.90 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34125/47780 [01:58<00:49, 276.35 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35707/47780 [01:58<00:43, 276.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35755/47780 [01:58<00:42, 284.14 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16609/47780 [01:58<02:05, 249.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33703/47780 [01:58<00:47, 294.62 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34823/47780 [01:58<00:52, 247.68 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33838/47780 [01:58<01:04, 216.60 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35248/47780 [01:58<00:42, 293.85 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34154/47780 [01:58<00:48, 280.03 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35736/47780 [01:58<00:42, 280.68 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35792/47780 [01:58<00:38, 308.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16635/47780 [01:58<02:05, 249.08 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35279/47780 [01:58<00:41, 298.37 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33867/47780 [01:58<01:00, 230.78 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34852/47780 [01:58<00:52, 245.58 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33736/47780 [01:58<00:49, 282.64 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34184/47780 [01:58<00:49, 276.51 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35765/47780 [01:58<00:44, 267.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35824/47780 [01:58<00:40, 291.69 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16666/47780 [01:58<01:58, 261.63 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33892/47780 [01:58<00:59, 234.83 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34885/47780 [01:58<00:48, 268.13 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33767/47780 [01:58<00:48, 286.93 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35310/47780 [01:58<00:43, 284.70 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34213/47780 [01:58<00:48, 277.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35793/47780 [01:58<00:44, 268.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35857/47780 [01:59<00:39, 299.06 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16695/47780 [01:58<01:56, 266.62 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33797/47780 [01:59<00:48, 288.43 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33916/47780 [01:59<01:01, 226.08 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34913/47780 [01:59<00:49, 261.27 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35339/47780 [01:59<00:45, 274.23 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35821/47780 [01:59<00:44, 268.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34241/47780 [01:59<00:52, 259.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16729/47780 [01:59<01:48, 287.38 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35888/47780 [01:59<00:40, 291.91 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33827/47780 [01:59<00:48, 290.52 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33939/47780 [01:59<01:02, 222.04 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35368/47780 [01:59<00:45, 273.66 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35855/47780 [01:59<00:41, 286.22 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34940/47780 [01:59<00:53, 241.19 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34268/47780 [01:59<00:53, 251.17 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16759/47780 [01:59<01:51, 279.22 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33965/47780 [01:59<01:00, 227.34 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35919/47780 [01:59<00:44, 266.03 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33857/47780 [01:59<00:51, 271.56 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35884/47780 [01:59<00:41, 286.35 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34965/47780 [01:59<00:53, 240.64 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35396/47780 [01:59<00:47, 260.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34294/47780 [01:59<00:54, 248.21 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16788/47780 [01:59<01:51, 277.85 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35954/47780 [01:59<00:41, 286.56 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33988/47780 [01:59<01:01, 223.45 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33885/47780 [01:59<00:51, 268.06 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35915/47780 [01:59<00:40, 290.43 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34994/47780 [01:59<00:50, 251.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35423/47780 [01:59<00:50, 246.73 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16816/47780 [01:59<01:53, 272.60 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34319/47780 [01:59<01:00, 221.89 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35987/47780 [01:59<00:39, 298.29 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34011/47780 [01:59<01:01, 222.52 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35949/47780 [01:59<00:38, 304.70 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33918/47780 [01:59<00:49, 277.91 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35024/47780 [01:59<00:48, 261.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35453/47780 [01:59<00:47, 259.82 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16847/47780 [01:59<01:49, 282.02 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34347/47780 [01:59<00:57, 232.13 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35983/47780 [01:59<00:37, 311.52 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34034/47780 [01:59<01:03, 215.14 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33947/47780 [01:59<00:50, 276.03 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35051/47780 [01:59<00:48, 259.78 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36020/47780 [01:59<00:42, 273.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35484/47780 [01:59<00:45, 272.08 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16877/47780 [01:59<01:52, 275.51 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34379/47780 [01:59<00:53, 250.41 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36018/47780 [01:59<00:36, 322.71 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33980/47780 [01:59<00:47, 291.14 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36068/47780 [01:59<00:35, 326.72 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34058/47780 [01:59<01:06, 205.77 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35078/47780 [01:59<00:51, 244.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35515/47780 [01:59<00:44, 273.31 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34413/47780 [01:59<00:49, 271.93 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16905/47780 [01:59<01:54, 269.39 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36051/47780 [01:59<00:37, 313.76 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34083/47780 [01:59<01:02, 217.65 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34010/47780 [01:59<00:50, 272.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35103/47780 [01:59<00:52, 243.59 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35546/47780 [01:59<00:44, 276.37 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36102/47780 [01:59<00:40, 287.59 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16940/47780 [01:59<01:46, 290.50 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34454/47780 [01:59<00:43, 303.37 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34105/47780 [01:59<01:04, 213.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36083/47780 [01:59<00:40, 285.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35129/47780 [01:59<00:52, 242.71 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35574/47780 [01:59<00:45, 269.07 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 16972/47780 [01:59<01:43, 298.77 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34493/47780 [01:59<00:40, 324.21 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34038/47780 [01:59<01:00, 226.96 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34139/47780 [01:59<00:55, 246.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36114/47780 [02:00<00:40, 289.21 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35162/47780 [02:00<00:48, 262.43 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36134/47780 [02:00<00:47, 245.99 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35604/47780 [02:00<00:44, 270.62 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17004/47780 [02:00<01:43, 298.17 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34526/47780 [02:00<00:41, 321.68 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34102/47780 [02:00<00:42, 324.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34164/47780 [02:00<00:56, 242.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35189/47780 [02:00<00:47, 263.46 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35636/47780 [02:00<00:42, 282.54 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36144/47780 [02:00<00:42, 273.34 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17034/47780 [02:00<01:46, 288.78 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36161/47780 [02:00<00:52, 222.71 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34559/47780 [02:00<00:43, 303.34 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34138/47780 [02:00<00:44, 309.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34189/47780 [02:00<00:56, 238.72 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35219/47780 [02:00<00:46, 267.74 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35665/47780 [02:00<00:42, 282.41 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36173/47780 [02:00<00:42, 272.60 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17063/47780 [02:00<01:48, 282.55 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36234/47780 [02:00<00:34, 331.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34593/47780 [02:00<00:42, 310.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34213/47780 [02:00<00:57, 236.16 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34171/47780 [02:00<00:46, 295.74 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35250/47780 [02:00<00:46, 268.01 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36204/47780 [02:00<00:40, 282.67 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35694/47780 [02:00<00:44, 269.77 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17094/47780 [02:00<01:45, 290.27 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34625/47780 [02:00<00:44, 292.88 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36271/47780 [02:00<00:36, 315.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34238/47780 [02:00<00:56, 237.71 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36233/47780 [02:00<00:40, 281.86 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35279/47780 [02:00<00:47, 262.59 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34202/47780 [02:00<00:49, 276.90 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35727/47780 [02:00<00:42, 282.22 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17124/47780 [02:00<01:51, 274.22 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34656/47780 [02:00<00:44, 294.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36307/47780 [02:00<00:35, 320.31 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34263/47780 [02:00<00:58, 232.97 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35318/47780 [02:00<00:41, 297.91 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35759/47780 [02:00<00:41, 292.84 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34234/47780 [02:00<00:48, 281.93 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36262/47780 [02:00<00:45, 252.60 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17155/47780 [02:00<01:50, 277.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34686/47780 [02:00<00:47, 274.77 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36341/47780 [02:00<00:37, 304.08 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34287/47780 [02:00<01:03, 213.29 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35789/47780 [02:00<00:42, 281.66 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35349/47780 [02:00<00:43, 283.05 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36309/47780 [02:00<00:36, 310.28 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34263/47780 [02:00<00:52, 259.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17184/47780 [02:00<01:50, 275.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34719/47780 [02:00<00:45, 289.66 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36373/47780 [02:00<00:38, 297.68 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34310/47780 [02:00<01:02, 215.61 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35820/47780 [02:00<00:41, 286.62 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35378/47780 [02:00<00:45, 271.54 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34290/47780 [02:00<00:51, 259.71 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36342/47780 [02:00<00:38, 298.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17212/47780 [02:00<01:51, 273.04 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34749/47780 [02:00<00:47, 277.00 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36409/47780 [02:00<00:36, 313.23 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35849/47780 [02:00<00:43, 275.06 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34332/47780 [02:00<01:06, 201.34 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35406/47780 [02:00<00:47, 262.44 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36378/47780 [02:00<00:36, 312.43 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17248/47780 [02:00<01:43, 294.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34317/47780 [02:00<00:54, 246.69 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34778/47780 [02:00<00:47, 271.80 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35881/47780 [02:00<00:41, 284.45 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36442/47780 [02:01<00:39, 288.05 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35434/47780 [02:01<00:46, 267.15 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17279/47780 [02:01<01:43, 295.70 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36416/47780 [02:01<00:35, 323.77 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34353/47780 [02:01<01:09, 193.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34343/47780 [02:01<00:54, 245.08 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34808/47780 [02:01<00:46, 279.45 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36476/47780 [02:01<00:38, 295.43 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35464/47780 [02:01<00:44, 276.14 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35910/47780 [02:01<00:43, 270.17 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17309/47780 [02:01<01:43, 293.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36449/47780 [02:01<00:36, 314.58 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34373/47780 [02:01<01:13, 183.45 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34371/47780 [02:01<00:53, 249.14 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34839/47780 [02:01<00:46, 276.55 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35492/47780 [02:01<00:45, 271.26 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36507/47780 [02:01<00:38, 290.38 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35942/47780 [02:01<00:42, 281.43 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17351/47780 [02:01<01:33, 326.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36483/47780 [02:01<00:35, 321.18 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34409/47780 [02:01<00:58, 229.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34402/47780 [02:01<00:50, 262.98 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34867/47780 [02:01<00:47, 271.78 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35971/47780 [02:01<00:41, 283.56 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36540/47780 [02:01<00:38, 295.42 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17384/47780 [02:01<01:33, 326.43 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36532/47780 [02:01<00:31, 361.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35523/47780 [02:01<00:45, 266.90 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34440/47780 [02:01<00:45, 292.16 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34433/47780 [02:01<01:00, 220.66 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34895/47780 [02:01<00:50, 255.39 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36001/47780 [02:01<00:41, 285.31 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17417/47780 [02:01<01:35, 316.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35550/47780 [02:01<00:47, 258.96 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34470/47780 [02:01<00:45, 294.23 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36569/47780 [02:01<00:33, 339.30 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34456/47780 [02:01<01:02, 212.41 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36570/47780 [02:01<00:44, 254.47 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34921/47780 [02:01<00:51, 251.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36030/47780 [02:01<00:41, 281.88 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34501/47780 [02:01<00:44, 295.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35579/47780 [02:01<00:46, 261.82 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17449/47780 [02:01<01:41, 297.63 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36604/47780 [02:01<00:34, 325.84 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34478/47780 [02:01<01:03, 209.23 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36599/47780 [02:01<00:44, 253.24 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36059/47780 [02:01<00:41, 281.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34947/47780 [02:01<00:52, 243.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35606/47780 [02:01<00:46, 261.50 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34534/47780 [02:01<00:44, 298.52 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17480/47780 [02:01<01:42, 294.51 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36637/47780 [02:01<00:34, 320.32 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36626/47780 [02:01<00:43, 254.59 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34502/47780 [02:01<01:04, 206.28 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34973/47780 [02:01<00:52, 245.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36088/47780 [02:01<00:42, 278.33 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35639/47780 [02:01<00:43, 277.82 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34564/47780 [02:01<00:48, 273.75 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17510/47780 [02:01<01:54, 263.57 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34532/47780 [02:01<00:58, 226.65 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36654/47780 [02:01<00:44, 250.90 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36670/47780 [02:01<00:37, 296.34 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36122/47780 [02:01<00:39, 292.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34999/47780 [02:01<00:52, 243.53 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35667/47780 [02:01<00:46, 257.78 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34595/47780 [02:01<00:46, 280.71 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17543/47780 [02:01<01:48, 278.21 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34559/47780 [02:01<00:55, 238.42 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36680/47780 [02:01<00:44, 251.37 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36152/47780 [02:01<00:40, 290.63 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35037/47780 [02:01<00:45, 278.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36703/47780 [02:02<00:39, 279.06 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35698/47780 [02:02<00:44, 269.09 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34624/47780 [02:02<00:49, 268.42 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17572/47780 [02:02<01:49, 275.34 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34589/47780 [02:02<00:52, 251.32 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36706/47780 [02:02<00:45, 242.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36191/47780 [02:02<00:37, 313.07 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36733/47780 [02:02<00:40, 270.54 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35067/47780 [02:02<00:47, 266.59 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35727/47780 [02:02<00:45, 266.64 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34652/47780 [02:02<00:49, 265.69 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17607/47780 [02:02<01:46, 283.78 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36737/47780 [02:02<00:42, 260.73 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34616/47780 [02:02<00:55, 239.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36223/47780 [02:02<00:36, 314.75 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36761/47780 [02:02<00:40, 270.18 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35110/47780 [02:02<00:41, 308.20 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35755/47780 [02:02<00:44, 269.83 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34679/47780 [02:02<00:49, 266.40 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17641/47780 [02:02<01:40, 298.82 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36770/47780 [02:02<00:40, 274.22 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34653/47780 [02:02<00:48, 269.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36255/47780 [02:02<00:38, 302.46 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35145/47780 [02:02<00:40, 312.91 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36789/47780 [02:02<00:41, 263.79 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35786/47780 [02:02<00:42, 281.19 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34714/47780 [02:02<00:45, 287.39 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17672/47780 [02:02<01:42, 293.70 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34689/47780 [02:02<00:45, 285.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36297/47780 [02:02<00:34, 335.88 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36821/47780 [02:02<00:39, 276.59 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36799/47780 [02:02<00:45, 243.14 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35815/47780 [02:02<00:43, 275.65 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35177/47780 [02:02<00:43, 288.87 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34743/47780 [02:02<00:47, 275.44 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36331/47780 [02:02<00:34, 329.54 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34718/47780 [02:02<00:46, 279.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17702/47780 [02:02<01:51, 270.39 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36840/47780 [02:02<00:38, 286.45 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35847/47780 [02:02<00:41, 286.64 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36849/47780 [02:02<00:42, 257.51 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35207/47780 [02:02<00:44, 279.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34772/47780 [02:02<00:46, 279.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36368/47780 [02:02<00:33, 338.02 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17738/47780 [02:02<01:43, 290.61 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34757/47780 [02:02<00:42, 303.97 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36884/47780 [02:02<00:33, 327.93 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35879/47780 [02:02<00:40, 293.05 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36883/47780 [02:02<00:38, 279.52 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35237/47780 [02:02<00:44, 279.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34801/47780 [02:02<00:47, 272.88 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36404/47780 [02:02<00:33, 339.79 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17772/47780 [02:02<01:39, 300.82 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34788/47780 [02:02<00:44, 292.69 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36919/47780 [02:02<00:33, 319.82 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35918/47780 [02:02<00:37, 317.54 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36914/47780 [02:02<00:38, 284.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35268/47780 [02:02<00:44, 281.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36440/47780 [02:02<00:33, 341.62 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34829/47780 [02:02<00:52, 247.09 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34818/47780 [02:02<00:44, 290.15 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17803/47780 [02:02<01:46, 281.12 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35951/47780 [02:02<00:36, 321.11 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36952/47780 [02:02<00:36, 296.51 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36949/47780 [02:02<00:38, 284.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35297/47780 [02:02<00:45, 274.69 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36479/47780 [02:02<00:32, 343.69 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34857/47780 [02:02<00:51, 250.55 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35985/47780 [02:02<00:36, 322.94 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34848/47780 [02:02<00:48, 263.99 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17832/47780 [02:02<01:54, 260.86 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36993/47780 [02:03<00:33, 324.16 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35325/47780 [02:02<00:47, 264.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36983/47780 [02:03<00:40, 265.95 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36521/47780 [02:02<00:30, 365.19 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34885/47780 [02:03<00:50, 255.85 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37030/47780 [02:03<00:32, 332.27 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36019/47780 [02:03<00:39, 299.89 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34878/47780 [02:03<00:49, 262.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17859/47780 [02:03<02:04, 240.98 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35352/47780 [02:03<00:50, 247.04 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37011/47780 [02:03<00:41, 256.74 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34921/47780 [02:03<00:45, 281.56 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36558/47780 [02:03<00:33, 332.25 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37073/47780 [02:03<00:30, 352.08 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36050/47780 [02:03<00:39, 295.48 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34905/47780 [02:03<00:50, 256.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17897/47780 [02:03<01:50, 270.81 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34951/47780 [02:03<00:44, 285.26 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35377/47780 [02:03<00:54, 226.10 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37038/47780 [02:03<00:44, 240.46 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37109/47780 [02:03<00:30, 353.69 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36080/47780 [02:03<00:41, 284.25 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17928/47780 [02:03<01:46, 280.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36592/47780 [02:03<00:38, 290.28 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34931/47780 [02:03<00:54, 234.29 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34981/47780 [02:03<00:44, 286.43 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37063/47780 [02:03<00:44, 240.97 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35400/47780 [02:03<00:56, 220.28 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36633/47780 [02:03<00:34, 320.21 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36109/47780 [02:03<00:41, 279.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37145/47780 [02:03<00:33, 319.39 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17957/47780 [02:03<01:49, 271.22 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34966/47780 [02:03<00:48, 261.96 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35010/47780 [02:03<00:46, 276.13 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37090/47780 [02:03<00:43, 248.02 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35426/47780 [02:03<00:53, 229.54 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36138/47780 [02:03<00:43, 270.60 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17988/47780 [02:03<01:46, 279.30 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37194/47780 [02:03<00:29, 357.60 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36667/47780 [02:03<00:35, 311.65 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34993/47780 [02:03<00:50, 251.64 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37125/47780 [02:03<00:38, 273.24 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35039/47780 [02:03<00:49, 257.00 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35450/47780 [02:03<00:55, 221.48 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18019/47780 [02:03<01:45, 281.59 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36166/47780 [02:03<00:44, 258.93 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36700/47780 [02:03<00:37, 298.03 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35020/47780 [02:03<00:51, 249.88 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37231/47780 [02:03<00:32, 328.70 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35067/47780 [02:03<00:48, 259.96 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37153/47780 [02:03<00:40, 260.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35473/47780 [02:03<00:56, 216.61 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18050/47780 [02:03<01:43, 287.09 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36193/47780 [02:03<00:44, 259.35 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37266/47780 [02:03<00:32, 323.70 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35046/47780 [02:03<00:54, 232.83 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36732/47780 [02:03<00:40, 269.74 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35094/47780 [02:03<00:50, 251.32 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35498/47780 [02:03<00:54, 223.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37180/47780 [02:03<00:45, 232.28 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18081/47780 [02:03<01:41, 292.76 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36223/47780 [02:03<00:43, 267.64 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35070/47780 [02:03<00:55, 230.29 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35524/47780 [02:03<00:52, 233.62 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36761/47780 [02:03<00:41, 266.80 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37300/47780 [02:03<00:36, 288.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35120/47780 [02:03<00:54, 231.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37204/47780 [02:04<00:46, 229.45 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18114/47780 [02:03<01:39, 297.31 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36250/47780 [02:03<00:43, 265.34 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35558/47780 [02:03<00:46, 263.86 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35094/47780 [02:04<00:59, 213.95 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36791/47780 [02:03<00:41, 261.91 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37341/47780 [02:04<00:32, 318.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35144/47780 [02:04<00:54, 233.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18144/47780 [02:04<01:39, 296.98 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36279/47780 [02:04<00:42, 268.46 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37228/47780 [02:04<00:47, 220.70 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35585/47780 [02:04<00:50, 243.11 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36818/47780 [02:04<00:42, 258.12 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37375/47780 [02:04<00:33, 314.27 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35116/47780 [02:04<01:00, 208.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35169/47780 [02:04<00:54, 233.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18178/47780 [02:04<01:36, 306.40 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36306/47780 [02:04<00:44, 260.25 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37251/47780 [02:04<00:49, 214.09 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35198/47780 [02:04<00:50, 248.73 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35138/47780 [02:04<01:00, 209.63 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36845/47780 [02:04<00:42, 256.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37408/47780 [02:04<00:33, 312.14 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35610/47780 [02:04<00:52, 232.20 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18209/47780 [02:04<01:39, 296.43 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36344/47780 [02:04<00:39, 291.29 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37273/47780 [02:04<00:52, 201.45 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35224/47780 [02:04<00:50, 248.75 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37446/47780 [02:04<00:31, 327.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35163/47780 [02:04<00:59, 213.65 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35634/47780 [02:04<00:52, 231.91 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36871/47780 [02:04<00:44, 244.64 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18242/47780 [02:04<01:37, 303.30 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36374/47780 [02:04<00:40, 283.78 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37300/47780 [02:04<00:47, 218.88 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35252/47780 [02:04<00:49, 255.09 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37480/47780 [02:04<00:31, 326.57 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18277/47780 [02:04<01:34, 312.48 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35658/47780 [02:04<00:53, 226.21 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36896/47780 [02:04<00:45, 239.71 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35185/47780 [02:04<01:02, 200.09 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37325/47780 [02:04<00:46, 227.18 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36403/47780 [02:04<00:43, 258.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35278/47780 [02:04<00:50, 247.71 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36922/47780 [02:04<00:44, 243.27 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35684/47780 [02:04<00:52, 230.77 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18313/47780 [02:04<01:32, 319.26 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35208/47780 [02:04<01:01, 205.13 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37514/47780 [02:04<00:34, 294.24 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37349/47780 [02:04<00:47, 220.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36433/47780 [02:04<00:42, 267.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35305/47780 [02:04<00:50, 248.63 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18345/47780 [02:04<01:33, 316.05 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35708/47780 [02:04<00:52, 230.38 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36950/47780 [02:04<00:44, 243.78 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35231/47780 [02:04<00:59, 210.41 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37545/47780 [02:04<00:34, 295.04 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37372/47780 [02:04<00:47, 220.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36466/47780 [02:04<00:40, 279.87 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35341/47780 [02:04<00:45, 270.96 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36975/47780 [02:04<00:44, 243.65 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35256/47780 [02:04<00:57, 218.69 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35734/47780 [02:04<00:52, 228.91 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18377/47780 [02:04<01:38, 299.79 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36495/47780 [02:04<00:40, 280.66 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37395/47780 [02:04<00:49, 211.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37576/47780 [02:04<00:38, 264.91 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35370/47780 [02:04<00:45, 270.25 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35759/47780 [02:04<00:51, 232.17 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18408/47780 [02:04<01:40, 292.43 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35279/47780 [02:04<01:00, 207.91 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37001/47780 [02:04<00:48, 221.22 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37426/47780 [02:05<00:45, 226.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36524/47780 [02:04<00:43, 260.59 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35403/47780 [02:05<00:43, 285.71 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37604/47780 [02:05<00:42, 238.68 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35785/47780 [02:04<00:50, 237.40 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18438/47780 [02:04<01:40, 292.13 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35303/47780 [02:05<00:57, 216.72 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37024/47780 [02:05<00:49, 219.21 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37453/47780 [02:05<00:43, 236.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36553/47780 [02:05<00:42, 265.67 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35434/47780 [02:05<00:42, 292.26 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37674/47780 [02:05<00:28, 351.54 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35810/47780 [02:05<00:50, 237.75 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18468/47780 [02:05<01:41, 290.18 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35325/47780 [02:05<01:01, 203.86 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37051/47780 [02:05<00:46, 230.37 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37486/47780 [02:05<00:39, 258.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36580/47780 [02:05<00:42, 261.89 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35839/47780 [02:05<00:47, 252.63 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35464/47780 [02:05<00:44, 277.62 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18508/47780 [02:05<01:31, 319.33 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37714/47780 [02:05<00:29, 340.26 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37076/47780 [02:05<00:45, 234.78 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35346/47780 [02:05<01:03, 195.04 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37515/47780 [02:05<00:38, 267.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36610/47780 [02:05<00:41, 272.29 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35867/47780 [02:05<00:46, 258.27 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35494/47780 [02:05<00:46, 262.31 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18541/47780 [02:05<01:35, 306.57 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37751/47780 [02:05<00:31, 318.75 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37102/47780 [02:05<00:46, 229.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35366/47780 [02:05<01:06, 186.25 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36638/47780 [02:05<00:41, 268.14 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37544/47780 [02:05<00:39, 259.02 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35893/47780 [02:05<00:47, 248.23 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18582/47780 [02:05<01:30, 321.03 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37132/47780 [02:05<00:43, 246.65 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35522/47780 [02:05<00:50, 241.31 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36670/47780 [02:05<00:39, 282.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35391/47780 [02:05<01:01, 201.20 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37580/47780 [02:05<00:35, 283.89 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37785/47780 [02:05<00:34, 292.53 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35930/47780 [02:05<00:42, 281.81 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18619/47780 [02:05<01:28, 328.32 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35548/47780 [02:05<00:49, 244.96 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37157/47780 [02:05<00:44, 236.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35416/47780 [02:05<00:57, 214.42 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37617/47780 [02:05<00:33, 304.95 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36700/47780 [02:05<00:40, 274.72 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35963/47780 [02:05<00:40, 292.36 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37816/47780 [02:05<00:36, 273.09 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18654/47780 [02:05<01:28, 329.81 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37190/47780 [02:05<00:40, 262.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35576/47780 [02:05<00:48, 250.36 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36728/47780 [02:05<00:40, 272.08 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35438/47780 [02:05<01:00, 203.76 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35995/47780 [02:05<00:40, 293.53 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37855/47780 [02:05<00:33, 297.33 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18690/47780 [02:05<01:27, 331.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35602/47780 [02:05<00:48, 253.00 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35459/47780 [02:05<01:00, 204.23 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37648/47780 [02:05<00:43, 232.20 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37217/47780 [02:05<00:42, 250.26 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36765/47780 [02:05<00:38, 288.06 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37891/47780 [02:05<00:31, 309.43 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36025/47780 [02:05<00:42, 276.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18725/47780 [02:05<01:27, 333.11 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37245/47780 [02:05<00:41, 253.37 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35481/47780 [02:05<00:59, 206.33 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37695/47780 [02:05<00:34, 288.23 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35628/47780 [02:05<00:51, 233.88 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36794/47780 [02:05<00:38, 282.23 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37930/47780 [02:06<00:30, 328.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36053/47780 [02:05<00:42, 274.09 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18761/47780 [02:05<01:32, 315.17 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37280/47780 [02:05<00:37, 280.21 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35506/47780 [02:06<00:56, 218.59 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37728/47780 [02:06<00:34, 290.06 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36823/47780 [02:06<00:40, 272.29 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35652/47780 [02:06<00:54, 220.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37964/47780 [02:06<00:31, 311.14 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35531/47780 [02:06<00:54, 225.23 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37309/47780 [02:06<00:37, 276.62 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36081/47780 [02:06<00:50, 231.39 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35675/47780 [02:06<00:54, 222.71 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37760/47780 [02:06<00:35, 281.50 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18793/47780 [02:06<01:42, 282.73 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36851/47780 [02:06<00:43, 253.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37996/47780 [02:06<00:31, 306.97 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35556/47780 [02:06<00:53, 229.34 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37337/47780 [02:06<00:40, 257.01 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18829/47780 [02:06<01:35, 302.75 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35698/47780 [02:06<00:55, 218.46 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36107/47780 [02:06<00:53, 218.81 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37790/47780 [02:06<00:37, 263.07 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38028/47780 [02:06<00:32, 303.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36877/47780 [02:06<00:46, 233.65 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35593/47780 [02:06<00:45, 267.52 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18863/47780 [02:06<01:34, 306.09 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35721/47780 [02:06<00:55, 215.88 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37364/47780 [02:06<00:43, 240.49 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37820/47780 [02:06<00:37, 267.28 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36130/47780 [02:06<00:56, 205.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36910/47780 [02:06<00:42, 257.28 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38059/47780 [02:06<00:34, 283.62 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35620/47780 [02:06<00:47, 253.36 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18903/47780 [02:06<01:28, 325.40 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35747/47780 [02:06<00:53, 226.55 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37852/47780 [02:06<00:35, 278.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37389/47780 [02:06<00:45, 227.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36152/47780 [02:06<00:56, 205.41 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38088/47780 [02:06<00:35, 273.20 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36937/47780 [02:06<00:45, 238.84 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35646/47780 [02:06<00:48, 252.54 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18939/47780 [02:06<01:27, 330.56 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35770/47780 [02:06<00:54, 220.18 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37414/47780 [02:06<00:44, 231.50 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36173/47780 [02:06<00:58, 197.63 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38119/47780 [02:06<00:34, 280.44 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36966/47780 [02:06<00:43, 249.60 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37881/47780 [02:06<00:40, 244.18 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35673/47780 [02:06<00:51, 234.31 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18974/47780 [02:06<01:29, 321.49 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35794/47780 [02:06<00:55, 215.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37439/47780 [02:06<00:45, 228.84 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36994/47780 [02:06<00:42, 255.07 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38148/47780 [02:06<00:35, 273.64 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37907/47780 [02:06<00:41, 238.01 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36194/47780 [02:06<01:04, 180.38 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35702/47780 [02:06<00:48, 247.24 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35816/47780 [02:06<00:59, 200.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37473/47780 [02:06<00:40, 253.53 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19007/47780 [02:06<01:39, 288.68 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37029/47780 [02:06<00:38, 278.18 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37940/47780 [02:06<00:37, 259.66 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38176/47780 [02:06<00:36, 260.26 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36217/47780 [02:06<01:00, 189.62 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35728/47780 [02:06<00:50, 240.41 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35851/47780 [02:06<00:49, 239.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37500/47780 [02:06<00:40, 256.21 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37069/47780 [02:06<00:34, 308.77 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37967/47780 [02:07<00:38, 253.47 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19038/47780 [02:06<01:51, 256.94 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38204/47780 [02:07<00:37, 255.66 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36237/47780 [02:06<01:04, 178.82 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37529/47780 [02:07<00:38, 264.71 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35753/47780 [02:07<00:53, 224.19 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35876/47780 [02:07<00:50, 234.40 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37104/47780 [02:07<00:33, 316.95 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37996/47780 [02:07<00:38, 255.97 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19078/47780 [02:07<01:39, 287.96 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38230/47780 [02:07<00:38, 248.84 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36258/47780 [02:07<01:03, 181.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37559/47780 [02:07<00:37, 273.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35786/47780 [02:07<00:48, 249.06 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35903/47780 [02:07<00:49, 238.93 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37139/47780 [02:07<00:33, 318.98 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38028/47780 [02:07<00:36, 268.15 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19109/47780 [02:07<01:39, 287.51 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38256/47780 [02:07<00:38, 249.10 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36279/47780 [02:07<01:02, 185.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37587/47780 [02:07<00:37, 273.45 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35812/47780 [02:07<00:50, 237.25 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35932/47780 [02:07<00:48, 244.90 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37172/47780 [02:07<00:34, 311.41 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19139/47780 [02:07<01:41, 283.01 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38282/47780 [02:07<00:38, 243.99 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38056/47780 [02:07<00:37, 256.52 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36300/47780 [02:07<01:00, 190.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37617/47780 [02:07<00:36, 280.94 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35965/47780 [02:07<00:44, 268.52 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35842/47780 [02:07<00:47, 251.26 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37204/47780 [02:07<00:36, 293.67 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19175/47780 [02:07<01:35, 300.71 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38308/47780 [02:07<00:38, 245.78 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38087/47780 [02:07<00:36, 268.34 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36320/47780 [02:07<01:01, 186.09 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37650/47780 [02:07<00:35, 288.76 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35876/47780 [02:07<00:44, 266.87 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35993/47780 [02:07<00:46, 254.29 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19206/47780 [02:07<01:35, 299.38 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38115/47780 [02:07<00:36, 268.31 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38336/47780 [02:07<00:38, 247.11 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37234/47780 [02:07<00:39, 267.19 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36342/47780 [02:07<00:59, 193.45 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37679/47780 [02:07<00:39, 257.40 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36020/47780 [02:07<00:47, 247.91 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35903/47780 [02:07<00:48, 243.28 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19241/47780 [02:07<01:32, 309.33 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38143/47780 [02:07<00:35, 271.35 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38368/47780 [02:07<00:35, 264.50 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37265/47780 [02:07<00:37, 278.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36369/47780 [02:07<00:53, 212.09 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37706/47780 [02:07<00:38, 259.67 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36048/47780 [02:07<00:47, 248.41 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35928/47780 [02:07<00:49, 237.86 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19285/47780 [02:07<01:22, 344.83 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37294/47780 [02:07<00:37, 280.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36391/47780 [02:07<00:53, 214.24 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38175/47780 [02:07<00:36, 261.07 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38395/47780 [02:07<00:38, 240.90 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37733/47780 [02:07<00:40, 248.84 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35954/47780 [02:07<00:49, 238.64 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36074/47780 [02:07<00:49, 238.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19320/47780 [02:07<01:27, 326.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37336/47780 [02:07<00:33, 309.45 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36415/47780 [02:07<00:53, 212.08 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38420/47780 [02:07<00:39, 238.54 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38202/47780 [02:07<00:38, 248.09 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37759/47780 [02:07<00:40, 248.61 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36100/47780 [02:07<00:48, 241.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35980/47780 [02:07<00:49, 236.56 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37368/47780 [02:07<00:34, 301.65 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36457/47780 [02:07<00:42, 267.59 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19354/47780 [02:07<01:34, 300.38 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38229/47780 [02:08<00:38, 251.15 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38445/47780 [02:08<00:42, 217.96 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36126/47780 [02:08<00:48, 241.21 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36010/47780 [02:08<00:46, 251.18 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37786/47780 [02:08<00:43, 228.50 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37400/47780 [02:08<00:34, 304.79 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36487/47780 [02:08<00:41, 274.01 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38261/47780 [02:08<00:35, 269.97 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38473/47780 [02:08<00:39, 233.94 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19385/47780 [02:08<01:43, 274.22 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36154/47780 [02:08<00:46, 251.99 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36037/47780 [02:08<00:46, 253.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37811/47780 [02:08<00:43, 230.14 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37431/47780 [02:08<00:33, 305.49 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38293/47780 [02:08<00:33, 281.12 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36515/47780 [02:08<00:43, 259.09 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38501/47780 [02:08<00:37, 246.36 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19421/47780 [02:08<01:35, 295.77 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36184/47780 [02:08<00:45, 254.58 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36063/47780 [02:08<00:46, 249.77 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37841/47780 [02:08<00:41, 241.34 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37463/47780 [02:08<00:34, 299.46 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38325/47780 [02:08<00:33, 285.60 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19452/47780 [02:08<01:34, 299.45 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36542/47780 [02:08<00:46, 244.12 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38527/47780 [02:08<00:39, 234.78 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37868/47780 [02:08<00:39, 249.05 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36210/47780 [02:08<00:47, 245.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36089/47780 [02:08<00:47, 245.05 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37508/47780 [02:08<00:30, 338.24 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38354/47780 [02:08<00:34, 271.42 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19488/47780 [02:08<01:30, 312.77 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36567/47780 [02:08<00:46, 240.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38551/47780 [02:08<00:39, 236.10 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36114/47780 [02:08<00:49, 234.06 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37894/47780 [02:08<00:41, 236.02 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36235/47780 [02:08<00:49, 230.99 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37542/47780 [02:08<00:31, 327.43 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38385/47780 [02:08<00:33, 281.98 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19520/47780 [02:08<01:33, 301.33 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36592/47780 [02:08<00:48, 228.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38575/47780 [02:08<00:40, 229.24 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37918/47780 [02:08<00:41, 235.33 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36139/47780 [02:08<00:49, 234.20 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36259/47780 [02:08<00:51, 223.73 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37577/47780 [02:08<00:32, 315.49 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19551/47780 [02:08<01:33, 303.50 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38416/47780 [02:08<00:34, 268.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38601/47780 [02:08<00:38, 235.50 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37946/47780 [02:08<00:39, 247.34 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36169/47780 [02:08<00:46, 247.39 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36282/47780 [02:08<00:51, 222.95 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36616/47780 [02:08<00:58, 192.24 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37609/47780 [02:08<00:34, 297.52 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38444/47780 [02:08<00:36, 257.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19582/47780 [02:08<01:38, 285.28 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38625/47780 [02:08<00:43, 212.44 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36194/47780 [02:08<00:47, 245.32 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37981/47780 [02:08<00:36, 270.41 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36305/47780 [02:08<00:53, 213.48 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36643/47780 [02:08<00:54, 205.04 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37640/47780 [02:08<00:34, 294.25 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19611/47780 [02:08<01:39, 284.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38472/47780 [02:08<00:36, 252.48 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36220/47780 [02:08<00:46, 249.27 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38658/47780 [02:08<00:38, 236.52 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38009/47780 [02:08<00:37, 264.04 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36672/47780 [02:08<00:50, 221.87 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37670/47780 [02:08<00:35, 286.61 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19642/47780 [02:08<01:38, 284.26 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38500/47780 [02:09<00:36, 257.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36327/47780 [02:09<01:01, 186.58 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38690/47780 [02:09<00:35, 258.83 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36247/47780 [02:09<00:46, 246.89 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38040/47780 [02:09<00:36, 264.73 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36696/47780 [02:09<00:51, 215.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37699/47780 [02:09<00:36, 278.02 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36354/47780 [02:09<00:56, 203.43 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38526/47780 [02:09<00:39, 232.30 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36272/47780 [02:09<00:47, 242.92 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38717/47780 [02:09<00:36, 250.87 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19671/47780 [02:09<01:52, 249.39 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38068/47780 [02:09<00:36, 266.14 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36719/47780 [02:09<00:51, 214.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37728/47780 [02:09<00:35, 279.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36375/47780 [02:09<00:55, 204.91 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38552/47780 [02:09<00:38, 237.28 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19708/47780 [02:09<01:40, 278.63 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38749/47780 [02:09<00:34, 263.07 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36297/47780 [02:09<00:49, 232.27 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38095/47780 [02:09<00:39, 242.63 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36741/47780 [02:09<00:52, 211.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37757/47780 [02:09<00:37, 263.79 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36396/47780 [02:09<00:57, 198.58 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38776/47780 [02:09<00:34, 257.66 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19746/47780 [02:09<01:34, 296.28 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36321/47780 [02:09<00:49, 231.57 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38577/47780 [02:09<00:42, 218.67 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38125/47780 [02:09<00:38, 250.18 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36763/47780 [02:09<00:52, 211.76 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37784/47780 [02:09<00:38, 259.10 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36423/47780 [02:09<00:52, 214.95 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19780/47780 [02:09<01:34, 295.32 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38600/47780 [02:09<00:41, 220.06 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38802/47780 [02:09<00:38, 234.83 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36346/47780 [02:09<00:52, 216.38 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36785/47780 [02:09<00:51, 211.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38157/47780 [02:09<00:36, 263.38 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37811/47780 [02:09<00:38, 259.97 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36445/47780 [02:09<00:55, 202.89 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19819/47780 [02:09<01:28, 317.53 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38637/47780 [02:09<00:35, 257.75 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38843/47780 [02:09<00:31, 281.06 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36370/47780 [02:09<00:51, 220.34 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36809/47780 [02:09<00:50, 217.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38184/47780 [02:09<00:36, 262.32 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37838/47780 [02:09<00:39, 249.43 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36476/47780 [02:09<00:49, 226.91 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19855/47780 [02:09<01:25, 325.69 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38664/47780 [02:09<00:36, 252.39 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36402/47780 [02:09<00:45, 247.43 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38873/47780 [02:09<00:32, 277.28 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36838/47780 [02:09<00:46, 237.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38217/47780 [02:09<00:34, 278.08 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37867/47780 [02:09<00:38, 254.27 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36502/47780 [02:09<00:49, 229.19 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19888/47780 [02:09<01:27, 317.22 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38909/47780 [02:09<00:29, 296.86 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38690/47780 [02:09<00:36, 246.58 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36428/47780 [02:09<00:47, 237.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38250/47780 [02:09<00:33, 282.14 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36862/47780 [02:09<00:48, 222.98 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37902/47780 [02:09<00:35, 276.08 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36526/47780 [02:09<00:50, 222.10 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19939/47780 [02:09<01:15, 370.02 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38722/47780 [02:09<00:35, 258.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38944/47780 [02:09<00:29, 298.21 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36453/47780 [02:09<00:49, 228.84 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38279/47780 [02:09<00:34, 273.84 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36885/47780 [02:09<00:49, 219.89 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37937/47780 [02:09<00:33, 292.32 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19979/47780 [02:09<01:13, 378.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36550/47780 [02:10<00:50, 222.91 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38311/47780 [02:10<00:33, 282.62 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36908/47780 [02:10<00:49, 219.93 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38749/47780 [02:10<00:37, 240.36 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36480/47780 [02:10<00:50, 225.27 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38975/47780 [02:10<00:32, 271.42 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37967/47780 [02:10<00:33, 290.74 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20018/47780 [02:10<01:16, 365.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36573/47780 [02:10<00:54, 207.31 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36932/47780 [02:10<00:48, 225.33 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38774/47780 [02:10<00:38, 235.28 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36503/47780 [02:10<00:50, 224.11 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39006/47780 [02:10<00:31, 280.14 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38340/47780 [02:10<00:35, 263.99 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37997/47780 [02:10<00:35, 277.79 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20055/47780 [02:10<01:19, 350.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36594/47780 [02:10<00:55, 201.86 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36963/47780 [02:10<00:44, 244.82 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39041/47780 [02:10<00:29, 295.68 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38798/47780 [02:10<00:39, 229.24 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36526/47780 [02:10<00:51, 218.25 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38026/47780 [02:10<00:34, 280.93 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38368/47780 [02:10<00:37, 250.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20091/47780 [02:10<01:22, 336.87 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36615/47780 [02:10<00:56, 197.62 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36995/47780 [02:10<00:41, 260.33 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39072/47780 [02:10<00:29, 293.69 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36548/47780 [02:10<00:52, 214.45 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38057/47780 [02:10<00:33, 287.96 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38822/47780 [02:10<00:41, 213.59 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38394/47780 [02:10<00:39, 238.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20128/47780 [02:10<01:21, 341.14 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39103/47780 [02:10<00:29, 293.04 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36576/47780 [02:10<00:49, 225.94 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36635/47780 [02:10<01:03, 175.36 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37022/47780 [02:10<00:46, 232.63 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38845/47780 [02:10<00:41, 215.57 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38425/47780 [02:10<00:37, 252.63 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38086/47780 [02:10<00:38, 254.44 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20163/47780 [02:10<01:23, 331.12 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39133/47780 [02:10<00:29, 291.66 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36657/47780 [02:10<00:59, 186.78 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36603/47780 [02:10<00:48, 232.07 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37046/47780 [02:10<00:46, 232.60 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38456/47780 [02:10<00:35, 265.17 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38117/47780 [02:10<00:36, 266.65 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38867/47780 [02:10<00:45, 193.82 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20197/47780 [02:10<01:25, 324.07 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39163/47780 [02:10<00:29, 288.62 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36627/47780 [02:10<00:48, 228.90 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36677/47780 [02:10<01:01, 180.62 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37070/47780 [02:10<00:47, 227.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38483/47780 [02:10<00:35, 260.82 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38895/47780 [02:10<00:41, 215.88 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38145/47780 [02:10<00:36, 261.77 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20230/47780 [02:10<01:26, 317.67 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39200/47780 [02:10<00:27, 310.66 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36653/47780 [02:10<00:47, 235.36 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36706/47780 [02:10<00:53, 207.84 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38514/47780 [02:10<00:34, 265.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37094/47780 [02:10<00:50, 211.01 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38918/47780 [02:10<00:42, 206.38 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20276/47780 [02:10<01:17, 355.74 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38172/47780 [02:10<00:39, 240.28 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39232/47780 [02:10<00:27, 312.93 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36678/47780 [02:10<00:46, 239.32 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36731/47780 [02:10<00:51, 214.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38544/47780 [02:10<00:33, 274.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37116/47780 [02:10<00:50, 210.44 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38951/47780 [02:11<00:38, 231.77 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20312/47780 [02:10<01:20, 342.84 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38197/47780 [02:11<00:40, 234.95 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36714/47780 [02:11<00:40, 271.29 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39267/47780 [02:11<00:28, 302.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36754/47780 [02:11<00:50, 218.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38572/47780 [02:11<00:34, 267.55 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37138/47780 [02:11<00:51, 204.98 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20349/47780 [02:11<01:18, 350.24 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38975/47780 [02:11<00:38, 226.37 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38231/47780 [02:11<00:36, 260.77 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36744/47780 [02:11<00:39, 279.53 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39300/47780 [02:11<00:28, 300.64 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36777/47780 [02:11<00:52, 209.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38599/47780 [02:11<00:34, 265.17 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37166/47780 [02:11<00:47, 222.05 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20394/47780 [02:11<01:13, 370.56 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38999/47780 [02:11<00:40, 218.55 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38259/47780 [02:11<00:38, 249.45 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39344/47780 [02:11<00:25, 332.20 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36774/47780 [02:11<00:40, 269.51 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36800/47780 [02:11<00:52, 210.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38628/47780 [02:11<00:33, 269.26 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37193/47780 [02:11<00:45, 234.80 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20432/47780 [02:11<01:15, 364.63 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39035/47780 [02:11<00:34, 256.49 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38286/47780 [02:11<00:37, 252.49 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36825/47780 [02:11<00:49, 221.77 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36802/47780 [02:11<00:42, 256.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39379/47780 [02:11<00:27, 309.45 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38665/47780 [02:11<00:31, 288.22 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37217/47780 [02:11<00:48, 217.29 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39064/47780 [02:11<00:33, 262.90 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20469/47780 [02:11<01:19, 342.72 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38323/47780 [02:11<00:33, 281.66 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36850/47780 [02:11<00:48, 227.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36831/47780 [02:11<00:41, 264.55 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39411/47780 [02:11<00:27, 300.88 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38694/47780 [02:11<00:34, 260.37 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37262/47780 [02:11<00:38, 271.45 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39091/47780 [02:11<00:34, 254.15 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38362/47780 [02:11<00:31, 301.81 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36859/47780 [02:11<00:40, 268.90 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36874/47780 [02:11<00:47, 228.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20504/47780 [02:11<01:26, 316.03 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39442/47780 [02:11<00:29, 286.32 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38725/47780 [02:11<00:33, 272.41 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37292/47780 [02:11<00:37, 278.70 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36902/47780 [02:11<00:45, 241.16 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38393/47780 [02:11<00:32, 287.97 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20538/47780 [02:11<01:25, 316.80 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39117/47780 [02:11<00:37, 233.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36888/47780 [02:11<00:41, 265.14 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39471/47780 [02:11<00:29, 283.76 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38754/47780 [02:11<00:33, 271.33 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36927/47780 [02:11<00:45, 240.15 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39142/47780 [02:11<00:36, 238.12 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36922/47780 [02:11<00:38, 283.93 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37321/47780 [02:11<00:42, 244.00 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38425/47780 [02:11<00:32, 290.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20571/47780 [02:11<01:27, 312.58 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39508/47780 [02:11<00:26, 307.32 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38782/47780 [02:11<00:33, 270.76 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37347/47780 [02:11<00:42, 247.45 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36953/47780 [02:11<00:37, 288.00 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20605/47780 [02:11<01:25, 317.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38465/47780 [02:11<00:29, 313.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39167/47780 [02:11<00:37, 232.29 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36952/47780 [02:11<00:47, 227.15 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39542/47780 [02:11<00:26, 315.85 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38810/47780 [02:11<00:34, 261.23 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36985/47780 [02:11<00:36, 296.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20646/47780 [02:11<01:19, 339.42 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36975/47780 [02:12<00:47, 227.70 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38497/47780 [02:12<00:31, 295.68 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37374/47780 [02:11<00:44, 233.78 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39191/47780 [02:12<00:39, 219.22 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39575/47780 [02:12<00:27, 294.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38839/47780 [02:12<00:33, 264.54 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36999/47780 [02:12<00:47, 228.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20682/47780 [02:12<01:21, 333.82 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37015/47780 [02:12<00:38, 281.52 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38528/47780 [02:12<00:31, 293.14 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39217/47780 [02:12<00:38, 225.20 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37398/47780 [02:12<00:47, 217.17 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39610/47780 [02:12<00:26, 307.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38870/47780 [02:12<00:32, 273.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37046/47780 [02:12<00:37, 288.28 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20717/47780 [02:12<01:21, 331.10 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37022/47780 [02:12<00:49, 218.95 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38558/47780 [02:12<00:32, 282.86 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39642/47780 [02:12<00:26, 305.41 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37421/47780 [02:12<00:48, 215.56 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39240/47780 [02:12<00:40, 208.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38898/47780 [02:12<00:35, 247.30 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20751/47780 [02:12<01:22, 325.92 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37076/47780 [02:12<00:39, 268.42 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37045/47780 [02:12<00:51, 208.15 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38587/47780 [02:12<00:33, 272.83 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39673/47780 [02:12<00:26, 305.62 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37451/47780 [02:12<00:45, 229.10 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39262/47780 [02:12<00:42, 200.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38939/47780 [02:12<00:30, 290.64 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20788/47780 [02:12<01:20, 335.10 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37104/47780 [02:12<00:40, 266.47 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37066/47780 [02:12<00:52, 204.22 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38615/47780 [02:12<00:33, 270.36 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39704/47780 [02:12<00:27, 298.60 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37483/47780 [02:12<00:41, 248.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39288/47780 [02:12<00:41, 203.61 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38969/47780 [02:12<00:32, 274.95 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37136/47780 [02:12<00:38, 274.55 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20822/47780 [02:12<01:27, 307.80 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37089/47780 [02:12<00:52, 204.56 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39735/47780 [02:12<00:26, 301.77 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38643/47780 [02:12<00:35, 258.29 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37509/47780 [02:12<00:43, 233.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39317/47780 [02:12<00:37, 223.92 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38998/47780 [02:12<00:33, 262.06 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20855/47780 [02:12<01:26, 311.04 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37166/47780 [02:12<00:39, 272.04 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39766/47780 [02:12<00:26, 300.24 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37115/47780 [02:12<00:50, 212.88 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38670/47780 [02:12<00:34, 260.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37534/47780 [02:12<00:43, 237.87 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39340/47780 [02:12<00:40, 209.69 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39025/47780 [02:12<00:33, 262.30 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39802/47780 [02:12<00:25, 312.88 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37195/47780 [02:12<00:40, 260.00 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37137/47780 [02:12<00:52, 201.08 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37564/47780 [02:12<00:40, 254.92 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20887/47780 [02:12<01:36, 279.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38697/47780 [02:12<00:38, 235.97 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39365/47780 [02:12<00:38, 220.23 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39053/47780 [02:12<00:34, 251.95 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37225/47780 [02:12<00:39, 268.15 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39834/47780 [02:12<00:27, 292.61 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37594/47780 [02:12<00:38, 264.61 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20929/47780 [02:12<01:26, 311.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37168/47780 [02:12<00:49, 212.64 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39388/47780 [02:12<00:38, 220.68 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38722/47780 [02:12<00:39, 228.41 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39079/47780 [02:12<00:35, 247.16 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37264/47780 [02:12<00:34, 301.72 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37621/47780 [02:12<00:38, 263.01 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20963/47780 [02:12<01:24, 315.88 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39864/47780 [02:13<00:28, 282.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37199/47780 [02:13<00:44, 237.78 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38749/47780 [02:13<00:38, 236.88 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39413/47780 [02:13<00:38, 218.91 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39104/47780 [02:13<00:36, 236.87 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37651/47780 [02:13<00:37, 273.41 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37295/47780 [02:13<00:36, 284.93 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20998/47780 [02:13<01:23, 319.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39893/47780 [02:13<00:28, 275.21 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38786/47780 [02:13<00:33, 270.13 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37224/47780 [02:13<00:45, 231.18 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39439/47780 [02:13<00:36, 227.73 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37328/47780 [02:13<00:35, 294.07 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21033/47780 [02:13<01:21, 327.99 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39137/47780 [02:13<00:34, 248.81 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39923/47780 [02:13<00:28, 279.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37679/47780 [02:13<00:39, 258.26 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37262/47780 [02:13<00:39, 265.99 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38815/47780 [02:13<00:33, 266.76 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39462/47780 [02:13<00:37, 221.13 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21067/47780 [02:13<01:20, 331.33 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39173/47780 [02:13<00:31, 276.14 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39952/47780 [02:13<00:28, 272.91 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37358/47780 [02:13<00:38, 273.95 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37706/47780 [02:13<00:41, 244.44 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38844/47780 [02:13<00:33, 267.25 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37289/47780 [02:13<00:41, 252.01 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39485/47780 [02:13<00:41, 200.11 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39981/47780 [02:13<00:28, 277.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21101/47780 [02:13<01:26, 308.74 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37732/47780 [02:13<00:41, 243.59 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39205/47780 [02:13<00:33, 254.33 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38871/47780 [02:13<00:34, 260.13 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37318/47780 [02:13<00:40, 260.80 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37386/47780 [02:13<00:41, 249.02 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39516/47780 [02:13<00:36, 227.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21135/47780 [02:13<01:24, 317.08 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40009/47780 [02:13<00:29, 263.51 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37757/47780 [02:13<00:42, 237.22 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37347/47780 [02:13<00:39, 265.19 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38898/47780 [02:13<00:34, 258.04 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39254/47780 [02:13<00:28, 303.88 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39544/47780 [02:13<00:34, 241.85 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37413/47780 [02:13<00:42, 241.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21175/47780 [02:13<01:18, 337.29 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40038/47780 [02:13<00:28, 270.86 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38930/47780 [02:13<00:32, 272.57 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39287/47780 [02:13<00:27, 306.09 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37374/47780 [02:13<00:41, 252.98 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37781/47780 [02:13<00:45, 218.74 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39574/47780 [02:13<00:32, 255.52 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37455/47780 [02:13<00:36, 279.61 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40066/47780 [02:13<00:28, 267.40 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21210/47780 [02:13<01:24, 315.37 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38958/47780 [02:13<00:33, 263.65 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37400/47780 [02:13<00:41, 252.00 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39319/47780 [02:13<00:28, 297.41 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37805/47780 [02:13<00:44, 222.20 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37485/47780 [02:13<00:36, 281.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39601/47780 [02:13<00:34, 240.46 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40095/47780 [02:13<00:28, 273.73 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21243/47780 [02:13<01:24, 312.85 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37427/47780 [02:13<00:40, 254.35 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37831/47780 [02:13<00:43, 229.96 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37518/47780 [02:13<00:35, 291.97 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38986/47780 [02:13<00:35, 250.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39350/47780 [02:13<00:29, 281.63 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39627/47780 [02:14<00:34, 233.09 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21277/47780 [02:13<01:22, 320.34 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40123/47780 [02:14<00:29, 260.49 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37453/47780 [02:14<00:41, 250.27 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39019/47780 [02:14<00:32, 270.09 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37549/47780 [02:14<00:35, 290.40 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37855/47780 [02:14<00:46, 213.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39379/47780 [02:14<00:30, 272.40 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39651/47780 [02:14<00:35, 227.32 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21310/47780 [02:14<01:22, 321.63 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40154/47780 [02:14<00:28, 271.49 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37481/47780 [02:14<00:40, 255.77 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39047/47780 [02:14<00:32, 269.86 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37580/47780 [02:14<00:35, 286.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39416/47780 [02:14<00:28, 295.60 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37877/47780 [02:14<00:48, 204.32 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39674/47780 [02:14<00:37, 216.67 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40185/47780 [02:14<00:27, 276.00 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37507/47780 [02:14<00:40, 255.72 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21343/47780 [02:14<01:30, 292.17 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39078/47780 [02:14<00:30, 281.18 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37612/47780 [02:14<00:34, 292.42 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37914/47780 [02:14<00:40, 243.38 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40222/47780 [02:14<00:25, 299.40 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39446/47780 [02:14<00:33, 250.34 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21380/47780 [02:14<01:24, 312.84 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39697/47780 [02:14<00:40, 200.77 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37533/47780 [02:14<00:41, 249.39 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39109/47780 [02:14<00:30, 284.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37649/47780 [02:14<00:32, 309.76 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37939/47780 [02:14<00:40, 240.39 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40257/47780 [02:14<00:25, 291.38 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39142/47780 [02:14<00:29, 295.93 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37558/47780 [02:14<00:42, 241.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21413/47780 [02:14<01:29, 294.45 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39718/47780 [02:14<00:44, 180.64 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37681/47780 [02:14<00:34, 293.49 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39473/47780 [02:14<00:37, 221.91 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37964/47780 [02:14<00:43, 227.61 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39174/47780 [02:14<00:28, 299.41 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40287/47780 [02:14<00:26, 283.56 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37585/47780 [02:14<00:41, 243.99 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21444/47780 [02:14<01:32, 283.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39785/47780 [02:14<00:26, 301.87 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39546/47780 [02:14<00:24, 338.72 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37711/47780 [02:14<00:35, 286.06 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37988/47780 [02:14<00:42, 230.90 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39205/47780 [02:14<00:29, 292.34 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40316/47780 [02:14<00:27, 270.53 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37611/47780 [02:14<00:42, 237.73 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21488/47780 [02:14<01:22, 318.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39824/47780 [02:14<00:24, 321.59 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38014/47780 [02:14<00:40, 238.76 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37740/47780 [02:14<00:37, 269.01 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39585/47780 [02:14<00:25, 324.90 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40344/47780 [02:14<00:27, 273.07 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39236/47780 [02:14<00:29, 290.68 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37635/47780 [02:14<00:43, 233.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21521/47780 [02:14<01:21, 321.39 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39859/47780 [02:14<00:25, 315.42 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38039/47780 [02:14<00:41, 236.85 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37770/47780 [02:14<00:36, 274.56 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39621/47780 [02:14<00:26, 304.05 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40375/47780 [02:14<00:26, 280.24 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37659/47780 [02:14<00:43, 234.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39276/47780 [02:14<00:27, 311.24 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21562/47780 [02:14<01:17, 338.64 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37805/47780 [02:14<00:34, 292.30 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39893/47780 [02:14<00:26, 299.38 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38067/47780 [02:14<00:40, 240.82 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39654/47780 [02:14<00:26, 307.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40404/47780 [02:15<00:26, 276.79 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21603/47780 [02:14<01:13, 355.04 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39313/47780 [02:14<00:26, 313.67 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37683/47780 [02:15<00:45, 221.12 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38095/47780 [02:15<00:38, 251.73 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39926/47780 [02:15<00:26, 298.34 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37835/47780 [02:15<00:35, 281.74 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39696/47780 [02:15<00:24, 329.46 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40433/47780 [02:15<00:26, 277.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39351/47780 [02:15<00:25, 331.86 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21639/47780 [02:15<01:15, 344.37 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37709/47780 [02:15<00:44, 227.13 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38128/47780 [02:15<00:35, 271.33 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37867/47780 [02:15<00:33, 292.29 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39960/47780 [02:15<00:25, 306.20 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39731/47780 [02:15<00:25, 311.93 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39391/47780 [02:15<00:24, 347.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40461/47780 [02:15<00:27, 265.91 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37732/47780 [02:15<00:44, 227.89 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21674/47780 [02:15<01:20, 323.85 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38158/47780 [02:15<00:34, 276.37 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37897/47780 [02:15<00:34, 286.65 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39992/47780 [02:15<00:26, 293.77 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39427/47780 [02:15<00:23, 351.20 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37767/47780 [02:15<00:38, 260.03 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39765/47780 [02:15<00:26, 304.80 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40488/47780 [02:15<00:28, 252.89 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21707/47780 [02:15<01:23, 312.38 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38186/47780 [02:15<00:36, 262.28 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40031/47780 [02:15<00:24, 316.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37926/47780 [02:15<00:37, 262.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39464/47780 [02:15<00:24, 345.12 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40518/47780 [02:15<00:27, 265.24 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37795/47780 [02:15<00:38, 262.14 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39797/47780 [02:15<00:27, 292.04 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21740/47780 [02:15<01:22, 317.11 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38219/47780 [02:15<00:33, 281.30 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40069/47780 [02:15<00:23, 333.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37953/47780 [02:15<00:38, 252.47 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37822/47780 [02:15<00:38, 261.65 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39499/47780 [02:15<00:25, 323.76 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39830/47780 [02:15<00:26, 298.90 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40545/47780 [02:15<00:28, 250.24 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21775/47780 [02:15<01:20, 322.79 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38248/47780 [02:15<00:34, 274.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40103/47780 [02:15<00:23, 328.52 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37979/47780 [02:15<00:41, 234.82 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40577/47780 [02:15<00:27, 265.88 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37849/47780 [02:15<00:40, 244.10 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39861/47780 [02:15<00:26, 294.74 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21808/47780 [02:15<01:22, 314.08 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39533/47780 [02:15<00:27, 298.39 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38276/47780 [02:15<00:35, 269.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40138/47780 [02:15<00:24, 306.35 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40606/47780 [02:15<00:26, 270.22 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39893/47780 [02:15<00:26, 300.80 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38003/47780 [02:15<00:43, 222.45 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37874/47780 [02:15<00:42, 234.69 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21840/47780 [02:15<01:24, 305.43 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39564/47780 [02:15<00:27, 296.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38304/47780 [02:15<00:36, 258.05 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40170/47780 [02:15<00:27, 275.42 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38036/47780 [02:15<00:39, 245.46 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40634/47780 [02:15<00:27, 260.69 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37900/47780 [02:15<00:42, 234.67 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21871/47780 [02:15<01:26, 299.77 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39595/47780 [02:15<00:28, 285.51 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39925/47780 [02:15<00:29, 268.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38338/47780 [02:15<00:34, 274.81 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40199/47780 [02:16<00:27, 278.27 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38064/47780 [02:15<00:38, 252.08 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40667/47780 [02:16<00:25, 274.37 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37924/47780 [02:15<00:41, 236.02 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21908/47780 [02:15<01:21, 316.24 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38367/47780 [02:15<00:33, 279.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39624/47780 [02:16<00:30, 270.31 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39953/47780 [02:15<00:30, 255.30 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40695/47780 [02:16<00:25, 275.79 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40228/47780 [02:16<00:28, 264.24 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38090/47780 [02:16<00:39, 243.75 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21943/47780 [02:16<01:22, 311.63 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38402/47780 [02:16<00:31, 298.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39984/47780 [02:16<00:29, 268.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37948/47780 [02:16<00:47, 206.98 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39652/47780 [02:16<00:31, 261.79 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38121/47780 [02:16<00:36, 261.58 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40255/47780 [02:16<00:29, 252.76 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21985/47780 [02:16<01:16, 338.16 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38433/47780 [02:16<00:31, 299.00 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40723/47780 [02:16<00:29, 241.24 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37973/47780 [02:16<00:45, 213.70 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39679/47780 [02:16<00:31, 258.37 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40012/47780 [02:16<00:29, 261.11 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40292/47780 [02:16<00:26, 283.66 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38148/47780 [02:16<00:38, 249.61 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38467/47780 [02:16<00:30, 307.27 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22021/47780 [02:16<01:17, 333.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40750/47780 [02:16<00:28, 246.53 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37995/47780 [02:16<00:46, 212.33 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39706/47780 [02:16<00:31, 255.98 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40039/47780 [02:16<00:34, 224.85 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40322/47780 [02:16<00:26, 281.57 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22055/47780 [02:16<01:16, 334.95 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38174/47780 [02:16<00:39, 241.92 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38498/47780 [02:16<00:30, 301.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40777/47780 [02:16<00:28, 247.17 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38018/47780 [02:16<00:47, 206.67 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39732/47780 [02:16<00:33, 241.17 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22089/47780 [02:16<01:17, 332.37 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38534/47780 [02:16<00:29, 314.49 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38201/47780 [02:16<00:39, 244.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40064/47780 [02:16<00:36, 214.23 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40803/47780 [02:16<00:28, 242.71 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40351/47780 [02:16<00:29, 253.36 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38042/47780 [02:16<00:46, 208.88 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39759/47780 [02:16<00:32, 248.93 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22126/47780 [02:16<01:14, 343.15 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38227/47780 [02:16<00:38, 245.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38566/47780 [02:16<00:30, 301.83 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40087/47780 [02:16<00:36, 211.78 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40378/47780 [02:16<00:29, 255.13 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40828/47780 [02:16<00:29, 234.44 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38065/47780 [02:16<00:45, 214.62 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39785/47780 [02:16<00:32, 246.57 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22162/47780 [02:16<01:15, 340.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38257/47780 [02:16<00:36, 258.31 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38597/47780 [02:16<00:31, 291.22 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40852/47780 [02:16<00:29, 235.93 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40405/47780 [02:16<00:29, 248.21 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38101/47780 [02:16<00:39, 247.43 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39810/47780 [02:16<00:34, 234.38 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40109/47780 [02:16<00:40, 187.10 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22197/47780 [02:16<01:15, 338.92 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38283/47780 [02:16<00:38, 247.51 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40880/47780 [02:16<00:28, 245.53 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40439/47780 [02:16<00:27, 270.23 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38128/47780 [02:16<00:39, 241.96 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40137/47780 [02:16<00:36, 207.75 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39834/47780 [02:16<00:35, 225.74 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38627/47780 [02:16<00:36, 249.18 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22231/47780 [02:16<01:16, 335.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38308/47780 [02:16<00:38, 245.42 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40470/47780 [02:17<00:26, 277.62 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38155/47780 [02:17<00:38, 248.58 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40159/47780 [02:16<00:36, 208.74 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40905/47780 [02:17<00:31, 219.23 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39860/47780 [02:17<00:34, 232.82 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38655/47780 [02:17<00:36, 251.83 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22266/47780 [02:17<01:15, 336.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38335/47780 [02:17<00:37, 252.20 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40499/47780 [02:17<00:27, 266.52 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40186/47780 [02:17<00:33, 224.96 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40932/47780 [02:17<00:29, 230.44 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38180/47780 [02:17<00:40, 234.79 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39890/47780 [02:17<00:32, 246.14 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38681/47780 [02:17<00:36, 252.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22303/47780 [02:17<01:14, 341.85 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38361/47780 [02:17<00:39, 237.83 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40526/47780 [02:17<00:28, 251.55 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38206/47780 [02:17<00:39, 241.65 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40956/47780 [02:17<00:30, 226.34 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38710/47780 [02:17<00:34, 261.25 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22341/47780 [02:17<01:12, 352.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39915/47780 [02:17<00:33, 231.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40210/47780 [02:17<00:38, 198.59 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38387/47780 [02:17<00:38, 241.53 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40553/47780 [02:17<00:28, 255.51 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40986/47780 [02:17<00:27, 245.90 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38231/47780 [02:17<00:40, 236.12 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38737/47780 [02:17<00:35, 257.94 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22377/47780 [02:17<01:11, 354.99 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39943/47780 [02:17<00:33, 235.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40233/47780 [02:17<00:36, 206.38 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38415/47780 [02:17<00:37, 249.74 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40584/47780 [02:17<00:27, 259.68 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38260/47780 [02:17<00:38, 250.32 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41012/47780 [02:17<00:28, 241.35 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38764/47780 [02:17<00:35, 256.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22413/47780 [02:17<01:12, 352.23 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40255/47780 [02:17<00:36, 203.68 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38441/47780 [02:17<00:38, 244.35 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39967/47780 [02:17<00:36, 214.32 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40612/47780 [02:17<00:27, 264.08 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38291/47780 [02:17<00:35, 265.18 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41042/47780 [02:17<00:26, 255.00 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22452/47780 [02:17<01:10, 359.17 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38792/47780 [02:17<00:36, 247.84 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40276/47780 [02:17<00:39, 190.92 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40644/47780 [02:17<00:25, 274.88 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38466/47780 [02:17<00:43, 215.77 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38318/47780 [02:17<00:36, 260.66 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41069/47780 [02:17<00:26, 248.93 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39989/47780 [02:17<00:42, 183.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22489/47780 [02:17<01:14, 338.12 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38819/47780 [02:17<00:36, 243.15 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40296/47780 [02:17<00:39, 189.25 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40673/47780 [02:17<00:25, 278.90 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38351/47780 [02:17<00:34, 277.31 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38489/47780 [02:17<00:45, 205.14 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41096/47780 [02:17<00:27, 240.66 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40022/47780 [02:17<00:36, 214.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22541/47780 [02:17<01:05, 385.20 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38852/47780 [02:17<00:34, 261.77 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40316/47780 [02:17<00:39, 186.73 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40709/47780 [02:17<00:23, 299.09 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38380/47780 [02:17<00:33, 280.29 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38518/47780 [02:17<00:41, 222.57 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40051/47780 [02:17<00:33, 231.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22580/47780 [02:17<01:05, 382.20 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41124/47780 [02:17<00:27, 245.52 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38880/47780 [02:17<00:33, 262.94 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40346/47780 [02:17<00:34, 217.05 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38409/47780 [02:17<00:33, 277.07 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40750/47780 [02:18<00:22, 313.05 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38541/47780 [02:17<00:41, 222.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22622/47780 [02:17<01:04, 392.98 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40076/47780 [02:18<00:33, 226.68 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38912/47780 [02:17<00:32, 270.86 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41149/47780 [02:18<00:29, 224.59 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40369/47780 [02:17<00:33, 218.19 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38437/47780 [02:18<00:33, 277.79 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38567/47780 [02:18<00:39, 232.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40782/47780 [02:18<00:23, 294.96 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38942/47780 [02:18<00:31, 278.82 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22662/47780 [02:18<01:08, 369.36 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40106/47780 [02:18<00:31, 240.08 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41187/47780 [02:18<00:25, 260.48 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40395/47780 [02:18<00:32, 230.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38597/47780 [02:18<00:36, 249.53 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40813/47780 [02:18<00:24, 288.01 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38972/47780 [02:18<00:31, 278.74 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22700/47780 [02:18<01:08, 364.18 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38466/47780 [02:18<00:38, 239.82 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40131/47780 [02:18<00:32, 236.02 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40420/47780 [02:18<00:32, 225.32 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41214/47780 [02:18<00:27, 237.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38623/47780 [02:18<00:36, 248.82 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38507/47780 [02:18<00:32, 284.40 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39005/47780 [02:18<00:30, 290.01 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40842/47780 [02:18<00:25, 275.81 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22741/47780 [02:18<01:08, 365.00 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40157/47780 [02:18<00:33, 226.43 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40445/47780 [02:18<00:31, 229.73 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41239/47780 [02:18<00:27, 239.14 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38649/47780 [02:18<00:36, 249.05 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39035/47780 [02:18<00:29, 292.87 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40870/47780 [02:18<00:25, 273.44 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38538/47780 [02:18<00:32, 280.25 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22779/47780 [02:18<01:10, 356.72 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40470/47780 [02:18<00:31, 230.27 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40186/47780 [02:18<00:33, 227.57 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41264/47780 [02:18<00:27, 233.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38676/47780 [02:18<00:36, 252.29 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39073/47780 [02:18<00:27, 314.60 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40898/47780 [02:18<00:25, 266.33 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38567/47780 [02:18<00:33, 276.54 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22815/47780 [02:18<01:10, 354.29 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40497/47780 [02:18<00:30, 240.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40212/47780 [02:18<00:32, 233.81 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38710/47780 [02:18<00:33, 271.18 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41288/47780 [02:18<00:31, 208.36 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39106/47780 [02:18<00:28, 304.75 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40928/47780 [02:18<00:25, 269.45 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22863/47780 [02:18<01:05, 381.32 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40522/47780 [02:18<00:30, 241.32 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38597/47780 [02:18<00:36, 251.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40236/47780 [02:18<00:34, 220.87 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38740/47780 [02:18<00:33, 267.58 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41324/47780 [02:18<00:26, 244.09 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39137/47780 [02:18<00:29, 289.86 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40955/47780 [02:18<00:26, 259.04 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40547/47780 [02:18<00:30, 237.99 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22902/47780 [02:18<01:10, 350.44 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40265/47780 [02:18<00:32, 234.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38623/47780 [02:18<00:37, 241.18 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38770/47780 [02:18<00:32, 276.57 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41350/47780 [02:18<00:26, 243.29 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39168/47780 [02:18<00:29, 295.25 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40982/47780 [02:18<00:27, 250.25 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40571/47780 [02:18<00:31, 231.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22938/47780 [02:18<01:10, 350.33 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40289/47780 [02:18<00:32, 231.03 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38657/47780 [02:18<00:35, 259.11 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38799/47780 [02:18<00:32, 277.19 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41375/47780 [02:19<00:26, 237.68 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39198/47780 [02:18<00:29, 293.86 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22977/47780 [02:18<01:09, 357.63 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41013/47780 [02:19<00:26, 255.42 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40595/47780 [02:18<00:33, 211.80 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38684/47780 [02:19<00:35, 258.84 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40324/47780 [02:19<00:29, 253.85 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38836/47780 [02:19<00:29, 300.59 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39228/47780 [02:19<00:29, 288.55 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41400/47780 [02:19<00:28, 225.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41040/47780 [02:19<00:26, 256.61 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23015/47780 [02:19<01:14, 333.72 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40617/47780 [02:19<00:34, 209.49 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38712/47780 [02:19<00:34, 259.32 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40358/47780 [02:19<00:26, 274.93 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38868/47780 [02:19<00:32, 274.29 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39257/47780 [02:19<00:29, 288.02 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41424/47780 [02:19<00:28, 222.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41066/47780 [02:19<00:26, 249.26 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23055/47780 [02:19<01:11, 347.87 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40646/47780 [02:19<00:31, 228.21 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38740/47780 [02:19<00:34, 258.63 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40387/47780 [02:19<00:27, 264.65 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38898/47780 [02:19<00:31, 278.36 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39286/47780 [02:19<00:30, 274.81 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41448/47780 [02:19<00:28, 220.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41095/47780 [02:19<00:25, 260.35 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23094/47780 [02:19<01:09, 355.63 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38770/47780 [02:19<00:33, 267.88 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40671/47780 [02:19<00:31, 225.42 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40414/47780 [02:19<00:27, 264.06 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38930/47780 [02:19<00:30, 287.84 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39314/47780 [02:19<00:31, 268.90 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41482/47780 [02:19<00:25, 250.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41125/47780 [02:19<00:24, 269.34 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23133/47780 [02:19<01:09, 357.18 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38808/47780 [02:19<00:30, 290.90 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40695/47780 [02:19<00:31, 224.20 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40443/47780 [02:19<00:27, 268.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38960/47780 [02:19<00:31, 283.13 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39341/47780 [02:19<00:34, 244.54 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41509/47780 [02:19<00:26, 239.71 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23171/47780 [02:19<01:08, 359.59 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41156/47780 [02:19<00:25, 256.93 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40473/47780 [02:19<00:26, 274.33 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40723/47780 [02:19<00:30, 229.43 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38838/47780 [02:19<00:34, 261.19 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38989/47780 [02:19<00:31, 276.30 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41535/47780 [02:19<00:26, 240.17 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23212/47780 [02:19<01:05, 373.48 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39373/47780 [02:19<00:32, 259.28 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41189/47780 [02:19<00:24, 270.90 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40747/47780 [02:19<00:30, 229.45 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38870/47780 [02:19<00:32, 275.61 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40501/47780 [02:19<00:29, 249.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39018/47780 [02:19<00:32, 267.38 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23255/47780 [02:19<01:04, 381.63 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39409/47780 [02:19<00:29, 280.52 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41564/47780 [02:19<00:25, 243.47 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40770/47780 [02:19<00:32, 217.85 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41218/47780 [02:19<00:26, 246.33 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40529/47780 [02:19<00:30, 237.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38899/47780 [02:19<00:35, 252.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23297/47780 [02:19<01:02, 392.62 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39045/47780 [02:19<00:37, 235.09 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41590/47780 [02:19<00:26, 234.95 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40794/47780 [02:19<00:31, 223.86 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39440/47780 [02:19<00:32, 254.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41244/47780 [02:19<00:26, 244.72 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38926/47780 [02:19<00:35, 248.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23342/47780 [02:19<01:00, 404.61 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40554/47780 [02:19<00:32, 222.30 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41623/47780 [02:20<00:24, 255.04 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40818/47780 [02:19<00:30, 228.27 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41269/47780 [02:20<00:26, 243.16 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39467/47780 [02:19<00:33, 246.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39070/47780 [02:20<00:43, 201.85 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38952/47780 [02:20<00:36, 241.51 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23384/47780 [02:20<01:03, 382.36 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40577/47780 [02:20<00:33, 213.23 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41649/47780 [02:20<00:24, 248.27 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40841/47780 [02:20<00:32, 216.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41299/47780 [02:20<00:25, 254.49 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38978/47780 [02:20<00:36, 241.37 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23423/47780 [02:20<01:03, 383.82 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39092/47780 [02:20<00:46, 186.45 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39495/47780 [02:20<00:38, 216.75 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40600/47780 [02:20<00:33, 215.43 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41676/47780 [02:20<00:24, 254.22 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41327/47780 [02:20<00:24, 260.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40868/47780 [02:20<00:30, 228.91 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39004/47780 [02:20<00:35, 243.85 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23462/47780 [02:20<01:03, 381.51 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39519/47780 [02:20<00:37, 218.61 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40625/47780 [02:20<00:32, 217.67 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39112/47780 [02:20<00:48, 179.53 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41359/47780 [02:20<00:23, 274.29 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40893/47780 [02:20<00:29, 231.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41702/47780 [02:20<00:26, 232.22 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39032/47780 [02:20<00:34, 251.03 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23503/47780 [02:20<01:03, 381.34 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40653/47780 [02:20<00:30, 234.35 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39542/47780 [02:20<00:39, 208.42 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41394/47780 [02:20<00:21, 292.61 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40919/47780 [02:20<00:28, 236.77 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39131/47780 [02:20<00:51, 169.04 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41726/47780 [02:20<00:26, 230.13 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23542/47780 [02:20<01:04, 374.85 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40677/47780 [02:20<00:30, 231.01 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39058/47780 [02:20<00:36, 236.52 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39612/47780 [02:20<00:24, 332.77 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41424/47780 [02:20<00:21, 294.73 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40946/47780 [02:20<00:28, 238.91 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39149/47780 [02:20<00:51, 168.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41752/47780 [02:20<00:26, 227.23 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23586/47780 [02:20<01:02, 389.45 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39686/47780 [02:20<00:18, 433.84 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39083/47780 [02:20<00:38, 227.29 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41457/47780 [02:20<00:20, 304.18 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40701/47780 [02:20<00:32, 218.78 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40971/47780 [02:20<00:28, 242.00 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39251/47780 [02:20<00:22, 383.99 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41775/47780 [02:20<00:27, 215.53 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40726/47780 [02:20<00:31, 227.27 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23627/47780 [02:20<01:06, 362.01 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41488/47780 [02:20<00:22, 283.20 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39106/47780 [02:20<00:41, 207.04 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39734/47780 [02:20<00:20, 396.86 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40996/47780 [02:20<00:31, 216.59 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41804/47780 [02:20<00:25, 234.17 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39294/47780 [02:20<00:25, 338.43 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23667/47780 [02:20<01:04, 372.20 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41519/47780 [02:20<00:21, 287.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40751/47780 [02:20<00:33, 208.08 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39128/47780 [02:20<00:43, 198.13 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41019/47780 [02:20<00:32, 209.19 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41828/47780 [02:20<00:27, 219.31 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23706/47780 [02:20<01:04, 375.03 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39777/47780 [02:20<00:23, 337.84 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39332/47780 [02:20<00:27, 304.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41549/47780 [02:21<00:22, 281.59 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40775/47780 [02:21<00:35, 199.55 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23753/47780 [02:21<01:00, 400.17 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41855/47780 [02:21<00:27, 216.24 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39149/47780 [02:21<00:49, 174.21 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39814/47780 [02:21<00:23, 340.17 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41041/47780 [02:21<00:37, 181.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41578/47780 [02:21<00:22, 280.81 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39366/47780 [02:21<00:28, 295.94 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40797/47780 [02:21<00:36, 191.87 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41882/47780 [02:21<00:25, 227.99 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39171/47780 [02:21<00:46, 185.27 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23795/47780 [02:21<01:01, 391.28 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41060/47780 [02:21<00:37, 179.63 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39851/47780 [02:21<00:24, 325.26 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41615/47780 [02:21<00:20, 296.07 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39398/47780 [02:21<00:29, 279.72 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40822/47780 [02:21<00:34, 201.78 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39192/47780 [02:21<00:45, 189.66 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41908/47780 [02:21<00:25, 226.84 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23835/47780 [02:21<01:03, 377.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41645/47780 [02:21<00:20, 293.53 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41079/47780 [02:21<00:39, 170.26 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39885/47780 [02:21<00:26, 299.20 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39428/47780 [02:21<00:30, 276.35 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40843/47780 [02:21<00:34, 199.61 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39214/47780 [02:21<00:43, 197.55 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41941/47780 [02:21<00:22, 254.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23874/47780 [02:21<01:04, 372.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41676/47780 [02:21<00:20, 291.92 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41101/47780 [02:21<00:36, 181.06 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39465/47780 [02:21<00:27, 297.70 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39917/47780 [02:21<00:27, 282.20 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39247/47780 [02:21<00:36, 231.82 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40873/47780 [02:21<00:31, 219.61 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41968/47780 [02:21<00:23, 250.21 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41707/47780 [02:21<00:20, 293.59 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41120/47780 [02:21<00:37, 179.65 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23912/47780 [02:21<01:11, 333.44 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39498/47780 [02:21<00:27, 299.78 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39947/47780 [02:21<00:28, 278.03 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39271/47780 [02:21<00:37, 226.45 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40906/47780 [02:21<00:28, 244.37 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41994/47780 [02:21<00:24, 237.36 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41747/47780 [02:21<00:19, 313.46 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41144/47780 [02:21<00:33, 195.81 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23947/47780 [02:21<01:11, 333.85 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39538/47780 [02:21<00:25, 323.28 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39979/47780 [02:21<00:27, 283.29 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39300/47780 [02:21<00:35, 239.14 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40934/47780 [02:21<00:27, 246.06 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42021/47780 [02:21<00:24, 231.30 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41172/47780 [02:21<00:30, 216.99 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41781/47780 [02:21<00:18, 317.35 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23983/47780 [02:21<01:12, 326.34 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39572/47780 [02:21<00:25, 324.25 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40008/47780 [02:21<00:27, 285.02 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39325/47780 [02:21<00:37, 226.39 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40959/47780 [02:21<00:29, 233.86 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41195/47780 [02:21<00:29, 220.66 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41814/47780 [02:21<00:18, 318.13 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42045/47780 [02:21<00:26, 215.19 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24017/47780 [02:21<01:15, 313.41 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39605/47780 [02:21<00:25, 317.44 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40039/47780 [02:21<00:26, 289.64 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40987/47780 [02:21<00:27, 246.36 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39348/47780 [02:21<00:37, 224.88 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41218/47780 [02:21<00:30, 218.30 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41846/47780 [02:21<00:19, 310.06 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42069/47780 [02:21<00:25, 221.60 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39641/47780 [02:21<00:25, 323.44 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24049/47780 [02:21<01:20, 296.31 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40069/47780 [02:21<00:27, 285.23 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39375/47780 [02:22<00:35, 237.30 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41013/47780 [02:22<00:27, 242.47 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41241/47780 [02:21<00:29, 221.47 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41878/47780 [02:22<00:19, 310.25 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42092/47780 [02:22<00:26, 212.22 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39674/47780 [02:22<00:25, 319.75 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24083/47780 [02:22<01:17, 304.99 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40099/47780 [02:22<00:26, 286.18 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39399/47780 [02:22<00:35, 234.11 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41264/47780 [02:22<00:29, 221.41 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41042/47780 [02:22<00:27, 242.06 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41918/47780 [02:22<00:17, 334.60 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42116/47780 [02:22<00:26, 217.56 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24127/47780 [02:22<01:11, 330.86 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39707/47780 [02:22<00:27, 297.63 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40128/47780 [02:22<00:28, 271.61 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39441/47780 [02:22<00:29, 285.98 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41067/47780 [02:22<00:28, 234.13 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41288/47780 [02:22<00:32, 199.17 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42139/47780 [02:22<00:26, 215.98 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41952/47780 [02:22<00:20, 287.38 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24161/47780 [02:22<01:11, 329.80 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39745/47780 [02:22<00:25, 319.92 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40156/47780 [02:22<00:28, 271.14 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39470/47780 [02:22<00:29, 277.07 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42167/47780 [02:22<00:24, 231.53 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41309/47780 [02:22<00:33, 193.78 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41091/47780 [02:22<00:31, 210.54 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24196/47780 [02:22<01:11, 331.75 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40190/47780 [02:22<00:26, 290.33 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39503/47780 [02:22<00:28, 286.31 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41984/47780 [02:22<00:21, 267.65 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39778/47780 [02:22<00:26, 296.60 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41122/47780 [02:22<00:28, 233.71 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42192/47780 [02:22<00:24, 223.96 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24234/47780 [02:22<01:08, 345.16 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41337/47780 [02:22<00:31, 203.76 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42013/47780 [02:22<00:21, 273.11 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39532/47780 [02:22<00:29, 277.83 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40220/47780 [02:22<00:28, 265.90 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39809/47780 [02:22<00:30, 264.33 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24269/47780 [02:22<01:08, 342.90 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42216/47780 [02:22<00:24, 223.20 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41367/47780 [02:22<00:28, 227.72 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42044/47780 [02:22<00:20, 277.25 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40251/47780 [02:22<00:27, 277.72 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39563/47780 [02:22<00:29, 279.19 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41146/47780 [02:22<00:33, 197.36 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39841/47780 [02:22<00:28, 276.95 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24308/47780 [02:22<01:05, 356.50 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42247/47780 [02:22<00:22, 242.43 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41401/47780 [02:22<00:25, 254.57 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40290/47780 [02:22<00:24, 308.99 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42074/47780 [02:22<00:21, 269.26 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39592/47780 [02:22<00:29, 276.88 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41167/47780 [02:22<00:33, 195.06 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39875/47780 [02:22<00:27, 290.60 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24344/47780 [02:22<01:07, 349.18 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41427/47780 [02:22<00:24, 255.52 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42274/47780 [02:22<00:23, 234.28 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40322/47780 [02:22<00:24, 305.04 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42102/47780 [02:22<00:21, 263.26 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41194/47780 [02:22<00:31, 211.48 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39620/47780 [02:22<00:32, 249.82 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39905/47780 [02:22<00:27, 286.98 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24384/47780 [02:22<01:05, 355.66 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41453/47780 [02:22<00:25, 251.42 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42299/47780 [02:23<00:23, 233.15 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40355/47780 [02:22<00:23, 311.54 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42129/47780 [02:23<00:22, 256.09 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41216/47780 [02:23<00:31, 209.69 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39935/47780 [02:22<00:27, 290.29 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24420/47780 [02:23<01:06, 349.04 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39646/47780 [02:23<00:35, 230.38 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40387/47780 [02:23<00:23, 310.04 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42323/47780 [02:23<00:24, 225.18 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41482/47780 [02:23<00:27, 230.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42166/47780 [02:23<00:19, 284.71 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41238/47780 [02:23<00:31, 209.69 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39965/47780 [02:23<00:27, 283.57 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24466/47780 [02:23<01:02, 372.10 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39686/47780 [02:23<00:30, 263.29 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40421/47780 [02:23<00:23, 316.36 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42349/47780 [02:23<00:23, 231.81 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41510/47780 [02:23<00:26, 238.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42195/47780 [02:23<00:19, 285.99 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41264/47780 [02:23<00:29, 220.33 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39998/47780 [02:23<00:26, 294.83 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24505/47780 [02:23<01:02, 373.01 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39726/47780 [02:23<00:27, 295.89 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42373/47780 [02:23<00:23, 229.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40453/47780 [02:23<00:25, 290.16 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41535/47780 [02:23<00:26, 231.93 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41288/47780 [02:23<00:29, 216.54 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40029/47780 [02:23<00:26, 297.64 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42224/47780 [02:23<00:21, 255.51 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24544/47780 [02:23<01:02, 373.59 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39757/47780 [02:23<00:27, 292.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42400/47780 [02:23<00:22, 238.33 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41566/47780 [02:23<00:25, 247.65 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40065/47780 [02:23<00:25, 305.08 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41311/47780 [02:23<00:30, 213.66 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24594/47780 [02:23<00:57, 405.62 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40483/47780 [02:23<00:29, 245.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42433/47780 [02:23<00:20, 264.29 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39788/47780 [02:23<00:30, 263.60 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42251/47780 [02:23<00:26, 211.63 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41596/47780 [02:23<00:24, 256.37 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41342/47780 [02:23<00:26, 239.88 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40100/47780 [02:23<00:24, 317.73 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24645/47780 [02:23<00:53, 430.90 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40525/47780 [02:23<00:25, 287.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42460/47780 [02:23<00:20, 260.07 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39816/47780 [02:23<00:29, 267.63 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41625/47780 [02:23<00:23, 259.94 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42311/47780 [02:23<00:18, 295.57 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41371/47780 [02:23<00:25, 251.71 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40132/47780 [02:23<00:24, 310.26 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24690/47780 [02:23<00:53, 428.01 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42491/47780 [02:23<00:19, 273.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40557/47780 [02:23<00:26, 270.71 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39857/47780 [02:23<00:26, 302.33 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42352/47780 [02:23<00:16, 323.78 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41656/47780 [02:23<00:22, 273.63 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41399/47780 [02:23<00:24, 258.12 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24739/47780 [02:23<00:51, 444.38 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40172/47780 [02:23<00:24, 311.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42519/47780 [02:23<00:19, 270.11 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40586/47780 [02:23<00:27, 262.21 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41426/47780 [02:23<00:24, 260.35 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42388/47780 [02:23<00:16, 320.05 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41684/47780 [02:23<00:23, 262.03 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39888/47780 [02:23<00:28, 279.74 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40206/47780 [02:23<00:23, 316.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24787/47780 [02:23<00:54, 419.97 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42549/47780 [02:23<00:19, 263.81 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40618/47780 [02:23<00:25, 275.83 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41453/47780 [02:23<00:24, 260.28 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42422/47780 [02:24<00:16, 318.56 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41715/47780 [02:23<00:22, 268.15 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40238/47780 [02:23<00:24, 310.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39917/47780 [02:24<00:31, 250.86 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24830/47780 [02:24<00:59, 388.69 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42582/47780 [02:24<00:18, 278.91 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40651/47780 [02:24<00:24, 285.44 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41481/47780 [02:24<00:23, 265.83 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41746/47780 [02:24<00:21, 279.70 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40279/47780 [02:24<00:22, 338.35 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39952/47780 [02:24<00:28, 273.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42456/47780 [02:24<00:19, 278.89 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42611/47780 [02:24<00:18, 275.84 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24870/47780 [02:24<01:00, 375.59 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41515/47780 [02:24<00:22, 281.08 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41780/47780 [02:24<00:20, 296.64 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40681/47780 [02:24<00:26, 270.53 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40321/47780 [02:24<00:20, 361.60 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39983/47780 [02:24<00:29, 263.28 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42486/47780 [02:24<00:19, 275.88 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42640/47780 [02:24<00:18, 273.67 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41546/47780 [02:24<00:21, 289.35 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24915/47780 [02:24<00:59, 383.22 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40712/47780 [02:24<00:25, 276.35 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41810/47780 [02:24<00:20, 288.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40369/47780 [02:24<00:19, 382.24 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42515/47780 [02:24<00:19, 271.40 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40014/47780 [02:24<00:29, 264.58 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24957/47780 [02:24<00:58, 390.77 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41578/47780 [02:24<00:21, 291.65 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41845/47780 [02:24<00:19, 305.42 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40747/47780 [02:24<00:24, 290.08 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42668/47780 [02:24<00:20, 252.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40411/47780 [02:24<00:18, 389.26 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42547/47780 [02:24<00:18, 284.01 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40042/47780 [02:24<00:29, 265.79 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24999/47780 [02:24<00:59, 382.51 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41882/47780 [02:24<00:18, 320.78 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41608/47780 [02:24<00:21, 281.04 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40780/47780 [02:24<00:23, 297.84 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42697/47780 [02:24<00:19, 257.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40450/47780 [02:24<00:18, 388.75 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42578/47780 [02:24<00:18, 278.71 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40071/47780 [02:24<00:29, 263.80 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25041/47780 [02:24<00:58, 386.11 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41646/47780 [02:24<00:20, 298.75 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41915/47780 [02:24<00:18, 312.31 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40501/47780 [02:24<00:17, 419.86 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42723/47780 [02:24<00:20, 246.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40811/47780 [02:24<00:25, 268.11 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40101/47780 [02:24<00:28, 271.92 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42611/47780 [02:24<00:18, 283.85 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41948/47780 [02:24<00:18, 313.54 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41692/47780 [02:24<00:18, 336.77 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25080/47780 [02:24<01:01, 366.79 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40545/47780 [02:24<00:17, 415.53 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42751/47780 [02:24<00:20, 245.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40839/47780 [02:24<00:26, 262.76 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40131/47780 [02:24<00:27, 278.41 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42645/47780 [02:24<00:17, 298.97 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41739/47780 [02:24<00:16, 370.23 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25132/47780 [02:24<00:56, 399.77 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42779/47780 [02:24<00:19, 254.66 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41980/47780 [02:24<00:19, 292.25 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40587/47780 [02:24<00:18, 397.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40871/47780 [02:24<00:24, 277.70 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40160/47780 [02:24<00:28, 263.81 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25174/47780 [02:24<00:55, 405.17 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42676/47780 [02:24<00:18, 269.07 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42017/47780 [02:24<00:18, 313.40 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42805/47780 [02:24<00:20, 245.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41777/47780 [02:24<00:17, 344.37 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40900/47780 [02:24<00:26, 264.23 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40627/47780 [02:24<00:21, 338.35 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25215/47780 [02:24<00:57, 393.50 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42049/47780 [02:24<00:18, 312.14 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40187/47780 [02:25<00:31, 243.92 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42704/47780 [02:25<00:19, 261.04 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42830/47780 [02:25<00:20, 241.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41812/47780 [02:25<00:17, 332.47 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40932/47780 [02:25<00:24, 276.22 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40663/47780 [02:25<00:22, 320.82 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25255/47780 [02:25<00:57, 390.13 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42082/47780 [02:25<00:18, 311.94 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40213/47780 [02:25<00:31, 243.17 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42855/47780 [02:25<00:20, 240.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42731/47780 [02:25<00:19, 252.53 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41846/47780 [02:25<00:19, 311.70 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40961/47780 [02:25<00:25, 270.95 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40703/47780 [02:25<00:21, 331.06 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40238/47780 [02:25<00:30, 245.00 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42115/47780 [02:25<00:18, 311.43 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42762/47780 [02:25<00:18, 265.09 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42885/47780 [02:25<00:19, 252.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25295/47780 [02:25<01:03, 356.73 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41878/47780 [02:25<00:19, 309.65 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40991/47780 [02:25<00:24, 276.12 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40754/47780 [02:25<00:18, 373.48 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42147/47780 [02:25<00:18, 302.28 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40263/47780 [02:25<00:32, 233.41 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42911/47780 [02:25<00:19, 254.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42789/47780 [02:25<00:19, 260.52 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25332/47780 [02:25<01:03, 354.51 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41019/47780 [02:25<00:24, 276.72 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41910/47780 [02:25<00:19, 298.92 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40288/47780 [02:25<00:31, 237.87 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42940/47780 [02:25<00:18, 261.81 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40793/47780 [02:25<00:19, 357.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42818/47780 [02:25<00:18, 267.07 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42179/47780 [02:25<00:19, 285.61 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41048/47780 [02:25<00:24, 274.61 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25368/47780 [02:25<01:07, 333.24 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41941/47780 [02:25<00:20, 288.04 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40318/47780 [02:25<00:29, 252.58 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42845/47780 [02:25<00:18, 266.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40836/47780 [02:25<00:18, 374.05 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42982/47780 [02:25<00:16, 290.68 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25405/47780 [02:25<01:05, 342.74 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41076/47780 [02:25<00:25, 267.11 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42208/47780 [02:25<00:20, 266.87 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41970/47780 [02:25<00:21, 272.66 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42872/47780 [02:25<00:18, 267.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40348/47780 [02:25<00:28, 262.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40876/47780 [02:25<00:18, 367.05 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43011/47780 [02:25<00:16, 281.09 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25441/47780 [02:25<01:04, 345.27 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41998/47780 [02:25<00:21, 268.85 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41103/47780 [02:25<00:28, 233.03 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42911/47780 [02:25<00:16, 299.78 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40375/47780 [02:25<00:28, 261.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42236/47780 [02:25<00:24, 228.88 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43039/47780 [02:25<00:16, 280.60 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40914/47780 [02:25<00:19, 356.61 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25478/47780 [02:25<01:03, 350.18 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42028/47780 [02:25<00:21, 273.00 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41134/47780 [02:25<00:26, 251.75 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40406/47780 [02:25<00:27, 272.91 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42942/47780 [02:25<00:16, 295.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42268/47780 [02:25<00:22, 247.85 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43073/47780 [02:25<00:15, 297.20 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25518/47780 [02:25<01:03, 353.20 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40955/47780 [02:25<00:19, 348.74 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41165/47780 [02:25<00:24, 266.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42060/47780 [02:25<00:21, 266.38 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40434/47780 [02:25<00:28, 257.08 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42294/47780 [02:25<00:22, 241.87 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42972/47780 [02:26<00:17, 274.73 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43106/47780 [02:26<00:15, 296.93 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25559/47780 [02:25<01:00, 368.74 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40992/47780 [02:26<00:19, 354.34 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41195/47780 [02:26<00:24, 272.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42087/47780 [02:26<00:21, 261.68 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40465/47780 [02:26<00:26, 271.82 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43139/47780 [02:26<00:15, 302.97 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25599/47780 [02:26<00:58, 377.46 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41034/47780 [02:26<00:18, 364.55 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 43000/47780 [02:26<00:18, 259.11 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42319/47780 [02:26<00:24, 225.07 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41223/47780 [02:26<00:24, 265.53 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40493/47780 [02:26<00:26, 273.27 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42114/47780 [02:26<00:22, 252.94 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41073/47780 [02:26<00:18, 367.59 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42343/47780 [02:26<00:23, 226.90 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25637/47780 [02:26<01:02, 353.57 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43029/47780 [02:26<00:18, 256.33 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43170/47780 [02:26<00:17, 270.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41254/47780 [02:26<00:23, 275.34 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40523/47780 [02:26<00:26, 274.65 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42140/47780 [02:26<00:24, 234.37 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41113/47780 [02:26<00:18, 368.33 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25673/47780 [02:26<01:03, 347.32 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43069/47780 [02:26<00:16, 288.90 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43203/47780 [02:26<00:16, 283.52 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42367/47780 [02:26<00:25, 216.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41287/47780 [02:26<00:22, 290.72 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40553/47780 [02:26<00:25, 279.02 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41150/47780 [02:26<00:18, 360.68 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25708/47780 [02:26<01:04, 340.59 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43103/47780 [02:26<00:15, 299.64 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42400/47780 [02:26<00:22, 243.75 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42168/47780 [02:26<00:24, 229.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43236/47780 [02:26<00:15, 289.94 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41317/47780 [02:26<00:24, 265.53 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40582/47780 [02:26<00:26, 273.41 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41187/47780 [02:26<00:18, 350.62 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42193/47780 [02:26<00:23, 234.59 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42430/47780 [02:26<00:20, 258.15 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43134/47780 [02:26<00:15, 297.98 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25743/47780 [02:26<01:06, 331.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43266/47780 [02:26<00:15, 283.27 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41350/47780 [02:26<00:23, 277.44 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40614/47780 [02:26<00:25, 276.87 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41223/47780 [02:26<00:18, 350.13 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25783/47780 [02:26<01:03, 348.74 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42217/47780 [02:26<00:24, 229.80 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43164/47780 [02:26<00:16, 286.77 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42457/47780 [02:26<00:21, 243.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43295/47780 [02:26<00:17, 259.88 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41379/47780 [02:26<00:23, 274.64 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40642/47780 [02:26<00:25, 277.17 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25826/47780 [02:26<00:59, 370.78 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41259/47780 [02:26<00:19, 341.73 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43194/47780 [02:26<00:15, 290.27 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42242/47780 [02:26<00:23, 232.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43322/47780 [02:26<00:17, 261.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42482/47780 [02:26<00:23, 229.02 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40671/47780 [02:26<00:25, 278.51 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41407/47780 [02:26<00:23, 267.50 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25869/47780 [02:26<00:56, 387.49 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41298/47780 [02:26<00:19, 335.94 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43224/47780 [02:26<00:16, 277.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42267/47780 [02:26<00:25, 215.07 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42506/47780 [02:26<00:24, 219.10 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43349/47780 [02:26<00:17, 247.17 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40702/47780 [02:26<00:24, 284.25 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41440/47780 [02:26<00:22, 284.82 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25917/47780 [02:26<00:52, 414.47 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41332/47780 [02:26<00:20, 322.39 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43252/47780 [02:27<00:17, 266.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42293/47780 [02:27<00:24, 224.69 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43376/47780 [02:27<00:17, 248.69 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41470/47780 [02:27<00:22, 285.88 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42530/47780 [02:27<00:24, 214.60 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40735/47780 [02:27<00:24, 285.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25967/47780 [02:27<00:50, 429.92 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42317/47780 [02:27<00:24, 221.70 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43279/47780 [02:27<00:17, 250.74 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41366/47780 [02:27<00:21, 304.26 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41503/47780 [02:27<00:21, 288.61 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43402/47780 [02:27<00:18, 237.36 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26013/47780 [02:27<00:50, 434.24 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40764/47780 [02:27<00:26, 267.38 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42552/47780 [02:27<00:26, 196.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42342/47780 [02:27<00:23, 228.19 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41397/47780 [02:27<00:22, 287.32 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43429/47780 [02:27<00:17, 245.03 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40797/47780 [02:27<00:24, 284.56 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41533/47780 [02:27<00:22, 276.26 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43305/47780 [02:27<00:20, 222.15 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42572/47780 [02:27<00:28, 184.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26057/47780 [02:27<00:55, 389.47 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42371/47780 [02:27<00:23, 233.96 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41433/47780 [02:27<00:20, 306.47 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40826/47780 [02:27<00:24, 283.08 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41564/47780 [02:27<00:22, 282.42 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43332/47780 [02:27<00:18, 234.14 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43454/47780 [02:27<00:18, 228.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42602/47780 [02:27<00:24, 209.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26097/47780 [02:27<00:58, 368.83 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42397/47780 [02:27<00:22, 238.53 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41469/47780 [02:27<00:19, 320.64 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40864/47780 [02:27<00:22, 307.16 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43358/47780 [02:27<00:18, 240.70 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43478/47780 [02:27<00:19, 224.41 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41593/47780 [02:27<00:24, 253.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42624/47780 [02:27<00:24, 211.86 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42421/47780 [02:27<00:22, 238.70 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26135/47780 [02:27<00:59, 363.51 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41507/47780 [02:27<00:18, 334.16 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43386/47780 [02:27<00:17, 249.71 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40898/47780 [02:27<00:21, 313.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43509/47780 [02:27<00:18, 236.91 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41619/47780 [02:27<00:25, 242.08 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42452/47780 [02:27<00:20, 256.35 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42650/47780 [02:27<00:25, 205.13 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41543/47780 [02:27<00:18, 337.47 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26172/47780 [02:27<01:02, 343.12 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43412/47780 [02:27<00:17, 252.00 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40935/47780 [02:27<00:21, 314.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43533/47780 [02:27<00:18, 226.20 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42481/47780 [02:27<00:19, 265.99 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41577/47780 [02:27<00:18, 337.75 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41644/47780 [02:27<00:26, 227.26 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42686/47780 [02:27<00:21, 238.07 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43439/47780 [02:27<00:16, 256.89 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26207/47780 [02:27<01:05, 329.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40967/47780 [02:27<00:22, 308.87 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42520/47780 [02:27<00:17, 298.86 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43556/47780 [02:27<00:19, 215.46 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41615/47780 [02:27<00:17, 346.96 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42712/47780 [02:27<00:20, 243.64 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41671/47780 [02:27<00:25, 236.21 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26250/47780 [02:27<01:00, 354.39 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43465/47780 [02:27<00:17, 249.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41003/47780 [02:27<00:21, 316.67 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42550/47780 [02:27<00:17, 295.69 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41697/47780 [02:27<00:25, 242.59 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43578/47780 [02:28<00:20, 204.94 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42740/47780 [02:27<00:20, 240.64 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41650/47780 [02:27<00:18, 324.25 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26290/47780 [02:27<00:59, 359.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43492/47780 [02:28<00:17, 249.55 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42584/47780 [02:28<00:17, 301.52 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41727/47780 [02:28<00:23, 255.70 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26334/47780 [02:28<00:56, 381.38 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41035/47780 [02:28<00:26, 256.90 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42765/47780 [02:28<00:20, 240.27 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43599/47780 [02:28<00:21, 190.78 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41683/47780 [02:28<00:19, 309.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43518/47780 [02:28<00:18, 229.02 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42615/47780 [02:28<00:17, 303.60 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41758/47780 [02:28<00:22, 270.98 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41095/47780 [02:28<00:19, 340.94 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43622/47780 [02:28<00:20, 199.06 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41715/47780 [02:28<00:19, 308.40 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42795/47780 [02:28<00:20, 242.62 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26373/47780 [02:28<01:00, 353.63 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43547/47780 [02:28<00:18, 232.88 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41797/47780 [02:28<00:19, 305.09 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42646/47780 [02:28<00:17, 295.15 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42828/47780 [02:28<00:18, 264.87 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41133/47780 [02:28<00:19, 336.56 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43643/47780 [02:28<00:21, 195.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26410/47780 [02:28<01:00, 350.69 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43571/47780 [02:28<00:18, 227.32 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41747/47780 [02:28<00:22, 266.94 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41832/47780 [02:28<00:18, 314.46 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42688/47780 [02:28<00:15, 327.66 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42855/47780 [02:28<00:19, 257.21 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41169/47780 [02:28<00:20, 329.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43663/47780 [02:28<00:21, 188.55 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26446/47780 [02:28<01:06, 319.73 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43595/47780 [02:28<00:18, 228.51 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41784/47780 [02:28<00:20, 287.63 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41865/47780 [02:28<00:19, 305.35 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42723/47780 [02:28<00:16, 302.17 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41205/47780 [02:28<00:19, 330.63 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43685/47780 [02:28<00:21, 193.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42881/47780 [02:28<00:21, 232.24 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26487/47780 [02:28<01:02, 341.36 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43622/47780 [02:28<00:17, 239.97 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41814/47780 [02:28<00:21, 276.03 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42757/47780 [02:28<00:16, 309.61 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41896/47780 [02:28<00:21, 274.88 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43708/47780 [02:28<00:20, 202.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41241/47780 [02:28<00:20, 320.86 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26522/47780 [02:28<01:02, 341.96 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43651/47780 [02:28<00:16, 251.32 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42908/47780 [02:28<00:20, 234.14 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41851/47780 [02:28<00:20, 294.85 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42792/47780 [02:28<00:15, 317.23 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41927/47780 [02:28<00:20, 281.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43739/47780 [02:28<00:17, 232.86 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41275/47780 [02:28<00:20, 309.86 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43682/47780 [02:28<00:15, 268.06 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26558/47780 [02:28<01:02, 339.65 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42938/47780 [02:28<00:19, 249.97 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41888/47780 [02:28<00:18, 311.73 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42827/47780 [02:28<00:16, 293.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41956/47780 [02:28<00:21, 266.10 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26596/47780 [02:28<01:00, 347.48 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43710/47780 [02:28<00:15, 262.50 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42966/47780 [02:28<00:19, 252.60 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41308/47780 [02:28<00:21, 302.13 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43763/47780 [02:28<00:19, 204.55 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41920/47780 [02:28<00:19, 300.46 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42857/47780 [02:28<00:17, 288.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41984/47780 [02:28<00:22, 258.42 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43740/47780 [02:29<00:14, 273.02 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26633/47780 [02:28<01:00, 349.36 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41339/47780 [02:29<00:21, 297.94 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43793/47780 [02:29<00:17, 224.91 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42992/47780 [02:28<00:19, 239.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41954/47780 [02:29<00:18, 307.23 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26674/47780 [02:29<00:57, 365.00 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42011/47780 [02:29<00:23, 245.50 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43769/47780 [02:29<00:15, 262.42 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42887/47780 [02:29<00:18, 261.14 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43819/47780 [02:29<00:17, 226.98 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41371/47780 [02:29<00:22, 286.85 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43017/47780 [02:29<00:20, 231.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41994/47780 [02:29<00:17, 329.17 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26714/47780 [02:29<00:56, 372.90 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42036/47780 [02:29<00:24, 236.96 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43851/47780 [02:29<00:15, 246.87 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42914/47780 [02:29<00:19, 255.39 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41404/47780 [02:29<00:21, 295.28 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43042/47780 [02:29<00:20, 235.08 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43799/47780 [02:29<00:15, 254.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42029/47780 [02:29<00:17, 328.99 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42061/47780 [02:29<00:24, 237.93 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26752/47780 [02:29<01:00, 345.34 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41439/47780 [02:29<00:20, 308.51 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43880/47780 [02:29<00:15, 253.21 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42963/47780 [02:29<00:15, 307.34 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43067/47780 [02:29<00:20, 235.57 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43826/47780 [02:29<00:15, 256.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42067/47780 [02:29<00:16, 339.57 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26792/47780 [02:29<00:58, 357.78 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43907/47780 [02:29<00:15, 257.63 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42998/47780 [02:29<00:15, 318.67 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43854/47780 [02:29<00:15, 261.31 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42088/47780 [02:29<00:24, 234.06 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41472/47780 [02:29<00:20, 300.99 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43102/47780 [02:29<00:17, 261.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42102/47780 [02:29<00:17, 323.31 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26830/47780 [02:29<00:58, 359.81 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43941/47780 [02:29<00:13, 278.63 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42114/47780 [02:29<00:23, 238.54 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43129/47780 [02:29<00:17, 263.89 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41507/47780 [02:29<00:20, 311.17 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43032/47780 [02:29<00:15, 298.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42142/47780 [02:29<00:16, 337.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43881/47780 [02:29<00:17, 227.59 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26870/47780 [02:29<00:56, 368.03 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42140/47780 [02:29<00:23, 244.44 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43161/47780 [02:29<00:16, 277.09 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41542/47780 [02:29<00:19, 318.52 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43971/47780 [02:29<00:14, 271.43 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43065/47780 [02:29<00:16, 288.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43906/47780 [02:29<00:16, 232.20 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42180/47780 [02:29<00:17, 311.41 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26908/47780 [02:29<00:58, 358.33 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44000/47780 [02:29<00:14, 267.48 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43189/47780 [02:29<00:17, 260.75 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41576/47780 [02:29<00:20, 300.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42165/47780 [02:29<00:25, 223.26 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43097/47780 [02:29<00:16, 279.06 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43930/47780 [02:29<00:17, 218.94 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26954/47780 [02:29<00:55, 378.63 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42212/47780 [02:29<00:19, 283.34 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42193/47780 [02:29<00:23, 238.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44027/47780 [02:29<00:15, 244.08 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43216/47780 [02:29<00:19, 240.03 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43126/47780 [02:29<00:17, 269.17 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41608/47780 [02:29<00:24, 255.65 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27003/47780 [02:29<00:52, 396.70 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42242/47780 [02:29<00:19, 284.11 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43954/47780 [02:30<00:19, 199.29 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42222/47780 [02:29<00:21, 252.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44052/47780 [02:30<00:15, 243.10 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43241/47780 [02:29<00:19, 233.39 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43155/47780 [02:30<00:17, 262.65 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43978/47780 [02:30<00:18, 207.42 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42276/47780 [02:30<00:18, 296.79 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41636/47780 [02:30<00:25, 239.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42248/47780 [02:30<00:22, 243.80 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27043/47780 [02:30<01:02, 333.85 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44077/47780 [02:30<00:16, 227.30 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43269/47780 [02:30<00:19, 233.74 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43184/47780 [02:30<00:17, 266.71 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44002/47780 [02:30<00:17, 215.16 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42308/47780 [02:30<00:19, 284.63 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41717/47780 [02:30<00:16, 375.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42274/47780 [02:30<00:22, 240.22 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27078/47780 [02:30<01:03, 328.07 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44101/47780 [02:30<00:16, 223.71 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43293/47780 [02:30<00:19, 230.70 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43213/47780 [02:30<00:16, 269.05 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44026/47780 [02:30<00:17, 218.07 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42360/47780 [02:30<00:15, 340.29 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41759/47780 [02:30<00:16, 357.85 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42299/47780 [02:30<00:24, 223.72 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27130/47780 [02:30<00:54, 377.75 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44132/47780 [02:30<00:15, 239.22 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43317/47780 [02:30<00:19, 227.84 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43242/47780 [02:30<00:16, 269.69 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44050/47780 [02:30<00:16, 221.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42407/47780 [02:30<00:14, 368.48 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41798/47780 [02:30<00:16, 352.50 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42322/47780 [02:30<00:24, 224.72 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43340/47780 [02:30<00:21, 210.20 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44158/47780 [02:30<00:16, 225.41 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44074/47780 [02:30<00:16, 225.20 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43270/47780 [02:30<00:17, 255.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42455/47780 [02:30<00:13, 398.22 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27170/47780 [02:30<01:05, 312.76 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42345/47780 [02:30<00:24, 226.00 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41835/47780 [02:30<00:16, 352.16 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43365/47780 [02:30<00:20, 220.71 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43305/47780 [02:30<00:16, 276.07 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44097/47780 [02:30<00:16, 220.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44182/47780 [02:30<00:16, 222.08 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27260/47780 [02:30<00:45, 448.85 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42369/47780 [02:30<00:23, 229.22 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42496/47780 [02:30<00:15, 346.26 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43334/47780 [02:30<00:16, 276.09 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41873/47780 [02:30<00:19, 307.36 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43389/47780 [02:30<00:20, 209.86 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44205/47780 [02:30<00:16, 212.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44120/47780 [02:30<00:17, 206.89 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42396/47780 [02:30<00:22, 236.44 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42557/47780 [02:30<00:12, 410.55 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27310/47780 [02:30<00:50, 401.60 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43363/47780 [02:30<00:15, 276.93 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44229/47780 [02:30<00:16, 219.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43417/47780 [02:30<00:19, 223.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44141/47780 [02:30<00:17, 205.92 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41906/47780 [02:30<00:20, 290.20 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42420/47780 [02:30<00:23, 227.08 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42600/47780 [02:30<00:13, 390.69 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43400/47780 [02:30<00:14, 296.59 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44253/47780 [02:30<00:15, 223.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27355/47780 [02:30<00:54, 376.53 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44169/47780 [02:31<00:16, 223.60 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43440/47780 [02:30<00:21, 203.34 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41937/47780 [02:30<00:20, 278.59 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42449/47780 [02:30<00:22, 239.40 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42641/47780 [02:31<00:13, 372.97 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43430/47780 [02:31<00:14, 296.13 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27396/47780 [02:31<00:53, 380.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44277/47780 [02:31<00:15, 220.71 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41966/47780 [02:31<00:20, 281.39 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44192/47780 [02:31<00:17, 206.44 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43467/47780 [02:31<00:19, 216.68 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42474/47780 [02:31<00:22, 237.01 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43460/47780 [02:31<00:14, 295.02 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42680/47780 [02:31<00:14, 354.07 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44303/47780 [02:31<00:15, 231.49 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27437/47780 [02:31<00:53, 380.55 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44215/47780 [02:31<00:17, 208.56 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43491/47780 [02:31<00:19, 219.76 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42004/47780 [02:31<00:19, 297.83 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42498/47780 [02:31<00:22, 229.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43492/47780 [02:31<00:14, 292.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42719/47780 [02:31<00:14, 359.37 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44327/47780 [02:31<00:16, 210.09 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43514/47780 [02:31<00:19, 220.39 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42036/47780 [02:31<00:19, 300.16 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27477/47780 [02:31<00:58, 346.03 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42524/47780 [02:31<00:22, 237.24 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44238/47780 [02:31<00:18, 195.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42759/47780 [02:31<00:13, 366.81 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43522/47780 [02:31<00:15, 275.26 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42069/47780 [02:31<00:18, 305.57 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44352/47780 [02:31<00:16, 211.22 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42551/47780 [02:31<00:21, 245.23 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27518/47780 [02:31<00:57, 354.84 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44274/47780 [02:31<00:15, 233.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43537/47780 [02:31<00:21, 193.03 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42797/47780 [02:31<00:14, 350.95 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43550/47780 [02:31<00:15, 269.97 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42100/47780 [02:31<00:18, 300.03 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27558/47780 [02:31<00:55, 365.85 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42581/47780 [02:31<00:19, 260.92 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44374/47780 [02:31<00:16, 209.54 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44301/47780 [02:31<00:14, 234.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43558/47780 [02:31<00:22, 189.60 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42834/47780 [02:31<00:14, 348.88 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42610/47780 [02:31<00:19, 266.40 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43579/47780 [02:31<00:16, 251.28 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42132/47780 [02:31<00:19, 292.29 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27596/47780 [02:31<00:56, 355.05 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44396/47780 [02:31<00:16, 201.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44334/47780 [02:31<00:13, 253.28 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43608/47780 [02:31<00:15, 267.46 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42874/47780 [02:31<00:13, 358.97 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43610/47780 [02:31<00:15, 264.13 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27635/47780 [02:31<00:55, 360.56 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42163/47780 [02:31<00:19, 290.97 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44420/47780 [02:31<00:16, 209.61 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42637/47780 [02:31<00:21, 239.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44362/47780 [02:31<00:13, 259.12 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42911/47780 [02:31<00:13, 357.61 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43641/47780 [02:31<00:15, 273.82 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42195/47780 [02:31<00:18, 298.85 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44451/47780 [02:31<00:14, 235.07 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27672/47780 [02:31<00:57, 351.50 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43637/47780 [02:31<00:18, 229.25 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42663/47780 [02:31<00:21, 239.88 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44390/47780 [02:31<00:13, 260.59 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42947/47780 [02:31<00:14, 335.88 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43671/47780 [02:31<00:14, 281.05 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42229/47780 [02:31<00:17, 310.40 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27712/47780 [02:31<00:55, 364.67 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43672/47780 [02:31<00:16, 256.09 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44475/47780 [02:31<00:14, 230.77 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42689/47780 [02:31<00:20, 242.80 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44417/47780 [02:32<00:13, 251.76 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43701/47780 [02:32<00:14, 286.38 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42982/47780 [02:32<00:14, 328.53 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27754/47780 [02:32<00:52, 380.09 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43700/47780 [02:32<00:16, 251.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42262/47780 [02:32<00:19, 277.16 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44499/47780 [02:32<00:15, 214.26 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42714/47780 [02:32<00:21, 233.76 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44443/47780 [02:32<00:13, 248.71 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43021/47780 [02:32<00:14, 338.57 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43730/47780 [02:32<00:15, 268.83 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27796/47780 [02:32<00:51, 385.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43727/47780 [02:32<00:16, 251.14 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42292/47780 [02:32<00:19, 278.09 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42738/47780 [02:32<00:21, 230.97 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44522/47780 [02:32<00:15, 212.27 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44468/47780 [02:32<00:13, 243.69 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43758/47780 [02:32<00:15, 263.14 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27835/47780 [02:32<00:53, 375.70 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43056/47780 [02:32<00:14, 319.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43753/47780 [02:32<00:16, 250.92 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42765/47780 [02:32<00:20, 241.64 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44496/47780 [02:32<00:13, 251.07 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42327/47780 [02:32<00:19, 285.17 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44548/47780 [02:32<00:14, 218.35 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43098/47780 [02:32<00:13, 344.06 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27874/47780 [02:32<00:54, 367.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43779/47780 [02:32<00:16, 248.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42794/47780 [02:32<00:19, 255.23 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43789/47780 [02:32<00:15, 251.00 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44524/47780 [02:32<00:12, 259.23 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42370/47780 [02:32<00:16, 321.05 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44572/47780 [02:32<00:15, 211.89 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43138/47780 [02:32<00:12, 357.54 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27911/47780 [02:32<00:54, 364.17 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43815/47780 [02:32<00:15, 253.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43806/47780 [02:32<00:16, 243.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42827/47780 [02:32<00:18, 271.03 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42404/47780 [02:32<00:16, 322.85 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44551/47780 [02:32<00:12, 250.67 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44594/47780 [02:32<00:15, 205.67 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43187/47780 [02:32<00:11, 388.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27949/47780 [02:32<00:54, 360.59 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42446/47780 [02:32<00:15, 346.08 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42856/47780 [02:32<00:18, 261.46 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43831/47780 [02:32<00:17, 232.28 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44579/47780 [02:32<00:12, 256.68 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43841/47780 [02:32<00:17, 230.57 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44617/47780 [02:32<00:15, 209.59 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27990/47780 [02:32<00:52, 374.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43227/47780 [02:32<00:12, 366.34 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42484/47780 [02:32<00:14, 355.52 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42886/47780 [02:32<00:18, 269.16 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44605/47780 [02:32<00:12, 256.65 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43868/47780 [02:32<00:16, 240.20 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43856/47780 [02:32<00:17, 224.89 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44640/47780 [02:32<00:14, 212.79 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28028/47780 [02:32<00:53, 371.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43266/47780 [02:32<00:12, 372.61 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42918/47780 [02:32<00:17, 280.41 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44631/47780 [02:32<00:12, 246.54 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42521/47780 [02:32<00:15, 333.12 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43882/47780 [02:32<00:16, 229.39 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44663/47780 [02:32<00:14, 215.84 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28068/47780 [02:32<00:52, 378.30 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43893/47780 [02:32<00:18, 207.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43306/47780 [02:32<00:11, 380.29 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42555/47780 [02:32<00:15, 334.96 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43910/47780 [02:32<00:16, 239.66 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44660/47780 [02:33<00:12, 250.38 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44685/47780 [02:33<00:15, 202.56 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42947/47780 [02:32<00:19, 244.20 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28106/47780 [02:32<00:52, 376.17 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43930/47780 [02:33<00:15, 242.31 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43345/47780 [02:33<00:12, 362.85 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42589/47780 [02:33<00:15, 332.59 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43939/47780 [02:33<00:15, 251.87 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44694/47780 [02:33<00:11, 266.62 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28147/47780 [02:33<00:50, 386.01 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42973/47780 [02:33<00:20, 235.09 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44706/47780 [02:33<00:16, 188.81 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43956/47780 [02:33<00:16, 234.54 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43383/47780 [02:33<00:13, 337.46 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43969/47780 [02:33<00:14, 256.77 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44721/47780 [02:33<00:11, 256.24 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42623/47780 [02:33<00:18, 282.96 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43013/47780 [02:33<00:17, 273.32 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43989/47780 [02:33<00:14, 256.96 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44727/47780 [02:33<00:17, 178.50 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43999/47780 [02:33<00:14, 265.90 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43418/47780 [02:33<00:13, 319.70 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44747/47780 [02:33<00:12, 251.73 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28186/47780 [02:33<01:05, 299.09 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43056/47780 [02:33<00:15, 311.89 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42653/47780 [02:33<00:18, 281.49 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44017/47780 [02:33<00:14, 257.24 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44753/47780 [02:33<00:15, 191.62 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44026/47780 [02:33<00:14, 266.84 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44773/47780 [02:33<00:11, 250.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43453/47780 [02:33<00:13, 311.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42683/47780 [02:33<00:18, 280.67 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28220/47780 [02:33<01:09, 281.48 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43090/47780 [02:33<00:15, 310.68 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44045/47780 [02:33<00:14, 257.89 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44774/47780 [02:33<00:15, 195.47 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44054/47780 [02:33<00:13, 270.52 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44815/47780 [02:33<00:10, 296.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43488/47780 [02:33<00:13, 315.11 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28338/47780 [02:33<00:38, 498.85 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42713/47780 [02:33<00:17, 282.45 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43122/47780 [02:33<00:16, 289.39 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44072/47780 [02:33<00:14, 254.68 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44794/47780 [02:33<00:16, 183.70 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44082/47780 [02:33<00:14, 260.87 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44847/47780 [02:33<00:09, 302.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43520/47780 [02:33<00:13, 309.76 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42748/47780 [02:33<00:17, 285.59 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43152/47780 [02:33<00:16, 288.80 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44103/47780 [02:33<00:13, 268.40 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28395/47780 [02:33<00:41, 464.64 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44113/47780 [02:33<00:13, 272.41 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44815/47780 [02:33<00:15, 188.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44879/47780 [02:33<00:10, 279.80 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43553/47780 [02:33<00:14, 284.27 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42780/47780 [02:33<00:17, 288.62 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43183/47780 [02:33<00:15, 289.14 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44131/47780 [02:33<00:14, 256.81 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28448/47780 [02:33<00:41, 466.48 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44838/47780 [02:33<00:14, 199.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44141/47780 [02:33<00:13, 268.51 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43597/47780 [02:33<00:13, 318.33 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43225/47780 [02:33<00:14, 321.69 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42810/47780 [02:33<00:18, 273.72 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44157/47780 [02:33<00:14, 255.18 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44909/47780 [02:33<00:11, 247.08 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44860/47780 [02:33<00:14, 203.42 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44175/47780 [02:33<00:12, 288.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28500/47780 [02:33<00:41, 460.52 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43630/47780 [02:33<00:13, 314.15 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43258/47780 [02:33<00:13, 324.00 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42838/47780 [02:33<00:18, 267.24 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44935/47780 [02:34<00:11, 248.10 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44205/47780 [02:33<00:12, 291.73 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44183/47780 [02:34<00:14, 242.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44881/47780 [02:34<00:15, 189.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28549/47780 [02:34<00:45, 424.75 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43294/47780 [02:34<00:13, 330.57 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42866/47780 [02:34<00:18, 267.28 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44961/47780 [02:34<00:11, 242.42 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44238/47780 [02:34<00:11, 296.33 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44904/47780 [02:34<00:14, 199.09 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43662/47780 [02:34<00:15, 269.29 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44208/47780 [02:34<00:17, 208.23 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28594/47780 [02:34<00:48, 395.86 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43328/47780 [02:34<00:13, 318.66 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42893/47780 [02:34<00:18, 260.46 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44986/47780 [02:34<00:11, 239.16 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43701/47780 [02:34<00:13, 296.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44273/47780 [02:34<00:12, 282.41 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44926/47780 [02:34<00:15, 190.12 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28639/47780 [02:34<00:47, 401.32 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44231/47780 [02:34<00:17, 204.97 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42922/47780 [02:34<00:18, 267.62 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43363/47780 [02:34<00:14, 302.44 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45012/47780 [02:34<00:11, 236.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43734/47780 [02:34<00:13, 295.83 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44303/47780 [02:34<00:12, 278.13 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44947/47780 [02:34<00:14, 189.27 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44289/47780 [02:34<00:11, 298.24 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28682/47780 [02:34<00:49, 387.47 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42950/47780 [02:34<00:18, 268.15 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45036/47780 [02:34<00:12, 227.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43775/47780 [02:34<00:12, 323.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43394/47780 [02:34<00:15, 278.28 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44331/47780 [02:34<00:12, 267.02 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44970/47780 [02:34<00:14, 191.92 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44321/47780 [02:34<00:11, 294.75 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28723/47780 [02:34<00:51, 367.25 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42977/47780 [02:34<00:19, 243.63 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43822/47780 [02:34<00:10, 362.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45061/47780 [02:34<00:12, 220.30 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43423/47780 [02:34<00:16, 267.48 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44369/47780 [02:34<00:11, 287.84 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44992/47780 [02:34<00:14, 197.51 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44353/47780 [02:34<00:12, 280.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28761/47780 [02:34<00:54, 349.00 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45088/47780 [02:34<00:11, 231.05 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43860/47780 [02:34<00:11, 333.87 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44408/47780 [02:34<00:10, 312.85 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45012/47780 [02:34<00:13, 198.00 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43002/47780 [02:34<00:21, 219.27 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43452/47780 [02:34<00:17, 240.57 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44383/47780 [02:34<00:12, 268.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28824/47780 [02:34<00:45, 417.49 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45126/47780 [02:34<00:09, 271.71 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43898/47780 [02:34<00:11, 346.03 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45034/47780 [02:34<00:13, 202.14 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44442/47780 [02:34<00:10, 310.03 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43025/47780 [02:34<00:22, 209.14 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43493/47780 [02:34<00:15, 282.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44411/47780 [02:34<00:12, 263.32 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28869/47780 [02:34<00:47, 396.20 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45056/47780 [02:34<00:13, 200.37 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45154/47780 [02:34<00:10, 246.34 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44474/47780 [02:34<00:11, 293.29 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43092/47780 [02:34<00:14, 319.48 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43934/47780 [02:34<00:12, 305.97 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43523/47780 [02:34<00:15, 271.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44440/47780 [02:34<00:12, 264.77 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28914/47780 [02:34<00:46, 406.43 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45078/47780 [02:35<00:13, 203.59 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44507/47780 [02:34<00:11, 296.76 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43126/47780 [02:35<00:14, 319.49 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43966/47780 [02:35<00:12, 300.46 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43558/47780 [02:35<00:14, 290.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45180/47780 [02:35<00:11, 217.84 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44467/47780 [02:35<00:12, 255.00 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28956/47780 [02:35<00:47, 397.14 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45099/47780 [02:35<00:13, 200.63 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44537/47780 [02:35<00:11, 279.19 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43159/47780 [02:35<00:15, 290.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43588/47780 [02:35<00:15, 269.63 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44493/47780 [02:35<00:13, 251.08 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45203/47780 [02:35<00:12, 204.50 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29004/47780 [02:35<00:45, 416.97 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43997/47780 [02:35<00:14, 256.54 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45121/47780 [02:35<00:13, 191.12 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44566/47780 [02:35<00:11, 279.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43190/47780 [02:35<00:15, 292.72 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43617/47780 [02:35<00:15, 261.29 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44526/47780 [02:35<00:12, 266.78 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29056/47780 [02:35<00:42, 445.01 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44059/47780 [02:35<00:11, 338.19 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45225/47780 [02:35<00:13, 183.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45141/47780 [02:35<00:13, 189.40 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44595/47780 [02:35<00:12, 251.26 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44555/47780 [02:35<00:11, 270.31 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43220/47780 [02:35<00:17, 264.24 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43644/47780 [02:35<00:16, 250.12 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44096/47780 [02:35<00:11, 332.78 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29102/47780 [02:35<00:45, 407.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45246/47780 [02:35<00:13, 189.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45161/47780 [02:35<00:15, 171.84 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44622/47780 [02:35<00:12, 253.85 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44588/47780 [02:35<00:11, 283.93 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43256/47780 [02:35<00:15, 285.18 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29164/47780 [02:35<00:40, 458.39 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43670/47780 [02:35<00:17, 235.45 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44132/47780 [02:35<00:11, 330.05 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45266/47780 [02:35<00:13, 186.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45181/47780 [02:35<00:14, 178.80 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44653/47780 [02:35<00:08, 379.50 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44649/47780 [02:35<00:13, 237.72 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43288/47780 [02:35<00:15, 285.19 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45289/47780 [02:35<00:12, 197.44 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43694/47780 [02:35<00:17, 229.52 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29211/47780 [02:35<00:42, 442.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44171/47780 [02:35<00:10, 334.90 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45201/47780 [02:35<00:14, 176.81 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44674/47780 [02:35<00:13, 238.49 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43318/47780 [02:35<00:15, 282.80 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44692/47780 [02:35<00:08, 350.25 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43729/47780 [02:35<00:15, 261.31 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29257/47780 [02:35<00:42, 437.61 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44206/47780 [02:35<00:11, 312.09 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45223/47780 [02:35<00:13, 184.55 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45310/47780 [02:35<00:14, 166.83 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44699/47780 [02:35<00:12, 241.58 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43757/47780 [02:35<00:15, 260.96 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29303/47780 [02:35<00:42, 438.01 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44728/47780 [02:35<00:09, 321.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44261/47780 [02:35<00:09, 370.35 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43349/47780 [02:35<00:18, 243.01 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45246/47780 [02:35<00:12, 197.02 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44729/47780 [02:35<00:11, 254.92 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45330/47780 [02:36<00:14, 170.45 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43785/47780 [02:35<00:15, 263.43 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44762/47780 [02:35<00:09, 323.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29348/47780 [02:35<00:43, 423.19 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43396/47780 [02:36<00:14, 298.71 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45269/47780 [02:36<00:12, 206.12 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44300/47780 [02:36<00:09, 348.80 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45354/47780 [02:36<00:12, 187.43 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44755/47780 [02:36<00:12, 250.74 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43812/47780 [02:36<00:15, 264.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44796/47780 [02:36<00:09, 320.90 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45292/47780 [02:36<00:11, 210.75 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43428/47780 [02:36<00:14, 298.04 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29392/47780 [02:36<00:46, 392.97 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44337/47780 [02:36<00:09, 351.20 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44782/47780 [02:36<00:11, 250.55 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45383/47780 [02:36<00:11, 203.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43845/47780 [02:36<00:14, 271.71 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43462/47780 [02:36<00:13, 309.19 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29452/47780 [02:36<00:40, 447.98 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44373/47780 [02:36<00:09, 353.19 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44829/47780 [02:36<00:10, 282.41 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45314/47780 [02:36<00:12, 195.46 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45406/47780 [02:36<00:11, 208.44 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44808/47780 [02:36<00:12, 242.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43875/47780 [02:36<00:14, 267.67 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29498/47780 [02:36<00:40, 451.07 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43495/47780 [02:36<00:14, 304.56 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44862/47780 [02:36<00:10, 289.30 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45341/47780 [02:36<00:11, 213.47 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44412/47780 [02:36<00:09, 336.97 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44843/47780 [02:36<00:10, 269.23 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45428/47780 [02:36<00:11, 198.63 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43915/47780 [02:36<00:12, 301.05 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43527/47780 [02:36<00:13, 305.37 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44447/47780 [02:36<00:09, 337.24 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45363/47780 [02:36<00:11, 203.94 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44871/47780 [02:36<00:10, 268.59 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44893/47780 [02:36<00:10, 265.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45449/47780 [02:36<00:12, 193.31 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43946/47780 [02:36<00:13, 290.63 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29544/47780 [02:36<00:53, 342.01 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43559/47780 [02:36<00:15, 278.70 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45388/47780 [02:36<00:11, 211.89 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44482/47780 [02:36<00:10, 325.93 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45471/47780 [02:36<00:11, 199.55 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44898/47780 [02:36<00:11, 247.13 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29636/47780 [02:36<00:38, 472.36 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44921/47780 [02:36<00:12, 234.62 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43588/47780 [02:36<00:15, 275.86 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45411/47780 [02:36<00:11, 214.55 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43977/47780 [02:36<00:15, 248.90 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44515/47780 [02:36<00:10, 301.23 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45492/47780 [02:36<00:11, 200.45 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44924/47780 [02:36<00:12, 221.75 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44946/47780 [02:36<00:12, 233.62 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43624/47780 [02:36<00:13, 298.54 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29690/47780 [02:36<00:42, 429.41 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44004/47780 [02:36<00:16, 235.33 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45433/47780 [02:36<00:12, 186.68 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45513/47780 [02:36<00:12, 183.32 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44948/47780 [02:36<00:12, 226.32 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44546/47780 [02:36<00:12, 259.53 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43656/47780 [02:36<00:13, 304.50 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29739/47780 [02:36<00:41, 435.01 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44971/47780 [02:36<00:13, 212.24 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44067/47780 [02:36<00:11, 331.68 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45455/47780 [02:36<00:11, 194.06 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45532/47780 [02:37<00:12, 185.08 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44973/47780 [02:36<00:12, 229.91 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44600/47780 [02:36<00:09, 327.92 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43687/47780 [02:37<00:13, 295.97 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29793/47780 [02:36<00:39, 452.80 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44995/47780 [02:37<00:12, 214.91 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44103/47780 [02:37<00:11, 323.02 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45551/47780 [02:37<00:12, 184.33 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45476/47780 [02:37<00:12, 189.32 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45002/47780 [02:37<00:11, 243.95 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43718/47780 [02:37<00:13, 296.59 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44636/47780 [02:37<00:10, 301.61 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29841/47780 [02:37<00:40, 440.81 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45018/47780 [02:37<00:13, 210.24 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44149/47780 [02:37<00:10, 356.31 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45572/47780 [02:37<00:11, 187.40 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45502/47780 [02:37<00:11, 201.78 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45027/47780 [02:37<00:12, 225.39 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43748/47780 [02:37<00:13, 290.08 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44669/47780 [02:37<00:10, 295.01 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29888/47780 [02:37<00:40, 439.95 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45040/47780 [02:37<00:13, 206.42 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44188/47780 [02:37<00:10, 336.26 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45591/47780 [02:37<00:12, 181.98 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45523/47780 [02:37<00:11, 201.55 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43778/47780 [02:37<00:14, 280.45 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45051/47780 [02:37<00:13, 209.25 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44700/47780 [02:37<00:10, 295.15 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45061/47780 [02:37<00:13, 203.01 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29934/47780 [02:37<00:43, 410.04 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44224/47780 [02:37<00:10, 332.03 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45610/47780 [02:37<00:12, 177.36 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45544/47780 [02:37<00:11, 187.41 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43808/47780 [02:37<00:14, 283.27 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45074/47780 [02:37<00:12, 212.44 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44731/47780 [02:37<00:10, 291.17 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45083/47780 [02:37<00:13, 207.11 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29978/47780 [02:37<00:45, 393.28 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44262/47780 [02:37<00:10, 337.61 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45630/47780 [02:37<00:11, 180.53 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45567/47780 [02:37<00:11, 198.50 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43842/47780 [02:37<00:13, 299.30 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45104/47780 [02:37<00:12, 206.18 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45096/47780 [02:37<00:13, 203.65 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44761/47780 [02:37<00:11, 271.57 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44297/47780 [02:37<00:10, 337.27 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45649/47780 [02:37<00:11, 181.17 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30021/47780 [02:37<00:45, 386.47 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45590/47780 [02:37<00:11, 188.89 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43873/47780 [02:37<00:13, 280.34 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45117/47780 [02:37<00:12, 204.97 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44789/47780 [02:37<00:11, 262.93 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45125/47780 [02:37<00:14, 184.17 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30061/47780 [02:37<00:45, 386.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45668/47780 [02:37<00:12, 173.94 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44332/47780 [02:37<00:10, 313.53 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43902/47780 [02:37<00:13, 282.60 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45611/47780 [02:37<00:11, 190.47 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45149/47780 [02:37<00:11, 234.60 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45145/47780 [02:37<00:14, 182.75 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44816/47780 [02:37<00:12, 246.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30107/47780 [02:37<00:44, 393.45 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45686/47780 [02:37<00:12, 166.06 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44365/47780 [02:37<00:11, 307.58 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43940/47780 [02:37<00:12, 309.78 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45173/47780 [02:37<00:11, 223.39 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45631/47780 [02:37<00:12, 172.56 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45164/47780 [02:37<00:14, 180.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44844/47780 [02:37<00:11, 255.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30157/47780 [02:37<00:42, 413.47 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45703/47780 [02:38<00:12, 162.07 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44397/47780 [02:37<00:11, 301.20 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43972/47780 [02:37<00:12, 305.95 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45196/47780 [02:37<00:12, 202.89 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45649/47780 [02:38<00:13, 160.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45185/47780 [02:38<00:14, 184.84 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30217/47780 [02:38<00:38, 456.20 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44873/47780 [02:38<00:11, 248.67 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44432/47780 [02:38<00:10, 310.61 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45726/47780 [02:38<00:11, 174.94 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44004/47780 [02:38<00:12, 306.46 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45220/47780 [02:38<00:12, 212.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45214/47780 [02:38<00:12, 209.20 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30266/47780 [02:38<00:37, 464.33 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45671/47780 [02:38<00:12, 169.69 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44901/47780 [02:38<00:11, 254.29 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44464/47780 [02:38<00:10, 303.71 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45744/47780 [02:38<00:11, 171.31 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44035/47780 [02:38<00:12, 290.73 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45255/47780 [02:38<00:10, 247.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45237/47780 [02:38<00:11, 212.64 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30313/47780 [02:38<00:37, 460.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45689/47780 [02:38<00:12, 172.29 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44966/47780 [02:38<00:07, 359.11 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44508/47780 [02:38<00:09, 341.41 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45766/47780 [02:38<00:10, 184.18 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44065/47780 [02:38<00:13, 283.87 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45293/47780 [02:38<00:08, 283.96 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30361/47780 [02:38<00:37, 463.06 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45265/47780 [02:38<00:11, 226.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45707/47780 [02:38<00:12, 172.10 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45004/47780 [02:38<00:07, 361.63 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45785/47780 [02:38<00:10, 184.35 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44543/47780 [02:38<00:09, 336.13 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44100/47780 [02:38<00:12, 298.69 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45323/47780 [02:38<00:08, 274.23 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45732/47780 [02:38<00:10, 192.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45294/47780 [02:38<00:10, 243.38 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30409/47780 [02:38<00:38, 454.90 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45041/47780 [02:38<00:07, 350.77 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44579/47780 [02:38<00:09, 333.95 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44137/47780 [02:38<00:11, 315.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45804/47780 [02:38<00:11, 171.55 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45351/47780 [02:38<00:09, 263.19 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45752/47780 [02:38<00:10, 187.45 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45325/47780 [02:38<00:09, 246.71 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45078/47780 [02:38<00:07, 344.59 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44623/47780 [02:38<00:09, 349.58 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30455/47780 [02:38<00:43, 397.59 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45825/47780 [02:38<00:10, 180.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44169/47780 [02:38<00:12, 290.21 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45384/47780 [02:38<00:08, 278.50 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45771/47780 [02:38<00:11, 180.43 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44668/47780 [02:38<00:08, 373.61 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45113/47780 [02:38<00:08, 320.95 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30504/47780 [02:38<00:41, 414.21 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45844/47780 [02:38<00:10, 181.28 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45350/47780 [02:38<00:11, 220.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44199/47780 [02:38<00:12, 290.66 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45422/47780 [02:38<00:07, 306.78 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45791/47780 [02:38<00:10, 185.73 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45147/47780 [02:38<00:08, 322.28 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45374/47780 [02:38<00:10, 225.45 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44708/47780 [02:38<00:08, 364.47 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45863/47780 [02:38<00:10, 179.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44229/47780 [02:38<00:12, 276.91 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45454/47780 [02:38<00:07, 299.73 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45811/47780 [02:38<00:10, 185.51 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30547/47780 [02:38<00:50, 340.60 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45397/47780 [02:38<00:10, 224.23 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45181/47780 [02:38<00:08, 320.87 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45883/47780 [02:38<00:10, 179.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44745/47780 [02:38<00:08, 346.05 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44263/47780 [02:38<00:12, 284.40 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30649/47780 [02:38<00:34, 502.32 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45486/47780 [02:38<00:08, 286.52 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45831/47780 [02:39<00:10, 180.70 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45223/47780 [02:39<00:07, 348.06 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45422/47780 [02:39<00:10, 225.89 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45906/47780 [02:39<00:09, 193.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44783/47780 [02:39<00:08, 333.79 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44294/47780 [02:39<00:12, 279.60 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45850/47780 [02:39<00:11, 174.29 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30707/47780 [02:39<00:35, 482.61 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45927/47780 [02:39<00:09, 196.51 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45516/47780 [02:39<00:08, 263.82 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45259/47780 [02:39<00:07, 332.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45452/47780 [02:39<00:09, 235.60 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44335/47780 [02:39<00:10, 314.81 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44817/47780 [02:39<00:09, 297.83 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45868/47780 [02:39<00:11, 170.70 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30762/47780 [02:39<00:34, 489.93 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45476/47780 [02:39<00:09, 234.21 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45294/47780 [02:39<00:07, 324.96 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45543/47780 [02:39<00:08, 252.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45947/47780 [02:39<00:10, 180.44 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44368/47780 [02:39<00:11, 302.27 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44848/47780 [02:39<00:09, 294.16 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45886/47780 [02:39<00:11, 165.49 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45500/47780 [02:39<00:09, 229.39 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45330/47780 [02:39<00:07, 328.95 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45569/47780 [02:39<00:08, 249.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45966/47780 [02:39<00:10, 180.36 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30818/47780 [02:39<00:38, 437.49 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44420/47780 [02:39<00:09, 358.62 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45905/47780 [02:39<00:11, 167.53 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44878/47780 [02:39<00:11, 262.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45524/47780 [02:39<00:10, 223.66 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45364/47780 [02:39<00:07, 314.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45986/47780 [02:39<00:09, 181.53 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30878/47780 [02:39<00:35, 474.79 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45595/47780 [02:39<00:09, 223.48 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44459/47780 [02:39<00:09, 359.40 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45925/47780 [02:39<00:10, 173.50 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44907/47780 [02:39<00:10, 269.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45547/47780 [02:39<00:10, 221.62 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46014/47780 [02:39<00:08, 200.96 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45403/47780 [02:39<00:07, 321.14 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30929/47780 [02:39<00:35, 472.98 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45623/47780 [02:39<00:09, 229.27 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44496/47780 [02:39<00:09, 349.80 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44943/47780 [02:39<00:09, 291.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45946/47780 [02:39<00:10, 174.06 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45570/47780 [02:39<00:10, 209.82 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30985/47780 [02:39<00:34, 491.74 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46035/47780 [02:39<00:09, 192.80 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45436/47780 [02:39<00:07, 303.27 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44533/47780 [02:39<00:09, 351.94 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45647/47780 [02:39<00:09, 224.04 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44974/47780 [02:39<00:09, 286.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45971/47780 [02:39<00:09, 189.32 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45592/47780 [02:39<00:10, 206.35 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46060/47780 [02:39<00:08, 208.39 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31037/47780 [02:39<00:33, 492.76 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45467/47780 [02:39<00:08, 286.60 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45670/47780 [02:39<00:09, 215.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45010/47780 [02:39<00:09, 296.61 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44570/47780 [02:39<00:10, 302.51 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45992/47780 [02:39<00:09, 186.79 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45618/47780 [02:39<00:09, 220.75 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31088/47780 [02:39<00:34, 482.66 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46082/47780 [02:39<00:08, 202.65 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45499/47780 [02:39<00:07, 289.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45700/47780 [02:39<00:08, 236.04 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44614/47780 [02:40<00:09, 337.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45042/47780 [02:39<00:09, 299.33 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46018/47780 [02:40<00:08, 206.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45651/47780 [02:40<00:08, 251.31 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31138/47780 [02:40<00:34, 487.38 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46114/47780 [02:40<00:07, 232.56 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45727/47780 [02:40<00:08, 241.68 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45529/47780 [02:40<00:08, 280.47 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45083/47780 [02:40<00:08, 327.07 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44666/47780 [02:40<00:08, 385.41 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45681/47780 [02:40<00:08, 252.96 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31191/47780 [02:40<00:33, 489.57 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46039/47780 [02:40<00:09, 192.21 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46138/47780 [02:40<00:07, 216.52 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45759/47780 [02:40<00:07, 261.94 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45558/47780 [02:40<00:07, 280.65 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44710/47780 [02:40<00:07, 392.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45117/47780 [02:40<00:08, 319.92 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31246/47780 [02:40<00:32, 501.92 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46061/47780 [02:40<00:08, 199.70 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45717/47780 [02:40<00:07, 271.53 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45589/47780 [02:40<00:07, 278.55 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45786/47780 [02:40<00:08, 245.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46162/47780 [02:40<00:08, 195.96 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45151/47780 [02:40<00:08, 311.10 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44751/47780 [02:40<00:08, 369.28 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31298/47780 [02:40<00:32, 504.83 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46082/47780 [02:40<00:08, 202.53 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45745/47780 [02:40<00:08, 248.96 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45617/47780 [02:40<00:08, 261.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45812/47780 [02:40<00:08, 241.07 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45184/47780 [02:40<00:08, 311.96 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46108/47780 [02:40<00:07, 218.63 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46185/47780 [02:40<00:08, 185.98 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44789/47780 [02:40<00:08, 344.78 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31349/47780 [02:40<00:35, 463.54 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45771/47780 [02:40<00:08, 239.25 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45649/47780 [02:40<00:07, 277.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45837/47780 [02:40<00:08, 237.22 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45221/47780 [02:40<00:07, 324.51 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46135/47780 [02:40<00:07, 231.19 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44833/47780 [02:40<00:07, 369.61 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46205/47780 [02:40<00:08, 182.84 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31397/47780 [02:40<00:36, 453.10 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45799/47780 [02:40<00:08, 245.64 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45686/47780 [02:40<00:07, 298.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45866/47780 [02:40<00:07, 250.86 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46160/47780 [02:40<00:07, 225.98 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44871/47780 [02:40<00:08, 360.59 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45255/47780 [02:40<00:08, 292.93 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31456/47780 [02:40<00:33, 485.74 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45718/47780 [02:40<00:06, 304.02 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45895/47780 [02:40<00:07, 261.54 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45825/47780 [02:40<00:08, 241.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46224/47780 [02:40<00:09, 163.72 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44909/47780 [02:40<00:08, 355.15 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46183/47780 [02:40<00:07, 208.35 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31506/47780 [02:40<00:34, 468.26 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45749/47780 [02:40<00:06, 300.86 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45851/47780 [02:40<00:07, 245.88 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45286/47780 [02:40<00:09, 269.47 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46241/47780 [02:40<00:10, 152.27 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45922/47780 [02:40<00:08, 230.29 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44949/47780 [02:40<00:07, 367.10 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31556/47780 [02:40<00:34, 472.46 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46205/47780 [02:40<00:07, 200.64 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45314/47780 [02:40<00:09, 269.39 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45780/47780 [02:40<00:06, 293.09 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45877/47780 [02:40<00:08, 222.43 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46257/47780 [02:41<00:10, 146.74 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45946/47780 [02:40<00:08, 224.89 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44987/47780 [02:41<00:07, 366.77 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31604/47780 [02:40<00:34, 468.56 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45344/47780 [02:41<00:08, 274.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46227/47780 [02:41<00:07, 194.31 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45810/47780 [02:41<00:07, 276.52 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45900/47780 [02:41<00:08, 222.09 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46277/47780 [02:41<00:09, 157.73 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45971/47780 [02:41<00:07, 226.71 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45025/47780 [02:41<00:07, 359.00 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46250/47780 [02:41<00:07, 195.32 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45843/47780 [02:41<00:06, 288.05 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45373/47780 [02:41<00:09, 257.44 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31652/47780 [02:41<00:39, 411.71 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46295/47780 [02:41<00:09, 161.12 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45923/47780 [02:41<00:08, 210.57 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45995/47780 [02:41<00:08, 220.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45062/47780 [02:41<00:08, 338.62 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31726/47780 [02:41<00:32, 489.98 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45875/47780 [02:41<00:06, 285.69 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45406/47780 [02:41<00:08, 267.00 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46271/47780 [02:41<00:08, 178.27 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46312/47780 [02:41<00:09, 156.83 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45945/47780 [02:41<00:08, 206.06 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46020/47780 [02:41<00:07, 228.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45098/47780 [02:41<00:08, 331.35 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31780/47780 [02:41<00:31, 500.56 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45445/47780 [02:41<00:08, 290.26 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46294/47780 [02:41<00:07, 191.23 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45904/47780 [02:41<00:07, 262.97 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45973/47780 [02:41<00:08, 219.32 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46328/47780 [02:41<00:09, 146.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46044/47780 [02:41<00:08, 215.03 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45132/47780 [02:41<00:08, 314.93 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31832/47780 [02:41<00:31, 499.53 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45477/47780 [02:41<00:07, 288.96 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45997/47780 [02:41<00:07, 223.08 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46314/47780 [02:41<00:08, 178.40 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45931/47780 [02:41<00:07, 247.09 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46066/47780 [02:41<00:08, 210.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46344/47780 [02:41<00:10, 138.70 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45177/47780 [02:41<00:07, 329.70 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31883/47780 [02:41<00:33, 480.93 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45509/47780 [02:41<00:07, 294.46 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46021/47780 [02:41<00:08, 217.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46333/47780 [02:41<00:08, 170.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45958/47780 [02:41<00:07, 231.39 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46088/47780 [02:41<00:08, 195.81 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46360/47780 [02:41<00:10, 138.57 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45214/47780 [02:41<00:07, 334.20 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31941/47780 [02:41<00:31, 498.14 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45547/47780 [02:41<00:07, 301.26 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46046/47780 [02:41<00:07, 224.23 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45987/47780 [02:41<00:07, 245.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46351/47780 [02:41<00:08, 162.98 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31996/47780 [02:41<00:30, 512.56 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45250/47780 [02:41<00:07, 337.45 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46108/47780 [02:41<00:09, 184.54 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46374/47780 [02:41<00:10, 128.05 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45578/47780 [02:41<00:07, 294.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46069/47780 [02:41<00:08, 211.58 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46013/47780 [02:41<00:07, 233.20 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32051/47780 [02:41<00:30, 518.88 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45284/47780 [02:41<00:07, 328.31 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46368/47780 [02:41<00:09, 150.73 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46387/47780 [02:41<00:11, 126.12 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46129/47780 [02:41<00:09, 181.71 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45608/47780 [02:41<00:07, 278.08 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46092/47780 [02:42<00:08, 199.78 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45318/47780 [02:42<00:07, 327.67 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32106/47780 [02:42<00:31, 503.06 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46384/47780 [02:42<00:09, 149.68 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46037/47780 [02:42<00:07, 219.12 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46148/47780 [02:42<00:09, 180.41 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46405/47780 [02:42<00:10, 135.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45639/47780 [02:42<00:07, 282.38 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46116/47780 [02:42<00:08, 207.59 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45360/47780 [02:42<00:06, 349.01 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32158/47780 [02:42<00:31, 503.71 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46403/47780 [02:42<00:08, 157.15 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46168/47780 [02:42<00:08, 185.48 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46060/47780 [02:42<00:07, 215.22 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46420/47780 [02:42<00:10, 132.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45671/47780 [02:42<00:07, 288.35 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46140/47780 [02:42<00:07, 213.01 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32210/47780 [02:42<00:30, 504.21 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46423/47780 [02:42<00:08, 165.31 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45395/47780 [02:42<00:07, 332.19 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46082/47780 [02:42<00:08, 208.12 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46187/47780 [02:42<00:09, 173.20 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45705/47780 [02:42<00:06, 301.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46434/47780 [02:42<00:10, 125.69 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46170/47780 [02:42<00:06, 231.45 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32261/47780 [02:42<00:32, 470.98 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45429/47780 [02:42<00:07, 315.30 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46112/47780 [02:42<00:07, 225.07 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46440/47780 [02:42<00:09, 148.38 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45737/47780 [02:42<00:06, 297.53 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46207/47780 [02:42<00:09, 169.79 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46452/47780 [02:42<00:10, 131.13 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46195/47780 [02:42<00:06, 231.60 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45465/47780 [02:42<00:07, 326.65 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46140/47780 [02:42<00:06, 237.12 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32310/47780 [02:42<00:34, 449.01 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46225/47780 [02:42<00:09, 168.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45768/47780 [02:42<00:06, 290.23 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46456/47780 [02:42<00:09, 136.87 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46469/47780 [02:42<00:09, 135.01 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46220/47780 [02:42<00:06, 226.83 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32359/47780 [02:42<00:33, 454.60 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46166/47780 [02:42<00:06, 238.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45498/47780 [02:42<00:07, 314.20 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46245/47780 [02:42<00:09, 168.06 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45798/47780 [02:42<00:07, 272.53 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46475/47780 [02:42<00:08, 148.00 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46484/47780 [02:42<00:09, 134.61 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46244/47780 [02:42<00:07, 210.59 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45542/47780 [02:42<00:06, 345.39 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32421/47780 [02:42<00:31, 492.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46195/47780 [02:42<00:06, 243.75 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46262/47780 [02:42<00:09, 163.02 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45826/47780 [02:42<00:07, 264.00 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46509/47780 [02:42<00:08, 157.28 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46495/47780 [02:42<00:08, 149.44 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45577/47780 [02:42<00:06, 346.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32498/47780 [02:42<00:27, 563.96 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46266/47780 [02:42<00:08, 187.64 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46286/47780 [02:42<00:08, 178.66 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45870/47780 [02:42<00:06, 307.37 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46220/47780 [02:42<00:07, 211.10 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46514/47780 [02:42<00:07, 158.74 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46526/47780 [02:42<00:08, 154.11 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32567/47780 [02:42<00:25, 592.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45612/47780 [02:42<00:06, 328.74 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46247/47780 [02:42<00:06, 223.47 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45904/47780 [02:42<00:06, 305.97 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46287/47780 [02:42<00:08, 176.99 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46304/47780 [02:42<00:08, 167.42 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32630/47780 [02:42<00:25, 583.56 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45646/47780 [02:43<00:06, 321.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46542/47780 [02:43<00:08, 139.93 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46531/47780 [02:43<00:08, 140.48 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46276/47780 [02:43<00:06, 236.78 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46321/47780 [02:43<00:08, 165.66 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46306/47780 [02:43<00:08, 169.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45935/47780 [02:43<00:06, 282.16 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32689/47780 [02:43<00:26, 564.71 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45679/47780 [02:43<00:06, 318.77 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46548/47780 [02:43<00:08, 144.71 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46557/47780 [02:43<00:09, 135.42 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46301/47780 [02:43<00:06, 235.71 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46342/47780 [02:43<00:08, 173.59 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46327/47780 [02:43<00:08, 177.05 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45965/47780 [02:43<00:06, 272.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32755/47780 [02:43<00:25, 590.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45716/47780 [02:43<00:06, 331.32 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46566/47780 [02:43<00:07, 153.28 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46578/47780 [02:43<00:08, 149.53 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46327/47780 [02:43<00:06, 239.46 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46354/47780 [02:43<00:07, 200.79 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46360/47780 [02:43<00:08, 166.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45995/47780 [02:43<00:06, 278.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32823/47780 [02:43<00:24, 604.81 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45751/47780 [02:43<00:06, 320.75 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46592/47780 [02:43<00:06, 171.30 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46602/47780 [02:43<00:07, 159.05 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46352/47780 [02:43<00:06, 225.02 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46377/47780 [02:43<00:08, 164.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46376/47780 [02:43<00:07, 195.60 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32895/47780 [02:43<00:23, 625.78 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46026/47780 [02:43<00:06, 270.74 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45786/47780 [02:43<00:06, 316.19 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46611/47780 [02:43<00:06, 174.47 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46622/47780 [02:43<00:07, 164.18 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46395/47780 [02:43<00:08, 166.08 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46062/47780 [02:43<00:05, 294.56 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32971/47780 [02:43<00:22, 658.82 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46398/47780 [02:43<00:07, 190.09 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46375/47780 [02:43<00:06, 200.86 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45825/47780 [02:43<00:05, 335.40 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46629/47780 [02:43<00:07, 157.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46413/47780 [02:43<00:08, 160.67 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46639/47780 [02:43<00:07, 149.14 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46418/47780 [02:43<00:07, 192.02 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46399/47780 [02:43<00:06, 205.78 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33039/47780 [02:43<00:23, 624.60 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46092/47780 [02:43<00:06, 270.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45859/47780 [02:43<00:06, 309.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46646/47780 [02:43<00:07, 146.93 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46435/47780 [02:43<00:07, 171.18 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46655/47780 [02:43<00:07, 144.93 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46439/47780 [02:43<00:07, 187.98 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46425/47780 [02:43<00:06, 218.84 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33109/47780 [02:43<00:22, 640.72 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46121/47780 [02:43<00:06, 274.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45892/47780 [02:43<00:06, 313.93 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46456/47780 [02:43<00:07, 177.94 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46676/47780 [02:43<00:06, 160.43 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46459/47780 [02:43<00:07, 188.24 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46450/47780 [02:43<00:05, 224.94 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33174/47780 [02:43<00:23, 623.59 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46662/47780 [02:43<00:08, 136.76 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46149/47780 [02:43<00:06, 256.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45924/47780 [02:43<00:06, 298.28 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46474/47780 [02:43<00:07, 178.40 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46694/47780 [02:44<00:06, 162.97 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46482/47780 [02:43<00:06, 196.65 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46473/47780 [02:43<00:06, 216.82 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33237/47780 [02:43<00:23, 608.65 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46676/47780 [02:44<00:08, 135.17 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45957/47780 [02:44<00:05, 305.88 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46177/47780 [02:43<00:06, 246.55 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46504/47780 [02:44<00:06, 198.48 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46497/47780 [02:44<00:07, 178.07 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33301/47780 [02:44<00:23, 607.38 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46497/47780 [02:44<00:06, 210.16 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46697/47780 [02:44<00:07, 146.46 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46711/47780 [02:44<00:07, 148.07 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45991/47780 [02:44<00:05, 308.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46211/47780 [02:44<00:05, 265.18 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46517/47780 [02:44<00:07, 177.83 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46524/47780 [02:44<00:06, 188.36 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46522/47780 [02:44<00:05, 220.25 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33362/47780 [02:44<00:24, 580.20 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46727/47780 [02:44<00:07, 145.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46712/47780 [02:44<00:07, 134.76 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46239/47780 [02:44<00:06, 253.01 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46023/47780 [02:44<00:06, 282.84 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46540/47780 [02:44<00:06, 190.16 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46543/47780 [02:44<00:06, 186.76 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33422/47780 [02:44<00:25, 568.94 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46545/47780 [02:44<00:05, 215.53 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46743/47780 [02:44<00:07, 140.51 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46056/47780 [02:44<00:06, 286.26 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46266/47780 [02:44<00:06, 249.33 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46727/47780 [02:44<00:08, 123.60 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46569/47780 [02:44<00:05, 205.75 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46572/47780 [02:44<00:05, 228.05 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46560/47780 [02:44<00:06, 179.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33481/47780 [02:44<00:25, 561.01 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46763/47780 [02:44<00:06, 150.34 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46293/47780 [02:44<00:05, 254.48 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46086/47780 [02:44<00:05, 286.19 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46740/47780 [02:44<00:08, 122.22 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46590/47780 [02:44<00:05, 204.98 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33543/47780 [02:44<00:24, 577.27 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46580/47780 [02:44<00:06, 177.18 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46597/47780 [02:44<00:05, 216.96 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46779/47780 [02:44<00:06, 148.74 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46320/47780 [02:44<00:05, 253.05 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46116/47780 [02:44<00:05, 286.30 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46754/47780 [02:44<00:08, 121.35 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46612/47780 [02:44<00:05, 201.02 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33602/47780 [02:44<00:24, 573.73 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46602/47780 [02:44<00:06, 186.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46621/47780 [02:44<00:05, 221.49 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46794/47780 [02:44<00:06, 149.08 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46349/47780 [02:44<00:05, 263.10 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46146/47780 [02:44<00:06, 268.04 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46636/47780 [02:44<00:05, 207.95 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46769/47780 [02:44<00:08, 124.50 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33671/47780 [02:44<00:23, 600.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46624/47780 [02:44<00:05, 194.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46648/47780 [02:44<00:04, 226.63 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46814/47780 [02:44<00:06, 159.19 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46376/47780 [02:44<00:05, 240.50 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33732/47780 [02:44<00:23, 601.18 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46657/47780 [02:44<00:05, 204.46 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46782/47780 [02:44<00:08, 122.16 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46174/47780 [02:44<00:06, 246.54 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46644/47780 [02:44<00:06, 186.85 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46832/47780 [02:44<00:05, 162.68 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46671/47780 [02:44<00:05, 195.67 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33796/47780 [02:44<00:22, 609.36 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46796/47780 [02:44<00:07, 124.09 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46402/47780 [02:44<00:06, 221.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46200/47780 [02:44<00:06, 242.53 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46665/47780 [02:44<00:06, 184.51 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46679/47780 [02:44<00:05, 183.66 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46850/47780 [02:45<00:06, 153.98 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46692/47780 [02:45<00:05, 197.29 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33858/47780 [02:45<00:23, 591.56 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46229/47780 [02:45<00:06, 246.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46425/47780 [02:45<00:06, 214.16 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46809/47780 [02:45<00:08, 109.85 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46699/47780 [02:45<00:06, 178.23 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46684/47780 [02:45<00:06, 164.05 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46874/47780 [02:45<00:05, 162.05 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46714/47780 [02:45<00:05, 190.98 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33918/47780 [02:45<00:23, 584.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46261/47780 [02:45<00:05, 260.84 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46449/47780 [02:45<00:06, 213.92 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46719/47780 [02:45<00:05, 176.99 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46821/47780 [02:45<00:09, 104.86 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46701/47780 [02:45<00:06, 161.52 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33987/47780 [02:45<00:22, 613.52 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46736/47780 [02:45<00:05, 196.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46892/47780 [02:45<00:05, 160.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46288/47780 [02:45<00:05, 259.97 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46473/47780 [02:45<00:06, 215.08 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46737/47780 [02:45<00:06, 165.98 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46832/47780 [02:45<00:09, 101.37 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46718/47780 [02:45<00:07, 149.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34050/47780 [02:45<00:23, 575.04 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46756/47780 [02:45<00:05, 172.09 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46909/47780 [02:45<00:05, 145.78 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46316/47780 [02:45<00:06, 237.21 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46495/47780 [02:45<00:06, 188.17 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46754/47780 [02:45<00:06, 159.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34110/47780 [02:45<00:23, 574.38 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46843/47780 [02:45<00:09, 94.10 examples/s] Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46734/47780 [02:45<00:07, 144.39 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46925/47780 [02:45<00:05, 146.68 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46344/47780 [02:45<00:05, 247.61 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46774/47780 [02:45<00:06, 159.60 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46515/47780 [02:45<00:06, 187.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46776/47780 [02:45<00:05, 174.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34168/47780 [02:45<00:23, 570.39 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46749/47780 [02:45<00:07, 140.55 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46945/47780 [02:45<00:05, 159.20 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46858/47780 [02:45<00:09, 99.04 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46372/47780 [02:45<00:05, 245.66 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46794/47780 [02:45<00:05, 167.82 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46794/47780 [02:45<00:05, 173.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46536/47780 [02:45<00:06, 183.91 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34227/47780 [02:45<00:24, 559.82 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46766/47780 [02:45<00:07, 144.54 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46873/47780 [02:45<00:08, 108.98 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46963/47780 [02:45<00:05, 156.15 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46397/47780 [02:45<00:05, 241.57 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46558/47780 [02:45<00:06, 192.01 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46812/47780 [02:45<00:06, 158.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46818/47780 [02:45<00:05, 185.00 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34291/47780 [02:45<00:23, 577.09 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46781/47780 [02:45<00:07, 139.35 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46890/47780 [02:45<00:07, 122.93 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46423/47780 [02:45<00:05, 241.87 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46833/47780 [02:45<00:05, 169.54 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46840/47780 [02:45<00:04, 193.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46580/47780 [02:45<00:06, 192.49 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46979/47780 [02:45<00:05, 135.06 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34350/47780 [02:45<00:24, 553.64 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46448/47780 [02:45<00:05, 243.01 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46798/47780 [02:45<00:07, 138.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46907/47780 [02:46<00:07, 123.96 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46998/47780 [02:46<00:05, 146.45 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46600/47780 [02:45<00:06, 180.31 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46851/47780 [02:46<00:05, 156.46 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46860/47780 [02:46<00:05, 172.19 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34406/47780 [02:46<00:25, 525.59 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46474/47780 [02:46<00:05, 247.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46814/47780 [02:46<00:07, 137.34 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46922/47780 [02:46<00:07, 118.27 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46619/47780 [02:46<00:06, 181.73 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47017/47780 [02:46<00:05, 151.91 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46879/47780 [02:46<00:05, 170.08 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34459/47780 [02:46<00:25, 512.71 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46868/47780 [02:46<00:06, 143.68 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46500/47780 [02:46<00:05, 230.88 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46829/47780 [02:46<00:06, 136.72 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47035/47780 [02:46<00:04, 153.98 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46936/47780 [02:46<00:07, 115.41 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34515/47780 [02:46<00:25, 520.24 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46898/47780 [02:46<00:05, 172.02 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46638/47780 [02:46<00:06, 168.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46884/47780 [02:46<00:06, 140.17 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46851/47780 [02:46<00:06, 150.84 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46525/47780 [02:46<00:05, 211.53 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47051/47780 [02:46<00:04, 151.67 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34572/47780 [02:46<00:24, 530.99 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46948/47780 [02:46<00:07, 112.55 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46657/47780 [02:46<00:06, 169.90 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46917/47780 [02:46<00:05, 171.25 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46901/47780 [02:46<00:05, 146.57 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46868/47780 [02:46<00:06, 150.96 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47069/47780 [02:46<00:04, 158.08 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46547/47780 [02:46<00:06, 201.51 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34631/47780 [02:46<00:24, 545.31 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46676/47780 [02:46<00:06, 170.01 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46938/47780 [02:46<00:04, 176.20 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46960/47780 [02:46<00:07, 104.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46916/47780 [02:46<00:06, 143.90 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46884/47780 [02:46<00:05, 153.14 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47088/47780 [02:46<00:04, 166.65 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34687/47780 [02:46<00:24, 527.91 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46962/47780 [02:46<00:04, 192.18 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46568/47780 [02:46<00:06, 178.91 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46697/47780 [02:46<00:06, 166.70 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46933/47780 [02:46<00:05, 148.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46971/47780 [02:46<00:07, 101.71 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46900/47780 [02:46<00:06, 144.82 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34744/47780 [02:46<00:24, 528.19 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47105/47780 [02:46<00:04, 153.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46982/47780 [02:46<00:04, 188.45 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46949/47780 [02:46<00:05, 143.64 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46719/47780 [02:46<00:06, 166.00 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46985/47780 [02:46<00:07, 101.19 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46588/47780 [02:46<00:07, 165.84 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46919/47780 [02:46<00:05, 150.96 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34807/47780 [02:46<00:23, 545.56 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47006/47780 [02:46<00:03, 201.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47122/47780 [02:46<00:04, 151.93 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46972/47780 [02:46<00:04, 163.80 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46739/47780 [02:46<00:06, 173.21 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46936/47780 [02:46<00:05, 155.99 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46609/47780 [02:46<00:07, 167.01 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46996/47780 [02:46<00:08, 95.90 examples/s] Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34864/47780 [02:46<00:23, 539.34 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47028/47780 [02:46<00:03, 204.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47138/47780 [02:46<00:04, 152.14 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46991/47780 [02:46<00:04, 167.90 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46627/47780 [02:46<00:06, 168.84 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46758/47780 [02:46<00:06, 161.77 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34926/47780 [02:46<00:22, 562.14 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46952/47780 [02:46<00:05, 144.68 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47010/47780 [02:47<00:07, 98.61 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47051/47780 [02:47<00:03, 201.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47154/47780 [02:47<00:04, 146.92 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47009/47780 [02:47<00:04, 165.89 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46645/47780 [02:47<00:06, 168.73 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46775/47780 [02:47<00:06, 159.15 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46967/47780 [02:47<00:05, 144.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34983/47780 [02:47<00:24, 525.23 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47021/47780 [02:47<00:07, 97.80 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47073/47780 [02:47<00:03, 194.85 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47170/47780 [02:47<00:04, 134.38 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47027/47780 [02:47<00:04, 160.65 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46671/47780 [02:47<00:05, 192.84 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46793/47780 [02:47<00:06, 159.71 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46985/47780 [02:47<00:05, 152.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35059/47780 [02:47<00:21, 589.02 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47031/47780 [02:47<00:08, 93.36 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47094/47780 [02:47<00:03, 184.38 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47045/47780 [02:47<00:04, 165.25 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47185/47780 [02:47<00:04, 130.16 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46693/47780 [02:47<00:05, 198.11 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47001/47780 [02:47<00:05, 151.49 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46812/47780 [02:47<00:05, 164.61 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35119/47780 [02:47<00:21, 583.85 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47041/47780 [02:47<00:08, 91.27 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47113/47780 [02:47<00:03, 180.24 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47064/47780 [02:47<00:04, 170.05 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46715/47780 [02:47<00:05, 192.78 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46835/47780 [02:47<00:05, 181.75 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47200/47780 [02:47<00:04, 123.53 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47018/47780 [02:47<00:05, 150.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35179/47780 [02:47<00:21, 584.77 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47058/47780 [02:47<00:06, 110.37 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47082/47780 [02:47<00:04, 172.57 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47133/47780 [02:47<00:03, 172.25 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46735/47780 [02:47<00:05, 190.08 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35249/47780 [02:47<00:20, 613.54 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46854/47780 [02:47<00:05, 175.33 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47213/47780 [02:47<00:05, 112.44 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47034/47780 [02:47<00:05, 133.16 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47071/47780 [02:47<00:06, 110.20 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47100/47780 [02:47<00:04, 155.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46875/47780 [02:47<00:04, 183.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35311/47780 [02:47<00:20, 602.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47153/47780 [02:47<00:03, 166.48 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46758/47780 [02:47<00:05, 187.10 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47227/47780 [02:47<00:04, 116.93 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47049/47780 [02:47<00:05, 133.32 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46895/47780 [02:47<00:04, 187.63 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35377/47780 [02:47<00:20, 619.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47116/47780 [02:47<00:04, 151.32 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47084/47780 [02:47<00:06, 100.60 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47171/47780 [02:47<00:03, 161.83 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46778/47780 [02:47<00:05, 179.20 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47065/47780 [02:47<00:05, 139.94 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47242/47780 [02:47<00:04, 117.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46919/47780 [02:47<00:04, 201.07 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47132/47780 [02:47<00:04, 148.33 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47193/47780 [02:47<00:03, 175.95 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35441/47780 [02:47<00:21, 586.07 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47102/47780 [02:47<00:05, 115.30 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46801/47780 [02:47<00:05, 189.72 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47086/47780 [02:47<00:04, 154.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47256/47780 [02:47<00:04, 122.09 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46940/47780 [02:47<00:04, 197.86 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47153/47780 [02:47<00:03, 164.63 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35517/47780 [02:47<00:19, 627.85 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47211/47780 [02:47<00:03, 170.46 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47119/47780 [02:48<00:05, 124.78 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46821/47780 [02:47<00:05, 190.21 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47102/47780 [02:47<00:04, 152.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47269/47780 [02:48<00:04, 117.65 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35586/47780 [02:48<00:19, 640.87 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46964/47780 [02:48<00:04, 193.70 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47170/47780 [02:48<00:04, 148.67 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46846/47780 [02:48<00:04, 195.83 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47120/47780 [02:48<00:04, 158.40 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47230/47780 [02:48<00:03, 153.80 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47132/47780 [02:48<00:05, 111.53 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47281/47780 [02:48<00:04, 112.86 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35674/47780 [02:48<00:17, 705.52 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46988/47780 [02:48<00:03, 200.05 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47187/47780 [02:48<00:03, 153.49 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46867/47780 [02:48<00:04, 197.72 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47145/47780 [02:48<00:05, 111.60 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47136/47780 [02:48<00:04, 146.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47293/47780 [02:48<00:04, 114.14 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47247/47780 [02:48<00:03, 144.73 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35764/47780 [02:48<00:15, 752.81 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47012/47780 [02:48<00:03, 208.16 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47205/47780 [02:48<00:03, 158.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46889/47780 [02:48<00:04, 201.44 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47309/47780 [02:48<00:03, 122.47 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47163/47780 [02:48<00:03, 166.13 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47157/47780 [02:48<00:05, 104.15 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47262/47780 [02:48<00:03, 134.72 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47035/47780 [02:48<00:03, 212.12 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47225/47780 [02:48<00:03, 167.59 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35841/47780 [02:48<00:17, 690.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46914/47780 [02:48<00:04, 210.23 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47322/47780 [02:48<00:03, 117.64 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47184/47780 [02:48<00:03, 168.58 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47059/47780 [02:48<00:03, 218.20 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47276/47780 [02:48<00:03, 132.07 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47169/47780 [02:48<00:06, 100.02 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35913/47780 [02:48<00:17, 661.95 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46943/47780 [02:48<00:03, 217.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47243/47780 [02:48<00:03, 151.23 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47334/47780 [02:48<00:04, 110.37 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47206/47780 [02:48<00:03, 176.22 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47083/47780 [02:48<00:03, 210.42 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35992/47780 [02:48<00:16, 694.48 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47181/47780 [02:48<00:05, 100.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47262/47780 [02:48<00:03, 160.07 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47290/47780 [02:48<00:04, 117.17 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46965/47780 [02:48<00:04, 200.47 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36063/47780 [02:48<00:16, 691.13 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47193/47780 [02:48<00:05, 101.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47224/47780 [02:48<00:03, 156.07 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47106/47780 [02:48<00:03, 189.34 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46987/47780 [02:48<00:03, 203.98 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47279/47780 [02:48<00:03, 151.71 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47346/47780 [02:48<00:04, 92.39 examples/s] Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47303/47780 [02:48<00:04, 105.50 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36138/47780 [02:48<00:16, 697.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47205/47780 [02:48<00:05, 101.71 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47241/47780 [02:48<00:03, 155.63 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47008/47780 [02:48<00:03, 202.68 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47126/47780 [02:48<00:03, 181.11 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47356/47780 [02:48<00:04, 89.78 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36212/47780 [02:48<00:16, 694.91 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47295/47780 [02:48<00:03, 132.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47316/47780 [02:48<00:04, 105.52 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47146/47780 [02:48<00:03, 185.74 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47257/47780 [02:48<00:03, 146.74 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47029/47780 [02:49<00:03, 188.19 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47216/47780 [02:49<00:06, 90.42 examples/s] Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47366/47780 [02:49<00:05, 82.03 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47327/47780 [02:49<00:04, 101.68 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36282/47780 [02:49<00:18, 631.50 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47309/47780 [02:49<00:03, 120.15 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47166/47780 [02:49<00:03, 183.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47229/47780 [02:49<00:05, 96.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47273/47780 [02:49<00:04, 126.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47050/47780 [02:49<00:04, 166.72 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47339/47780 [02:49<00:04, 99.13 examples/s] Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47322/47780 [02:49<00:03, 121.07 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36348/47780 [02:49<00:18, 603.92 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47375/47780 [02:49<00:05, 75.83 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47186/47780 [02:49<00:03, 179.67 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47242/47780 [02:49<00:05, 101.65 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47068/47780 [02:49<00:04, 166.33 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47288/47780 [02:49<00:03, 127.61 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47354/47780 [02:49<00:03, 110.62 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36418/47780 [02:49<00:18, 629.45 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47340/47780 [02:49<00:03, 133.11 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47212/47780 [02:49<00:02, 198.09 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47387/47780 [02:49<00:04, 80.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47253/47780 [02:49<00:05, 103.77 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47087/47780 [02:49<00:04, 169.50 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47305/47780 [02:49<00:03, 136.43 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36486/47780 [02:49<00:18, 620.19 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47367/47780 [02:49<00:03, 108.69 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47354/47780 [02:49<00:03, 127.25 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47265/47780 [02:49<00:04, 107.62 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47396/47780 [02:49<00:04, 79.71 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47233/47780 [02:49<00:02, 183.48 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47105/47780 [02:49<00:04, 163.27 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36556/47780 [02:49<00:17, 640.26 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47379/47780 [02:49<00:03, 110.26 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47320/47780 [02:49<00:04, 114.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47276/47780 [02:49<00:04, 100.92 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47252/47780 [02:49<00:03, 173.82 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47405/47780 [02:49<00:05, 71.82 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36622/47780 [02:49<00:17, 641.20 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47368/47780 [02:49<00:03, 105.30 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47122/47780 [02:49<00:04, 158.99 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47392/47780 [02:49<00:03, 101.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47287/47780 [02:49<00:04, 101.56 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47270/47780 [02:49<00:03, 166.27 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47416/47780 [02:49<00:04, 80.34 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36692/47780 [02:49<00:17, 628.24 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47333/47780 [02:49<00:04, 101.06 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47139/47780 [02:49<00:04, 151.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47380/47780 [02:49<00:04, 94.30 examples/s] Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47298/47780 [02:49<00:04, 101.40 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47287/47780 [02:49<00:03, 163.13 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47403/47780 [02:49<00:04, 90.40 examples/s] Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36757/47780 [02:49<00:17, 613.53 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47427/47780 [02:49<00:04, 80.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47155/47780 [02:49<00:04, 144.09 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47344/47780 [02:49<00:04, 93.90 examples/s] Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47309/47780 [02:49<00:04, 102.46 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47393/47780 [02:49<00:03, 98.48 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47305/47780 [02:49<00:02, 164.94 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47439/47780 [02:50<00:03, 89.79 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36822/47780 [02:49<00:18, 601.40 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47414/47780 [02:49<00:04, 86.53 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47171/47780 [02:50<00:04, 142.00 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47322/47780 [02:50<00:04, 107.01 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47355/47780 [02:50<00:04, 88.38 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47405/47780 [02:50<00:03, 95.16 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47322/47780 [02:50<00:02, 156.58 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47450/47780 [02:50<00:03, 92.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36898/47780 [02:50<00:17, 637.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47425/47780 [02:50<00:04, 88.70 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47340/47780 [02:50<00:03, 123.67 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47186/47780 [02:50<00:04, 132.54 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47340/47780 [02:50<00:02, 161.79 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47415/47780 [02:50<00:03, 92.13 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36964/47780 [02:50<00:17, 629.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47368/47780 [02:50<00:04, 90.46 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47460/47780 [02:50<00:03, 83.85 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47202/47780 [02:50<00:04, 136.88 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47435/47780 [02:50<00:04, 82.46 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47425/47780 [02:50<00:03, 91.64 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37030/47780 [02:50<00:16, 636.98 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47357/47780 [02:50<00:02, 154.23 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47353/47780 [02:50<00:04, 106.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47384/47780 [02:50<00:03, 101.18 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47217/47780 [02:50<00:04, 133.45 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47471/47780 [02:50<00:03, 80.63 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47445/47780 [02:50<00:04, 81.75 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37101/47780 [02:50<00:16, 653.00 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47373/47780 [02:50<00:02, 153.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47396/47780 [02:50<00:03, 105.28 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47437/47780 [02:50<00:03, 90.59 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47365/47780 [02:50<00:04, 101.11 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47233/47780 [02:50<00:03, 138.59 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47486/47780 [02:50<00:03, 95.15 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37175/47780 [02:50<00:15, 677.64 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47455/47780 [02:50<00:03, 82.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47390/47780 [02:50<00:02, 156.09 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47408/47780 [02:50<00:03, 107.01 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47449/47780 [02:50<00:03, 97.22 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47382/47780 [02:50<00:03, 111.09 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47498/47780 [02:50<00:02, 101.37 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47251/47780 [02:50<00:03, 143.61 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47464/47780 [02:50<00:03, 83.37 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47408/47780 [02:50<00:02, 160.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37243/47780 [02:50<00:16, 643.96 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47460/47780 [02:50<00:03, 96.25 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47394/47780 [02:50<00:03, 110.88 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47419/47780 [02:50<00:03, 94.06 examples/s] Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47267/47780 [02:50<00:03, 145.79 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47512/47780 [02:50<00:02, 108.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37308/47780 [02:50<00:16, 632.27 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47473/47780 [02:50<00:03, 78.58 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47425/47780 [02:50<00:02, 149.12 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47472/47780 [02:50<00:03, 100.53 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47406/47780 [02:50<00:03, 106.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47524/47780 [02:50<00:02, 105.40 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47429/47780 [02:50<00:04, 84.65 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37373/47780 [02:50<00:17, 610.27 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47283/47780 [02:50<00:03, 132.44 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47441/47780 [02:50<00:02, 140.59 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47481/47780 [02:50<00:04, 72.14 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47484/47780 [02:50<00:03, 94.88 examples/s] 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47420/47780 [02:50<00:03, 113.69 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37435/47780 [02:50<00:16, 612.61 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47440/47780 [02:50<00:03, 86.40 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47536/47780 [02:51<00:02, 100.81 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47297/47780 [02:50<00:03, 128.78 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47489/47780 [02:50<00:04, 72.50 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47456/47780 [02:50<00:02, 135.48 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47436/47780 [02:51<00:02, 124.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47495/47780 [02:50<00:03, 93.54 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37497/47780 [02:51<00:17, 588.67 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47547/47780 [02:51<00:02, 101.70 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47312/47780 [02:51<00:03, 133.17 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47449/47780 [02:51<00:04, 81.53 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47499/47780 [02:51<00:03, 74.04 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47470/47780 [02:51<00:02, 128.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47449/47780 [02:51<00:02, 118.18 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37561/47780 [02:51<00:17, 594.56 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47559/47780 [02:51<00:02, 105.17 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47505/47780 [02:51<00:03, 83.03 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47327/47780 [02:51<00:03, 130.80 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47458/47780 [02:51<00:03, 80.54 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47488/47780 [02:51<00:02, 139.02 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47463/47780 [02:51<00:02, 120.84 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47508/47780 [02:51<00:03, 72.43 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37624/47780 [02:51<00:17, 594.41 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47575/47780 [02:51<00:01, 115.49 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47341/47780 [02:51<00:03, 130.63 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47516/47780 [02:51<00:03, 84.98 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47469/47780 [02:51<00:03, 86.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47503/47780 [02:51<00:01, 140.61 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47477/47780 [02:51<00:02, 121.79 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47520/47780 [02:51<00:03, 82.17 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37692/47780 [02:51<00:16, 618.27 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47359/47780 [02:51<00:02, 141.41 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47531/47780 [02:51<00:02, 99.34 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47484/47780 [02:51<00:02, 102.49 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47587/47780 [02:51<00:01, 107.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47522/47780 [02:51<00:01, 150.36 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37755/47780 [02:51<00:16, 616.29 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47530/47780 [02:51<00:03, 82.51 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47490/47780 [02:51<00:02, 116.33 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47375/47780 [02:51<00:02, 143.63 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47542/47780 [02:51<00:02, 100.69 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47495/47780 [02:51<00:02, 100.19 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47598/47780 [02:51<00:01, 98.33 examples/s] Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47538/47780 [02:51<00:01, 143.95 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37821/47780 [02:51<00:16, 622.43 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47540/47780 [02:51<00:02, 84.89 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47502/47780 [02:51<00:02, 105.09 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47391/47780 [02:51<00:02, 141.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47506/47780 [02:51<00:02, 96.74 examples/s] Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47553/47780 [02:51<00:01, 139.62 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37885/47780 [02:51<00:16, 607.91 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47553/47780 [02:51<00:02, 85.37 examples/s] Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47549/47780 [02:51<00:02, 81.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47609/47780 [02:51<00:01, 87.13 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47514/47780 [02:51<00:02, 99.46 examples/s] Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47407/47780 [02:51<00:02, 131.63 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37947/47780 [02:51<00:16, 607.59 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47516/47780 [02:51<00:03, 86.65 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47564/47780 [02:51<00:02, 87.57 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47569/47780 [02:51<00:01, 133.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47559/47780 [02:51<00:02, 78.17 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47619/47780 [02:51<00:02, 80.47 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47526/47780 [02:51<00:02, 100.76 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38019/47780 [02:51<00:15, 637.16 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47423/47780 [02:51<00:02, 131.42 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47531/47780 [02:51<00:02, 100.12 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47583/47780 [02:51<00:01, 129.40 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47575/47780 [02:51<00:02, 85.79 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47568/47780 [02:51<00:02, 80.60 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47628/47780 [02:52<00:01, 77.07 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38084/47780 [02:51<00:16, 598.41 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47437/47780 [02:52<00:02, 126.22 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47537/47780 [02:52<00:02, 91.52 examples/s] Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47543/47780 [02:51<00:02, 95.30 examples/s] 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47598/47780 [02:52<00:01, 126.22 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47586/47780 [02:52<00:02, 87.11 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47577/47780 [02:52<00:02, 77.11 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38160/47780 [02:52<00:15, 639.20 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47450/47780 [02:52<00:02, 122.48 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47551/47780 [02:52<00:02, 99.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47612/47780 [02:52<00:01, 129.36 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47595/47780 [02:52<00:02, 85.39 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47636/47780 [02:52<00:02, 64.60 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38235/47780 [02:52<00:14, 666.81 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47585/47780 [02:52<00:02, 71.21 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47554/47780 [02:52<00:02, 84.06 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47562/47780 [02:52<00:02, 100.67 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47463/47780 [02:52<00:02, 111.90 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47626/47780 [02:52<00:01, 127.17 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47606/47780 [02:52<00:02, 83.42 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47643/47780 [02:52<00:02, 60.93 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38303/47780 [02:52<00:15, 628.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47593/47780 [02:52<00:02, 68.52 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47564/47780 [02:52<00:02, 78.42 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47475/47780 [02:52<00:02, 112.79 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47574/47780 [02:52<00:02, 96.35 examples/s] Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47639/47780 [02:52<00:01, 117.58 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47615/47780 [02:52<00:01, 84.32 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47650/47780 [02:52<00:02, 60.57 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47604/47780 [02:52<00:02, 78.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38367/47780 [02:52<00:15, 606.39 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47487/47780 [02:52<00:02, 111.12 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47574/47780 [02:52<00:02, 79.45 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47584/47780 [02:52<00:02, 92.17 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47651/47780 [02:52<00:01, 110.28 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47657/47780 [02:52<00:01, 62.79 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47624/47780 [02:52<00:01, 78.53 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38432/47780 [02:52<00:15, 616.82 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47499/47780 [02:52<00:02, 111.22 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47597/47780 [02:52<00:01, 94.68 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38507/47780 [02:52<00:14, 636.43 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47614/47780 [02:52<00:02, 62.14 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47633/47780 [02:52<00:02, 70.17 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47511/47780 [02:52<00:02, 100.40 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47583/47780 [02:52<00:03, 59.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38571/47780 [02:52<00:14, 623.36 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47664/47780 [02:52<00:01, 83.59 examples/s] Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47608/47780 [02:52<00:02, 80.25 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47665/47780 [02:52<00:02, 44.84 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47621/47780 [02:52<00:02, 55.15 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47522/47780 [02:52<00:02, 95.34 examples/s] 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38654/47780 [02:52<00:13, 673.93 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47676/47780 [02:52<00:01, 85.51 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47641/47780 [02:52<00:02, 56.74 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47590/47780 [02:52<00:03, 50.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47671/47780 [02:53<00:02, 45.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47532/47780 [02:52<00:02, 94.74 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38723/47780 [02:52<00:13, 655.24 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47629/47780 [02:53<00:02, 51.69 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47689/47780 [02:52<00:01, 90.38 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47618/47780 [02:53<00:02, 66.52 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47649/47780 [02:53<00:02, 58.95 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38792/47780 [02:53<00:13, 656.84 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47544/47780 [02:53<00:02, 94.69 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47597/47780 [02:53<00:03, 47.85 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47656/47780 [02:53<00:02, 59.99 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47635/47780 [02:53<00:02, 49.73 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47677/47780 [02:53<00:02, 39.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47630/47780 [02:53<00:02, 72.36 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38873/47780 [02:53<00:12, 685.91 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47699/47780 [02:53<00:01, 78.35 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47554/47780 [02:53<00:02, 91.47 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47604/47780 [02:53<00:03, 45.82 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47664/47780 [02:53<00:01, 58.94 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38945/47780 [02:53<00:13, 669.21 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47641/47780 [02:53<00:02, 46.76 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47682/47780 [02:53<00:02, 36.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47566/47780 [02:53<00:02, 87.25 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47611/47780 [02:53<00:03, 49.88 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39017/47780 [02:53<00:12, 681.60 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47639/47780 [02:53<00:02, 58.04 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47649/47780 [02:53<00:02, 51.43 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47671/47780 [02:53<00:02, 51.43 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47577/47780 [02:53<00:02, 90.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47688/47780 [02:53<00:02, 37.31 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47708/47780 [02:53<00:01, 56.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39088/47780 [02:53<00:12, 684.59 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47678/47780 [02:53<00:01, 54.03 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47617/47780 [02:53<00:03, 42.19 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47692/47780 [02:53<00:02, 36.05 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39164/47780 [02:53<00:12, 703.41 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47646/47780 [02:53<00:02, 49.71 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47587/47780 [02:53<00:02, 79.69 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47659/47780 [02:53<00:02, 46.00 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39247/47780 [02:53<00:11, 739.83 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47623/47780 [02:53<00:03, 41.94 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47598/47780 [02:53<00:02, 82.71 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47684/47780 [02:53<00:02, 47.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47696/47780 [02:53<00:02, 31.27 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39322/47780 [02:53<00:12, 701.73 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47664/47780 [02:53<00:02, 42.92 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47609/47780 [02:53<00:01, 86.27 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47689/47780 [02:53<00:02, 44.43 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47628/47780 [02:53<00:03, 39.28 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47653/47780 [02:53<00:03, 39.98 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47704/47780 [02:53<00:01, 39.24 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39398/47780 [02:53<00:11, 709.75 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47669/47780 [02:53<00:02, 43.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47716/47780 [02:53<00:01, 37.01 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47620/47780 [02:53<00:01, 88.78 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47659/47780 [02:54<00:02, 42.94 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47635/47780 [02:53<00:03, 43.70 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47709/47780 [02:54<00:01, 39.65 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39471/47780 [02:54<00:11, 705.86 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47694/47780 [02:54<00:02, 39.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47675/47780 [02:54<00:02, 42.94 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47633/47780 [02:54<00:01, 97.49 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47666/47780 [02:54<00:02, 46.96 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47640/47780 [02:54<00:03, 44.64 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39551/47780 [02:54<00:11, 731.67 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47723/47780 [02:54<00:01, 36.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47703/47780 [02:54<00:01, 49.12 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47643/47780 [02:54<00:01, 90.80 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47685/47780 [02:54<00:01, 50.16 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39625/47780 [02:54<00:11, 729.48 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47648/47780 [02:54<00:02, 49.99 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47714/47780 [02:54<00:02, 31.07 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47672/47780 [02:54<00:02, 43.43 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47709/47780 [02:54<00:01, 45.66 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39701/47780 [02:54<00:11, 729.20 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47655/47780 [02:54<00:01, 88.84 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47692/47780 [02:54<00:01, 47.81 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47656/47780 [02:54<00:02, 51.03 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47677/47780 [02:54<00:02, 43.09 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39779/47780 [02:54<00:10, 742.29 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47720/47780 [02:54<00:01, 32.44 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47714/47780 [02:54<00:01, 42.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47728/47780 [02:54<00:01, 29.13 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47665/47780 [02:54<00:01, 84.57 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47662/47780 [02:54<00:02, 52.51 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47699/47780 [02:54<00:01, 48.60 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47683/47780 [02:54<00:02, 44.11 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39874/47780 [02:54<00:09, 799.95 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47721/47780 [02:54<00:01, 47.99 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47724/47780 [02:54<00:01, 31.42 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47674/47780 [02:54<00:01, 82.88 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47670/47780 [02:54<00:01, 57.10 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47734/47780 [02:54<00:01, 31.10 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39956/47780 [02:54<00:10, 763.21 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47708/47780 [02:54<00:01, 52.57 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47691/47780 [02:54<00:01, 46.96 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47729/47780 [02:54<00:00, 51.83 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47676/47780 [02:54<00:01, 55.32 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47731/47780 [02:54<00:01, 34.14 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47684/47780 [02:54<00:01, 77.13 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40041/47780 [02:54<00:10, 762.89 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47715/47780 [02:54<00:01, 54.07 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47696/47780 [02:54<00:01, 44.92 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47740/47780 [02:54<00:01, 29.85 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47735/47780 [02:54<00:00, 48.42 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40128/47780 [02:54<00:09, 792.42 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47683/47780 [02:54<00:01, 52.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47692/47780 [02:54<00:01, 72.02 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47739/47780 [02:54<00:01, 38.07 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47722/47780 [02:54<00:01, 49.36 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40216/47780 [02:54<00:09, 806.04 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47702/47780 [02:55<00:01, 41.79 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47741/47780 [02:54<00:00, 47.76 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47689/47780 [02:54<00:01, 52.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47701/47780 [02:55<00:01, 76.03 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47746/47780 [02:55<00:01, 29.51 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47743/47780 [02:55<00:01, 35.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40299/47780 [02:55<00:09, 809.51 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47696/47780 [02:55<00:01, 55.46 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47710/47780 [02:55<00:00, 74.74 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47750/47780 [02:55<00:00, 52.89 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47731/47780 [02:55<00:00, 51.93 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47711/47780 [02:55<00:01, 47.57 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40403/47780 [02:55<00:08, 874.01 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47752/47780 [02:55<00:00, 32.48 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47748/47780 [02:55<00:00, 36.11 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47706/47780 [02:55<00:01, 65.49 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47717/47780 [02:55<00:01, 48.25 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47739/47780 [02:55<00:00, 53.46 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40497/47780 [02:55<00:08, 885.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47722/47780 [02:55<00:00, 73.35 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47755/47780 [02:55<00:00, 39.92 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47745/47780 [02:55<00:00, 51.95 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47713/47780 [02:55<00:01, 54.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47722/47780 [02:55<00:01, 42.76 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40588/47780 [02:55<00:08, 814.99 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [02:55<00:00, 33.35 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47731/47780 [02:55<00:00, 61.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [02:55<00:00, 24.83 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40671/47780 [02:55<00:08, 806.54 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47727/47780 [02:55<00:01, 41.53 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47751/47780 [02:55<00:00, 46.45 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47720/47780 [02:55<00:01, 50.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47760/47780 [02:55<00:00, 33.04 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40754/47780 [02:55<00:08, 808.32 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47761/47780 [02:55<00:00, 33.47 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47760/47780 [02:55<00:00, 25.61 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47733/47780 [02:55<00:01, 45.18 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47739/47780 [02:55<00:00, 58.51 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47759/47780 [02:55<00:00, 50.90 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47727/47780 [02:55<00:01, 51.14 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47764/47780 [02:55<00:00, 32.51 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40855/47780 [02:55<00:08, 854.26 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47764/47780 [02:55<00:00, 27.60 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47740/47780 [02:55<00:00, 49.71 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47766/47780 [02:55<00:00, 34.80 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47746/47780 [02:55<00:00, 59.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47733/47780 [02:55<00:00, 51.34 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47770/47780 [02:55<00:00, 36.28 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40942/47780 [02:55<00:08, 844.28 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47768/47780 [02:55<00:00, 53.47 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47770/47780 [02:55<00:00, 33.15 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47758/47780 [02:55<00:00, 72.85 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47749/47780 [02:55<00:00, 56.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47772/47780 [02:55<00:00, 37.98 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41038/47780 [02:55<00:07, 874.23 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47742/47780 [02:55<00:00, 55.38 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [02:56<00:00, 34.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [02:56<00:00, 55.40 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [02:56<00:00, 67.17 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41126/47780 [02:56<00:07, 836.05 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [02:56<00:00, 28.66 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47748/47780 [02:56<00:00, 48.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [02:56<00:00, 38.69 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47765/47780 [02:56<00:00, 61.34 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41211/47780 [02:56<00:08, 819.19 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47777/47780 [02:56<00:00, 28.77 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [02:56<00:00, 27.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47775/47780 [02:56<00:00, 62.20 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47754/47780 [02:56<00:00, 48.01 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [02:56<00:00, 27.59 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41313/47780 [02:56<00:07, 871.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47772/47780 [02:56<00:00, 58.31 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41405/47780 [02:56<00:07, 883.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [02:56<00:00, 58.21 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41494/47780 [02:56<00:07, 862.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47760/47780 [02:56<00:00, 39.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41589/47780 [02:56<00:07, 884.31 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41684/47780 [02:56<00:06, 895.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47766/47780 [02:56<00:00, 34.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41774/47780 [02:56<00:06, 878.66 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47770/47780 [02:56<00:00, 33.39 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41866/47780 [02:56<00:07, 839.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41952/47780 [02:56<00:06, 838.46 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47775/47780 [02:57<00:00, 29.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42038/47780 [02:57<00:07, 790.51 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42136/47780 [02:57<00:06, 833.53 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [02:57<00:00, 27.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42221/47780 [02:57<00:06, 819.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42306/47780 [02:57<00:06, 827.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42398/47780 [02:57<00:06, 847.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42485/47780 [02:57<00:06, 840.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42575/47780 [02:57<00:06, 838.13 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42659/47780 [02:57<00:06, 823.88 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [02:57<00:00, 268.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42748/47780 [02:57<00:06, 783.52 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42834/47780 [02:58<00:06, 795.86 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42917/47780 [02:58<00:06, 788.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 43000/47780 [02:58<00:06, 751.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43079/47780 [02:58<00:06, 758.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43156/47780 [02:58<00:06, 729.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43231/47780 [02:58<00:06, 708.58 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43317/47780 [02:58<00:05, 748.54 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43394/47780 [02:58<00:06, 730.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43472/47780 [02:58<00:05, 731.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43547/47780 [02:59<00:05, 710.55 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43620/47780 [02:59<00:06, 658.01 examples/s]Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:01<00:50, 931.42 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43688/47780 [02:59<00:07, 559.82 examples/s]Truncating train dataset (num_proc=32):  30%|███       | 14494/47780 [00:01<00:02, 16522.24 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [02:59<00:00, 266.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43747/47780 [02:59<00:07, 521.78 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  51%|█████     | 24411/47780 [00:01<00:00, 27291.04 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43803/47780 [02:59<00:07, 515.78 examples/s]Truncating train dataset (num_proc=32):  73%|███████▎  | 34877/47780 [00:01<00:00, 39773.80 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [02:59<00:00,  5.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43883/47780 [02:59<00:06, 583.60 examples/s]Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43964/47780 [02:59<00:06, 634.46 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  92%|█████████▏| 43836/47780 [00:01<00:00, 39285.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44031/47780 [02:59<00:06, 601.69 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44093/47780 [03:00<00:06, 571.92 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:00<00:00, 265.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44157/47780 [03:00<00:06, 575.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44238/47780 [03:00<00:05, 620.58 examples/s]Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44314/47780 [03:00<00:05, 642.21 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44380/47780 [03:00<00:05, 626.30 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44445/47780 [03:00<00:05, 565.43 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:43, 1074.34 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44503/47780 [03:00<00:05, 552.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):   8%|▊         | 4000/47780 [00:01<00:09, 4823.82 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44561/47780 [03:00<00:05, 539.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  47%|████▋     | 22482/47780 [00:01<00:00, 32777.50 examples/s]Truncating train dataset (num_proc=32):  73%|███████▎  | 34906/47780 [00:01<00:00, 49365.97 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44617/47780 [03:01<00:06, 512.23 examples/s]Truncating train dataset (num_proc=32):  98%|█████████▊| 46794/47780 [00:01<00:00, 60062.33 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44670/47780 [03:01<00:06, 487.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44721/47780 [03:01<00:06, 486.60 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44770/47780 [03:01<00:06, 468.84 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:46, 1000.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44818/47780 [03:01<00:06, 460.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  23%|██▎       | 11000/47780 [00:01<00:02, 12821.14 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44865/47780 [03:01<00:06, 443.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  66%|██████▌   | 31441/47780 [00:01<00:00, 40465.86 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44913/47780 [03:01<00:06, 449.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  90%|████████▉ | 42808/47780 [00:01<00:00, 50046.04 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44971/47780 [03:01<00:05, 478.62 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45028/47780 [03:01<00:05, 488.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45082/47780 [03:01<00:05, 502.14 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45134/47780 [03:02<00:05, 476.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45183/47780 [03:02<00:05, 456.05 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45231/47780 [03:02<00:05, 453.47 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45279/47780 [03:02<00:05, 457.19 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45331/47780 [03:02<00:05, 471.10 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45380/47780 [03:02<00:05, 423.16 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45434/47780 [03:02<00:05, 448.93 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45484/47780 [03:02<00:05, 459.19 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45533/47780 [03:03<00:04, 457.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45581/47780 [03:03<00:04, 457.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45628/47780 [03:03<00:04, 443.26 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45673/47780 [03:03<00:04, 429.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45717/47780 [03:03<00:04, 416.90 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45765/47780 [03:03<00:04, 432.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45809/47780 [03:03<00:04, 427.75 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45858/47780 [03:03<00:04, 425.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45903/47780 [03:03<00:04, 423.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45946/47780 [03:03<00:04, 423.07 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45989/47780 [03:04<00:04, 417.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46032/47780 [03:04<00:04, 411.32 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46075/47780 [03:04<00:04, 377.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46114/47780 [03:04<00:04, 374.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46152/47780 [03:04<00:04, 367.26 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46191/47780 [03:04<00:04, 356.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46242/47780 [03:04<00:03, 396.47 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46284/47780 [03:04<00:04, 354.64 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46322/47780 [03:05<00:04, 354.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46373/47780 [03:05<00:03, 385.16 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46414/47780 [03:05<00:03, 382.88 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46453/47780 [03:05<00:03, 371.73 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46493/47780 [03:05<00:03, 352.52 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46530/47780 [03:05<00:03, 354.44 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46571/47780 [03:05<00:03, 356.81 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46609/47780 [03:05<00:03, 361.39 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46647/47780 [03:05<00:03, 348.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46684/47780 [03:06<00:03, 327.88 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46719/47780 [03:06<00:03, 329.85 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [03:06<00:00, 62.20 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:06<00:00, 256.50 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46754/47780 [03:06<00:03, 303.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46791/47780 [03:06<00:03, 319.00 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46824/47780 [03:06<00:03, 302.11 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46856/47780 [03:06<00:03, 296.83 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46892/47780 [03:06<00:02, 299.27 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46923/47780 [03:06<00:02, 301.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46960/47780 [03:06<00:02, 315.85 examples/s]Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:29, 1605.85 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46993/47780 [03:07<00:02, 280.36 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  13%|█▎        | 6000/47780 [00:00<00:03, 10619.77 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47023/47780 [03:07<00:02, 261.12 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  46%|████▌     | 21975/47780 [00:00<00:00, 41706.76 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47054/47780 [03:07<00:02, 271.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  78%|███████▊  | 37398/47780 [00:00<00:00, 66349.41 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47083/47780 [03:07<00:02, 274.45 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47111/47780 [03:07<00:02, 256.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47138/47780 [03:07<00:02, 244.10 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47166/47780 [03:07<00:02, 252.23 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47193/47780 [03:07<00:02, 248.18 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47219/47780 [03:08<00:02, 237.33 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47249/47780 [03:08<00:02, 248.14 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47276/47780 [03:08<00:02, 245.87 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47301/47780 [03:08<00:02, 216.90 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47324/47780 [03:08<00:02, 218.71 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:08<00:00,  2.04 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47347/47780 [03:08<00:02, 201.92 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47368/47780 [03:08<00:02, 188.83 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:08<00:00, 252.87 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47389/47780 [03:08<00:02, 179.07 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47410/47780 [03:09<00:02, 182.59 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47429/47780 [03:09<00:02, 172.09 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47453/47780 [03:09<00:01, 187.88 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47473/47780 [03:09<00:01, 170.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47497/47780 [03:09<00:01, 187.08 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47517/47780 [03:09<00:01, 177.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:28, 1624.88 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47537/47780 [03:09<00:01, 148.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  17%|█▋        | 8000/47780 [00:00<00:02, 14179.78 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47554/47780 [03:09<00:01, 152.70 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  50%|█████     | 23975/47780 [00:00<00:00, 44475.58 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47573/47780 [03:10<00:01, 158.23 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  80%|████████  | 38384/47780 [00:00<00:00, 66740.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47590/47780 [03:10<00:01, 142.74 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47605/47780 [03:10<00:01, 132.66 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47620/47780 [03:10<00:01, 115.56 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47635/47780 [03:10<00:01, 114.55 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47647/47780 [03:10<00:01, 113.64 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47659/47780 [03:10<00:01, 87.01 examples/s] Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47669/47780 [03:11<00:01, 79.80 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47679/47780 [03:11<00:01, 81.07 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47689/47780 [03:11<00:01, 66.65 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47697/47780 [03:11<00:01, 62.57 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47705/47780 [03:11<00:01, 61.05 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47713/47780 [03:11<00:01, 55.65 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47724/47780 [03:12<00:00, 61.91 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47732/47780 [03:12<00:00, 59.61 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47739/47780 [03:12<00:00, 60.73 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47747/47780 [03:12<00:00, 45.80 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47753/47780 [03:12<00:00, 39.09 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:14<00:00, 245.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:14<00:00, 245.37 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:16<00:00, 39285.76 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:14<00:00, 50046.04 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:17<00:00, 1388.92 examples/s] 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:15<00:00, 1872.95 examples/s] 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:15<00:00, 60062.33 examples/s]Truncating train dataset (num_proc=32):   9%|▉         | 4479/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):   9%|▉         | 4479/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:18<00:00, 1269.13 examples/s] Truncating train dataset (num_proc=32):  11%|█▏        | 5479/47780 [00:06<04:21, 161.92 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  11%|█▏        | 5479/47780 [00:06<04:21, 161.58 examples/s]Truncating train dataset (num_proc=32):  15%|█▍        | 6972/47780 [00:07<01:40, 406.72 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  21%|██        | 9958/47780 [00:07<00:39, 956.52 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [03:22<00:00, 39.09 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47757/47780 [03:23<00:12,  1.89 examples/s]Truncating train dataset (num_proc=32):  22%|██▏       | 10466/47780 [00:08<00:37, 1001.34 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  25%|██▌       | 11958/47780 [00:08<00:32, 1117.17 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:15<00:00, 66740.24 examples/s]Truncating train dataset (num_proc=32):  43%|████▎     | 20452/47780 [00:09<00:10, 2658.91 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  40%|███▉      | 18959/47780 [00:09<00:11, 2562.86 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:18<00:00, 66349.41 examples/s]Truncating train dataset (num_proc=32):  44%|████▍     | 20945/47780 [00:09<00:09, 2723.30 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  45%|████▍     | 21440/47780 [00:09<00:08, 3212.40 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:28<00:00, 1388.92 examples/s]Truncating train dataset (num_proc=32):  45%|████▍     | 21438/47780 [00:10<00:13, 2009.88 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  54%|█████▍    | 25919/47780 [00:10<00:06, 3480.96 examples/s]Truncating train dataset (num_proc=32):  67%|██████▋   | 31890/47780 [00:10<00:02, 6073.28 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  82%|████████▏ | 39370/47780 [00:10<00:00, 8644.31 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  92%|█████████▏| 43834/47780 [00:11<00:00, 12028.86 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:26<00:00, 1872.95 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32):  95%|█████████▍| 45314/47780 [00:12<00:00, 6894.94 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47758/47780 [03:29<00:18,  1.22 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:26<00:00, 1192.58 examples/s] 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47762/47780 [03:33<00:16,  1.10 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:33<00:00, 1413.82 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:36<00:00, 1321.59 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:25<00:00, 1212.73 examples/s] backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:35<00:00, 1269.13 examples/s][2025-08-04 00:34:18,792] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 00:34:18,813] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:38<00:00, 1247.60 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 00:34:20,551] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m df: /root/.triton/autotune: No such file or directory
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47765/47780 [03:39<00:16,  1.13s/ examples]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:33<00:00, 1428.51 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 00:34:22,261] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:32<00:00, 1479.76 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [03:42<00:15,  1.20s/ examples][2025-08-04 00:34:24,216] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47771/47780 [03:43<00:07,  1.17 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47772/47780 [03:43<00:06,  1.29 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [03:43<00:01,  2.01 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [00:29<00:00, 12028.86 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [00:29<00:00, 1001.29 examples/s] 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [03:45<00:01,  1.59 examples/s]Truncating train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [00:30<00:00, 1415.49 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Truncating train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [00:30<00:00, 1415.19 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 00:34:28,276] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 00:34:28,276] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 00:34:28,276] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 00:34:28,276] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 00:34:28,276] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 00:34:28,978] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 00:34:29,085] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:48<00:00, 209.24 examples/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 00:34:30,239] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 00:34:30,275] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 00:34:30,454] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 00:34:31,546] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   0%|          | 0/25 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3442)[0m   4%|▍         | 1/25 [00:46<18:31, 46.33s/it]
[36m(head, rank=0, pid=3442)[0m   8%|▊         | 2/25 [01:26<16:17, 42.49s/it]
[36m(head, rank=0, pid=3442)[0m  12%|█▏        | 3/25 [02:07<15:21, 41.90s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  16%|█▌        | 4/25 [02:46<14:19, 40.92s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  20%|██        | 5/25 [03:26<13:31, 40.56s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 170.35 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 170.35s (Total: 170.35s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 170.35 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 170.35 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 170.35s (Total: 170.35s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 170.35s (Total: 170.35s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 170.35 secondsCompleted Save checkpoint in 170.35 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 170.34 secondsCheckpoint save time: 170.35s (Total: 170.35s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 170.35 secondsCompleted Save checkpoint in 170.35 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 170.35s (Total: 170.35s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 170.34s (Total: 170.34s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 170.35s (Total: 170.35s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 170.35s (Total: 170.35s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 170.34 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 170.34s (Total: 170.34s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 170.35 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 170.35s (Total: 170.35s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 170.34 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 170.34s (Total: 170.34s)Completed Save checkpoint in 170.34 seconds
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 170.34s (Total: 170.34s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 170.35 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 170.35s (Total: 170.35s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 170.34 seconds
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 170.34 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 170.34s (Total: 170.34s)Checkpoint save time: 170.34s (Total: 170.34s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 301.88 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 301.88s (Total: 301.88s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  24%|██▍       | 6/25 [09:09<45:23, 143.33s/it]
[36m(head, rank=0, pid=3442)[0m  28%|██▊       | 7/25 [09:49<32:53, 109.65s/it]
[36m(head, rank=0, pid=3442)[0m  32%|███▏      | 8/25 [10:29<24:47, 87.47s/it] 
[36m(head, rank=0, pid=3442)[0m  36%|███▌      | 9/25 [11:08<19:14, 72.19s/it] 40%|████      | 10/25 [11:45<15:18, 61.22s/it]Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m                                                {'loss': 125.3922, 'grad_norm': 49.56791305541992, 'learning_rate': 1.2800000000000001e-05, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3442)[0m  40%|████      | 10/25 [11:45<15:18, 61.22s/it]Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 175.02 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 175.02s (Total: 345.37s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 175.02 seconds
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 175.02 secondsCheckpoint save time: 175.02s (Total: 345.37s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 175.02s (Total: 345.37s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 175.02 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 175.02s (Total: 345.37s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 175.02 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 175.02s (Total: 345.37s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 175.02 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 175.02s (Total: 345.37s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 175.02 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 175.02s (Total: 345.37s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 175.02 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 175.02s (Total: 345.37s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 175.02 secondsCompleted Save checkpoint in 175.02 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 175.02s (Total: 345.37s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 175.02s (Total: 345.37s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 175.02 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 175.02s (Total: 345.37s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 175.02 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 175.02s (Total: 345.37s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 175.02 secondsCompleted Save checkpoint in 175.02 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 175.02s (Total: 345.37s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 175.02s (Total: 345.37s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 175.03 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 175.03s (Total: 345.37s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 309.25 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 309.25s (Total: 611.13s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  44%|████▍     | 11/25 [17:31<34:40, 148.61s/it]
[36m(head, rank=0, pid=3442)[0m  48%|████▊     | 12/25 [18:15<25:17, 116.73s/it]
[36m(head, rank=0, pid=3442)[0m  52%|█████▏    | 13/25 [18:53<18:34, 92.87s/it] 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  56%|█████▌    | 14/25 [19:31<13:58, 76.25s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  60%|██████    | 15/25 [20:10<10:50, 65.04s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 173.36 secondsCompleted Save checkpoint in 173.37 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 173.37 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 173.37s (Total: 518.73s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 173.36s (Total: 518.73s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 173.37s (Total: 518.74s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 173.36 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 173.36s (Total: 518.73s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 173.36 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 173.36s (Total: 518.73s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 173.36 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 173.36s (Total: 518.73s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 173.36 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 173.36s (Total: 518.73s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 173.36 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 173.36s (Total: 518.74s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 173.37 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 173.37s (Total: 518.74s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 173.37 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 173.37s (Total: 518.74s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 173.37 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 173.37s (Total: 518.74s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 173.37 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 173.37s (Total: 518.74s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 173.36 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 173.36s (Total: 518.73s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 173.36 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 173.36s (Total: 518.73s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 173.37 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 173.37s (Total: 518.74s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 306.00 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 306.00s (Total: 917.13s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  64%|██████▍   | 16/25 [25:57<22:29, 149.97s/it]
[36m(head, rank=0, pid=3442)[0m  68%|██████▊   | 17/25 [26:36<15:33, 116.66s/it]
[36m(head, rank=0, pid=3442)[0m  72%|███████▏  | 18/25 [27:15<10:52, 93.17s/it] 
[36m(head, rank=0, pid=3442)[0m  76%|███████▌  | 19/25 [27:53<07:40, 76.74s/it] 80%|████████  | 20/25 [28:30<05:22, 64.58s/it]Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m                                                Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m {'loss': 94.3979, 'grad_norm': 22.57253646850586, 'learning_rate': 4.800000000000001e-06, 'num_tokens': 19076177.0, 'epoch': 0.05}
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  80%|████████  | 20/25 [28:30<05:22, 64.58s/it]Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 177.29 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 177.29s (Total: 696.02s)Completed Save checkpoint in 177.29 seconds
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 177.29 seconds
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 177.29s (Total: 696.02s)Checkpoint save time: 177.29s (Total: 696.03s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 177.29 seconds
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 177.29 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 177.29s (Total: 696.02s)
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 177.29s (Total: 696.03s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 177.29 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 177.29s (Total: 696.02s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 177.29 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 177.29s (Total: 696.02s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 177.29 secondsCompleted Save checkpoint in 177.29 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 177.29 secondsCompleted Save checkpoint in 177.29 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 177.29s (Total: 696.02s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 177.29s (Total: 696.02s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 177.29s (Total: 696.02s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 177.29s (Total: 696.02s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 177.29 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 177.29s (Total: 696.02s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 177.29 secondsCompleted Save checkpoint in 177.29 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 177.29s (Total: 696.02s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 177.29s (Total: 696.02s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 177.29 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 177.29s (Total: 696.02s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 338.61 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 338.61s (Total: 1255.74s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  84%|████████▍ | 21/25 [34:49<10:36, 159.15s/it]
[36m(head, rank=0, pid=3442)[0m  88%|████████▊ | 22/25 [35:28<06:08, 122.96s/it]
[36m(head, rank=0, pid=3442)[0m  92%|█████████▏| 23/25 [36:09<03:17, 98.53s/it] 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  96%|█████████▌| 24/25 [36:46<01:19, 79.95s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 100%|██████████| 25/25 [37:24<00:00, 67.41s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 181.63 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 181.63s (Total: 877.66s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 181.63 seconds
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 181.63 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 181.63s (Total: 877.65s)
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 181.63s (Total: 877.66s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 181.62 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 181.62s (Total: 877.65s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 181.63 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 181.63s (Total: 877.65s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 181.63 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 181.63s (Total: 877.65s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 181.63 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 181.63s (Total: 877.65s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 181.63 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 181.63 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 181.63 secondsCheckpoint save time: 181.63s (Total: 877.65s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 181.63s (Total: 877.65s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 181.63s (Total: 877.66s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 181.63 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 181.63s (Total: 877.65s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 181.63 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 181.63 secondsCheckpoint save time: 181.63s (Total: 877.65s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 181.63s (Total: 877.65s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 181.63 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 181.63s (Total: 877.65s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 181.63 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 181.63s (Total: 877.65s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 2926.76 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 2926.86 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 877.65s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 170.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 142.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 47.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1305.67s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 6.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 118.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 877.65s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 170.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 142.48s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 47.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1307.43s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 6.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 118.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 2926.80 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 2926.85 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 877.65s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 170.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 142.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 47.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1305.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 6.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 118.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 877.65s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 170.34s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 142.48s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 47.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1307.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 6.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.58s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 118.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 2926.82 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 877.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 170.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 142.49s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 47.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1307.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 6.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 118.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /tmp/checkpoint/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /tmp/checkpoint/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 2905.18 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /tmp/checkpoint/training_run_4_1_info.jsonCheckpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 877.65s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 170.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 142.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1  - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 47.29s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1304.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 6.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 118.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /tmp/checkpoint/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /tmp/checkpoint/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /tmp/checkpoint/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 2926.77 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 877.65s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 170.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 142.50s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 47.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1307.12s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 6.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.62s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 117.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /tmp/checkpoint/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 2926.82 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 877.65s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 170.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 142.49s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 47.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1307.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 6.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.62s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 118.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /tmp/checkpoint/training_run_6_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 312.15 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 312.15s (Total: 1567.89s)
[36m(head, rank=0, pid=3442)[0m                                                {'train_runtime': 2556.7155, 'train_samples_per_second': 1.252, 'train_steps_per_second': 0.01, 'train_loss': 106.388515625, 'num_tokens': 23880036.0, 'epoch': 0.07}
[36m(head, rank=0, pid=3442)[0m 100%|██████████| 25/25 [42:36<00:00, 67.41s/it]100%|██████████| 25/25 [42:36<00:00, 102.27s/it]
[36m(head, rank=0, pid=3442)[0m Completed Training in 2907.01 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1567.89s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 313.58s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 301.88s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 338.61s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 0.96s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 0.04s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 0.12s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 888.60s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 4.44s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.66s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 9.00s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Completed Training in 2926.70 seconds
[36m(head, rank=0, pid=3442)[0m Saved training info to: /tmp/checkpoint/training_run_0_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 877.66s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 175.53s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 170.35s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 181.63s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 142.48s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 5.70s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 47.29s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1306.55s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 6.53s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.66s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 118.10s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Completed Training in 2926.64 seconds
[36m(head, rank=0, pid=3442)[0m Completed Training in 2926.77 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 877.65s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 175.53s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 170.34s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 181.62s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 142.48s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 5.70s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 47.28s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1306.99s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 6.53s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.56s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 118.10s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 877.65s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 175.53s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 170.34s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 181.63s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 142.48s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 5.70s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 47.29s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1306.87s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 6.53s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.66s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 118.10s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Completed Training in 2926.70 seconds
[36m(head, rank=0, pid=3442)[0m Saved training info to: /tmp/checkpoint/training_run_4_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Completed Training in 2926.69 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 877.65s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 175.53s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 170.34s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 181.63s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 142.55s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 5.70s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 47.29s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1307.54s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 6.54s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.66s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 118.01s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 877.66s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 175.53s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 170.35s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 181.63s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 142.48s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 5.70s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 47.29s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1306.57s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 6.53s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.66s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 118.10s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /tmp/checkpoint/training_run_6_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /tmp/checkpoint/training_run_7_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Completed Training in 2926.81 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 877.65s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 175.53s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 170.34s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 181.63s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 142.48s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 5.70s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 47.29s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1305.62s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 6.53s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.66s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 118.10s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /tmp/checkpoint/training_run_3_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /tmp/checkpoint/training_run_1_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /tmp/checkpoint/training_run_2_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Completed Training in 2926.67 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 877.65s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 175.53s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 170.34s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 181.63s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 142.52s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 5.70s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 47.28s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1306.73s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 6.53s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.54s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 118.10s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /tmp/checkpoint/training_run_5_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 23.16s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 23.16s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 23.16s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 23.16s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2905.18s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2905.18s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2905.18s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2905.18s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 6.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 118.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1304.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 47.29s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 142.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 170.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 877.65s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 2930.42s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 2930.42s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 2930.42s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 2930.42s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_0.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m --- Training Run 1 Info (Directory: /tmp/checkpoint) ---
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "run_id": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "timestamp": "2025-08-04T00:28:44.103007",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "checkpoint_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training_status": "completed",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "output_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "dataset_load_time": 2.0761120319366455,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "model_load_time": 23.161664247512817,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training_time": 2905.183804988861,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_time": 2930.4215812683105,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "error": null,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "num_checkpoints_saved": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_checkpoint_save_time": 877.6505901813507,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "average_checkpoint_save_time": 175.53011803627015,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "min_checkpoint_save_time": 170.34664392471313,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "max_checkpoint_save_time": 181.6316635608673,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     170.34664392471313,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     175.0239806175232,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     173.361154794693,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     177.28714728355408,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     181.6316635608673
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "num_batch_samples": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_batch_sample_time": 142.5252845287323,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "average_batch_sample_time": 5.701011381149292,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "min_batch_sample_time": 0.02773571014404297,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "max_batch_sample_time": 47.28518271446228,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.08550429344177246,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.02915024757385254,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.030402421951293945,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.030255556106567383,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.032494306564331055,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     31.19205665588379,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.0300748348236084,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.027950525283813477,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.029708385467529297,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.028656482696533203,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     31.953596115112305,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.02957749366760254,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03227639198303223,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03190183639526367,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.02974700927734375,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     31.402690172195435,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.028238296508789062,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03293490409851074,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.02773571014404297,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.029135942459106445,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     47.28518271446228,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03119683265686035,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.02957630157470703,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03399181365966797,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.031249284744262695
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "num_training_steps": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_training_step_time": 1304.9580273628235,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "average_training_step_time": 6.524790136814118,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "min_training_step_time": 3.6611456871032715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "max_training_step_time": 118.10209560394287,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "individual_training_step_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     8.158034086227417,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.420812606811523,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.3248255252838135,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.226606607437134,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.296921730041504,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.005376100540161,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.25602650642395,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.26355767250061,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.17536997795105,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.068260669708252,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.169172048568726,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.122112512588501,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.100708723068237,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.376881837844849,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.142096996307373,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.246106147766113,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.7804341316223145,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     6.269430637359619,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.091584920883179,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.104257106781006,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.731847763061523,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.117052316665649,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.130824565887451,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.147643566131592,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.515976667404175,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.487926006317139,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.296510934829712,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.12257981300354,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.871211290359497,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.120450735092163,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.240461111068726,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.7755818367004395,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.367708683013916,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.315516710281372,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.511936902999878,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.497719764709473,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.796001195907593,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.551709890365601,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6611456871032715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.136261940002441,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     104.20335650444031,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.172838449478149,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     8.01435399055481,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.341175079345703,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.371575593948364,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.167011022567749,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9661829471588135,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.21596884727478,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.290886878967285,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.092750549316406,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.231820821762085,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.083268404006958,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.784714460372925,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.198103189468384,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.6596715450286865,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.951279640197754,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.36901330947876,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.4653000831604,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.261666536331177,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.579878568649292,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9693782329559326,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.224982738494873,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.1165611743927,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.744927406311035,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.004565715789795,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8949196338653564,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.087867021560669,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9696438312530518,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.560364723205566,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.38588547706604,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.215837717056274,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.594383955001831,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9854793548583984,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.510158538818359,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.986107587814331,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.1463940143585205,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.344271898269653,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.070952653884888,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.666271209716797,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.123869180679321,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     106.5441472530365,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.95865273475647,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.0070459842681885,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.297482967376709,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8583948612213135,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7790119647979736,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.423780679702759,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9799225330352783,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     7.2276411056518555,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.298871755599976,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.075706481933594,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.435844659805298,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.0420167446136475,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8752431869506836,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.197235345840454,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.153940677642822,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.106441497802734,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.093391418457031,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.673285961151123,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.459609031677246,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.165073871612549,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.24584698677063,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.2968590259552,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8900301456451416,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9682135581970215,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.959961414337158,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.117118835449219,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.241462469100952,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.00026535987854,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9753246307373047,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.850703716278076,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9806854724884033,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.108062744140625,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9752957820892334,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.579007863998413,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.860147714614868,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.216358423233032,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.3376688957214355,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.183120489120483,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.793026685714722,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     106.06315517425537,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7313075065612793,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.413938522338867,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7115752696990967,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     7.044660806655884,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.446852445602417,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.916122913360596,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9731533527374268,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.088242530822754,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.249807119369507,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.280327558517456,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8042895793914795,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8429930210113525,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.990854263305664,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9529755115509033,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7949490547180176,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9598512649536133,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.312476873397827,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.7457356452941895,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.471818447113037,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.008926153182983,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.859194755554199,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9486896991729736,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.138405799865723,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.184072256088257,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.3525230884552,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.191965341567993,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.744009256362915,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.88918399810791,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9907612800598145,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.202612400054932,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8490090370178223,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.164306879043579,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.852947235107422,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.098646640777588,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.870241641998291,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7689764499664307,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.026753664016724,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8160738945007324,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.9529008865356445,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     118.10209560394287,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.492103576660156,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     8.566345453262329,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.100851058959961,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.961869955062866,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.066743612289429,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.031850337982178,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.928785800933838,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.981875419616699,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.087559461593628,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.982424020767212,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.146455764770508,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.957932710647583,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.974228858947754,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.236263751983643,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.2732579708099365,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.953607082366943,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.081347942352295,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.8625547885894775,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.780612468719482,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.007587194442749,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.791154623031616,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.326411485671997,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.1458046436309814,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.40025782585144,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9176383018493652,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.72508978843689,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.951359748840332,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.056627035140991,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6941275596618652,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9325623512268066,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.2537665367126465,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9626688957214355,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9495327472686768,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.148818731307983,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.195500373840332,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.1134912967681885,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.558296203613281,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.910210132598877,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.392885684967041
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   ]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m --- All Training Runs Summary ---
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "run_id": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "timestamp": "2025-08-04T00:28:44.103007",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_status": "completed",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "output_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_time": 2.0761120319366455,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_time": 23.161664247512817,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_time": 2905.183804988861,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_time": 2930.4215812683105,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "error": null,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "num_checkpoints_saved": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_checkpoint_save_time": 877.6505901813507,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_checkpoint_save_time": 175.53011803627015,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "min_checkpoint_save_time": 170.34664392471313,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "max_checkpoint_save_time": 181.6316635608673,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       170.34664392471313,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       175.0239806175232,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       173.361154794693,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       177.28714728355408,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       181.6316635608673
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "num_batch_samples": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_batch_sample_time": 142.5252845287323,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_batch_sample_time": 5.701011381149292,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "min_batch_sample_time": 0.02773571014404297,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "max_batch_sample_time": 47.28518271446228,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.08550429344177246,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.02915024757385254,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.030402421951293945,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.030255556106567383,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.032494306564331055,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       31.19205665588379,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.0300748348236084,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.027950525283813477,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.029708385467529297,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.028656482696533203,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       31.953596115112305,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.02957749366760254,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03227639198303223,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03190183639526367,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.02974700927734375,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       31.402690172195435,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.028238296508789062,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03293490409851074,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.02773571014404297,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.029135942459106445,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       47.28518271446228,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03119683265686035,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.02957630157470703,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03399181365966797,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.031249284744262695
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "num_training_steps": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_training_step_time": 1304.9580273628235,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_training_step_time": 6.524790136814118,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "min_training_step_time": 3.6611456871032715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "max_training_step_time": 118.10209560394287,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "individual_training_step_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       8.158034086227417,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.420812606811523,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.3248255252838135,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.226606607437134,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.296921730041504,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.005376100540161,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.25602650642395,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.26355767250061,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.17536997795105,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.068260669708252,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.169172048568726,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.122112512588501,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.100708723068237,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.376881837844849,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.142096996307373,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.246106147766113,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.7804341316223145,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       6.269430637359619,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.091584920883179,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.104257106781006,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.731847763061523,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.117052316665649,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.130824565887451,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.147643566131592,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.515976667404175,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.487926006317139,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.296510934829712,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.12257981300354,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.871211290359497,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.120450735092163,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.240461111068726,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.7755818367004395,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.367708683013916,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.315516710281372,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.511936902999878,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.497719764709473,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.796001195907593,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.551709890365601,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6611456871032715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.136261940002441,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       104.20335650444031,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.172838449478149,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       8.01435399055481,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.341175079345703,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.371575593948364,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.167011022567749,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9661829471588135,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.21596884727478,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.290886878967285,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.092750549316406,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.231820821762085,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.083268404006958,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.784714460372925,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.198103189468384,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.6596715450286865,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.951279640197754,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.36901330947876,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.4653000831604,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.261666536331177,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.579878568649292,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9693782329559326,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.224982738494873,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.1165611743927,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.744927406311035,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.004565715789795,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8949196338653564,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.087867021560669,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9696438312530518,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.560364723205566,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.38588547706604,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.215837717056274,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.594383955001831,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9854793548583984,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.510158538818359,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.986107587814331,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.1463940143585205,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.344271898269653,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.070952653884888,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.666271209716797,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.123869180679321,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       106.5441472530365,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.95865273475647,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.0070459842681885,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.297482967376709,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8583948612213135,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7790119647979736,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.423780679702759,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9799225330352783,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       7.2276411056518555,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.298871755599976,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.075706481933594,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.435844659805298,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.0420167446136475,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8752431869506836,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.197235345840454,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.153940677642822,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.106441497802734,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.093391418457031,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.673285961151123,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.459609031677246,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.165073871612549,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.24584698677063,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.2968590259552,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8900301456451416,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9682135581970215,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.959961414337158,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.117118835449219,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.241462469100952,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.00026535987854,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9753246307373047,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.850703716278076,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9806854724884033,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.108062744140625,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9752957820892334,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.579007863998413,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.860147714614868,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.216358423233032,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.3376688957214355,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.183120489120483,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.793026685714722,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       106.06315517425537,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7313075065612793,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.413938522338867,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7115752696990967,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       7.044660806655884,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.446852445602417,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.916122913360596,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9731533527374268,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.088242530822754,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.249807119369507,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.280327558517456,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8042895793914795,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8429930210113525,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.990854263305664,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9529755115509033,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7949490547180176,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9598512649536133,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.312476873397827,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.7457356452941895,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.471818447113037,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.008926153182983,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.859194755554199,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9486896991729736,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.138405799865723,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.184072256088257,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.3525230884552,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.191965341567993,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.744009256362915,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.88918399810791,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9907612800598145,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.202612400054932,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8490090370178223,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.164306879043579,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.852947235107422,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.098646640777588,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.870241641998291,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7689764499664307,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.026753664016724,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8160738945007324,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.9529008865356445,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       118.10209560394287,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.492103576660156,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       8.566345453262329,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.100851058959961,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.961869955062866,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.066743612289429,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.031850337982178,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.928785800933838,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.981875419616699,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.087559461593628,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.982424020767212,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.146455764770508,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.957932710647583,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.974228858947754,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.236263751983643,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.2732579708099365,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.953607082366943,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.081347942352295,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.8625547885894775,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.780612468719482,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.007587194442749,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.791154623031616,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.326411485671997,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.1458046436309814,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.40025782585144,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9176383018493652,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.72508978843689,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.951359748840332,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.056627035140991,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6941275596618652,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9325623512268066,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.2537665367126465,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9626688957214355,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9495327472686768,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.148818731307983,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.195500373840332,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.1134912967681885,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.558296203613281,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.910210132598877,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.392885684967041
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     ]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m --- Timing Summary ---
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_runs": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "dataset_loading": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_average": 2.0761120319366455,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_min": 2.0761120319366455,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_max": 2.0761120319366455,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_total": 2.0761120319366455
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "model_loading": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_average": 23.161664247512817,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_min": 23.161664247512817,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_max": 23.161664247512817,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_total": 23.161664247512817
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_average": 2905.183804988861,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_min": 2905.183804988861,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_max": 2905.183804988861,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_total": 2905.183804988861
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_run_time": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_average": 2930.4215812683105,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_min": 2930.4215812683105,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_max": 2930.4215812683105,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_total": 2930.4215812683105
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "checkpoint_saving": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_checkpoints_saved": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_checkpoint_save_time": 877.6505901813507,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_save_time_per_checkpoint": 175.53011803627015,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_times_count": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_min": 170.34664392471313,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_max": 181.6316635608673,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_average": 175.53011803627015
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "batch_sampling": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_batch_samples": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_batch_sample_time": 142.5252845287323,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_sample_time_per_batch": 5.701011381149292,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_times_count": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_min": 0.02773571014404297,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_max": 47.28518271446228,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_average": 5.701011381149292
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training_steps": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_training_steps": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_training_step_time": 1304.9580273628235,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_step_time_per_step": 6.524790136814118,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_times_count": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_min": 3.6611456871032715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_max": 118.10209560394287,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_average": 6.524790136814118
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.29s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.29s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.29s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.29s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 0.96s
[36m(head, rank=0, pid=3442)[0m   • Min time: 0.96s
[36m(head, rank=0, pid=3442)[0m   • Max time: 0.96s
[36m(head, rank=0, pid=3442)[0m   • Total time: 0.96s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2926.64s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2926.64s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2926.64s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2926.64s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 6.53s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.56s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 118.10s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1306.99s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 5.70s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 47.28s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 142.48s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 175.53s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 170.34s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 181.62s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 877.65s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 2929.90s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 2929.90s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 2929.90s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 2929.90s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.09s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.09s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.09s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.09s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 0.91s
[36m(head, rank=0, pid=3442)[0m   • Min time: 0.91s
[36m(head, rank=0, pid=3442)[0m   • Max time: 0.91s
[36m(head, rank=0, pid=3442)[0m   • Total time: 0.91s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2926.77s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2926.77s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2926.77s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2926.77s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 6.53s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.66s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 118.10s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1306.87s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 5.70s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 47.29s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 142.48s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 175.53s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 170.34s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 181.63s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 877.65s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 2929.77s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 2929.77s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 2929.77s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 2929.77s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.07s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.07s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.07s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.07s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.02s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.02s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.02s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.02s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2926.70s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2926.70s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2926.70s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2926.70s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 6.53s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.66sSaved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   • Max step time: 118.10s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1306.55s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 5.70s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 47.29s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 142.48s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 175.53s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 170.35s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 181.63s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 877.66s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 2929.79s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 2929.79s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 2929.79s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 2929.79s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.33s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.33s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.33s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.33s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 0.91s
[36m(head, rank=0, pid=3442)[0m   • Min time: 0.91s
[36m(head, rank=0, pid=3442)[0m   • Max time: 0.91s
[36m(head, rank=0, pid=3442)[0m   • Total time: 0.91s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2926.69s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2926.69s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2926.69s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2926.69s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 6.53s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.66s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 118.10s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1306.57s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 5.70s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 47.29s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 142.48s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 175.53s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 170.35s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 181.63s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 877.66s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 2929.93s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 2929.93s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 2929.93s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 2929.93s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.09s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.09s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.09s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.09s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 0.95s
[36m(head, rank=0, pid=3442)[0m   • Min time: 0.95s
[36m(head, rank=0, pid=3442)[0m   • Max time: 0.95s
[36m(head, rank=0, pid=3442)[0m   • Total time: 0.95s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2926.70s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2926.70s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2926.70s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2926.70s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 6.54s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.66s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 118.01s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1307.54s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 5.70s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 47.29s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 142.55s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 175.53s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 170.34s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 181.63s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 877.65s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 2929.74s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 2929.74s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 2929.74s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 2929.74s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.09s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.09s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.09s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.09s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 21.33s
[36m(head, rank=0, pid=3442)[0m   • Min time: 21.33s
[36m(head, rank=0, pid=3442)[0m   • Max time: 21.33s
[36m(head, rank=0, pid=3442)[0m   • Total time: 21.33s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2907.01s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2907.01s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2907.01s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2907.01s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 4.44s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.66s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 9.00s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 888.60s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 0.12s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 0.96s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 313.58s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 301.88s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 338.61s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1567.89s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 2930.43s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 2930.43s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 2930.43s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 2930.43s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m --- Training Run 1 Info (Directory: /tmp/checkpoint) ---
[36m(head, rank=0, pid=3442)[0m {
[36m(head, rank=0, pid=3442)[0m   "run_id": 1,
[36m(head, rank=0, pid=3442)[0m   "timestamp": "2025-08-04T00:28:44.103516",
[36m(head, rank=0, pid=3442)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3442)[0m   "checkpoint_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3442)[0m   "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3442)[0m   "training_status": "completed",
[36m(head, rank=0, pid=3442)[0m   "output_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3442)[0m   "dataset_load_time": 2.0864126682281494,
[36m(head, rank=0, pid=3442)[0m   "model_load_time": 21.330164194107056,
[36m(head, rank=0, pid=3442)[0m   "training_time": 2907.0133254528046,
[36m(head, rank=0, pid=3442)[0m   "total_time": 2930.4299023151398,
[36m(head, rank=0, pid=3442)[0m   "error": null,
[36m(head, rank=0, pid=3442)[0m   "num_checkpoints_saved": 5,
[36m(head, rank=0, pid=3442)[0m   "total_checkpoint_save_time": 1567.8917469978333,
[36m(head, rank=0, pid=3442)[0m   "average_checkpoint_save_time": 313.57834939956666,
[36m(head, rank=0, pid=3442)[0m   "min_checkpoint_save_time": 301.87854194641113,
[36m(head, rank=0, pid=3442)[0m   "max_checkpoint_save_time": 338.61338472366333,
[36m(head, rank=0, pid=3442)[0m   "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3442)[0m     301.87854194641113,
[36m(head, rank=0, pid=3442)[0m     309.2528467178345,
[36m(head, rank=0, pid=3442)[0m     305.99927163124084,
[36m(head, rank=0, pid=3442)[0m     338.61338472366333,
[36m(head, rank=0, pid=3442)[0m     312.1477019786835
[36m(head, rank=0, pid=3442)[0m   ],
[36m(head, rank=0, pid=3442)[0m   "num_batch_samples": 25,
[36m(head, rank=0, pid=3442)[0m   "total_batch_sample_time": 0.9569046497344971,
[36m(head, rank=0, pid=3442)[0m   "average_batch_sample_time": 0.03827618598937988,
[36m(head, rank=0, pid=3442)[0m   "min_batch_sample_time": 0.02638721466064453,
[36m(head, rank=0, pid=3442)[0m   "max_batch_sample_time": 0.12395215034484863,
[36m(head, rank=0, pid=3442)[0m   "individual_batch_sample_times": [
[36m(head, rank=0, pid=3442)[0m     0.06297540664672852,
[36m(head, rank=0, pid=3442)[0m     0.029206514358520508,
[36m(head, rank=0, pid=3442)[0m     0.03035712242126465,
[36m(head, rank=0, pid=3442)[0m     0.028657913208007812,
[36m(head, rank=0, pid=3442)[0m     0.02964043617248535,
[36m(head, rank=0, pid=3442)[0m     0.030486345291137695,
[36m(head, rank=0, pid=3442)[0m     0.03291916847229004,
[36m(head, rank=0, pid=3442)[0m     0.0316312313079834,
[36m(head, rank=0, pid=3442)[0m     0.026617050170898438,
[36m(head, rank=0, pid=3442)[0m     0.028642654418945312,
[36m(head, rank=0, pid=3442)[0m     0.03183341026306152,
[36m(head, rank=0, pid=3442)[0m     0.030431509017944336,
[36m(head, rank=0, pid=3442)[0m     0.02638721466064453,
[36m(head, rank=0, pid=3442)[0m     0.02859210968017578,
[36m(head, rank=0, pid=3442)[0m     0.029331445693969727,
[36m(head, rank=0, pid=3442)[0m     0.12395215034484863,
[36m(head, rank=0, pid=3442)[0m     0.035149574279785156,
[36m(head, rank=0, pid=3442)[0m     0.0334169864654541,
[36m(head, rank=0, pid=3442)[0m     0.0325016975402832,
[36m(head, rank=0, pid=3442)[0m     0.028483152389526367,
[36m(head, rank=0, pid=3442)[0m     0.07806658744812012,
[36m(head, rank=0, pid=3442)[0m     0.04226064682006836,
[36m(head, rank=0, pid=3442)[0m     0.03759169578552246,
[36m(head, rank=0, pid=3442)[0m     0.03681778907775879,
[36m(head, rank=0, pid=3442)[0m     0.030954837799072266
[36m(head, rank=0, pid=3442)[0m   ],
[36m(head, rank=0, pid=3442)[0m   "num_training_steps": 200,
[36m(head, rank=0, pid=3442)[0m   "total_training_step_time": 888.599869966507,
[36m(head, rank=0, pid=3442)[0m   "average_training_step_time": 4.442999349832535,
[36m(head, rank=0, pid=3442)[0m   "min_training_step_time": 3.6595282554626465,
[36m(head, rank=0, pid=3442)[0m   "max_training_step_time": 8.996733903884888,
[36m(head, rank=0, pid=3442)[0m   "individual_training_step_times": [
[36m(head, rank=0, pid=3442)[0m     8.996733903884888,
[36m(head, rank=0, pid=3442)[0m     4.814598083496094,
[36m(head, rank=0, pid=3442)[0m     5.332859754562378,
[36m(head, rank=0, pid=3442)[0m     4.2270896434783936,
[36m(head, rank=0, pid=3442)[0m     5.265184164047241,
[36m(head, rank=0, pid=3442)[0m     4.00435471534729,
[36m(head, rank=0, pid=3442)[0m     4.1070237159729,
[36m(head, rank=0, pid=3442)[0m     4.266810417175293,
[36m(head, rank=0, pid=3442)[0m     4.25379490852356,
[36m(head, rank=0, pid=3442)[0m     5.097965955734253,
[36m(head, rank=0, pid=3442)[0m     4.169838190078735,
[36m(head, rank=0, pid=3442)[0m     4.121963739395142,
[36m(head, rank=0, pid=3442)[0m     4.100440740585327,
[36m(head, rank=0, pid=3442)[0m     5.378668546676636,
[36m(head, rank=0, pid=3442)[0m     4.142361879348755,
[36m(head, rank=0, pid=3442)[0m     4.750032901763916,
[36m(head, rank=0, pid=3442)[0m     4.835744857788086,
[36m(head, rank=0, pid=3442)[0m     6.273422718048096,
[36m(head, rank=0, pid=3442)[0m     4.018996715545654,
[36m(head, rank=0, pid=3442)[0m     4.105278730392456,
[36m(head, rank=0, pid=3442)[0m     4.711097478866577,
[36m(head, rank=0, pid=3442)[0m     4.11498236656189,
[36m(head, rank=0, pid=3442)[0m     5.132357120513916,
[36m(head, rank=0, pid=3442)[0m     4.145087242126465,
[36m(head, rank=0, pid=3442)[0m     5.5218000411987305,
[36m(head, rank=0, pid=3442)[0m     4.392833948135376,
[36m(head, rank=0, pid=3442)[0m     4.2984089851379395,
[36m(head, rank=0, pid=3442)[0m     4.125567674636841,
[36m(head, rank=0, pid=3442)[0m     4.021824359893799,
[36m(head, rank=0, pid=3442)[0m     4.118624210357666,
[36m(head, rank=0, pid=3442)[0m     4.266567230224609,
[36m(head, rank=0, pid=3442)[0m     4.775826930999756,
[36m(head, rank=0, pid=3442)[0m     5.323858022689819,
[36m(head, rank=0, pid=3442)[0m     4.318108081817627,
[36m(head, rank=0, pid=3442)[0m     4.512164354324341,
[36m(head, rank=0, pid=3442)[0m     4.500317096710205,
[36m(head, rank=0, pid=3442)[0m     4.798299074172974,
[36m(head, rank=0, pid=3442)[0m     4.593712568283081,
[36m(head, rank=0, pid=3442)[0m     3.6595282554626465,
[36m(head, rank=0, pid=3442)[0m     4.137315511703491,
[36m(head, rank=0, pid=3442)[0m     3.919907808303833,
[36m(head, rank=0, pid=3442)[0m     4.0234222412109375,
[36m(head, rank=0, pid=3442)[0m     8.043860673904419,
[36m(head, rank=0, pid=3442)[0m     4.344482183456421,
[36m(head, rank=0, pid=3442)[0m     4.345244407653809,
[36m(head, rank=0, pid=3442)[0m     4.166297912597656,
[36m(head, rank=0, pid=3442)[0m     3.9689698219299316,
[36m(head, rank=0, pid=3442)[0m     4.213576316833496,
[36m(head, rank=0, pid=3442)[0m     5.144278526306152,
[36m(head, rank=0, pid=3442)[0m     5.0931854248046875,
[36m(head, rank=0, pid=3442)[0m     4.35783839225769,
[36m(head, rank=0, pid=3442)[0m     4.0861358642578125,
[36m(head, rank=0, pid=3442)[0m     4.7836244106292725,
[36m(head, rank=0, pid=3442)[0m     4.2863171100616455,
[36m(head, rank=0, pid=3442)[0m     4.681871652603149,
[36m(head, rank=0, pid=3442)[0m     3.9518015384674072,
[36m(head, rank=0, pid=3442)[0m     5.369300603866577,
[36m(head, rank=0, pid=3442)[0m     4.466315984725952,
[36m(head, rank=0, pid=3442)[0m     4.2587974071502686,
[36m(head, rank=0, pid=3442)[0m     4.599525690078735,
[36m(head, rank=0, pid=3442)[0m     4.114660739898682,
[36m(head, rank=0, pid=3442)[0m     4.22622013092041,
[36m(head, rank=0, pid=3442)[0m     4.117686033248901,
[36m(head, rank=0, pid=3442)[0m     4.841781139373779,
[36m(head, rank=0, pid=3442)[0m     4.009570121765137,
[36m(head, rank=0, pid=3442)[0m     3.9825050830841064,
[36m(head, rank=0, pid=3442)[0m     4.08527135848999,
[36m(head, rank=0, pid=3442)[0m     3.884977102279663,
[36m(head, rank=0, pid=3442)[0m     4.558824300765991,
[36m(head, rank=0, pid=3442)[0m     5.380278825759888,
[36m(head, rank=0, pid=3442)[0m     4.214171409606934,
[36m(head, rank=0, pid=3442)[0m     4.590816497802734,
[36m(head, rank=0, pid=3442)[0m     3.852241277694702,
[36m(head, rank=0, pid=3442)[0m     4.472700595855713,
[36m(head, rank=0, pid=3442)[0m     4.128572225570679,
[36m(head, rank=0, pid=3442)[0m     4.150026798248291,
[36m(head, rank=0, pid=3442)[0m     4.429317951202393,
[36m(head, rank=0, pid=3442)[0m     4.094755411148071,
[36m(head, rank=0, pid=3442)[0m     3.662590742111206,
[36m(head, rank=0, pid=3442)[0m     4.124629259109497,
[36m(head, rank=0, pid=3442)[0m     4.235240459442139,
[36m(head, rank=0, pid=3442)[0m     5.0663628578186035,
[36m(head, rank=0, pid=3442)[0m     4.007302761077881,
[36m(head, rank=0, pid=3442)[0m     4.303620100021362,
[36m(head, rank=0, pid=3442)[0m     3.856496572494507,
[36m(head, rank=0, pid=3442)[0m     3.7767982482910156,
[36m(head, rank=0, pid=3442)[0m     4.53976035118103,
[36m(head, rank=0, pid=3442)[0m     3.9866905212402344,
[36m(head, rank=0, pid=3442)[0m     7.248344659805298,
[36m(head, rank=0, pid=3442)[0m     5.407552480697632,
[36m(head, rank=0, pid=3442)[0m     5.0786402225494385,
[36m(head, rank=0, pid=3442)[0m     4.439354181289673,
[36m(head, rank=0, pid=3442)[0m     5.042923450469971,
[36m(head, rank=0, pid=3442)[0m     3.970787525177002,
[36m(head, rank=0, pid=3442)[0m     4.226814270019531,
[36m(head, rank=0, pid=3442)[0m     4.122639894485474,
[36m(head, rank=0, pid=3442)[0m     4.105255365371704,
[36m(head, rank=0, pid=3442)[0m     5.215703010559082,
[36m(head, rank=0, pid=3442)[0m     3.6743619441986084,
[36m(head, rank=0, pid=3442)[0m     4.45955228805542,
[36m(head, rank=0, pid=3442)[0m     4.161985158920288,
[36m(head, rank=0, pid=3442)[0m     4.247955799102783,
[36m(head, rank=0, pid=3442)[0m     4.272046804428101,
[36m(head, rank=0, pid=3442)[0m     3.9211502075195312,
[36m(head, rank=0, pid=3442)[0m     3.846134901046753,
[36m(head, rank=0, pid=3442)[0m     3.9617509841918945,
[36m(head, rank=0, pid=3442)[0m     5.117217302322388,
[36m(head, rank=0, pid=3442)[0m     5.240119457244873,
[36m(head, rank=0, pid=3442)[0m     3.9111766815185547,
[36m(head, rank=0, pid=3442)[0m     3.973604679107666,
[36m(head, rank=0, pid=3442)[0m     3.848815441131592,
[36m(head, rank=0, pid=3442)[0m     3.9808943271636963,
[36m(head, rank=0, pid=3442)[0m     5.108564853668213,
[36m(head, rank=0, pid=3442)[0m     3.976918935775757,
[36m(head, rank=0, pid=3442)[0m     4.7043867111206055,
[36m(head, rank=0, pid=3442)[0m     3.859144926071167,
[36m(head, rank=0, pid=3442)[0m     4.214777708053589,
[36m(head, rank=0, pid=3442)[0m     4.335997819900513,
[36m(head, rank=0, pid=3442)[0m     4.197707414627075,
[36m(head, rank=0, pid=3442)[0m     4.699139356613159,
[36m(head, rank=0, pid=3442)[0m     4.733209848403931,
[36m(head, rank=0, pid=3442)[0m     3.875058889389038,
[36m(head, rank=0, pid=3442)[0m     4.413527250289917,
[36m(head, rank=0, pid=3442)[0m     3.7091684341430664,
[36m(head, rank=0, pid=3442)[0m     7.045746326446533,
[36m(head, rank=0, pid=3442)[0m     4.452908515930176,
[36m(head, rank=0, pid=3442)[0m     4.914632558822632,
[36m(head, rank=0, pid=3442)[0m     3.8293867111206055,
[36m(head, rank=0, pid=3442)[0m     5.1887452602386475,
[36m(head, rank=0, pid=3442)[0m     5.248610973358154,
[36m(head, rank=0, pid=3442)[0m     5.231962203979492,
[36m(head, rank=0, pid=3442)[0m     3.8045904636383057,
[36m(head, rank=0, pid=3442)[0m     3.845182418823242,
[36m(head, rank=0, pid=3442)[0m     4.117551565170288,
[36m(head, rank=0, pid=3442)[0m     3.952436685562134,
[36m(head, rank=0, pid=3442)[0m     3.9411752223968506,
[36m(head, rank=0, pid=3442)[0m     3.9523069858551025,
[36m(head, rank=0, pid=3442)[0m     4.312820672988892,
[36m(head, rank=0, pid=3442)[0m     4.741469383239746,
[36m(head, rank=0, pid=3442)[0m     4.389430046081543,
[36m(head, rank=0, pid=3442)[0m     4.009045362472534,
[36m(head, rank=0, pid=3442)[0m     4.859507083892822,
[36m(head, rank=0, pid=3442)[0m     3.9462063312530518,
[36m(head, rank=0, pid=3442)[0m     4.13858437538147,
[36m(head, rank=0, pid=3442)[0m     4.178035736083984,
[36m(head, rank=0, pid=3442)[0m     4.46828031539917,
[36m(head, rank=0, pid=3442)[0m     4.19342827796936,
[36m(head, rank=0, pid=3442)[0m     4.743472576141357,
[36m(head, rank=0, pid=3442)[0m     3.891422986984253,
[36m(head, rank=0, pid=3442)[0m     3.99025821685791,
[36m(head, rank=0, pid=3442)[0m     5.107449531555176,
[36m(head, rank=0, pid=3442)[0m     3.939835548400879,
[36m(head, rank=0, pid=3442)[0m     4.164681673049927,
[36m(head, rank=0, pid=3442)[0m     3.873439073562622,
[36m(head, rank=0, pid=3442)[0m     4.096798419952393,
[36m(head, rank=0, pid=3442)[0m     3.8691444396972656,
[36m(head, rank=0, pid=3442)[0m     3.7700657844543457,
[36m(head, rank=0, pid=3442)[0m     3.892025947570801,
[36m(head, rank=0, pid=3442)[0m     3.914344072341919,
[36m(head, rank=0, pid=3442)[0m     4.952620983123779,
[36m(head, rank=0, pid=3442)[0m     3.8505430221557617,
[36m(head, rank=0, pid=3442)[0m     4.492830753326416,
[36m(head, rank=0, pid=3442)[0m     8.574343919754028,
[36m(head, rank=0, pid=3442)[0m     4.109266519546509,
[36m(head, rank=0, pid=3442)[0m     4.072402238845825,
[36m(head, rank=0, pid=3442)[0m     4.063337802886963,
[36m(head, rank=0, pid=3442)[0m     4.035444736480713,
[36m(head, rank=0, pid=3442)[0m     3.9289329051971436,
[36m(head, rank=0, pid=3442)[0m     3.960615873336792,
[36m(head, rank=0, pid=3442)[0m     5.089396238327026,
[36m(head, rank=0, pid=3442)[0m     3.9841408729553223,
[36m(head, rank=0, pid=3442)[0m     4.192255020141602,
[36m(head, rank=0, pid=3442)[0m     3.958606481552124,
[36m(head, rank=0, pid=3442)[0m     3.9691433906555176,
[36m(head, rank=0, pid=3442)[0m     5.236887216567993,
[36m(head, rank=0, pid=3442)[0m     4.273489952087402,
[36m(head, rank=0, pid=3442)[0m     4.94099760055542,
[36m(head, rank=0, pid=3442)[0m     5.1874308586120605,
[36m(head, rank=0, pid=3442)[0m     4.841870307922363,
[36m(head, rank=0, pid=3442)[0m     4.781341314315796,
[36m(head, rank=0, pid=3442)[0m     4.004480838775635,
[36m(head, rank=0, pid=3442)[0m     4.7973573207855225,
[36m(head, rank=0, pid=3442)[0m     4.373647928237915,
[36m(head, rank=0, pid=3442)[0m     4.146348476409912,
[36m(head, rank=0, pid=3442)[0m     4.35509467124939,
[36m(head, rank=0, pid=3442)[0m     3.922814130783081,
[36m(head, rank=0, pid=3442)[0m     4.726800918579102,
[36m(head, rank=0, pid=3442)[0m     3.9515883922576904,
[36m(head, rank=0, pid=3442)[0m     4.0578696727752686,
[36m(head, rank=0, pid=3442)[0m     3.6943817138671875,
[36m(head, rank=0, pid=3442)[0m     3.9321436882019043,
[36m(head, rank=0, pid=3442)[0m     4.25642204284668,
[36m(head, rank=0, pid=3442)[0m     3.9635050296783447,
[36m(head, rank=0, pid=3442)[0m     3.821711540222168,
[36m(head, rank=0, pid=3442)[0m     4.030169486999512,
[36m(head, rank=0, pid=3442)[0m     4.161214351654053,
[36m(head, rank=0, pid=3442)[0m     4.112074613571167,
[36m(head, rank=0, pid=3442)[0m     4.5591881275177,
[36m(head, rank=0, pid=3442)[0m     4.999413967132568,
[36m(head, rank=0, pid=3442)[0m     4.390312433242798
[36m(head, rank=0, pid=3442)[0m   ]
[36m(head, rank=0, pid=3442)[0m }
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m --- All Training Runs Summary ---
[36m(head, rank=0, pid=3442)[0m [
[36m(head, rank=0, pid=3442)[0m   {
[36m(head, rank=0, pid=3442)[0m     "run_id": 1,
[36m(head, rank=0, pid=3442)[0m     "timestamp": "2025-08-04T00:28:44.103516",
[36m(head, rank=0, pid=3442)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3442)[0m     "checkpoint_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3442)[0m     "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3442)[0m     "training_status": "completed",
[36m(head, rank=0, pid=3442)[0m     "output_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3442)[0m     "dataset_load_time": 2.0864126682281494,
[36m(head, rank=0, pid=3442)[0m     "model_load_time": 21.330164194107056,
[36m(head, rank=0, pid=3442)[0m     "training_time": 2907.0133254528046,
[36m(head, rank=0, pid=3442)[0m     "total_time": 2930.4299023151398,
[36m(head, rank=0, pid=3442)[0m     "error": null,
[36m(head, rank=0, pid=3442)[0m     "num_checkpoints_saved": 5,
[36m(head, rank=0, pid=3442)[0m     "total_checkpoint_save_time": 1567.8917469978333,
[36m(head, rank=0, pid=3442)[0m     "average_checkpoint_save_time": 313.57834939956666,
[36m(head, rank=0, pid=3442)[0m     "min_checkpoint_save_time": 301.87854194641113,
[36m(head, rank=0, pid=3442)[0m     "max_checkpoint_save_time": 338.61338472366333,
[36m(head, rank=0, pid=3442)[0m     "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3442)[0m       301.87854194641113,
[36m(head, rank=0, pid=3442)[0m       309.2528467178345,
[36m(head, rank=0, pid=3442)[0m       305.99927163124084,
[36m(head, rank=0, pid=3442)[0m       338.61338472366333,
[36m(head, rank=0, pid=3442)[0m       312.1477019786835
[36m(head, rank=0, pid=3442)[0m     ],
[36m(head, rank=0, pid=3442)[0m     "num_batch_samples": 25,
[36m(head, rank=0, pid=3442)[0m     "total_batch_sample_time": 0.9569046497344971,
[36m(head, rank=0, pid=3442)[0m     "average_batch_sample_time": 0.03827618598937988,
[36m(head, rank=0, pid=3442)[0m     "min_batch_sample_time": 0.02638721466064453,
[36m(head, rank=0, pid=3442)[0m     "max_batch_sample_time": 0.12395215034484863,
[36m(head, rank=0, pid=3442)[0m     "individual_batch_sample_times": [
[36m(head, rank=0, pid=3442)[0m       0.06297540664672852,
[36m(head, rank=0, pid=3442)[0m       0.029206514358520508,
[36m(head, rank=0, pid=3442)[0m       0.03035712242126465,
[36m(head, rank=0, pid=3442)[0m       0.028657913208007812,
[36m(head, rank=0, pid=3442)[0m       0.02964043617248535,
[36m(head, rank=0, pid=3442)[0m       0.030486345291137695,
[36m(head, rank=0, pid=3442)[0m       0.03291916847229004,
[36m(head, rank=0, pid=3442)[0m       0.0316312313079834,
[36m(head, rank=0, pid=3442)[0m       0.026617050170898438,
[36m(head, rank=0, pid=3442)[0m       0.028642654418945312,
[36m(head, rank=0, pid=3442)[0m       0.03183341026306152,
[36m(head, rank=0, pid=3442)[0m       0.030431509017944336,
[36m(head, rank=0, pid=3442)[0m       0.02638721466064453,
[36m(head, rank=0, pid=3442)[0m       0.02859210968017578,
[36m(head, rank=0, pid=3442)[0m       0.029331445693969727,
[36m(head, rank=0, pid=3442)[0m       0.12395215034484863,
[36m(head, rank=0, pid=3442)[0m       0.035149574279785156,
[36m(head, rank=0, pid=3442)[0m       0.0334169864654541,
[36m(head, rank=0, pid=3442)[0m       0.0325016975402832,
[36m(head, rank=0, pid=3442)[0m       0.028483152389526367,
[36m(head, rank=0, pid=3442)[0m       0.07806658744812012,
[36m(head, rank=0, pid=3442)[0m       0.04226064682006836,
[36m(head, rank=0, pid=3442)[0m       0.03759169578552246,
[36m(head, rank=0, pid=3442)[0m       0.03681778907775879,
[36m(head, rank=0, pid=3442)[0m       0.030954837799072266
[36m(head, rank=0, pid=3442)[0m     ],
[36m(head, rank=0, pid=3442)[0m     "num_training_steps": 200,
[36m(head, rank=0, pid=3442)[0m     "total_training_step_time": 888.599869966507,
[36m(head, rank=0, pid=3442)[0m     "average_training_step_time": 4.442999349832535,
[36m(head, rank=0, pid=3442)[0m     "min_training_step_time": 3.6595282554626465,
[36m(head, rank=0, pid=3442)[0m     "max_training_step_time": 8.996733903884888,
[36m(head, rank=0, pid=3442)[0m     "individual_training_step_times": [
[36m(head, rank=0, pid=3442)[0m       8.996733903884888,
[36m(head, rank=0, pid=3442)[0m       4.814598083496094,
[36m(head, rank=0, pid=3442)[0m       5.332859754562378,
[36m(head, rank=0, pid=3442)[0m       4.2270896434783936,
[36m(head, rank=0, pid=3442)[0m       5.265184164047241,
[36m(head, rank=0, pid=3442)[0m       4.00435471534729,
[36m(head, rank=0, pid=3442)[0m       4.1070237159729,
[36m(head, rank=0, pid=3442)[0m       4.266810417175293,
[36m(head, rank=0, pid=3442)[0m       4.25379490852356,
[36m(head, rank=0, pid=3442)[0m       5.097965955734253,
[36m(head, rank=0, pid=3442)[0m       4.169838190078735,
[36m(head, rank=0, pid=3442)[0m       4.121963739395142,
[36m(head, rank=0, pid=3442)[0m       4.100440740585327,
[36m(head, rank=0, pid=3442)[0m       5.378668546676636,
[36m(head, rank=0, pid=3442)[0m       4.142361879348755,
[36m(head, rank=0, pid=3442)[0m       4.750032901763916,
[36m(head, rank=0, pid=3442)[0m       4.835744857788086,
[36m(head, rank=0, pid=3442)[0m       6.273422718048096,
[36m(head, rank=0, pid=3442)[0m       4.018996715545654,
[36m(head, rank=0, pid=3442)[0m       4.105278730392456,
[36m(head, rank=0, pid=3442)[0m       4.711097478866577,
[36m(head, rank=0, pid=3442)[0m       4.11498236656189,
[36m(head, rank=0, pid=3442)[0m       5.132357120513916,
[36m(head, rank=0, pid=3442)[0m       4.145087242126465,
[36m(head, rank=0, pid=3442)[0m       5.5218000411987305,
[36m(head, rank=0, pid=3442)[0m       4.392833948135376,
[36m(head, rank=0, pid=3442)[0m       4.2984089851379395,
[36m(head, rank=0, pid=3442)[0m       4.125567674636841,
[36m(head, rank=0, pid=3442)[0m       4.021824359893799,
[36m(head, rank=0, pid=3442)[0m       4.118624210357666,
[36m(head, rank=0, pid=3442)[0m       4.266567230224609,
[36m(head, rank=0, pid=3442)[0m       4.775826930999756,
[36m(head, rank=0, pid=3442)[0m       5.323858022689819,
[36m(head, rank=0, pid=3442)[0m       4.318108081817627,
[36m(head, rank=0, pid=3442)[0m       4.512164354324341,
[36m(head, rank=0, pid=3442)[0m       4.500317096710205,
[36m(head, rank=0, pid=3442)[0m       4.798299074172974,
[36m(head, rank=0, pid=3442)[0m       4.593712568283081,
[36m(head, rank=0, pid=3442)[0m       3.6595282554626465,
[36m(head, rank=0, pid=3442)[0m       4.137315511703491,
[36m(head, rank=0, pid=3442)[0m       3.919907808303833,
[36m(head, rank=0, pid=3442)[0m       4.0234222412109375,
[36m(head, rank=0, pid=3442)[0m       8.043860673904419,
[36m(head, rank=0, pid=3442)[0m       4.344482183456421,
[36m(head, rank=0, pid=3442)[0m       4.345244407653809,
[36m(head, rank=0, pid=3442)[0m       4.166297912597656,
[36m(head, rank=0, pid=3442)[0m       3.9689698219299316,
[36m(head, rank=0, pid=3442)[0m       4.213576316833496,
[36m(head, rank=0, pid=3442)[0m       5.144278526306152,
[36m(head, rank=0, pid=3442)[0m       5.0931854248046875,
[36m(head, rank=0, pid=3442)[0m       4.35783839225769,
[36m(head, rank=0, pid=3442)[0m       4.0861358642578125,
[36m(head, rank=0, pid=3442)[0m       4.7836244106292725,
[36m(head, rank=0, pid=3442)[0m       4.2863171100616455,
[36m(head, rank=0, pid=3442)[0m       4.681871652603149,
[36m(head, rank=0, pid=3442)[0m       3.9518015384674072,
[36m(head, rank=0, pid=3442)[0m       5.369300603866577,
[36m(head, rank=0, pid=3442)[0m       4.466315984725952,
[36m(head, rank=0, pid=3442)[0m       4.2587974071502686,
[36m(head, rank=0, pid=3442)[0m       4.599525690078735,
[36m(head, rank=0, pid=3442)[0m       4.114660739898682,
[36m(head, rank=0, pid=3442)[0m       4.22622013092041,
[36m(head, rank=0, pid=3442)[0m       4.117686033248901,
[36m(head, rank=0, pid=3442)[0m       4.841781139373779,
[36m(head, rank=0, pid=3442)[0m       4.009570121765137,
[36m(head, rank=0, pid=3442)[0m       3.9825050830841064,
[36m(head, rank=0, pid=3442)[0m       4.08527135848999,
[36m(head, rank=0, pid=3442)[0m       3.884977102279663,
[36m(head, rank=0, pid=3442)[0m       4.558824300765991,
[36m(head, rank=0, pid=3442)[0m       5.380278825759888,
[36m(head, rank=0, pid=3442)[0m       4.214171409606934,
[36m(head, rank=0, pid=3442)[0m       4.590816497802734,
[36m(head, rank=0, pid=3442)[0m       3.852241277694702,
[36m(head, rank=0, pid=3442)[0m       4.472700595855713,
[36m(head, rank=0, pid=3442)[0m       4.128572225570679,
[36m(head, rank=0, pid=3442)[0m       4.150026798248291,
[36m(head, rank=0, pid=3442)[0m       4.429317951202393,
[36m(head, rank=0, pid=3442)[0m       4.094755411148071,
[36m(head, rank=0, pid=3442)[0m       3.662590742111206,
[36m(head, rank=0, pid=3442)[0m       4.124629259109497,
[36m(head, rank=0, pid=3442)[0m       4.235240459442139,
[36m(head, rank=0, pid=3442)[0m       5.0663628578186035,
[36m(head, rank=0, pid=3442)[0m       4.007302761077881,
[36m(head, rank=0, pid=3442)[0m       4.303620100021362,
[36m(head, rank=0, pid=3442)[0m       3.856496572494507,
[36m(head, rank=0, pid=3442)[0m       3.7767982482910156,
[36m(head, rank=0, pid=3442)[0m       4.53976035118103,
[36m(head, rank=0, pid=3442)[0m       3.9866905212402344,
[36m(head, rank=0, pid=3442)[0m       7.248344659805298,
[36m(head, rank=0, pid=3442)[0m       5.407552480697632,
[36m(head, rank=0, pid=3442)[0m       5.0786402225494385,
[36m(head, rank=0, pid=3442)[0m       4.439354181289673,
[36m(head, rank=0, pid=3442)[0m       5.042923450469971,
[36m(head, rank=0, pid=3442)[0m       3.970787525177002,
[36m(head, rank=0, pid=3442)[0m       4.226814270019531,
[36m(head, rank=0, pid=3442)[0m       4.122639894485474,
[36m(head, rank=0, pid=3442)[0m       4.105255365371704,
[36m(head, rank=0, pid=3442)[0m       5.215703010559082,
[36m(head, rank=0, pid=3442)[0m       3.6743619441986084,
[36m(head, rank=0, pid=3442)[0m       4.45955228805542,
[36m(head, rank=0, pid=3442)[0m       4.161985158920288,
[36m(head, rank=0, pid=3442)[0m       4.247955799102783,
[36m(head, rank=0, pid=3442)[0m       4.272046804428101,
[36m(head, rank=0, pid=3442)[0m       3.9211502075195312,
[36m(head, rank=0, pid=3442)[0m       3.846134901046753,
[36m(head, rank=0, pid=3442)[0m       3.9617509841918945,
[36m(head, rank=0, pid=3442)[0m       5.117217302322388,
[36m(head, rank=0, pid=3442)[0m       5.240119457244873,
[36m(head, rank=0, pid=3442)[0m       3.9111766815185547,
[36m(head, rank=0, pid=3442)[0m       3.973604679107666,
[36m(head, rank=0, pid=3442)[0m       3.848815441131592,
[36m(head, rank=0, pid=3442)[0m       3.9808943271636963,
[36m(head, rank=0, pid=3442)[0m       5.108564853668213,
[36m(head, rank=0, pid=3442)[0m       3.976918935775757,
[36m(head, rank=0, pid=3442)[0m       4.7043867111206055,
[36m(head, rank=0, pid=3442)[0m       3.859144926071167,
[36m(head, rank=0, pid=3442)[0m       4.214777708053589,
[36m(head, rank=0, pid=3442)[0m       4.335997819900513,
[36m(head, rank=0, pid=3442)[0m       4.197707414627075,
[36m(head, rank=0, pid=3442)[0m       4.699139356613159,
[36m(head, rank=0, pid=3442)[0m       4.733209848403931,
[36m(head, rank=0, pid=3442)[0m       3.875058889389038,
[36m(head, rank=0, pid=3442)[0m       4.413527250289917,
[36m(head, rank=0, pid=3442)[0m       3.7091684341430664,
[36m(head, rank=0, pid=3442)[0m       7.045746326446533,
[36m(head, rank=0, pid=3442)[0m       4.452908515930176,
[36m(head, rank=0, pid=3442)[0m       4.914632558822632,
[36m(head, rank=0, pid=3442)[0m       3.8293867111206055,
[36m(head, rank=0, pid=3442)[0m       5.1887452602386475,
[36m(head, rank=0, pid=3442)[0m       5.248610973358154,
[36m(head, rank=0, pid=3442)[0m       5.231962203979492,
[36m(head, rank=0, pid=3442)[0m       3.8045904636383057,
[36m(head, rank=0, pid=3442)[0m       3.845182418823242,
[36m(head, rank=0, pid=3442)[0m       4.117551565170288,
[36m(head, rank=0, pid=3442)[0m       3.952436685562134,
[36m(head, rank=0, pid=3442)[0m       3.9411752223968506,
[36m(head, rank=0, pid=3442)[0m       3.9523069858551025,
[36m(head, rank=0, pid=3442)[0m       4.312820672988892,
[36m(head, rank=0, pid=3442)[0m       4.741469383239746,
[36m(head, rank=0, pid=3442)[0m       4.389430046081543,
[36m(head, rank=0, pid=3442)[0m       4.009045362472534,
[36m(head, rank=0, pid=3442)[0m       4.859507083892822,
[36m(head, rank=0, pid=3442)[0m       3.9462063312530518,
[36m(head, rank=0, pid=3442)[0m       4.13858437538147,
[36m(head, rank=0, pid=3442)[0m       4.178035736083984,
[36m(head, rank=0, pid=3442)[0m       4.46828031539917,
[36m(head, rank=0, pid=3442)[0m       4.19342827796936,
[36m(head, rank=0, pid=3442)[0m       4.743472576141357,
[36m(head, rank=0, pid=3442)[0m       3.891422986984253,
[36m(head, rank=0, pid=3442)[0m       3.99025821685791,
[36m(head, rank=0, pid=3442)[0m       5.107449531555176,
[36m(head, rank=0, pid=3442)[0m       3.939835548400879,
[36m(head, rank=0, pid=3442)[0m       4.164681673049927,
[36m(head, rank=0, pid=3442)[0m       3.873439073562622,
[36m(head, rank=0, pid=3442)[0m       4.096798419952393,
[36m(head, rank=0, pid=3442)[0m       3.8691444396972656,
[36m(head, rank=0, pid=3442)[0m       3.7700657844543457,
[36m(head, rank=0, pid=3442)[0m       3.892025947570801,
[36m(head, rank=0, pid=3442)[0m       3.914344072341919,
[36m(head, rank=0, pid=3442)[0m       4.952620983123779,
[36m(head, rank=0, pid=3442)[0m       3.8505430221557617,
[36m(head, rank=0, pid=3442)[0m       4.492830753326416,
[36m(head, rank=0, pid=3442)[0m       8.574343919754028,
[36m(head, rank=0, pid=3442)[0m       4.109266519546509,
[36m(head, rank=0, pid=3442)[0m       4.072402238845825,
[36m(head, rank=0, pid=3442)[0m       4.063337802886963,
[36m(head, rank=0, pid=3442)[0m       4.035444736480713,
[36m(head, rank=0, pid=3442)[0m       3.9289329051971436,
[36m(head, rank=0, pid=3442)[0m       3.960615873336792,
[36m(head, rank=0, pid=3442)[0m       5.089396238327026,
[36m(head, rank=0, pid=3442)[0m       3.9841408729553223,
[36m(head, rank=0, pid=3442)[0m       4.192255020141602,
[36m(head, rank=0, pid=3442)[0m       3.958606481552124,
[36m(head, rank=0, pid=3442)[0m       3.9691433906555176,
[36m(head, rank=0, pid=3442)[0m       5.236887216567993,
[36m(head, rank=0, pid=3442)[0m       4.273489952087402,
[36m(head, rank=0, pid=3442)[0m       4.94099760055542,
[36m(head, rank=0, pid=3442)[0m       5.1874308586120605,
[36m(head, rank=0, pid=3442)[0m       4.841870307922363,
[36m(head, rank=0, pid=3442)[0m       4.781341314315796,
[36m(head, rank=0, pid=3442)[0m       4.004480838775635,
[36m(head, rank=0, pid=3442)[0m       4.7973573207855225,
[36m(head, rank=0, pid=3442)[0m       4.373647928237915,
[36m(head, rank=0, pid=3442)[0m       4.146348476409912,
[36m(head, rank=0, pid=3442)[0m       4.35509467124939,
[36m(head, rank=0, pid=3442)[0m       3.922814130783081,
[36m(head, rank=0, pid=3442)[0m       4.726800918579102,
[36m(head, rank=0, pid=3442)[0m       3.9515883922576904,
[36m(head, rank=0, pid=3442)[0m       4.0578696727752686,
[36m(head, rank=0, pid=3442)[0m       3.6943817138671875,
[36m(head, rank=0, pid=3442)[0m       3.9321436882019043,
[36m(head, rank=0, pid=3442)[0m       4.25642204284668,
[36m(head, rank=0, pid=3442)[0m       3.9635050296783447,
[36m(head, rank=0, pid=3442)[0m       3.821711540222168,
[36m(head, rank=0, pid=3442)[0m       4.030169486999512,
[36m(head, rank=0, pid=3442)[0m       4.161214351654053,
[36m(head, rank=0, pid=3442)[0m       4.112074613571167,
[36m(head, rank=0, pid=3442)[0m       4.5591881275177,
[36m(head, rank=0, pid=3442)[0m       4.999413967132568,
[36m(head, rank=0, pid=3442)[0m       4.390312433242798
[36m(head, rank=0, pid=3442)[0m     ]
[36m(head, rank=0, pid=3442)[0m   }
[36m(head, rank=0, pid=3442)[0m ]
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m --- Timing Summary ---
[36m(head, rank=0, pid=3442)[0m {
[36m(head, rank=0, pid=3442)[0m   "total_runs": 1,
[36m(head, rank=0, pid=3442)[0m   "dataset_loading": {
[36m(head, rank=0, pid=3442)[0m     "dataset_load_count": 1,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_average": 2.0864126682281494,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_min": 2.0864126682281494,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_max": 2.0864126682281494,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_total": 2.0864126682281494
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "model_loading": {
[36m(head, rank=0, pid=3442)[0m     "model_load_count": 1,
[36m(head, rank=0, pid=3442)[0m     "model_load_average": 21.330164194107056,
[36m(head, rank=0, pid=3442)[0m     "model_load_min": 21.330164194107056,
[36m(head, rank=0, pid=3442)[0m     "model_load_max": 21.330164194107056,
[36m(head, rank=0, pid=3442)[0m     "model_load_total": 21.330164194107056
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "training": {
[36m(head, rank=0, pid=3442)[0m     "training_count": 1,
[36m(head, rank=0, pid=3442)[0m     "training_average": 2907.0133254528046,
[36m(head, rank=0, pid=3442)[0m     "training_min": 2907.0133254528046,
[36m(head, rank=0, pid=3442)[0m     "training_max": 2907.0133254528046,
[36m(head, rank=0, pid=3442)[0m     "training_total": 2907.0133254528046
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "total_run_time": {
[36m(head, rank=0, pid=3442)[0m     "total_count": 1,
[36m(head, rank=0, pid=3442)[0m     "total_average": 2930.4299023151398,
[36m(head, rank=0, pid=3442)[0m     "total_min": 2930.4299023151398,
[36m(head, rank=0, pid=3442)[0m     "total_max": 2930.4299023151398,
[36m(head, rank=0, pid=3442)[0m     "total_total": 2930.4299023151398
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "checkpoint_saving": {
[36m(head, rank=0, pid=3442)[0m     "total_checkpoints_saved": 5,
[36m(head, rank=0, pid=3442)[0m     "total_checkpoint_save_time": 1567.8917469978333,
[36m(head, rank=0, pid=3442)[0m     "average_save_time_per_checkpoint": 313.57834939956666,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_times_count": 5,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_min": 301.87854194641113,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_max": 338.61338472366333,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_average": 313.57834939956666
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "batch_sampling": {
[36m(head, rank=0, pid=3442)[0m     "total_batch_samples": 25,
[36m(head, rank=0, pid=3442)[0m     "total_batch_sample_time": 0.9569046497344971,
[36m(head, rank=0, pid=3442)[0m     "average_sample_time_per_batch": 0.03827618598937988,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_times_count": 25,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_min": 0.02638721466064453,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_max": 0.12395215034484863,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_average": 0.03827618598937988
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "training_steps": {
[36m(head, rank=0, pid=3442)[0m     "total_training_steps": 200,
[36m(head, rank=0, pid=3442)[0m     "total_training_step_time": 888.599869966507,
[36m(head, rank=0, pid=3442)[0m     "average_step_time_per_step": 4.442999349832535,
[36m(head, rank=0, pid=3442)[0m     "training_step_times_count": 200,
[36m(head, rank=0, pid=3442)[0m     "training_step_min": 3.6595282554626465,
[36m(head, rank=0, pid=3442)[0m     "training_step_max": 8.996733903884888,
[36m(head, rank=0, pid=3442)[0m     "training_step_average": 4.442999349832535
[36m(head, rank=0, pid=3442)[0m   }
[36m(head, rank=0, pid=3442)[0m }
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.05s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.05s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.05s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.05s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 0.92s
[36m(head, rank=0, pid=3442)[0m   • Min time: 0.92s
[36m(head, rank=0, pid=3442)[0m   • Max time: 0.92s
[36m(head, rank=0, pid=3442)[0m   • Total time: 0.92s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2926.81s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2926.81s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2926.81s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2926.81s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 6.53s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.66s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 118.10s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1305.62s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 5.70s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 47.29s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 142.48s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 175.53s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 170.34s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 181.63s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 877.65s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 2929.79s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 2929.79s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 2929.79s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 2929.79s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.33s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.33s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.33s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.33s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.05s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.05s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.05s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.05s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2926.67s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2926.67s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2926.67s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2926.67s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 6.53s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.54s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 118.10s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1306.73s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 5.70s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 47.28s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 142.52s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 175.53s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 170.34s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 181.63s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 877.65s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 2930.05s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 2930.05s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 2930.05s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 2930.05s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.16s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.16s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.16s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.16s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2926.80s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2926.80s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2926.80s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2926.80s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 6.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 118.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1305.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 47.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 142.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 170.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 877.65s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 2929.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 2929.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 2929.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 2929.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_4.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.12s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.12s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.12s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.12s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2926.82s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2926.82s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2926.82s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2926.82s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 6.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 118.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1307.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 47.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 142.49s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 170.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 877.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 2930.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 2930.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 2930.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 2930.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.36s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.36s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.36s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.36s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2926.76s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2926.76s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2926.76s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2926.76s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 6.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 118.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1305.67s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 47.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 142.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 170.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 877.65s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 2930.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 2930.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 2930.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 2930.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 0.99s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 0.99s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 0.99s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 0.99s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2926.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2926.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2926.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2926.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 6.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.58s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 118.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1307.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 47.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 142.48s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 170.34s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 877.65s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 2929.92s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 2929.92s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 2929.92s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 2929.92s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.13s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.13s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.13s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.13s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2926.82s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2926.82s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2926.82s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2926.82s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 6.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.62s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 118.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1307.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 47.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 142.49s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 170.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 877.65s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 2929.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 2929.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 2929.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 2929.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 0.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 0.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 0.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 0.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2926.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2926.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2926.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2926.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 6.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 118.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1307.43s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 47.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 142.48s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 170.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 877.65s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 2929.92s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 2929.92s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 2929.92s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 2929.92s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 0.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 0.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 0.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 0.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2926.77s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2926.77s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2926.77s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2926.77s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 6.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.62s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 117.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1307.12s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 5.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 47.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 142.50s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 175.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 170.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 181.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 877.65s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 2930.13s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 2930.13s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 2930.13s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 2930.13s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_5.json
[36m(head, rank=0, pid=3442)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3442)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: 'pytorch_model-00001-of-00012.bin'
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.28 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.29 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.31 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.33 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.38 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.41 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.47 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 1.99 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.47 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.01 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.04 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.05 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.11 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.25 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.31 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.86 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 62.25it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 64.02it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3442)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 59.66it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 0.97 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 0.96 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 69.74it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 65.20it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 68.00it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.05 seconds
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 67.52it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 62.18it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 53.94it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 62.24it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 0.94 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 0.99 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.08 seconds
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 61.47it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 1.00 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 0.99 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.00 seconds
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 62.46it/s]
[36m(head, rank=0, pid=3442)[0m Completed Load model in 0.98 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.07 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 60.16it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 0.97 seconds
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 63.90it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 0.94 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.10 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:21,  5.42s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.91s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:10<00:15,  5.09s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:11<00:16,  5.52s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:15<00:09,  4.99s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:16<00:10,  5.34s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:19<00:04,  4.92s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:24<00:00,  4.75s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:24<00:00,  4.88s/it]
[36m(head, rank=0, pid=3442)[0m Completed Load model in 25.26 seconds
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:21<00:05,  5.24s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:25<00:00,  5.00s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:25<00:00,  5.19s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 26.93 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:51,661] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:52,901] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:53,028] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:53,028] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:53,030] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:53,031] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:53,033] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:53,033] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:53,036] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:53,467] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:53,469] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:53,470] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:53,470] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:53,486] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:53,491] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:53,505] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:53,507] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:54,273] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:54,282] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:54,288] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:54,298] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:54,299] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:54,362] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 01:18:54,367] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:54,662] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:54,669] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:54,671] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:54,675] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:54,720] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:54,746] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:54,757] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 01:18:54,785] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   0%|          | 0/25 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3442)[0m   4%|▍         | 1/25 [00:39<15:39, 39.13s/it]
[36m(head, rank=0, pid=3442)[0m   8%|▊         | 2/25 [01:15<14:20, 37.41s/it]
[36m(head, rank=0, pid=3442)[0m  12%|█▏        | 3/25 [01:50<13:23, 36.50s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  16%|█▌        | 4/25 [02:26<12:39, 36.18s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  20%|██        | 5/25 [03:03<12:08, 36.44s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 364.94 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 364.94s (Total: 364.94s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 364.94 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 364.94s (Total: 364.94s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 364.94 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 364.94s (Total: 364.94s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 364.94 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 364.94s (Total: 364.94s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 364.95 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 364.95s (Total: 364.95s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 364.95 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 364.95s (Total: 364.95s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 364.93 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 364.93s (Total: 364.93s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 364.94 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 364.94s (Total: 364.94s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 364.94 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 364.94s (Total: 364.94s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 364.95 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 364.95s (Total: 364.95s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 364.95 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 364.95s (Total: 364.95s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 364.95 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 364.95s (Total: 364.95s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 364.95 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 364.95s (Total: 364.95s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 364.95 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 364.95s (Total: 364.95s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 364.95 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 364.95s (Total: 364.95s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 675.28 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 675.28s (Total: 675.28s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  24%|██▍       | 6/25 [14:55<1:24:15, 266.08s/it]
[36m(head, rank=0, pid=3442)[0m  28%|██▊       | 7/25 [15:31<57:17, 190.99s/it]  
[36m(head, rank=0, pid=3442)[0m  32%|███▏      | 8/25 [16:07<40:10, 141.78s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  36%|███▌      | 9/25 [16:43<28:56, 108.54s/it] 40%|████      | 10/25 [17:17<21:22, 85.51s/it]Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m                                                {'loss': 125.3922, 'grad_norm': 49.56791305541992, 'learning_rate': 1.2800000000000001e-05, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3442)[0m  40%|████      | 10/25 [17:17<21:22, 85.51s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 359.73 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 359.73s (Total: 724.66s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 359.73 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 359.73s (Total: 724.67s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 359.73 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 359.73s (Total: 724.68s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 359.73 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 359.73s (Total: 724.67s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 359.73 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 359.73s (Total: 724.68s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 359.74 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 359.74s (Total: 724.68s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 359.74 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 359.74s (Total: 724.67s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 359.73 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 359.73s (Total: 724.68s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 359.73 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 359.73s (Total: 724.67s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 359.73 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 359.73s (Total: 724.67s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 359.73 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 359.73s (Total: 724.68s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 359.73 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 359.73s (Total: 724.68s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 359.74 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 359.74s (Total: 724.69s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 359.74 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 359.74s (Total: 724.69s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 359.74 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 359.74s (Total: 724.70s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 647.95 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 647.95s (Total: 1323.23s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  44%|████▍     | 11/25 [28:43<1:02:50, 269.33s/it]
[36m(head, rank=0, pid=3442)[0m  48%|████▊     | 12/25 [29:21<43:05, 198.91s/it]  
[36m(head, rank=0, pid=3442)[0m  52%|█████▏    | 13/25 [29:56<29:51, 149.32s/it]
[36m(head, rank=0, pid=3442)[0m  56%|█████▌    | 14/25 [30:32<21:04, 114.99s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  60%|██████    | 15/25 [31:08<15:13, 91.31s/it] Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 350.08 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 350.08s (Total: 1074.76s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 350.09 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 350.09s (Total: 1074.77s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 350.09 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 350.09s (Total: 1074.76s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 350.09 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 350.09s (Total: 1074.78s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 350.09 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 350.09s (Total: 1074.77s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 350.09 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 350.09s (Total: 1074.78s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 350.09 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 350.09s (Total: 1074.77s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 350.10 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 350.10s (Total: 1074.79s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 350.08 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 350.08s (Total: 1074.74s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 350.08 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 350.08s (Total: 1074.76s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 350.09 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 350.09s (Total: 1074.77s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 350.09 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 350.09s (Total: 1074.76s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 350.09 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 350.09s (Total: 1074.77s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 350.09 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 350.09s (Total: 1074.77s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 350.10 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 350.10s (Total: 1074.78s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 641.79 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 641.79s (Total: 1965.02s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  64%|██████▍   | 16/25 [42:30<40:22, 269.15s/it]
[36m(head, rank=0, pid=3442)[0m  68%|██████▊   | 17/25 [43:07<26:33, 199.23s/it]
[36m(head, rank=0, pid=3442)[0m  72%|███████▏  | 18/25 [43:43<17:32, 150.31s/it]
[36m(head, rank=0, pid=3442)[0m  76%|███████▌  | 19/25 [44:19<11:35, 115.89s/it] 80%|████████  | 20/25 [44:53<07:36, 91.39s/it] Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m                                                {'loss': 94.3979, 'grad_norm': 22.57253646850586, 'learning_rate': 4.800000000000001e-06, 'num_tokens': 19076177.0, 'epoch': 0.05}
[36m(head, rank=0, pid=3442)[0m  80%|████████  | 20/25 [44:53<07:36, 91.39s/it]Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 373.21 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 373.21s (Total: 1447.97s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 373.21 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 373.21s (Total: 1447.98s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 373.21 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 373.21s (Total: 1447.98s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 373.22 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 373.22s (Total: 1447.99s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 373.22 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 373.22s (Total: 1448.00s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 373.22 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 373.22s (Total: 1448.00s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 373.22 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 373.22s (Total: 1448.02s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 373.23 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 373.23s (Total: 1447.99s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 373.21 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 373.21s (Total: 1447.99s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 373.21 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 373.21s (Total: 1447.95s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 373.21 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 373.21s (Total: 1447.98s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 373.22 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 373.22s (Total: 1447.97s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 373.22 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 373.22s (Total: 1447.98s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 373.22 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 373.22s (Total: 1447.99s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 373.22 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 373.22s (Total: 1447.99s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 676.70 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 676.70s (Total: 2641.72s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  84%|████████▍ | 21/25 [56:47<18:32, 278.13s/it]
[36m(head, rank=0, pid=3442)[0m  88%|████████▊ | 22/25 [57:23<10:16, 205.48s/it]
[36m(head, rank=0, pid=3442)[0m  92%|█████████▏| 23/25 [58:02<05:11, 155.58s/it]
[36m(head, rank=0, pid=3442)[0m  96%|█████████▌| 24/25 [58:37<01:59, 119.35s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m 100%|██████████| 25/25 [59:13<00:00, 94.23s/it] Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 366.54 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 366.54s (Total: 1814.54s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 366.54 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 366.54s (Total: 1814.53s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 366.54 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 366.54s (Total: 1814.52s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 366.55 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 366.55s (Total: 1814.54s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 366.55 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 366.55s (Total: 1814.52s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 366.54 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 366.54s (Total: 1814.53s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 366.53 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 366.53s (Total: 1814.51s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 366.54 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 366.54s (Total: 1814.53s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 366.54 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 366.54s (Total: 1814.49s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 366.54 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 366.54s (Total: 1814.52s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 366.54 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 366.54s (Total: 1814.54s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 366.55 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 366.55s (Total: 1814.53s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 366.55 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 366.55s (Total: 1814.56s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 366.55 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 366.55s (Total: 1814.54s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 366.55 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 366.55s (Total: 1814.54s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 4282.96 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 4283.00 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1814.56s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 362.91s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 350.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 373.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 126.48s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.06s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 31.62s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1878.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 9.39s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 282.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1814.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 362.91s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 350.09s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 373.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 126.79s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 31.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1878.93s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 9.39s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 282.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 4282.99 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 4283.11 secondsCompleted Training in 4257.74 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1814.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 362.91s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 350.09s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 373.23s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 126.74s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 31.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1879.95s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 9.40s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 282.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1814.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 362.91s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 350.09s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 373.21s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 126.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 31.64s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1878.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 9.39s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 282.88s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1814.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 362.91s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 350.09s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 373.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 126.79s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 31.62s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1879.71s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 9.40s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 282.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 4283.06 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 4282.96 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1814.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 362.90s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 350.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 373.21s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 126.74s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 31.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1880.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 9.40s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 282.84s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1814.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 362.90s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 350.09s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 373.21s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 126.68s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 31.64s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1878.58s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 9.39s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 282.95s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 4283.08 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1814.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 362.91s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 350.09s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 373.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 126.79s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 5.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 31.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1879.90s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 9.40s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 282.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /mnt/data/training_run_7_1_info.jsonSaved training info to: /mnt/data/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /mnt/data/training_run_6_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /mnt/data/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /mnt/data/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /mnt/data/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /mnt/data/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /mnt/data/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 665.43 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 665.43s (Total: 3307.15s)
[36m(head, rank=0, pid=3442)[0m                                                {'train_runtime': 4218.5153, 'train_samples_per_second': 0.759, 'train_steps_per_second': 0.006, 'train_loss': 106.388515625, 'num_tokens': 23880036.0, 'epoch': 0.07}
[36m(head, rank=0, pid=3442)[0m 100%|██████████| 25/25 [1:10:18<00:00, 94.23s/it]100%|██████████| 25/25 [1:10:18<00:00, 168.74s/it]
[36m(head, rank=0, pid=3442)[0m Completed Training in 4259.26 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 3307.15s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 661.43s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 641.79s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 676.70s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 1.26s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 0.29s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 809.62s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 4.05s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 7.97s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Completed Training in 4282.71 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1814.53s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 362.91s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 350.09s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 373.22s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 126.70s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 5.07s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 31.64s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1879.49s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 9.40s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 282.97s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Completed Training in 4282.62 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1814.52s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 362.90s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 350.09s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 373.22s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 126.73s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 5.07s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 31.64s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1879.28s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 9.40s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.53s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 282.96s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Completed Training in 4282.69 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1814.54s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 362.91s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 350.09s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 373.22s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 126.72s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 5.07s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 31.63s
[36m(head, rank=0, pid=3442)[0m Completed Training in 4282.63 secondsTraining Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1879.06s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 9.40s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 282.97s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1814.53s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 362.91s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 350.09s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 373.21s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 126.78s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 5.07s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 31.63s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1879.15s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 9.40s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 282.96s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Completed Training in 4282.59 seconds
[36m(head, rank=0, pid=3442)[0m Completed Training in 4282.75 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1814.53s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 362.91s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 350.10s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 373.21s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 126.68s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 5.07s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 31.63s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1879.21s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 9.40s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 282.97s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1814.49s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 362.90s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 350.08s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 373.21s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 126.74s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 5.07s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 31.64s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1878.74s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 9.39s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.53s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 282.96s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Completed Training in 4282.62 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1814.51s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 362.90s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 350.08s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 373.22s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 126.84s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 5.07s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 31.63s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1880.06s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 9.40s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.53s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 282.97s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /mnt/data/training_run_0_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /mnt/data/training_run_7_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /mnt/data/training_run_6_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /mnt/data/training_run_4_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /mnt/data/training_run_2_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /mnt/data/training_run_1_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /mnt/data/training_run_5_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /mnt/data/training_run_3_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.05s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.05s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.05s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.05s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.00s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.00s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.00s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.00s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4282.63s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4282.63s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4282.63s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4282.63s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 9.40s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 282.96s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1879.15s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 5.07s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 31.63s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 126.78s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 362.91s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 350.09s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 373.21s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1814.53s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4285.68s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4285.68s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4285.68s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4285.68s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_5.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.31s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.31s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.31s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.31s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.10s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.10s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.10s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.10s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4282.62s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4282.62s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4282.62s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4282.62s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 9.40s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.53s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 282.96s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1879.28s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 5.07s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 31.64s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 126.73s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 362.90s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 350.09s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 373.22s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1814.52s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4286.03s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4286.03s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4286.03s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4286.03s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.01s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.01s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.01s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.01s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 0.99s
[36m(head, rank=0, pid=3442)[0m   • Min time: 0.99s
[36m(head, rank=0, pid=3442)[0m   • Max time: 0.99s
[36m(head, rank=0, pid=3442)[0m   • Total time: 0.99s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4282.71s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4282.71s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4282.71s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4282.71s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 9.40s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 282.97s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1879.49s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 5.07s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 31.64s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 126.70s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 362.91s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 350.09s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 373.22s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1814.53s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4285.71s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4285.71s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4285.71s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4285.71s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.11s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.11s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.11s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.11s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 0.98s
[36m(head, rank=0, pid=3442)[0m   • Min time: 0.98s
[36m(head, rank=0, pid=3442)[0m   • Max time: 0.98s
[36m(head, rank=0, pid=3442)[0m   • Total time: 0.98s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4282.69s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4282.69s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4282.69s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4282.69s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 9.40s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.52s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 282.97s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1879.06s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 5.07s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 31.63s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 126.72s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 362.91s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 350.09s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 373.22s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1814.54s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4285.78s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4285.78s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4285.78s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4285.78s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.25s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.25s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.25s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.25s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 0.97s
[36m(head, rank=0, pid=3442)[0m   • Min time: 0.97s
[36m(head, rank=0, pid=3442)[0m   • Max time: 0.97s
[36m(head, rank=0, pid=3442)[0m   • Total time: 0.97s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4282.59s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4282.59s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4282.59s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4282.59s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 9.40s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.52s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 282.97s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1879.21s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 5.07s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.02s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 31.63s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 126.68s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 362.91s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 350.10s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 373.21s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1814.53s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4285.80s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4285.80s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4285.80s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4285.80s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.47s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.47s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.47s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.47s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 25.26s
[36m(head, rank=0, pid=3442)[0m   • Min time: 25.26s
[36m(head, rank=0, pid=3442)[0m   • Max time: 25.26s
[36m(head, rank=0, pid=3442)[0m   • Total time: 25.26s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4259.26s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4259.26s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4259.26s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4259.26s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 4.05s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.52s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 7.97s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 809.62s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 0.29s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 1.26s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 661.43s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 641.79s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 676.70s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 3307.15s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4286.99s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4286.99s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4286.99s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4286.99s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m --- Training Run 1 Info (Directory: /mnt/data/) ---
[36m(head, rank=0, pid=3442)[0m {
[36m(head, rank=0, pid=3442)[0m   "run_id": 1,
[36m(head, rank=0, pid=3442)[0m   "timestamp": "2025-08-04T01:18:20.600782",
[36m(head, rank=0, pid=3442)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3442)[0m   "checkpoint_dir": "/mnt/data",
[36m(head, rank=0, pid=3442)[0m   "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3442)[0m   "training_status": "completed",
[36m(head, rank=0, pid=3442)[0m   "output_dir": "/mnt/data",
[36m(head, rank=0, pid=3442)[0m   "dataset_load_time": 2.326582193374634,
[36m(head, rank=0, pid=3442)[0m   "model_load_time": 26.92659616470337,
[36m(head, rank=0, pid=3442)[0m   "training_time": 4257.742622852325,
[36m(head, rank=0, pid=3442)[0m   "total_time": 4286.995801210403,
[36m(head, rank=0, pid=3442)[0m   "error": null,
[36m(head, rank=0, pid=3442)[0m   "num_checkpoints_saved": 5,
[36m(head, rank=0, pid=3442)[0m   "total_checkpoint_save_time": 1814.525184392929,
[36m(head, rank=0, pid=3442)[0m   "average_checkpoint_save_time": 362.9050368785858,
[36m(head, rank=0, pid=3442)[0m   "min_checkpoint_save_time": 350.09020495414734,
[36m(head, rank=0, pid=3442)[0m   "max_checkpoint_save_time": 373.21482944488525,
[36m(head, rank=0, pid=3442)[0m   "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3442)[0m     364.9538495540619,
[36m(head, rank=0, pid=3442)[0m     359.72520542144775,
[36m(head, rank=0, pid=3442)[0m     350.09020495414734,
[36m(head, rank=0, pid=3442)[0m     373.21482944488525,
[36m(head, rank=0, pid=3442)[0m     366.54109501838684
[36m(head, rank=0, pid=3442)[0m   ],
[36m(head, rank=0, pid=3442)[0m   "num_batch_samples": 25,
[36m(head, rank=0, pid=3442)[0m   "total_batch_sample_time": 126.65879392623901,
[36m(head, rank=0, pid=3442)[0m   "average_batch_sample_time": 5.066351757049561,
[36m(head, rank=0, pid=3442)[0m   "min_batch_sample_time": 0.025083065032958984,
[36m(head, rank=0, pid=3442)[0m   "max_batch_sample_time": 31.636186599731445,
[36m(head, rank=0, pid=3442)[0m   "individual_batch_sample_times": [
[36m(head, rank=0, pid=3442)[0m     0.074554443359375,
[36m(head, rank=0, pid=3442)[0m     0.05079483985900879,
[36m(head, rank=0, pid=3442)[0m     0.042083024978637695,
[36m(head, rank=0, pid=3442)[0m     0.046128273010253906,
[36m(head, rank=0, pid=3442)[0m     0.054231882095336914,
[36m(head, rank=0, pid=3442)[0m     31.062037706375122,
[36m(head, rank=0, pid=3442)[0m     0.035566091537475586,
[36m(head, rank=0, pid=3442)[0m     0.02979135513305664,
[36m(head, rank=0, pid=3442)[0m     0.04201865196228027,
[36m(head, rank=0, pid=3442)[0m     0.02749013900756836,
[36m(head, rank=0, pid=3442)[0m     31.636186599731445,
[36m(head, rank=0, pid=3442)[0m     0.026549816131591797,
[36m(head, rank=0, pid=3442)[0m     0.02803325653076172,
[36m(head, rank=0, pid=3442)[0m     0.029286623001098633,
[36m(head, rank=0, pid=3442)[0m     0.027493000030517578,
[36m(head, rank=0, pid=3442)[0m     31.395930767059326,
[36m(head, rank=0, pid=3442)[0m     0.031694650650024414,
[36m(head, rank=0, pid=3442)[0m     0.03140616416931152,
[36m(head, rank=0, pid=3442)[0m     0.025083065032958984,
[36m(head, rank=0, pid=3442)[0m     0.031415462493896484,
[36m(head, rank=0, pid=3442)[0m     31.5491886138916,
[36m(head, rank=0, pid=3442)[0m     0.031143903732299805,
[36m(head, rank=0, pid=3442)[0m     0.026129961013793945,
[36m(head, rank=0, pid=3442)[0m     0.029123306274414062,
[36m(head, rank=0, pid=3442)[0m     0.29543232917785645
[36m(head, rank=0, pid=3442)[0m   ],
[36m(head, rank=0, pid=3442)[0m   "num_training_steps": 200,
[36m(head, rank=0, pid=3442)[0m   "total_training_step_time": 1878.2480072975159,
[36m(head, rank=0, pid=3442)[0m   "average_training_step_time": 9.391240036487579,
[36m(head, rank=0, pid=3442)[0m   "min_training_step_time": 3.512376070022583,
[36m(head, rank=0, pid=3442)[0m   "max_training_step_time": 282.8835458755493,
[36m(head, rank=0, pid=3442)[0m   "individual_training_step_times": [
[36m(head, rank=0, pid=3442)[0m     5.1752166748046875,
[36m(head, rank=0, pid=3442)[0m     3.7206153869628906,
[36m(head, rank=0, pid=3442)[0m     4.437203407287598,
[36m(head, rank=0, pid=3442)[0m     3.6644840240478516,
[36m(head, rank=0, pid=3442)[0m     4.760375499725342,
[36m(head, rank=0, pid=3442)[0m     3.8788375854492188,
[36m(head, rank=0, pid=3442)[0m     3.776496410369873,
[36m(head, rank=0, pid=3442)[0m     3.67899227142334,
[36m(head, rank=0, pid=3442)[0m     4.221089839935303,
[36m(head, rank=0, pid=3442)[0m     4.68178391456604,
[36m(head, rank=0, pid=3442)[0m     3.666757583618164,
[36m(head, rank=0, pid=3442)[0m     3.7534515857696533,
[36m(head, rank=0, pid=3442)[0m     3.670611619949341,
[36m(head, rank=0, pid=3442)[0m     4.917409181594849,
[36m(head, rank=0, pid=3442)[0m     3.666802406311035,
[36m(head, rank=0, pid=3442)[0m     4.563892364501953,
[36m(head, rank=0, pid=3442)[0m     4.084828615188599,
[36m(head, rank=0, pid=3442)[0m     3.711211681365967,
[36m(head, rank=0, pid=3442)[0m     3.8596255779266357,
[36m(head, rank=0, pid=3442)[0m     3.678041458129883,
[36m(head, rank=0, pid=3442)[0m     4.3246049880981445,
[36m(head, rank=0, pid=3442)[0m     3.666987419128418,
[36m(head, rank=0, pid=3442)[0m     4.56370210647583,
[36m(head, rank=0, pid=3442)[0m     3.68031907081604,
[36m(head, rank=0, pid=3442)[0m     4.927763223648071,
[36m(head, rank=0, pid=3442)[0m     3.6929943561553955,
[36m(head, rank=0, pid=3442)[0m     3.9324235916137695,
[36m(head, rank=0, pid=3442)[0m     3.7076306343078613,
[36m(head, rank=0, pid=3442)[0m     3.5806729793548584,
[36m(head, rank=0, pid=3442)[0m     3.686368465423584,
[36m(head, rank=0, pid=3442)[0m     3.8007853031158447,
[36m(head, rank=0, pid=3442)[0m     4.387805700302124,
[36m(head, rank=0, pid=3442)[0m     4.706195831298828,
[36m(head, rank=0, pid=3442)[0m     3.86515736579895,
[36m(head, rank=0, pid=3442)[0m     3.6858067512512207,
[36m(head, rank=0, pid=3442)[0m     4.0548930168151855,
[36m(head, rank=0, pid=3442)[0m     4.571312665939331,
[36m(head, rank=0, pid=3442)[0m     4.383613586425781,
[36m(head, rank=0, pid=3442)[0m     3.676517963409424,
[36m(head, rank=0, pid=3442)[0m     3.843723773956299,
[36m(head, rank=0, pid=3442)[0m     282.8835458755493,
[36m(head, rank=0, pid=3442)[0m     3.6754708290100098,
[36m(head, rank=0, pid=3442)[0m     4.759801149368286,
[36m(head, rank=0, pid=3442)[0m     3.6711652278900146,
[36m(head, rank=0, pid=3442)[0m     5.372419595718384,
[36m(head, rank=0, pid=3442)[0m     3.684436321258545,
[36m(head, rank=0, pid=3442)[0m     3.920243978500366,
[36m(head, rank=0, pid=3442)[0m     4.030949831008911,
[36m(head, rank=0, pid=3442)[0m     4.954099178314209,
[36m(head, rank=0, pid=3442)[0m     4.760239839553833,
[36m(head, rank=0, pid=3442)[0m     3.5364482402801514,
[36m(head, rank=0, pid=3442)[0m     3.6683387756347656,
[36m(head, rank=0, pid=3442)[0m     3.9564247131347656,
[36m(head, rank=0, pid=3442)[0m     3.5815043449401855,
[36m(head, rank=0, pid=3442)[0m     4.253296852111816,
[36m(head, rank=0, pid=3442)[0m     3.668962001800537,
[36m(head, rank=0, pid=3442)[0m     4.929504156112671,
[36m(head, rank=0, pid=3442)[0m     4.048418760299683,
[36m(head, rank=0, pid=3442)[0m     3.8241567611694336,
[36m(head, rank=0, pid=3442)[0m     4.078517913818359,
[36m(head, rank=0, pid=3442)[0m     3.5308797359466553,
[36m(head, rank=0, pid=3442)[0m     3.717790126800537,
[36m(head, rank=0, pid=3442)[0m     3.6672000885009766,
[36m(head, rank=0, pid=3442)[0m     4.36125111579895,
[36m(head, rank=0, pid=3442)[0m     3.6629579067230225,
[36m(head, rank=0, pid=3442)[0m     4.029800653457642,
[36m(head, rank=0, pid=3442)[0m     3.6788673400878906,
[36m(head, rank=0, pid=3442)[0m     3.632537603378296,
[36m(head, rank=0, pid=3442)[0m     4.229649066925049,
[36m(head, rank=0, pid=3442)[0m     4.793485403060913,
[36m(head, rank=0, pid=3442)[0m     3.703537940979004,
[36m(head, rank=0, pid=3442)[0m     3.868201732635498,
[36m(head, rank=0, pid=3442)[0m     3.6827211380004883,
[36m(head, rank=0, pid=3442)[0m     4.179302215576172,
[36m(head, rank=0, pid=3442)[0m     3.5294582843780518,
[36m(head, rank=0, pid=3442)[0m     3.863398790359497,
[36m(head, rank=0, pid=3442)[0m     3.8375682830810547,
[36m(head, rank=0, pid=3442)[0m     3.656111478805542,
[36m(head, rank=0, pid=3442)[0m     3.667653799057007,
[36m(head, rank=0, pid=3442)[0m     3.6906142234802246,
[36m(head, rank=0, pid=3442)[0m     260.29067873954773,
[36m(head, rank=0, pid=3442)[0m     4.605090856552124,
[36m(head, rank=0, pid=3442)[0m     3.6607306003570557,
[36m(head, rank=0, pid=3442)[0m     6.978400230407715,
[36m(head, rank=0, pid=3442)[0m     3.705528974533081,
[36m(head, rank=0, pid=3442)[0m     3.8228371143341064,
[36m(head, rank=0, pid=3442)[0m     4.146059989929199,
[36m(head, rank=0, pid=3442)[0m     3.6677627563476562,
[36m(head, rank=0, pid=3442)[0m     4.124673843383789,
[36m(head, rank=0, pid=3442)[0m     4.468088626861572,
[36m(head, rank=0, pid=3442)[0m     4.694268226623535,
[36m(head, rank=0, pid=3442)[0m     4.090676546096802,
[36m(head, rank=0, pid=3442)[0m     4.842165231704712,
[36m(head, rank=0, pid=3442)[0m     3.615593194961548,
[36m(head, rank=0, pid=3442)[0m     3.84822154045105,
[36m(head, rank=0, pid=3442)[0m     3.6871337890625,
[36m(head, rank=0, pid=3442)[0m     3.697450876235962,
[36m(head, rank=0, pid=3442)[0m     4.7940754890441895,
[36m(head, rank=0, pid=3442)[0m     3.675856351852417,
[36m(head, rank=0, pid=3442)[0m     4.1094536781311035,
[36m(head, rank=0, pid=3442)[0m     3.659118413925171,
[36m(head, rank=0, pid=3442)[0m     3.6738569736480713,
[36m(head, rank=0, pid=3442)[0m     3.9776766300201416,
[36m(head, rank=0, pid=3442)[0m     3.595843553543091,
[36m(head, rank=0, pid=3442)[0m     3.7149288654327393,
[36m(head, rank=0, pid=3442)[0m     3.810771942138672,
[36m(head, rank=0, pid=3442)[0m     4.805229902267456,
[36m(head, rank=0, pid=3442)[0m     4.912998914718628,
[36m(head, rank=0, pid=3442)[0m     3.673764705657959,
[36m(head, rank=0, pid=3442)[0m     3.6670243740081787,
[36m(head, rank=0, pid=3442)[0m     3.670501232147217,
[36m(head, rank=0, pid=3442)[0m     3.675086259841919,
[36m(head, rank=0, pid=3442)[0m     4.8603925704956055,
[36m(head, rank=0, pid=3442)[0m     3.9234890937805176,
[36m(head, rank=0, pid=3442)[0m     4.307585954666138,
[36m(head, rank=0, pid=3442)[0m     3.673971652984619,
[36m(head, rank=0, pid=3442)[0m     3.733140707015991,
[36m(head, rank=0, pid=3442)[0m     3.6947154998779297,
[36m(head, rank=0, pid=3442)[0m     3.7720704078674316,
[36m(head, rank=0, pid=3442)[0m     4.460222959518433,
[36m(head, rank=0, pid=3442)[0m     268.2784044742584,
[36m(head, rank=0, pid=3442)[0m     3.537520170211792,
[36m(head, rank=0, pid=3442)[0m     4.086101055145264,
[36m(head, rank=0, pid=3442)[0m     3.7920126914978027,
[36m(head, rank=0, pid=3442)[0m     4.25760555267334,
[36m(head, rank=0, pid=3442)[0m     4.400486469268799,
[36m(head, rank=0, pid=3442)[0m     4.5327372550964355,
[36m(head, rank=0, pid=3442)[0m     3.6683273315429688,
[36m(head, rank=0, pid=3442)[0m     4.427438020706177,
[36m(head, rank=0, pid=3442)[0m     4.932512998580933,
[36m(head, rank=0, pid=3442)[0m     4.864494562149048,
[36m(head, rank=0, pid=3442)[0m     3.662473440170288,
[36m(head, rank=0, pid=3442)[0m     3.665327787399292,
[36m(head, rank=0, pid=3442)[0m     3.535162925720215,
[36m(head, rank=0, pid=3442)[0m     3.796424627304077,
[36m(head, rank=0, pid=3442)[0m     3.512376070022583,
[36m(head, rank=0, pid=3442)[0m     3.8410699367523193,
[36m(head, rank=0, pid=3442)[0m     3.916715145111084,
[36m(head, rank=0, pid=3442)[0m     4.417297124862671,
[36m(head, rank=0, pid=3442)[0m     4.173470973968506,
[36m(head, rank=0, pid=3442)[0m     3.916689395904541,
[36m(head, rank=0, pid=3442)[0m     4.615582227706909,
[36m(head, rank=0, pid=3442)[0m     3.672025680541992,
[36m(head, rank=0, pid=3442)[0m     3.8470964431762695,
[36m(head, rank=0, pid=3442)[0m     3.822141170501709,
[36m(head, rank=0, pid=3442)[0m     4.132974863052368,
[36m(head, rank=0, pid=3442)[0m     3.6779634952545166,
[36m(head, rank=0, pid=3442)[0m     4.367546319961548,
[36m(head, rank=0, pid=3442)[0m     3.665607452392578,
[36m(head, rank=0, pid=3442)[0m     3.663867950439453,
[36m(head, rank=0, pid=3442)[0m     4.785090923309326,
[36m(head, rank=0, pid=3442)[0m     3.575103759765625,
[36m(head, rank=0, pid=3442)[0m     3.8875908851623535,
[36m(head, rank=0, pid=3442)[0m     3.7014920711517334,
[36m(head, rank=0, pid=3442)[0m     3.6767399311065674,
[36m(head, rank=0, pid=3442)[0m     3.6705985069274902,
[36m(head, rank=0, pid=3442)[0m     3.7380528450012207,
[36m(head, rank=0, pid=3442)[0m     3.669579029083252,
[36m(head, rank=0, pid=3442)[0m     3.564431667327881,
[36m(head, rank=0, pid=3442)[0m     4.659433841705322,
[36m(head, rank=0, pid=3442)[0m     275.6346650123596,
[36m(head, rank=0, pid=3442)[0m     4.242079973220825,
[36m(head, rank=0, pid=3442)[0m     4.996636152267456,
[36m(head, rank=0, pid=3442)[0m     3.7814865112304688,
[36m(head, rank=0, pid=3442)[0m     3.561622142791748,
[36m(head, rank=0, pid=3442)[0m     3.6750547885894775,
[36m(head, rank=0, pid=3442)[0m     3.67232084274292,
[36m(head, rank=0, pid=3442)[0m     5.389596939086914,
[36m(head, rank=0, pid=3442)[0m     3.65755295753479,
[36m(head, rank=0, pid=3442)[0m     4.817900896072388,
[36m(head, rank=0, pid=3442)[0m     3.671800136566162,
[36m(head, rank=0, pid=3442)[0m     3.8054988384246826,
[36m(head, rank=0, pid=3442)[0m     3.781794548034668,
[36m(head, rank=0, pid=3442)[0m     3.6676127910614014,
[36m(head, rank=0, pid=3442)[0m     4.631753444671631,
[36m(head, rank=0, pid=3442)[0m     4.077137470245361,
[36m(head, rank=0, pid=3442)[0m     4.534646272659302,
[36m(head, rank=0, pid=3442)[0m     4.81629753112793,
[36m(head, rank=0, pid=3442)[0m     4.474386930465698,
[36m(head, rank=0, pid=3442)[0m     4.519698619842529,
[36m(head, rank=0, pid=3442)[0m     3.8182427883148193,
[36m(head, rank=0, pid=3442)[0m     4.459801197052002,
[36m(head, rank=0, pid=3442)[0m     4.190524339675903,
[36m(head, rank=0, pid=3442)[0m     3.785505533218384,
[36m(head, rank=0, pid=3442)[0m     4.047178506851196,
[36m(head, rank=0, pid=3442)[0m     3.693903684616089,
[36m(head, rank=0, pid=3442)[0m     4.535181045532227,
[36m(head, rank=0, pid=3442)[0m     3.660269021987915,
[36m(head, rank=0, pid=3442)[0m     3.9380621910095215,
[36m(head, rank=0, pid=3442)[0m     3.667137384414673,
[36m(head, rank=0, pid=3442)[0m     3.675557851791382,
[36m(head, rank=0, pid=3442)[0m     3.946711540222168,
[36m(head, rank=0, pid=3442)[0m     3.674938440322876,
[36m(head, rank=0, pid=3442)[0m     3.6651177406311035,
[36m(head, rank=0, pid=3442)[0m     3.674659252166748,
[36m(head, rank=0, pid=3442)[0m     3.7097787857055664,
[36m(head, rank=0, pid=3442)[0m     3.6603469848632812,
[36m(head, rank=0, pid=3442)[0m     4.20470666885376,
[36m(head, rank=0, pid=3442)[0m     4.710012674331665,
[36m(head, rank=0, pid=3442)[0m     4.178187370300293
[36m(head, rank=0, pid=3442)[0m   ]
[36m(head, rank=0, pid=3442)[0m }
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m --- All Training Runs Summary ---
[36m(head, rank=0, pid=3442)[0m [
[36m(head, rank=0, pid=3442)[0m   {
[36m(head, rank=0, pid=3442)[0m     "run_id": 1,
[36m(head, rank=0, pid=3442)[0m     "timestamp": "2025-08-04T01:18:20.601110",
[36m(head, rank=0, pid=3442)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3442)[0m     "checkpoint_dir": "/mnt/data",
[36m(head, rank=0, pid=3442)[0m     "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3442)[0m     "training_status": "completed",
[36m(head, rank=0, pid=3442)[0m     "output_dir": "/mnt/data",
[36m(head, rank=0, pid=3442)[0m     "dataset_load_time": 2.473289966583252,
[36m(head, rank=0, pid=3442)[0m     "model_load_time": 25.26194977760315,
[36m(head, rank=0, pid=3442)[0m     "training_time": 4259.256002664566,
[36m(head, rank=0, pid=3442)[0m     "total_time": 4286.991242408752,
[36m(head, rank=0, pid=3442)[0m     "error": null,
[36m(head, rank=0, pid=3442)[0m     "num_checkpoints_saved": 5,
[36m(head, rank=0, pid=3442)[0m     "total_checkpoint_save_time": 3307.146084547043,
[36m(head, rank=0, pid=3442)[0m     "average_checkpoint_save_time": 661.4292169094085,
[36m(head, rank=0, pid=3442)[0m     "min_checkpoint_save_time": 641.7910447120667,
[36m(head, rank=0, pid=3442)[0m     "max_checkpoint_save_time": 676.6965086460114,
[36m(head, rank=0, pid=3442)[0m     "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3442)[0m       675.2821083068848,
[36m(head, rank=0, pid=3442)[0m       647.9465341567993,
[36m(head, rank=0, pid=3442)[0m       641.7910447120667,
[36m(head, rank=0, pid=3442)[0m       676.6965086460114,
[36m(head, rank=0, pid=3442)[0m       665.4298887252808
[36m(head, rank=0, pid=3442)[0m     ],
[36m(head, rank=0, pid=3442)[0m     "num_batch_samples": 25,
[36m(head, rank=0, pid=3442)[0m     "total_batch_sample_time": 1.2581970691680908,
[36m(head, rank=0, pid=3442)[0m     "average_batch_sample_time": 0.05032788276672363,
[36m(head, rank=0, pid=3442)[0m     "min_batch_sample_time": 0.028130531311035156,
[36m(head, rank=0, pid=3442)[0m     "max_batch_sample_time": 0.29116392135620117,
[36m(head, rank=0, pid=3442)[0m     "individual_batch_sample_times": [
[36m(head, rank=0, pid=3442)[0m       0.13395094871520996,
[36m(head, rank=0, pid=3442)[0m       0.049073219299316406,
[36m(head, rank=0, pid=3442)[0m       0.06688237190246582,
[36m(head, rank=0, pid=3442)[0m       0.037421464920043945,
[36m(head, rank=0, pid=3442)[0m       0.04761552810668945,
[36m(head, rank=0, pid=3442)[0m       0.037125587463378906,
[36m(head, rank=0, pid=3442)[0m       0.037218570709228516,
[36m(head, rank=0, pid=3442)[0m       0.03947114944458008,
[36m(head, rank=0, pid=3442)[0m       0.03326010704040527,
[36m(head, rank=0, pid=3442)[0m       0.03283548355102539,
[36m(head, rank=0, pid=3442)[0m       0.04155278205871582,
[36m(head, rank=0, pid=3442)[0m       0.03269171714782715,
[36m(head, rank=0, pid=3442)[0m       0.028130531311035156,
[36m(head, rank=0, pid=3442)[0m       0.031162500381469727,
[36m(head, rank=0, pid=3442)[0m       0.02975630760192871,
[36m(head, rank=0, pid=3442)[0m       0.03211641311645508,
[36m(head, rank=0, pid=3442)[0m       0.031857967376708984,
[36m(head, rank=0, pid=3442)[0m       0.03131747245788574,
[36m(head, rank=0, pid=3442)[0m       0.03149604797363281,
[36m(head, rank=0, pid=3442)[0m       0.029239416122436523,
[36m(head, rank=0, pid=3442)[0m       0.035639286041259766,
[36m(head, rank=0, pid=3442)[0m       0.0326845645904541,
[36m(head, rank=0, pid=3442)[0m       0.03183627128601074,
[36m(head, rank=0, pid=3442)[0m       0.032697439193725586,
[36m(head, rank=0, pid=3442)[0m       0.29116392135620117
[36m(head, rank=0, pid=3442)[0m     ],
[36m(head, rank=0, pid=3442)[0m     "num_training_steps": 200,
[36m(head, rank=0, pid=3442)[0m     "total_training_step_time": 809.6187808513641,
[36m(head, rank=0, pid=3442)[0m     "average_training_step_time": 4.04809390425682,
[36m(head, rank=0, pid=3442)[0m     "min_training_step_time": 3.519930839538574,
[36m(head, rank=0, pid=3442)[0m     "max_training_step_time": 7.965790510177612,
[36m(head, rank=0, pid=3442)[0m     "individual_training_step_times": [
[36m(head, rank=0, pid=3442)[0m       5.37217116355896,
[36m(head, rank=0, pid=3442)[0m       3.5854415893554688,
[36m(head, rank=0, pid=3442)[0m       4.436198472976685,
[36m(head, rank=0, pid=3442)[0m       3.6619434356689453,
[36m(head, rank=0, pid=3442)[0m       4.729819297790527,
[36m(head, rank=0, pid=3442)[0m       3.877984046936035,
[36m(head, rank=0, pid=3442)[0m       3.6246180534362793,
[36m(head, rank=0, pid=3442)[0m       3.679765224456787,
[36m(head, rank=0, pid=3442)[0m       3.950908660888672,
[36m(head, rank=0, pid=3442)[0m       4.709012985229492,
[36m(head, rank=0, pid=3442)[0m       3.664231538772583,
[36m(head, rank=0, pid=3442)[0m       3.752840995788574,
[36m(head, rank=0, pid=3442)[0m       3.665316343307495,
[36m(head, rank=0, pid=3442)[0m       4.916112661361694,
[36m(head, rank=0, pid=3442)[0m       3.6670939922332764,
[36m(head, rank=0, pid=3442)[0m       4.059868335723877,
[36m(head, rank=0, pid=3442)[0m       4.1064674854278564,
[36m(head, rank=0, pid=3442)[0m       3.710317850112915,
[36m(head, rank=0, pid=3442)[0m       3.785945177078247,
[36m(head, rank=0, pid=3442)[0m       3.6772055625915527,
[36m(head, rank=0, pid=3442)[0m       4.300460338592529,
[36m(head, rank=0, pid=3442)[0m       3.665687084197998,
[36m(head, rank=0, pid=3442)[0m       4.562826871871948,
[36m(head, rank=0, pid=3442)[0m       3.677598476409912,
[36m(head, rank=0, pid=3442)[0m       4.931552410125732,
[36m(head, rank=0, pid=3442)[0m       3.5980820655822754,
[36m(head, rank=0, pid=3442)[0m       3.9329686164855957,
[36m(head, rank=0, pid=3442)[0m       3.7091434001922607,
[36m(head, rank=0, pid=3442)[0m       3.728015899658203,
[36m(head, rank=0, pid=3442)[0m       3.684326410293579,
[36m(head, rank=0, pid=3442)[0m       3.8240303993225098,
[36m(head, rank=0, pid=3442)[0m       4.385685682296753,
[36m(head, rank=0, pid=3442)[0m       4.666236400604248,
[36m(head, rank=0, pid=3442)[0m       3.8576724529266357,
[36m(head, rank=0, pid=3442)[0m       3.6828999519348145,
[36m(head, rank=0, pid=3442)[0m       4.052249431610107,
[36m(head, rank=0, pid=3442)[0m       4.571199178695679,
[36m(head, rank=0, pid=3442)[0m       4.420983076095581,
[36m(head, rank=0, pid=3442)[0m       3.6748151779174805,
[36m(head, rank=0, pid=3442)[0m       3.8429906368255615,
[36m(head, rank=0, pid=3442)[0m       3.660456657409668,
[36m(head, rank=0, pid=3442)[0m       3.527409791946411,
[36m(head, rank=0, pid=3442)[0m       4.7636988162994385,
[36m(head, rank=0, pid=3442)[0m       3.6676058769226074,
[36m(head, rank=0, pid=3442)[0m       5.360615015029907,
[36m(head, rank=0, pid=3442)[0m       3.6701040267944336,
[36m(head, rank=0, pid=3442)[0m       3.9213767051696777,
[36m(head, rank=0, pid=3442)[0m       4.026604413986206,
[36m(head, rank=0, pid=3442)[0m       4.7761430740356445,
[36m(head, rank=0, pid=3442)[0m       4.7568113803863525,
[36m(head, rank=0, pid=3442)[0m       3.6558330059051514,
[36m(head, rank=0, pid=3442)[0m       3.6667966842651367,
[36m(head, rank=0, pid=3442)[0m       3.951975107192993,
[36m(head, rank=0, pid=3442)[0m       3.665433645248413,
[36m(head, rank=0, pid=3442)[0m       4.272090196609497,
[36m(head, rank=0, pid=3442)[0m       3.6637887954711914,
[36m(head, rank=0, pid=3442)[0m       4.914861440658569,
[36m(head, rank=0, pid=3442)[0m       4.048007011413574,
[36m(head, rank=0, pid=3442)[0m       3.8238742351531982,
[36m(head, rank=0, pid=3442)[0m       4.098035573959351,
[36m(head, rank=0, pid=3442)[0m       3.671567440032959,
[36m(head, rank=0, pid=3442)[0m       3.713184356689453,
[36m(head, rank=0, pid=3442)[0m       3.6634304523468018,
[36m(head, rank=0, pid=3442)[0m       4.45559024810791,
[36m(head, rank=0, pid=3442)[0m       3.6629464626312256,
[36m(head, rank=0, pid=3442)[0m       4.114391088485718,
[36m(head, rank=0, pid=3442)[0m       3.6747939586639404,
[36m(head, rank=0, pid=3442)[0m       3.5463812351226807,
[36m(head, rank=0, pid=3442)[0m       4.227115631103516,
[36m(head, rank=0, pid=3442)[0m       4.791055917739868,
[36m(head, rank=0, pid=3442)[0m       3.698688507080078,
[36m(head, rank=0, pid=3442)[0m       3.8656017780303955,
[36m(head, rank=0, pid=3442)[0m       3.533703565597534,
[36m(head, rank=0, pid=3442)[0m       4.138953924179077,
[36m(head, rank=0, pid=3442)[0m       3.6662397384643555,
[36m(head, rank=0, pid=3442)[0m       3.862809896469116,
[36m(head, rank=0, pid=3442)[0m       3.9227139949798584,
[36m(head, rank=0, pid=3442)[0m       3.6779909133911133,
[36m(head, rank=0, pid=3442)[0m       3.6665754318237305,
[36m(head, rank=0, pid=3442)[0m       3.688436508178711,
[36m(head, rank=0, pid=3442)[0m       3.662698745727539,
[36m(head, rank=0, pid=3442)[0m       4.713405132293701,
[36m(head, rank=0, pid=3442)[0m       3.662882089614868,
[36m(head, rank=0, pid=3442)[0m       6.992896318435669,
[36m(head, rank=0, pid=3442)[0m       3.6605920791625977,
[36m(head, rank=0, pid=3442)[0m       3.822934627532959,
[36m(head, rank=0, pid=3442)[0m       4.262164831161499,
[36m(head, rank=0, pid=3442)[0m       3.6710691452026367,
[36m(head, rank=0, pid=3442)[0m       4.104529857635498,
[36m(head, rank=0, pid=3442)[0m       4.579232931137085,
[36m(head, rank=0, pid=3442)[0m       4.69982123374939,
[36m(head, rank=0, pid=3442)[0m       4.094576358795166,
[36m(head, rank=0, pid=3442)[0m       4.84267783164978,
[36m(head, rank=0, pid=3442)[0m       3.7106289863586426,
[36m(head, rank=0, pid=3442)[0m       3.8737194538116455,
[36m(head, rank=0, pid=3442)[0m       3.652174711227417,
[36m(head, rank=0, pid=3442)[0m       3.6878349781036377,
[36m(head, rank=0, pid=3442)[0m       4.916690349578857,
[36m(head, rank=0, pid=3442)[0m       3.674298048019409,
[36m(head, rank=0, pid=3442)[0m       4.109268665313721,
[36m(head, rank=0, pid=3442)[0m       3.6567845344543457,
[36m(head, rank=0, pid=3442)[0m       3.6728999614715576,
[36m(head, rank=0, pid=3442)[0m       3.949450731277466,
[36m(head, rank=0, pid=3442)[0m       3.628526449203491,
[36m(head, rank=0, pid=3442)[0m       3.5771102905273438,
[36m(head, rank=0, pid=3442)[0m       3.8068413734436035,
[36m(head, rank=0, pid=3442)[0m       4.803084850311279,
[36m(head, rank=0, pid=3442)[0m       4.910745620727539,
[36m(head, rank=0, pid=3442)[0m       3.5848565101623535,
[36m(head, rank=0, pid=3442)[0m       3.6661510467529297,
[36m(head, rank=0, pid=3442)[0m       3.6699464321136475,
[36m(head, rank=0, pid=3442)[0m       3.673058032989502,
[36m(head, rank=0, pid=3442)[0m       4.853266477584839,
[36m(head, rank=0, pid=3442)[0m       3.921327590942383,
[36m(head, rank=0, pid=3442)[0m       4.4312543869018555,
[36m(head, rank=0, pid=3442)[0m       3.6720190048217773,
[36m(head, rank=0, pid=3442)[0m       3.733637571334839,
[36m(head, rank=0, pid=3442)[0m       3.6915876865386963,
[36m(head, rank=0, pid=3442)[0m       3.782296895980835,
[36m(head, rank=0, pid=3442)[0m       4.3643317222595215,
[36m(head, rank=0, pid=3442)[0m       7.965790510177612,
[36m(head, rank=0, pid=3442)[0m       3.6762495040893555,
[36m(head, rank=0, pid=3442)[0m       4.088785886764526,
[36m(head, rank=0, pid=3442)[0m       3.7959513664245605,
[36m(head, rank=0, pid=3442)[0m       4.2564537525177,
[36m(head, rank=0, pid=3442)[0m       4.403475046157837,
[36m(head, rank=0, pid=3442)[0m       4.535320520401001,
[36m(head, rank=0, pid=3442)[0m       3.519930839538574,
[36m(head, rank=0, pid=3442)[0m       4.424072504043579,
[36m(head, rank=0, pid=3442)[0m       4.93641996383667,
[36m(head, rank=0, pid=3442)[0m       4.814030170440674,
[36m(head, rank=0, pid=3442)[0m       3.6618432998657227,
[36m(head, rank=0, pid=3442)[0m       3.6647963523864746,
[36m(head, rank=0, pid=3442)[0m       3.6624584197998047,
[36m(head, rank=0, pid=3442)[0m       3.7975759506225586,
[36m(head, rank=0, pid=3442)[0m       3.6577014923095703,
[36m(head, rank=0, pid=3442)[0m       3.830439805984497,
[36m(head, rank=0, pid=3442)[0m       3.9202024936676025,
[36m(head, rank=0, pid=3442)[0m       4.4207868576049805,
[36m(head, rank=0, pid=3442)[0m       4.094029903411865,
[36m(head, rank=0, pid=3442)[0m       3.9207615852355957,
[36m(head, rank=0, pid=3442)[0m       4.61798882484436,
[36m(head, rank=0, pid=3442)[0m       3.6728270053863525,
[36m(head, rank=0, pid=3442)[0m       3.8440167903900146,
[36m(head, rank=0, pid=3442)[0m       3.810519218444824,
[36m(head, rank=0, pid=3442)[0m       4.249359607696533,
[36m(head, rank=0, pid=3442)[0m       3.674363613128662,
[36m(head, rank=0, pid=3442)[0m       4.368576765060425,
[36m(head, rank=0, pid=3442)[0m       3.6649630069732666,
[36m(head, rank=0, pid=3442)[0m       3.663322925567627,
[36m(head, rank=0, pid=3442)[0m       4.689655780792236,
[36m(head, rank=0, pid=3442)[0m       3.665761947631836,
[36m(head, rank=0, pid=3442)[0m       3.8855056762695312,
[36m(head, rank=0, pid=3442)[0m       3.719775915145874,
[36m(head, rank=0, pid=3442)[0m       3.677212715148926,
[36m(head, rank=0, pid=3442)[0m       3.666099786758423,
[36m(head, rank=0, pid=3442)[0m       3.736069917678833,
[36m(head, rank=0, pid=3442)[0m       3.534635543823242,
[36m(head, rank=0, pid=3442)[0m       3.6597065925598145,
[36m(head, rank=0, pid=3442)[0m       4.657799243927002,
[36m(head, rank=0, pid=3442)[0m       3.5294904708862305,
[36m(head, rank=0, pid=3442)[0m       4.241694450378418,
[36m(head, rank=0, pid=3442)[0m       4.990478515625,
[36m(head, rank=0, pid=3442)[0m       3.774242639541626,
[36m(head, rank=0, pid=3442)[0m       3.6538872718811035,
[36m(head, rank=0, pid=3442)[0m       3.6729323863983154,
[36m(head, rank=0, pid=3442)[0m       3.6695656776428223,
[36m(head, rank=0, pid=3442)[0m       5.416918754577637,
[36m(head, rank=0, pid=3442)[0m       3.6531431674957275,
[36m(head, rank=0, pid=3442)[0m       4.771597623825073,
[36m(head, rank=0, pid=3442)[0m       3.6672141551971436,
[36m(head, rank=0, pid=3442)[0m       3.8496885299682617,
[36m(head, rank=0, pid=3442)[0m       3.777500629425049,
[36m(head, rank=0, pid=3442)[0m       3.669102430343628,
[36m(head, rank=0, pid=3442)[0m       4.6308753490448,
[36m(head, rank=0, pid=3442)[0m       4.074944734573364,
[36m(head, rank=0, pid=3442)[0m       4.525083303451538,
[36m(head, rank=0, pid=3442)[0m       4.925763845443726,
[36m(head, rank=0, pid=3442)[0m       4.4491143226623535,
[36m(head, rank=0, pid=3442)[0m       4.516699314117432,
[36m(head, rank=0, pid=3442)[0m       3.815960645675659,
[36m(head, rank=0, pid=3442)[0m       4.462713241577148,
[36m(head, rank=0, pid=3442)[0m       4.2327399253845215,
[36m(head, rank=0, pid=3442)[0m       3.780245542526245,
[36m(head, rank=0, pid=3442)[0m       3.988837242126465,
[36m(head, rank=0, pid=3442)[0m       3.6939494609832764,
[36m(head, rank=0, pid=3442)[0m       4.5307605266571045,
[36m(head, rank=0, pid=3442)[0m       3.6570770740509033,
[36m(head, rank=0, pid=3442)[0m       3.937329053878784,
[36m(head, rank=0, pid=3442)[0m       3.6664178371429443,
[36m(head, rank=0, pid=3442)[0m       3.673321485519409,
[36m(head, rank=0, pid=3442)[0m       3.9424657821655273,
[36m(head, rank=0, pid=3442)[0m       3.6768393516540527,
[36m(head, rank=0, pid=3442)[0m       3.535896062850952,
[36m(head, rank=0, pid=3442)[0m       3.5561397075653076,
[36m(head, rank=0, pid=3442)[0m       3.6747331619262695,
[36m(head, rank=0, pid=3442)[0m       3.661606788635254,
[36m(head, rank=0, pid=3442)[0m       4.205643892288208,
[36m(head, rank=0, pid=3442)[0m       4.801770448684692,
[36m(head, rank=0, pid=3442)[0m       4.179506063461304
[36m(head, rank=0, pid=3442)[0m     ]
[36m(head, rank=0, pid=3442)[0m   }
[36m(head, rank=0, pid=3442)[0m ]
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m --- Timing Summary ---
[36m(head, rank=0, pid=3442)[0m {
[36m(head, rank=0, pid=3442)[0m   "total_runs": 1,
[36m(head, rank=0, pid=3442)[0m   "dataset_loading": {
[36m(head, rank=0, pid=3442)[0m     "dataset_load_count": 1,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_average": 2.473289966583252,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_min": 2.473289966583252,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_max": 2.473289966583252,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_total": 2.473289966583252
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "model_loading": {
[36m(head, rank=0, pid=3442)[0m     "model_load_count": 1,
[36m(head, rank=0, pid=3442)[0m     "model_load_average": 25.26194977760315,
[36m(head, rank=0, pid=3442)[0m     "model_load_min": 25.26194977760315,
[36m(head, rank=0, pid=3442)[0m     "model_load_max": 25.26194977760315,
[36m(head, rank=0, pid=3442)[0m     "model_load_total": 25.26194977760315
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "training": {
[36m(head, rank=0, pid=3442)[0m     "training_count": 1,
[36m(head, rank=0, pid=3442)[0m     "training_average": 4259.256002664566,
[36m(head, rank=0, pid=3442)[0m     "training_min": 4259.256002664566,
[36m(head, rank=0, pid=3442)[0m     "training_max": 4259.256002664566,
[36m(head, rank=0, pid=3442)[0m     "training_total": 4259.256002664566
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "total_run_time": {
[36m(head, rank=0, pid=3442)[0m     "total_count": 1,
[36m(head, rank=0, pid=3442)[0m     "total_average": 4286.991242408752,
[36m(head, rank=0, pid=3442)[0m     "total_min": 4286.991242408752,
[36m(head, rank=0, pid=3442)[0m     "total_max": 4286.991242408752,
[36m(head, rank=0, pid=3442)[0m     "total_total": 4286.991242408752
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "checkpoint_saving": {
[36m(head, rank=0, pid=3442)[0m     "total_checkpoints_saved": 5,
[36m(head, rank=0, pid=3442)[0m     "total_checkpoint_save_time": 3307.146084547043,
[36m(head, rank=0, pid=3442)[0m     "average_save_time_per_checkpoint": 661.4292169094085,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_times_count": 5,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_min": 641.7910447120667,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_max": 676.6965086460114,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_average": 661.4292169094085
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "batch_sampling": {
[36m(head, rank=0, pid=3442)[0m     "total_batch_samples": 25,
[36m(head, rank=0, pid=3442)[0m     "total_batch_sample_time": 1.2581970691680908,
[36m(head, rank=0, pid=3442)[0m     "average_sample_time_per_batch": 0.05032788276672363,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_times_count": 25,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_min": 0.028130531311035156,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_max": 0.29116392135620117,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_average": 0.05032788276672363
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "training_steps": {
[36m(head, rank=0, pid=3442)[0m     "total_training_steps": 200,
[36m(head, rank=0, pid=3442)[0m     "total_training_step_time": 809.6187808513641,
[36m(head, rank=0, pid=3442)[0m     "average_step_time_per_step": 4.04809390425682,
[36m(head, rank=0, pid=3442)[0m     "training_step_times_count": 200,
[36m(head, rank=0, pid=3442)[0m     "training_step_min": 3.519930839538574,
[36m(head, rank=0, pid=3442)[0m     "training_step_max": 7.965790510177612,
[36m(head, rank=0, pid=3442)[0m     "training_step_average": 4.04809390425682
[36m(head, rank=0, pid=3442)[0m   }
[36m(head, rank=0, pid=3442)[0m }
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.38s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.38s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.38s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.38s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 4282.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4282.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4282.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4282.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 9.39s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 282.95s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1878.58s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 5.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 31.64s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 126.68s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 362.90s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 350.09s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 373.21s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1814.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 4286.42s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 4286.42s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 4286.42s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 4286.42s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 0.99s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 0.99s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 0.99s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 0.99s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 4282.99s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4282.99s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4282.99s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4282.99s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 9.40s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 282.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1879.95s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 5.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 31.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 126.74s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 362.91s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 350.09s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 373.23s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1814.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 4286.40s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 4286.40s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 4286.40s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 4286.40s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.29s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.29s  • Average time: 2.47s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_0.json  • Max time: 2.29s  • Min time: 2.47s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.29s  • Max time: 2.47s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:  • Total time: 2.47s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:  • Average time: 0.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_2.json  • Average time: 0.94s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 0.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 0.94s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 0.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 0.94s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 0.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 0.94s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 4283.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 4283.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4283.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4283.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4283.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4283.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4283.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4283.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200  • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 9.40s  • Average step time per step: 9.39s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.53s  • Min step time: 3.53s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 282.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 282.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1879.90s  • Total training step time: 1878.93s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25  • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 5.07s  • Average sample time per batch: 5.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s  • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 31.63s  • Max sample time: 31.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 126.79s  • Total batch sample time: 126.79s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5  • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================  • Average save time per checkpoint: 362.91s  • Average save time per checkpoint: 362.91s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 350.09s  • Min save time: 350.09s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 373.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY  • Max save time: 373.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1  • Total checkpoint save time: 1814.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1814.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 4286.33s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 4286.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:  • Average time: 2.33s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 4286.33s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 4286.33s  • Min total time: 4286.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.33s  • Average time: 2.31s  • Total time across all runs: 4286.33s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 4286.41s  • Max time: 2.33s  • Min time: 2.31s================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 4286.41s  • Max time: 2.31s  • Total time: 2.33s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================  • Total time: 2.31s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 26.93s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.05s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 26.93s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.05s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 26.93s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.05s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 26.93s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.05s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 4257.74s  • Average time: 4283.06s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4257.74s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4283.06s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4257.74s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4283.06s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4257.74s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4283.06s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200  • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 9.39s  • Average step time per step: 9.40s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.51s  • Min step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 282.88s  • Max step time: 282.84s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1878.25s  • Total training step time: 1880.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25  • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 5.07s  • Average sample time per batch: 5.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s  • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 31.64s  • Max sample time: 31.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 126.66s  • Total batch sample time: 126.74s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5  • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 362.91s  • Average save time per checkpoint: 362.90s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 350.09s  • Min save time: 350.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 373.21s  • Max save time: 373.21s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1814.53s  • Total checkpoint save time: 1814.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 4287.00s  • Average total time per run: 4286.42s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 4287.00s  • Min total time: 4286.42s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 4287.00s  • Max total time: 4286.42s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 4287.00s  • Total time across all runs: 4286.42s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.28s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 0.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 0.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 0.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 0.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 4283.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4283.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4283.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4283.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 9.40s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 282.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1879.71s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 5.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 31.62s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 126.79s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 362.91s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 350.09s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 373.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1814.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 4286.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 4286.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 4286.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 4286.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_0.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m --- Training Run 1 Info (Directory: /mnt/data/) ---
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "run_id": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "timestamp": "2025-08-04T01:18:20.600782",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "checkpoint_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training_status": "completed",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "output_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "dataset_load_time": 2.326582193374634,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "model_load_time": 26.92659616470337,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training_time": 4257.742622852325,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_time": 4286.995801210403,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "error": null,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "num_checkpoints_saved": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_checkpoint_save_time": 1814.525184392929,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "average_checkpoint_save_time": 362.9050368785858,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "min_checkpoint_save_time": 350.09020495414734,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "max_checkpoint_save_time": 373.21482944488525,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     364.9538495540619,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     359.72520542144775,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     350.09020495414734,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     373.21482944488525,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     366.54109501838684
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "num_batch_samples": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_batch_sample_time": 126.65879392623901,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "average_batch_sample_time": 5.066351757049561,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "min_batch_sample_time": 0.025083065032958984,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "max_batch_sample_time": 31.636186599731445,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.074554443359375,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.05079483985900879,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.042083024978637695,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.046128273010253906,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.054231882095336914,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     31.062037706375122,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.035566091537475586,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.02979135513305664,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.04201865196228027,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.02749013900756836,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     31.636186599731445,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.026549816131591797,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.02803325653076172,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.029286623001098633,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.027493000030517578,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     31.395930767059326,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.031694650650024414,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03140616416931152,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.025083065032958984,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.031415462493896484,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     31.5491886138916,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.031143903732299805,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.026129961013793945,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.029123306274414062,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.29543232917785645
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "num_training_steps": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_training_step_time": 1878.2480072975159,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "average_training_step_time": 9.391240036487579,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "min_training_step_time": 3.512376070022583,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "max_training_step_time": 282.8835458755493,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "individual_training_step_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.1752166748046875,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7206153869628906,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.437203407287598,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6644840240478516,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.760375499725342,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8788375854492188,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.776496410369873,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.67899227142334,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.221089839935303,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.68178391456604,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.666757583618164,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7534515857696533,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.670611619949341,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.917409181594849,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.666802406311035,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.563892364501953,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.084828615188599,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.711211681365967,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8596255779266357,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.678041458129883,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.3246049880981445,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.666987419128418,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.56370210647583,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.68031907081604,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.927763223648071,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6929943561553955,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9324235916137695,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7076306343078613,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5806729793548584,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.686368465423584,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8007853031158447,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.387805700302124,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.706195831298828,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.86515736579895,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6858067512512207,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.0548930168151855,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.571312665939331,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.383613586425781,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.676517963409424,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.843723773956299,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     282.8835458755493,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6754708290100098,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.759801149368286,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6711652278900146,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.372419595718384,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.684436321258545,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.920243978500366,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.030949831008911,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.954099178314209,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.760239839553833,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5364482402801514,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6683387756347656,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9564247131347656,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5815043449401855,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.253296852111816,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.668962001800537,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.929504156112671,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.048418760299683,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8241567611694336,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.078517913818359,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5308797359466553,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.717790126800537,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6672000885009766,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.36125111579895,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6629579067230225,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.029800653457642,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6788673400878906,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.632537603378296,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.229649066925049,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.793485403060913,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.703537940979004,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.868201732635498,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6827211380004883,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.179302215576172,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5294582843780518,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.863398790359497,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8375682830810547,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.656111478805542,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.667653799057007,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6906142234802246,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     260.29067873954773,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.605090856552124,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6607306003570557,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     6.978400230407715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.705528974533081,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8228371143341064,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.146059989929199,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6677627563476562,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.124673843383789,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.468088626861572,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.694268226623535,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.090676546096802,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.842165231704712,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.615593194961548,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.84822154045105,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6871337890625,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.697450876235962,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.7940754890441895,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.675856351852417,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.1094536781311035,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.659118413925171,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6738569736480713,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9776766300201416,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.595843553543091,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7149288654327393,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.810771942138672,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.805229902267456,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.912998914718628,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.673764705657959,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6670243740081787,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.670501232147217,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.675086259841919,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.8603925704956055,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9234890937805176,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.307585954666138,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.673971652984619,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.733140707015991,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6947154998779297,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7720704078674316,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.460222959518433,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     268.2784044742584,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.537520170211792,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.086101055145264,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7920126914978027,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.25760555267334,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.400486469268799,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.5327372550964355,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6683273315429688,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.427438020706177,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.932512998580933,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.864494562149048,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.662473440170288,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.665327787399292,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.535162925720215,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.796424627304077,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.512376070022583,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8410699367523193,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.916715145111084,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.417297124862671,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.173470973968506,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.916689395904541,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.615582227706909,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.672025680541992,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8470964431762695,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.822141170501709,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.132974863052368,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6779634952545166,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.367546319961548,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.665607452392578,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.663867950439453,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.785090923309326,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.575103759765625,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8875908851623535,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7014920711517334,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6767399311065674,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6705985069274902,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7380528450012207,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.669579029083252,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.564431667327881,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.659433841705322,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     275.6346650123596,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.242079973220825,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.996636152267456,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7814865112304688,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.561622142791748,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6750547885894775,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.67232084274292,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.389596939086914,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.65755295753479,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.817900896072388,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.671800136566162,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8054988384246826,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.781794548034668,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6676127910614014,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.631753444671631,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.077137470245361,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.534646272659302,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.81629753112793,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.474386930465698,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.519698619842529,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8182427883148193,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.459801197052002,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.190524339675903,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.785505533218384,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.047178506851196,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.693903684616089,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.535181045532227,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.660269021987915,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9380621910095215,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.667137384414673,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.675557851791382,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.946711540222168,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.674938440322876,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6651177406311035,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.674659252166748,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7097787857055664,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6603469848632812,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.20470666885376,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.710012674331665,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.178187370300293
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   ]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m --- All Training Runs Summary ---
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "run_id": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "timestamp": "2025-08-04T01:18:20.600782",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_status": "completed",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "output_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_time": 2.326582193374634,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_time": 26.92659616470337,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_time": 4257.742622852325,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_time": 4286.995801210403,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "error": null,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "num_checkpoints_saved": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_checkpoint_save_time": 1814.525184392929,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_checkpoint_save_time": 362.9050368785858,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "min_checkpoint_save_time": 350.09020495414734,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "max_checkpoint_save_time": 373.21482944488525,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       364.9538495540619,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       359.72520542144775,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       350.09020495414734,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       373.21482944488525,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       366.54109501838684
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "num_batch_samples": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_batch_sample_time": 126.65879392623901,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_batch_sample_time": 5.066351757049561,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "min_batch_sample_time": 0.025083065032958984,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "max_batch_sample_time": 31.636186599731445,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.074554443359375,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.05079483985900879,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.042083024978637695,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.046128273010253906,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.054231882095336914,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       31.062037706375122,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.035566091537475586,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.02979135513305664,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.04201865196228027,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.02749013900756836,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       31.636186599731445,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.026549816131591797,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.02803325653076172,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.029286623001098633,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.027493000030517578,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       31.395930767059326,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.031694650650024414,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03140616416931152,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.025083065032958984,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.031415462493896484,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       31.5491886138916,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.031143903732299805,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.026129961013793945,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.029123306274414062,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.29543232917785645
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "num_training_steps": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_training_step_time": 1878.2480072975159,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_training_step_time": 9.391240036487579,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "min_training_step_time": 3.512376070022583,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "max_training_step_time": 282.8835458755493,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "individual_training_step_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.1752166748046875,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7206153869628906,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.437203407287598,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6644840240478516,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.760375499725342,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8788375854492188,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.776496410369873,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.67899227142334,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.221089839935303,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.68178391456604,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.666757583618164,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7534515857696533,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.670611619949341,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.917409181594849,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.666802406311035,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.563892364501953,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.084828615188599,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.711211681365967,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8596255779266357,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.678041458129883,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.3246049880981445,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.666987419128418,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.56370210647583,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.68031907081604,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.927763223648071,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6929943561553955,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9324235916137695,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7076306343078613,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5806729793548584,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.686368465423584,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8007853031158447,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.387805700302124,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.706195831298828,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.86515736579895,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6858067512512207,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.0548930168151855,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.571312665939331,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.383613586425781,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.676517963409424,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.843723773956299,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       282.8835458755493,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6754708290100098,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.759801149368286,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6711652278900146,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.372419595718384,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.684436321258545,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.920243978500366,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.030949831008911,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.954099178314209,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.760239839553833,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5364482402801514,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6683387756347656,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9564247131347656,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5815043449401855,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.253296852111816,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.668962001800537,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.929504156112671,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.048418760299683,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8241567611694336,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.078517913818359,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5308797359466553,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.717790126800537,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6672000885009766,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.36125111579895,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6629579067230225,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.029800653457642,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6788673400878906,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.632537603378296,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.229649066925049,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.793485403060913,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.703537940979004,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.868201732635498,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6827211380004883,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.179302215576172,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5294582843780518,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.863398790359497,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8375682830810547,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.656111478805542,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.667653799057007,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6906142234802246,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       260.29067873954773,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.605090856552124,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6607306003570557,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       6.978400230407715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.705528974533081,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8228371143341064,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.146059989929199,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6677627563476562,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.124673843383789,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.468088626861572,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.694268226623535,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.090676546096802,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.842165231704712,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.615593194961548,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.84822154045105,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6871337890625,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.697450876235962,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.7940754890441895,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.675856351852417,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.1094536781311035,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.659118413925171,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6738569736480713,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9776766300201416,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.595843553543091,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7149288654327393,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.810771942138672,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.805229902267456,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.912998914718628,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.673764705657959,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6670243740081787,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.670501232147217,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.675086259841919,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.8603925704956055,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9234890937805176,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.307585954666138,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.673971652984619,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.733140707015991,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6947154998779297,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7720704078674316,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.460222959518433,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       268.2784044742584,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.537520170211792,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.086101055145264,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7920126914978027,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.25760555267334,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.400486469268799,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.5327372550964355,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6683273315429688,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.427438020706177,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.932512998580933,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.864494562149048,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.662473440170288,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.665327787399292,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.535162925720215,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.796424627304077,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.512376070022583,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8410699367523193,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.916715145111084,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.417297124862671,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.173470973968506,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.916689395904541,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.615582227706909,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.672025680541992,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8470964431762695,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.822141170501709,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.132974863052368,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6779634952545166,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.367546319961548,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.665607452392578,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.663867950439453,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.785090923309326,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.575103759765625,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8875908851623535,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7014920711517334,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6767399311065674,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6705985069274902,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7380528450012207,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.669579029083252,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.564431667327881,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.659433841705322,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       275.6346650123596,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.242079973220825,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.996636152267456,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7814865112304688,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.561622142791748,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6750547885894775,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.67232084274292,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.389596939086914,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.65755295753479,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.817900896072388,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.671800136566162,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8054988384246826,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.781794548034668,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6676127910614014,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.631753444671631,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.077137470245361,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.534646272659302,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.81629753112793,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.474386930465698,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.519698619842529,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8182427883148193,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.459801197052002,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.190524339675903,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.785505533218384,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.047178506851196,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.693903684616089,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.535181045532227,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.660269021987915,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9380621910095215,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.667137384414673,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.675557851791382,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.946711540222168,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.674938440322876,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6651177406311035,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.674659252166748,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7097787857055664,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6603469848632812,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.20470666885376,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.710012674331665,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.178187370300293
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     ]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m --- Timing Summary ---
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_runs": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "dataset_loading": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_average": 2.326582193374634,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_min": 2.326582193374634,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_max": 2.326582193374634,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_total": 2.326582193374634
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "model_loading": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_average": 26.92659616470337,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_min": 26.92659616470337,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_max": 26.92659616470337,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_total": 26.92659616470337
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_average": 4257.742622852325,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_min": 4257.742622852325,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_max": 4257.742622852325,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_total": 4257.742622852325
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_run_time": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_average": 4286.995801210403,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_min": 4286.995801210403,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_max": 4286.995801210403,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_total": 4286.995801210403
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "checkpoint_saving": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_checkpoints_saved": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_checkpoint_save_time": 1814.525184392929,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_save_time_per_checkpoint": 362.9050368785858,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_times_count": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_min": 350.09020495414734,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_max": 373.21482944488525,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_average": 362.9050368785858
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "batch_sampling": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_batch_samples": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_batch_sample_time": 126.65879392623901,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_sample_time_per_batch": 5.066351757049561,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_times_count": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_min": 0.025083065032958984,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_max": 31.636186599731445,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_average": 5.066351757049561
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training_steps": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_training_steps": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_training_step_time": 1878.2480072975159,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_step_time_per_step": 9.391240036487579,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_times_count": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_min": 3.512376070022583,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_max": 282.8835458755493,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_average": 9.391240036487579
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 0.94s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 0.94s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 0.94s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 0.94s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 4282.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4282.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4282.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4282.96s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 9.39s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 282.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1878.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 5.06s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 31.62s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 126.48s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 362.91s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 350.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 373.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1814.56s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 4286.76s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 4286.76s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 4286.76s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 4286.76s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.99s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.99s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.99s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.99s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.00s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.00s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.00s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.00s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4282.75s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4282.75s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4282.75s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4282.75s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 9.39s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.53s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 282.96s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1878.74s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 5.07s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 31.64s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 126.74s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 362.90s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 350.08s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 373.21s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1814.49s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4285.75s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4285.75s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4285.75s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4285.75s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.04s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.04s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.04s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.04s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.07s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.07s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.07s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.07s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4282.62s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4282.62s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4282.62s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4282.62s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 9.40s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.53s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 282.97s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1880.06s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 5.07s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 31.63s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 126.84s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 362.90s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 350.08s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 373.22s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1814.51s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4285.73s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4285.73s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4285.73s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4285.73s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(head, rank=0, pid=3442)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3442)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 3.07 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 3.06 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 3.09 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 3.07 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 3.10 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 3.12 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 3.07 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 3.04 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 3.04 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 3.12 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 3.06 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 3.07 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 3.05 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 3.07 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 3.13 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3442)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  8.30it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  7.57it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  7.65it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  9.43it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  9.55it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  7.94it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  7.38it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  7.42it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  9.12it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  9.31it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00, 10.14it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  8.15it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  8.21it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  9.13it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  7.63it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:01,  2.95it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  9.52it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  8.70it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  8.10it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  8.82it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  8.62it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  8.07it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  5.28it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  7.81it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  7.93it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00, 13.42it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  9.10it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  8.92it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  8.46it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  8.44it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  8.78it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  8.77it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  8.93it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  8.99it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  9.30it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  8.39it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  8.30it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  4.87it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.08it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.24it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.33it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.11it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.38it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.08it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.21it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  8.83it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 10.57it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.83it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 10.99it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  9.02it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.62it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.58it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.74it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.66it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.68it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.82it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.36it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.37it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.36it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.39it/s]
[36m(head, rank=0, pid=3442)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  6.97it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.68it/s]
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.66 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.66 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.67 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.64 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.64 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.65 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.65 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.66 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.66 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.66 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.67 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.68 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.82 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 7.32 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 103.46it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.00 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:09<00:39,  9.86s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:10<00:41, 10.32s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:19<00:28,  9.56s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:20<00:30, 10.01s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:28<00:19,  9.51s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:30<00:20, 10.18s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:38<00:09,  9.46s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:47<00:00,  9.49s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:47<00:00,  9.52s/it]
[36m(head, rank=0, pid=3442)[0m Completed Load model in 48.62 seconds
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:39<00:09,  9.85s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:48<00:00,  9.38s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:48<00:00,  9.68s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 49.44 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:36,701] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:37,520] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:37,521] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:37,521] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:37,526] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:37,539] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:37,547] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:37,598] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:37,927] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:38,784] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:38,793] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:38,801] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:38,802] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:38,813] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:38,829] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 02:31:38,863] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:01,455] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:01,455] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:01,465] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:01,466] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:01,466] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:01,468] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:01,470] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:01,474] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:02,677] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:02,690] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:02,691] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:02,692] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:02,704] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:02,708] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:02,709] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 02:32:02,849] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   0%|          | 0/25 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3442)[0m   4%|▍         | 1/25 [00:39<15:51, 39.65s/it]
[36m(head, rank=0, pid=3442)[0m   8%|▊         | 2/25 [01:16<14:33, 37.96s/it]
[36m(head, rank=0, pid=3442)[0m  12%|█▏        | 3/25 [01:52<13:39, 37.27s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  16%|█▌        | 4/25 [02:29<12:54, 36.88s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  20%|██        | 5/25 [03:06<12:22, 37.12s/it]Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 262.73 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 262.73s (Total: 262.73s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 262.73 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 262.73s (Total: 262.73s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 262.71 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 262.71s (Total: 262.71s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 262.72 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 262.72s (Total: 262.72s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 262.73 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 262.73s (Total: 262.73s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 262.73 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 262.73s (Total: 262.73s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 262.73 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 262.73s (Total: 262.73s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 262.73 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 262.73s (Total: 262.73s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 262.73 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 262.73s (Total: 262.73s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 262.73 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 262.73s (Total: 262.73s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 262.73 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 262.73s (Total: 262.73s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 262.74 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 262.74s (Total: 262.74s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 262.74 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 262.74s (Total: 262.74s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 262.74 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 262.74s (Total: 262.74s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 262.75 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 262.75s (Total: 262.75s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 464.31 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 464.31s (Total: 464.31s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  24%|██▍       | 6/25 [11:28<1:01:46, 195.10s/it]
[36m(head, rank=0, pid=3442)[0m  28%|██▊       | 7/25 [12:05<43:01, 143.43s/it]  
[36m(head, rank=0, pid=3442)[0m  32%|███▏      | 8/25 [12:42<31:03, 109.64s/it]
[36m(head, rank=0, pid=3442)[0m  36%|███▌      | 9/25 [13:19<23:07, 86.72s/it]  40%|████      | 10/25 [13:54<17:40, 70.71s/it]Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m                                                {'loss': 125.3922, 'grad_norm': 49.56791305541992, 'learning_rate': 1.2800000000000001e-05, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint... 40%|████      | 10/25 [13:54<17:40, 70.71s/it]
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 256.62 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 256.62s (Total: 519.35s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 256.62 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 256.62s (Total: 519.35s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 256.63 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 256.63s (Total: 519.35s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 256.63 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 256.63s (Total: 519.34s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 256.63 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 256.63s (Total: 519.36s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 256.63 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 256.63s (Total: 519.36s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 256.64 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 256.64s (Total: 519.36s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 256.64 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 256.64s (Total: 519.37s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 256.64 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 256.64s (Total: 519.38s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 256.64 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 256.64s (Total: 519.38s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 256.65 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 256.65s (Total: 519.39s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 256.65 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 256.65s (Total: 519.40s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 256.65 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 256.65s (Total: 519.38s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 256.66 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 256.66s (Total: 519.39s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 256.66 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 256.66s (Total: 519.40s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 440.80 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 440.80s (Total: 905.11s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  44%|████▍     | 11/25 [21:53<45:43, 195.97s/it]
[36m(head, rank=0, pid=3442)[0m  48%|████▊     | 12/25 [22:32<32:04, 148.06s/it]
[36m(head, rank=0, pid=3442)[0m  52%|█████▏    | 13/25 [23:08<22:48, 114.07s/it]
[36m(head, rank=0, pid=3442)[0m  56%|█████▌    | 14/25 [23:44<16:37, 90.69s/it] Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  60%|██████    | 15/25 [24:22<12:25, 74.52s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 241.85 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 241.85s (Total: 761.23s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 241.85 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 241.85s (Total: 761.26s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 241.85 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 241.85s (Total: 761.23s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 241.86 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 241.86s (Total: 761.23s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 241.86 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 241.86s (Total: 761.23s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 241.85 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 241.85s (Total: 761.25s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 241.86 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 241.86s (Total: 761.25s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 241.83 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 241.83s (Total: 761.18s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 241.83 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 241.83s (Total: 761.18s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 241.84 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 241.84s (Total: 761.20s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 241.83 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 241.83s (Total: 761.18s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 241.84 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 241.84s (Total: 761.20s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 241.84 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 241.84s (Total: 761.21s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 241.85 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 241.85s (Total: 761.20s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 241.86 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 241.86s (Total: 761.25s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 421.36 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 421.36s (Total: 1326.47s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  64%|██████▍   | 16/25 [32:03<28:39, 191.09s/it]
[36m(head, rank=0, pid=3442)[0m  68%|██████▊   | 17/25 [32:41<19:19, 144.88s/it]
[36m(head, rank=0, pid=3442)[0m  72%|███████▏  | 18/25 [33:18<13:07, 112.50s/it]
[36m(head, rank=0, pid=3442)[0m  76%|███████▌  | 19/25 [33:54<08:57, 89.67s/it]  80%|████████  | 20/25 [34:29<06:06, 73.25s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m                                                {'loss': 94.3979, 'grad_norm': 22.57253646850586, 'learning_rate': 4.800000000000001e-06, 'num_tokens': 19076177.0, 'epoch': 0.05}
[36m(head, rank=0, pid=3442)[0m  80%|████████  | 20/25 [34:29<06:06, 73.25s/it]Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 244.91 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 244.91s (Total: 1006.09s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 244.91 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 244.91s (Total: 1006.09s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 244.91 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 244.91s (Total: 1006.11s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 244.92 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 244.92s (Total: 1006.11s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 244.92 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 244.92s (Total: 1006.09s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 244.92 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 244.92s (Total: 1006.12s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 244.92 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 244.92s (Total: 1006.12s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 244.92 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 244.92s (Total: 1006.16s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 244.92 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 244.92s (Total: 1006.17s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 244.93 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 244.93s (Total: 1006.16s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 244.93 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 244.93s (Total: 1006.17s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 244.93 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 244.93s (Total: 1006.19s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 244.93 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 244.93s (Total: 1006.18s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 244.93 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 244.93s (Total: 1006.19s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 244.94 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 244.94s (Total: 1006.17s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 457.47 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 457.47s (Total: 1783.94s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  84%|████████▍ | 21/25 [42:44<13:19, 199.89s/it]
[36m(head, rank=0, pid=3442)[0m  88%|████████▊ | 22/25 [43:21<07:32, 150.94s/it]
[36m(head, rank=0, pid=3442)[0m  92%|█████████▏| 23/25 [44:01<03:55, 117.62s/it]
[36m(head, rank=0, pid=3442)[0m  96%|█████████▌| 24/25 [44:37<01:33, 93.05s/it] Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 100%|██████████| 25/25 [45:13<00:00, 76.08s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 273.22 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 273.22s (Total: 1279.30s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 273.22 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 273.22s (Total: 1279.34s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 273.23 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 273.23s (Total: 1279.33s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 273.23 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 273.23s (Total: 1279.35s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 273.23 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 273.23s (Total: 1279.32s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 273.23 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 273.23s (Total: 1279.36s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 273.24 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 273.24s (Total: 1279.33s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 273.23 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 273.23s (Total: 1279.39s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 273.24 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 273.24s (Total: 1279.40s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 273.25 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 273.25s (Total: 1279.41s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 273.25 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 273.25s (Total: 1279.44s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 273.25 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 273.25s (Total: 1279.41s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 273.25 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 273.25s (Total: 1279.43s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 273.25 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 273.25s (Total: 1279.43s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 273.26 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 273.26s (Total: 1279.42s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 3318.70 secondsCompleted Training in 3318.79 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 3318.66 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 3271.55 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 3318.70 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1279.42s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 255.88s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 241.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 273.26s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 159.49s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 6.38s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.43s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 48.46s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1450.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 7.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 173.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1279.43s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 255.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 241.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 273.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 158.90s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 6.36s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.50s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 48.23s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1450.43s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 7.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 172.95s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1279.40s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 255.88s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 241.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 273.24s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 158.68s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 6.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.44s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 48.24s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1448.38s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1279.43s  - Average training step time: 7.24s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 255.89s  - Min training step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 241.85s  - Max training step time: 172.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1  - Max save time: 273.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 158.47s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 6.34s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 3315.71 seconds  - Min batch sample time: 0.48s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 48.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1449.20s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 7.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 173.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1279.44s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 255.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 241.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 273.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 158.13s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 6.33s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.34s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 48.33s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1451.39s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 7.26s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 172.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 3318.72 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1279.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 255.88s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 241.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 273.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 158.37s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 6.33s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 48.19s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1451.33s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 7.26s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 172.87s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1279.39s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 255.88s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 241.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 273.23s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 158.48s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 6.34s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 48.16s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1449.67s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 7.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 172.91s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 3318.80 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1279.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 255.88s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 241.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 273.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 159.39s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 6.38s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.44s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 48.21s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1450.24s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 7.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 173.05s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 474.10 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 474.10s (Total: 2258.04s)
[36m(head, rank=0, pid=3442)[0m                                                {'train_runtime': 3187.9718, 'train_samples_per_second': 1.004, 'train_steps_per_second': 0.008, 'train_loss': 106.388515625, 'num_tokens': 23880036.0, 'epoch': 0.07}
[36m(head, rank=0, pid=3442)[0m 100%|██████████| 25/25 [53:07<00:00, 76.08s/it]100%|██████████| 25/25 [53:07<00:00, 127.52s/it]
[36m(head, rank=0, pid=3442)[0m Completed Training in 3318.75 seconds
[36m(head, rank=0, pid=3442)[0m Completed Training in 3272.38 seconds
[36m(head, rank=0, pid=3442)[0m Completed Training in 3318.67 secondsCheckpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 2258.04s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 451.61s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 421.36s
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:  - Max save time: 474.10s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5  - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 16.61s  - Total checkpoint save time: 1279.36s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 0.66s  - Average save time per checkpoint: 255.87s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.43s  - Min save time: 241.84s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 1.03s  - Max save time: 273.23s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200  - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 813.92s
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 157.84s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 4.07s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 6.31s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.51s  - Min batch sample time: 0.43s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 7.67s  - Max batch sample time: 47.98s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1451.20s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 7.26s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 173.05s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Completed Training in 3318.65 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1279.30s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 255.86s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 241.83s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 273.22s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 158.85s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 6.35s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.54s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 48.25s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1451.07s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 7.26s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.53s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 173.10s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1279.33s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 255.87s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 241.83s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 273.24s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 158.84s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 6.35s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.50s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 48.18s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1450.07s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 7.25s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 173.15s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Completed Training in 3318.65 secondsCompleted Training in 3318.70 seconds
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Completed Training in 3318.61 seconds
[36m(head, rank=0, pid=3442)[0m Completed Training in 3318.70 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1279.34s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 255.87s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 241.84s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 273.22s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 158.99s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 6.36s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.36s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 48.46s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1450.10s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 7.25s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.54s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 173.05s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1279.33s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 255.87s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 241.84s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 273.23s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 158.93s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 6.36s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.43s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 48.04s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1449.90s
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5  - Average training step time: 7.25s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.51s  - Total checkpoint save time: 1279.35s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 173.03s  - Average save time per checkpoint: 255.87s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1  - Min save time: 241.85s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Max save time: 273.23s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 159.08s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 6.36s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.39s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 48.18s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1449.85s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 7.25s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 173.03s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1279.32s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 255.86s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 241.83s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 273.23s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 159.54s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 6.38s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.51s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 48.22s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1448.92s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 7.24s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 172.85s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3/training_run_1_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3/training_run_3_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3/training_run_6_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3/training_run_0_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3/training_run_4_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3/training_run_2_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3/training_run_5_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3/training_run_7_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3/training_run_6_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 3.12s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 3.12s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 3.12s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 3.12s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 49.44s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 49.44s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 49.44s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 49.44s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 3271.55s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 3271.55s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 3271.55s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 3271.55s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 7.24s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 172.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1448.38s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.35s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.44s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 48.24s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 158.68s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 255.88s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 241.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 273.24s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1279.40s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 3324.12s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 3324.12s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 3324.12s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 3324.12s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_0.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m --- Training Run 1 Info (Directory: /checkpoints_s3) ---
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 3.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 3.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 3.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 3.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 3318.79s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 3318.79s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 3318.79s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 3318.79s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 7.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 172.95s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1450.43s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.36s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.50s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 48.23s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 158.90s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 255.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 241.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 273.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1279.43s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 3323.56s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 3323.56s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 3323.56s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 3323.56s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "run_id": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "timestamp": "2025-08-04T02:30:16.067465",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "checkpoint_dir": "/checkpoints_s3",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training_status": "completed",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "output_dir": "/checkpoints_s3",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "dataset_load_time": 3.1219489574432373,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "model_load_time": 49.443859577178955,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training_time": 3271.5522236824036,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_time": 3324.1180322170258,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "error": null,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "num_checkpoints_saved": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_checkpoint_save_time": 1279.4038336277008,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "average_checkpoint_save_time": 255.88076672554016,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "min_checkpoint_save_time": 241.86017608642578,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "max_checkpoint_save_time": 273.23559308052063,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     262.7251625061035,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     256.6624150276184,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     241.86017608642578,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     244.92048692703247,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     273.23559308052063
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "num_batch_samples": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_batch_sample_time": 158.6773648262024,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "average_batch_sample_time": 6.347094593048095,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "min_batch_sample_time": 0.4403049945831299,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "max_batch_sample_time": 48.23834037780762,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.44299745559692383,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     1.0121574401855469,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.6946630477905273,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.8166942596435547,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.7991502285003662,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     33.23867344856262,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.7510347366333008,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.7647843360900879,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.6705911159515381,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.5986123085021973,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     31.507477521896362,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.676586389541626,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.6345481872558594,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.5468006134033203,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.6241214275360107,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     31.477567434310913,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.5825564861297607,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.5891740322113037,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.7647266387939453,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.7441651821136475,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     48.23834037780762,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.7266123294830322,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.6395721435546875,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.4403049945831299,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.6954526901245117
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "num_training_steps": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_training_step_time": 1448.3841090202332,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "average_training_step_time": 7.2419205451011655,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "min_training_step_time": 3.5086004734039307,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "max_training_step_time": 172.85317254066467,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "individual_training_step_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.095972299575806,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8352744579315186,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.377690076828003,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.664755344390869,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.722215890884399,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8533565998077393,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.675532579421997,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.668330669403076,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.009481430053711,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.643975257873535,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6594159603118896,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.667940616607666,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6614744663238525,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.907278060913086,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.666224479675293,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.535798072814941,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.401745319366455,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.748253345489502,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8463709354400635,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6704702377319336,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.330034971237183,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.671680212020874,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.566232681274414,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.694287061691284,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.967939853668213,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.672391176223755,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7934494018554688,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.696962833404541,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.578510046005249,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6812937259674072,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7975199222564697,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.33853554725647,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.85681939125061,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.865225076675415,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6843435764312744,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.041748285293579,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.418869495391846,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.342301845550537,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.665015697479248,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.835632085800171,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     172.85317254066467,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.660093307495117,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.7670440673828125,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6728367805480957,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.494616746902466,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6630938053131104,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.821685552597046,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.017667770385742,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.893883228302002,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.781256914138794,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5393688678741455,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6638336181640625,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.94626522064209,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5872457027435303,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.2548277378082275,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.671013116836548,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.97481369972229,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.107132911682129,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.818244457244873,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.12868595123291,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.521540641784668,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.703559398651123,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6668529510498047,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.375903844833374,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.791722059249878,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.109347105026245,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.702460765838623,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.641172409057617,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.234598636627197,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.8015241622924805,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6727285385131836,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8474326133728027,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9262611865997314,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.187294006347656,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5418472290039062,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9139420986175537,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.904418706893921,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.648942470550537,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.673703193664551,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6833994388580322,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     156.94617295265198,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.607828855514526,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6660351753234863,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     7.452484130859375,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.656132221221924,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8196473121643066,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.091250896453857,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6658294200897217,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.140710353851318,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.45854377746582,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.685868501663208,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.111569881439209,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.833923101425171,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6071407794952393,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8250949382781982,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.687783718109131,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.794564723968506,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.774856328964233,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.672508716583252,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.103418588638306,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6573596000671387,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.667603015899658,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.978393793106079,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5701911449432373,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9505910873413086,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8003756999969482,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.068619251251221,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.903794765472412,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6651928424835205,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6678595542907715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.66698956489563,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6645567417144775,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.898447513580322,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8853816986083984,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.284979343414307,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.672896146774292,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7757623195648193,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6888012886047363,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7733571529388428,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.4563939571380615,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     156.1199562549591,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5115392208099365,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.074060916900635,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.829474449157715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.255335807800293,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.344017028808594,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.534534454345703,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6648802757263184,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.619636058807373,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.944024562835693,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.863347768783569,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6924633979797363,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6637110710144043,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5425429344177246,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.831542491912842,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5086004734039307,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9727094173431396,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9172441959381104,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.4025163650512695,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.168955564498901,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.922588586807251,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.604442596435547,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.665667772293091,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.872041940689087,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8192644119262695,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.140849828720093,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6620891094207764,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.3705894947052,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6604905128479004,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6720101833343506,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.807771682739258,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.574263572692871,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.893829345703125,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6709811687469482,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.668353319168091,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.666510581970215,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7585294246673584,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6651766300201416,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5628743171691895,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.662513494491577,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     168.43957233428955,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.274756669998169,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.003454685211182,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.779428482055664,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5699033737182617,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6616876125335693,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6705596446990967,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.789283752441406,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.781540870666504,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.76500391960144,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.660353422164917,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.81762957572937,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.739443778991699,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.661639451980591,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.642771005630493,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.077324867248535,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.565345048904419,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.8769707679748535,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.482592344284058,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.521880865097046,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8296854496002197,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.458897113800049,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.190767049789429,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.767611265182495,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.431005001068115,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7385475635528564,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.577759265899658,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6615102291107178,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9665448665618896,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.670180082321167,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.679224967956543,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.942047119140625,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.158606052398682,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6698179244995117,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.673210620880127,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6819205284118652,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6624510288238525,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.192361354827881,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.714391469955444,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.1798036098480225
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   ]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m --- All Training Runs Summary ---
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "run_id": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "timestamp": "2025-08-04T02:30:16.067465",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_dir": "/checkpoints_s3",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_status": "completed",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "output_dir": "/checkpoints_s3",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_time": 3.1219489574432373,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_time": 49.443859577178955,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_time": 3271.5522236824036,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_time": 3324.1180322170258,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "error": null,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "num_checkpoints_saved": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_checkpoint_save_time": 1279.4038336277008,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_checkpoint_save_time": 255.88076672554016,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "min_checkpoint_save_time": 241.86017608642578,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "max_checkpoint_save_time": 273.23559308052063,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       262.7251625061035,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       256.6624150276184,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       241.86017608642578,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       244.92048692703247,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       273.23559308052063
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "num_batch_samples": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_batch_sample_time": 158.6773648262024,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_batch_sample_time": 6.347094593048095,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "min_batch_sample_time": 0.4403049945831299,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "max_batch_sample_time": 48.23834037780762,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.44299745559692383,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       1.0121574401855469,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.6946630477905273,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.8166942596435547,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.7991502285003662,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       33.23867344856262,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.7510347366333008,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.7647843360900879,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.6705911159515381,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.5986123085021973,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       31.507477521896362,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.676586389541626,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.6345481872558594,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.5468006134033203,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.6241214275360107,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       31.477567434310913,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.5825564861297607,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.5891740322113037,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.7647266387939453,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.7441651821136475,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       48.23834037780762,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.7266123294830322,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.6395721435546875,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.4403049945831299,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.6954526901245117
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "num_training_steps": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_training_step_time": 1448.3841090202332,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_training_step_time": 7.2419205451011655,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "min_training_step_time": 3.5086004734039307,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "max_training_step_time": 172.85317254066467,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "individual_training_step_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.095972299575806,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8352744579315186,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.377690076828003,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.664755344390869,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.722215890884399,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8533565998077393,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.675532579421997,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.668330669403076,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.009481430053711,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.643975257873535,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6594159603118896,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.667940616607666,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6614744663238525,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.907278060913086,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.666224479675293,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.535798072814941,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.401745319366455,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.748253345489502,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8463709354400635,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6704702377319336,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.330034971237183,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.671680212020874,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.566232681274414,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.694287061691284,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.967939853668213,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.672391176223755,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7934494018554688,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.696962833404541,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.578510046005249,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6812937259674072,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7975199222564697,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.33853554725647,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.85681939125061,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.865225076675415,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6843435764312744,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.041748285293579,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.418869495391846,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.342301845550537,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.665015697479248,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.835632085800171,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       172.85317254066467,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.660093307495117,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.7670440673828125,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6728367805480957,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.494616746902466,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6630938053131104,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.821685552597046,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.017667770385742,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.893883228302002,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.781256914138794,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5393688678741455,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6638336181640625,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.94626522064209,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5872457027435303,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.2548277378082275,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.671013116836548,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.97481369972229,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.107132911682129,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.818244457244873,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.12868595123291,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.521540641784668,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.703559398651123,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6668529510498047,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.375903844833374,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.791722059249878,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.109347105026245,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.702460765838623,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.641172409057617,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.234598636627197,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.8015241622924805,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6727285385131836,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8474326133728027,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9262611865997314,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.187294006347656,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5418472290039062,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9139420986175537,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.904418706893921,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.648942470550537,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.673703193664551,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6833994388580322,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       156.94617295265198,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.607828855514526,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6660351753234863,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       7.452484130859375,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.656132221221924,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8196473121643066,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.091250896453857,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6658294200897217,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.140710353851318,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.45854377746582,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.685868501663208,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.111569881439209,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.833923101425171,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6071407794952393,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8250949382781982,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.687783718109131,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.794564723968506,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.774856328964233,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.672508716583252,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.103418588638306,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6573596000671387,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.667603015899658,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.978393793106079,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5701911449432373,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9505910873413086,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8003756999969482,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.068619251251221,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.903794765472412,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6651928424835205,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6678595542907715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.66698956489563,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6645567417144775,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.898447513580322,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8853816986083984,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.284979343414307,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.672896146774292,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7757623195648193,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6888012886047363,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7733571529388428,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.4563939571380615,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       156.1199562549591,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5115392208099365,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.074060916900635,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.829474449157715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.255335807800293,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.344017028808594,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.534534454345703,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6648802757263184,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.619636058807373,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.944024562835693,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.863347768783569,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6924633979797363,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6637110710144043,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5425429344177246,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.831542491912842,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5086004734039307,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9727094173431396,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9172441959381104,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.4025163650512695,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.168955564498901,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.922588586807251,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.604442596435547,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.665667772293091,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.872041940689087,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8192644119262695,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.140849828720093,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6620891094207764,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.3705894947052,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6604905128479004,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6720101833343506,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.807771682739258,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.574263572692871,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.893829345703125,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6709811687469482,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.668353319168091,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.666510581970215,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7585294246673584,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6651766300201416,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5628743171691895,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.662513494491577,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       168.43957233428955,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.274756669998169,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.003454685211182,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.779428482055664,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5699033737182617,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6616876125335693,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6705596446990967,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.789283752441406,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.781540870666504,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.76500391960144,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.660353422164917,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.81762957572937,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.739443778991699,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.661639451980591,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.642771005630493,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.077324867248535,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.565345048904419,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.8769707679748535,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.482592344284058,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.521880865097046,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8296854496002197,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.458897113800049,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.190767049789429,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.767611265182495,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.431005001068115,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7385475635528564,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.577759265899658,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6615102291107178,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9665448665618896,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.670180082321167,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.679224967956543,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.942047119140625,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.158606052398682,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6698179244995117,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.673210620880127,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6819205284118652,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6624510288238525,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.192361354827881,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.714391469955444,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.1798036098480225
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     ]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m --- Timing Summary ---
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_runs": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "dataset_loading": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_average": 3.1219489574432373,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_min": 3.1219489574432373,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_max": 3.1219489574432373,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_total": 3.1219489574432373
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "model_loading": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_average": 49.443859577178955,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_min": 49.443859577178955,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_max": 49.443859577178955,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_total": 49.443859577178955
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_average": 3271.5522236824036,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_min": 3271.5522236824036,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_max": 3271.5522236824036,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_total": 3271.5522236824036
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_run_time": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_average": 3324.1180322170258,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_min": 3324.1180322170258,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_max": 3324.1180322170258,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_total": 3324.1180322170258
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "checkpoint_saving": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_checkpoints_saved": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_checkpoint_save_time": 1279.4038336277008,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_save_time_per_checkpoint": 255.88076672554016,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_times_count": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_min": 241.86017608642578,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_max": 273.23559308052063,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_average": 255.88076672554016
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "batch_sampling": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_batch_samples": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_batch_sample_time": 158.6773648262024,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_sample_time_per_batch": 6.347094593048095,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_times_count": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_min": 0.4403049945831299,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_max": 48.23834037780762,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_average": 6.347094593048095
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training_steps": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_training_steps": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_training_step_time": 1448.3841090202332,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_step_time_per_step": 7.2419205451011655,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_times_count": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_min": 3.5086004734039307,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_max": 172.85317254066467,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_average": 7.2419205451011655
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 3.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 3.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 3.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 3.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.68s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.68s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.68s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.68s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 3318.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 3318.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 3318.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 3318.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 7.26s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 172.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1451.39s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.33s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.34s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 48.33s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 158.13s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 255.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 241.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 273.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1279.44s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 3323.45s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 3323.45s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 3323.45s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 3323.45s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 3.09s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 3.09s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 3.09s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 3.09s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.67s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.67s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.67s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.67s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 3318.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 3318.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 3318.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 3318.70s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 7.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 173.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1450.11s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.38s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.43s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 48.46s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 159.49s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 255.88s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 241.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 273.26s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1279.42s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 3323.46s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 3323.46s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 3323.46s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 3323.46s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 3.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 3.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 3.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 3.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.82s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.82s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.82s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.82s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 3318.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 3318.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 3318.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 3318.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 7.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 173.08s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1449.20s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.34s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.48s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 48.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 158.47s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 255.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 241.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 273.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1279.43s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 3323.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 3323.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 3323.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 3323.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_4.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 7.32s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 7.32s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 7.32s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 7.32s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 3315.71s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 3315.71s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 3315.71s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 3315.71s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 7.26s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 172.87s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1451.33s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.33s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 48.19s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 158.37s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 255.88s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 241.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 273.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1279.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 3324.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 3324.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 3324.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 3324.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3.04s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3.04s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3.04s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3.04s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.67s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.67s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.67s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.67s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3318.65s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3318.65s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3318.65s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3318.65s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 7.25s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.52s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 173.15s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1450.07s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 6.35s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.50s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 48.18s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 158.84s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 255.87s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 241.83s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 273.24s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1279.33s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 3323.35s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 3323.35s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 3323.35s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 3323.35s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3.07s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3.07s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3.07s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3.07s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.65s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.65s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.65s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.65s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3318.67s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3318.67s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3318.67s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3318.67s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 7.26s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.53s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 173.10s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1451.07s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 6.35s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.54s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 48.25s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 158.85s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 255.86s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 241.83s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 273.22s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1279.30s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 3323.40s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 3323.40s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 3323.40s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 3323.40s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3.06s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3.06s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3.06s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3.06s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.66s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.66s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.66s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.66s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3318.65s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3318.65s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3318.65s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3318.65s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 7.25s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.54s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 173.05s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1450.10s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 6.36s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.36s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 48.46s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 158.99s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 255.87s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 241.84s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 273.22s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1279.34s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 3323.37s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 3323.37s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 3323.37s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 3323.37s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3.13s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3.13s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3.13s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3.13s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.64s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.64s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.64s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.64s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3318.61s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3318.61s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3318.61s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3318.61s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 7.25s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 173.03s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1449.90s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 6.36s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.43s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 48.04s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 158.93s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 255.87s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 241.84s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 273.23s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1279.33s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 3323.38s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 3323.38s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 3323.38s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 3323.38s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3.05s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3.05s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3.05s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3.05s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.65s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.65s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.65s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.65s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3318.70s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3318.70s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3318.70s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3318.70s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 7.25s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 173.03s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1449.85s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 6.36s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.39s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 48.18s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 159.08s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 255.87s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 241.85s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 273.23s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1279.35s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 3323.40s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 3323.40s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 3323.40s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 3323.40s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_5.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3.07s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3.07s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3.07s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3.07s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.64s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.64s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.64s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.64s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3318.70s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3318.70s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3318.70s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3318.70s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 7.24s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.52s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 172.85s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1448.92s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 6.38s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.51s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 48.22s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 159.54s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 255.86s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 241.83s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 273.23s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1279.32s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 3323.41s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 3323.41s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 3323.41s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 3323.41s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3.04s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3.04s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3.04s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3.04s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.66s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.66s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.66s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.66s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3318.75s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3318.75s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3318.75s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3318.75s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 7.26s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 173.05s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1451.20s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 6.31s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.43s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 47.98s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 157.84s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 255.87s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 241.84s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 273.23s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1279.36s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 3323.45s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 3323.45s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 3323.45s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 3323.45s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 3.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 3.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 3.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 3.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 3318.72s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 3318.72s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 3318.72s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 3318.72s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 7.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 172.91s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1449.67s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.34s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 48.16s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 158.48s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 255.88s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 241.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 273.23s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1279.39s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 3323.45s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 3323.45s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 3323.45s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 3323.45s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 3.06s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 3.06s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 3.06s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 3.06s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.66s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 3318.80s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 3318.80s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 3318.80s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 3318.80s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 7.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 173.05s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1450.24s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.38s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.44s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 48.21s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 159.39s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 255.88s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 241.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 273.25s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1279.41s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 3323.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 3323.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 3323.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 3323.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3.12s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3.12s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3.12s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3.12s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 48.62s
[36m(head, rank=0, pid=3442)[0m   • Min time: 48.62s
[36m(head, rank=0, pid=3442)[0m   • Max time: 48.62s
[36m(head, rank=0, pid=3442)[0m   • Total time: 48.62s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 3272.38s
[36m(head, rank=0, pid=3442)[0m   • Min time: 3272.38s
[36m(head, rank=0, pid=3442)[0m   • Max time: 3272.38s
[36m(head, rank=0, pid=3442)[0m   • Total time: 3272.38s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 4.07s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 7.67s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 813.92s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 0.66s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.43s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 1.03s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 16.61s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 451.61s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 421.36s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 474.10s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 2258.04s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 3324.11s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 3324.11s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 3324.11s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 3324.11s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m --- Training Run 1 Info (Directory: /checkpoints_s3) ---
[36m(head, rank=0, pid=3442)[0m {
[36m(head, rank=0, pid=3442)[0m   "run_id": 1,
[36m(head, rank=0, pid=3442)[0m   "timestamp": "2025-08-04T02:30:16.068039",
[36m(head, rank=0, pid=3442)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3442)[0m   "checkpoint_dir": "/checkpoints_s3",
[36m(head, rank=0, pid=3442)[0m   "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3442)[0m   "training_status": "completed",
[36m(head, rank=0, pid=3442)[0m   "output_dir": "/checkpoints_s3",
[36m(head, rank=0, pid=3442)[0m   "dataset_load_time": 3.1180226802825928,
[36m(head, rank=0, pid=3442)[0m   "model_load_time": 48.61657738685608,
[36m(head, rank=0, pid=3442)[0m   "training_time": 3272.375806570053,
[36m(head, rank=0, pid=3442)[0m   "total_time": 3324.1104066371918,
[36m(head, rank=0, pid=3442)[0m   "error": null,
[36m(head, rank=0, pid=3442)[0m   "num_checkpoints_saved": 5,
[36m(head, rank=0, pid=3442)[0m   "total_checkpoint_save_time": 2258.0382368564606,
[36m(head, rank=0, pid=3442)[0m   "average_checkpoint_save_time": 451.6076473712921,
[36m(head, rank=0, pid=3442)[0m   "min_checkpoint_save_time": 421.36059045791626,
[36m(head, rank=0, pid=3442)[0m   "max_checkpoint_save_time": 474.0977509021759,
[36m(head, rank=0, pid=3442)[0m   "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3442)[0m     464.30868124961853,
[36m(head, rank=0, pid=3442)[0m     440.7973666191101,
[36m(head, rank=0, pid=3442)[0m     421.36059045791626,
[36m(head, rank=0, pid=3442)[0m     457.47384762763977,
[36m(head, rank=0, pid=3442)[0m     474.0977509021759
[36m(head, rank=0, pid=3442)[0m   ],
[36m(head, rank=0, pid=3442)[0m   "num_batch_samples": 25,
[36m(head, rank=0, pid=3442)[0m   "total_batch_sample_time": 16.607704639434814,
[36m(head, rank=0, pid=3442)[0m   "average_batch_sample_time": 0.6643081855773926,
[36m(head, rank=0, pid=3442)[0m   "min_batch_sample_time": 0.4301433563232422,
[36m(head, rank=0, pid=3442)[0m   "max_batch_sample_time": 1.0295207500457764,
[36m(head, rank=0, pid=3442)[0m   "individual_batch_sample_times": [
[36m(head, rank=0, pid=3442)[0m     1.0295207500457764,
[36m(head, rank=0, pid=3442)[0m     0.5690951347351074,
[36m(head, rank=0, pid=3442)[0m     0.9281387329101562,
[36m(head, rank=0, pid=3442)[0m     0.7479639053344727,
[36m(head, rank=0, pid=3442)[0m     0.6385622024536133,
[36m(head, rank=0, pid=3442)[0m     0.9234836101531982,
[36m(head, rank=0, pid=3442)[0m     0.7065296173095703,
[36m(head, rank=0, pid=3442)[0m     0.6546268463134766,
[36m(head, rank=0, pid=3442)[0m     0.6749355792999268,
[36m(head, rank=0, pid=3442)[0m     0.7400646209716797,
[36m(head, rank=0, pid=3442)[0m     0.6539878845214844,
[36m(head, rank=0, pid=3442)[0m     0.7239606380462646,
[36m(head, rank=0, pid=3442)[0m     0.5918419361114502,
[36m(head, rank=0, pid=3442)[0m     0.7054438591003418,
[36m(head, rank=0, pid=3442)[0m     0.5687265396118164,
[36m(head, rank=0, pid=3442)[0m     0.4444084167480469,
[36m(head, rank=0, pid=3442)[0m     0.547680139541626,
[36m(head, rank=0, pid=3442)[0m     0.5927250385284424,
[36m(head, rank=0, pid=3442)[0m     0.4301433563232422,
[36m(head, rank=0, pid=3442)[0m     0.5732321739196777,
[36m(head, rank=0, pid=3442)[0m     0.4593231678009033,
[36m(head, rank=0, pid=3442)[0m     0.6249208450317383,
[36m(head, rank=0, pid=3442)[0m     0.5999593734741211,
[36m(head, rank=0, pid=3442)[0m     0.6028897762298584,
[36m(head, rank=0, pid=3442)[0m     0.8755404949188232
[36m(head, rank=0, pid=3442)[0m   ],
[36m(head, rank=0, pid=3442)[0m   "num_training_steps": 200,
[36m(head, rank=0, pid=3442)[0m   "total_training_step_time": 813.9187307357788,
[36m(head, rank=0, pid=3442)[0m   "average_training_step_time": 4.069593653678894,
[36m(head, rank=0, pid=3442)[0m   "min_training_step_time": 3.513488292694092,
[36m(head, rank=0, pid=3442)[0m   "max_training_step_time": 7.672798156738281,
[36m(head, rank=0, pid=3442)[0m   "individual_training_step_times": [
[36m(head, rank=0, pid=3442)[0m     5.408696889877319,
[36m(head, rank=0, pid=3442)[0m     4.224516153335571,
[36m(head, rank=0, pid=3442)[0m     4.374135494232178,
[36m(head, rank=0, pid=3442)[0m     3.6646506786346436,
[36m(head, rank=0, pid=3442)[0m     4.695664644241333,
[36m(head, rank=0, pid=3442)[0m     3.8565452098846436,
[36m(head, rank=0, pid=3442)[0m     3.5360941886901855,
[36m(head, rank=0, pid=3442)[0m     3.668941020965576,
[36m(head, rank=0, pid=3442)[0m     4.17244029045105,
[36m(head, rank=0, pid=3442)[0m     4.672351837158203,
[36m(head, rank=0, pid=3442)[0m     3.66336989402771,
[36m(head, rank=0, pid=3442)[0m     3.6689603328704834,
[36m(head, rank=0, pid=3442)[0m     3.6603689193725586,
[36m(head, rank=0, pid=3442)[0m     4.908206939697266,
[36m(head, rank=0, pid=3442)[0m     3.665113925933838,
[36m(head, rank=0, pid=3442)[0m     4.033595323562622,
[36m(head, rank=0, pid=3442)[0m     4.220582962036133,
[36m(head, rank=0, pid=3442)[0m     3.7450404167175293,
[36m(head, rank=0, pid=3442)[0m     3.775317907333374,
[36m(head, rank=0, pid=3442)[0m     3.673004150390625,
[36m(head, rank=0, pid=3442)[0m     4.302476644515991,
[36m(head, rank=0, pid=3442)[0m     3.673687696456909,
[36m(head, rank=0, pid=3442)[0m     4.562340974807739,
[36m(head, rank=0, pid=3442)[0m     3.695207357406616,
[36m(head, rank=0, pid=3442)[0m     5.0370872020721436,
[36m(head, rank=0, pid=3442)[0m     3.5824248790740967,
[36m(head, rank=0, pid=3442)[0m     3.7990975379943848,
[36m(head, rank=0, pid=3442)[0m     3.702152729034424,
[36m(head, rank=0, pid=3442)[0m     3.7279813289642334,
[36m(head, rank=0, pid=3442)[0m     3.681522846221924,
[36m(head, rank=0, pid=3442)[0m     3.823760509490967,
[36m(head, rank=0, pid=3442)[0m     4.3454954624176025,
[36m(head, rank=0, pid=3442)[0m     4.961686611175537,
[36m(head, rank=0, pid=3442)[0m     3.8650527000427246,
[36m(head, rank=0, pid=3442)[0m     3.6916773319244385,
[36m(head, rank=0, pid=3442)[0m     4.042714595794678,
[36m(head, rank=0, pid=3442)[0m     4.425193548202515,
[36m(head, rank=0, pid=3442)[0m     4.385880708694458,
[36m(head, rank=0, pid=3442)[0m     3.667921781539917,
[36m(head, rank=0, pid=3442)[0m     3.841768264770508,
[36m(head, rank=0, pid=3442)[0m     3.666067361831665,
[36m(head, rank=0, pid=3442)[0m     3.51458740234375,
[36m(head, rank=0, pid=3442)[0m     4.768497467041016,
[36m(head, rank=0, pid=3442)[0m     3.674201726913452,
[36m(head, rank=0, pid=3442)[0m     5.477250814437866,
[36m(head, rank=0, pid=3442)[0m     3.6602959632873535,
[36m(head, rank=0, pid=3442)[0m     3.8242807388305664,
[36m(head, rank=0, pid=3442)[0m     4.022038459777832,
[36m(head, rank=0, pid=3442)[0m     4.753447532653809,
[36m(head, rank=0, pid=3442)[0m     4.7832629680633545,
[36m(head, rank=0, pid=3442)[0m     3.6625633239746094,
[36m(head, rank=0, pid=3442)[0m     3.663895606994629,
[36m(head, rank=0, pid=3442)[0m     3.943683385848999,
[36m(head, rank=0, pid=3442)[0m     3.674084424972534,
[36m(head, rank=0, pid=3442)[0m     4.2752344608306885,
[36m(head, rank=0, pid=3442)[0m     3.668142795562744,
[36m(head, rank=0, pid=3442)[0m     5.085987091064453,
[36m(head, rank=0, pid=3442)[0m     4.105518102645874,
[36m(head, rank=0, pid=3442)[0m     3.8193888664245605,
[36m(head, rank=0, pid=3442)[0m     4.150400638580322,
[36m(head, rank=0, pid=3442)[0m     3.671936273574829,
[36m(head, rank=0, pid=3442)[0m     3.7046353816986084,
[36m(head, rank=0, pid=3442)[0m     3.6631076335906982,
[36m(head, rank=0, pid=3442)[0m     4.473838806152344,
[36m(head, rank=0, pid=3442)[0m     3.786754846572876,
[36m(head, rank=0, pid=3442)[0m     4.200466156005859,
[36m(head, rank=0, pid=3442)[0m     3.6989521980285645,
[36m(head, rank=0, pid=3442)[0m     3.5614869594573975,
[36m(head, rank=0, pid=3442)[0m     4.234843969345093,
[36m(head, rank=0, pid=3442)[0m     4.8019304275512695,
[36m(head, rank=0, pid=3442)[0m     3.6735503673553467,
[36m(head, rank=0, pid=3442)[0m     3.8496549129486084,
[36m(head, rank=0, pid=3442)[0m     3.644404172897339,
[36m(head, rank=0, pid=3442)[0m     4.148587465286255,
[36m(head, rank=0, pid=3442)[0m     3.6874377727508545,
[36m(head, rank=0, pid=3442)[0m     3.9170358180999756,
[36m(head, rank=0, pid=3442)[0m     3.9929137229919434,
[36m(head, rank=0, pid=3442)[0m     3.675367593765259,
[36m(head, rank=0, pid=3442)[0m     3.6733529567718506,
[36m(head, rank=0, pid=3442)[0m     3.6807806491851807,
[36m(head, rank=0, pid=3442)[0m     3.6642439365386963,
[36m(head, rank=0, pid=3442)[0m     4.716253757476807,
[36m(head, rank=0, pid=3442)[0m     3.665783405303955,
[36m(head, rank=0, pid=3442)[0m     7.460346698760986,
[36m(head, rank=0, pid=3442)[0m     3.6556780338287354,
[36m(head, rank=0, pid=3442)[0m     3.8220438957214355,
[36m(head, rank=0, pid=3442)[0m     4.2041332721710205,
[36m(head, rank=0, pid=3442)[0m     3.6668143272399902,
[36m(head, rank=0, pid=3442)[0m     4.088354110717773,
[36m(head, rank=0, pid=3442)[0m     4.569618225097656,
[36m(head, rank=0, pid=3442)[0m     4.688375234603882,
[36m(head, rank=0, pid=3442)[0m     4.11511754989624,
[36m(head, rank=0, pid=3442)[0m   833923101425171,
[36m(head, rank=0, pid=3442)[0m     3.6071407794952393,
[36m(head, rank=0, pid=3442)[0m     3.8250949382781982,
[36m(head, rank=0, pid=3442)[0m     3.687783718109131,
[36m(head, rank=0, pid=3442)[0m     3.794564723968506,
[36m(head, rank=0, pid=3442)[0m     4.774856328964233,
[36m(head, rank=0, pid=3442)[0m     3.672508716583252,
[36m(head, rank=0, pid=3442)[0m     4.103418588638306,
[36m(head, rank=0, pid=3442)[0m     3.6573596000671387,
[36m(head, rank=0, pid=3442)[0m     3.667603015899658,
[36m(head, rank=0, pid=3442)[0m     3.978393793106079,
[36m(head, rank=0, pid=3442)[0m     3.5701911449432373,
[36m(head, rank=0, pid=3442)[0m     3.9505910873413086,
[36m(head, rank=0, pid=3442)[0m     3.8003756999969482,
[36m(head, rank=0, pid=3442)[0m     5.068619251251221,
[36m(head, rank=0, pid=3442)[0m     4.903794765472412,
[36m(head, rank=0, pid=3442)[0m     3.6651928424835205,
[36m(head, rank=0, pid=3442)[0m     3.6678595542907715,
[36m(head, rank=0, pid=3442)[0m     3.66698956489563,
[36m(head, rank=0, pid=3442)[0m     3.6645567417144775,
[36m(head, rank=0, pid=3442)[0m     4.898447513580322,
[36m(head, rank=0, pid=3442)[0m     3.8853816986083984,
[36m(head, rank=0, pid=3442)[0m     4.284979343414307,
[36m(head, rank=0, pid=3442)[0m     3.672896146774292,
[36m(head, rank=0, pid=3442)[0m     3.7757623195648193,
[36m(head, rank=0, pid=3442)[0m     3.6888012886047363,
[36m(head, rank=0, pid=3442)[0m     3.7733571529388428,
[36m(head, rank=0, pid=3442)[0m     4.4563939571380615,
[36m(head, rank=0, pid=3442)[0m     156.1199562549591,
[36m(head, rank=0, pid=3442)[0m     3.5115392208099365,
[36m(head, rank=0, pid=3442)[0m     4.074060916900635,
[36m(head, rank=0, pid=3442)[0m     3.829474449157715,
[36m(head, rank=0, pid=3442)[0m     4.255335807800293,
[36m(head, rank=0, pid=3442)[0m     4.344017028808594,
[36m(head, rank=0, pid=3442)[0m     4.534534454345703,
[36m(head, rank=0, pid=3442)[0m     3.6648802757263184,
[36m(head, rank=0, pid=3442)[0m     4.619636058807373,
[36m(head, rank=0, pid=3442)[0m     4.944024562835693,
[36m(head, rank=0, pid=3442)[0m     4.863347768783569,
[36m(head, rank=0, pid=3442)[0m     3.6924633979797363,
[36m(head, rank=0, pid=3442)[0m     3.6637110710144043,
[36m(head, rank=0, pid=3442)[0m     3.5425429344177246,
[36m(head, rank=0, pid=3442)[0m     3.831542491912842,
[36m(head, rank=0, pid=3442)[0m     3.5086004734039307,
[36m(head, rank=0, pid=3442)[0m     3.9727094173431396,
[36m(head, rank=0, pid=3442)[0m     3.9172441959381104,
[36m(head, rank=0, pid=3442)[0m     4.4025163650512695,
[36m(head, rank=0, pid=3442)[0m     4.168955564498901,
[36m(head, rank=0, pid=3442)[0m     3.922588586807251,
[36m(head, rank=0, pid=3442)[0m     4.604442596435547,
[36m(head, rank=0, pid=3442)[0m     3.665667772293091,
[36m(head, rank=0, pid=3442)[0m     3.872041940689087,
[36m(head, rank=0, pid=3442)[0m     3.8192644119262695,
[36m(head, rank=0, pid=3442)[0m     4.140849828720093,
[36m(head, rank=0, pid=3442)[0m     3.6620891094207764,
[36m(head, rank=0, pid=3442)[0m     4.3705894947052,
[36m(head, rank=0, pid=3442)[0m     3.6604905128479004,
[36m(head, rank=0, pid=3442)[0m     3.6720101833343506,
[36m(head, rank=0, pid=3442)[0m     4.807771682739258,
[36m(head, rank=0, pid=3442)[0m     3.574263572692871,
[36m(head, rank=0, pid=3442)[0m     3.893829345703125,
[36m(head, rank=0, pid=3442)[0m     3.6709811687469482,
[36m(head, rank=0, pid=3442)[0m     3.668353319168091,
[36m(head, rank=0, pid=3442)[0m     3.666510581970215,
[36m(head, rank=0, pid=3442)[0m     3.7585294246673584,
[36m(head, rank=0, pid=3442)[0m     3.6651766300201416,
[36m(head, rank=0, pid=3442)[0m     3.5628743171691895,
[36m(head, rank=0, pid=3442)[0m     4.662513494491577,
[36m(head, rank=0, pid=3442)[0m     168.43957233428955,
[36m(head, rank=0, pid=3442)[0m     4.274756669998169,
[36m(head, rank=0, pid=3442)[0m     5.003454685211182,
[36m(head, rank=0, pid=3442)[0m     3.779428482055664,
[36m(head, rank=0, pid=3442)[0m     3.5699033737182617,
[36m(head, rank=0, pid=3442)[0m     3.6616876125335693,
[36m(head, rank=0, pid=3442)[0m     3.6705596446990967,
[36m(head, rank=0, pid=3442)[0m     5.789283752441406,
[36m(head, rank=0, pid=3442)[0m     3.781540870666504,
[36m(head, rank=0, pid=3442)[0m     4.76500391960144,
[36m(head, rank=0, pid=3442)[0m     3.660353422164917,
[36m(head, rank=0, pid=3442)[0m     3.81762957572937,
[36m(head, rank=0, pid=3442)[0m     3.739443778991699,
[36m(head, rank=0, pid=3442)[0m     3.661639451980591,
[36m(head, rank=0, pid=3442)[0m     4.642771005630493,
[36m(head, rank=0, pid=3442)[0m     4.077324867248535,
[36m(head, rank=0, pid=3442)[0m     4.565345048904419,
[36m(head, rank=0, pid=3442)[0m     4.8769707679748535,
[36m(head, rank=0, pid=3442)[0m     4.482592344284058,
[36m(head, rank=0, pid=3442)[0m     4.521880865097046,
[36m(head, rank=0, pid=3442)[0m     3.8296854496002197,
[36m(head, rank=0, pid=3442)[0m     4.458897113800049,
[36m(head, rank=0, pid=3442)[0m     4.190767049789429,
[36m(head, rank=0, pid=3442)[0m     3.767611265182495,
[36m(head, rank=0, pid=3442)[0m     4.431005001068115,
[36m(head, rank=0, pid=3442)[0m     3.7385475635528564,
[36m(head, rank=0, pid=3442)[0m     4.577759265899658,
[36m(head, rank=0, pid=3442)[0m     3.6615102291107178,
[36m(head, rank=0, pid=3442)[0m     3.9665448665618896,
[36m(head, rank=0, pid=3442)[0m     3.670180082321167,
[36m(head, rank=0, pid=3442)[0m     3.679224967956543,
[36m(head, rank=0, pid=3442)[0m     3.942047119140625,
[36m(head, rank=0, pid=3442)[0m     4.158606052398682,
[36m(head, rank=0, pid=3442)[0m     3.6698179244995117,
[36m(head, rank=0, pid=3442)[0m     3.673210620880127,
[36m(head, rank=0, pid=3442)[0m     3.6819205284118652,
[36m(head, rank=0, pid=3442)[0m     3.6624510288238525,
[36m(head, rank=0, pid=3442)[0m     4.192361354827881,
[36m(head, rank=0, pid=3442)[0m     4.714391469955444,
[36m(head, rank=0, pid=3442)[0m     4.1798036098480225
[36m(head, rank=0, pid=3442)[0m   ]
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m --- All Training Runs Summary ---
[36m(head, rank=0, pid=3442)[0m [
[36m(head, rank=0, pid=3442)[0m   {
[36m(head, rank=0, pid=3442)[0m     "run_id": 1,
[36m(head, rank=0, pid=3442)[0m     "timestamp": "2025-08-04T02:30:16.068039",
[36m(head, rank=0, pid=3442)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3442)[0m     "checkpoint_dir": "/checkpoints_s3",
[36m(head, rank=0, pid=3442)[0m     "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3442)[0m     "training_status": "completed",
[36m(head, rank=0, pid=3442)[0m     "output_dir": "/checkpoints_s3",
[36m(head, rank=0, pid=3442)[0m     "dataset_load_time": 3.1180226802825928,
[36m(head, rank=0, pid=3442)[0m     "model_load_time": 48.61657738685608,
[36m(head, rank=0, pid=3442)[0m     "training_time": 3272.375806570053,
[36m(head, rank=0, pid=3442)[0m     "total_time": 3324.1104066371918,
[36m(head, rank=0, pid=3442)[0m     "error": null,
[36m(head, rank=0, pid=3442)[0m     "num_checkpoints_saved": 5,
[36m(head, rank=0, pid=3442)[0m     "total_checkpoint_save_time": 2258.0382368564606,
[36m(head, rank=0, pid=3442)[0m     "average_checkpoint_save_time": 451.6076473712921,
[36m(head, rank=0, pid=3442)[0m     "min_checkpoint_save_time": 421.36059045791626,
[36m(head, rank=0, pid=3442)[0m     "max_checkpoint_save_time": 474.0977509021759,
[36m(head, rank=0, pid=3442)[0m     "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3442)[0m       464.30868124961853,
[36m(head, rank=0, pid=3442)[0m       440.7973666191101,
[36m(head, rank=0, pid=3442)[0m       421.36059045791626,
[36m(head, rank=0, pid=3442)[0m       457.47384762763977,
[36m(head, rank=0, pid=3442)[0m       474.0977509021759
[36m(head, rank=0, pid=3442)[0m     ],
[36m(head, rank=0, pid=3442)[0m     "num_batch_samples": 25,
[36m(head, rank=0, pid=3442)[0m     "total_batch_sample_time": 16.607704639434814,
[36m(head, rank=0, pid=3442)[0m     "average_batch_sample_time": 0.6643081855773926,
[36m(head, rank=0, pid=3442)[0m     "min_batch_sample_time": 0.4301433563232422,
[36m(head, rank=0, pid=3442)[0m     "max_batch_sample_time": 1.0295207500457764,
[36m(head, rank=0, pid=3442)[0m     "individual_batch_sample_times": [
[36m(head, rank=0, pid=3442)[0m       1.0295207500457764,
[36m(head, rank=0, pid=3442)[0m       0.5690951347351074,
[36m(head, rank=0, pid=3442)[0m       0.9281387329101562,
[36m(head, rank=0, pid=3442)[0m       0.7479639053344727,
[36m(head, rank=0, pid=3442)[0m       0.6385622024536133,
[36m(head, rank=0, pid=3442)[0m       0.9234836101531982,
[36m(head, rank=0, pid=3442)[0m       0.7065296173095703,
[36m(head, rank=0, pid=3442)[0m       0.6546268463134766,
[36m(head, rank=0, pid=3442)[0m       0.6749355792999268,
[36m(head, rank=0, pid=3442)[0m       0.7400646209716797,
[36m(head, rank=0, pid=3442)[0m       0.6539878845214844,
[36m(head, rank=0, pid=3442)[0m       0.7239606380462646,
[36m(head, rank=0, pid=3442)[0m       0.5918419361114502,
[36m(head, rank=0, pid=3442)[0m       0.7054438591003418,
[36m(head, rank=0, pid=3442)[0m       0.5687265396118164,
[36m(head, rank=0, pid=3442)[0m       0.4444084167480469,
[36m(head, rank=0, pid=3442)[0m       0.547680139541626,
[36m(head, rank=0, pid=3442)[0m       0.5927250385284424,
[36m(head, rank=0, pid=3442)[0m       0.4301433563232422,
[36m(head, rank=0, pid=3442)[0m       0.5732321739196777,
[36m(head, rank=0, pid=3442)[0m       0.4593231678009033,
[36m(head, rank=0, pid=3442)[0m       0.6249208450317383,
[36m(head, rank=0, pid=3442)[0m       0.5999593734741211,
[36m(head, rank=0, pid=3442)[0m       0.6028897762298584,
[36m(head, rank=0, pid=3442)[0m       0.8755404949188232
[36m(head, rank=0, pid=3442)[0m     ],
[36m(head, rank=0, pid=3442)[0m     "num_training_steps": 200,
[36m(head, rank=0, pid=3442)[0m     "total_training_step_time": 813.9187307357788,
[36m(head, rank=0, pid=3442)[0m     "average_training_step_time": 4.069593653678894,
[36m(head, rank=0, pid=3442)[0m     "min_training_step_time": 3.513488292694092,
[36m(head, rank=0, pid=3442)[0m     "max_training_step_time": 7.672798156738281,
[36m(head, rank=0, pid=3442)[0m     "individual_training_step_times": [
[36m(head, rank=0, pid=3442)[0m       5.408696889877319,
[36m(head, rank=0, pid=3442)[0m       4.224516153335571,
[36m(head, rank=0, pid=3442)[0m       4.374135494232178,
[36m(head, rank=0, pid=3442)[0m       3.6646506786346436,
[36m(head, rank=0, pid=3442)[0m       4.695664644241333,
[36m(head, rank=0, pid=3442)[0m       3.8565452098846436,
[36m(head, rank=0, pid=3442)[0m       3.5360941886901855,
[36m(head, rank=0, pid=3442)[0m       3.668941020965576,
[36m(head, rank=0, pid=3442)[0m       4.17244029045105,
[36m(head, rank=0, pid=3442)[0m       4.672351837158203,
[36m(head, rank=0, pid=3442)[0m       3.66336989402771,
[36m(head, rank=0, pid=3442)[0m       3.6689603328704834,
[36m(head, rank=0, pid=3442)[0m       3.6603689193725586,
[36m(head, rank=0, pid=3442)[0m       4.908206939697266,
[36m(head, rank=0, pid=3442)[0m       3.665113925933838,
[36m(head, rank=0, pid=3442)[0m       4.033595323562622,
[36m(head, rank=0, pid=3442)[0m       4.220582962036133,
[36m(head, rank=0, pid=3442)[0m       3.7450404167175293,
[36m(head, rank=0, pid=3442)[0m       3.775317907333374,
[36m(head, rank=0, pid=3442)[0m       3.673004150390625,
[36m(head, rank=0, pid=3442)[0m       4.302476644515991,
[36m(head, rank=0, pid=3442)[0m       3.673687696456909,
[36m(head, rank=0, pid=3442)[0m       4.562340974807739,
[36m(head, rank=0, pid=3442)[0m       3.695207357406616,
[36m(head, rank=0, pid=3442)[0m       5.0370872020721436,
[36m(head, rank=0, pid=3442)[0m       3.5824248790740967,
[36m(head, rank=0, pid=3442)[0m       3.7990975379943848,
[36m(head, rank=0, pid=3442)[0m       3.702152729034424,
[36m(head, rank=0, pid=3442)[0m       3.7279813289642334,
[36m(head, rank=0, pid=3442)[0m       3.681522846221924,
[36m(head, rank=0, pid=3442)[0m       3.823760509490967,
[36m(head, rank=0, pid=3442)[0m       4.3454954624176025,
[36m(head, rank=0, pid=3442)[0m       4.961686611175537,
[36m(head, rank=0, pid=3442)[0m       3.8650527000427246,
[36m(head, rank=0, pid=3442)[0m       3.6916773319244385,
[36m(head, rank=0, pid=3442)[0m       4.042714595794678,
[36m(head, rank=0, pid=3442)[0m       4.425193548202515,
[36m(head, rank=0, pid=3442)[0m       4.385880708694458,
[36m(head, rank=0, pid=3442)[0m       3.667921781539917,
[36m(head, rank=0, pid=3442)[0m       3.841768264770508,
[36m(head, rank=0, pid=3442)[0m       3.666067361831665,
[36m(head, rank=0, pid=3442)[0m       3.51458740234375,
[36m(head, rank=0, pid=3442)[0m       4.768497467041016,
[36m(head, rank=0, pid=3442)[0m       3.674201726913452,
[36m(head, rank=0, pid=3442)[0m       5.477250814437866,
[36m(head, rank=0, pid=3442)[0m       3.6602959632873535,
[36m(head, rank=0, pid=3442)[0m       3.8242807388305664,
[36m(head, rank=0, pid=3442)[0m       4.022038459777832,
[36m(head, rank=0, pid=3442)[0m       4.753447532653809,
[36m(head, rank=0, pid=3442)[0m       4.7832629680633545,
[36m(head, rank=0, pid=3442)[0m       3.6625633239746094,
[36m(head, rank=0, pid=3442)[0m       3.663895606994629,
[36m(head, rank=0, pid=3442)[0m       3.943683385848999,
[36m(head, rank=0, pid=3442)[0m       3.674084424972534,
[36m(head, rank=0, pid=3442)[0m       4.2752344608306885,
[36m(head, rank=0, pid=3442)[0m       3.668142795562744,
[36m(head, rank=0, pid=3442)[0m       5.085987091064453,
[36m(head, rank=0, pid=3442)[0m       4.105518102645874,
[36m(head, rank=0, pid=3442)[0m       3.8193888664245605,
[36m(head, rank=0, pid=3442)[0m       4.150400638580322,
[36m(head, rank=0, pid=3442)[0m       3.671936273574829,
[36m(head, rank=0, pid=3442)[0m       3.7046353816986084,
[36m(head, rank=0, pid=3442)[0m       3.6631076335906982,
[36m(head, rank=0, pid=3442)[0m       4.473838806152344,
[36m(head, rank=0, pid=3442)[0m       3.786754846572876,
[36m(head, rank=0, pid=3442)[0m       4.200466156005859,
[36m(head, rank=0, pid=3442)[0m       3.6989521980285645,
[36m(head, rank=0, pid=3442)[0m       3.5614869594573975,
[36m(head, rank=0, pid=3442)[0m       4.234843969345093,
[36m(head, rank=0, pid=3442)[0m       4.8019304275512695,
[36m(head, rank=0, pid=3442)[0m       3.6735503673553467,
[36m(head, rank=0, pid=3442)[0m       3.8496549129486084,
[36m(head, rank=0, pid=3442)[0m       3.644404172897339,
[36m(head, rank=0, pid=3442)[0m       4.148587465286255,
[36m(head, rank=0, pid=3442)[0m       3.6874377727508545,
[36m(head, rank=0, pid=3442)[0m       3.9170358180999756,
[36m(head, rank=0, pid=3442)[0m       3.9929137229919434,
[36m(head, rank=0, pid=3442)[0m       3.675367593765259,
[36m(head, rank=0, pid=3442)[0m       3.6733529567718506,
[36m(head, rank=0, pid=3442)[0m       3.6807806491851807,
[36m(head, rank=0, pid=3442)[0m       3.6642439365386963,
[36m(head, rank=0, pid=3442)[0m       4.716253757476807,
[36m(head, rank=0, pid=3442)[0m       3.665783405303955,
[36m(head, rank=0, pid=3442)[0m       7.460346698760986,
[36m(head, rank=0, pid=3442)[0m       3.6556780338287354,
[36m(head, rank=0, pid=3442)[0m       3.8220438957214355,
[36m(head, rank=0, pid=3442)[0m       4.2041332721710205,
[36m(head, rank=0, pid=3442)[0m       3.6668143272399902,
[36m(head, rank=0, pid=3442)[0m       4.088354110717773,
[36m(head, rank=0, pid=3442)[0m       4.569618225097656,
[36m(head, rank=0, pid=3442)[0m       4.688375234603882,
[36m(head, rank=0, pid=3442)[0m       4.11511754989624,
[36m(head, rank=0, pid=3442)[0m       4.836381196975708,
[36m(head, rank=0, pid=3442)[0m       3.7051384449005127,
[36m(head, rank=0, pid=3442)[0m       3.8528902530670166,
[36m(head, rank=0, pid=3442)[0m       3.6547961235046387,
[36m(head, rank=0, pid=3442)[0m       3.8283615112304688,
[36m(head, rank=0, pid=3442)[0m       4.897339105606079,
[36m(head, rank=0, pid=3442)[0m       3.670302152633667,
[36m(head, rank=0, pid=3442)[0m       4.102971076965332,
[36m(head, rank=0, pid=3442)[0m       3.6551778316497803,
[36m(head, rank=0, pid=3442)[0m       3.6650614738464355,
[36m(head, rank=0, pid=3442)[0m       3.9539899826049805,
[36m(head, rank=0, pid=3442)[0m       3.6027944087982178,
[36m(head, rank=0, pid=3442)[0m       3.660248041152954,
[36m(head, rank=0, pid=3442)[0m       3.804086923599243,
[36m(head, rank=0, pid=3442)[0m       5.070463418960571,
[36m(head, rank=0, pid=3442)[0m       4.909335374832153,
[36m(head, rank=0, pid=3442)[0m       3.576735258102417,
[36m(head, rank=0, pid=3442)[0m       3.6678130626678467,
[36m(head, rank=0, pid=3442)[0m       3.6688499450683594,
[36m(head, rank=0, pid=3442)[0m       3.666945219039917,
[36m(head, rank=0, pid=3442)[0m       4.957415580749512,
[36m(head, rank=0, pid=3442)[0m       3.8836543560028076,
[36m(head, rank=0, pid=3442)[0m       4.4054114818573,
[36m(head, rank=0, pid=3442)[0m       3.672304630279541,
[36m(head, rank=0, pid=3442)[0m       3.7757208347320557,
[36m(head, rank=0, pid=3442)[0m       3.6872432231903076,
[36m(head, rank=0, pid=3442)[0m       3.7854249477386475,
[36m(head, rank=0, pid=3442)[0m       4.362869501113892,
[36m(head, rank=0, pid=3442)[0m       7.672798156738281,
[36m(head, rank=0, pid=3442)[0m       3.658066511154175,
[36m(head, rank=0, pid=3442)[0m       4.075739145278931,
[36m(head, rank=0, pid=3442)[0m       3.8301594257354736,
[36m(head, rank=0, pid=3442)[0m       4.256816625595093,
[36m(head, rank=0, pid=3442)[0m       4.343449354171753,
[36m(head, rank=0, pid=3442)[0m       4.533471345901489,
[36m(head, rank=0, pid=3442)[0m       3.513488292694092,
[36m(head, rank=0, pid=3442)[0m       4.6323487758636475,
[36m(head, rank=0, pid=3442)[0m       4.946802139282227,
[36m(head, rank=0, pid=3442)[0m       4.81425142288208,
[36m(head, rank=0, pid=3442)[0m       3.6925852298736572,
[36m(head, rank=0, pid=3442)[0m       3.665947437286377,
[36m(head, rank=0, pid=3442)[0m       3.6724655628204346,
[36m(head, rank=0, pid=3442)[0m       3.8336362838745117,
[36m(head, rank=0, pid=3442)[0m       3.657604217529297,
[36m(head, rank=0, pid=3442)[0m       3.9569101333618164,
[36m(head, rank=0, pid=3442)[0m       3.920891761779785,
[36m(head, rank=0, pid=3442)[0m       4.409648180007935,
[36m(head, rank=0, pid=3442)[0m       4.08956241607666,
[36m(head, rank=0, pid=3442)[0m       3.9231927394866943,
[36m(head, rank=0, pid=3442)[0m       4.6065754890441895,
[36m(head, rank=0, pid=3442)[0m       3.665332794189453,
[36m(head, rank=0, pid=3442)[0m       3.8731026649475098,
[36m(head, rank=0, pid=3442)[0m       4.152980089187622,
[36m(head, rank=0, pid=3442)[0m       4.25727653503418,
[36m(head, rank=0, pid=3442)[0m       3.659987211227417,
[36m(head, rank=0, pid=3442)[0m       4.368990421295166,
[36m(head, rank=0, pid=3442)[0m       3.6598386764526367,
[36m(head, rank=0, pid=3442)[0m       3.669921398162842,
[36m(head, rank=0, pid=3442)[0m       4.712204456329346,
[36m(head, rank=0, pid=3442)[0m       3.6681199073791504,
[36m(head, rank=0, pid=3442)[0m       4.065587997436523,
[36m(head, rank=0, pid=3442)[0m       3.6901988983154297,
[36m(head, rank=0, pid=3442)[0m       3.6669998168945312,
[36m(head, rank=0, pid=3442)[0m       3.665097951889038,
[36m(head, rank=0, pid=3442)[0m       3.754929304122925,
[36m(head, rank=0, pid=3442)[0m       3.5276761054992676,
[36m(head, rank=0, pid=3442)[0m       3.659213066101074,
[36m(head, rank=0, pid=3442)[0m       4.660694122314453,
[36m(head, rank=0, pid=3442)[0m       3.5288469791412354,
[36m(head, rank=0, pid=3442)[0m       4.2788825035095215,
[36m(head, rank=0, pid=3442)[0m       4.999266624450684,
[36m(head, rank=0, pid=3442)[0m       3.7739439010620117,
[36m(head, rank=0, pid=3442)[0m       3.6634228229522705,
[36m(head, rank=0, pid=3442)[0m       3.662731170654297,
[36m(head, rank=0, pid=3442)[0m       3.675689935684204,
[36m(head, rank=0, pid=3442)[0m       5.785076141357422,
[36m(head, rank=0, pid=3442)[0m       3.8870277404785156,
[36m(head, rank=0, pid=3442)[0m       4.772861957550049,
[36m(head, rank=0, pid=3442)[0m       3.6638107299804688,
[36m(head, rank=0, pid=3442)[0m       3.866766929626465,
[36m(head, rank=0, pid=3442)[0m       3.744164228439331,
[36m(head, rank=0, pid=3442)[0m       3.6597206592559814,
[36m(head, rank=0, pid=3442)[0m       4.636754512786865,
[36m(head, rank=0, pid=3442)[0m       4.0778968334198,
[36m(head, rank=0, pid=3442)[0m       4.601852655410767,
[36m(head, rank=0, pid=3442)[0m       4.983529329299927,
[36m(head, rank=0, pid=3442)[0m       4.4590537548065186,
[36m(head, rank=0, pid=3442)[0m       4.525782346725464,
[36m(head, rank=0, pid=3442)[0m       3.828274965286255,
[36m(head, rank=0, pid=3442)[0m       4.457215070724487,
[36m(head, rank=0, pid=3442)[0m       4.232161998748779,
[36m(head, rank=0, pid=3442)[0m       3.765244960784912,
[36m(head, rank=0, pid=3442)[0m       4.225640058517456,
[36m(head, rank=0, pid=3442)[0m       3.7379157543182373,
[36m(head, rank=0, pid=3442)[0m       4.573972940444946,
[36m(head, rank=0, pid=3442)[0m       3.658562421798706,
[36m(head, rank=0, pid=3442)[0m       3.9670217037200928,
[36m(head, rank=0, pid=3442)[0m       3.667428970336914,
[36m(head, rank=0, pid=3442)[0m       3.6757068634033203,
[36m(head, rank=0, pid=3442)[0m       3.941370725631714,
[36m(head, rank=0, pid=3442)[0m       3.968196153640747,
[36m(head, rank=0, pid=3442)[0m       3.5369904041290283,
[36m(head, rank=0, pid=3442)[0m       3.547879219055176,
[36m(head, rank=0, pid=3442)[0m       3.6443417072296143,
[36m(head, rank=0, pid=3442)[0m       3.658498764038086,
[36m(head, rank=0, pid=3442)[0m       4.193968296051025,
[36m(head, rank=0, pid=3442)[0m       4.796071767807007,
[36m(head, rank=0, pid=3442)[0m       4.177541255950928
[36m(head, rank=0, pid=3442)[0m     ]
[36m(head, rank=0, pid=3442)[0m   }
[36m(head, rank=0, pid=3442)[0m ]
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m --- Timing Summary ---
[36m(head, rank=0, pid=3442)[0m {
[36m(head, rank=0, pid=3442)[0m   "total_runs": 1,
[36m(head, rank=0, pid=3442)[0m   "dataset_loading": {
[36m(head, rank=0, pid=3442)[0m     "dataset_load_count": 1,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_average": 3.1180226802825928,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_min": 3.1180226802825928,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_max": 3.1180226802825928,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_total": 3.1180226802825928
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "model_loading": {
[36m(head, rank=0, pid=3442)[0m     "model_load_count": 1,
[36m(head, rank=0, pid=3442)[0m     "model_load_average": 48.61657738685608,
[36m(head, rank=0, pid=3442)[0m     "model_load_min": 48.61657738685608,
[36m(head, rank=0, pid=3442)[0m     "model_load_max": 48.61657738685608,
[36m(head, rank=0, pid=3442)[0m     "model_load_total": 48.61657738685608
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "training": {
[36m(head, rank=0, pid=3442)[0m     "training_count": 1,
[36m(head, rank=0, pid=3442)[0m     "training_average": 3272.375806570053,
[36m(head, rank=0, pid=3442)[0m     "training_min": 3272.375806570053,
[36m(head, rank=0, pid=3442)[0m     "training_max": 3272.375806570053,
[36m(head, rank=0, pid=3442)[0m     "training_total": 3272.375806570053
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "total_run_time": {
[36m(head, rank=0, pid=3442)[0m     "total_count": 1,
[36m(head, rank=0, pid=3442)[0m     "total_average": 3324.1104066371918,
[36m(head, rank=0, pid=3442)[0m     "total_min": 3324.1104066371918,
[36m(head, rank=0, pid=3442)[0m     "total_max": 3324.1104066371918,
[36m(head, rank=0, pid=3442)[0m     "total_total": 3324.1104066371918
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "checkpoint_saving": {
[36m(head, rank=0, pid=3442)[0m     "total_checkpoints_saved": 5,
[36m(head, rank=0, pid=3442)[0m     "total_checkpoint_save_time": 2258.0382368564606,
[36m(head, rank=0, pid=3442)[0m     "average_save_time_per_checkpoint": 451.6076473712921,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_times_count": 5,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_min": 421.36059045791626,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_max": 474.0977509021759,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_average": 451.6076473712921
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "batch_sampling": {
[36m(head, rank=0, pid=3442)[0m     "total_batch_samples": 25,
[36m(head, rank=0, pid=3442)[0m     "total_batch_sample_time": 16.607704639434814,
[36m(head, rank=0, pid=3442)[0m     "average_sample_time_per_batch": 0.6643081855773926,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_times_count": 25,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_min": 0.4301433563232422,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_max": 1.0295207500457764,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_average": 0.6643081855773926
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "training_steps": {
[36m(head, rank=0, pid=3442)[0m     "total_training_steps": 200,
[36m(head, rank=0, pid=3442)[0m     "total_training_step_time": 813.9187307357788,
[36m(head, rank=0, pid=3442)[0m     "average_step_time_per_step": 4.069593653678894,
[36m(head, rank=0, pid=3442)[0m     "training_step_times_count": 200,
[36m(head, rank=0, pid=3442)[0m     "training_step_min": 3.513488292694092,
[36m(head, rank=0, pid=3442)[0m     "training_step_max": 7.672798156738281,
[36m(head, rank=0, pid=3442)[0m     "training_step_average": 4.069593653678894
[36m(head, rank=0, pid=3442)[0m   }
[36m(head, rank=0, pid=3442)[0m }
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3442)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3442)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3442)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3442)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(head, rank=0, pid=3442)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load dataset...Starting Load dataset...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.44 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.44 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.44 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.44 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.44 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.44 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 2.45 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.51 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.51 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.51 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.51 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.51 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.51 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.54 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load dataset in 2.55 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Load model...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00, 28.38it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00, 28.37it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 30.48it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 54.81it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 30.46it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 77.51it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 53.57it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 46.95it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 46.65it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 46.97it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 46.87it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 46.57it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 46.87it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 46.88it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 46.79it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 100.56it/s]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 89.79it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.02 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.07 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.07 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.04 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.07 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 1.07 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.13 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.13 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.13 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.17 seconds
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.20 seconds
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 99.01it/s]
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.43 seconds
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Completed Load dataset in 5.92 seconds
[36m(head, rank=0, pid=3442)[0m Starting Load model...
[36m(head, rank=0, pid=3442)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  7.84it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 35.41it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 4.10 seconds
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  7.94it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 35.88it/s]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m Completed Load model in 1.01 seconds
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:21<01:25, 21.50s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:21<01:26, 21.65s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:43<01:04, 21.51s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:43<01:04, 21.58s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  60%|██████    | 3/5 [01:04<00:43, 21.65s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  60%|██████    | 3/5 [01:04<00:43, 21.68s/it]
[36m(head, rank=0, pid=3442)[0m Loading checkpoint shards:  80%|████████  | 4/5 [01:26<00:21, 21.70s/it]Loading checkpoint shards: 100%|██████████| 5/5 [01:47<00:00, 21.40s/it]Loading checkpoint shards: 100%|██████████| 5/5 [01:47<00:00, 21.50s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Loading checkpoint shards:  80%|████████  | 4/5 [01:26<00:21, 21.72s/it]Loading checkpoint shards: 100%|██████████| 5/5 [01:47<00:00, 21.39s/it]Loading checkpoint shards: 100%|██████████| 5/5 [01:47<00:00, 21.52s/it]
[36m(head, rank=0, pid=3442)[0m Completed Load model in 108.58 seconds
[36m(head, rank=0, pid=3442)[0m Starting Training...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Load model in 108.76 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Training...
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:09,342] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:10,282] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:10,287] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:10,291] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:10,292] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:10,295] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:10,297] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:10,300] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:10,589] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:11,543] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:11,543] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:11,556] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:11,561] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:11,563] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:11,569] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m [2025-08-04 03:28:11,574] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:15,152] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:15,167] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:15,168] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:15,168] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:15,169] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:15,170] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:15,174] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:15,176] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:16,253] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:16,413] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:16,417] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:16,417] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:16,419] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:16,421] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:16,456] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [2025-08-04 03:28:16,461] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   0%|          | 0/25 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3442)[0m   4%|▍         | 1/25 [00:39<15:56, 39.85s/it]
[36m(head, rank=0, pid=3442)[0m   8%|▊         | 2/25 [01:16<14:29, 37.81s/it]
[36m(head, rank=0, pid=3442)[0m  12%|█▏        | 3/25 [01:51<13:29, 36.80s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  16%|█▌        | 4/25 [02:27<12:42, 36.29s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  20%|██        | 5/25 [03:04<12:10, 36.53s/it]Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 339.89 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 339.89s (Total: 339.89s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 339.89 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 339.89s (Total: 339.89s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 339.89 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 339.89s (Total: 339.89s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 339.89 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 339.89s (Total: 339.89s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 339.89 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 339.89s (Total: 339.89s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 339.89 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 339.89s (Total: 339.89s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 339.89 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 339.89s (Total: 339.89s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 339.88 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 339.88s (Total: 339.88s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 339.88 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 339.88s (Total: 339.88s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 339.88 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 339.88s (Total: 339.88s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 339.88 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 339.88s (Total: 339.88s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 339.88 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 339.88s (Total: 339.88s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 339.88 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 339.88s (Total: 339.88s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 339.88 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 339.88s (Total: 339.88s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 339.88 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 339.88s (Total: 339.88s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 614.48 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 614.48s (Total: 614.48s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  24%|██▍       | 6/25 [13:56<1:17:51, 245.88s/it]
[36m(head, rank=0, pid=3442)[0m  28%|██▊       | 7/25 [14:33<53:13, 177.42s/it]  
[36m(head, rank=0, pid=3442)[0m  32%|███▏      | 8/25 [15:10<37:37, 132.82s/it]
[36m(head, rank=0, pid=3442)[0m  36%|███▌      | 9/25 [15:47<27:26, 102.88s/it] 40%|████      | 10/25 [16:22<20:30, 82.05s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m                                                {'loss': 125.3922, 'grad_norm': 49.56791305541992, 'learning_rate': 1.2800000000000001e-05, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3442)[0m  40%|████      | 10/25 [16:22<20:30, 82.05s/it]Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 342.49 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 342.49s (Total: 682.37s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 342.49 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 342.49s (Total: 682.37s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 342.49 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 342.49s (Total: 682.37s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 342.49 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 342.49s (Total: 682.37s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 342.49 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 342.49s (Total: 682.37s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 342.49 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 342.49s (Total: 682.37s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 342.49 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 342.49s (Total: 682.37s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 342.50 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 342.50s (Total: 682.39s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 342.50 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 342.50s (Total: 682.40s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 342.50 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 342.50s (Total: 682.40s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 342.50 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 342.50s (Total: 682.40s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 342.50 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 342.50s (Total: 682.40s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 342.50 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 342.50s (Total: 682.40s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 342.50 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 342.50s (Total: 682.39s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 342.51 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 342.51s (Total: 682.40s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 625.91 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 625.91s (Total: 1240.39s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  44%|████▍     | 11/25 [27:28<1:00:49, 260.70s/it]
[36m(head, rank=0, pid=3442)[0m  48%|████▊     | 12/25 [28:07<41:50, 193.10s/it]  
[36m(head, rank=0, pid=3442)[0m  52%|█████▏    | 13/25 [28:42<29:03, 145.31s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  56%|█████▌    | 14/25 [29:18<20:35, 112.32s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  60%|██████    | 15/25 [29:55<14:56, 89.63s/it] Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 357.56 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 357.56s (Total: 1039.92s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 357.56 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 357.56s (Total: 1039.93s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 357.56 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 357.56s (Total: 1039.92s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 357.55 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 357.55s (Total: 1039.92s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 357.56 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 357.56s (Total: 1039.93s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 357.56 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 357.56s (Total: 1039.93s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 357.56 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 357.56s (Total: 1039.93s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 357.57 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 357.57s (Total: 1039.97s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 357.57 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 357.57s (Total: 1039.97s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 357.58 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 357.58s (Total: 1039.97s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 357.57 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 357.57s (Total: 1039.97s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 357.57 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 357.57s (Total: 1039.96s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 357.56 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 357.56s (Total: 1039.95s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 357.58 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 357.58s (Total: 1039.97s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 357.58 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 357.58s (Total: 1039.97s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 635.02 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 635.02s (Total: 1875.42s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  64%|██████▍   | 16/25 [41:12<39:58, 266.45s/it]
[36m(head, rank=0, pid=3442)[0m  68%|██████▊   | 17/25 [41:49<26:19, 197.46s/it]
[36m(head, rank=0, pid=3442)[0m  72%|███████▏  | 18/25 [42:26<17:24, 149.18s/it]
[36m(head, rank=0, pid=3442)[0m  76%|███████▌  | 19/25 [43:02<11:31, 115.21s/it] 80%|████████  | 20/25 [43:37<07:34, 91.00s/it] Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...                                               
[36m(head, rank=0, pid=3442)[0m {'loss': 94.3979, 'grad_norm': 22.57253646850586, 'learning_rate': 4.800000000000001e-06, 'num_tokens': 19076177.0, 'epoch': 0.05}
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  80%|████████  | 20/25 [43:37<07:34, 91.00s/it]Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 341.41 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 341.41s (Total: 1381.33s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 341.41 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 341.41s (Total: 1381.34s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 341.42 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 341.42s (Total: 1381.34s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 341.42 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 341.42s (Total: 1381.35s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 341.42 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 341.42s (Total: 1381.35s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 341.42 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 341.42s (Total: 1381.34s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 341.43 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 341.43s (Total: 1381.35s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 341.42 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 341.42s (Total: 1381.38s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 341.42 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 341.42s (Total: 1381.39s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 341.42 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 341.42s (Total: 1381.37s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 341.42 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 341.42s (Total: 1381.40s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 341.42 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 341.42s (Total: 1381.39s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 341.42 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 341.42s (Total: 1381.39s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 341.42 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 341.42s (Total: 1381.39s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 341.42 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 341.42s (Total: 1381.39s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 624.08 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 624.08s (Total: 2499.50s)
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m  84%|████████▍ | 21/25 [54:39<17:29, 262.45s/it]
[36m(head, rank=0, pid=3442)[0m  88%|████████▊ | 22/25 [55:15<09:43, 194.64s/it]
[36m(head, rank=0, pid=3442)[0m  92%|█████████▏| 23/25 [55:55<04:56, 148.12s/it]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m  96%|█████████▌| 24/25 [56:30<01:54, 114.33s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m 100%|██████████| 25/25 [57:06<00:00, 90.82s/it] Starting Save checkpoint...
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 351.60 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 351.60s (Total: 1732.95s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 351.60 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 351.60s (Total: 1732.95s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 351.60 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 351.60s (Total: 1732.94s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 351.60 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 351.60s (Total: 1732.94s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 351.60 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 351.60s (Total: 1732.95s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 351.60 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 351.60s (Total: 1732.95s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 351.60 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 351.60s (Total: 1732.94s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 351.61 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 351.61s (Total: 1733.01s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 351.61 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 351.61s (Total: 1733.01s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 351.61 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 351.61s (Total: 1733.00s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 351.61 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 351.61s (Total: 1733.01s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 351.61 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 351.61s (Total: 1733.01s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 351.61 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 351.61s (Total: 1732.98s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 351.61 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 351.61s (Total: 1733.01s)
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Save checkpoint in 351.62 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint save time: 351.62s (Total: 1733.00s)
[36m(head, rank=0, pid=3442)[0m Completed Save checkpoint in 618.58 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint save time: 618.58s (Total: 3118.08s)
[36m(head, rank=0, pid=3442)[0m                                                {'train_runtime': 4045.4386, 'train_samples_per_second': 0.791, 'train_steps_per_second': 0.006, 'train_loss': 106.388515625, 'num_tokens': 23880036.0, 'epoch': 0.07}
[36m(head, rank=0, pid=3442)[0m 100%|██████████| 25/25 [1:07:25<00:00, 90.82s/it]100%|██████████| 25/25 [1:07:25<00:00, 161.82s/it]
[36m(head, rank=0, pid=3442)[0m Completed Training in 4094.20 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 3118.08s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 623.62s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 614.48s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 635.02s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 7.58s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 0.30s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.06s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 1.51s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 820.10s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 4.10s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 9.45s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Completed Training in 4201.21 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1732.95s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 346.59s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 339.88s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 357.56s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 155.23s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 6.21s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 43.28s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1791.34s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 8.96s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 252.63s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Completed Training in 4201.28 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1732.95s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 346.59s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 339.88s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 357.56s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 155.63s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 6.23s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 43.33s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1790.76s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 8.95s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.54s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 252.71s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Completed Training in 4201.25 seconds
[36m(head, rank=0, pid=3442)[0m Completed Training in 4201.28 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5Completed Training in 4198.29 seconds
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1732.95s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 346.59s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 339.88s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 357.56s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 156.47s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 6.26s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.04s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 43.23s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1790.84s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 8.95s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.53s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 252.74s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m Completed Training in 4201.27 seconds  - Total checkpoint save time: 1732.94s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 346.59s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 339.88s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Max save time: 357.55s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 155.26s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 6.21s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.06s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 43.28s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1790.98s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 8.95s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 252.74s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Completed Training in 4201.21 seconds
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1732.95s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 346.59s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 339.88s
[36m(head, rank=0, pid=3442)[0m   - Max save time: 357.56s
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 155.76s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 6.23s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 43.31s
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1790.55s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 8.95s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 252.64s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3442)[0m   - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1732.94s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 346.59s
[36m(head, rank=0, pid=3442)[0m Checkpoint Save Statistics:  - Min save time: 339.88s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Max save time: 357.56s  - Number of checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m   - Total checkpoint save time: 1732.94s
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 156.30s
[36m(head, rank=0, pid=3442)[0m   - Average save time per checkpoint: 346.59s
[36m(head, rank=0, pid=3442)[0m   - Average batch sample time: 6.25s
[36m(head, rank=0, pid=3442)[0m   - Min save time: 339.88s
[36m(head, rank=0, pid=3442)[0m   - Min batch sample time: 0.03s  - Max save time: 357.56s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 43.30sBatch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:  - Number of batch samples: 25
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m   - Total batch sample time: 156.38s
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1789.68s  - Average batch sample time: 6.26s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 8.95s  - Min batch sample time: 0.04s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3442)[0m   - Max batch sample time: 43.26s  - Max training step time: 252.66s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1  - Number of training steps: 200
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m   - Total training step time: 1789.86s
[36m(head, rank=0, pid=3442)[0m   - Average training step time: 8.95s
[36m(head, rank=0, pid=3442)[0m   - Min training step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   - Max training step time: 252.75s
[36m(head, rank=0, pid=3442)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_0_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_7_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_6_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_3_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_1_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_5_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_4_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_2_1_info.json
[36m(head, rank=0, pid=3442)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 4201.13 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 4201.15 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 4094.02 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 4201.15 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 4201.22 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 4201.15 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 4198.68 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed Training in 4201.16 seconds
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1733.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 346.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 339.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 357.58s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 150.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 6.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 42.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1797.21s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 8.99s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 252.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1733.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 346.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 339.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 357.57s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 150.23s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 6.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 42.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1796.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 8.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 252.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1733.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 346.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 339.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 357.58sCheckpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 149.93s  - Total checkpoint save time: 1733.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:  - Average batch sample time: 6.00s  - Average save time per checkpoint: 346.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5  - Min save time: 339.89sCheckpoint Save Statistics:  - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 357.57s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 42.98sBatch Sampling Performance:  - Total checkpoint save time: 1733.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:  - Average save time per checkpoint: 346.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1733.01s  - Total batch sample time: 149.95s  - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 339.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 6.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1794.56s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 346.60s  - Max save time: 357.57s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.03s  - Average training step time: 8.97s  - Min save time: 339.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 357.58s  - Max batch sample time: 42.98s  - Max training step time: 252.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5Batch Sampling Performance:  - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25  - Total batch sample time: 150.60s  - Total checkpoint save time: 1733.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200  - Average batch sample time: 6.02s  - Average save time per checkpoint: 346.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 150.94s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1795.43s  - Min save time: 339.89s  - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 6.04s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 357.57s  - Max batch sample time: 42.98s  - Average training step time: 8.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:Training Step Performance:  - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25  - Max training step time: 252.98s  - Max batch sample time: 42.98s  - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 150.59sTraining completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1796.63sTraining Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 6.02s  - Average training step time: 8.98s  - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.03s  - Min training step time: 3.51s  - Total training step time: 1796.34s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 42.98s  - Max training step time: 252.85s  - Average training step time: 8.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1  - Min training step time: 3.55s  - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 252.95s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1796.31s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 8.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 252.94s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total checkpoint save time: 1732.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average save time per checkpoint: 346.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min save time: 339.88s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max save time: 357.56s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total batch sample time: 150.06s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average batch sample time: 6.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max batch sample time: 42.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Number of training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Total training step time: 1795.81s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Average training step time: 8.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   - Max training step time: 252.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_6_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Completed run 1/1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.44s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.17s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.17s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.17s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.17s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4201.25s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4201.25s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4201.25s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4201.25s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 8.95s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.53s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 252.74s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1790.84s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 6.26s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.04s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 43.23s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 156.47s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 346.59s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 339.88s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 357.56s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1732.95s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4204.86s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4204.86s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4204.86s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4204.86s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.44s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.20s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.20s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.20s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.20s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4201.21s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4201.21s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4201.21s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4201.21s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 8.96s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.52s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 252.63s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1791.34s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 6.21s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 43.28s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 155.23s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 346.59s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 339.88s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 357.56s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1732.95s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4204.85s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4204.85s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4204.85s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4204.85s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.44s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.13s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.13s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.13s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.13s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4201.28s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4201.28s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4201.28s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4201.28s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 8.95s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.54s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 252.71s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1790.76s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 6.23s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 43.33s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 155.63s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 346.59s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 339.88s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 357.56s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1732.95s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4204.85s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4204.85s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4204.85s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4204.85s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.45s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.45s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.45s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.45s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 108.58s
[36m(head, rank=0, pid=3442)[0m   • Min time: 108.58s
[36m(head, rank=0, pid=3442)[0m   • Max time: 108.58s
[36m(head, rank=0, pid=3442)[0m   • Total time: 108.58s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4094.20s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4094.20s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4094.20s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4094.20s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 4.10s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 9.45s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 820.10s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 0.30s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.06s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 1.51s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 7.58s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 623.62s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 614.48s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 635.02s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 3118.08s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4205.23s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4205.23s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4205.23s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4205.23s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m --- Training Run 1 Info (Directory: /checkpoints_s3_mount_cached) ---
[36m(head, rank=0, pid=3442)[0m {
[36m(head, rank=0, pid=3442)[0m   "run_id": 1,
[36m(head, rank=0, pid=3442)[0m   "timestamp": "2025-08-04T03:26:08.206399",
[36m(head, rank=0, pid=3442)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3442)[0m   "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3442)[0m   "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3442)[0m   "training_status": "completed",
[36m(head, rank=0, pid=3442)[0m   "output_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3442)[0m   "dataset_load_time": 2.4535374641418457,
[36m(head, rank=0, pid=3442)[0m   "model_load_time": 108.58293414115906,
[36m(head, rank=0, pid=3442)[0m   "training_time": 4094.197447538376,
[36m(head, rank=0, pid=3442)[0m   "total_time": 4205.233919143677,
[36m(head, rank=0, pid=3442)[0m   "error": null,
[36m(head, rank=0, pid=3442)[0m   "num_checkpoints_saved": 5,
[36m(head, rank=0, pid=3442)[0m   "total_checkpoint_save_time": 3118.0791783332825,
[36m(head, rank=0, pid=3442)[0m   "average_checkpoint_save_time": 623.6158356666565,
[36m(head, rank=0, pid=3442)[0m   "min_checkpoint_save_time": 614.4782469272614,
[36m(head, rank=0, pid=3442)[0m   "max_checkpoint_save_time": 635.0228147506714,
[36m(head, rank=0, pid=3442)[0m   "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3442)[0m     614.4782469272614,
[36m(head, rank=0, pid=3442)[0m     625.9140017032623,
[36m(head, rank=0, pid=3442)[0m     635.0228147506714,
[36m(head, rank=0, pid=3442)[0m     624.0803954601288,
[36m(head, rank=0, pid=3442)[0m     618.5837194919586
[36m(head, rank=0, pid=3442)[0m   ],
[36m(head, rank=0, pid=3442)[0m   "num_batch_samples": 25,
[36m(head, rank=0, pid=3442)[0m   "total_batch_sample_time": 7.583165645599365,
[36m(head, rank=0, pid=3442)[0m   "average_batch_sample_time": 0.3033266258239746,
[36m(head, rank=0, pid=3442)[0m   "min_batch_sample_time": 0.06083941459655762,
[36m(head, rank=0, pid=3442)[0m   "max_batch_sample_time": 1.5066702365875244,
[36m(head, rank=0, pid=3442)[0m   "individual_batch_sample_times": [
[36m(head, rank=0, pid=3442)[0m     0.38025712966918945,
[36m(head, rank=0, pid=3442)[0m     0.08834505081176758,
[36m(head, rank=0, pid=3442)[0m     0.1412816047668457,
[36m(head, rank=0, pid=3442)[0m     0.061011552810668945,
[36m(head, rank=0, pid=3442)[0m     0.06083941459655762,
[36m(head, rank=0, pid=3442)[0m     0.2978529930114746,
[36m(head, rank=0, pid=3442)[0m     0.2027437686920166,
[36m(head, rank=0, pid=3442)[0m     0.40087056159973145,
[36m(head, rank=0, pid=3442)[0m     1.5066702365875244,
[36m(head, rank=0, pid=3442)[0m     0.2957742214202881,
[36m(head, rank=0, pid=3442)[0m     0.27310895919799805,
[36m(head, rank=0, pid=3442)[0m     0.2988440990447998,
[36m(head, rank=0, pid=3442)[0m     0.1280524730682373,
[36m(head, rank=0, pid=3442)[0m     0.24644088745117188,
[36m(head, rank=0, pid=3442)[0m     0.252673864364624,
[36m(head, rank=0, pid=3442)[0m     0.2233881950378418,
[36m(head, rank=0, pid=3442)[0m     0.27696752548217773,
[36m(head, rank=0, pid=3442)[0m     0.2608058452606201,
[36m(head, rank=0, pid=3442)[0m     0.13956522941589355,
[36m(head, rank=0, pid=3442)[0m     0.30768704414367676,
[36m(head, rank=0, pid=3442)[0m     0.1370222568511963,
[36m(head, rank=0, pid=3442)[0m     0.3825376033782959,
[36m(head, rank=0, pid=3442)[0m     0.3477916717529297,
[36m(head, rank=0, pid=3442)[0m     0.28188586235046387,
[36m(head, rank=0, pid=3442)[0m     0.590747594833374
[36m(head, rank=0, pid=3442)[0m   ],
[36m(head, rank=0, pid=3442)[0m   "num_training_steps": 200,
[36m(head, rank=0, pid=3442)[0m   "total_training_step_time": 820.0995137691498,
[36m(head, rank=0, pid=3442)[0m   "average_training_step_time": 4.100497568845749,
[36m(head, rank=0, pid=3442)[0m   "min_training_step_time": 3.5135459899902344,
[36m(head, rank=0, pid=3442)[0m   "max_training_step_time": 9.449189186096191,
[36m(head, rank=0, pid=3442)[0m   "individual_training_step_times": [
[36m(head, rank=0, pid=3442)[0m     6.082111120223999,
[36m(head, rank=0, pid=3442)[0m     4.137019634246826,
[36m(head, rank=0, pid=3442)[0m     4.359653949737549,
[36m(head, rank=0, pid=3442)[0m     3.672677516937256,
[36m(head, rank=0, pid=3442)[0m     4.773275852203369,
[36m(head, rank=0, pid=3442)[0m     3.8468332290649414,
[36m(head, rank=0, pid=3442)[0m     3.604747772216797,
[36m(head, rank=0, pid=3442)[0m     3.680586814880371,
[36m(head, rank=0, pid=3442)[0m     4.135495901107788,
[36m(head, rank=0, pid=3442)[0m     4.768024206161499,
[36m(head, rank=0, pid=3442)[0m     3.656430244445801,
[36m(head, rank=0, pid=3442)[0m     3.727752685546875,
[36m(head, rank=0, pid=3442)[0m     3.6579623222351074,
[36m(head, rank=0, pid=3442)[0m     4.898967504501343,
[36m(head, rank=0, pid=3442)[0m     3.6588408946990967,
[36m(head, rank=0, pid=3442)[0m     4.024798393249512,
[36m(head, rank=0, pid=3442)[0m     4.1390221118927,
[36m(head, rank=0, pid=3442)[0m     3.695798873901367,
[36m(head, rank=0, pid=3442)[0m     3.853951930999756,
[36m(head, rank=0, pid=3442)[0m     3.671435594558716,
[36m(head, rank=0, pid=3442)[0m     4.328242063522339,
[36m(head, rank=0, pid=3442)[0m     3.662219285964966,
[36m(head, rank=0, pid=3442)[0m     4.560378789901733,
[36m(head, rank=0, pid=3442)[0m     3.686946153640747,
[36m(head, rank=0, pid=3442)[0m     5.011504650115967,
[36m(head, rank=0, pid=3442)[0m     3.5702991485595703,
[36m(head, rank=0, pid=3442)[0m     3.792008399963379,
[36m(head, rank=0, pid=3442)[0m     3.686631917953491,
[36m(head, rank=0, pid=3442)[0m     3.686638832092285,
[36m(head, rank=0, pid=3442)[0m     3.6725270748138428,
[36m(head, rank=0, pid=3442)[0m     3.8279941082000732,
[36m(head, rank=0, pid=3442)[0m     4.326137065887451,
[36m(head, rank=0, pid=3442)[0m     4.794512987136841,
[36m(head, rank=0, pid=3442)[0m     3.904542922973633,
[36m(head, rank=0, pid=3442)[0m     3.710742712020874,
[36m(head, rank=0, pid=3442)[0m     4.041815757751465,
[36m(head, rank=0, pid=3442)[0m     4.477088928222656,
[36m(head, rank=0, pid=3442)[0m     4.403865337371826,
[36m(head, rank=0, pid=3442)[0m     3.6702051162719727,
[36m(head, rank=0, pid=3442)[0m     3.8344693183898926,
[36m(head, rank=0, pid=3442)[0m     3.682722568511963,
[36m(head, rank=0, pid=3442)[0m     3.5135459899902344,
[36m(head, rank=0, pid=3442)[0m     4.76223349571228,
[36m(head, rank=0, pid=3442)[0m     3.668062925338745,
[36m(head, rank=0, pid=3442)[0m     6.50824761390686,
[36m(head, rank=0, pid=3442)[0m     3.6599576473236084,
[36m(head, rank=0, pid=3442)[0m     3.806729555130005,
[36m(head, rank=0, pid=3442)[0m     4.006260871887207,
[36m(head, rank=0, pid=3442)[0m     4.745951414108276,
[36m(head, rank=0, pid=3442)[0m     4.763403415679932,
[36m(head, rank=0, pid=3442)[0m     3.658230781555176,
[36m(head, rank=0, pid=3442)[0m     3.6650631427764893,
[36m(head, rank=0, pid=3442)[0m     3.926076889038086,
[36m(head, rank=0, pid=3442)[0m     3.66763973236084,
[36m(head, rank=0, pid=3442)[0m     4.267864465713501,
[36m(head, rank=0, pid=3442)[0m     3.6736841201782227,
[36m(head, rank=0, pid=3442)[0m     5.405500411987305,
[36m(head, rank=0, pid=3442)[0m     4.040645599365234,
[36m(head, rank=0, pid=3442)[0m     3.868955373764038,
[36m(head, rank=0, pid=3442)[0m     4.109880447387695,
[36m(head, rank=0, pid=3442)[0m     3.672534942626953,
[36m(head, rank=0, pid=3442)[0m     3.7126097679138184,
[36m(head, rank=0, pid=3442)[0m     3.669262170791626,
[36m(head, rank=0, pid=3442)[0m     4.463946104049683,
[36m(head, rank=0, pid=3442)[0m     3.667888641357422,
[36m(head, rank=0, pid=3442)[0m     4.150312185287476,
[36m(head, rank=0, pid=3442)[0m     3.734142303466797,
[36m(head, rank=0, pid=3442)[0m     3.5393760204315186,
[36m(head, rank=0, pid=3442)[0m     4.246011734008789,
[36m(head, rank=0, pid=3442)[0m     4.792626142501831,
[36m(head, rank=0, pid=3442)[0m     3.6804513931274414,
[36m(head, rank=0, pid=3442)[0m     3.8617148399353027,
[36m(head, rank=0, pid=3442)[0m     4.627889156341553,
[36m(head, rank=0, pid=3442)[0m     4.138732194900513,
[36m(head, rank=0, pid=3442)[0m     3.728088617324829,
[36m(head, rank=0, pid=3442)[0m     3.867159128189087,
[36m(head, rank=0, pid=3442)[0m     4.00374436378479,
[36m(head, rank=0, pid=3442)[0m     3.67199969291687,
[36m(head, rank=0, pid=3442)[0m     3.669619560241699,
[36m(head, rank=0, pid=3442)[0m     3.680495023727417,
[36m(head, rank=0, pid=3442)[0m     3.6672186851501465,
[36m(head, rank=0, pid=3442)[0m     4.732809543609619,
[36m(head, rank=0, pid=3442)[0m     3.6655497550964355,
[36m(head, rank=0, pid=3442)[0m     8.38368821144104,
[36m(head, rank=0, pid=3442)[0m     3.6734554767608643,
[36m(head, rank=0, pid=3442)[0m     3.847074270248413,
[36m(head, rank=0, pid=3442)[0m     4.225313186645508,
[36m(head, rank=0, pid=3442)[0m     3.6842105388641357,
[36m(head, rank=0, pid=3442)[0m     4.007396697998047,
[36m(head, rank=0, pid=3442)[0m     4.638585567474365,
[36m(head, rank=0, pid=3442)[0m     4.688464403152466,
[36m(head, rank=0, pid=3442)[0m     4.099054336547852,
[36m(head, rank=0, pid=3442)[0m     4.896109342575073,
[36m(head, rank=0, pid=3442)[0m     3.7100489139556885,
[36m(head, rank=0, pid=3442)[0m     3.8733386993408203,
[36m(head, rank=0, pid=3442)[0m     3.6694231033325195,
[36m(head, rank=0, pid=3442)[0m     3.6675753593444824,
[36m(head, rank=0, pid=3442)[0m     4.940654993057251,
[36m(head, rank=0, pid=3442)[0m     3.685685396194458,
[36m(head, rank=0, pid=3442)[0m     4.127200603485107,
[36m(head, rank=0, pid=3442)[0m     3.6807761192321777,
[36m(head, rank=0, pid=3442)[0m     3.6680831909179688,
[36m(head, rank=0, pid=3442)[0m     3.95778751373291,
[36m(head, rank=0, pid=3442)[0m     3.620183229446411,
[36m(head, rank=0, pid=3442)[0m     3.8514280319213867,
[36m(head, rank=0, pid=3442)[0m     3.673673391342163,
[36m(head, rank=0, pid=3442)[0m     4.8213324546813965,
[36m(head, rank=0, pid=3442)[0m     4.925596237182617,
[36m(head, rank=0, pid=3442)[0m     3.598360300064087,
[36m(head, rank=0, pid=3442)[0m     3.6826107501983643,
[36m(head, rank=0, pid=3442)[0m     3.680964231491089,
[36m(head, rank=0, pid=3442)[0m     3.6792116165161133,
[36m(head, rank=0, pid=3442)[0m     5.051176071166992,
[36m(head, rank=0, pid=3442)[0m     3.9942612648010254,
[36m(head, rank=0, pid=3442)[0m     4.451862096786499,
[36m(head, rank=0, pid=3442)[0m     3.685270309448242,
[36m(head, rank=0, pid=3442)[0m     3.753436326980591,
[36m(head, rank=0, pid=3442)[0m     3.6944448947906494,
[36m(head, rank=0, pid=3442)[0m     3.8007569313049316,
[36m(head, rank=0, pid=3442)[0m     4.37457275390625,
[36m(head, rank=0, pid=3442)[0m     9.449189186096191,
[36m(head, rank=0, pid=3442)[0m     3.659820079803467,
[36m(head, rank=0, pid=3442)[0m     4.087396621704102,
[36m(head, rank=0, pid=3442)[0m     3.816269636154175,
[36m(head, rank=0, pid=3442)[0m     4.280553340911865,
[36m(head, rank=0, pid=3442)[0m     4.414016485214233,
[36m(head, rank=0, pid=3442)[0m     4.535991907119751,
[36m(head, rank=0, pid=3442)[0m     3.5228028297424316,
[36m(head, rank=0, pid=3442)[0m     4.508650064468384,
[36m(head, rank=0, pid=3442)[0m     4.943737030029297,
[36m(head, rank=0, pid=3442)[0m     4.822918891906738,
[36m(head, rank=0, pid=3442)[0m     3.6689841747283936,
[36m(head, rank=0, pid=3442)[0m     3.67229962348938,
[36m(head, rank=0, pid=3442)[0m     3.6834828853607178,
[36m(head, rank=0, pid=3442)[0m     3.836383581161499,
[36m(head, rank=0, pid=3442)[0m     3.6686394214630127,
[36m(head, rank=0, pid=3442)[0m     3.8762433528900146,
[36m(head, rank=0, pid=3442)[0m     3.9399986267089844,
[36m(head, rank=0, pid=3442)[0m     4.42216420173645,
[36m(head, rank=0, pid=3442)[0m     4.088910102844238,
[36m(head, rank=0, pid=3442)[0m     3.9441235065460205,
[36m(head, rank=0, pid=3442)[0m     4.617703199386597,
[36m(head, rank=0, pid=3442)[0m     3.666142463684082,
[36m(head, rank=0, pid=3442)[0m     3.8710196018218994,
[36m(head, rank=0, pid=3442)[0m     3.959066152572632,
[36m(head, rank=0, pid=3442)[0m     4.293790340423584,
[36m(head, rank=0, pid=3442)[0m     3.670140266418457,
[36m(head, rank=0, pid=3442)[0m     4.366088628768921,
[36m(head, rank=0, pid=3442)[0m     3.6680538654327393,
[36m(head, rank=0, pid=3442)[0m     3.6718358993530273,
[36m(head, rank=0, pid=3442)[0m     4.716587781906128,
[36m(head, rank=0, pid=3442)[0m     3.6709835529327393,
[36m(head, rank=0, pid=3442)[0m     3.9280848503112793,
[36m(head, rank=0, pid=3442)[0m     3.717869997024536,
[36m(head, rank=0, pid=3442)[0m     3.678272247314453,
[36m(head, rank=0, pid=3442)[0m     3.6686336994171143,
[36m(head, rank=0, pid=3442)[0m     3.665254592895508,
[36m(head, rank=0, pid=3442)[0m     3.5409371852874756,
[36m(head, rank=0, pid=3442)[0m     3.662656545639038,
[36m(head, rank=0, pid=3442)[0m     4.683438539505005,
[36m(head, rank=0, pid=3442)[0m     3.5382721424102783,
[36m(head, rank=0, pid=3442)[0m     4.288809299468994,
[36m(head, rank=0, pid=3442)[0m     5.006460189819336,
[36m(head, rank=0, pid=3442)[0m     3.7802443504333496,
[36m(head, rank=0, pid=3442)[0m     3.6619880199432373,
[36m(head, rank=0, pid=3442)[0m     3.6591994762420654,
[36m(head, rank=0, pid=3442)[0m     3.6690433025360107,
[36m(head, rank=0, pid=3442)[0m     6.517585515975952,
[36m(head, rank=0, pid=3442)[0m     3.7410202026367188,
[36m(head, rank=0, pid=3442)[0m     4.776158571243286,
[36m(head, rank=0, pid=3442)[0m     3.7042906284332275,
[36m(head, rank=0, pid=3442)[0m     3.853433132171631,
[36m(head, rank=0, pid=3442)[0m     3.7653908729553223,
[36m(head, rank=0, pid=3442)[0m     3.6698431968688965,
[36m(head, rank=0, pid=3442)[0m     4.637605428695679,
[36m(head, rank=0, pid=3442)[0m     4.082735061645508,
[36m(head, rank=0, pid=3442)[0m     4.716008186340332,
[36m(head, rank=0, pid=3442)[0m     4.9137303829193115,
[36m(head, rank=0, pid=3442)[0m     4.459279537200928,
[36m(head, rank=0, pid=3442)[0m     4.532241106033325,
[36m(head, rank=0, pid=3442)[0m     3.82216477394104,
[36m(head, rank=0, pid=3442)[0m     4.467235803604126,
[36m(head, rank=0, pid=3442)[0m     4.479982852935791,
[36m(head, rank=0, pid=3442)[0m     3.7425031661987305,
[36m(head, rank=0, pid=3442)[0m     4.0530290603637695,
[36m(head, rank=0, pid=3442)[0m     3.790985584259033,
[36m(head, rank=0, pid=3442)[0m     4.522022247314453,
[36m(head, rank=0, pid=3442)[0m     3.6685376167297363,
[36m(head, rank=0, pid=3442)[0m     4.181723356246948,
[36m(head, rank=0, pid=3442)[0m     3.6741831302642822,
[36m(head, rank=0, pid=3442)[0m     3.6812825202941895,
[36m(head, rank=0, pid=3442)[0m     3.9588794708251953,
[36m(head, rank=0, pid=3442)[0m     3.7193233966827393,
[36m(head, rank=0, pid=3442)[0m     3.553040027618408,
[36m(head, rank=0, pid=3442)[0m     3.5493409633636475,
[36m(head, rank=0, pid=3442)[0m     3.6600756645202637,
[36m(head, rank=0, pid=3442)[0m     3.6611006259918213,
[36m(head, rank=0, pid=3442)[0m     4.185717821121216,
[36m(head, rank=0, pid=3442)[0m     4.803048610687256,
[36m(head, rank=0, pid=3442)[0m     4.19080114364624
[36m(head, rank=0, pid=3442)[0m   ]
[36m(head, rank=0, pid=3442)[0m }
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m --- All Training Runs Summary ---
[36m(head, rank=0, pid=3442)[0m [
[36m(head, rank=0, pid=3442)[0m   {
[36m(head, rank=0, pid=3442)[0m     "run_id": 1,
[36m(head, rank=0, pid=3442)[0m     "timestamp": "2025-08-04T03:26:08.206399",
[36m(head, rank=0, pid=3442)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3442)[0m     "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3442)[0m     "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3442)[0m     "training_status": "completed",
[36m(head, rank=0, pid=3442)[0m     "output_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3442)[0m     "dataset_load_time": 2.4535374641418457,
[36m(head, rank=0, pid=3442)[0m     "model_load_time": 108.58293414115906,
[36m(head, rank=0, pid=3442)[0m     "training_time": 4094.197447538376,
[36m(head, rank=0, pid=3442)[0m     "total_time": 4205.233919143677,
[36m(head, rank=0, pid=3442)[0m     "error": null,
[36m(head, rank=0, pid=3442)[0m     "num_checkpoints_saved": 5,
[36m(head, rank=0, pid=3442)[0m     "total_checkpoint_save_time": 3118.0791783332825,
[36m(head, rank=0, pid=3442)[0m     "average_checkpoint_save_time": 623.6158356666565,
[36m(head, rank=0, pid=3442)[0m     "min_checkpoint_save_time": 614.4782469272614,
[36m(head, rank=0, pid=3442)[0m     "max_checkpoint_save_time": 635.0228147506714,
[36m(head, rank=0, pid=3442)[0m     "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3442)[0m       614.4782469272614,
[36m(head, rank=0, pid=3442)[0m       625.9140017032623,
[36m(head, rank=0, pid=3442)[0m       635.0228147506714,
[36m(head, rank=0, pid=3442)[0m       624.0803954601288,
[36m(head, rank=0, pid=3442)[0m       618.5837194919586
[36m(head, rank=0, pid=3442)[0m     ],
[36m(head, rank=0, pid=3442)[0m     "num_batch_samples": 25,
[36m(head, rank=0, pid=3442)[0m     "total_batch_sample_time": 7.583165645599365,
[36m(head, rank=0, pid=3442)[0m     "average_batch_sample_time": 0.3033266258239746,
[36m(head, rank=0, pid=3442)[0m     "min_batch_sample_time": 0.06083941459655762,
[36m(head, rank=0, pid=3442)[0m     "max_batch_sample_time": 1.5066702365875244,
[36m(head, rank=0, pid=3442)[0m     "individual_batch_sample_times": [
[36m(head, rank=0, pid=3442)[0m       0.38025712966918945,
[36m(head, rank=0, pid=3442)[0m       0.08834505081176758,
[36m(head, rank=0, pid=3442)[0m       0.1412816047668457,
[36m(head, rank=0, pid=3442)[0m       0.061011552810668945,
[36m(head, rank=0, pid=3442)[0m       0.06083941459655762,
[36m(head, rank=0, pid=3442)[0m       0.2978529930114746,
[36m(head, rank=0, pid=3442)[0m       0.2027437686920166,
[36m(head, rank=0, pid=3442)[0m       0.40087056159973145,
[36m(head, rank=0, pid=3442)[0m       1.5066702365875244,
[36m(head, rank=0, pid=3442)[0m       0.2957742214202881,
[36m(head, rank=0, pid=3442)[0m       0.27310895919799805,
[36m(head, rank=0, pid=3442)[0m       0.2988440990447998,
[36m(head, rank=0, pid=3442)[0m       0.1280524730682373,
[36m(head, rank=0, pid=3442)[0m       0.24644088745117188,
[36m(head, rank=0, pid=3442)[0m       0.252673864364624,
[36m(head, rank=0, pid=3442)[0m       0.2233881950378418,
[36m(head, rank=0, pid=3442)[0m       0.27696752548217773,
[36m(head, rank=0, pid=3442)[0m       0.2608058452606201,
[36m(head, rank=0, pid=3442)[0m       0.13956522941589355,
[36m(head, rank=0, pid=3442)[0m       0.30768704414367676,
[36m(head, rank=0, pid=3442)[0m       0.1370222568511963,
[36m(head, rank=0, pid=3442)[0m       0.3825376033782959,
[36m(head, rank=0, pid=3442)[0m       0.3477916717529297,
[36m(head, rank=0, pid=3442)[0m       0.28188586235046387,
[36m(head, rank=0, pid=3442)[0m       0.590747594833374
[36m(head, rank=0, pid=3442)[0m     ],
[36m(head, rank=0, pid=3442)[0m     "num_training_steps": 200,
[36m(head, rank=0, pid=3442)[0m     "total_training_step_time": 820.0995137691498,
[36m(head, rank=0, pid=3442)[0m     "average_training_step_time": 4.100497568845749,
[36m(head, rank=0, pid=3442)[0m     "min_training_step_time": 3.5135459899902344,
[36m(head, rank=0, pid=3442)[0m     "max_training_step_time": 9.449189186096191,
[36m(head, rank=0, pid=3442)[0m     "individual_training_step_times": [
[36m(head, rank=0, pid=3442)[0m       6.082111120223999,
[36m(head, rank=0, pid=3442)[0m       4.137019634246826,
[36m(head, rank=0, pid=3442)[0m       4.359653949737549,
[36m(head, rank=0, pid=3442)[0m       3.672677516937256,
[36m(head, rank=0, pid=3442)[0m       4.773275852203369,
[36m(head, rank=0, pid=3442)[0m       3.8468332290649414,
[36m(head, rank=0, pid=3442)[0m       3.604747772216797,
[36m(head, rank=0, pid=3442)[0m       3.680586814880371,
[36m(head, rank=0, pid=3442)[0m       4.135495901107788,
[36m(head, rank=0, pid=3442)[0m       4.768024206161499,
[36m(head, rank=0, pid=3442)[0m       3.656430244445801,
[36m(head, rank=0, pid=3442)[0m       3.727752685546875,
[36m(head, rank=0, pid=3442)[0m       3.6579623222351074,
[36m(head, rank=0, pid=3442)[0m       4.898967504501343,
[36m(head, rank=0, pid=3442)[0m       3.6588408946990967,
[36m(head, rank=0, pid=3442)[0m       4.024798393249512,
[36m(head, rank=0, pid=3442)[0m       4.1390221118927,
[36m(head, rank=0, pid=3442)[0m       3.695798873901367,
[36m(head, rank=0, pid=3442)[0m       3.853951930999756,
[36m(head, rank=0, pid=3442)[0m       3.671435594558716,
[36m(head, rank=0, pid=3442)[0m       4.328242063522339,
[36m(head, rank=0, pid=3442)[0m       3.662219285964966,
[36m(head, rank=0, pid=3442)[0m       4.560378789901733,
[36m(head, rank=0, pid=3442)[0m       3.686946153640747,
[36m(head, rank=0, pid=3442)[0m       5.011504650115967,
[36m(head, rank=0, pid=3442)[0m       3.5702991485595703,
[36m(head, rank=0, pid=3442)[0m       3.792008399963379,
[36m(head, rank=0, pid=3442)[0m       3.686631917953491,
[36m(head, rank=0, pid=3442)[0m       3.686638832092285,
[36m(head, rank=0, pid=3442)[0m       3.6725270748138428,
[36m(head, rank=0, pid=3442)[0m       3.8279941082000732,
[36m(head, rank=0, pid=3442)[0m       4.326137065887451,
[36m(head, rank=0, pid=3442)[0m       4.794512987136841,
[36m(head, rank=0, pid=3442)[0m       3.904542922973633,
[36m(head, rank=0, pid=3442)[0m       3.710742712020874,
[36m(head, rank=0, pid=3442)[0m       4.041815757751465,
[36m(head, rank=0, pid=3442)[0m       4.477088928222656,
[36m(head, rank=0, pid=3442)[0m       4.403865337371826,
[36m(head, rank=0, pid=3442)[0m       3.6702051162719727,
[36m(head, rank=0, pid=3442)[0m       3.8344693183898926,
[36m(head, rank=0, pid=3442)[0m       3.682722568511963,
[36m(head, rank=0, pid=3442)[0m       3.5135459899902344,
[36m(head, rank=0, pid=3442)[0m       4.76223349571228,
[36m(head, rank=0, pid=3442)[0m       3.668062925338745,
[36m(head, rank=0, pid=3442)[0m       6.50824761390686,
[36m(head, rank=0, pid=3442)[0m       3.6599576473236084,
[36m(head, rank=0, pid=3442)[0m       3.806729555130005,
[36m(head, rank=0, pid=3442)[0m       4.006260871887207,
[36m(head, rank=0, pid=3442)[0m       4.745951414108276,
[36m(head, rank=0, pid=3442)[0m       4.763403415679932,
[36m(head, rank=0, pid=3442)[0m       3.658230781555176,
[36m(head, rank=0, pid=3442)[0m       3.6650631427764893,
[36m(head, rank=0, pid=3442)[0m       3.926076889038086,
[36m(head, rank=0, pid=3442)[0m       3.66763973236084,
[36m(head, rank=0, pid=3442)[0m       4.267864465713501,
[36m(head, rank=0, pid=3442)[0m       3.6736841201782227,
[36m(head, rank=0, pid=3442)[0m       5.405500411987305,
[36m(head, rank=0, pid=3442)[0m       4.040645599365234,
[36m(head, rank=0, pid=3442)[0m       3.868955373764038,
[36m(head, rank=0, pid=3442)[0m       4.109880447387695,
[36m(head, rank=0, pid=3442)[0m       3.672534942626953,
[36m(head, rank=0, pid=3442)[0m       3.7126097679138184,
[36m(head, rank=0, pid=3442)[0m       3.669262170791626,
[36m(head, rank=0, pid=3442)[0m       4.463946104049683,
[36m(head, rank=0, pid=3442)[0m       3.667888641357422,
[36m(head, rank=0, pid=3442)[0m       4.150312185287476,
[36m(head, rank=0, pid=3442)[0m       3.734142303466797,
[36m(head, rank=0, pid=3442)[0m       3.5393760204315186,
[36m(head, rank=0, pid=3442)[0m       4.246011734008789,
[36m(head, rank=0, pid=3442)[0m       4.792626142501831,
[36m(head, rank=0, pid=3442)[0m       3.6804513931274414,
[36m(head, rank=0, pid=3442)[0m       3.8617148399353027,
[36m(head, rank=0, pid=3442)[0m       4.627889156341553,
[36m(head, rank=0, pid=3442)[0m       4.138732194900513,
[36m(head, rank=0, pid=3442)[0m       3.728088617324829,
[36m(head, rank=0, pid=3442)[0m       3.867159128189087,
[36m(head, rank=0, pid=3442)[0m       4.00374436378479,
[36m(head, rank=0, pid=3442)[0m       3.67199969291687,
[36m(head, rank=0, pid=3442)[0m       3.669619560241699,
[36m(head, rank=0, pid=3442)[0m       3.680495023727417,
[36m(head, rank=0, pid=3442)[0m       3.6672186851501465,
[36m(head, rank=0, pid=3442)[0m       4.732809543609619,
[36m(head, rank=0, pid=3442)[0m       3.6655497550964355,
[36m(head, rank=0, pid=3442)[0m       8.38368821144104,
[36m(head, rank=0, pid=3442)[0m       3.6734554767608643,
[36m(head, rank=0, pid=3442)[0m       3.847074270248413,
[36m(head, rank=0, pid=3442)[0m       4.225313186645508,
[36m(head, rank=0, pid=3442)[0m       3.6842105388641357,
[36m(head, rank=0, pid=3442)[0m       4.007396697998047,
[36m(head, rank=0, pid=3442)[0m       4.638585567474365,
[36m(head, rank=0, pid=3442)[0m       4.688464403152466,
[36m(head, rank=0, pid=3442)[0m       4.099054336547852,
[36m(head, rank=0, pid=3442)[0m       4.896109342575073,
[36m(head, rank=0, pid=3442)[0m       3.7100489139556885,
[36m(head, rank=0, pid=3442)[0m       3.8733386993408203,
[36m(head, rank=0, pid=3442)[0m       3.6694231033325195,
[36m(head, rank=0, pid=3442)[0m       3.6675753593444824,
[36m(head, rank=0, pid=3442)[0m       4.940654993057251,
[36m(head, rank=0, pid=3442)[0m       3.685685396194458,
[36m(head, rank=0, pid=3442)[0m       4.127200603485107,
[36m(head, rank=0, pid=3442)[0m       3.6807761192321777,
[36m(head, rank=0, pid=3442)[0m       3.6680831909179688,
[36m(head, rank=0, pid=3442)[0m       3.95778751373291,
[36m(head, rank=0, pid=3442)[0m       3.620183229446411,
[36m(head, rank=0, pid=3442)[0m       3.8514280319213867,
[36m(head, rank=0, pid=3442)[0m       3.673673391342163,
[36m(head, rank=0, pid=3442)[0m       4.8213324546813965,
[36m(head, rank=0, pid=3442)[0m       4.925596237182617,
[36m(head, rank=0, pid=3442)[0m       3.598360300064087,
[36m(head, rank=0, pid=3442)[0m       3.6826107501983643,
[36m(head, rank=0, pid=3442)[0m       3.680964231491089,
[36m(head, rank=0, pid=3442)[0m       3.6792116165161133,
[36m(head, rank=0, pid=3442)[0m       5.051176071166992,
[36m(head, rank=0, pid=3442)[0m       3.9942612648010254,
[36m(head, rank=0, pid=3442)[0m       4.451862096786499,
[36m(head, rank=0, pid=3442)[0m       3.685270309448242,
[36m(head, rank=0, pid=3442)[0m       3.753436326980591,
[36m(head, rank=0, pid=3442)[0m       3.6944448947906494,
[36m(head, rank=0, pid=3442)[0m       3.8007569313049316,
[36m(head, rank=0, pid=3442)[0m       4.37457275390625,
[36m(head, rank=0, pid=3442)[0m       9.449189186096191,
[36m(head, rank=0, pid=3442)[0m       3.659820079803467,
[36m(head, rank=0, pid=3442)[0m       4.087396621704102,
[36m(head, rank=0, pid=3442)[0m       3.816269636154175,
[36m(head, rank=0, pid=3442)[0m       4.280553340911865,
[36m(head, rank=0, pid=3442)[0m       4.414016485214233,
[36m(head, rank=0, pid=3442)[0m       4.535991907119751,
[36m(head, rank=0, pid=3442)[0m       3.5228028297424316,
[36m(head, rank=0, pid=3442)[0m       4.508650064468384,
[36m(head, rank=0, pid=3442)[0m       4.943737030029297,
[36m(head, rank=0, pid=3442)[0m       4.822918891906738,
[36m(head, rank=0, pid=3442)[0m       3.6689841747283936,
[36m(head, rank=0, pid=3442)[0m       3.67229962348938,
[36m(head, rank=0, pid=3442)[0m       3.6834828853607178,
[36m(head, rank=0, pid=3442)[0m       3.836383581161499,
[36m(head, rank=0, pid=3442)[0m       3.6686394214630127,
[36m(head, rank=0, pid=3442)[0m       3.8762433528900146,
[36m(head, rank=0, pid=3442)[0m       3.9399986267089844,
[36m(head, rank=0, pid=3442)[0m       4.42216420173645,
[36m(head, rank=0, pid=3442)[0m       4.088910102844238,
[36m(head, rank=0, pid=3442)[0m       3.9441235065460205,
[36m(head, rank=0, pid=3442)[0m       4.617703199386597,
[36m(head, rank=0, pid=3442)[0m       3.666142463684082,
[36m(head, rank=0, pid=3442)[0m       3.8710196018218994,
[36m(head, rank=0, pid=3442)[0m       3.959066152572632,
[36m(head, rank=0, pid=3442)[0m       4.293790340423584,
[36m(head, rank=0, pid=3442)[0m       3.670140266418457,
[36m(head, rank=0, pid=3442)[0m       4.366088628768921,
[36m(head, rank=0, pid=3442)[0m       3.6680538654327393,
[36m(head, rank=0, pid=3442)[0m       3.6718358993530273,
[36m(head, rank=0, pid=3442)[0m       4.716587781906128,
[36m(head, rank=0, pid=3442)[0m       3.6709835529327393,
[36m(head, rank=0, pid=3442)[0m       3.9280848503112793,
[36m(head, rank=0, pid=3442)[0m       3.717869997024536,
[36m(head, rank=0, pid=3442)[0m       3.678272247314453,
[36m(head, rank=0, pid=3442)[0m       3.6686336994171143,
[36m(head, rank=0, pid=3442)[0m       3.665254592895508,
[36m(head, rank=0, pid=3442)[0m       3.5409371852874756,
[36m(head, rank=0, pid=3442)[0m       3.662656545639038,
[36m(head, rank=0, pid=3442)[0m       4.683438539505005,
[36m(head, rank=0, pid=3442)[0m       3.5382721424102783,
[36m(head, rank=0, pid=3442)[0m       4.288809299468994,
[36m(head, rank=0, pid=3442)[0m       5.006460189819336,
[36m(head, rank=0, pid=3442)[0m       3.7802443504333496,
[36m(head, rank=0, pid=3442)[0m       3.6619880199432373,
[36m(head, rank=0, pid=3442)[0m       3.6591994762420654,
[36m(head, rank=0, pid=3442)[0m       3.6690433025360107,
[36m(head, rank=0, pid=3442)[0m       6.517585515975952,
[36m(head, rank=0, pid=3442)[0m       3.7410202026367188,
[36m(head, rank=0, pid=3442)[0m       4.776158571243286,
[36m(head, rank=0, pid=3442)[0m       3.7042906284332275,
[36m(head, rank=0, pid=3442)[0m       3.853433132171631,
[36m(head, rank=0, pid=3442)[0m       3.7653908729553223,
[36m(head, rank=0, pid=3442)[0m       3.6698431968688965,
[36m(head, rank=0, pid=3442)[0m       4.637605428695679,
[36m(head, rank=0, pid=3442)[0m       4.082735061645508,
[36m(head, rank=0, pid=3442)[0m       4.716008186340332,
[36m(head, rank=0, pid=3442)[0m       4.9137303829193115,
[36m(head, rank=0, pid=3442)[0m       4.459279537200928,
[36m(head, rank=0, pid=3442)[0m       4.532241106033325,
[36m(head, rank=0, pid=3442)[0m       3.82216477394104,
[36m(head, rank=0, pid=3442)[0m       4.467235803604126,
[36m(head, rank=0, pid=3442)[0m       4.479982852935791,
[36m(head, rank=0, pid=3442)[0m       3.7425031661987305,
[36m(head, rank=0, pid=3442)[0m       4.0530290603637695,
[36m(head, rank=0, pid=3442)[0m       3.790985584259033,
[36m(head, rank=0, pid=3442)[0m       4.522022247314453,
[36m(head, rank=0, pid=3442)[0m       3.6685376167297363,
[36m(head, rank=0, pid=3442)[0m       4.181723356246948,
[36m(head, rank=0, pid=3442)[0m       3.6741831302642822,
[36m(head, rank=0, pid=3442)[0m       3.6812825202941895,
[36m(head, rank=0, pid=3442)[0m       3.9588794708251953,
[36m(head, rank=0, pid=3442)[0m       3.7193233966827393,
[36m(head, rank=0, pid=3442)[0m       3.553040027618408,
[36m(head, rank=0, pid=3442)[0m       3.5493409633636475,
[36m(head, rank=0, pid=3442)[0m       3.6600756645202637,
[36m(head, rank=0, pid=3442)[0m       3.6611006259918213,
[36m(head, rank=0, pid=3442)[0m       4.185717821121216,
[36m(head, rank=0, pid=3442)[0m       4.803048610687256,
[36m(head, rank=0, pid=3442)[0m       4.19080114364624
[36m(head, rank=0, pid=3442)[0m     ]
[36m(head, rank=0, pid=3442)[0m   }
[36m(head, rank=0, pid=3442)[0m ]
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m --- Timing Summary ---
[36m(head, rank=0, pid=3442)[0m {
[36m(head, rank=0, pid=3442)[0m   "total_runs": 1,
[36m(head, rank=0, pid=3442)[0m   "dataset_loading": {
[36m(head, rank=0, pid=3442)[0m     "dataset_load_count": 1,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_average": 2.4535374641418457,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_min": 2.4535374641418457,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_max": 2.4535374641418457,
[36m(head, rank=0, pid=3442)[0m     "dataset_load_total": 2.4535374641418457
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "model_loading": {
[36m(head, rank=0, pid=3442)[0m     "model_load_count": 1,
[36m(head, rank=0, pid=3442)[0m     "model_load_average": 108.58293414115906,
[36m(head, rank=0, pid=3442)[0m     "model_load_min": 108.58293414115906,
[36m(head, rank=0, pid=3442)[0m     "model_load_max": 108.58293414115906,
[36m(head, rank=0, pid=3442)[0m     "model_load_total": 108.58293414115906
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "training": {
[36m(head, rank=0, pid=3442)[0m     "training_count": 1,
[36m(head, rank=0, pid=3442)[0m     "training_average": 4094.197447538376,
[36m(head, rank=0, pid=3442)[0m     "training_min": 4094.197447538376,
[36m(head, rank=0, pid=3442)[0m     "training_max": 4094.197447538376,
[36m(head, rank=0, pid=3442)[0m     "training_total": 4094.197447538376
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "total_run_time": {
[36m(head, rank=0, pid=3442)[0m     "total_count": 1,
[36m(head, rank=0, pid=3442)[0m     "total_average": 4205.233919143677,
[36m(head, rank=0, pid=3442)[0m     "total_min": 4205.233919143677,
[36m(head, rank=0, pid=3442)[0m     "total_max": 4205.233919143677,
[36m(head, rank=0, pid=3442)[0m     "total_total": 4205.233919143677
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "checkpoint_saving": {
[36m(head, rank=0, pid=3442)[0m     "total_checkpoints_saved": 5,
[36m(head, rank=0, pid=3442)[0m     "total_checkpoint_save_time": 3118.0791783332825,
[36m(head, rank=0, pid=3442)[0m     "average_save_time_per_checkpoint": 623.6158356666565,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_times_count": 5,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_min": 614.4782469272614,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_max": 635.0228147506714,
[36m(head, rank=0, pid=3442)[0m     "checkpoint_save_average": 623.6158356666565
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "batch_sampling": {
[36m(head, rank=0, pid=3442)[0m     "total_batch_samples": 25,
[36m(head, rank=0, pid=3442)[0m     "total_batch_sample_time": 7.583165645599365,
[36m(head, rank=0, pid=3442)[0m     "average_sample_time_per_batch": 0.3033266258239746,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_times_count": 25,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_min": 0.06083941459655762,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_max": 1.5066702365875244,
[36m(head, rank=0, pid=3442)[0m     "batch_sample_average": 0.3033266258239746
[36m(head, rank=0, pid=3442)[0m   },
[36m(head, rank=0, pid=3442)[0m   "training_steps": {
[36m(head, rank=0, pid=3442)[0m     "total_training_steps": 200,
[36m(head, rank=0, pid=3442)[0m     "total_training_step_time": 820.0995137691498,
[36m(head, rank=0, pid=3442)[0m     "average_step_time_per_step": 4.100497568845749,
[36m(head, rank=0, pid=3442)[0m     "training_step_times_count": 200,
[36m(head, rank=0, pid=3442)[0m     "training_step_min": 3.5135459899902344,
[36m(head, rank=0, pid=3442)[0m     "training_step_max": 9.449189186096191,
[36m(head, rank=0, pid=3442)[0m     "training_step_average": 4.100497568845749
[36m(head, rank=0, pid=3442)[0m   }
[36m(head, rank=0, pid=3442)[0m }
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.44s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.13s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.13s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.13s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.13s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4201.28s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4201.28s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4201.28s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4201.28s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 8.95s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 252.74s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1790.98s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 6.21s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.06s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 43.28s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 155.26s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 346.59s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 339.88s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 357.55s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1732.94s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4204.84s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4204.84s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4204.84s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4204.84s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.44s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.43s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.43s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.43s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.43s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4201.21s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4201.21s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4201.21s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4201.21s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 8.95s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 252.75s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1789.86s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 6.26s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.04s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 43.26s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 156.38s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 346.59s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 339.88s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 357.56s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1732.94s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4205.08s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4205.08s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4205.08s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4205.08s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Min time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Max time: 2.44s
[36m(head, rank=0, pid=3442)[0m   • Total time: 2.44s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.13s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.13s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.13s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.13s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4201.27s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4201.27s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4201.27s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4201.27s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 8.95s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.51s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 252.64s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1790.55s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 6.23s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 43.31s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 155.76s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 346.59s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 339.88s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 357.56s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1732.95s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4204.84s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4204.84s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4204.84s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4204.84s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_5.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 5.92s
[36m(head, rank=0, pid=3442)[0m   • Min time: 5.92s
[36m(head, rank=0, pid=3442)[0m   • Max time: 5.92s
[36m(head, rank=0, pid=3442)[0m   • Total time: 5.92s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Model Loading Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 1.01s
[36m(head, rank=0, pid=3442)[0m   • Min time: 1.01s
[36m(head, rank=0, pid=3442)[0m   • Max time: 1.01s
[36m(head, rank=0, pid=3442)[0m   • Total time: 1.01s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Performance:
[36m(head, rank=0, pid=3442)[0m   • Average time: 4198.29s
[36m(head, rank=0, pid=3442)[0m   • Min time: 4198.29s
[36m(head, rank=0, pid=3442)[0m   • Max time: 4198.29s
[36m(head, rank=0, pid=3442)[0m   • Total time: 4198.29s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Training Step Performance:
[36m(head, rank=0, pid=3442)[0m   • Total training steps: 200
[36m(head, rank=0, pid=3442)[0m   • Average step time per step: 8.95s
[36m(head, rank=0, pid=3442)[0m   • Min step time: 3.52s
[36m(head, rank=0, pid=3442)[0m   • Max step time: 252.66s
[36m(head, rank=0, pid=3442)[0m   • Total training step time: 1789.68s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3442)[0m   • Total batch samples: 25
[36m(head, rank=0, pid=3442)[0m   • Average sample time per batch: 6.25s
[36m(head, rank=0, pid=3442)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3442)[0m   • Max sample time: 43.30s
[36m(head, rank=0, pid=3442)[0m   • Total batch sample time: 156.30s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3442)[0m   • Total checkpoints saved: 5
[36m(head, rank=0, pid=3442)[0m   • Average save time per checkpoint: 346.59s
[36m(head, rank=0, pid=3442)[0m   • Min save time: 339.88s
[36m(head, rank=0, pid=3442)[0m   • Max save time: 357.56s
[36m(head, rank=0, pid=3442)[0m   • Total checkpoint save time: 1732.94s
[36m(head, rank=0, pid=3442)[0m 
[36m(head, rank=0, pid=3442)[0m Overall Run Performance:
[36m(head, rank=0, pid=3442)[0m   • Average total time per run: 4205.23s
[36m(head, rank=0, pid=3442)[0m   • Min total time: 4205.23s
[36m(head, rank=0, pid=3442)[0m   • Max total time: 4205.23s
[36m(head, rank=0, pid=3442)[0m   • Total time across all runs: 4205.23s
[36m(head, rank=0, pid=3442)[0m ================================================================================
[36m(head, rank=0, pid=3442)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 4201.15s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4201.15s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4201.15s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================  • Total time: 4201.15s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 8.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 252.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1796.86s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.01s  • Average time: 2.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s  • Min time: 2.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 42.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 150.23s  • Max time: 2.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.04s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 346.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 339.89s  • Min time: 1.04s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 357.57s  • Max time: 1.04s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1733.00s  • Total time: 1.04s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 4204.73s  • Average time: 4201.13s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 4204.73s  • Min time: 4201.13s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 4204.73s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4201.13s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 4204.73s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4201.13s================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 8.99s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.54s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 252.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1797.21s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 42.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 150.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 346.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 339.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 357.58s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1733.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 4204.71s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 4204.71s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 4204.71s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 4204.71s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 4201.15s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4201.15s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4201.15s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4201.15s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 8.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 252.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1795.43s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 42.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 149.95s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 346.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 339.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 357.57s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1733.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 4204.73s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 4204.73s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 4204.73s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 4204.73s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_4.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 4201.15s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4201.15s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4201.15s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4201.15s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 8.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 252.85s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1796.63s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 42.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 150.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 346.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 339.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 357.57s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1733.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 4204.72s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 4204.72s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 4204.72s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 4204.72s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 108.76s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 108.76s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 108.76s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 108.76s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 4094.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4094.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4094.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4094.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 8.97s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 252.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1794.56s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 42.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 149.93s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 346.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 339.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 357.58s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1733.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 4205.29s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 4205.29s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 4205.29s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 4205.29s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_0.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m --- Training Run 1 Info (Directory: /checkpoints_s3_mount_cached) ---
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "run_id": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "timestamp": "2025-08-04T03:26:08.205563",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training_status": "completed",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "output_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "dataset_load_time": 2.511092185974121,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "model_load_time": 108.76317548751831,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training_time": 4094.02054977417,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_time": 4205.294817447662,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "error": null,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "num_checkpoints_saved": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_checkpoint_save_time": 1733.0068826675415,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "average_checkpoint_save_time": 346.6013765335083,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "min_checkpoint_save_time": 339.89280819892883,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "max_checkpoint_save_time": 357.57605504989624,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     339.89280819892883,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     342.5030782222748,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     357.57605504989624,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     341.4221839904785,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     351.61275720596313
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "num_batch_samples": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_batch_sample_time": 149.93164825439453,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "average_batch_sample_time": 5.997265930175781,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "min_batch_sample_time": 0.03078317642211914,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "max_batch_sample_time": 42.9773051738739,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.11854004859924316,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.18291115760803223,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03877592086791992,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.1264352798461914,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.08548545837402344,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     37.18442678451538,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.0348813533782959,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.08180546760559082,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.04030251502990723,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03433680534362793,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     42.9773051738739,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.032769203186035156,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.07843351364135742,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03827714920043945,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03278803825378418,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     34.116602420806885,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03187894821166992,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03644061088562012,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03078317642211914,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03419184684753418,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     34.21334624290466,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.035974979400634766,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03318476676940918,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.03549003601074219,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     0.27628135681152344
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "num_training_steps": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_training_step_time": 1794.563717365265,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "average_training_step_time": 8.972818586826325,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "min_training_step_time": 3.51300311088562,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "max_training_step_time": 252.97595691680908,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "individual_training_step_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.177407503128052,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7471275329589844,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.364180326461792,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6742193698883057,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.800214767456055,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.846937894821167,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7524468898773193,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.681551933288574,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.311538934707642,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.737256050109863,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6579630374908447,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7316830158233643,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6588263511657715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.897255897521973,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.661489725112915,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.528608083724976,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.191934585571289,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.700798988342285,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9281787872314453,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6720383167266846,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.351558446884155,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6648831367492676,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.5640974044799805,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6900644302368164,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.95225715637207,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6677238941192627,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.794180154800415,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.686027765274048,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5375759601593018,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6764109134674072,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8116040229797363,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.32819128036499,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.82056450843811,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9041507244110107,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7103285789489746,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.039252996444702,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.474931955337524,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.359262943267822,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.670936346054077,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.838505268096924,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     241.30551314353943,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6615536212921143,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.768169641494751,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6685497760772705,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     6.418376445770264,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6599984169006348,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8076670169830322,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.004891395568848,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.115558385848999,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.7644500732421875,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.536461591720581,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.667574644088745,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.925961971282959,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.582260847091675,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.245268106460571,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6738855838775635,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.726324558258057,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.038132429122925,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.870368480682373,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.090127229690552,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5291635990142822,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.714229106903076,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.671809196472168,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.369868516921997,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.140239953994751,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.066346168518066,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.741899013519287,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6288652420043945,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.247907638549805,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.794798851013184,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.685307025909424,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8650870323181152,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.020089387893677,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.1763646602630615,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.58829927444458,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.869316339492798,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9206736087799072,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6496293544769287,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.671693801879883,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6847400665283203,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     244.3752691745758,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.624579906463623,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6685523986816406,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     8.377848863601685,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.669621467590332,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.847752094268799,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.10859751701355,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6814510822296143,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.298346519470215,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.53112268447876,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.688982009887695,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.094104290008545,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.897332191467285,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6149239540100098,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.843834638595581,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.697925090789795,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.087396621704102,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.816823959350586,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.682476758956909,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.127143621444702,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.679569959640503,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.665315628051758,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9800264835357666,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5794732570648193,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.196256875991821,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.676086664199829,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.821242809295654,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.928873062133789,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.683553695678711,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6804938316345215,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.67923903465271,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6797995567321777,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.278852701187134,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9911415576934814,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.3307600021362305,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6853718757629395,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7531845569610596,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6969637870788574,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7868897914886475,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.467771291732788,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     252.97595691680908,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.51300311088562,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.079504489898682,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.817774772644043,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.279357671737671,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.411333084106445,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.540182828903198,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6705141067504883,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.754162073135376,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.936776638031006,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.873294115066528,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6641688346862793,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6738617420196533,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.556060791015625,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8417434692382812,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5232863426208496,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.10233736038208,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9362683296203613,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.423536062240601,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.172576427459717,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9437384605407715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.612236738204956,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.668583869934082,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.869539976119995,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.086947202682495,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.179211854934692,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6709864139556885,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.367009401321411,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.670699119567871,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6708149909973145,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.809374809265137,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.581915855407715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.213742256164551,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.7019968032836914,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6825361251831055,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.669809103012085,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.668241500854492,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6809868812561035,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5743777751922607,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.685638666152954,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     252.25436067581177,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.2895777225494385,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     5.008652925491333,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.777937889099121,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.5702555179595947,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6645989418029785,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.675060272216797,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     6.511410236358643,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.10086464881897,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.771870851516724,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.707609176635742,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.8102450370788574,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.77213191986084,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6731455326080322,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.642109394073486,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.084608316421509,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.708261251449585,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.807703495025635,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.4910054206848145,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.529153347015381,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.822935104370117,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.465139150619507,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.4344964027404785,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.749237298965454,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.3476622104644775,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.793670177459717,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.523698329925537,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6694529056549072,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.183181047439575,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.673283338546753,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.681734561920166,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.9581196308135986,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.0430309772491455,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6822147369384766,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.673072338104248,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.699800491333008,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     3.6660473346710205,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.186377048492432,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.710247278213501,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     4.189129114151001
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   ]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m --- All Training Runs Summary ---
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "run_id": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "timestamp": "2025-08-04T03:26:08.205563",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_status": "completed",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "output_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_time": 2.511092185974121,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_time": 108.76317548751831,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_time": 4094.02054977417,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_time": 4205.294817447662,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "error": null,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "num_checkpoints_saved": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_checkpoint_save_time": 1733.0068826675415,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_checkpoint_save_time": 346.6013765335083,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "min_checkpoint_save_time": 339.89280819892883,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "max_checkpoint_save_time": 357.57605504989624,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       339.89280819892883,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       342.5030782222748,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       357.57605504989624,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       341.4221839904785,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       351.61275720596313
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "num_batch_samples": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_batch_sample_time": 149.93164825439453,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_batch_sample_time": 5.997265930175781,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "min_batch_sample_time": 0.03078317642211914,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "max_batch_sample_time": 42.9773051738739,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.11854004859924316,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.18291115760803223,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03877592086791992,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.1264352798461914,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.08548545837402344,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       37.18442678451538,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.0348813533782959,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.08180546760559082,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.04030251502990723,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03433680534362793,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       42.9773051738739,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.032769203186035156,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.07843351364135742,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03827714920043945,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03278803825378418,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       34.116602420806885,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03187894821166992,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03644061088562012,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03078317642211914,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03419184684753418,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       34.21334624290466,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.035974979400634766,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03318476676940918,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.03549003601074219,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       0.27628135681152344
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     ],
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "num_training_steps": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_training_step_time": 1794.563717365265,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_training_step_time": 8.972818586826325,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "min_training_step_time": 3.51300311088562,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "max_training_step_time": 252.97595691680908,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "individual_training_step_times": [
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.177407503128052,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7471275329589844,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.364180326461792,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6742193698883057,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.800214767456055,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.846937894821167,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7524468898773193,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.681551933288574,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.311538934707642,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.737256050109863,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6579630374908447,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7316830158233643,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6588263511657715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.897255897521973,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.661489725112915,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.528608083724976,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.191934585571289,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.700798988342285,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9281787872314453,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6720383167266846,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.351558446884155,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6648831367492676,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.5640974044799805,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6900644302368164,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.95225715637207,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6677238941192627,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.794180154800415,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.686027765274048,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5375759601593018,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6764109134674072,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8116040229797363,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.32819128036499,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.82056450843811,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9041507244110107,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7103285789489746,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.039252996444702,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.474931955337524,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.359262943267822,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.670936346054077,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.838505268096924,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       241.30551314353943,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6615536212921143,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.768169641494751,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6685497760772705,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       6.418376445770264,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6599984169006348,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8076670169830322,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.004891395568848,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.115558385848999,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.7644500732421875,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.536461591720581,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.667574644088745,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.925961971282959,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.582260847091675,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.245268106460571,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6738855838775635,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.726324558258057,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.038132429122925,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.870368480682373,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.090127229690552,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5291635990142822,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.714229106903076,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.671809196472168,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.369868516921997,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.140239953994751,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.066346168518066,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.741899013519287,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6288652420043945,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.247907638549805,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.794798851013184,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.685307025909424,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8650870323181152,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.020089387893677,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.1763646602630615,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.58829927444458,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.869316339492798,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9206736087799072,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6496293544769287,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.671693801879883,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6847400665283203,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       244.3752691745758,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.624579906463623,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6685523986816406,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       8.377848863601685,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.669621467590332,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.847752094268799,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.10859751701355,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6814510822296143,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.298346519470215,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.53112268447876,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.688982009887695,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.094104290008545,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.897332191467285,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6149239540100098,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.843834638595581,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.697925090789795,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.087396621704102,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.816823959350586,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.682476758956909,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.127143621444702,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.679569959640503,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.665315628051758,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9800264835357666,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5794732570648193,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.196256875991821,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.676086664199829,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.821242809295654,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.928873062133789,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.683553695678711,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6804938316345215,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.67923903465271,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6797995567321777,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.278852701187134,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9911415576934814,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.3307600021362305,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6853718757629395,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7531845569610596,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6969637870788574,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7868897914886475,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.467771291732788,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       252.97595691680908,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.51300311088562,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.079504489898682,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.817774772644043,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.279357671737671,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.411333084106445,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.540182828903198,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6705141067504883,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.754162073135376,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.936776638031006,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.873294115066528,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6641688346862793,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6738617420196533,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.556060791015625,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8417434692382812,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5232863426208496,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.10233736038208,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9362683296203613,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.423536062240601,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.172576427459717,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9437384605407715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.612236738204956,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.668583869934082,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.869539976119995,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.086947202682495,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.179211854934692,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6709864139556885,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.367009401321411,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.670699119567871,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6708149909973145,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.809374809265137,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.581915855407715,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.213742256164551,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.7019968032836914,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6825361251831055,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.669809103012085,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.668241500854492,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6809868812561035,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5743777751922607,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.685638666152954,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       252.25436067581177,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.2895777225494385,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       5.008652925491333,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.777937889099121,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.5702555179595947,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6645989418029785,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.675060272216797,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       6.511410236358643,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.10086464881897,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.771870851516724,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.707609176635742,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.8102450370788574,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.77213191986084,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6731455326080322,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.642109394073486,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.084608316421509,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.708261251449585,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.807703495025635,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.4910054206848145,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.529153347015381,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.822935104370117,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.465139150619507,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.4344964027404785,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.749237298965454,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.3476622104644775,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.793670177459717,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.523698329925537,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6694529056549072,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.183181047439575,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.673283338546753,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.681734561920166,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.9581196308135986,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.0430309772491455,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6822147369384766,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.673072338104248,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.699800491333008,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       3.6660473346710205,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.186377048492432,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.710247278213501,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m       4.189129114151001
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     ]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ]
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m --- Timing Summary ---
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_runs": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "dataset_loading": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_average": 2.511092185974121,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_min": 2.511092185974121,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_max": 2.511092185974121,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "dataset_load_total": 2.511092185974121
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "model_loading": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_average": 108.76317548751831,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_min": 108.76317548751831,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_max": 108.76317548751831,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "model_load_total": 108.76317548751831
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_average": 4094.02054977417,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_min": 4094.02054977417,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_max": 4094.02054977417,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_total": 4094.02054977417
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "total_run_time": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_count": 1,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_average": 4205.294817447662,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_min": 4205.294817447662,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_max": 4205.294817447662,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_total": 4205.294817447662
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "checkpoint_saving": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_checkpoints_saved": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_checkpoint_save_time": 1733.0068826675415,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_save_time_per_checkpoint": 346.6013765335083,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_times_count": 5,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_min": 339.89280819892883,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_max": 357.57605504989624,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "checkpoint_save_average": 346.6013765335083
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "batch_sampling": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_batch_samples": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_batch_sample_time": 149.93164825439453,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_sample_time_per_batch": 5.997265930175781,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_times_count": 25,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_min": 0.03078317642211914,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_max": 42.9773051738739,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "batch_sample_average": 5.997265930175781
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   },
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   "training_steps": {
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_training_steps": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "total_training_step_time": 1794.563717365265,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "average_step_time_per_step": 8.972818586826325,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_times_count": 200,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_min": 3.51300311088562,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_max": 252.97595691680908,
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m     "training_step_average": 8.972818586826325
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m }
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.55s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.55s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.55s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.55s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 4201.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4201.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4201.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4201.22s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 8.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.55s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 252.95s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1796.34s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.04s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 42.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 150.94s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 346.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 339.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 357.58s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1733.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 4204.79s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 4204.79s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 4204.79s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 4204.79s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 4.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4.10s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 4198.68s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4198.68s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4198.68s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4198.68s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 8.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 252.94s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1796.31s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.02s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 42.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 150.59s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 346.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 339.89s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 357.57s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1733.01s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 4205.29s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 4205.29s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 4205.29s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 4205.29s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 2.51s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 1.07s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average time: 4201.16s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min time: 4201.16s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max time: 4201.16s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time: 4201.16s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training steps: 200
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average step time per step: 8.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min step time: 3.52s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max step time: 252.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total training step time: 1795.81s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch samples: 25
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average sample time per batch: 6.00s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max sample time: 42.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total batch sample time: 150.06s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoints saved: 5
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average save time per checkpoint: 346.60s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min save time: 339.88s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max save time: 357.56s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total checkpoint save time: 1732.98s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m 
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Average total time per run: 4204.74s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Min total time: 4204.74s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Max total time: 4204.74s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m   • Total time across all runs: 4204.74s
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m ================================================================================
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3442)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2531, ip=10.102.30.76)[0m skypilot: cached mount uploaded complete
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3442)[0m skypilot: cached mount is still uploading to remote
