[33mTailing logs of the last job on cluster 'dd'...[0m
Job ID not provided. Streaming the logs of the latest job.
[2m├── [0m[2mWaiting for task resources on 2 nodes.[0m
[2m└── [0mJob started. Streaming logs... [2m(Ctrl-C to exit log streaming; job will not be killed)[0m
[36m(setup pid=3447)[0m Channels:
[36m(setup pid=3447)[0m  - nvidia
[36m(setup pid=3447)[0m  - defaults
[36m(setup pid=3447)[0m Platform: linux-64
[36m(setup pid=2571, ip=10.102.30.23)[0m Channels:
[36m(setup pid=2571, ip=10.102.30.23)[0m  - nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m  - defaults
[36m(setup pid=2571, ip=10.102.30.23)[0m Platform: linux-64
[36m(setup pid=3447)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=3447)[0m Solving environment: ...working... done
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m ## Package Plan ##
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m   environment location: /root/miniconda3
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m   added / updated specs:
[36m(setup pid=3447)[0m     - cuda
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m The following packages will be downloaded:
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m     package                    |            build
[36m(setup pid=3447)[0m     ---------------------------|-----------------
[36m(setup pid=3447)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=3447)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=3447)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=3447)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=3447)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=3447)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=3447)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=3447)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=3447)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=3447)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=3447)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=3447)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=3447)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=3447)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=3447)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=3447)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=3447)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=3447)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=3447)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=3447)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=3447)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=3447)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=3447)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=3447)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=3447)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=3447)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=3447)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=3447)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=3447)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=3447)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=3447)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=3447)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=3447)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=3447)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=3447)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=3447)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=3447)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=3447)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=3447)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=3447)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=3447)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=3447)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=3447)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=3447)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=3447)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=3447)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=3447)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=3447)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=3447)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=3447)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=3447)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=3447)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=3447)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=3447)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=3447)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=3447)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=3447)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=3447)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=3447)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=3447)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=3447)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=3447)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=3447)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=3447)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=3447)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=3447)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=3447)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=3447)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=3447)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=3447)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=3447)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=3447)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=3447)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=3447)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=3447)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=3447)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=3447)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=3447)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=3447)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=3447)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=3447)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=3447)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=3447)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=3447)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=3447)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=3447)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=3447)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=3447)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=3447)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=3447)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=3447)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=3447)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=3447)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=3447)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=3447)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=3447)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=3447)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=3447)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=3447)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=3447)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=3447)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=3447)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=3447)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=3447)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=3447)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=3447)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=3447)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=3447)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=3447)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=3447)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=3447)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=3447)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=3447)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=3447)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=3447)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=3447)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=3447)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=3447)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=3447)[0m     ------------------------------------------------------------
[36m(setup pid=3447)[0m                                            Total:        2.06 GB
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=3447)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=3447)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=3447)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=3447)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=3447)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=3447)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=3447)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=3447)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=3447)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=3447)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=3447)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=3447)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=3447)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=3447)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=3447)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=3447)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=3447)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=3447)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=3447)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=3447)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=3447)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=3447)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=3447)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=3447)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=3447)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=3447)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=3447)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=3447)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=3447)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=3447)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=3447)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=3447)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=3447)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=3447)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=3447)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=3447)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=3447)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=3447)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=3447)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=3447)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=3447)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=3447)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=3447)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=3447)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=3447)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=3447)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=3447)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=3447)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=3447)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=3447)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=3447)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=3447)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=3447)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=3447)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=3447)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=3447)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3447)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=3447)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=3447)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=3447)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=3447)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=3447)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3447)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=3447)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=3447)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=3447)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=3447)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=3447)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=3447)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=3447)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=3447)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=3447)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=3447)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=3447)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=3447)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=3447)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=3447)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=3447)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3447)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=3447)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=3447)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=3447)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=3447)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=3447)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=3447)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=3447)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=3447)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=3447)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=3447)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=3447)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3447)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=3447)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=3447)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=3447)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=3447)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=3447)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=3447)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=3447)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=3447)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=3447)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=3447)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=3447)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=3447)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=3447)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=3447)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=3447)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m The following packages will be UPDATED:
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=3447)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=3447)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=3447)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=3447)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=3447)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=3447)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=3447)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=3447)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=3447)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=3447)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m Proceed ([y]/n)? 
[36m(setup pid=3447)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=2571, ip=10.102.30.23)[0m Solving environment: ...working... done
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m ## Package Plan ##
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m   environment location: /root/miniconda3
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m   added / updated specs:
[36m(setup pid=2571, ip=10.102.30.23)[0m     - cuda
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m The following packages will be downloaded:
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m     package                    |            build
[36m(setup pid=2571, ip=10.102.30.23)[0m     ---------------------------|-----------------
[36m(setup pid=2571, ip=10.102.30.23)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=2571, ip=10.102.30.23)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=2571, ip=10.102.30.23)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=2571, ip=10.102.30.23)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=2571, ip=10.102.30.23)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=2571, ip=10.102.30.23)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=2571, ip=10.102.30.23)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=2571, ip=10.102.30.23)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=2571, ip=10.102.30.23)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=2571, ip=10.102.30.23)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=2571, ip=10.102.30.23)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=2571, ip=10.102.30.23)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=2571, ip=10.102.30.23)[0m     ------------------------------------------------------------
[36m(setup pid=2571, ip=10.102.30.23)[0m                                            Total:        2.06 GB
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=2571, ip=10.102.30.23)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=2571, ip=10.102.30.23)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=2571, ip=10.102.30.23)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=2571, ip=10.102.30.23)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=2571, ip=10.102.30.23)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m The following packages will be UPDATED:
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=2571, ip=10.102.30.23)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=2571, ip=10.102.30.23)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m Proceed ([y]/n)? 
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=3447)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=3447)[0m Preparing transaction: ...working... done
[36m(setup pid=3447)[0m Verifying transaction: ...working... done
[36m(setup pid=3447)[0m Executing transaction: ...working... done
[36m(setup pid=3447)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=3447)[0m Using CPython 3.10.12 interpreter at: /usr/bin/python3.10
[36m(setup pid=3447)[0m Creating virtual environment with seed packages at: /root/training
[36m(setup pid=3447)[0m  + pip==25.2
[36m(setup pid=3447)[0m  + setuptools==80.9.0
[36m(setup pid=3447)[0m  + wheel==0.45.1
[36m(setup pid=3447)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3447)[0m Resolved 29 packages in 127ms
[36m(setup pid=3447)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=3447)[0m Downloading sympy (6.0MiB)
[36m(setup pid=3447)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=3447)[0m Downloading pillow (6.3MiB)
[36m(setup pid=3447)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=3447)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=3447)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=3447)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=3447)[0m Downloading triton (148.4MiB)
[36m(setup pid=3447)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=3447)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=3447)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=3447)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=3447)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=3447)[0m Downloading torch (783.1MiB)
[36m(setup pid=3447)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=3447)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=3447)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=3447)[0m  Downloading nvidia-cufile-cu12
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=3447)[0m  Downloading torchaudio
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing transaction: ...working... done
[36m(setup pid=3447)[0m  Downloading pillow
[36m(setup pid=3447)[0m  Downloading torchvision
[36m(setup pid=3447)[0m  Downloading nvidia-cuda-cupti-cu12
[36m(setup pid=2571, ip=10.102.30.23)[0m Verifying transaction: ...working... done
[36m(setup pid=3447)[0m  Downloading nvidia-nvjitlink-cu12
[36m(setup pid=3447)[0m  Downloading nvidia-cuda-nvrtc-cu12
[36m(setup pid=2571, ip=10.102.30.23)[0m Executing transaction: ...working... done
[36m(setup pid=2571, ip=10.102.30.23)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=2571, ip=10.102.30.23)[0m Using CPython 3.10.12 interpreter at: /usr/bin/python3.10
[36m(setup pid=2571, ip=10.102.30.23)[0m Creating virtual environment with seed packages at: /root/training
[36m(setup pid=2571, ip=10.102.30.23)[0m  + pip==25.2
[36m(setup pid=2571, ip=10.102.30.23)[0m  + setuptools==80.9.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + wheel==0.45.1
[36m(setup pid=2571, ip=10.102.30.23)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2571, ip=10.102.30.23)[0m Resolved 29 packages in 112ms
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading pillow (6.3MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading torch (783.1MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading sympy (6.0MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading triton (148.4MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading nvidia-cufile-cu12
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading torchaudio
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading torchvision
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading pillow
[36m(setup pid=3447)[0m  Downloading nvidia-curand-cu12
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading nvidia-cuda-cupti-cu12
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading nvidia-nvjitlink-cu12
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading nvidia-cuda-nvrtc-cu12
[36m(setup pid=3447)[0m  Downloading sympy
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading nvidia-curand-cu12
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading sympy
[36m(setup pid=3447)[0m  Downloading nvidia-cusparselt-cu12
[36m(setup pid=3447)[0m  Downloading nvidia-cusolver-cu12
[36m(setup pid=3447)[0m  Downloading triton
[36m(setup pid=3447)[0m  Downloading nvidia-cufft-cu12
[36m(setup pid=3447)[0m  Downloading nvidia-nccl-cu12
[36m(setup pid=3447)[0m  Downloading nvidia-cusparse-cu12
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading nvidia-cusparselt-cu12
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading nvidia-cusolver-cu12
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading triton
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading nvidia-nccl-cu12
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading nvidia-cufft-cu12
[36m(setup pid=3447)[0m  Downloading nvidia-cublas-cu12
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading nvidia-cusparse-cu12
[36m(setup pid=3447)[0m  Downloading nvidia-cudnn-cu12
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading nvidia-cublas-cu12
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading nvidia-cudnn-cu12
[36m(setup pid=3447)[0m  Downloading torch
[36m(setup pid=3447)[0m Prepared 22 packages in 22.78s
[36m(setup pid=3447)[0m Installed 28 packages in 231ms
[36m(setup pid=3447)[0m  + filelock==3.18.0
[36m(setup pid=3447)[0m  + fsspec==2025.7.0
[36m(setup pid=3447)[0m  + jinja2==3.1.6
[36m(setup pid=3447)[0m  + markupsafe==3.0.2
[36m(setup pid=3447)[0m  + mpmath==1.3.0
[36m(setup pid=3447)[0m  + networkx==3.4.2
[36m(setup pid=3447)[0m  + numpy==2.2.6
[36m(setup pid=3447)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=3447)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=3447)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=3447)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=3447)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=3447)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=3447)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=3447)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=3447)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=3447)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=3447)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=3447)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=3447)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=3447)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=3447)[0m  + pillow==11.3.0
[36m(setup pid=3447)[0m  + sympy==1.14.0
[36m(setup pid=3447)[0m  + torch==2.7.1
[36m(setup pid=3447)[0m  + torchaudio==2.7.1
[36m(setup pid=3447)[0m  + torchvision==0.22.1
[36m(setup pid=3447)[0m  + triton==3.3.1
[36m(setup pid=3447)[0m  + typing-extensions==4.14.1
[36m(setup pid=3447)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3447)[0m Resolved 73 packages in 386ms
[36m(setup pid=3447)[0m    Building deepspeed==0.17.4
[36m(setup pid=3447)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=3447)[0m Downloading transformers (10.7MiB)
[36m(setup pid=3447)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=3447)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=3447)[0m  Downloading hf-xet
[36m(setup pid=3447)[0m  Downloading tokenizers
[36m(setup pid=3447)[0m  Downloading pyarrow
[36m(setup pid=3447)[0m  Downloading transformers
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading torch
[36m(setup pid=2571, ip=10.102.30.23)[0m Prepared 22 packages in 21.32s
[36m(setup pid=3447)[0m       Built deepspeed==0.17.4
[36m(setup pid=3447)[0m Prepared 21 packages in 1.47s
[36m(setup pid=3447)[0m Uninstalled 1 package in 0.97ms
[36m(setup pid=3447)[0m Installed 48 packages in 55ms
[36m(setup pid=3447)[0m  + accelerate==1.9.0
[36m(setup pid=3447)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=3447)[0m  + aiohttp==3.12.15
[36m(setup pid=3447)[0m  + aiosignal==1.4.0
[36m(setup pid=3447)[0m  + annotated-types==0.7.0
[36m(setup pid=3447)[0m  + async-timeout==5.0.1
[36m(setup pid=3447)[0m  + attrs==25.3.0
[36m(setup pid=3447)[0m  + certifi==2025.7.14
[36m(setup pid=3447)[0m  + charset-normalizer==3.4.2
[36m(setup pid=3447)[0m  + datasets==4.0.0
[36m(setup pid=3447)[0m  + deepspeed==0.17.4
[36m(setup pid=3447)[0m  + dill==0.3.8
[36m(setup pid=3447)[0m  + einops==0.8.1
[36m(setup pid=3447)[0m  + frozenlist==1.7.0
[36m(setup pid=3447)[0m  - fsspec==2025.7.0
[36m(setup pid=3447)[0m  + fsspec==2025.3.0
[36m(setup pid=3447)[0m  + hf-xet==1.1.5
[36m(setup pid=3447)[0m  + hjson==3.1.0
[36m(setup pid=3447)[0m  + huggingface-hub==0.34.3
[36m(setup pid=3447)[0m  + idna==3.10
[36m(setup pid=3447)[0m  + liger-kernel==0.6.1
[36m(setup pid=3447)[0m  + msgpack==1.1.1
[36m(setup pid=3447)[0m  + multidict==6.6.3
[36m(setup pid=3447)[0m  + multiprocess==0.70.16
[36m(setup pid=3447)[0m  + ninja==1.11.1.4
[36m(setup pid=3447)[0m  + packaging==25.0
[36m(setup pid=3447)[0m  + pandas==2.3.1
[36m(setup pid=3447)[0m  + propcache==0.3.2
[36m(setup pid=3447)[0m  + psutil==7.0.0
[36m(setup pid=3447)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=3447)[0m  + pyarrow==21.0.0
[36m(setup pid=3447)[0m  + pydantic==2.11.7
[36m(setup pid=3447)[0m  + pydantic-core==2.33.2
[36m(setup pid=3447)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=3447)[0m  + pytz==2025.2
[36m(setup pid=3447)[0m  + pyyaml==6.0.2
[36m(setup pid=3447)[0m  + regex==2025.7.34
[36m(setup pid=3447)[0m  + requests==2.32.4
[36m(setup pid=3447)[0m  + safetensors==0.5.3
[36m(setup pid=3447)[0m  + six==1.17.0
[36m(setup pid=3447)[0m  + tokenizers==0.21.4
[36m(setup pid=3447)[0m  + tqdm==4.67.1
[36m(setup pid=3447)[0m  + transformers==4.54.1
[36m(setup pid=3447)[0m  + trl==0.20.0
[36m(setup pid=3447)[0m  + typing-inspection==0.4.1
[36m(setup pid=3447)[0m  + tzdata==2025.2
[36m(setup pid=3447)[0m  + urllib3==2.5.0
[36m(setup pid=3447)[0m  + xxhash==3.5.0
[36m(setup pid=3447)[0m  + yarl==1.20.1
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3447)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m Installed 28 packages in 154ms
[36m(setup pid=2571, ip=10.102.30.23)[0m  + filelock==3.18.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + fsspec==2025.7.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + jinja2==3.1.6
[36m(setup pid=2571, ip=10.102.30.23)[0m  + markupsafe==3.0.2
[36m(setup pid=2571, ip=10.102.30.23)[0m  + mpmath==1.3.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + networkx==3.4.2
[36m(setup pid=2571, ip=10.102.30.23)[0m  + numpy==2.2.6
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=2571, ip=10.102.30.23)[0m  + pillow==11.3.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + sympy==1.14.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + torch==2.7.1
[36m(setup pid=2571, ip=10.102.30.23)[0m  + torchaudio==2.7.1
[36m(setup pid=2571, ip=10.102.30.23)[0m  + torchvision==0.22.1
[36m(setup pid=2571, ip=10.102.30.23)[0m  + triton==3.3.1
[36m(setup pid=2571, ip=10.102.30.23)[0m  + typing-extensions==4.14.1
[36m(setup pid=2571, ip=10.102.30.23)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2571, ip=10.102.30.23)[0m Resolved 73 packages in 261ms
[36m(setup pid=2571, ip=10.102.30.23)[0m    Building deepspeed==0.17.4
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading transformers (10.7MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading tokenizers
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading hf-xet
[36m(setup pid=3447)[0m Reading package lists...
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading pyarrow
[36m(setup pid=3447)[0m Building dependency tree...
[36m(setup pid=3447)[0m Reading state information...
[36m(setup pid=2571, ip=10.102.30.23)[0m  Downloading transformers
[36m(setup pid=3447)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3447)[0m   libfuse2
[36m(setup pid=3447)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3447)[0m The following additional packages will be installed:
[36m(setup pid=3447)[0m   vim-common vim-runtime
[36m(setup pid=3447)[0m Suggested packages:
[36m(setup pid=3447)[0m   ctags vim-doc vim-scripts
[36m(setup pid=3447)[0m The following NEW packages will be installed:
[36m(setup pid=3447)[0m   vmtouch
[36m(setup pid=3447)[0m The following packages will be upgraded:
[36m(setup pid=3447)[0m   vim vim-common vim-runtime
[36m(setup pid=3447)[0m 3 upgraded, 1 newly installed, 0 to remove and 84 not upgraded.
[36m(setup pid=3447)[0m Need to get 8664 kB of archives.
[36m(setup pid=3447)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=3447)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 vmtouch amd64 1.3.1-2 [21.5 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m       Built deepspeed==0.17.4
[36m(setup pid=2571, ip=10.102.30.23)[0m Prepared 21 packages in 1.31s
[36m(setup pid=2571, ip=10.102.30.23)[0m Uninstalled 1 package in 0.88ms
[36m(setup pid=2571, ip=10.102.30.23)[0m Installed 48 packages in 53ms
[36m(setup pid=2571, ip=10.102.30.23)[0m  + accelerate==1.9.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=2571, ip=10.102.30.23)[0m  + aiohttp==3.12.15
[36m(setup pid=2571, ip=10.102.30.23)[0m  + aiosignal==1.4.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + annotated-types==0.7.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + async-timeout==5.0.1
[36m(setup pid=2571, ip=10.102.30.23)[0m  + attrs==25.3.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + certifi==2025.7.14
[36m(setup pid=2571, ip=10.102.30.23)[0m  + charset-normalizer==3.4.2
[36m(setup pid=2571, ip=10.102.30.23)[0m  + datasets==4.0.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + deepspeed==0.17.4
[36m(setup pid=2571, ip=10.102.30.23)[0m  + dill==0.3.8
[36m(setup pid=2571, ip=10.102.30.23)[0m  + einops==0.8.1
[36m(setup pid=2571, ip=10.102.30.23)[0m  + frozenlist==1.7.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  - fsspec==2025.7.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + fsspec==2025.3.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + hf-xet==1.1.5
[36m(setup pid=2571, ip=10.102.30.23)[0m  + hjson==3.1.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + huggingface-hub==0.34.3
[36m(setup pid=2571, ip=10.102.30.23)[0m  + idna==3.10
[36m(setup pid=2571, ip=10.102.30.23)[0m  + liger-kernel==0.6.1
[36m(setup pid=2571, ip=10.102.30.23)[0m  + msgpack==1.1.1
[36m(setup pid=2571, ip=10.102.30.23)[0m  + multidict==6.6.3
[36m(setup pid=2571, ip=10.102.30.23)[0m  + multiprocess==0.70.16
[36m(setup pid=2571, ip=10.102.30.23)[0m  + ninja==1.11.1.4
[36m(setup pid=2571, ip=10.102.30.23)[0m  + packaging==25.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + pandas==2.3.1
[36m(setup pid=2571, ip=10.102.30.23)[0m  + propcache==0.3.2
[36m(setup pid=2571, ip=10.102.30.23)[0m  + psutil==7.0.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + pyarrow==21.0.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + pydantic==2.11.7
[36m(setup pid=2571, ip=10.102.30.23)[0m  + pydantic-core==2.33.2
[36m(setup pid=2571, ip=10.102.30.23)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + pytz==2025.2
[36m(setup pid=2571, ip=10.102.30.23)[0m  + pyyaml==6.0.2
[36m(setup pid=2571, ip=10.102.30.23)[0m  + regex==2025.7.34
[36m(setup pid=2571, ip=10.102.30.23)[0m  + requests==2.32.4
[36m(setup pid=2571, ip=10.102.30.23)[0m  + safetensors==0.5.3
[36m(setup pid=2571, ip=10.102.30.23)[0m  + six==1.17.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + tokenizers==0.21.4
[36m(setup pid=2571, ip=10.102.30.23)[0m  + tqdm==4.67.1
[36m(setup pid=2571, ip=10.102.30.23)[0m  + transformers==4.54.1
[36m(setup pid=2571, ip=10.102.30.23)[0m  + trl==0.20.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + typing-inspection==0.4.1
[36m(setup pid=2571, ip=10.102.30.23)[0m  + tzdata==2025.2
[36m(setup pid=2571, ip=10.102.30.23)[0m  + urllib3==2.5.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + xxhash==3.5.0
[36m(setup pid=2571, ip=10.102.30.23)[0m  + yarl==1.20.1
[36m(setup pid=3447)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim amd64 2:8.2.3995-1ubuntu2.24 [1728 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=3447)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-runtime all 2:8.2.3995-1ubuntu2.24 [6833 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Reading package lists...
[36m(setup pid=3447)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-common all 2:8.2.3995-1ubuntu2.24 [81.5 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Building dependency tree...
[36m(setup pid=2571, ip=10.102.30.23)[0m Reading state information...
[36m(setup pid=3447)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3447)[0m Fetched 8664 kB in 1s (6610 kB/s)
[36m(setup pid=3447)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=3447)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23408 files and directories currently installed.)
[36m(setup pid=3447)[0m Preparing to unpack .../vmtouch_1.3.1-2_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking vmtouch (1.3.1-2) ...
[36m(setup pid=3447)[0m Preparing to unpack .../vim_2%3a8.2.3995-1ubuntu2.24_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking vim (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3447)[0m Preparing to unpack .../vim-runtime_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=3447)[0m Unpacking vim-runtime (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2571, ip=10.102.30.23)[0m   libfuse2
[36m(setup pid=2571, ip=10.102.30.23)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2571, ip=10.102.30.23)[0m The following additional packages will be installed:
[36m(setup pid=2571, ip=10.102.30.23)[0m   vim-common vim-runtime
[36m(setup pid=2571, ip=10.102.30.23)[0m Suggested packages:
[36m(setup pid=2571, ip=10.102.30.23)[0m   ctags vim-doc vim-scripts
[36m(setup pid=2571, ip=10.102.30.23)[0m The following NEW packages will be installed:
[36m(setup pid=2571, ip=10.102.30.23)[0m   vmtouch
[36m(setup pid=2571, ip=10.102.30.23)[0m The following packages will be upgraded:
[36m(setup pid=2571, ip=10.102.30.23)[0m   vim vim-common vim-runtime
[36m(setup pid=2571, ip=10.102.30.23)[0m 3 upgraded, 1 newly installed, 0 to remove and 84 not upgraded.
[36m(setup pid=2571, ip=10.102.30.23)[0m Need to get 8664 kB of archives.
[36m(setup pid=2571, ip=10.102.30.23)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 vmtouch amd64 1.3.1-2 [21.5 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim amd64 2:8.2.3995-1ubuntu2.24 [1728 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-runtime all 2:8.2.3995-1ubuntu2.24 [6833 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-common all 2:8.2.3995-1ubuntu2.24 [81.5 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2571, ip=10.102.30.23)[0m Fetched 8664 kB in 0s (17.4 MB/s)
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=2571, ip=10.102.30.23)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23408 files and directories currently installed.)
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../vmtouch_1.3.1-2_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking vmtouch (1.3.1-2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../vim_2%3a8.2.3995-1ubuntu2.24_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking vim (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../vim-runtime_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking vim-runtime (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3447)[0m Preparing to unpack .../vim-common_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=3447)[0m Unpacking vim-common (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3447)[0m Setting up vmtouch (1.3.1-2) ...
[36m(setup pid=3447)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=3447)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=3447)[0m Setting up vim-common (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3447)[0m Setting up vim-runtime (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3447)[0m Setting up vim (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m Reading package lists...
[36m(setup pid=3447)[0m Building dependency tree...
[36m(setup pid=3447)[0m Reading state information...
[36m(setup pid=3447)[0m build-essential is already the newest version (12.9ubuntu3).
[36m(setup pid=3447)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3447)[0m   libfuse2
[36m(setup pid=3447)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3447)[0m The following additional packages will be installed:
[36m(setup pid=3447)[0m   javascript-common libexpat1 libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=3447)[0m   libjs-underscore libpython3-dev libpython3.10 libpython3.10-dev
[36m(setup pid=3447)[0m   libpython3.10-minimal libpython3.10-stdlib python3-distutils python3-lib2to3
[36m(setup pid=3447)[0m   python3.10 python3.10-minimal
[36m(setup pid=3447)[0m Suggested packages:
[36m(setup pid=3447)[0m   apache2 | lighttpd | httpd python3.10-venv python3.10-doc binfmt-support
[36m(setup pid=3447)[0m The following NEW packages will be installed:
[36m(setup pid=3447)[0m   javascript-common libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=3447)[0m   libjs-underscore libpython3-dev libpython3.10-dev python3-dev
[36m(setup pid=3447)[0m   python3-distutils python3-lib2to3 python3.10-dev
[36m(setup pid=3447)[0m The following packages will be upgraded:
[36m(setup pid=3447)[0m   libexpat1 libpython3.10 libpython3.10-minimal libpython3.10-stdlib
[36m(setup pid=3447)[0m   python3.10 python3.10-minimal
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../vim-common_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking vim-common (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3447)[0m 6 upgraded, 11 newly installed, 0 to remove and 78 not upgraded.
[36m(setup pid=3447)[0m Need to get 13.7 MB of archives.
[36m(setup pid=3447)[0m After this operation, 25.1 MB of additional disk space will be used.
[36m(setup pid=3447)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1 amd64 2.4.7-1ubuntu0.6 [92.1 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up vmtouch (1.3.1-2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=2571, ip=10.102.30.23)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up vim-common (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up vim-runtime (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up vim (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3447)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.10 [1950 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=3447)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=3447)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.10 [1850 kB]
[36m(setup pid=3447)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.10 [2277 kB]
[36m(setup pid=3447)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.10 [815 kB]
[36m(setup pid=3447)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5936 B]
[36m(setup pid=3447)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1-dev amd64 2.4.7-1ubuntu0.6 [148 kB]
[36m(setup pid=3447)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-jquery all 3.6.0+dfsg+~3.5.13-1 [321 kB]
[36m(setup pid=3447)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]
[36m(setup pid=3447)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]
[36m(setup pid=3447)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.10 [4763 kB]
[36m(setup pid=3447)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3-dev amd64 3.10.6-1~22.04.1 [7064 B]
[36m(setup pid=3447)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=3447)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-lib2to3 all 3.10.8-1~22.04 [77.6 kB]
[36m(setup pid=3447)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-distutils all 3.10.8-1~22.04 [139 kB]
[36m(setup pid=3447)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]
[36m(setup pid=3447)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3447)[0m Fetched 13.7 MB in 1s (25.5 MB/s)
[36m(setup pid=3447)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23418 files and directories currently installed.)
[36m(setup pid=3447)[0m Preparing to unpack .../00-libexpat1_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libexpat1:amd64 (2.4.7-1ubuntu0.6) over (2.4.7-1ubuntu0.4) ...
[36m(setup pid=3447)[0m Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libpython3.10:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3447)[0m Preparing to unpack .../02-python3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking python3.10 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3447)[0m Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Reading package lists...
[36m(setup pid=2571, ip=10.102.30.23)[0m Building dependency tree...
[36m(setup pid=2571, ip=10.102.30.23)[0m Reading state information...
[36m(setup pid=3447)[0m Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking python3.10-minimal (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3447)[0m Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m build-essential is already the newest version (12.9ubuntu3).
[36m(setup pid=2571, ip=10.102.30.23)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2571, ip=10.102.30.23)[0m   libfuse2
[36m(setup pid=2571, ip=10.102.30.23)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2571, ip=10.102.30.23)[0m The following additional packages will be installed:
[36m(setup pid=2571, ip=10.102.30.23)[0m   javascript-common libexpat1 libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=2571, ip=10.102.30.23)[0m   libjs-underscore libpython3-dev libpython3.10 libpython3.10-dev
[36m(setup pid=2571, ip=10.102.30.23)[0m   libpython3.10-minimal libpython3.10-stdlib python3-distutils python3-lib2to3
[36m(setup pid=2571, ip=10.102.30.23)[0m   python3.10 python3.10-minimal
[36m(setup pid=2571, ip=10.102.30.23)[0m Suggested packages:
[36m(setup pid=2571, ip=10.102.30.23)[0m   apache2 | lighttpd | httpd python3.10-venv python3.10-doc binfmt-support
[36m(setup pid=2571, ip=10.102.30.23)[0m The following NEW packages will be installed:
[36m(setup pid=2571, ip=10.102.30.23)[0m   javascript-common libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=2571, ip=10.102.30.23)[0m   libjs-underscore libpython3-dev libpython3.10-dev python3-dev
[36m(setup pid=2571, ip=10.102.30.23)[0m   python3-distutils python3-lib2to3 python3.10-dev
[36m(setup pid=2571, ip=10.102.30.23)[0m The following packages will be upgraded:
[36m(setup pid=2571, ip=10.102.30.23)[0m   libexpat1 libpython3.10 libpython3.10-minimal libpython3.10-stdlib
[36m(setup pid=2571, ip=10.102.30.23)[0m   python3.10 python3.10-minimal
[36m(setup pid=2571, ip=10.102.30.23)[0m 6 upgraded, 11 newly installed, 0 to remove and 78 not upgraded.
[36m(setup pid=2571, ip=10.102.30.23)[0m Need to get 13.7 MB of archives.
[36m(setup pid=2571, ip=10.102.30.23)[0m After this operation, 25.1 MB of additional disk space will be used.
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1 amd64 2.4.7-1ubuntu0.6 [92.1 kB]
[36m(setup pid=3447)[0m Selecting previously unselected package javascript-common.
[36m(setup pid=3447)[0m Preparing to unpack .../06-javascript-common_11+nmu1_all.deb ...
[36m(setup pid=3447)[0m Unpacking javascript-common (11+nmu1) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libexpat1-dev:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../07-libexpat1-dev_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libjs-jquery.
[36m(setup pid=3447)[0m Preparing to unpack .../08-libjs-jquery_3.6.0+dfsg+~3.5.13-1_all.deb ...
[36m(setup pid=3447)[0m Unpacking libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libjs-underscore.
[36m(setup pid=3447)[0m Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...
[36m(setup pid=3447)[0m Unpacking libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.10 [1950 kB]
[36m(setup pid=3447)[0m Selecting previously unselected package libjs-sphinxdoc.
[36m(setup pid=3447)[0m Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...
[36m(setup pid=3447)[0m Unpacking libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libpython3.10-dev:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../11-libpython3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libpython3-dev:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../12-libpython3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=3447)[0m Selecting previously unselected package python3.10-dev.
[36m(setup pid=3447)[0m Preparing to unpack .../13-python3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=3447)[0m Selecting previously unselected package python3-lib2to3.
[36m(setup pid=3447)[0m Preparing to unpack .../14-python3-lib2to3_3.10.8-1~22.04_all.deb ...
[36m(setup pid=3447)[0m Unpacking python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=3447)[0m Selecting previously unselected package python3-distutils.
[36m(setup pid=3447)[0m Preparing to unpack .../15-python3-distutils_3.10.8-1~22.04_all.deb ...
[36m(setup pid=3447)[0m Unpacking python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3447)[0m Selecting previously unselected package python3-dev.
[36m(setup pid=3447)[0m Preparing to unpack .../16-python3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.10 [1850 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.10 [2277 kB]
[36m(setup pid=3447)[0m Setting up libexpat1:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3447)[0m Setting up javascript-common (11+nmu1) ...
[36m(setup pid=3447)[0m Setting up libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3447)[0m Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3447)[0m Setting up libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=3447)[0m Setting up python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.10 [815 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5936 B]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1-dev amd64 2.4.7-1ubuntu0.6 [148 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-jquery all 3.6.0+dfsg+~3.5.13-1 [321 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.10 [4763 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3-dev amd64 3.10.6-1~22.04.1 [7064 B]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-lib2to3 all 3.10.8-1~22.04 [77.6 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-distutils all 3.10.8-1~22.04 [139 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]
[36m(setup pid=3447)[0m Setting up libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3447)[0m Setting up python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3447)[0m Setting up python3.10-minimal (3.10.12-1~22.04.10) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Fetched 13.7 MB in 1s (23.4 MB/s)
[36m(setup pid=2571, ip=10.102.30.23)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23418 files and directories currently installed.)
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../00-libexpat1_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libexpat1:amd64 (2.4.7-1ubuntu0.6) over (2.4.7-1ubuntu0.4) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libpython3.10:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../02-python3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking python3.10 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3447)[0m Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3447)[0m Setting up libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=3447)[0m Setting up libpython3.10:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3447)[0m Setting up python3.10 (3.10.12-1~22.04.10) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking python3.10-minimal (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3447)[0m Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package javascript-common.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../06-javascript-common_11+nmu1_all.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking javascript-common (11+nmu1) ...
[36m(setup pid=3447)[0m Setting up python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=3447)[0m Setting up libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=3447)[0m Setting up python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libexpat1-dev:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../07-libexpat1-dev_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libjs-jquery.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../08-libjs-jquery_3.6.0+dfsg+~3.5.13-1_all.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libjs-underscore.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libjs-sphinxdoc.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libpython3.10-dev:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../11-libpython3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3447)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libpython3-dev:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../12-libpython3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package python3.10-dev.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../13-python3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3447)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package python3-lib2to3.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../14-python3-lib2to3_3.10.8-1~22.04_all.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package python3-distutils.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../15-python3-distutils_3.10.8-1~22.04_all.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package python3-dev.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../16-python3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libexpat1:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up javascript-common (11+nmu1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=3447)[0m Reading package lists...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3447)[0m Building dependency tree...
[36m(setup pid=3447)[0m Reading state information...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up python3.10-minimal (3.10.12-1~22.04.10) ...
[36m(setup pid=3447)[0m infiniband-diags is already the newest version (2410mlnx54-1.2410068).
[36m(setup pid=3447)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3447)[0m   libfuse2
[36m(setup pid=3447)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3447)[0m The following additional packages will be installed:
[36m(setup pid=3447)[0m   dbus dmsetup gir1.2-glib-2.0 libapparmor1 libargon2-1 libatm1 libbpf0
[36m(setup pid=3447)[0m   libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1 libgirepository-1.0-1
[36m(setup pid=3447)[0m   libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5 libmnl0 libnl-genl-3-200
[36m(setup pid=3447)[0m   libsensors-config libsensors5 libsystemd0 libxtables12 networkd-dispatcher
[36m(setup pid=3447)[0m   python3-dbus python3-gi shared-mime-info systemd systemd-timesyncd
[36m(setup pid=3447)[0m   xdg-user-dirs
[36m(setup pid=3447)[0m Suggested packages:
[36m(setup pid=3447)[0m   default-dbus-session-bus | dbus-session-bus lm-sensors lsof strace
[36m(setup pid=3447)[0m   iproute2-doc iw | wireless-tools python-dbus-doc isag systemd-container
[36m(setup pid=3447)[0m   libtss2-esys-3.0.2-0 libtss2-mu0 libtss2-rc0 policykit-1
[36m(setup pid=3447)[0m The following NEW packages will be installed:
[36m(setup pid=3447)[0m   dbus dmsetup gir1.2-glib-2.0 htop iproute2 libapparmor1 libargon2-1 libatm1
[36m(setup pid=3447)[0m   libbpf0 libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1
[36m(setup pid=3447)[0m   libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5
[36m(setup pid=3447)[0m   libmnl0 libnl-genl-3-200 libsensors-config libsensors5 libxtables12
[36m(setup pid=3447)[0m   networkd-dispatcher python3-dbus python3-gi shared-mime-info sysstat systemd
[36m(setup pid=3447)[0m   systemd-timesyncd xdg-user-dirs
[36m(setup pid=3447)[0m The following packages will be upgraded:
[36m(setup pid=3447)[0m   libsystemd0 net-tools
[36m(setup pid=3447)[0m 2 upgraded, 31 newly installed, 0 to remove and 76 not upgraded.
[36m(setup pid=3447)[0m Need to get 10.6 MB of archives.
[36m(setup pid=3447)[0m After this operation, 35.4 MB of additional disk space will be used.
[36m(setup pid=3447)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsystemd0 amd64 249.11-0ubuntu3.16 [317 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libpython3.10:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up python3.10 (3.10.12-1~22.04.10) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=3447)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapparmor1 amd64 3.0.4-2ubuntu2.4 [39.7 kB]
[36m(setup pid=3447)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libargon2-1 amd64 0~20171227-0.3 [19.5 kB]
[36m(setup pid=3447)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdevmapper1.02.1 amd64 2:1.02.175-2.1ubuntu5 [139 kB]
[36m(setup pid=3447)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjson-c5 amd64 0.15-3~ubuntu1.22.04.2 [33.5 kB]
[36m(setup pid=3447)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcryptsetup12 amd64 2:2.4.3-1ubuntu1.3 [211 kB]
[36m(setup pid=3447)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip4tc2 amd64 1.8.7-1ubuntu5.2 [19.9 kB]
[36m(setup pid=3447)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd amd64 249.11-0ubuntu3.16 [4581 kB]
[36m(setup pid=3447)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-3 amd64 1.12.20-2ubuntu4.1 [189 kB]
[36m(setup pid=3447)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dbus amd64 1.12.20-2ubuntu4.1 [158 kB]
[36m(setup pid=3447)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dmsetup amd64 2:1.02.175-2.1ubuntu5 [81.7 kB]
[36m(setup pid=3447)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.5 [1466 kB]
[36m(setup pid=3447)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgirepository-1.0-1 amd64 1.72.0-1 [55.6 kB]
[36m(setup pid=3447)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-glib-2.0 amd64 1.72.0-1 [164 kB]
[36m(setup pid=3447)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libelf1 amd64 0.186-1ubuntu0.1 [51.1 kB]
[36m(setup pid=3447)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbpf0 amd64 1:0.5.0-1ubuntu22.04.1 [140 kB]
[36m(setup pid=3447)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmnl0 amd64 1.0.4-3build2 [13.2 kB]
[36m(setup pid=3447)[0m Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxtables12 amd64 1.8.7-1ubuntu5.2 [31.3 kB]
[36m(setup pid=3447)[0m Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 iproute2 amd64 5.15.0-1ubuntu2 [1070 kB]
[36m(setup pid=3447)[0m Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatm1 amd64 1:2.5.1-4build2 [22.8 kB]
[36m(setup pid=3447)[0m Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.5 [4656 B]
[36m(setup pid=3447)[0m Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-dbus amd64 1.2.18-3build1 [99.5 kB]
[36m(setup pid=3447)[0m Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-gi amd64 3.42.1-0ubuntu1 [229 kB]
[36m(setup pid=3447)[0m Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 networkd-dispatcher all 2.1-2ubuntu0.22.04.2 [15.8 kB]
[36m(setup pid=3447)[0m Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]
[36m(setup pid=3447)[0m Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-timesyncd amd64 249.11-0ubuntu3.16 [31.2 kB]
[36m(setup pid=3447)[0m Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]
[36m(setup pid=3447)[0m Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Reading package lists...
[36m(setup pid=3447)[0m Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 htop amd64 3.0.5-7build2 [128 kB]
[36m(setup pid=3447)[0m Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]
[36m(setup pid=3447)[0m Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]
[36m(setup pid=3447)[0m Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 net-tools amd64 1.60+git20181103.0eebece-1ubuntu5.4 [204 kB]
[36m(setup pid=3447)[0m Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Building dependency tree...
[36m(setup pid=2571, ip=10.102.30.23)[0m Reading state information...
[36m(setup pid=3447)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3447)[0m Fetched 10.6 MB in 2s (6378 kB/s)
[36m(setup pid=3447)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=3447)[0m Preparing to unpack .../libsystemd0_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libsystemd0:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...
[36m(setup pid=3447)[0m Setting up libsystemd0:amd64 (249.11-0ubuntu3.16) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libapparmor1:amd64.
[36m(setup pid=3447)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
[36m(setup pid=3447)[0m (Reading database ... 60%
[36m(setup pid=3447)[0m (Reading database ... 65%
(Reading database ... 70%
[36m(setup pid=3447)[0m (Reading database ... 75%
(Reading database ... 80%
[36m(setup pid=3447)[0m (Reading database ... 85%
[36m(setup pid=3447)[0m (Reading database ... 90%
[36m(setup pid=3447)[0m (Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=3447)[0m Preparing to unpack .../00-libapparmor1_3.0.4-2ubuntu2.4_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m infiniband-diags is already the newest version (2410mlnx54-1.2410068).
[36m(setup pid=2571, ip=10.102.30.23)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2571, ip=10.102.30.23)[0m   libfuse2
[36m(setup pid=2571, ip=10.102.30.23)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2571, ip=10.102.30.23)[0m The following additional packages will be installed:
[36m(setup pid=2571, ip=10.102.30.23)[0m   dbus dmsetup gir1.2-glib-2.0 libapparmor1 libargon2-1 libatm1 libbpf0
[36m(setup pid=2571, ip=10.102.30.23)[0m   libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1 libgirepository-1.0-1
[36m(setup pid=2571, ip=10.102.30.23)[0m   libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5 libmnl0 libnl-genl-3-200
[36m(setup pid=2571, ip=10.102.30.23)[0m   libsensors-config libsensors5 libsystemd0 libxtables12 networkd-dispatcher
[36m(setup pid=2571, ip=10.102.30.23)[0m   python3-dbus python3-gi shared-mime-info systemd systemd-timesyncd
[36m(setup pid=2571, ip=10.102.30.23)[0m   xdg-user-dirs
[36m(setup pid=2571, ip=10.102.30.23)[0m Suggested packages:
[36m(setup pid=2571, ip=10.102.30.23)[0m   default-dbus-session-bus | dbus-session-bus lm-sensors lsof strace
[36m(setup pid=2571, ip=10.102.30.23)[0m   iproute2-doc iw | wireless-tools python-dbus-doc isag systemd-container
[36m(setup pid=2571, ip=10.102.30.23)[0m   libtss2-esys-3.0.2-0 libtss2-mu0 libtss2-rc0 policykit-1
[36m(setup pid=2571, ip=10.102.30.23)[0m The following NEW packages will be installed:
[36m(setup pid=2571, ip=10.102.30.23)[0m   dbus dmsetup gir1.2-glib-2.0 htop iproute2 libapparmor1 libargon2-1 libatm1
[36m(setup pid=2571, ip=10.102.30.23)[0m   libbpf0 libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1
[36m(setup pid=2571, ip=10.102.30.23)[0m   libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5
[36m(setup pid=2571, ip=10.102.30.23)[0m   libmnl0 libnl-genl-3-200 libsensors-config libsensors5 libxtables12
[36m(setup pid=2571, ip=10.102.30.23)[0m   networkd-dispatcher python3-dbus python3-gi shared-mime-info sysstat systemd
[36m(setup pid=2571, ip=10.102.30.23)[0m   systemd-timesyncd xdg-user-dirs
[36m(setup pid=2571, ip=10.102.30.23)[0m The following packages will be upgraded:
[36m(setup pid=2571, ip=10.102.30.23)[0m   libsystemd0 net-tools
[36m(setup pid=3447)[0m Unpacking libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libargon2-1:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../01-libargon2-1_0~20171227-0.3_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libdevmapper1.02.1:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../02-libdevmapper1.02.1_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libjson-c5:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../03-libjson-c5_0.15-3~ubuntu1.22.04.2_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libcryptsetup12:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../04-libcryptsetup12_2%3a2.4.3-1ubuntu1.3_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libip4tc2:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../05-libip4tc2_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3447)[0m Selecting previously unselected package systemd.
[36m(setup pid=3447)[0m Preparing to unpack .../06-systemd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libdbus-1-3:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../07-libdbus-1-3_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3447)[0m Selecting previously unselected package dbus.
[36m(setup pid=3447)[0m Preparing to unpack .../08-dbus_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m 2 upgraded, 31 newly installed, 0 to remove and 76 not upgraded.
[36m(setup pid=2571, ip=10.102.30.23)[0m Need to get 10.6 MB of archives.
[36m(setup pid=2571, ip=10.102.30.23)[0m After this operation, 35.4 MB of additional disk space will be used.
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsystemd0 amd64 249.11-0ubuntu3.16 [317 kB]
[36m(setup pid=3447)[0m Selecting previously unselected package dmsetup.
[36m(setup pid=3447)[0m Preparing to unpack .../09-dmsetup_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libglib2.0-0:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../10-libglib2.0-0_2.72.4-0ubuntu2.5_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libgirepository-1.0-1:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../11-libgirepository-1.0-1_1.72.0-1_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=3447)[0m Selecting previously unselected package gir1.2-glib-2.0:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../12-gir1.2-glib-2.0_1.72.0-1_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../13-libelf1_0.186-1ubuntu0.1_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libbpf0:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../14-libbpf0_1%3a0.5.0-1ubuntu22.04.1_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../15-libmnl0_1.0.4-3build2_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../16-libxtables12_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3447)[0m Selecting previously unselected package iproute2.
[36m(setup pid=3447)[0m Preparing to unpack .../17-iproute2_5.15.0-1ubuntu2_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../18-libatm1_1%3a2.5.1-4build2_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libglib2.0-data.
[36m(setup pid=3447)[0m Preparing to unpack .../19-libglib2.0-data_2.72.4-0ubuntu2.5_all.deb ...
[36m(setup pid=3447)[0m Unpacking libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3447)[0m Selecting previously unselected package python3-dbus.
[36m(setup pid=3447)[0m Preparing to unpack .../20-python3-dbus_1.2.18-3build1_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking python3-dbus (1.2.18-3build1) ...
[36m(setup pid=3447)[0m Selecting previously unselected package python3-gi.
[36m(setup pid=3447)[0m Preparing to unpack .../21-python3-gi_3.42.1-0ubuntu1_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=3447)[0m Selecting previously unselected package networkd-dispatcher.
[36m(setup pid=3447)[0m Preparing to unpack .../22-networkd-dispatcher_2.1-2ubuntu0.22.04.2_all.deb ...
[36m(setup pid=3447)[0m Unpacking networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=3447)[0m Selecting previously unselected package shared-mime-info.
[36m(setup pid=3447)[0m Preparing to unpack .../23-shared-mime-info_2.1-2_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking shared-mime-info (2.1-2) ...
[36m(setup pid=3447)[0m Selecting previously unselected package systemd-timesyncd.
[36m(setup pid=3447)[0m Preparing to unpack .../24-systemd-timesyncd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking systemd-timesyncd (249.11-0ubuntu3.16) ...
[36m(setup pid=3447)[0m Selecting previously unselected package xdg-user-dirs.
[36m(setup pid=3447)[0m Preparing to unpack .../25-xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libnl-genl-3-200:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../26-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=3447)[0m Selecting previously unselected package htop.
[36m(setup pid=3447)[0m Preparing to unpack .../27-htop_3.0.5-7build2_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking htop (3.0.5-7build2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapparmor1 amd64 3.0.4-2ubuntu2.4 [39.7 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libargon2-1 amd64 0~20171227-0.3 [19.5 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdevmapper1.02.1 amd64 2:1.02.175-2.1ubuntu5 [139 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjson-c5 amd64 0.15-3~ubuntu1.22.04.2 [33.5 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcryptsetup12 amd64 2:2.4.3-1ubuntu1.3 [211 kB]
[36m(setup pid=3447)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=3447)[0m Preparing to unpack .../28-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...
[36m(setup pid=3447)[0m Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3447)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=3447)[0m Preparing to unpack .../29-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3447)[0m Preparing to unpack .../30-net-tools_1.60+git20181103.0eebece-1ubuntu5.4_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking net-tools (1.60+git20181103.0eebece-1ubuntu5.4) over (1.60+git20181103.0eebece-1ubuntu5) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip4tc2 amd64 1.8.7-1ubuntu5.2 [19.9 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd amd64 249.11-0ubuntu3.16 [4581 kB]
[36m(setup pid=3447)[0m Selecting previously unselected package sysstat.
[36m(setup pid=3447)[0m Preparing to unpack .../31-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...
[36m(setup pid=3447)[0m Unpacking sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=3447)[0m Setting up libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3447)[0m Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5.4) ...
[36m(setup pid=3447)[0m Setting up libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3447)[0m Setting up xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3447)[0m Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3447)[0m No schema files found: doing nothing.
[36m(setup pid=3447)[0m Setting up libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=3447)[0m Setting up libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3447)[0m Setting up libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=3447)[0m Setting up libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3447)[0m Setting up libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3447)[0m Setting up dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3447)[0m Setting up shared-mime-info (2.1-2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-3 amd64 1.12.20-2ubuntu4.1 [189 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dbus amd64 1.12.20-2ubuntu4.1 [158 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dmsetup amd64 2:1.02.175-2.1ubuntu5 [81.7 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.5 [1466 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgirepository-1.0-1 amd64 1.72.0-1 [55.6 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-glib-2.0 amd64 1.72.0-1 [164 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libelf1 amd64 0.186-1ubuntu0.1 [51.1 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbpf0 amd64 1:0.5.0-1ubuntu22.04.1 [140 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmnl0 amd64 1.0.4-3build2 [13.2 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxtables12 amd64 1.8.7-1ubuntu5.2 [31.3 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 iproute2 amd64 5.15.0-1ubuntu2 [1070 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatm1 amd64 1:2.5.1-4build2 [22.8 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.5 [4656 B]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-dbus amd64 1.2.18-3build1 [99.5 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-gi amd64 3.42.1-0ubuntu1 [229 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 networkd-dispatcher all 2.1-2ubuntu0.22.04.2 [15.8 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-timesyncd amd64 249.11-0ubuntu3.16 [31.2 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 htop amd64 3.0.5-7build2 [128 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 net-tools amd64 1.60+git20181103.0eebece-1ubuntu5.4 [204 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]
[36m(setup pid=2571, ip=10.102.30.23)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2571, ip=10.102.30.23)[0m Fetched 10.6 MB in 2s (6373 kB/s)
[36m(setup pid=2571, ip=10.102.30.23)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../libsystemd0_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libsystemd0:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libsystemd0:amd64 (249.11-0ubuntu3.16) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libapparmor1:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../00-libapparmor1_3.0.4-2ubuntu2.4_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libargon2-1:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../01-libargon2-1_0~20171227-0.3_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libdevmapper1.02.1:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../02-libdevmapper1.02.1_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libjson-c5:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../03-libjson-c5_0.15-3~ubuntu1.22.04.2_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libcryptsetup12:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../04-libcryptsetup12_2%3a2.4.3-1ubuntu1.3_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libip4tc2:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../05-libip4tc2_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package systemd.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../06-systemd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3447)[0m Setting up libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=3447)[0m Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3447)[0m Setting up libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3447)[0m Setting up libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3447)[0m Setting up dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3447)[0m Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=3447)[0m Setting up libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libdbus-1-3:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../07-libdbus-1-3_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3447)[0m Setting up libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=3447)[0m Setting up libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=3447)[0m Setting up sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package dbus.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../08-dbus_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package dmsetup.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../09-dmsetup_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libglib2.0-0:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../10-libglib2.0-0_2.72.4-0ubuntu2.5_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=3447)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=3447)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libgirepository-1.0-1:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../11-libgirepository-1.0-1_1.72.0-1_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package gir1.2-glib-2.0:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../12-gir1.2-glib-2.0_1.72.0-1_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../13-libelf1_0.186-1ubuntu0.1_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libbpf0:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../14-libbpf0_1%3a0.5.0-1ubuntu22.04.1_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../15-libmnl0_1.0.4-3build2_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=3447)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /lib/systemd/system/sysstat-collect.timer.
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../16-libxtables12_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package iproute2.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../17-iproute2_5.15.0-1ubuntu2_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../18-libatm1_1%3a2.5.1-4build2_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libglib2.0-data.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../19-libglib2.0-data_2.72.4-0ubuntu2.5_all.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package python3-dbus.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../20-python3-dbus_1.2.18-3build1_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking python3-dbus (1.2.18-3build1) ...
[36m(setup pid=3447)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /lib/systemd/system/sysstat-summary.timer.
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package python3-gi.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../21-python3-gi_3.42.1-0ubuntu1_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package networkd-dispatcher.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../22-networkd-dispatcher_2.1-2ubuntu0.22.04.2_all.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package shared-mime-info.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../23-shared-mime-info_2.1-2_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking shared-mime-info (2.1-2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package systemd-timesyncd.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../24-systemd-timesyncd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking systemd-timesyncd (249.11-0ubuntu3.16) ...
[36m(setup pid=3447)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.
[36m(setup pid=3447)[0m Setting up python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package xdg-user-dirs.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../25-xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libnl-genl-3-200:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../26-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package htop.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../27-htop_3.0.5-7build2_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking htop (3.0.5-7build2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../28-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3447)[0m Setting up htop (3.0.5-7build2) ...
[36m(setup pid=3447)[0m Setting up gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=3447)[0m Setting up libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=3447)[0m Setting up libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3447)[0m Setting up iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../29-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../30-net-tools_1.60+git20181103.0eebece-1ubuntu5.4_amd64.deb ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking net-tools (1.60+git20181103.0eebece-1ubuntu5.4) over (1.60+git20181103.0eebece-1ubuntu5) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Selecting previously unselected package sysstat.
[36m(setup pid=2571, ip=10.102.30.23)[0m Preparing to unpack .../31-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...
[36m(setup pid=3447)[0m Setting up systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m Configuration file '/etc/systemd/system.conf'
[36m(setup pid=3447)[0m  ==> File on system created by you or by a script.
[36m(setup pid=3447)[0m  ==> File also in package provided by package maintainer.
[36m(setup pid=3447)[0m    What would you like to do about it ?  Your options are:
[36m(setup pid=3447)[0m     Y or I  : install the package maintainer's version
[36m(setup pid=3447)[0m     N or O  : keep your currently-installed version
[36m(setup pid=3447)[0m       D     : show the differences between the versions
[36m(setup pid=3447)[0m       Z     : start a shell to examine the situation
[36m(setup pid=3447)[0m  The default action is to keep your current version.
[36m(setup pid=3447)[0m *** system.conf (Y/I/N/O/D/Z) [default=N] ? dpkg: error processing package systemd (--configure):
[36m(setup pid=3447)[0m  end of file on stdin at conffile prompt
[36m(setup pid=3447)[0m Setting up python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Unpacking sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5.4) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m No schema files found: doing nothing.
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3447)[0m dpkg: dependency problems prevent configuration of systemd-timesyncd:
[36m(setup pid=3447)[0m  systemd-timesyncd depends on systemd (= 249.11-0ubuntu3.16); however:
[36m(setup pid=3447)[0m   Package systemd is not configured yet.
[36m(setup pid=3447)[0m 
[36m(setup pid=3447)[0m dpkg: error processing package systemd-timesyncd (--configure):
[36m(setup pid=3447)[0m  dependency problems - leaving unconfigured
[36m(setup pid=3447)[0m Setting up networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up shared-mime-info (2.1-2) ...
[36m(setup pid=3447)[0m Created symlink /etc/systemd/system/multi-user.target.wants/networkd-dispatcher.service → /lib/systemd/system/networkd-dispatcher.service.
[36m(setup pid=3447)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=3447)[0m Errors were encountered while processing:
[36m(setup pid=3447)[0m  systemd
[36m(setup pid=3447)[0m  systemd-timesyncd
[36m(setup pid=3447)[0m E: Sub-process /usr/bin/dpkg returned an error code (1)
[36m(setup pid=3447)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3447)[0m Resolved 3 packages in 149ms
[36m(setup pid=3447)[0m Prepared 1 package in 11ms
[36m(setup pid=3447)[0m Installed 2 packages in 16ms
[36m(setup pid=3447)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=3447)[0m  + nvitop==1.5.2
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=2571, ip=10.102.30.23)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=2571, ip=10.102.30.23)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=2571, ip=10.102.30.23)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /lib/systemd/system/sysstat-collect.timer.
[36m(setup pid=2571, ip=10.102.30.23)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /lib/systemd/system/sysstat-summary.timer.
[36m(setup pid=2571, ip=10.102.30.23)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up htop (3.0.5-7build2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m Configuration file '/etc/systemd/system.conf'
[36m(setup pid=2571, ip=10.102.30.23)[0m  ==> File on system created by you or by a script.
[36m(setup pid=2571, ip=10.102.30.23)[0m  ==> File also in package provided by package maintainer.
[36m(setup pid=2571, ip=10.102.30.23)[0m    What would you like to do about it ?  Your options are:
[36m(setup pid=2571, ip=10.102.30.23)[0m     Y or I  : install the package maintainer's version
[36m(setup pid=2571, ip=10.102.30.23)[0m     N or O  : keep your currently-installed version
[36m(setup pid=2571, ip=10.102.30.23)[0m       D     : show the differences between the versions
[36m(setup pid=2571, ip=10.102.30.23)[0m       Z     : start a shell to examine the situation
[36m(setup pid=2571, ip=10.102.30.23)[0m  The default action is to keep your current version.
[36m(setup pid=2571, ip=10.102.30.23)[0m *** system.conf (Y/I/N/O/D/Z) [default=N] ? dpkg: error processing package systemd (--configure):
[36m(setup pid=2571, ip=10.102.30.23)[0m  end of file on stdin at conffile prompt
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m dpkg: dependency problems prevent configuration of systemd-timesyncd:
[36m(setup pid=2571, ip=10.102.30.23)[0m  systemd-timesyncd depends on systemd (= 249.11-0ubuntu3.16); however:
[36m(setup pid=2571, ip=10.102.30.23)[0m   Package systemd is not configured yet.
[36m(setup pid=2571, ip=10.102.30.23)[0m 
[36m(setup pid=2571, ip=10.102.30.23)[0m dpkg: error processing package systemd-timesyncd (--configure):
[36m(setup pid=2571, ip=10.102.30.23)[0m  dependency problems - leaving unconfigured
[36m(setup pid=2571, ip=10.102.30.23)[0m Setting up networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Created symlink /etc/systemd/system/multi-user.target.wants/networkd-dispatcher.service → /lib/systemd/system/networkd-dispatcher.service.
[36m(setup pid=2571, ip=10.102.30.23)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2571, ip=10.102.30.23)[0m Errors were encountered while processing:
[36m(setup pid=2571, ip=10.102.30.23)[0m  systemd
[36m(setup pid=2571, ip=10.102.30.23)[0m  systemd-timesyncd
[36m(setup pid=2571, ip=10.102.30.23)[0m E: Sub-process /usr/bin/dpkg returned an error code (1)
[36m(setup pid=2571, ip=10.102.30.23)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2571, ip=10.102.30.23)[0m Resolved 3 packages in 39ms
[36m(setup pid=2571, ip=10.102.30.23)[0m Prepared 1 package in 9ms
[36m(setup pid=2571, ip=10.102.30.23)[0m Installed 2 packages in 16ms
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=2571, ip=10.102.30.23)[0m  + nvitop==1.5.2
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m === Processing directory 1/2: /tmp/checkpoint ===
[36m(head, rank=0, pid=3447)[0m Preserving existing cache directories...
[36m(head, rank=0, pid=3447)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3447)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3447)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Downloading and caching dataset...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m === Processing directory 1/2: /tmp/checkpoint ===
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Preserving existing cache directories...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Downloading and caching dataset...
[36m(head, rank=0, pid=3447)[0m Setting num_proc from 128 to 10 for the train split as it only contains 10 shards.
[36m(head, rank=0, pid=3447)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Setting num_proc from 128 to 10 for the train split as it only contains 10 shards.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(head, rank=0, pid=3447)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3447)[0m Generating train split:   2%|▏         | 1000/47780 [00:00<00:23, 1965.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3447)[0m Generating train split:  15%|█▍        | 7000/47780 [00:00<00:02, 14449.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Generating train split:   2%|▏         | 1000/47780 [00:00<00:23, 2021.33 examples/s]
[36m(head, rank=0, pid=3447)[0m Generating train split:  23%|██▎       | 11000/47780 [00:00<00:01, 19608.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Generating train split:  17%|█▋        | 8000/47780 [00:00<00:02, 16821.34 examples/s]
[36m(head, rank=0, pid=3447)[0m Generating train split:  36%|███▌      | 17000/47780 [00:00<00:01, 28800.69 examples/s]
[36m(head, rank=0, pid=3447)[0m Generating train split:  46%|████▌     | 22000/47780 [00:00<00:00, 31421.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Generating train split:  25%|██▌       | 12000/47780 [00:00<00:01, 20402.92 examples/s]
[36m(head, rank=0, pid=3447)[0m Generating train split:  63%|██████▎   | 30000/47780 [00:01<00:00, 41577.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Generating train split:  44%|████▍     | 21000/47780 [00:00<00:00, 30771.73 examples/s]
[36m(head, rank=0, pid=3447)[0m Generating train split:  80%|████████  | 38334/47780 [00:01<00:00, 51841.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Generating train split:  63%|██████▎   | 30000/47780 [00:01<00:00, 42663.95 examples/s]
[36m(head, rank=0, pid=3447)[0m Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 59495.46 examples/s]
Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 34455.34 examples/s]
[36m(head, rank=0, pid=3447)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(head, rank=0, pid=3447)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Generating train split:  81%|████████  | 38556/47780 [00:01<00:00, 51797.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 61779.18 examples/s]
Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 36312.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3447)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3447)[0m vmtouch output: Files: 14
[36m(head, rank=0, pid=3447)[0m      Directories: 5
[36m(head, rank=0, pid=3447)[0m    Evicted Pages: 1212952 (4G)
[36m(head, rank=0, pid=3447)[0m          Elapsed: 3.6639 seconds
[36m(head, rank=0, pid=3447)[0m Downloading and caching model...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m vmtouch output: Files: 14
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m      Directories: 5
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m    Evicted Pages: 1212952 (4G)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m          Elapsed: 3.6675 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Downloading and caching model...
[36m(head, rank=0, pid=3447)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Fetching 5 files:  20%|██        | 1/5 [00:21<01:27, 21.92s/it]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Fetching 5 files:  40%|████      | 2/5 [00:22<00:27,  9.16s/it]
Fetching 5 files:  80%|████████  | 4/5 [00:22<00:03,  3.56s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:22<00:00,  4.52s/it]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(head, rank=0, pid=3447)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3447)[0m Fetching 5 files:  20%|██        | 1/5 [00:24<01:38, 24.53s/it]
[36m(head, rank=0, pid=3447)[0m Fetching 5 files:  40%|████      | 2/5 [00:25<00:32, 10.95s/it]
Fetching 5 files:  80%|████████  | 4/5 [00:26<00:04,  4.28s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:26<00:00,  5.32s/it]
[36m(head, rank=0, pid=3447)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:03<00:15,  3.97s/it]
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:07<00:11,  3.83s/it]
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:16,  4.14s/it]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:11<00:07,  3.81s/it]
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:08<00:12,  4.05s/it]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:15<00:03,  3.81s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.72s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.77s/it]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Model downloaded and cached at: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Flushing filesystem cache for: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:12<00:08,  4.04s/it]
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:16<00:04,  4.02s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.92s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.98s/it]
[36m(head, rank=0, pid=3447)[0m Model downloaded and cached at: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Flushing filesystem cache for: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3447)[0m vmtouch output: Files: 18
[36m(head, rank=0, pid=3447)[0m      Directories: 10
[36m(head, rank=0, pid=3447)[0m    Evicted Pages: 5950909 (22G)
[36m(head, rank=0, pid=3447)[0m          Elapsed: 14.54 seconds
[36m(head, rank=0, pid=3447)[0m Completed processing directory 1/2
[36m(head, rank=0, pid=3447)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache, /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3447)[0m vmtouch output: Files: 32
[36m(head, rank=0, pid=3447)[0m      Directories: 15
[36m(head, rank=0, pid=3447)[0m    Evicted Pages: 7163861 (27G)
[36m(head, rank=0, pid=3447)[0m          Elapsed: 0.001787 seconds
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m === Processing directory 2/2: /mnt/data ===
[36m(head, rank=0, pid=3447)[0m Preserving existing cache directories...
[36m(head, rank=0, pid=3447)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3447)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3447)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3447)[0m Downloading and caching dataset...
[36m(head, rank=0, pid=3447)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(head, rank=0, pid=3447)[0m Flushing filesystem cache for: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3447)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3447)[0m vmtouch output: Files: 78
[36m(head, rank=0, pid=3447)[0m      Directories: 5
[36m(head, rank=0, pid=3447)[0m    Evicted Pages: 4617819 (17G)
[36m(head, rank=0, pid=3447)[0m          Elapsed: 0.24935 seconds
[36m(head, rank=0, pid=3447)[0m Downloading and caching model...
[36m(head, rank=0, pid=3447)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m vmtouch output: Files: 18
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m      Directories: 10
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m    Evicted Pages: 5950909 (22G)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m          Elapsed: 22.266 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed processing directory 1/2
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache, /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m vmtouch output: Files: 32
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m      Directories: 15
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m    Evicted Pages: 7163861 (27G)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m          Elapsed: 0.001359 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m === Processing directory 2/2: /mnt/data ===
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Preserving existing cache directories...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Downloading and caching dataset...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Flushing filesystem cache for: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m vmtouch output: Files: 78
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m      Directories: 5
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m    Evicted Pages: 4617819 (17G)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m          Elapsed: 0.22753 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Downloading and caching model...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.76s/it]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:22,  5.62s/it]
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:10<00:16,  5.45s/it]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:10<00:15,  5.30s/it]
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:16<00:10,  5.32s/it]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:15<00:10,  5.12s/it]
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:21<00:05,  5.26s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:26<00:00,  5.08s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:26<00:00,  5.22s/it]
[36m(head, rank=0, pid=3447)[0m Model downloaded and cached at: /mnt/data/model_cache
[36m(head, rank=0, pid=3447)[0m Flushing filesystem cache for: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:20<00:05,  5.06s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:25<00:00,  4.92s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:25<00:00,  5.05s/it]
[36m(head, rank=0, pid=3447)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3447)[0m vmtouch output: Files: 18
[36m(head, rank=0, pid=3447)[0m      Directories: 10
[36m(head, rank=0, pid=3447)[0m    Evicted Pages: 5950909 (22G)
[36m(head, rank=0, pid=3447)[0m          Elapsed: 1.0568 seconds
[36m(head, rank=0, pid=3447)[0m Completed processing directory 2/2
[36m(head, rank=0, pid=3447)[0m Flushing filesystem cache for: /mnt/data/dataset_cache, /mnt/data/model_cache
[36m(head, rank=0, pid=3447)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3447)[0m vmtouch output: Files: 96
[36m(head, rank=0, pid=3447)[0m      Directories: 15
[36m(head, rank=0, pid=3447)[0m    Evicted Pages: 10568728 (40G)
[36m(head, rank=0, pid=3447)[0m          Elapsed: 0.11921 seconds
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m === Copying cached data to S3 directories ===
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Copying to S3 directory 1/2: /checkpoints_s3
[36m(head, rank=0, pid=3447)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Model downloaded and cached at: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Flushing filesystem cache for: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m vmtouch output: Files: 18
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m      Directories: 10
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m    Evicted Pages: 5950909 (22G)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m          Elapsed: 1.0324 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed processing directory 2/2
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Flushing filesystem cache for: /mnt/data/dataset_cache, /mnt/data/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m vmtouch output: Files: 96
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m      Directories: 15
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m    Evicted Pages: 10568728 (40G)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m          Elapsed: 0.11567 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m === Copying cached data to S3 directories ===
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Copying to S3 directory 1/2: /checkpoints_s3
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset cache copied successfully
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3447)[0m Dataset cache copied successfully
[36m(head, rank=0, pid=3447)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Model cache copied successfully
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoints copied successfully
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed copying to S3 directory 1/2
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Copying to S3 directory 2/2: /checkpoints_s3_mount_cached
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Error setting up S3 directory /checkpoints_s3_mount_cached: [Errno 5] Input/output error: '/checkpoints_s3_mount_cached/dataset_cache'
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Skipping this S3 directory...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m === Download and caching completed ===
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3447)[0m Model cache copied successfully
[36m(head, rank=0, pid=3447)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3447)[0m Checkpoints copied successfully
[36m(head, rank=0, pid=3447)[0m Completed copying to S3 directory 1/2
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Copying to S3 directory 2/2: /checkpoints_s3_mount_cached
[36m(head, rank=0, pid=3447)[0m Error setting up S3 directory /checkpoints_s3_mount_cached: [Errno 5] Input/output error: '/checkpoints_s3_mount_cached/dataset_cache'
[36m(head, rank=0, pid=3447)[0m Skipping this S3 directory...
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m === Download and caching completed ===
[36m(head, rank=0, pid=3447)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3447)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3447)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3447)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3447)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3447)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3447)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3447)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3447)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3447)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3447)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3447)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3447)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3447)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3447)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3447)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3447)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3447)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3447)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3447)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3447)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3447)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3447)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3447)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3447)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3447)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(head, rank=0, pid=3447)[0m Starting Load dataset...
[36m(head, rank=0, pid=3447)[0m Starting Load dataset...
[36m(head, rank=0, pid=3447)[0m Starting Load dataset...
[36m(head, rank=0, pid=3447)[0m Starting Load dataset...
[36m(head, rank=0, pid=3447)[0m Starting Load dataset...
[36m(head, rank=0, pid=3447)[0m Starting Load dataset...
[36m(head, rank=0, pid=3447)[0m Starting Load dataset...
[36m(head, rank=0, pid=3447)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load dataset in 2.07 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load model...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Completed Load dataset in 2.06 seconds
[36m(head, rank=0, pid=3447)[0m Starting Load model...
[36m(head, rank=0, pid=3447)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Completed Load dataset in 2.07 seconds
[36m(head, rank=0, pid=3447)[0m Starting Load model...
[36m(head, rank=0, pid=3447)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Completed Load dataset in 2.07 seconds
[36m(head, rank=0, pid=3447)[0m Starting Load model...
[36m(head, rank=0, pid=3447)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Completed Load dataset in 2.12 seconds
[36m(head, rank=0, pid=3447)[0m Starting Load model...
[36m(head, rank=0, pid=3447)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load dataset in 2.09 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load model...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load dataset in 2.25 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load model...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load dataset in 2.27 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load model...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load dataset in 2.27 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load model...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Completed Load dataset in 2.26 seconds
[36m(head, rank=0, pid=3447)[0m Starting Load model...
[36m(head, rank=0, pid=3447)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Completed Load dataset in 2.27 seconds
[36m(head, rank=0, pid=3447)[0m Starting Load model...
[36m(head, rank=0, pid=3447)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Completed Load dataset in 2.27 seconds
[36m(head, rank=0, pid=3447)[0m Starting Load model...
[36m(head, rank=0, pid=3447)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m Completed Load dataset in 2.30 seconds
[36m(head, rank=0, pid=3447)[0m Starting Load model...
[36m(head, rank=0, pid=3447)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load dataset in 2.30 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load model...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load dataset in 2.30 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load model...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load dataset in 2.37 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Load model...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3447)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 134.84it/s]
[36m(head, rank=0, pid=3447)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 135.01it/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 135.92it/s]
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 131.16it/s]
[36m(head, rank=0, pid=3447)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 129.47it/s]
[36m(head, rank=0, pid=3447)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load model in 0.86 seconds
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 0.91 seconds
[36m(head, rank=0, pid=3447)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 137.23it/s]
[36m(head, rank=0, pid=3447)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 0.91 seconds
[36m(head, rank=0, pid=3447)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 132.48it/s]
[36m(head, rank=0, pid=3447)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 128.19it/s]
[36m(head, rank=0, pid=3447)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 130.43it/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load model in 0.93 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 130.54it/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 138.53it/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 136.85it/s]
[36m(head, rank=0, pid=3447)[0m Completed Load model in 1.01 seconds
[36m(head, rank=0, pid=3447)[0m Completed Load model in 0.88 seconds
[36m(head, rank=0, pid=3447)[0m Completed Load model in 0.91 seconds
[36m(head, rank=0, pid=3447)[0m Completed Load model in 0.92 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 131.36it/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 130.25it/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load model in 0.96 seconds
[36m(head, rank=0, pid=3447)[0m Completed Load model in 0.95 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Training...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load model in 0.94 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load model in 0.97 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load model in 0.99 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load model in 0.89 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Training...
[36m(head, rank=0, pid=3447)[0m Starting Training...
[36m(head, rank=0, pid=3447)[0m Starting Training...
[36m(head, rank=0, pid=3447)[0m Starting Training...
[36m(head, rank=0, pid=3447)[0m Starting Training...
[36m(head, rank=0, pid=3447)[0m Starting Training...
[36m(head, rank=0, pid=3447)[0m Starting Training...
[36m(head, rank=0, pid=3447)[0m Starting Training...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Training...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Training...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Training...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Training...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Training...
[36m(head, rank=0, pid=3447)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:16,  4.18s/it]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:16,  4.12s/it]
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:07<00:11,  3.96s/it]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:07<00:11,  3.89s/it]
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:11<00:07,  3.94s/it]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:11<00:07,  3.87s/it]
[36m(head, rank=0, pid=3447)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:15<00:03,  3.89s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.76s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.85s/it]
[36m(head, rank=0, pid=3447)[0m Completed Load model in 20.05 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:15<00:03,  3.88s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.78s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.84s/it]
[36m(head, rank=0, pid=3447)[0m Starting Training...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Load model in 20.09 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Training...
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   0%|          | 7/47780 [00:10<20:11:19,  1.52s/ examples]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   0%|          | 38/47780 [00:10<2:51:38,  4.64 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   0%|          | 72/47780 [00:11<1:17:40, 10.24 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   0%|          | 151/47780 [00:11<28:42, 27.65 examples/s] 
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   0%|          | 215/47780 [00:11<17:56, 44.19 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   1%|          | 285/47780 [00:12<12:03, 65.66 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   1%|          | 367/47780 [00:12<08:21, 94.57 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   1%|          | 454/47780 [00:12<06:13, 126.80 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   1%|          | 589/47780 [00:13<04:10, 188.44 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 730/47780 [00:13<03:10, 246.95 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 889/47780 [00:13<02:30, 311.44 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1039/47780 [00:14<02:11, 356.21 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1177/47780 [00:14<02:02, 379.31 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1360/47780 [00:14<01:47, 429.86 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1566/47780 [00:14<01:33, 492.99 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1777/47780 [00:15<01:24, 542.69 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2007/47780 [00:15<01:16, 599.24 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2213/47780 [00:15<01:14, 612.60 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2478/47780 [00:16<01:07, 675.53 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2725/47780 [00:16<01:04, 695.86 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2968/47780 [00:16<01:02, 714.69 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3239/47780 [00:17<00:59, 752.27 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3508/47780 [00:17<01:01, 719.28 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3912/47780 [00:17<00:51, 857.83 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4223/47780 [00:18<00:49, 881.43 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4569/47780 [00:18<00:46, 934.86 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4896/47780 [00:18<00:44, 957.69 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5246/47780 [00:19<00:34, 1247.25 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5420/47780 [00:19<00:35, 1192.27 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5571/47780 [00:19<00:36, 1168.33 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5710/47780 [00:19<00:37, 1128.24 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5842/47780 [00:19<00:36, 1146.68 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5967/47780 [00:19<00:36, 1152.78 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6091/47780 [00:19<00:36, 1155.34 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6213/47780 [00:19<00:35, 1163.08 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6334/47780 [00:20<00:35, 1152.21 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6456/47780 [00:20<00:35, 1147.93 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6575/47780 [00:20<00:35, 1157.11 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6698/47780 [00:20<00:36, 1134.53 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6831/47780 [00:20<00:34, 1187.60 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6960/47780 [00:20<00:34, 1197.54 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7094/47780 [00:20<00:32, 1234.01 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7219/47780 [00:20<00:33, 1198.02 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7347/47780 [00:20<00:33, 1196.04 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7482/47780 [00:21<00:32, 1230.04 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7608/47780 [00:21<00:33, 1205.18 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7729/47780 [00:21<00:34, 1147.33 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7846/47780 [00:21<00:35, 1129.54 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7961/47780 [00:21<00:35, 1112.39 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8087/47780 [00:21<00:34, 1151.16 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8204/47780 [00:21<00:35, 1128.26 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8337/47780 [00:21<00:33, 1178.02 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8456/47780 [00:21<00:34, 1127.52 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8577/47780 [00:21<00:35, 1117.63 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8702/47780 [00:22<00:33, 1154.49 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8826/47780 [00:22<00:33, 1178.15 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8945/47780 [00:22<00:33, 1174.69 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9079/47780 [00:22<00:31, 1219.62 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9207/47780 [00:22<00:31, 1232.04 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9332/47780 [00:22<00:31, 1209.14 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9463/47780 [00:22<00:30, 1238.32 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9589/47780 [00:22<00:32, 1186.40 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9709/47780 [00:22<00:32, 1164.52 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9827/47780 [00:23<00:32, 1159.56 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9956/47780 [00:23<00:31, 1188.45 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10081/47780 [00:23<00:31, 1205.63 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10203/47780 [00:23<00:32, 1169.58 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10324/47780 [00:23<00:31, 1170.59 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10453/47780 [00:23<00:31, 1202.65 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10575/47780 [00:23<00:31, 1166.76 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10703/47780 [00:23<00:31, 1193.44 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10824/47780 [00:23<00:31, 1192.03 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10950/47780 [00:23<00:30, 1203.47 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11072/47780 [00:24<00:31, 1155.46 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11190/47780 [00:24<00:31, 1153.60 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11306/47780 [00:24<00:31, 1148.62 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11430/47780 [00:24<00:31, 1171.66 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11548/47780 [00:24<00:30, 1172.20 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11687/47780 [00:24<00:29, 1228.80 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11826/47780 [00:24<00:28, 1260.16 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 11954/47780 [00:24<00:29, 1224.84 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12078/47780 [00:24<00:29, 1227.98 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12205/47780 [00:25<00:28, 1234.12 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12342/47780 [00:25<00:27, 1273.63 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12470/47780 [00:25<00:28, 1253.87 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12596/47780 [00:25<00:28, 1218.85 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12725/47780 [00:25<00:28, 1239.24 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12863/47780 [00:25<00:27, 1262.86 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12994/47780 [00:25<00:27, 1271.27 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13136/47780 [00:25<00:26, 1311.14 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13269/47780 [00:25<00:28, 1222.15 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13394/47780 [00:25<00:28, 1187.30 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13531/47780 [00:26<00:27, 1223.93 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13682/47780 [00:26<00:26, 1301.04 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13816/47780 [00:26<00:26, 1288.47 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13948/47780 [00:26<00:26, 1256.71 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14076/47780 [00:26<00:26, 1261.49 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14213/47780 [00:26<00:26, 1285.53 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14342/47780 [00:26<00:27, 1217.58 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14468/47780 [00:26<00:27, 1203.56 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14591/47780 [00:26<00:29, 1140.90 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14715/47780 [00:27<00:28, 1166.04 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14845/47780 [00:27<00:27, 1180.58 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14985/47780 [00:27<00:26, 1234.49 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15111/47780 [00:27<00:27, 1194.90 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15232/47780 [00:27<00:27, 1178.64 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15352/47780 [00:27<00:29, 1106.08 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15476/47780 [00:27<00:28, 1133.57 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15593/47780 [00:27<00:28, 1134.87 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15708/47780 [00:27<00:29, 1105.62 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15826/47780 [00:28<00:28, 1123.85 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15965/47780 [00:28<00:26, 1189.10 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16089/47780 [00:28<00:26, 1202.54 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16226/47780 [00:28<00:25, 1244.58 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16352/47780 [00:28<00:25, 1229.26 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16495/47780 [00:28<00:24, 1267.92 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16625/47780 [00:28<00:25, 1240.29 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16752/47780 [00:28<00:25, 1240.17 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16894/47780 [00:28<00:23, 1292.13 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17024/47780 [00:28<00:24, 1236.50 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17165/47780 [00:29<00:23, 1284.60 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17295/47780 [00:29<00:24, 1247.41 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17421/47780 [00:29<00:24, 1236.45 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17549/47780 [00:29<00:24, 1220.23 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17694/47780 [00:29<00:23, 1272.00 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17825/47780 [00:29<00:23, 1272.33 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17958/47780 [00:29<00:23, 1288.39 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18089/47780 [00:29<00:23, 1275.37 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18218/47780 [00:29<00:23, 1249.42 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18354/47780 [00:30<00:23, 1269.62 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18483/47780 [00:30<00:23, 1223.86 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18607/47780 [00:30<00:24, 1199.14 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18730/47780 [00:30<00:24, 1207.49 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18864/47780 [00:30<00:23, 1240.74 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18991/47780 [00:30<00:23, 1245.84 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19116/47780 [00:30<00:23, 1224.61 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19240/47780 [00:30<00:24, 1187.73 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19366/47780 [00:30<00:23, 1208.19 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19488/47780 [00:30<00:23, 1190.51 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19612/47780 [00:31<00:23, 1201.29 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19733/47780 [00:31<00:23, 1197.09 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19862/47780 [00:31<00:22, 1219.18 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19985/47780 [00:31<00:23, 1172.34 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20105/47780 [00:31<00:23, 1170.50 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20224/47780 [00:31<00:24, 1140.00 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20352/47780 [00:31<00:23, 1172.37 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20479/47780 [00:31<00:22, 1189.16 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20604/47780 [00:31<00:22, 1200.67 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20727/47780 [00:32<00:22, 1205.57 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20862/47780 [00:32<00:22, 1222.12 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20989/47780 [00:32<00:21, 1235.87 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21115/47780 [00:32<00:21, 1212.56 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21238/47780 [00:32<00:22, 1190.98 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21366/47780 [00:32<00:22, 1199.85 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21504/47780 [00:32<00:21, 1245.30 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21630/47780 [00:32<00:21, 1228.19 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21753/47780 [00:32<00:21, 1190.07 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21878/47780 [00:32<00:21, 1197.02 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21998/47780 [00:33<00:21, 1186.77 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22129/47780 [00:33<00:21, 1212.35 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22251/47780 [00:33<00:21, 1206.09 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22375/47780 [00:33<00:20, 1213.58 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22507/47780 [00:33<00:20, 1240.87 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22632/47780 [00:33<00:20, 1233.79 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22757/47780 [00:33<00:20, 1237.75 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22894/47780 [00:33<00:19, 1274.98 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23025/47780 [00:33<00:20, 1201.69 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23148/47780 [00:34<00:21, 1155.96 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23266/47780 [00:34<00:21, 1159.28 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23398/47780 [00:34<00:20, 1203.99 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23520/47780 [00:34<00:20, 1161.92 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23638/47780 [00:34<00:21, 1097.39 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23764/47780 [00:34<00:21, 1130.18 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23878/47780 [00:34<00:21, 1111.59 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24016/47780 [00:34<00:20, 1177.28 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24154/47780 [00:34<00:19, 1228.21 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24279/47780 [00:34<00:20, 1164.50 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24418/47780 [00:35<00:19, 1224.49 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24542/47780 [00:35<00:19, 1181.10 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24676/47780 [00:35<00:19, 1213.39 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24799/47780 [00:35<00:20, 1141.71 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24920/47780 [00:35<00:19, 1159.33 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25044/47780 [00:35<00:19, 1176.43 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25164/47780 [00:35<00:19, 1180.19 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25283/47780 [00:35<00:19, 1145.09 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25409/47780 [00:35<00:19, 1169.86 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25527/47780 [00:36<00:19, 1149.53 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25644/47780 [00:36<00:19, 1145.45 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25765/47780 [00:36<00:18, 1163.85 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25884/47780 [00:36<00:19, 1110.27 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26012/47780 [00:36<00:18, 1147.80 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26130/47780 [00:36<00:19, 1099.35 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26241/47780 [00:36<00:20, 1065.63 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26349/47780 [00:36<00:20, 1059.15 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26468/47780 [00:36<00:19, 1094.31 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26595/47780 [00:37<00:18, 1141.40 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26710/47780 [00:37<00:19, 1094.77 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26839/47780 [00:37<00:18, 1144.23 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26959/47780 [00:37<00:18, 1152.30 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27075/47780 [00:37<00:19, 1088.91 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27185/47780 [00:37<00:19, 1049.17 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27295/47780 [00:37<00:19, 1035.13 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27407/47780 [00:37<00:19, 1055.07 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27515/47780 [00:37<00:19, 1034.24 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27640/47780 [00:37<00:18, 1079.42 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27752/47780 [00:38<00:18, 1088.83 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27863/47780 [00:38<00:18, 1051.69 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27982/47780 [00:38<00:18, 1075.25 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28090/47780 [00:38<00:18, 1044.06 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28196/47780 [00:38<00:19, 1023.13 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28318/47780 [00:38<00:18, 1078.53 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28431/47780 [00:38<00:18, 1061.97 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28538/47780 [00:38<00:19, 993.32 examples/s] 
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28642/47780 [00:38<00:19, 987.58 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28743/47780 [00:39<00:19, 989.56 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28844/47780 [00:39<00:19, 978.63 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28972/47780 [00:39<00:17, 1056.35 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29079/47780 [00:39<00:17, 1054.64 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29191/47780 [00:39<00:17, 1071.05 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29312/47780 [00:39<00:16, 1093.62 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29434/47780 [00:39<00:16, 1129.36 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29551/47780 [00:39<00:16, 1078.18 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29660/47780 [00:39<00:17, 1051.45 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29770/47780 [00:40<00:17, 1052.41 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29886/47780 [00:40<00:16, 1079.41 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30001/47780 [00:40<00:16, 1098.52 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30125/47780 [00:40<00:15, 1135.59 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30242/47780 [00:40<00:15, 1139.11 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30359/47780 [00:40<00:15, 1143.14 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30475/47780 [00:40<00:15, 1101.10 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30592/47780 [00:40<00:15, 1120.77 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30722/47780 [00:40<00:14, 1171.72 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30840/47780 [00:40<00:14, 1157.77 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30958/47780 [00:41<00:15, 1112.04 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31084/47780 [00:41<00:14, 1136.52 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31200/47780 [00:41<00:14, 1130.90 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31318/47780 [00:41<00:14, 1100.70 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31431/47780 [00:41<00:15, 1061.14 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31539/47780 [00:41<00:15, 1059.27 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31646/47780 [00:41<00:15, 1053.18 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31776/47780 [00:41<00:14, 1111.80 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31892/47780 [00:41<00:14, 1114.25 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32004/47780 [00:42<00:14, 1090.60 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32114/47780 [00:42<00:14, 1073.19 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32237/47780 [00:42<00:14, 1110.20 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32367/47780 [00:42<00:13, 1158.79 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32492/47780 [00:42<00:12, 1183.95 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32613/47780 [00:42<00:13, 1134.22 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32728/47780 [00:42<00:13, 1133.20 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32857/47780 [00:42<00:12, 1176.30 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32976/47780 [00:42<00:12, 1164.46 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33094/47780 [00:42<00:12, 1139.89 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33221/47780 [00:43<00:12, 1169.76 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33347/47780 [00:43<00:12, 1188.31 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33467/47780 [00:43<00:12, 1174.31 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33589/47780 [00:43<00:12, 1176.65 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33709/47780 [00:43<00:12, 1169.31 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33831/47780 [00:43<00:12, 1139.65 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33946/47780 [00:43<00:12, 1121.96 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34059/47780 [00:43<00:12, 1109.19 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34182/47780 [00:43<00:12, 1130.87 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34296/47780 [00:44<00:12, 1081.66 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34410/47780 [00:44<00:13, 1024.85 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34515/47780 [00:44<00:13, 1000.17 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34617/47780 [00:44<00:13, 979.26 examples/s] 
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34717/47780 [00:44<00:13, 974.41 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34835/47780 [00:44<00:12, 998.84 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34946/47780 [00:44<00:12, 989.25 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35047/47780 [00:44<00:13, 946.11 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35143/47780 [00:44<00:13, 925.22 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35236/47780 [00:45<00:13, 899.89 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35333/47780 [00:45<00:13, 909.23 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35438/47780 [00:45<00:13, 943.61 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35534/47780 [00:45<00:13, 893.85 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35626/47780 [00:45<00:13, 883.41 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35732/47780 [00:45<00:12, 929.98 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35826/47780 [00:45<00:13, 913.23 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35918/47780 [00:45<00:13, 868.56 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36008/47780 [00:45<00:14, 839.67 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36113/47780 [00:46<00:13, 887.77 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36216/47780 [00:46<00:12, 925.00 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36335/47780 [00:46<00:11, 992.75 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36436/47780 [00:46<00:12, 942.54 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36533/47780 [00:46<00:11, 938.30 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36633/47780 [00:46<00:11, 951.72 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36742/47780 [00:46<00:11, 987.49 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36847/47780 [00:46<00:11, 982.06 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36957/47780 [00:46<00:10, 1014.44 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37059/47780 [00:46<00:10, 983.37 examples/s] 
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37178/47780 [00:47<00:10, 1033.43 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37295/47780 [00:47<00:09, 1070.04 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37408/47780 [00:47<00:09, 1076.52 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37516/47780 [00:47<00:09, 1055.13 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37626/47780 [00:47<00:09, 1067.70 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37760/47780 [00:47<00:08, 1137.70 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37884/47780 [00:47<00:08, 1159.73 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38002/47780 [00:47<00:08, 1132.74 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38125/47780 [00:47<00:08, 1156.54 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38253/47780 [00:48<00:08, 1179.27 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38372/47780 [00:48<00:08, 1156.20 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38491/47780 [00:48<00:08, 1155.00 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38618/47780 [00:48<00:07, 1167.84 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38736/47780 [00:48<00:07, 1160.68 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38855/47780 [00:48<00:08, 1110.78 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38968/47780 [00:48<00:07, 1112.43 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39087/47780 [00:48<00:07, 1119.59 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39207/47780 [00:48<00:07, 1139.99 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39322/47780 [00:48<00:07, 1103.14 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39433/47780 [00:49<00:07, 1077.84 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39542/47780 [00:49<00:07, 1063.88 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39650/47780 [00:49<00:07, 1046.66 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39756/47780 [00:49<00:07, 1014.14 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39862/47780 [00:49<00:07, 1023.42 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39967/47780 [00:49<00:07, 981.85 examples/s] 
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40084/47780 [00:49<00:07, 1033.37 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40194/47780 [00:49<00:07, 1048.44 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40301/47780 [00:49<00:07, 1050.09 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40425/47780 [00:50<00:06, 1096.53 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40535/47780 [00:50<00:06, 1062.80 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40661/47780 [00:50<00:06, 1118.80 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40774/47780 [00:50<00:06, 1089.65 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40898/47780 [00:50<00:06, 1127.56 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41033/47780 [00:50<00:05, 1177.06 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41152/47780 [00:50<00:05, 1123.16 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41267/47780 [00:50<00:06, 1067.82 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41376/47780 [00:50<00:05, 1072.48 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41485/47780 [00:51<00:06, 1037.63 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41591/47780 [00:51<00:06, 1016.59 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41700/47780 [00:51<00:05, 1030.02 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41825/47780 [00:51<00:05, 1084.10 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41934/47780 [00:51<00:05, 1047.84 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42045/47780 [00:51<00:05, 1060.58 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42152/47780 [00:51<00:05, 1028.94 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42256/47780 [00:51<00:05, 1020.06 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42359/47780 [00:51<00:05, 995.38 examples/s] 
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42475/47780 [00:51<00:05, 1032.45 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42582/47780 [00:52<00:05, 971.85 examples/s] 
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42682/47780 [00:52<00:05, 965.33 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42786/47780 [00:52<00:05, 975.54 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42886/47780 [00:52<00:05, 974.10 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42985/47780 [00:52<00:05, 918.00 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43078/47780 [00:52<00:05, 851.28 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43172/47780 [00:52<00:05, 865.49 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43261/47780 [00:52<00:05, 858.64 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43349/47780 [00:52<00:05, 828.51 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43448/47780 [00:53<00:04, 871.63 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43554/47780 [00:53<00:04, 913.21 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43647/47780 [00:53<00:04, 862.57 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43735/47780 [00:53<00:04, 845.22 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43821/47780 [00:53<00:04, 824.35 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43904/47780 [00:53<00:04, 796.44 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43985/47780 [00:53<00:04, 794.83 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44067/47780 [00:53<00:04, 765.58 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44145/47780 [00:53<00:04, 758.92 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44227/47780 [00:54<00:04, 754.65 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44305/47780 [00:54<00:04, 751.40 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44382/47780 [00:54<00:04, 730.51 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44471/47780 [00:54<00:04, 741.30 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44546/47780 [00:54<00:04, 711.78 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44629/47780 [00:54<00:04, 735.21 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44703/47780 [00:54<00:04, 733.27 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44778/47780 [00:54<00:04, 669.13 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44847/47780 [00:54<00:04, 650.65 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44920/47780 [00:55<00:04, 664.17 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44999/47780 [00:55<00:04, 691.93 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45073/47780 [00:55<00:03, 697.24 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45144/47780 [00:55<00:03, 678.81 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45225/47780 [00:55<00:03, 698.74 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45303/47780 [00:55<00:03, 719.07 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45376/47780 [00:55<00:03, 686.14 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45446/47780 [00:55<00:03, 632.14 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45513/47780 [00:55<00:03, 635.55 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45579/47780 [00:56<00:03, 626.34 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45656/47780 [00:56<00:03, 661.15 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45723/47780 [00:56<00:03, 635.96 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45801/47780 [00:56<00:02, 674.16 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45870/47780 [00:56<00:02, 668.65 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45941/47780 [00:56<00:02, 668.59 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46012/47780 [00:56<00:02, 621.61 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46077/47780 [00:56<00:02, 576.86 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46143/47780 [00:56<00:02, 581.48 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46204/47780 [00:57<00:02, 575.27 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46263/47780 [00:57<00:02, 566.07 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46321/47780 [00:57<00:02, 542.50 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46377/47780 [00:57<00:02, 539.10 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46433/47780 [00:57<00:02, 526.84 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46487/47780 [00:57<00:02, 492.10 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46538/47780 [00:57<00:02, 464.71 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46586/47780 [00:57<00:02, 460.64 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46634/47780 [00:58<00:02, 454.38 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46680/47780 [00:58<00:02, 446.18 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46729/47780 [00:58<00:02, 453.82 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46775/47780 [00:58<00:02, 434.82 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46826/47780 [00:58<00:02, 447.31 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46871/47780 [00:58<00:02, 412.74 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46914/47780 [00:58<00:02, 396.35 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46956/47780 [00:58<00:02, 375.45 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46996/47780 [00:58<00:02, 369.01 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47034/47780 [00:59<00:02, 366.05 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47072/47780 [00:59<00:01, 356.55 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47108/47780 [00:59<00:01, 352.11 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47145/47780 [00:59<00:02, 289.00 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47178/47780 [00:59<00:02, 292.89 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47209/47780 [00:59<00:02, 282.53 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47240/47780 [00:59<00:02, 262.67 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47269/47780 [00:59<00:02, 241.42 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47295/47780 [01:00<00:02, 222.12 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47318/47780 [01:00<00:02, 223.12 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47342/47780 [01:00<00:01, 222.28 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47365/47780 [01:00<00:01, 222.61 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47388/47780 [01:00<00:01, 210.00 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47412/47780 [01:00<00:01, 193.31 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47433/47780 [01:00<00:02, 156.59 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47451/47780 [01:01<00:02, 116.56 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47466/47780 [01:01<00:02, 107.48 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47480/47780 [01:01<00:03, 99.26 examples/s] 
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47492/47780 [01:01<00:03, 92.54 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47506/47780 [01:01<00:02, 98.17 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47518/47780 [01:01<00:02, 96.05 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47530/47780 [01:02<00:02, 88.45 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47541/47780 [01:02<00:02, 88.31 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47553/47780 [01:02<00:02, 95.26 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47565/47780 [01:02<00:02, 96.52 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47575/47780 [01:02<00:02, 84.05 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47586/47780 [01:02<00:02, 82.20 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47595/47780 [01:02<00:02, 79.35 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47604/47780 [01:03<00:02, 66.82 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47613/47780 [01:03<00:02, 68.13 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47623/47780 [01:03<00:02, 71.78 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47631/47780 [01:03<00:02, 68.73 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47640/47780 [01:03<00:02, 68.26 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47649/47780 [01:03<00:01, 72.35 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47658/47780 [01:03<00:01, 71.60 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47667/47780 [01:03<00:01, 68.45 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47676/47780 [01:04<00:01, 65.89 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47684/47780 [01:04<00:02, 46.51 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47690/47780 [01:04<00:02, 40.63 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47695/47780 [01:04<00:02, 38.57 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47702/47780 [01:04<00:01, 40.56 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47708/47780 [01:05<00:01, 42.84 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47715/47780 [01:05<00:01, 45.90 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47720/47780 [01:05<00:01, 44.98 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47726/47780 [01:05<00:01, 44.82 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47734/47780 [01:05<00:00, 49.90 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47740/47780 [01:05<00:00, 50.09 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47746/47780 [01:05<00:00, 39.07 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47752/47780 [01:06<00:00, 35.71 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [01:06<00:00, 33.95 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47761/47780 [01:06<00:00, 35.08 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47766/47780 [01:06<00:00, 36.39 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47771/47780 [01:06<00:00, 38.07 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [01:06<00:00, 38.01 examples/s]
[36m(head, rank=0, pid=3447)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [01:07<00:00, 10.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [01:09<00:00, 690.40 examples/s]
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3447)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:09<07:02, 110.66 examples/s]
[36m(head, rank=0, pid=3447)[0m Truncating train dataset (num_proc=32):   9%|▉         | 4494/47780 [00:09<01:06, 651.59 examples/s]
[36m(head, rank=0, pid=3447)[0m Truncating train dataset (num_proc=32):  47%|████▋     | 22481/47780 [00:09<00:05, 4542.56 examples/s]
[36m(head, rank=0, pid=3447)[0m Truncating train dataset (num_proc=32):  88%|████████▊ | 41864/47780 [00:09<00:00, 10219.84 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:15<00:00, 2986.92 examples/s] 
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:55,935] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3447)[0m df: /root/.triton/autotune: No such file or directory
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:56,562] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:56,612] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:56,615] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:56,618] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:56,619] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:56,621] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:56,635] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:58,201] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:58,201] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:58,201] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:58,201] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:58,201] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:58,201] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:58,201] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3447)[0m [2025-08-02 19:24:58,201] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:18:35,  2.50 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:24:11,  2.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:26:43,  2.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:42:40,  2.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:50:08,  2.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 24/47780 [00:02<1:15:06, 10.60 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 24/47780 [00:02<1:15:40, 10.52 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 24/47780 [00:02<1:17:04, 10.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 5/47780 [00:02<7:36:45,  1.74 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 24/47780 [00:02<1:19:33, 10.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 25/47780 [00:03<1:16:53, 10.35 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 5/47780 [00:03<8:16:02,  1.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 42/47780 [00:03<43:51, 18.14 examples/s]  
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 58/47780 [00:03<30:10, 26.35 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 13/47780 [00:03<2:46:23,  4.78 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 52/47780 [00:03<35:17, 22.54 examples/s]  
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 43/47780 [00:03<45:16, 17.57 examples/s]  
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 52/47780 [00:03<37:32, 21.19 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 79/47780 [00:03<22:13, 35.77 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 95/47780 [00:03<19:04, 41.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 58/47780 [00:03<31:02, 25.63 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 30/47780 [00:03<1:14:09, 10.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 103/47780 [00:03<17:02, 46.63 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 104/47780 [00:03<17:41, 44.92 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 79/47780 [00:03<25:18, 31.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 153/47780 [00:04<11:07, 71.38 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 176/47780 [00:04<09:52, 80.38 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 166/47780 [00:04<10:41, 74.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 81/47780 [00:04<26:00, 30.56 examples/s]  
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 100/47780 [00:04<19:54, 39.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 181/47780 [00:04<10:09, 78.15 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 239/47780 [00:04<07:55, 100.00 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 236/47780 [00:04<07:59, 99.24 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 185/47780 [00:04<10:05, 78.64 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 222/47780 [00:04<08:34, 92.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 146/47780 [00:04<14:16, 55.63 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 196/47780 [00:04<09:19, 84.99 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|          | 261/47780 [00:04<07:29, 105.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|          | 335/47780 [00:05<06:21, 124.47 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 273/47780 [00:05<07:53, 100.43 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 331/47780 [00:05<06:42, 117.96 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 245/47780 [00:05<09:02, 87.58 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 325/47780 [00:05<06:35, 119.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 219/47780 [00:05<10:27, 75.84 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|          | 326/47780 [00:05<07:27, 106.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|          | 361/47780 [00:05<05:43, 138.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|          | 446/47780 [00:05<05:10, 152.49 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 393/47780 [00:05<05:59, 131.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|          | 459/47780 [00:05<05:00, 157.22 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 457/47780 [00:05<05:22, 146.74 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|          | 338/47780 [00:05<07:08, 110.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|          | 438/47780 [00:05<05:32, 142.21 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|          | 432/47780 [00:06<06:14, 126.32 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 587/47780 [00:06<03:28, 226.39 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 591/47780 [00:06<04:19, 181.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|          | 515/47780 [00:06<04:54, 160.59 examples/s]
Tokenizing train dataset (num_proc=32):   1%|▏         | 652/47780 [00:06<03:52, 202.65 examples/s]
Tokenizing train dataset (num_proc=32):   1%|▏         | 619/47780 [00:06<04:13, 186.08 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|          | 458/47780 [00:06<05:52, 134.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|          | 582/47780 [00:06<04:17, 183.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 644/47780 [00:06<04:20, 180.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 806/47780 [00:06<03:16, 239.44 examples/s]
Tokenizing train dataset (num_proc=32):   1%|▏         | 631/47780 [00:06<04:38, 169.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 819/47780 [00:06<03:17, 237.48 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 726/47780 [00:07<03:39, 214.09 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 831/47780 [00:07<03:25, 228.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 619/47780 [00:06<04:36, 170.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 792/47780 [00:07<03:55, 199.17 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 983/47780 [00:07<03:06, 251.55 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 809/47780 [00:07<03:49, 204.61 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 958/47780 [00:07<03:22, 230.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 797/47780 [00:07<03:31, 222.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1155/47780 [00:07<02:12, 352.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1037/47780 [00:07<03:01, 257.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 857/47780 [00:07<04:02, 193.34 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 949/47780 [00:07<03:29, 223.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1063/47780 [00:07<02:26, 318.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1136/47780 [00:08<02:58, 260.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 958/47780 [00:08<03:42, 210.83 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 925/47780 [00:08<03:41, 211.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1113/47780 [00:08<02:25, 320.33 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1207/47780 [00:08<03:02, 255.83 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1229/47780 [00:08<03:20, 232.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1141/47780 [00:08<03:03, 254.63 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1085/47780 [00:08<03:37, 214.74 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1301/47780 [00:08<03:00, 257.08 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1132/47780 [00:08<03:21, 231.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1186/47780 [00:08<03:06, 249.68 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1288/47780 [00:08<02:30, 309.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1410/47780 [00:09<02:52, 269.29 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1435/47780 [00:09<03:06, 248.63 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1280/47780 [00:09<03:11, 242.94 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1659/47780 [00:09<02:02, 377.23 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1491/47780 [00:09<02:00, 382.66 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1265/47780 [00:09<03:21, 231.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1505/47780 [00:09<02:50, 271.53 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1307/47780 [00:09<03:16, 236.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1700/47780 [00:09<02:02, 377.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1521/47780 [00:09<02:11, 352.76 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1356/47780 [00:09<03:38, 212.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1599/47780 [00:09<02:50, 270.76 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1534/47780 [00:09<02:16, 340.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1755/47780 [00:09<02:37, 291.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1440/47780 [00:09<03:14, 238.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1534/47780 [00:10<02:45, 279.26 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▎         | 1771/47780 [00:10<02:54, 263.12 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1587/47780 [00:10<03:17, 233.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1599/47780 [00:10<02:56, 262.01 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1972/47780 [00:10<01:58, 387.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1872/47780 [00:10<01:51, 412.42 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2067/47780 [00:10<01:53, 403.80 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1621/47780 [00:10<03:13, 238.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1626/47780 [00:10<04:05, 188.08 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1826/47780 [00:10<03:33, 215.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1782/47780 [00:10<02:11, 349.94 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2189/47780 [00:10<01:42, 446.92 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1578/47780 [00:10<04:07, 186.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1659/47780 [00:10<03:43, 206.54 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1873/47780 [00:10<02:12, 346.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1931/47780 [00:11<01:50, 415.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1707/47780 [00:11<04:35, 167.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1821/47780 [00:11<03:28, 220.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2003/47780 [00:11<02:55, 261.50 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2162/47780 [00:11<02:12, 345.31 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1947/47780 [00:11<02:43, 280.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2332/47780 [00:11<02:25, 313.36 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2147/47780 [00:11<03:34, 212.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2214/47780 [00:11<01:44, 437.17 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2472/47780 [00:11<01:48, 417.27 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2276/47780 [00:11<02:01, 373.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1947/47780 [00:11<03:40, 207.87 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2394/47780 [00:11<01:40, 451.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2186/47780 [00:11<01:59, 380.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2048/47780 [00:11<02:45, 277.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2324/47780 [00:12<01:41, 446.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1862/47780 [00:12<05:08, 149.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2052/47780 [00:12<02:55, 259.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2322/47780 [00:12<02:41, 282.00 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2581/47780 [00:12<01:44, 432.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2597/47780 [00:12<02:50, 265.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2297/47780 [00:13<03:34, 211.64 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2463/47780 [00:13<02:46, 272.83 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2497/47780 [00:13<03:42, 203.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2583/47780 [00:13<02:00, 374.89 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2507/47780 [00:13<03:50, 196.84 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2600/47780 [00:13<02:14, 336.92 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2914/47780 [00:13<01:38, 454.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2913/47780 [00:13<02:01, 369.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2130/47780 [00:13<05:09, 147.62 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2732/47780 [00:13<03:29, 215.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2478/47780 [00:13<02:17, 329.65 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▋         | 3054/47780 [00:13<01:58, 378.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2707/47780 [00:13<02:41, 278.51 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2710/47780 [00:13<02:56, 255.88 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▋         | 3083/47780 [00:13<01:57, 380.58 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2788/47780 [00:14<02:25, 310.28 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3209/47780 [00:14<01:54, 388.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 3080/47780 [00:14<02:30, 297.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3234/47780 [00:14<02:02, 362.72 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2712/47780 [00:14<03:23, 221.59 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2803/47780 [00:14<03:23, 221.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2619/47780 [00:14<02:53, 260.25 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2952/47780 [00:14<02:11, 339.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3230/47780 [00:14<01:37, 458.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2863/47780 [00:14<03:41, 202.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3185/47780 [00:15<03:14, 228.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3603/47780 [00:15<01:42, 429.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3403/47780 [00:15<02:01, 366.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3310/47780 [00:15<03:40, 201.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3772/47780 [00:15<01:41, 434.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 2989/47780 [00:15<02:45, 271.43 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3363/47780 [00:16<03:34, 207.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3210/47780 [00:16<02:02, 365.04 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▋         | 3087/47780 [00:16<03:31, 211.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3876/47780 [00:16<01:40, 438.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3421/47780 [00:16<02:01, 365.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2919/47780 [00:16<06:31, 114.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3286/47780 [00:16<02:34, 287.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3433/47780 [00:16<02:01, 363.81 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3532/47780 [00:16<03:03, 241.21 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3659/47780 [00:16<02:30, 293.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3334/47780 [00:16<02:35, 285.20 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3973/47780 [00:16<01:30, 483.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3614/47780 [00:17<01:42, 432.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3891/47780 [00:17<01:11, 610.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4095/47780 [00:17<02:09, 338.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4471/47780 [00:17<01:24, 514.28 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3579/47780 [00:17<03:03, 241.43 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3962/47780 [00:17<02:55, 250.07 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3874/47780 [00:17<01:57, 373.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4275/47780 [00:17<01:55, 376.98 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3568/47780 [00:17<03:22, 218.48 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3793/47780 [00:18<02:12, 331.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4127/47780 [00:18<02:24, 301.88 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3796/47780 [00:18<04:09, 176.25 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 4041/47780 [00:18<02:57, 246.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4685/47780 [00:18<02:13, 321.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 5003/47780 [00:18<01:33, 458.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4460/47780 [00:19<02:41, 268.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 4035/47780 [00:19<02:30, 289.87 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4466/47780 [00:19<01:22, 526.78 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4072/47780 [00:19<03:01, 240.34 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4539/47780 [00:19<01:38, 437.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 4040/47780 [00:19<03:14, 225.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4235/47780 [00:19<02:24, 300.81 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4510/47780 [00:19<01:37, 444.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4319/47780 [00:19<03:22, 215.03 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4617/47780 [00:19<02:07, 339.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 2/47780 [00:19<131:45:12,  9.93s/ examples]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 26/47780 [00:19<7:19:07,  1.81 examples/s] 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4211/47780 [00:20<03:44, 194.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4662/47780 [00:20<01:54, 375.23 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5065/47780 [00:20<01:11, 599.47 examples/s]
Tokenizing train dataset (num_proc=32):  10%|█         | 4811/47780 [00:20<02:54, 246.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4690/47780 [00:20<02:17, 312.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5085/47780 [00:20<02:05, 341.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5238/47780 [00:20<01:47, 396.96 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5202/47780 [00:21<02:56, 241.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4770/47780 [00:21<02:34, 278.90 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█▏        | 5391/47780 [00:21<02:19, 304.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4979/47780 [00:21<02:01, 353.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5518/47780 [00:21<01:06, 635.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4876/47780 [00:21<02:54, 246.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5255/47780 [00:21<01:46, 397.74 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5452/47780 [00:21<01:26, 488.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5286/47780 [00:21<02:01, 349.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5539/47780 [00:21<01:31, 462.99 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4820/47780 [00:22<03:26, 208.06 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4333/47780 [00:22<05:24, 133.69 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█▏        | 5381/47780 [00:22<02:41, 262.38 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 47/47780 [00:22<4:07:52,  3.21 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5259/47780 [00:22<01:47, 396.79 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4420/47780 [00:22<04:39, 154.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5485/47780 [00:22<02:22, 297.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5547/47780 [00:22<03:00, 234.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5770/47780 [00:22<02:09, 323.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5803/47780 [00:22<01:47, 391.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6206/47780 [00:22<01:12, 570.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5642/47780 [00:23<03:01, 232.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5726/47780 [00:23<02:28, 282.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6031/47780 [00:23<01:36, 431.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6142/47780 [00:23<01:29, 465.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 58/47780 [00:23<3:25:54,  3.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 131/47780 [00:23<56:08, 14.14 examples/s] 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5639/47780 [00:23<03:11, 220.29 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6010/47780 [00:23<01:57, 355.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5451/47780 [00:23<02:58, 236.79 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6214/47780 [00:24<01:33, 442.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5713/47780 [00:24<02:06, 331.74 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6467/47780 [00:24<01:46, 386.21 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5922/47780 [00:24<01:38, 426.25 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4748/47780 [00:24<04:35, 156.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5054/47780 [00:24<02:53, 246.49 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5306/47780 [00:24<02:04, 342.43 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6265/47780 [00:24<02:07, 326.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 156/47780 [00:24<48:39, 16.31 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5618/47780 [00:24<01:24, 496.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6550/47780 [00:24<01:28, 466.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6355/47780 [00:24<02:05, 329.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6545/47780 [00:24<01:41, 407.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 178/47780 [00:25<43:16, 18.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6415/47780 [00:25<02:17, 300.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   0%|          | 223/47780 [00:25<25:46, 30.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6642/47780 [00:25<01:42, 401.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6945/47780 [00:25<01:28, 463.98 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7267/47780 [00:25<01:03, 637.88 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6655/47780 [00:25<02:27, 278.84 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6101/47780 [00:25<02:35, 268.79 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5916/47780 [00:25<05:08, 135.59 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6882/47780 [00:25<01:53, 359.88 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6316/47780 [00:25<01:54, 362.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6019/47780 [00:25<04:18, 161.38 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 246/47780 [00:26<28:53, 27.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5817/47780 [00:26<02:45, 253.07 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6709/47780 [00:26<03:00, 227.07 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 338/47780 [00:26<12:49, 61.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6176/47780 [00:26<01:45, 395.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6987/47780 [00:26<02:02, 334.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7451/47780 [00:27<01:54, 353.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6471/47780 [00:27<02:55, 234.93 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7116/47780 [00:27<02:35, 262.34 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6777/47780 [00:27<01:51, 369.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6813/47780 [00:27<03:01, 225.25 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7450/47780 [00:27<01:42, 391.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7135/47780 [00:27<01:54, 353.46 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 378/47780 [00:27<14:05, 56.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7584/47780 [00:27<02:05, 321.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7979/47780 [00:27<01:15, 528.67 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6125/47780 [00:27<06:05, 113.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6226/47780 [00:27<04:51, 142.34 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7152/47780 [00:28<02:54, 233.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8168/47780 [00:28<01:24, 466.98 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7633/47780 [00:28<02:08, 312.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7921/47780 [00:28<01:30, 442.77 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8310/47780 [00:28<01:29, 438.71 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7270/47780 [00:28<02:59, 226.29 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6939/47780 [00:28<02:50, 239.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|          | 415/47780 [00:28<17:33, 44.97 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7633/47780 [00:28<01:42, 393.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7235/47780 [00:28<01:50, 365.33 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 437/47780 [00:29<15:10, 52.02 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7807/47780 [00:29<01:22, 481.98 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6308/47780 [00:29<05:49, 118.64 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6385/47780 [00:29<03:11, 216.67 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8420/47780 [00:29<01:35, 412.70 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8100/47780 [00:29<01:37, 406.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6608/47780 [00:29<02:54, 236.44 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6823/47780 [00:29<01:59, 341.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7315/47780 [00:29<03:05, 217.80 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7105/47780 [00:29<01:18, 520.89 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8507/47780 [00:29<01:38, 398.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7767/47780 [00:29<01:43, 386.68 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7976/47780 [00:29<01:26, 462.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7448/47780 [00:29<00:50, 791.86 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7770/47780 [00:29<00:37, 1078.77 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8578/47780 [00:29<01:41, 387.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8235/47780 [00:29<01:44, 378.68 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8638/47780 [00:29<01:44, 373.05 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8028/47780 [00:29<00:38, 1038.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8107/47780 [00:29<01:32, 430.44 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8382/47780 [00:29<00:28, 1393.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8690/47780 [00:29<01:49, 357.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8338/47780 [00:29<01:51, 352.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8726/47780 [00:30<00:23, 1691.71 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8735/47780 [00:30<01:52, 348.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7986/47780 [00:30<01:47, 369.94 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8423/47780 [00:30<01:49, 358.69 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8209/47780 [00:30<01:41, 390.14 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8776/47780 [00:30<01:55, 336.97 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   1%|          | 457/47780 [00:30<21:14, 37.14 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 717/47780 [00:30<04:55, 159.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8815/47780 [00:30<01:56, 334.52 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6639/47780 [00:30<03:16, 209.45 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8491/47780 [00:30<01:52, 349.48 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8289/47780 [00:30<01:44, 379.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8851/47780 [00:30<01:56, 333.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6749/47780 [00:30<02:53, 236.14 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8548/47780 [00:30<01:52, 349.17 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8887/47780 [00:30<02:01, 320.46 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7403/47780 [00:30<02:57, 227.58 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8149/47780 [00:30<01:53, 349.98 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8926/47780 [00:30<01:55, 335.96 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8355/47780 [00:30<01:54, 343.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8601/47780 [00:30<01:50, 354.15 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8961/47780 [00:30<01:57, 330.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8648/47780 [00:30<01:47, 362.49 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8996/47780 [00:30<01:57, 331.35 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8409/47780 [00:30<02:00, 325.84 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8992/47780 [00:30<00:51, 755.90 examples/s] 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8693/47780 [00:30<01:50, 353.42 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9030/47780 [00:30<01:56, 333.46 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8272/47780 [00:30<01:53, 349.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8455/47780 [00:31<02:02, 321.42 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9067/47780 [00:31<01:55, 336.34 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8734/47780 [00:31<02:00, 323.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 807/47780 [00:31<05:34, 140.38 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9101/47780 [00:31<02:00, 320.04 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8496/47780 [00:31<02:08, 306.08 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8773/47780 [00:31<01:57, 330.83 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9161/47780 [00:31<01:37, 396.28 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8369/47780 [00:31<01:56, 339.50 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8815/47780 [00:31<01:51, 349.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8532/47780 [00:31<02:14, 292.31 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9202/47780 [00:31<01:39, 386.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8853/47780 [00:31<01:50, 353.56 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8566/47780 [00:31<02:13, 294.50 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9187/47780 [00:31<01:04, 596.32 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8898/47780 [00:31<01:44, 373.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9242/47780 [00:31<01:54, 337.25 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8601/47780 [00:31<02:08, 305.26 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8446/47780 [00:31<02:02, 320.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8949/47780 [00:31<01:35, 404.77 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9280/47780 [00:31<01:52, 342.02 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8634/47780 [00:31<02:19, 281.12 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6850/47780 [00:31<03:46, 180.58 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 8997/47780 [00:31<01:32, 420.48 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8507/47780 [00:31<01:57, 335.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9320/47780 [00:31<01:47, 357.27 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8670/47780 [00:31<02:11, 298.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7112/47780 [00:31<02:24, 281.60 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9041/47780 [00:31<01:40, 383.60 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9358/47780 [00:31<01:54, 334.20 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7319/47780 [00:31<01:46, 381.50 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8703/47780 [00:31<02:08, 303.21 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8564/47780 [00:31<01:58, 330.43 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7524/47780 [00:31<03:53, 172.66 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9334/47780 [00:31<01:17, 494.91 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9398/47780 [00:31<01:49, 351.34 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9081/47780 [00:32<01:47, 361.15 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7645/47780 [00:32<01:07, 594.21 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8744/47780 [00:32<02:00, 323.87 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7673/47780 [00:31<03:00, 222.30 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9441/47780 [00:32<01:43, 369.24 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9122/47780 [00:32<01:44, 370.35 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7852/47780 [00:32<00:54, 732.97 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8613/47780 [00:32<02:01, 322.98 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8780/47780 [00:32<01:57, 333.33 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 874/47780 [00:32<07:00, 111.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7856/47780 [00:32<02:11, 304.06 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9479/47780 [00:32<01:44, 367.59 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8128/47780 [00:32<00:40, 975.12 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9160/47780 [00:32<01:49, 353.34 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8815/47780 [00:32<02:05, 310.35 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8656/47780 [00:32<02:04, 315.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1020/47780 [00:32<04:19, 180.45 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8165/47780 [00:32<01:20, 492.13 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9521/47780 [00:32<01:40, 380.33 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8477/47780 [00:32<00:29, 1341.57 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9196/47780 [00:32<01:53, 341.24 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8850/47780 [00:32<02:05, 311.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9446/47780 [00:32<01:27, 438.22 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8695/47780 [00:32<02:03, 315.82 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8755/47780 [00:32<00:24, 1589.68 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9568/47780 [00:32<01:37, 390.79 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9236/47780 [00:32<01:48, 354.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8882/47780 [00:32<02:04, 311.83 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8735/47780 [00:32<01:58, 329.80 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9024/47780 [00:32<00:21, 1804.02 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9615/47780 [00:32<01:33, 408.60 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9272/47780 [00:32<01:50, 347.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8914/47780 [00:32<02:08, 302.58 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8773/47780 [00:32<02:00, 323.90 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9294/47780 [00:32<00:19, 2000.54 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9657/47780 [00:32<01:39, 384.19 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9536/47780 [00:32<01:33, 409.17 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9308/47780 [00:32<01:56, 328.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8340/47780 [00:32<01:22, 478.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8950/47780 [00:32<02:04, 311.55 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8809/47780 [00:32<02:04, 312.98 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9700/47780 [00:32<01:36, 393.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9343/47780 [00:32<01:58, 323.82 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8982/47780 [00:32<02:05, 310.09 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8843/47780 [00:32<02:04, 313.37 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9740/47780 [00:32<01:37, 391.31 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9606/47780 [00:32<01:38, 388.92 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9015/47780 [00:32<02:08, 302.38 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9376/47780 [00:32<02:05, 305.48 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9780/47780 [00:32<01:39, 380.25 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8876/47780 [00:32<02:12, 294.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1095/47780 [00:33<05:05, 153.03 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9408/47780 [00:33<02:05, 306.49 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9053/47780 [00:33<02:00, 320.45 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9664/47780 [00:33<01:40, 379.97 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9562/47780 [00:33<00:32, 1164.01 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9819/47780 [00:33<01:44, 364.95 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8907/47780 [00:33<02:11, 295.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8476/47780 [00:33<01:30, 434.89 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9086/47780 [00:33<01:59, 323.12 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9440/47780 [00:33<02:05, 306.59 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8941/47780 [00:33<02:06, 306.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9856/47780 [00:33<01:44, 363.72 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9121/47780 [00:33<01:56, 330.60 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9472/47780 [00:33<02:03, 310.31 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9715/47780 [00:33<01:47, 353.32 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9895/47780 [00:33<01:43, 367.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 8973/47780 [00:33<02:06, 307.06 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9155/47780 [00:33<01:55, 333.10 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9504/47780 [00:33<02:07, 299.53 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8583/47780 [00:33<01:32, 425.82 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9759/47780 [00:33<01:46, 358.51 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9011/47780 [00:33<01:58, 327.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9933/47780 [00:33<01:46, 354.37 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9190/47780 [00:33<01:54, 338.04 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9542/47780 [00:33<02:01, 315.01 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9049/47780 [00:33<01:56, 331.04 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9970/47780 [00:33<01:46, 355.35 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9801/47780 [00:33<01:48, 349.36 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9226/47780 [00:33<01:53, 341.08 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9580/47780 [00:33<01:55, 331.56 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8673/47780 [00:33<01:34, 414.97 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9084/47780 [00:33<01:55, 334.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10006/47780 [00:33<01:45, 356.59 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9262/47780 [00:33<01:57, 326.94 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9614/47780 [00:33<01:54, 331.96 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9840/47780 [00:33<01:54, 330.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10044/47780 [00:33<01:43, 363.25 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9118/47780 [00:33<02:01, 319.49 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9300/47780 [00:33<01:52, 342.01 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9876/47780 [00:33<01:53, 333.27 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9648/47780 [00:33<02:02, 311.85 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9768/47780 [00:33<00:56, 672.75 examples/s] 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8744/47780 [00:33<01:36, 402.96 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9157/47780 [00:33<01:54, 337.68 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10081/47780 [00:33<01:49, 345.33 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1161/47780 [00:33<06:11, 125.65 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9340/47780 [00:33<01:50, 346.91 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9681/47780 [00:33<02:01, 314.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9912/47780 [00:33<01:55, 327.64 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9199/47780 [00:33<01:48, 354.90 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10118/47780 [00:33<01:48, 348.23 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8806/47780 [00:33<01:35, 407.37 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1296/47780 [00:34<03:56, 196.38 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9380/47780 [00:33<01:48, 354.26 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9947/47780 [00:33<01:56, 324.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9725/47780 [00:34<01:54, 331.05 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9236/47780 [00:34<01:53, 339.87 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10153/47780 [00:34<01:52, 333.51 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9416/47780 [00:34<01:50, 348.02 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8861/47780 [00:34<01:37, 400.65 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9988/47780 [00:34<01:51, 338.47 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9759/47780 [00:34<02:03, 308.82 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9271/47780 [00:34<01:53, 338.91 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10188/47780 [00:34<01:52, 334.13 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9451/47780 [00:34<01:50, 348.39 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10023/47780 [00:34<01:50, 341.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9792/47780 [00:34<02:01, 313.35 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8911/47780 [00:34<01:39, 390.77 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9922/47780 [00:34<01:08, 554.54 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9310/47780 [00:34<01:48, 353.30 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10222/47780 [00:34<01:53, 332.32 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9486/47780 [00:34<01:50, 345.08 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10064/47780 [00:34<01:45, 355.90 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9825/47780 [00:34<02:04, 306.04 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9347/47780 [00:34<01:48, 353.83 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10257/47780 [00:34<01:52, 334.55 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8958/47780 [00:34<01:40, 385.91 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9521/47780 [00:34<01:52, 340.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10101/47780 [00:34<01:44, 359.29 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9856/47780 [00:34<02:03, 307.06 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9557/47780 [00:34<01:50, 344.52 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10293/47780 [00:34<01:55, 325.47 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9383/47780 [00:34<01:57, 325.72 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10154/47780 [00:34<01:33, 403.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9001/47780 [00:34<01:49, 353.09 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9887/47780 [00:34<02:15, 279.09 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9592/47780 [00:34<01:51, 341.81 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10326/47780 [00:34<01:58, 316.47 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10197/47780 [00:34<01:32, 406.05 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9417/47780 [00:34<02:02, 312.38 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10039/47780 [00:34<01:17, 486.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9040/47780 [00:34<01:49, 354.57 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9927/47780 [00:34<02:02, 309.11 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9634/47780 [00:34<01:44, 364.18 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10360/47780 [00:34<01:57, 319.45 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9450/47780 [00:34<02:00, 316.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10240/47780 [00:34<01:32, 405.02 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9078/47780 [00:34<01:56, 333.49 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9959/47780 [00:34<02:03, 305.37 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9676/47780 [00:34<01:41, 376.60 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10393/47780 [00:34<02:04, 299.80 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10281/47780 [00:34<01:36, 387.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9483/47780 [00:34<02:07, 300.74 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9113/47780 [00:34<01:55, 334.71 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9714/47780 [00:34<01:46, 357.39 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9990/47780 [00:34<02:11, 287.41 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10427/47780 [00:34<02:01, 306.27 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9514/47780 [00:34<02:08, 296.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10321/47780 [00:34<01:40, 374.32 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9153/47780 [00:34<01:51, 347.20 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10131/47780 [00:34<01:29, 419.73 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10023/47780 [00:35<02:07, 295.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10462/47780 [00:35<01:58, 314.98 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10359/47780 [00:35<01:41, 367.68 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9750/47780 [00:35<02:02, 311.42 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9544/47780 [00:35<02:12, 287.84 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9189/47780 [00:35<01:52, 343.19 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10063/47780 [00:35<01:56, 324.69 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10497/47780 [00:35<01:56, 321.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10203/47780 [00:35<01:28, 422.31 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9589/47780 [00:35<01:55, 329.35 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10398/47780 [00:35<01:42, 365.63 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9797/47780 [00:35<01:51, 341.24 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9227/47780 [00:35<01:54, 335.42 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10114/47780 [00:35<01:42, 368.74 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10530/47780 [00:35<01:59, 312.99 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9623/47780 [00:35<01:56, 328.19 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10439/47780 [00:35<01:39, 373.87 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9834/47780 [00:35<01:49, 346.23 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9261/47780 [00:35<01:58, 326.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10163/47780 [00:35<01:38, 380.84 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10565/47780 [00:35<01:55, 323.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9662/47780 [00:35<01:51, 342.45 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10266/47780 [00:35<01:37, 386.28 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10481/47780 [00:35<01:37, 382.73 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1364/47780 [00:35<06:42, 115.33 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9870/47780 [00:35<01:53, 332.90 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9302/47780 [00:35<01:50, 348.72 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10209/47780 [00:35<01:34, 399.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10602/47780 [00:35<01:52, 329.40 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9703/47780 [00:35<01:46, 357.71 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10521/47780 [00:35<01:36, 386.87 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10319/47780 [00:35<01:33, 398.72 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1551/47780 [00:35<03:45, 205.01 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9905/47780 [00:35<01:54, 331.31 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9340/47780 [00:35<01:48, 353.41 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10250/47780 [00:35<01:33, 401.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10636/47780 [00:35<01:54, 324.99 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10560/47780 [00:35<01:36, 384.73 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9746/47780 [00:35<01:41, 374.08 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9939/47780 [00:35<01:56, 324.49 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10370/47780 [00:35<01:35, 392.34 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9376/47780 [00:35<01:50, 347.41 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10669/47780 [00:35<01:53, 325.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10291/47780 [00:35<01:38, 382.16 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9792/47780 [00:35<01:37, 389.84 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10599/47780 [00:35<01:41, 364.55 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9973/47780 [00:35<01:56, 324.65 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9412/47780 [00:35<01:49, 350.73 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10417/47780 [00:35<01:32, 402.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10711/47780 [00:35<01:45, 351.60 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9837/47780 [00:35<01:35, 398.08 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10330/47780 [00:35<01:43, 360.79 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10636/47780 [00:35<01:44, 353.99 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10008/47780 [00:35<01:53, 331.70 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9448/47780 [00:35<01:53, 337.63 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10747/47780 [00:35<01:44, 353.35 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10464/47780 [00:35<01:36, 388.55 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9877/47780 [00:35<01:40, 376.69 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10367/47780 [00:35<01:48, 343.79 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10048/47780 [00:35<01:53, 332.76 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10672/47780 [00:35<01:56, 319.81 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9482/47780 [00:35<01:56, 327.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10783/47780 [00:35<01:45, 350.08 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10507/47780 [00:36<01:40, 371.25 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10410/47780 [00:36<01:42, 363.82 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9915/47780 [00:36<01:46, 354.23 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10087/47780 [00:36<01:48, 347.92 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10707/47780 [00:36<01:54, 324.48 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9525/47780 [00:35<01:47, 355.97 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10819/47780 [00:36<01:50, 332.99 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10547/47780 [00:36<01:42, 363.48 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10447/47780 [00:36<01:46, 349.99 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10742/47780 [00:36<01:51, 331.42 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10122/47780 [00:36<01:55, 326.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9951/47780 [00:36<01:55, 327.28 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9561/47780 [00:36<01:57, 324.20 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10853/47780 [00:36<01:53, 324.48 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10483/47780 [00:36<01:46, 348.89 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10585/47780 [00:36<01:47, 344.82 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1640/47780 [00:36<04:25, 173.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10163/47780 [00:36<01:49, 342.41 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9599/47780 [00:36<01:52, 339.19 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9985/47780 [00:36<02:01, 309.98 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10776/47780 [00:36<02:04, 297.11 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10886/47780 [00:36<01:58, 311.93 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10524/47780 [00:36<01:45, 354.04 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10623/47780 [00:36<01:49, 340.21 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10198/47780 [00:36<01:55, 325.94 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10823/47780 [00:36<01:48, 340.18 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10018/47780 [00:36<02:03, 306.39 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9634/47780 [00:36<01:55, 330.47 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10918/47780 [00:36<02:05, 294.53 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10562/47780 [00:36<01:44, 357.31 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10661/47780 [00:36<01:48, 343.59 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10859/47780 [00:36<01:50, 335.37 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10049/47780 [00:36<02:05, 301.21 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9679/47780 [00:36<01:48, 352.51 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10231/47780 [00:36<02:08, 292.31 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10951/47780 [00:36<02:02, 300.90 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10599/47780 [00:36<01:44, 356.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10697/47780 [00:36<01:51, 334.04 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10897/47780 [00:36<01:46, 346.99 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10083/47780 [00:36<02:02, 308.41 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9717/47780 [00:36<01:46, 356.40 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10274/47780 [00:36<01:54, 327.72 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10993/47780 [00:36<01:50, 333.74 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10635/47780 [00:36<01:48, 341.67 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10733/47780 [00:36<01:49, 337.39 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10934/47780 [00:36<01:47, 344.34 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9763/47780 [00:36<01:39, 381.30 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10117/47780 [00:36<02:04, 303.63 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10316/47780 [00:36<01:47, 349.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11028/47780 [00:36<01:50, 332.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10670/47780 [00:36<01:57, 316.95 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10768/47780 [00:36<01:52, 329.22 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10969/47780 [00:36<01:47, 341.77 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9802/47780 [00:36<01:39, 380.87 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10152/47780 [00:36<02:00, 312.91 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10356/47780 [00:36<01:45, 355.33 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11062/47780 [00:36<01:53, 322.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1706/47780 [00:36<05:03, 151.79 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10704/47780 [00:36<01:58, 311.90 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11004/47780 [00:36<01:47, 343.70 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9857/47780 [00:36<01:28, 427.90 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10189/47780 [00:36<01:54, 328.86 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10802/47780 [00:36<02:01, 303.62 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10396/47780 [00:36<01:42, 363.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11096/47780 [00:36<01:53, 321.91 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10742/47780 [00:37<01:53, 327.28 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9901/47780 [00:36<01:28, 426.54 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11045/47780 [00:37<01:43, 355.35 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10226/47780 [00:37<01:51, 336.74 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11129/47780 [00:37<01:53, 323.08 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10433/47780 [00:37<01:51, 336.30 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10776/47780 [00:37<01:57, 314.66 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10833/47780 [00:37<02:33, 239.97 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10265/47780 [00:37<01:47, 348.21 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11081/47780 [00:37<01:47, 340.65 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9944/47780 [00:37<01:35, 394.67 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10468/47780 [00:37<01:57, 317.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11162/47780 [00:37<02:02, 300.11 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10812/47780 [00:37<01:54, 322.17 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10913/47780 [00:37<01:41, 363.71 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11117/47780 [00:37<01:47, 342.40 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10300/47780 [00:37<01:51, 336.56 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9985/47780 [00:37<01:40, 374.58 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11198/47780 [00:37<01:56, 312.91 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10846/47780 [00:37<01:54, 323.57 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10957/47780 [00:37<01:41, 364.17 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11152/47780 [00:37<01:51, 329.18 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10501/47780 [00:37<02:16, 272.35 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10334/47780 [00:37<01:58, 316.32 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10023/47780 [00:37<01:56, 323.60 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11230/47780 [00:37<02:12, 275.20 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10880/47780 [00:37<01:58, 310.76 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10538/47780 [00:37<02:05, 296.00 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11204/47780 [00:37<01:36, 379.06 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10999/47780 [00:37<01:40, 367.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10372/47780 [00:37<01:53, 330.01 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10064/47780 [00:37<01:50, 341.69 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11279/47780 [00:37<01:50, 330.68 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11243/47780 [00:37<01:37, 373.68 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10570/47780 [00:37<02:07, 292.85 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10912/47780 [00:37<02:05, 293.63 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11039/47780 [00:37<01:40, 364.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10407/47780 [00:37<01:56, 321.52 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11315/47780 [00:37<01:50, 331.18 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10100/47780 [00:37<01:57, 319.97 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10601/47780 [00:37<02:07, 291.32 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10950/47780 [00:37<01:56, 316.79 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10444/47780 [00:37<01:51, 334.94 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11281/47780 [00:37<01:43, 351.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11078/47780 [00:37<01:48, 339.40 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11354/47780 [00:37<01:44, 347.16 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10133/47780 [00:37<01:56, 322.26 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10486/47780 [00:37<01:43, 359.02 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10983/47780 [00:37<01:58, 310.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10631/47780 [00:37<02:17, 270.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11317/47780 [00:37<01:51, 328.45 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11120/47780 [00:37<01:46, 345.77 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10173/47780 [00:37<01:51, 336.88 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11390/47780 [00:37<01:51, 325.44 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11023/47780 [00:37<01:50, 331.51 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10659/47780 [00:37<02:16, 272.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10523/47780 [00:37<01:51, 335.10 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11355/47780 [00:37<01:48, 335.11 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11156/47780 [00:37<01:51, 329.09 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10208/47780 [00:37<01:53, 332.22 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11062/47780 [00:38<01:45, 347.99 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11424/47780 [00:37<01:54, 318.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10687/47780 [00:38<02:17, 269.20 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10558/47780 [00:38<01:52, 331.98 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11397/47780 [00:38<01:41, 358.08 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1841/47780 [00:38<05:39, 135.32 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11190/47780 [00:38<02:00, 303.27 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10243/47780 [00:38<01:56, 322.36 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11098/47780 [00:38<01:50, 332.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10716/47780 [00:38<02:14, 274.67 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11457/47780 [00:38<02:05, 290.46 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10592/47780 [00:38<01:55, 323.11 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11434/47780 [00:38<01:51, 324.55 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2068/47780 [00:38<03:08, 242.49 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10280/47780 [00:38<01:52, 332.30 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11223/47780 [00:38<02:04, 292.71 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11135/47780 [00:38<01:49, 335.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10745/47780 [00:38<02:15, 273.07 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11487/47780 [00:38<02:09, 279.44 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10626/47780 [00:38<01:59, 310.79 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11470/47780 [00:38<01:49, 330.99 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10320/47780 [00:38<01:46, 351.15 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11169/47780 [00:38<01:48, 336.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10776/47780 [00:38<02:11, 280.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11253/47780 [00:38<02:10, 280.33 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10659/47780 [00:38<01:57, 315.88 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11529/47780 [00:38<01:55, 315.05 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11508/47780 [00:38<01:45, 344.06 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10368/47780 [00:38<01:37, 383.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10807/47780 [00:38<02:08, 288.81 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11282/47780 [00:38<02:12, 275.69 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10700/47780 [00:38<01:48, 342.19 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11562/47780 [00:38<01:54, 315.71 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11203/47780 [00:38<01:59, 306.15 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11543/47780 [00:38<01:50, 327.76 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10408/47780 [00:38<01:40, 373.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10844/47780 [00:38<01:58, 312.29 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11325/47780 [00:38<01:57, 311.46 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10736/47780 [00:38<01:46, 347.11 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11602/47780 [00:38<01:46, 338.78 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11242/47780 [00:38<01:52, 325.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11581/47780 [00:38<01:45, 342.07 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10876/47780 [00:38<02:02, 300.32 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10446/47780 [00:38<01:47, 345.71 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10779/47780 [00:38<01:40, 367.50 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11637/47780 [00:38<01:46, 340.67 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11277/47780 [00:38<01:54, 317.78 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11357/47780 [00:38<02:12, 275.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11619/47780 [00:38<01:45, 341.21 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10907/47780 [00:38<02:03, 299.55 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10483/47780 [00:38<01:48, 342.40 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11672/47780 [00:38<01:48, 334.12 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10817/47780 [00:38<01:43, 357.92 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11314/47780 [00:38<01:50, 328.84 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11401/47780 [00:38<01:54, 316.67 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11656/47780 [00:38<01:44, 345.42 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10941/47780 [00:38<02:03, 297.49 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10518/47780 [00:38<01:53, 328.87 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11350/47780 [00:38<01:48, 336.63 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10854/47780 [00:38<01:45, 349.87 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11706/47780 [00:38<01:52, 320.47 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11435/47780 [00:38<01:56, 312.44 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11691/47780 [00:38<01:51, 324.67 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2159/47780 [00:39<03:49, 198.57 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10975/47780 [00:38<02:00, 306.32 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10890/47780 [00:38<01:45, 349.71 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11384/47780 [00:39<01:48, 334.52 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11739/47780 [00:38<01:53, 318.59 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10557/47780 [00:38<01:53, 327.56 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11468/47780 [00:39<01:54, 317.06 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11726/47780 [00:39<01:49, 327.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2247/47780 [00:39<03:09, 240.56 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11006/47780 [00:39<02:02, 300.16 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11426/47780 [00:39<01:42, 355.26 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11778/47780 [00:39<01:49, 328.56 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10590/47780 [00:39<01:59, 311.71 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10926/47780 [00:39<01:57, 314.54 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11502/47780 [00:39<01:58, 306.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11760/47780 [00:39<01:49, 330.35 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11468/47780 [00:39<01:37, 373.60 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11037/47780 [00:39<02:10, 281.01 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11811/47780 [00:39<01:50, 324.79 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10637/47780 [00:39<01:45, 353.57 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10961/47780 [00:39<01:55, 318.58 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11534/47780 [00:39<01:56, 310.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11794/47780 [00:39<01:53, 316.08 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11507/47780 [00:39<01:35, 378.28 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11075/47780 [00:39<02:01, 303.18 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11852/47780 [00:39<01:48, 330.75 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11019/47780 [00:39<01:34, 389.66 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11566/47780 [00:39<02:00, 299.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10673/47780 [00:39<01:53, 326.00 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11826/47780 [00:39<01:55, 310.29 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11545/47780 [00:39<01:36, 374.50 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11112/47780 [00:39<01:54, 319.82 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11890/47780 [00:39<01:46, 336.98 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10716/47780 [00:39<01:45, 350.87 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11597/47780 [00:39<02:00, 299.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11060/47780 [00:39<01:39, 370.56 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11858/47780 [00:39<01:59, 299.58 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11583/47780 [00:39<01:44, 347.89 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11149/47780 [00:39<01:52, 326.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11925/47780 [00:39<01:46, 336.80 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11628/47780 [00:39<02:02, 295.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11098/47780 [00:39<01:39, 369.21 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11895/47780 [00:39<01:52, 319.01 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10752/47780 [00:39<01:53, 324.89 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11187/47780 [00:39<01:47, 341.60 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11962/47780 [00:39<01:44, 342.43 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2319/47780 [00:39<03:49, 198.27 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11619/47780 [00:39<01:53, 318.74 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11667/47780 [00:39<01:52, 322.42 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11137/47780 [00:39<01:39, 366.79 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11930/47780 [00:39<01:50, 324.20 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10786/47780 [00:39<01:56, 318.68 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11224/47780 [00:39<01:46, 343.94 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12010/47780 [00:39<01:33, 381.31 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11656/47780 [00:39<01:50, 325.81 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11700/47780 [00:39<01:56, 310.31 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11963/47780 [00:39<01:55, 310.90 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11175/47780 [00:39<01:48, 336.38 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10819/47780 [00:39<01:59, 309.43 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11259/47780 [00:39<01:46, 343.94 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12063/47780 [00:39<01:27, 406.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11690/47780 [00:39<01:49, 329.31 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11732/47780 [00:39<01:56, 309.57 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11995/47780 [00:39<01:55, 310.54 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11210/47780 [00:39<01:55, 316.07 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10851/47780 [00:39<02:06, 292.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11294/47780 [00:39<01:53, 322.58 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12104/47780 [00:39<01:32, 385.34 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11768/47780 [00:39<01:51, 323.91 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11724/47780 [00:40<01:54, 314.61 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12028/47780 [00:40<01:53, 314.11 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11243/47780 [00:40<02:01, 301.25 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10881/47780 [00:40<02:14, 274.03 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11327/47780 [00:40<02:03, 295.53 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11801/47780 [00:40<01:54, 314.77 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12143/47780 [00:40<01:36, 369.81 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12060/47780 [00:40<01:53, 314.43 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11756/47780 [00:40<02:00, 299.88 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11274/47780 [00:40<02:04, 294.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10918/47780 [00:40<02:04, 296.12 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11369/47780 [00:40<01:50, 328.49 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11844/47780 [00:40<01:44, 343.71 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12181/47780 [00:40<01:38, 360.14 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12092/47780 [00:40<01:54, 312.29 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11787/47780 [00:40<02:02, 293.18 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10951/47780 [00:40<02:00, 305.23 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11305/47780 [00:40<02:04, 292.25 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11886/47780 [00:40<01:38, 365.12 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11403/47780 [00:40<01:54, 317.47 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12231/47780 [00:40<01:29, 395.37 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12124/47780 [00:40<01:57, 303.44 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11817/47780 [00:40<02:07, 282.30 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10996/47780 [00:40<01:47, 341.61 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11335/47780 [00:40<02:06, 288.17 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11925/47780 [00:40<01:37, 368.70 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12277/47780 [00:40<01:25, 413.14 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11444/47780 [00:40<01:49, 332.15 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12169/47780 [00:40<01:44, 342.07 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11846/47780 [00:40<02:13, 270.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11035/47780 [00:40<01:44, 351.40 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11364/47780 [00:40<02:07, 285.19 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11963/47780 [00:40<01:38, 363.04 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11494/47780 [00:40<01:36, 374.21 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12206/47780 [00:40<01:41, 350.01 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12319/47780 [00:40<01:32, 384.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11875/47780 [00:40<02:10, 275.41 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11398/47780 [00:40<02:02, 297.56 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11072/47780 [00:40<01:51, 330.24 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11532/47780 [00:40<01:39, 362.90 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12360/47780 [00:40<01:36, 367.49 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12244/47780 [00:40<01:49, 324.62 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11903/47780 [00:40<02:12, 270.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12000/47780 [00:40<01:52, 317.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11432/47780 [00:40<01:57, 308.83 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11106/47780 [00:40<01:59, 306.27 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11569/47780 [00:40<01:40, 359.65 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11942/47780 [00:40<01:57, 303.86 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12398/47780 [00:40<01:35, 369.90 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12047/47780 [00:40<01:40, 354.35 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12277/47780 [00:40<01:56, 305.75 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11464/47780 [00:40<02:02, 295.76 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11139/47780 [00:40<01:59, 305.60 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11606/47780 [00:40<01:45, 341.37 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12438/47780 [00:40<01:35, 370.89 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11978/47780 [00:40<01:55, 309.91 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12084/47780 [00:40<01:46, 336.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12309/47780 [00:40<01:56, 303.18 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11502/47780 [00:40<01:53, 319.11 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11175/47780 [00:40<01:55, 317.18 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12010/47780 [00:40<01:55, 309.15 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12476/47780 [00:40<01:38, 357.52 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11641/47780 [00:40<01:52, 322.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12122/47780 [00:41<01:43, 344.70 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11535/47780 [00:41<02:02, 297.04 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2392/47780 [00:41<06:22, 118.80 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11208/47780 [00:41<02:04, 294.66 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12051/47780 [00:41<01:48, 330.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11674/47780 [00:41<01:51, 322.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12159/47780 [00:41<01:44, 340.13 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12340/47780 [00:41<02:35, 228.13 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11569/47780 [00:41<01:57, 307.13 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2731/47780 [00:41<02:37, 286.40 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12513/47780 [00:41<02:03, 285.27 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11242/47780 [00:41<02:01, 300.35 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11707/47780 [00:41<01:56, 309.53 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12394/47780 [00:41<01:58, 298.39 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12087/47780 [00:41<01:59, 298.09 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11607/47780 [00:41<01:51, 323.82 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12575/47780 [00:41<01:37, 361.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11273/47780 [00:41<02:05, 290.22 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11740/47780 [00:41<01:58, 303.69 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12195/47780 [00:41<02:16, 260.11 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12429/47780 [00:41<01:57, 301.75 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12118/47780 [00:41<01:58, 300.74 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11640/47780 [00:41<01:56, 311.50 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12615/47780 [00:41<01:36, 363.77 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11308/47780 [00:41<02:01, 300.06 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11776/47780 [00:41<01:53, 317.19 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12267/47780 [00:41<01:37, 364.89 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12152/47780 [00:41<01:55, 308.61 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12463/47780 [00:41<01:58, 296.85 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11674/47780 [00:41<01:53, 319.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12656/47780 [00:41<01:36, 364.08 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11810/47780 [00:41<01:51, 323.46 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11339/47780 [00:41<02:05, 289.99 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12188/47780 [00:41<01:50, 322.24 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12498/47780 [00:41<01:53, 309.90 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12309/47780 [00:41<01:40, 354.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11708/47780 [00:41<01:50, 325.05 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11846/47780 [00:41<01:48, 330.27 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12695/47780 [00:41<01:41, 345.68 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11375/47780 [00:41<02:06, 287.13 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12531/47780 [00:41<01:55, 306.01 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12349/47780 [00:41<01:39, 354.76 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11743/47780 [00:41<01:50, 324.99 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12223/47780 [00:41<01:59, 296.97 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11881/47780 [00:41<01:51, 321.14 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12734/47780 [00:41<01:41, 346.20 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12566/47780 [00:41<01:50, 317.80 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12389/47780 [00:41<01:36, 366.01 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11408/47780 [00:41<02:05, 289.36 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12254/47780 [00:41<01:58, 299.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11776/47780 [00:41<01:56, 308.47 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12601/47780 [00:41<01:47, 326.48 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12770/47780 [00:41<01:45, 332.44 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11914/47780 [00:41<02:00, 296.84 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11438/47780 [00:41<02:07, 286.11 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12428/47780 [00:41<01:42, 346.23 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11809/47780 [00:41<01:56, 309.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12285/47780 [00:41<02:09, 273.95 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12809/47780 [00:41<01:42, 340.35 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11467/47780 [00:41<02:06, 287.07 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11945/47780 [00:41<02:04, 287.98 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12635/47780 [00:42<01:55, 303.12 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12472/47780 [00:42<01:36, 367.62 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11851/47780 [00:41<01:46, 338.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12314/47780 [00:42<02:10, 271.29 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11499/47780 [00:42<02:03, 293.18 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12844/47780 [00:42<01:44, 335.37 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11976/47780 [00:42<02:03, 290.86 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12667/47780 [00:42<01:54, 307.30 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11886/47780 [00:42<01:44, 341.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12511/47780 [00:42<01:40, 352.68 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12342/47780 [00:42<02:12, 267.79 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12879/47780 [00:42<01:46, 329.01 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12701/47780 [00:42<01:51, 313.47 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12008/47780 [00:42<02:02, 292.33 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11931/47780 [00:42<01:36, 373.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11530/47780 [00:42<02:16, 264.78 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12371/47780 [00:42<02:10, 271.22 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12548/47780 [00:42<01:48, 324.47 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12913/47780 [00:42<01:46, 328.46 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12739/47780 [00:42<01:45, 332.30 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12047/47780 [00:42<01:53, 316.07 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11969/47780 [00:42<01:37, 366.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11562/47780 [00:42<02:10, 276.50 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12399/47780 [00:42<02:13, 264.81 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12585/47780 [00:42<01:44, 336.11 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12946/47780 [00:42<01:45, 328.89 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12779/47780 [00:42<01:41, 343.73 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12079/47780 [00:42<01:56, 306.44 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12006/47780 [00:42<01:41, 351.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11591/47780 [00:42<02:12, 273.34 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2860/47780 [00:42<03:48, 196.35 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12429/47780 [00:42<02:12, 265.83 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12620/47780 [00:42<01:44, 336.22 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12979/47780 [00:42<01:51, 311.34 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12814/47780 [00:42<01:44, 333.38 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12110/47780 [00:42<01:58, 300.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12048/47780 [00:42<01:38, 362.64 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▋         | 3105/47780 [00:42<02:23, 311.26 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12466/47780 [00:42<01:59, 294.68 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11619/47780 [00:42<02:22, 253.53 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12657/47780 [00:42<01:48, 323.14 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13013/47780 [00:42<01:52, 309.10 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12141/47780 [00:42<01:58, 299.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12089/47780 [00:42<01:34, 375.81 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12848/47780 [00:42<01:58, 295.16 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11652/47780 [00:42<02:11, 273.81 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12496/47780 [00:42<02:05, 280.37 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12690/47780 [00:42<01:48, 322.63 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13050/47780 [00:42<01:46, 325.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12172/47780 [00:42<02:02, 290.02 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12127/47780 [00:42<01:43, 345.13 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11682/47780 [00:42<02:12, 272.21 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12879/47780 [00:42<02:02, 284.68 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12723/47780 [00:42<01:48, 324.55 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12525/47780 [00:42<02:18, 254.69 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13084/47780 [00:42<01:45, 329.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12203/47780 [00:42<02:02, 291.03 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11713/47780 [00:42<02:08, 279.62 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12756/47780 [00:42<01:47, 325.80 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12909/47780 [00:42<02:07, 274.23 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12163/47780 [00:42<01:53, 314.70 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12578/47780 [00:42<01:48, 323.67 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13118/47780 [00:42<01:45, 328.98 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12248/47780 [00:42<01:48, 326.38 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12940/47780 [00:43<02:04, 280.72 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12196/47780 [00:43<01:52, 315.05 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12789/47780 [00:43<01:55, 302.96 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11742/47780 [00:42<02:20, 255.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12612/47780 [00:43<01:49, 321.04 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13152/47780 [00:43<01:51, 310.50 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12986/47780 [00:43<01:47, 322.32 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12820/47780 [00:43<01:54, 304.85 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11771/47780 [00:43<02:16, 263.04 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12646/47780 [00:43<01:48, 322.74 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12229/47780 [00:43<02:02, 290.90 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12281/47780 [00:43<02:21, 251.03 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13184/47780 [00:43<01:55, 299.83 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12852/47780 [00:43<01:53, 308.71 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11799/47780 [00:43<02:15, 264.73 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13026/47780 [00:43<01:44, 332.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12265/47780 [00:43<01:55, 306.19 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12679/47780 [00:43<01:57, 297.77 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12354/47780 [00:43<01:38, 360.30 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13222/47780 [00:43<01:48, 318.52 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12886/47780 [00:43<01:50, 314.60 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13062/47780 [00:43<01:42, 340.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11826/47780 [00:43<02:18, 260.42 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12297/47780 [00:43<01:59, 296.07 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12710/47780 [00:43<01:57, 298.27 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13255/47780 [00:43<01:49, 315.15 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12918/47780 [00:43<01:51, 312.57 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12395/47780 [00:43<01:48, 327.18 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13098/47780 [00:43<01:41, 342.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11853/47780 [00:43<02:16, 263.09 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12334/47780 [00:43<01:52, 313.73 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12741/47780 [00:43<02:00, 291.90 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13295/47780 [00:43<01:45, 327.48 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12951/47780 [00:43<01:49, 317.49 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12432/47780 [00:43<01:45, 333.60 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11883/47780 [00:43<02:13, 269.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13133/47780 [00:43<01:48, 318.90 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12367/47780 [00:43<01:51, 318.01 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12776/47780 [00:43<01:54, 304.48 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13333/47780 [00:43<01:42, 334.86 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11923/47780 [00:43<01:57, 304.67 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12983/47780 [00:43<01:55, 300.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12468/47780 [00:43<01:48, 324.43 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13166/47780 [00:43<01:51, 309.06 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12400/47780 [00:43<01:55, 307.56 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12808/47780 [00:43<01:53, 308.83 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13373/47780 [00:43<01:38, 349.08 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11958/47780 [00:43<01:54, 314.16 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13017/47780 [00:43<01:56, 298.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12503/47780 [00:43<01:51, 317.28 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12432/47780 [00:43<01:53, 310.79 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13198/47780 [00:43<01:57, 295.20 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12840/47780 [00:43<01:57, 298.36 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13409/47780 [00:43<01:42, 336.27 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11997/47780 [00:43<01:51, 321.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13052/47780 [00:43<01:53, 305.65 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12464/47780 [00:43<01:56, 303.16 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13230/47780 [00:43<01:55, 298.73 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12878/47780 [00:43<01:51, 314.23 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13448/47780 [00:43<01:38, 348.10 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12537/47780 [00:43<02:08, 274.53 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12037/47780 [00:43<01:45, 339.78 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13083/47780 [00:43<01:54, 303.85 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12496/47780 [00:43<01:55, 304.83 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13264/47780 [00:44<01:51, 310.09 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12913/47780 [00:44<01:48, 320.72 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12581/47780 [00:44<01:52, 312.05 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13484/47780 [00:44<01:41, 336.31 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12074/47780 [00:44<01:43, 345.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13114/47780 [00:44<01:56, 298.10 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13296/47780 [00:44<01:54, 302.11 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12528/47780 [00:44<01:58, 297.53 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12946/47780 [00:44<01:47, 323.00 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12615/47780 [00:44<01:51, 315.72 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13518/47780 [00:44<01:43, 329.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12115/47780 [00:44<01:38, 362.84 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13149/47780 [00:44<01:54, 303.12 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3240/47780 [00:44<03:58, 186.39 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12561/47780 [00:44<01:56, 301.30 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12980/47780 [00:44<01:51, 313.33 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13327/47780 [00:44<02:00, 285.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13552/47780 [00:44<01:45, 325.39 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12152/47780 [00:44<01:41, 349.91 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12649/47780 [00:44<02:03, 283.51 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13192/47780 [00:44<01:43, 332.97 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3606/47780 [00:44<02:08, 343.64 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12601/47780 [00:44<01:48, 325.57 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13012/47780 [00:44<01:54, 302.65 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13359/47780 [00:44<02:03, 279.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13585/47780 [00:44<01:48, 316.03 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12188/47780 [00:44<01:43, 343.79 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12697/47780 [00:44<01:45, 332.33 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13226/47780 [00:44<01:43, 332.99 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12634/47780 [00:44<01:48, 322.74 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13043/47780 [00:44<02:00, 287.97 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13393/47780 [00:44<01:59, 286.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13617/47780 [00:44<01:50, 310.19 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12737/47780 [00:44<01:41, 346.33 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13263/47780 [00:44<01:41, 340.22 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12223/47780 [00:44<01:50, 322.84 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12672/47780 [00:44<01:44, 335.81 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13076/47780 [00:44<01:58, 292.97 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13431/47780 [00:44<01:53, 302.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13649/47780 [00:44<01:52, 302.70 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12777/47780 [00:44<01:38, 357.11 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13299/47780 [00:44<01:40, 344.07 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12706/47780 [00:44<01:45, 333.22 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12263/47780 [00:44<01:49, 323.28 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13465/47780 [00:44<01:50, 309.21 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13106/47780 [00:44<02:00, 288.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13682/47780 [00:44<01:50, 309.79 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13335/47780 [00:44<01:39, 346.19 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12814/47780 [00:44<01:41, 345.28 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12298/47780 [00:44<01:48, 327.04 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12741/47780 [00:44<01:48, 322.96 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13501/47780 [00:44<01:46, 320.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13714/47780 [00:44<01:49, 309.74 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13135/47780 [00:44<02:10, 265.66 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13374/47780 [00:44<01:38, 351.04 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12850/47780 [00:44<01:42, 341.73 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12340/47780 [00:44<01:41, 348.55 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12783/47780 [00:44<01:41, 343.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13536/47780 [00:44<01:44, 328.01 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13759/47780 [00:44<01:40, 338.43 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13163/47780 [00:44<02:09, 266.33 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12885/47780 [00:44<01:43, 336.51 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13410/47780 [00:44<01:42, 333.95 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12825/47780 [00:44<01:35, 364.43 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12379/47780 [00:44<01:41, 348.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13573/47780 [00:45<01:41, 336.18 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13793/47780 [00:45<01:41, 335.15 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13190/47780 [00:45<02:13, 258.78 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12923/47780 [00:45<01:40, 347.68 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13446/47780 [00:45<01:41, 339.84 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12862/47780 [00:45<01:36, 361.70 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12422/47780 [00:45<01:35, 370.97 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13609/47780 [00:45<01:40, 339.26 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13828/47780 [00:45<01:42, 331.67 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13221/47780 [00:45<02:09, 266.97 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12959/47780 [00:45<01:40, 346.77 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13490/47780 [00:45<01:34, 362.14 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12460/47780 [00:45<01:39, 353.86 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12901/47780 [00:45<01:43, 338.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13645/47780 [00:45<01:41, 337.49 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13864/47780 [00:45<01:39, 339.37 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13249/47780 [00:45<02:08, 269.22 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13527/47780 [00:45<01:40, 340.63 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12994/47780 [00:45<01:53, 305.73 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12496/47780 [00:45<01:44, 336.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13685/47780 [00:45<01:37, 351.21 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12936/47780 [00:45<01:53, 308.00 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13898/47780 [00:45<01:45, 319.81 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13278/47780 [00:45<02:06, 273.54 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13562/47780 [00:45<01:40, 339.75 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13043/47780 [00:45<01:40, 346.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12533/47780 [00:45<01:43, 342.19 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13721/47780 [00:45<01:41, 334.28 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12968/47780 [00:45<01:53, 308.03 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13932/47780 [00:45<01:44, 323.48 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13307/47780 [00:45<02:05, 275.05 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13079/47780 [00:45<01:40, 346.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13597/47780 [00:45<01:49, 310.77 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12568/47780 [00:45<01:47, 328.97 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13757/47780 [00:45<01:40, 337.85 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13000/47780 [00:45<01:53, 307.76 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13339/47780 [00:45<01:59, 287.79 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13970/47780 [00:45<01:40, 335.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13635/47780 [00:45<01:43, 328.81 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13115/47780 [00:45<01:45, 330.11 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13792/47780 [00:45<01:41, 333.86 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12603/47780 [00:45<01:49, 321.27 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13033/47780 [00:45<01:50, 313.53 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14004/47780 [00:45<01:41, 333.25 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13369/47780 [00:45<02:00, 284.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13670/47780 [00:45<01:42, 331.66 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13149/47780 [00:45<01:47, 322.65 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13828/47780 [00:45<01:40, 337.51 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12639/47780 [00:45<01:48, 322.95 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14049/47780 [00:45<01:31, 366.87 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13401/47780 [00:45<01:57, 291.68 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13065/47780 [00:45<01:57, 295.84 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13709/47780 [00:45<01:38, 344.47 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13188/47780 [00:45<01:41, 340.94 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14092/47780 [00:45<01:28, 380.95 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13863/47780 [00:45<01:43, 328.43 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12672/47780 [00:45<01:51, 316.25 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13440/47780 [00:45<01:47, 320.18 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13095/47780 [00:45<01:58, 293.74 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13744/47780 [00:45<01:38, 344.96 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13223/47780 [00:45<01:41, 339.74 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13896/47780 [00:45<01:44, 324.23 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12707/47780 [00:45<01:50, 318.55 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14131/47780 [00:45<01:30, 370.56 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13473/47780 [00:45<01:50, 311.66 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13125/47780 [00:45<01:58, 292.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13781/47780 [00:46<01:38, 345.39 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14169/47780 [00:46<01:30, 373.23 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13156/47780 [00:46<01:56, 297.25 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13258/47780 [00:46<01:51, 310.64 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13511/47780 [00:46<01:45, 324.32 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13929/47780 [00:46<01:50, 307.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12739/47780 [00:46<02:05, 278.41 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13818/47780 [00:46<01:39, 340.18 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14212/47780 [00:46<01:28, 380.77 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13291/47780 [00:46<01:50, 312.74 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13963/47780 [00:46<01:46, 316.10 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13544/47780 [00:46<01:46, 322.25 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13193/47780 [00:46<01:52, 307.58 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12792/47780 [00:46<01:43, 337.60 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13853/47780 [00:46<01:41, 335.33 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3783/47780 [00:46<03:37, 202.31 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13323/47780 [00:46<01:49, 314.73 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14254/47780 [00:46<01:26, 387.55 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13578/47780 [00:46<01:45, 323.63 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13224/47780 [00:46<01:55, 298.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12834/47780 [00:46<01:37, 358.43 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13888/47780 [00:46<01:39, 339.45 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13999/47780 [00:46<02:04, 270.42 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4212/47780 [00:46<02:00, 361.84 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14294/47780 [00:46<01:26, 388.88 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13355/47780 [00:46<01:50, 312.72 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13616/47780 [00:46<01:42, 332.31 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13254/47780 [00:46<01:58, 292.44 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13923/47780 [00:46<01:39, 338.99 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12871/47780 [00:46<01:43, 335.75 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14056/47780 [00:46<01:38, 343.68 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14334/47780 [00:46<01:25, 390.20 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13656/47780 [00:46<01:37, 351.76 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13286/47780 [00:46<01:55, 299.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13387/47780 [00:46<02:06, 271.39 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12906/47780 [00:46<01:49, 319.10 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13958/47780 [00:46<01:52, 300.52 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14094/47780 [00:46<01:44, 321.00 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13322/47780 [00:46<01:48, 316.99 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14374/47780 [00:46<01:31, 367.02 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13692/47780 [00:46<01:44, 327.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13431/47780 [00:46<01:51, 308.71 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12939/47780 [00:46<01:48, 321.92 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14128/47780 [00:46<01:43, 325.47 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13998/47780 [00:46<01:45, 320.24 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14417/47780 [00:46<01:26, 384.58 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13356/47780 [00:46<01:47, 320.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13733/47780 [00:46<01:37, 350.19 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13463/47780 [00:46<01:57, 293.00 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12981/47780 [00:46<01:43, 337.62 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14164/47780 [00:46<01:41, 331.50 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14032/47780 [00:46<01:45, 318.58 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13390/47780 [00:46<01:46, 321.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14458/47780 [00:46<01:28, 374.52 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13769/47780 [00:46<01:45, 323.27 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13498/47780 [00:46<01:52, 306.07 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13016/47780 [00:46<01:45, 330.24 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13426/47780 [00:46<01:44, 329.46 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14065/47780 [00:46<01:48, 311.22 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14498/47780 [00:46<01:27, 381.56 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14199/47780 [00:46<01:49, 306.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13804/47780 [00:46<01:42, 330.39 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13530/47780 [00:46<01:53, 302.14 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13050/47780 [00:46<01:46, 325.63 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13461/47780 [00:47<01:42, 335.34 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14537/47780 [00:47<01:28, 375.15 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14098/47780 [00:47<01:49, 306.58 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14231/47780 [00:47<01:49, 306.64 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13561/47780 [00:47<01:52, 304.27 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13500/47780 [00:47<01:37, 351.35 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14575/47780 [00:47<01:29, 368.98 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14263/47780 [00:47<01:50, 303.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13838/47780 [00:47<02:10, 260.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13083/47780 [00:47<02:00, 288.21 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14129/47780 [00:47<02:01, 276.64 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13592/47780 [00:47<01:54, 298.86 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13541/47780 [00:47<01:32, 368.28 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13909/47780 [00:47<01:32, 367.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14613/47780 [00:47<01:34, 351.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14294/47780 [00:47<01:53, 295.80 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13122/47780 [00:47<01:54, 302.35 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13623/47780 [00:47<01:53, 301.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13578/47780 [00:47<01:41, 337.10 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14658/47780 [00:47<01:30, 367.06 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14158/47780 [00:47<02:32, 220.43 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14324/47780 [00:47<01:57, 284.21 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13153/47780 [00:47<01:57, 295.13 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13654/47780 [00:47<01:54, 297.25 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13951/47780 [00:47<01:38, 342.06 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13613/47780 [00:47<01:45, 322.82 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14697/47780 [00:47<01:28, 373.34 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13992/47780 [00:47<01:34, 355.87 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13684/47780 [00:47<01:56, 291.71 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13183/47780 [00:47<02:05, 275.81 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14353/47780 [00:47<02:08, 260.43 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14183/47780 [00:47<02:46, 201.50 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13646/47780 [00:47<01:48, 314.49 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14735/47780 [00:47<01:32, 359.09 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13722/47780 [00:47<01:48, 313.45 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13216/47780 [00:47<02:00, 286.92 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14384/47780 [00:47<02:03, 270.61 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14035/47780 [00:47<01:34, 356.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14234/47780 [00:47<02:05, 268.12 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13680/47780 [00:47<01:46, 321.44 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4423/47780 [00:47<02:37, 275.28 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14772/47780 [00:47<01:37, 339.34 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14076/47780 [00:47<01:31, 370.34 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14417/47780 [00:47<01:57, 283.58 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13247/47780 [00:47<01:59, 289.94 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13764/47780 [00:47<01:43, 327.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14297/47780 [00:47<01:35, 351.63 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13714/47780 [00:47<01:45, 323.08 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4618/47780 [00:47<02:04, 347.59 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14808/47780 [00:47<01:38, 333.66 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13277/47780 [00:47<02:00, 286.44 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14115/47780 [00:47<01:31, 367.50 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14446/47780 [00:47<01:59, 278.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13797/47780 [00:47<01:45, 322.16 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14338/47780 [00:47<01:41, 329.64 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13747/47780 [00:47<01:48, 313.19 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14843/47780 [00:47<01:38, 334.90 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13306/47780 [00:47<02:02, 281.23 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13831/47780 [00:47<01:46, 320.13 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14475/47780 [00:47<02:03, 269.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14153/47780 [00:47<01:38, 341.26 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14375/47780 [00:48<01:40, 332.41 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13780/47780 [00:48<01:51, 304.87 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14880/47780 [00:48<01:36, 340.93 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13340/47780 [00:47<01:58, 291.09 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13864/47780 [00:48<01:47, 315.90 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14509/47780 [00:48<01:57, 283.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14189/47780 [00:48<01:37, 346.12 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13815/47780 [00:48<01:50, 308.71 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14411/47780 [00:48<01:47, 311.36 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14915/47780 [00:48<01:39, 331.79 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13373/47780 [00:48<01:56, 295.37 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14548/47780 [00:48<01:46, 313.15 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13898/47780 [00:48<01:47, 315.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14225/47780 [00:48<01:38, 341.92 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13847/47780 [00:48<01:49, 310.66 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14452/47780 [00:48<01:43, 323.23 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14590/47780 [00:48<01:37, 340.02 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13412/47780 [00:48<01:47, 318.56 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14949/47780 [00:48<01:42, 319.61 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13930/47780 [00:48<01:48, 313.21 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14260/47780 [00:48<01:38, 340.97 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13879/47780 [00:48<01:55, 293.71 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14487/47780 [00:48<01:41, 326.57 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14628/47780 [00:48<01:34, 351.44 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14986/47780 [00:48<01:39, 330.45 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13962/47780 [00:48<01:49, 308.15 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14298/47780 [00:48<01:36, 348.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13444/47780 [00:48<01:53, 301.43 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13913/47780 [00:48<01:50, 305.99 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14521/47780 [00:48<01:41, 326.79 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14664/47780 [00:48<01:33, 353.85 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13998/47780 [00:48<01:44, 322.54 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15022/47780 [00:48<01:40, 327.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14336/47780 [00:48<01:34, 353.22 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13475/47780 [00:48<01:57, 291.23 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14555/47780 [00:48<01:44, 318.69 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14700/47780 [00:48<01:37, 339.72 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15063/47780 [00:48<01:33, 350.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14031/47780 [00:48<01:47, 314.05 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14372/47780 [00:48<01:38, 339.67 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13505/47780 [00:48<02:05, 272.57 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13944/47780 [00:48<02:14, 250.67 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14589/47780 [00:48<01:44, 318.88 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14735/47780 [00:48<01:38, 334.77 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14063/47780 [00:48<01:46, 315.48 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14417/47780 [00:48<01:30, 370.63 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15099/47780 [00:48<01:40, 323.94 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13986/47780 [00:48<01:56, 289.71 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13533/47780 [00:48<02:14, 255.47 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14773/47780 [00:48<01:34, 347.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14107/47780 [00:48<01:36, 347.84 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14455/47780 [00:48<01:30, 368.99 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14622/47780 [00:48<01:52, 295.37 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15132/47780 [00:48<01:41, 321.71 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14017/47780 [00:48<01:55, 291.67 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13560/47780 [00:48<02:11, 259.26 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14143/47780 [00:48<01:35, 350.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14808/47780 [00:48<01:38, 333.33 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14493/47780 [00:48<01:31, 363.56 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15167/47780 [00:48<01:39, 326.35 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14653/47780 [00:48<01:54, 290.03 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14048/47780 [00:48<01:54, 293.63 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13588/47780 [00:48<02:11, 260.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14180/47780 [00:49<01:36, 348.80 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14842/47780 [00:49<01:41, 324.13 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15205/47780 [00:49<01:36, 337.34 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14685/47780 [00:49<01:53, 291.97 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14086/47780 [00:49<01:46, 317.18 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14530/47780 [00:49<01:40, 330.98 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13618/47780 [00:49<02:07, 268.41 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14215/47780 [00:49<01:40, 333.21 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15244/47780 [00:49<01:33, 348.76 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14889/47780 [00:49<01:34, 349.35 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14121/47780 [00:49<01:43, 326.21 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14717/47780 [00:49<01:56, 284.04 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14564/47780 [00:49<01:40, 330.37 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13646/47780 [00:49<02:08, 264.67 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4782/47780 [00:49<02:59, 239.63 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15288/47780 [00:49<01:27, 370.83 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14249/47780 [00:49<01:44, 321.11 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14924/47780 [00:49<01:35, 345.40 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14599/47780 [00:49<01:38, 335.78 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14758/47780 [00:49<01:45, 311.59 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14155/47780 [00:49<01:46, 316.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13681/47780 [00:49<01:58, 288.53 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14960/47780 [00:49<01:35, 342.28 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14282/47780 [00:49<01:47, 312.88 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15326/47780 [00:49<01:32, 352.50 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14790/47780 [00:49<01:45, 313.82 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13721/47780 [00:49<01:48, 313.23 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14635/47780 [00:49<01:44, 317.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14188/47780 [00:49<01:52, 299.51 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14996/47780 [00:49<01:34, 346.95 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14318/47780 [00:49<01:43, 322.67 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15364/47780 [00:49<01:31, 352.70 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14822/47780 [00:49<01:45, 313.47 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14219/47780 [00:49<01:52, 299.34 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14672/47780 [00:49<01:41, 324.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13772/47780 [00:49<01:34, 361.21 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14351/47780 [00:49<01:43, 324.47 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15402/47780 [00:49<01:30, 356.42 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15032/47780 [00:49<01:40, 324.80 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14854/47780 [00:49<01:48, 303.61 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14251/47780 [00:49<01:49, 305.10 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13809/47780 [00:49<01:36, 351.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14705/47780 [00:49<01:45, 312.44 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14384/47780 [00:49<01:44, 318.57 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15445/47780 [00:49<01:26, 373.19 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14890/47780 [00:49<01:44, 315.91 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15081/47780 [00:49<01:30, 362.25 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14290/47780 [00:49<01:42, 325.63 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13846/47780 [00:49<01:41, 332.84 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14737/47780 [00:49<01:53, 291.54 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15484/47780 [00:49<01:25, 377.96 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15122/47780 [00:49<01:27, 371.51 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14323/47780 [00:49<01:42, 326.58 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14923/47780 [00:49<01:50, 296.30 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14416/47780 [00:49<02:07, 262.33 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13882/47780 [00:49<01:41, 334.47 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14767/47780 [00:49<02:00, 273.08 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15522/47780 [00:49<01:27, 368.35 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14357/47780 [00:49<01:42, 326.94 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15160/47780 [00:49<01:35, 342.97 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14953/47780 [00:49<01:52, 290.75 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13917/47780 [00:49<01:44, 324.36 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14805/47780 [00:49<01:50, 298.78 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15559/47780 [00:50<01:33, 346.42 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14390/47780 [00:50<01:46, 312.91 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15197/47780 [00:50<01:34, 346.45 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14445/47780 [00:50<02:34, 215.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14983/47780 [00:50<01:56, 280.87 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13958/47780 [00:50<01:40, 336.91 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14836/47780 [00:50<01:50, 297.47 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15600/47780 [00:50<01:28, 363.92 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14516/47780 [00:50<01:42, 325.48 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14422/47780 [00:50<01:52, 297.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15233/47780 [00:50<01:38, 330.96 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13994/47780 [00:50<01:39, 339.37 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15012/47780 [00:50<02:09, 253.06 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14873/47780 [00:50<01:44, 315.23 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15637/47780 [00:50<01:34, 338.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14455/47780 [00:50<01:50, 300.55 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15278/47780 [00:50<01:32, 352.79 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14905/47780 [00:50<01:43, 316.12 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14554/47780 [00:50<01:50, 300.11 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14029/47780 [00:50<01:49, 308.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15676/47780 [00:50<01:33, 341.68 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14488/47780 [00:50<01:49, 305.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 15038/47780 [00:50<02:32, 214.50 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15319/47780 [00:50<01:28, 368.08 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14947/47780 [00:50<01:35, 342.37 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14593/47780 [00:50<01:45, 313.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14061/47780 [00:50<01:49, 307.50 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15096/47780 [00:50<01:49, 298.88 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14519/47780 [00:50<01:55, 287.03 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15711/47780 [00:50<01:42, 312.46 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15357/47780 [00:50<01:36, 337.65 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14628/47780 [00:50<01:43, 319.23 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14982/47780 [00:50<01:40, 325.30 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14096/47780 [00:50<01:46, 316.03 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15142/47780 [00:50<01:38, 332.71 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14554/47780 [00:50<01:51, 297.92 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15744/47780 [00:50<01:44, 307.98 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15397/47780 [00:50<01:32, 349.73 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15015/47780 [00:50<01:42, 320.12 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14666/47780 [00:50<01:40, 327.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14128/47780 [00:50<01:50, 303.63 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15178/47780 [00:50<01:40, 322.80 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14599/47780 [00:50<01:40, 329.27 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15433/47780 [00:50<01:32, 348.61 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15776/47780 [00:50<01:49, 292.14 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14705/47780 [00:50<01:37, 340.83 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15048/47780 [00:50<01:46, 308.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14159/47780 [00:50<01:51, 301.43 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14642/47780 [00:50<01:33, 355.37 examples/s]
Tokenizing train dataset (num_proc=32):  10%|█         | 4995/47780 [00:50<03:41, 193.38 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15212/47780 [00:50<01:47, 302.07 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15814/47780 [00:50<01:42, 312.37 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15469/47780 [00:50<01:39, 323.88 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15086/47780 [00:50<01:41, 321.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14741/47780 [00:50<01:44, 314.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14191/47780 [00:50<01:57, 284.86 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█▏        | 5416/47780 [00:50<02:03, 341.71 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15847/47780 [00:50<01:40, 316.92 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14678/47780 [00:50<01:39, 332.02 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15503/47780 [00:50<01:38, 328.19 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15124/47780 [00:50<01:36, 337.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15244/47780 [00:50<01:51, 291.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14774/47780 [00:50<01:47, 306.10 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14223/47780 [00:50<01:56, 288.15 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15159/47780 [00:51<01:36, 337.60 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14712/47780 [00:51<01:46, 310.63 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15275/47780 [00:51<01:55, 281.50 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15880/47780 [00:51<01:50, 288.65 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15537/47780 [00:51<01:49, 295.39 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14806/47780 [00:51<01:49, 300.49 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14253/47780 [00:51<02:01, 276.38 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15193/47780 [00:51<01:39, 327.01 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14754/47780 [00:51<01:39, 332.51 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15924/47780 [00:51<01:39, 321.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15304/47780 [00:51<01:59, 272.76 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14839/47780 [00:51<01:46, 308.38 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15570/47780 [00:51<01:46, 301.35 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14289/47780 [00:51<01:55, 289.46 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15230/47780 [00:51<01:36, 337.18 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14791/47780 [00:51<01:37, 338.97 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15970/47780 [00:51<01:28, 358.83 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14871/47780 [00:51<01:45, 311.27 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15601/47780 [00:51<01:47, 300.09 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15332/47780 [00:51<02:05, 258.18 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14319/47780 [00:51<02:01, 274.42 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14828/47780 [00:51<01:38, 332.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15264/47780 [00:51<01:43, 314.19 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15638/47780 [00:51<01:41, 316.29 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14903/47780 [00:51<01:48, 303.79 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15369/47780 [00:51<01:53, 284.75 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16007/47780 [00:51<01:36, 329.25 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14349/47780 [00:51<02:00, 278.34 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14864/47780 [00:51<01:37, 336.70 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14935/47780 [00:51<01:46, 308.35 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15671/47780 [00:51<01:41, 316.52 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15300/47780 [00:51<01:42, 316.74 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15406/47780 [00:51<01:46, 304.54 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16046/47780 [00:51<01:33, 337.97 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14378/47780 [00:51<02:00, 278.01 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14898/47780 [00:51<01:38, 333.51 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15333/47780 [00:51<01:41, 319.96 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14967/47780 [00:51<01:46, 307.83 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15437/47780 [00:51<01:45, 305.53 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16081/47780 [00:51<01:34, 333.85 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15704/47780 [00:51<01:54, 279.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14406/47780 [00:51<02:04, 268.80 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14933/47780 [00:51<01:38, 334.75 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14998/47780 [00:51<01:47, 305.18 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15366/47780 [00:51<01:43, 312.68 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15471/47780 [00:51<01:44, 308.79 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16115/47780 [00:51<01:37, 324.75 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15765/47780 [00:51<01:28, 361.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14433/47780 [00:51<02:07, 261.46 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14978/47780 [00:51<01:29, 365.24 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15029/47780 [00:51<01:46, 306.51 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15399/47780 [00:51<01:43, 313.87 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15503/47780 [00:51<01:50, 292.17 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16148/47780 [00:51<01:40, 315.77 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15803/47780 [00:51<01:32, 346.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14468/47780 [00:51<02:00, 276.87 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15065/47780 [00:51<01:42, 318.60 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15431/47780 [00:51<01:43, 312.22 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15015/47780 [00:51<01:34, 345.21 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16183/47780 [00:51<01:37, 323.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15533/47780 [00:51<01:53, 284.88 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15839/47780 [00:52<01:37, 326.96 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14497/47780 [00:51<02:06, 264.03 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15057/47780 [00:52<01:29, 366.04 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15097/47780 [00:52<01:47, 304.68 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15463/47780 [00:52<01:46, 303.47 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15567/47780 [00:52<01:49, 293.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16216/47780 [00:52<01:43, 303.50 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14526/47780 [00:52<02:04, 267.19 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15497/47780 [00:52<01:45, 306.91 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15873/47780 [00:52<01:47, 296.21 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15094/47780 [00:52<01:36, 339.33 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15128/47780 [00:52<01:56, 280.72 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15601/47780 [00:52<01:46, 303.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16247/47780 [00:52<01:46, 295.72 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14564/47780 [00:52<01:52, 295.20 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15532/47780 [00:52<01:43, 312.66 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15163/47780 [00:52<01:51, 292.97 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15635/47780 [00:52<01:42, 312.93 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15904/47780 [00:52<01:51, 284.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16280/47780 [00:52<01:44, 301.77 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14597/47780 [00:52<01:48, 304.88 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15129/47780 [00:52<01:55, 283.49 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15940/47780 [00:52<01:45, 301.40 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15564/47780 [00:52<01:51, 288.39 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15667/47780 [00:52<01:47, 298.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16311/47780 [00:52<01:45, 297.48 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14628/47780 [00:52<01:54, 289.77 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15195/47780 [00:52<02:13, 243.86 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15160/47780 [00:52<02:03, 263.19 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15982/47780 [00:52<01:36, 329.36 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15698/47780 [00:52<01:49, 291.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16341/47780 [00:52<01:47, 291.61 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14660/47780 [00:52<01:51, 298.11 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15594/47780 [00:52<02:08, 250.68 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15253/47780 [00:52<01:40, 322.55 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15193/47780 [00:52<01:57, 277.95 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16019/47780 [00:52<01:35, 333.12 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15728/47780 [00:52<01:51, 287.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16379/47780 [00:52<01:40, 312.94 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5597/47780 [00:52<03:03, 229.75 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15643/47780 [00:52<01:44, 307.53 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14701/47780 [00:52<01:43, 319.06 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15288/47780 [00:52<01:42, 316.09 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15225/47780 [00:52<01:56, 280.11 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16055/47780 [00:52<01:33, 340.25 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15757/47780 [00:52<01:53, 281.78 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16411/47780 [00:52<01:41, 307.59 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5930/47780 [00:52<02:00, 348.03 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15676/47780 [00:52<01:43, 309.92 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14734/47780 [00:52<01:45, 311.76 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15258/47780 [00:52<01:52, 290.14 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15322/47780 [00:52<01:44, 309.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16090/47780 [00:52<01:35, 332.10 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15790/47780 [00:52<01:51, 286.90 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16451/47780 [00:52<01:35, 326.86 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15709/47780 [00:52<01:51, 287.64 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15366/47780 [00:52<01:35, 340.36 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15288/47780 [00:52<01:53, 286.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16124/47780 [00:52<01:41, 313.09 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15819/47780 [00:52<01:58, 270.38 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16484/47780 [00:52<01:44, 300.51 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14766/47780 [00:52<02:16, 241.03 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15739/47780 [00:52<01:50, 290.82 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15402/47780 [00:52<01:35, 338.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15330/47780 [00:52<01:42, 316.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16156/47780 [00:53<01:43, 304.89 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15849/47780 [00:53<01:55, 276.88 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16518/47780 [00:53<01:40, 311.15 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15773/47780 [00:53<01:45, 304.12 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15438/47780 [00:53<01:33, 344.16 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15363/47780 [00:53<01:45, 306.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14794/47780 [00:53<02:28, 222.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16189/47780 [00:53<01:43, 305.28 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15881/47780 [00:53<01:50, 288.94 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16553/47780 [00:53<01:40, 310.96 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15805/47780 [00:53<01:47, 298.42 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15474/47780 [00:53<01:36, 333.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14862/47780 [00:53<01:41, 325.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15395/47780 [00:53<01:51, 291.16 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16224/47780 [00:53<01:41, 310.83 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15911/47780 [00:53<01:49, 291.74 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16589/47780 [00:53<01:36, 321.60 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15838/47780 [00:53<01:46, 300.11 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15508/47780 [00:53<01:40, 320.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14899/47780 [00:53<01:42, 320.35 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15431/47780 [00:53<01:45, 306.27 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15944/47780 [00:53<01:46, 299.60 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16256/47780 [00:53<01:43, 305.23 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16629/47780 [00:53<01:36, 321.85 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15873/47780 [00:53<01:43, 307.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15545/47780 [00:53<01:37, 331.13 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15462/47780 [00:53<01:48, 297.94 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15975/47780 [00:53<01:47, 295.84 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16288/47780 [00:53<01:49, 287.80 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14934/47780 [00:53<01:50, 296.30 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16678/47780 [00:53<01:26, 360.19 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15905/47780 [00:53<01:43, 309.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15579/47780 [00:53<01:37, 329.87 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 16005/47780 [00:53<01:47, 296.29 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6121/47780 [00:53<02:14, 309.57 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14966/47780 [00:53<01:53, 288.60 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15493/47780 [00:53<02:02, 262.90 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16318/47780 [00:53<01:56, 270.04 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16717/47780 [00:53<01:24, 366.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15938/47780 [00:53<01:48, 293.64 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15613/47780 [00:53<01:46, 301.76 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6392/47780 [00:53<01:36, 430.79 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14997/47780 [00:53<01:54, 286.70 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15527/47780 [00:53<01:55, 279.96 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16035/47780 [00:53<02:03, 256.29 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16361/47780 [00:53<01:42, 306.66 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16754/47780 [00:53<01:29, 345.30 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15968/47780 [00:53<01:51, 284.04 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15645/47780 [00:53<01:48, 297.26 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16079/47780 [00:53<01:44, 304.63 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16395/47780 [00:53<01:39, 315.61 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15556/47780 [00:53<01:56, 276.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 15028/47780 [00:53<01:55, 282.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 16000/47780 [00:53<01:48, 291.56 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16789/47780 [00:53<01:41, 306.77 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15681/47780 [00:53<01:44, 307.61 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16113/47780 [00:53<01:40, 314.06 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16429/47780 [00:53<01:38, 319.13 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15585/47780 [00:53<01:56, 277.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15070/47780 [00:53<01:44, 313.50 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16030/47780 [00:53<01:51, 284.89 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16821/47780 [00:53<01:41, 303.52 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15713/47780 [00:53<01:43, 310.61 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16148/47780 [00:54<01:38, 320.94 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15621/47780 [00:54<01:48, 297.15 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16463/47780 [00:54<01:41, 307.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15103/47780 [00:53<01:47, 304.93 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16063/47780 [00:54<01:48, 291.62 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16853/47780 [00:54<01:42, 301.79 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15745/47780 [00:54<01:47, 296.78 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15656/47780 [00:54<01:44, 308.42 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16181/47780 [00:54<01:45, 300.85 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15135/47780 [00:54<01:46, 305.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16495/47780 [00:54<01:45, 297.79 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16885/47780 [00:54<01:40, 306.54 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15778/47780 [00:54<01:44, 305.86 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16093/47780 [00:54<02:04, 254.06 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15688/47780 [00:54<01:50, 291.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16212/47780 [00:54<01:48, 290.63 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16528/47780 [00:54<01:44, 300.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15166/47780 [00:54<01:51, 293.75 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16919/47780 [00:54<01:39, 309.13 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15809/47780 [00:54<01:48, 293.97 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16134/47780 [00:54<01:48, 291.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16244/47780 [00:54<01:46, 296.75 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15196/47780 [00:54<01:51, 292.40 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15726/47780 [00:54<01:45, 302.75 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16559/47780 [00:54<01:48, 286.88 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16951/47780 [00:54<01:39, 309.13 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15844/47780 [00:54<01:43, 309.34 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16165/47780 [00:54<01:52, 281.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16277/47780 [00:54<01:43, 303.24 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15226/47780 [00:54<01:51, 292.35 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15757/47780 [00:54<01:50, 290.43 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16589/47780 [00:54<01:54, 272.75 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16983/47780 [00:54<01:38, 311.50 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15876/47780 [00:54<01:44, 304.60 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16194/47780 [00:54<01:54, 274.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16309/47780 [00:54<01:43, 302.93 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15262/47780 [00:54<01:44, 310.19 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15787/47780 [00:54<01:50, 288.33 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17021/47780 [00:54<01:33, 327.81 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16622/47780 [00:54<01:49, 284.83 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15910/47780 [00:54<01:43, 308.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15298/47780 [00:54<01:40, 324.39 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16232/47780 [00:54<01:49, 287.65 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16356/47780 [00:54<01:33, 336.94 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15816/47780 [00:54<01:53, 282.62 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6571/47780 [00:54<02:08, 321.84 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17057/47780 [00:54<01:33, 329.58 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16652/47780 [00:54<01:50, 282.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15942/47780 [00:54<01:44, 304.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15338/47780 [00:54<01:34, 342.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16264/47780 [00:54<01:46, 296.29 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16400/47780 [00:54<01:25, 365.55 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6780/47780 [00:54<01:37, 420.84 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15850/47780 [00:54<01:50, 288.87 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16689/47780 [00:54<01:42, 303.85 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17091/47780 [00:54<01:34, 323.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15974/47780 [00:54<01:48, 293.70 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15374/47780 [00:54<01:35, 339.88 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16297/47780 [00:54<01:44, 302.13 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16438/47780 [00:54<01:25, 365.99 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15884/47780 [00:54<01:45, 303.01 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17124/47780 [00:54<01:34, 323.24 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16723/47780 [00:54<01:41, 306.94 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 16004/47780 [00:54<01:48, 292.90 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16475/47780 [00:55<01:28, 354.79 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16328/47780 [00:55<01:47, 291.31 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15409/47780 [00:54<01:41, 320.48 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17160/47780 [00:55<01:32, 330.08 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16754/47780 [00:55<01:43, 301.10 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15915/47780 [00:55<01:52, 282.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16037/47780 [00:55<01:45, 301.65 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16512/47780 [00:55<01:27, 358.87 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16369/47780 [00:55<01:36, 323.94 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15445/47780 [00:55<01:39, 324.33 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16787/47780 [00:55<01:41, 305.72 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17196/47780 [00:55<01:32, 331.00 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15945/47780 [00:55<01:50, 287.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16070/47780 [00:55<01:42, 309.75 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16405/47780 [00:55<01:34, 332.34 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16550/47780 [00:55<01:30, 344.96 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15977/47780 [00:55<01:48, 293.32 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16832/47780 [00:55<01:31, 339.25 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15478/47780 [00:55<01:48, 298.80 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6935/47780 [00:55<01:43, 396.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17230/47780 [00:55<01:44, 293.22 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16102/47780 [00:55<01:49, 288.93 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16444/47780 [00:55<01:30, 347.23 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16009/47780 [00:55<01:45, 300.65 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16866/47780 [00:55<01:33, 329.71 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15509/47780 [00:55<01:52, 286.64 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16585/47780 [00:55<01:42, 305.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17267/47780 [00:55<01:37, 313.49 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16133/47780 [00:55<01:48, 291.87 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16480/47780 [00:55<01:35, 327.78 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16040/47780 [00:55<01:48, 293.47 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16900/47780 [00:55<01:35, 323.77 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15540/47780 [00:55<01:53, 283.84 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17303/47780 [00:55<01:33, 324.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16618/47780 [00:55<01:46, 293.17 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16163/47780 [00:55<01:49, 287.61 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16517/47780 [00:55<01:34, 332.46 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16071/47780 [00:55<01:46, 298.15 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16941/47780 [00:55<01:30, 340.46 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15569/47780 [00:55<01:56, 276.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16652/47780 [00:55<01:42, 302.62 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17337/47780 [00:55<01:38, 309.46 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16192/47780 [00:55<01:52, 281.62 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7053/47780 [00:55<01:46, 381.87 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16551/47780 [00:55<01:34, 331.66 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16111/47780 [00:55<01:36, 327.50 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16977/47780 [00:55<01:30, 342.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16690/47780 [00:55<01:37, 320.19 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15599/47780 [00:55<01:58, 271.00 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17369/47780 [00:55<01:41, 300.70 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16229/47780 [00:55<01:45, 299.98 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16587/47780 [00:55<01:36, 323.85 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16144/47780 [00:55<01:42, 309.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17023/47780 [00:55<01:22, 370.96 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15633/47780 [00:55<01:53, 283.66 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16723/47780 [00:55<01:42, 302.82 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16261/47780 [00:55<01:43, 305.64 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17401/47780 [00:55<01:49, 277.47 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16624/47780 [00:55<01:35, 326.17 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7146/47780 [00:55<01:46, 381.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16178/47780 [00:55<01:40, 314.75 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17061/47780 [00:55<01:26, 353.36 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16758/47780 [00:55<01:38, 314.66 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16292/47780 [00:55<01:43, 303.65 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15662/47780 [00:55<01:57, 273.11 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17434/47780 [00:55<01:45, 288.36 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16663/47780 [00:55<01:31, 340.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16210/47780 [00:55<01:42, 309.18 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17097/47780 [00:56<01:34, 323.16 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16790/47780 [00:56<01:44, 297.11 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15690/47780 [00:55<02:01, 263.68 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16323/47780 [00:56<01:51, 282.28 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17467/47780 [00:56<01:43, 293.09 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7222/47780 [00:56<01:48, 374.70 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16698/47780 [00:56<01:34, 328.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16243/47780 [00:56<01:40, 315.08 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16821/47780 [00:56<01:44, 297.44 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15720/47780 [00:56<01:59, 267.86 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17130/47780 [00:56<01:38, 311.41 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16357/47780 [00:56<01:47, 293.24 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17503/47780 [00:56<01:37, 309.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16740/47780 [00:56<01:28, 349.92 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16275/47780 [00:56<01:53, 278.24 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16855/47780 [00:56<01:40, 309.21 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7286/47780 [00:56<01:47, 377.08 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15751/47780 [00:56<01:54, 279.45 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16390/47780 [00:56<01:43, 302.21 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17171/47780 [00:56<01:34, 324.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17544/47780 [00:56<01:31, 332.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16776/47780 [00:56<01:34, 326.93 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16304/47780 [00:56<01:56, 269.07 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17210/47780 [00:56<01:30, 338.39 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15780/47780 [00:56<01:59, 266.96 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16422/47780 [00:56<01:45, 297.85 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17590/47780 [00:56<01:22, 364.50 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16887/47780 [00:56<01:50, 280.46 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7343/47780 [00:56<01:46, 380.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16810/47780 [00:56<01:33, 330.26 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17245/47780 [00:56<01:30, 337.45 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15809/47780 [00:56<01:59, 267.73 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16332/47780 [00:56<02:06, 248.70 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16921/47780 [00:56<01:44, 293.96 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17628/47780 [00:56<01:26, 348.99 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16452/47780 [00:56<01:57, 266.90 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16849/47780 [00:56<01:30, 343.26 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7395/47780 [00:56<01:50, 366.59 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17280/47780 [00:56<01:30, 337.50 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16366/47780 [00:56<01:55, 272.26 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16954/47780 [00:56<01:41, 303.10 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15836/47780 [00:56<02:03, 258.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16496/47780 [00:56<01:40, 310.41 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16884/47780 [00:56<01:32, 333.90 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17665/47780 [00:56<01:33, 322.52 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17314/47780 [00:56<01:30, 338.20 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16990/47780 [00:56<01:37, 317.20 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15862/47780 [00:56<02:05, 254.43 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7441/47780 [00:56<01:53, 354.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16395/47780 [00:56<02:00, 260.43 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16532/47780 [00:56<01:38, 316.83 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16918/47780 [00:56<01:33, 331.32 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17698/47780 [00:56<01:35, 314.42 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17349/47780 [00:56<01:29, 341.56 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7484/47780 [00:56<01:51, 362.46 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16428/47780 [00:56<01:54, 273.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17023/47780 [00:56<01:41, 301.63 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16570/47780 [00:56<01:34, 330.95 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16954/47780 [00:56<01:33, 328.93 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17730/47780 [00:56<01:39, 302.77 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15888/47780 [00:56<02:32, 209.23 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17384/47780 [00:56<01:33, 325.14 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7526/47780 [00:56<01:48, 370.99 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16468/47780 [00:56<01:42, 304.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17054/47780 [00:56<01:42, 300.42 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16988/47780 [00:56<01:34, 324.54 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16604/47780 [00:56<01:40, 309.07 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17764/47780 [00:56<01:36, 309.55 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17418/47780 [00:57<01:33, 323.36 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7567/47780 [00:57<01:46, 375.97 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17093/47780 [00:57<01:35, 322.56 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16500/47780 [00:57<01:48, 289.16 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15911/47780 [00:56<02:56, 180.69 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16636/47780 [00:57<01:40, 308.46 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17022/47780 [00:57<01:38, 310.88 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17796/47780 [00:57<01:38, 305.78 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17451/47780 [00:57<01:35, 316.34 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7609/47780 [00:57<01:44, 382.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17131/47780 [00:57<01:32, 331.33 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16539/47780 [00:57<01:41, 308.64 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15972/47780 [00:57<01:54, 278.69 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16668/47780 [00:57<01:41, 305.08 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17071/47780 [00:57<01:26, 357.00 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17827/47780 [00:57<01:38, 303.54 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17489/47780 [00:57<01:32, 327.28 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7650/47780 [00:57<01:42, 389.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17171/47780 [00:57<01:29, 343.28 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16573/47780 [00:57<01:39, 315.06 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 16005/47780 [00:57<01:50, 287.43 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16699/47780 [00:57<01:43, 299.90 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17113/47780 [00:57<01:22, 371.16 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17860/47780 [00:57<01:37, 307.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17528/47780 [00:57<01:28, 342.29 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7692/47780 [00:57<01:46, 377.68 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16605/47780 [00:57<01:42, 302.83 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17206/47780 [00:57<01:36, 315.89 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16736/47780 [00:57<01:38, 315.81 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16037/47780 [00:57<01:56, 273.55 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17151/47780 [00:57<01:27, 349.22 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17891/47780 [00:57<01:43, 288.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17571/47780 [00:57<01:22, 366.29 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7737/47780 [00:57<01:42, 388.91 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17239/47780 [00:57<01:38, 309.99 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16771/47780 [00:57<01:36, 321.98 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16068/47780 [00:57<01:58, 267.20 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17924/47780 [00:57<01:40, 296.82 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17187/47780 [00:57<01:30, 337.39 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17609/47780 [00:57<01:22, 366.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16637/47780 [00:57<02:00, 258.70 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7777/47780 [00:57<01:43, 387.75 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16804/47780 [00:57<01:36, 320.56 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17271/47780 [00:57<01:40, 302.87 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17958/47780 [00:57<01:37, 305.29 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16098/47780 [00:57<01:56, 272.13 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17646/47780 [00:57<01:22, 366.99 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16672/47780 [00:57<01:53, 274.74 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17222/47780 [00:57<01:38, 310.17 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7825/47780 [00:57<01:38, 406.79 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17302/47780 [00:57<01:42, 297.68 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16837/47780 [00:57<01:41, 305.50 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17989/47780 [00:57<01:38, 303.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17683/47780 [00:57<01:26, 349.15 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16127/47780 [00:57<02:04, 253.28 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16705/47780 [00:57<01:50, 281.83 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17266/47780 [00:57<01:29, 340.66 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7880/47780 [00:57<01:30, 439.11 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17332/47780 [00:57<01:42, 295.67 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16870/47780 [00:57<01:41, 305.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18020/47780 [00:57<01:42, 291.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17721/47780 [00:57<01:25, 352.22 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16734/47780 [00:57<01:50, 281.08 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7925/47780 [00:57<01:30, 441.65 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16154/47780 [00:57<02:07, 247.39 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17301/47780 [00:57<01:33, 325.37 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17362/47780 [00:57<01:45, 287.07 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16903/47780 [00:57<01:39, 309.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18050/47780 [00:57<01:44, 284.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16764/47780 [00:57<01:48, 286.15 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17764/47780 [00:57<01:22, 362.21 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16180/47780 [00:57<02:11, 240.46 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7971/47780 [00:58<01:40, 396.94 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17335/47780 [00:58<01:40, 303.59 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17394/47780 [00:58<01:43, 293.09 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16935/47780 [00:58<01:39, 308.65 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18080/47780 [00:58<01:42, 288.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17805/47780 [00:58<01:19, 375.69 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16794/47780 [00:58<01:51, 277.23 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16205/47780 [00:58<02:19, 226.62 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8018/47780 [00:58<01:36, 412.40 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17373/47780 [00:58<01:36, 316.72 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16969/47780 [00:58<01:38, 314.07 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17424/47780 [00:58<01:51, 273.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18116/47780 [00:58<01:35, 309.22 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17843/47780 [00:58<01:24, 356.37 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16823/47780 [00:58<02:01, 255.75 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16230/47780 [00:58<02:15, 232.65 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8061/47780 [00:58<01:38, 403.71 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17406/47780 [00:58<01:36, 313.45 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17005/47780 [00:58<01:36, 319.92 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18151/47780 [00:58<01:33, 317.34 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17453/47780 [00:58<01:53, 267.54 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17882/47780 [00:58<01:22, 364.36 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16855/47780 [00:58<01:53, 272.70 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16262/47780 [00:58<02:04, 253.51 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8108/47780 [00:58<01:34, 417.61 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17444/47780 [00:58<01:31, 331.36 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18183/47780 [00:58<01:34, 314.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17480/47780 [00:58<01:53, 266.54 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17919/47780 [00:58<01:26, 344.42 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16297/47780 [00:58<01:53, 277.14 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17038/47780 [00:58<01:58, 259.78 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16883/47780 [00:58<01:55, 268.31 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17484/47780 [00:58<01:26, 350.52 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8152/47780 [00:58<01:35, 414.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18215/47780 [00:58<01:35, 308.85 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17510/47780 [00:58<01:54, 264.30 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17954/47780 [00:58<01:28, 337.91 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16918/47780 [00:58<01:47, 288.33 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17094/47780 [00:58<01:32, 331.39 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16326/47780 [00:58<01:54, 274.60 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17520/47780 [00:58<01:31, 330.80 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8194/47780 [00:58<01:42, 385.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18250/47780 [00:58<01:33, 317.11 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17539/47780 [00:58<01:53, 265.65 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17989/47780 [00:58<01:28, 337.49 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16953/47780 [00:58<01:40, 305.64 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16358/47780 [00:58<01:49, 285.69 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17130/47780 [00:58<01:35, 321.41 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8238/47780 [00:58<01:38, 400.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18284/47780 [00:58<01:31, 323.49 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17568/47780 [00:58<01:54, 263.53 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16984/47780 [00:58<01:41, 302.91 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18023/47780 [00:58<01:34, 313.42 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17168/47780 [00:58<01:31, 333.87 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16387/47780 [00:58<02:01, 258.86 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17555/47780 [00:58<02:00, 250.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18317/47780 [00:58<01:34, 313.27 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8279/47780 [00:58<01:46, 370.35 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17600/47780 [00:58<01:51, 269.93 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17017/47780 [00:58<01:41, 304.15 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17207/47780 [00:58<01:28, 345.38 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18055/47780 [00:58<01:37, 305.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16414/47780 [00:58<02:03, 253.69 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18371/47780 [00:58<01:19, 371.37 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8322/47780 [00:58<01:42, 386.34 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17632/47780 [00:58<01:48, 276.89 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17054/47780 [00:58<01:35, 320.35 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17243/47780 [00:58<01:27, 348.90 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17585/47780 [00:58<02:17, 219.79 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18090/47780 [00:58<01:35, 310.67 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16446/47780 [00:58<01:56, 268.64 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18409/47780 [00:59<01:22, 357.43 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8362/47780 [00:59<01:45, 373.20 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17660/47780 [00:59<01:49, 275.73 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17087/47780 [00:59<01:40, 304.43 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17670/47780 [00:59<01:25, 351.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17279/47780 [00:59<01:33, 326.46 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16474/47780 [00:59<02:00, 260.41 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18445/47780 [00:59<01:24, 346.22 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8400/47780 [00:59<01:48, 363.23 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17688/47780 [00:59<01:49, 274.03 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18122/47780 [00:59<01:54, 258.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17313/47780 [00:59<01:32, 330.07 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17118/47780 [00:59<01:51, 275.34 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16503/47780 [00:59<01:56, 268.41 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18484/47780 [00:59<01:22, 354.83 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17712/47780 [00:59<01:34, 319.61 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8441/47780 [00:59<01:46, 370.22 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17719/47780 [00:59<01:48, 278.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18193/47780 [00:59<01:20, 369.64 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16533/47780 [00:59<01:53, 274.28 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17152/47780 [00:59<01:46, 286.49 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18523/47780 [00:59<01:21, 360.73 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17749/47780 [00:59<01:33, 322.71 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17756/47780 [00:59<01:39, 300.87 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8481/47780 [00:59<01:50, 356.57 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17347/47780 [00:59<01:57, 258.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18234/47780 [00:59<01:26, 341.46 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16561/47780 [00:59<01:57, 266.39 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17182/47780 [00:59<01:48, 281.02 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18561/47780 [00:59<01:20, 364.48 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17785/47780 [00:59<01:30, 330.27 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8540/47780 [00:59<01:33, 420.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18271/47780 [00:59<01:26, 341.46 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17213/47780 [00:59<01:45, 288.78 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16590/47780 [00:59<01:55, 270.21 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17787/47780 [00:59<02:04, 240.02 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17376/47780 [00:59<02:07, 238.04 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18598/47780 [00:59<01:22, 354.95 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8583/47780 [00:59<01:36, 405.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17821/47780 [00:59<01:39, 302.23 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18309/47780 [00:59<01:29, 329.26 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16626/47780 [00:59<01:46, 293.44 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17436/47780 [00:59<01:34, 319.96 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17846/47780 [00:59<01:32, 322.67 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17243/47780 [00:59<01:55, 265.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8625/47780 [00:59<01:42, 383.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17854/47780 [00:59<01:41, 293.89 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18634/47780 [00:59<01:42, 284.72 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18350/47780 [00:59<01:26, 341.50 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16656/47780 [00:59<01:48, 287.88 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17896/47780 [00:59<01:21, 368.00 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17472/47780 [00:59<01:33, 323.37 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17272/47780 [00:59<01:53, 268.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8664/47780 [00:59<01:45, 369.45 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18708/47780 [00:59<01:13, 393.36 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18389/47780 [00:59<01:23, 350.59 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17885/47780 [00:59<01:48, 276.31 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16685/47780 [00:59<01:51, 278.99 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17507/47780 [00:59<01:34, 320.34 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17301/47780 [00:59<01:52, 271.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17936/47780 [00:59<01:25, 349.89 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8709/47780 [01:00<01:42, 382.98 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18429/47780 [00:59<01:21, 360.21 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17921/47780 [00:59<01:41, 294.53 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18752/47780 [00:59<01:14, 389.41 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16721/47780 [00:59<01:45, 295.16 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17330/47780 [00:59<01:54, 264.94 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17541/47780 [00:59<01:39, 303.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17974/47780 [01:00<01:30, 330.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8753/47780 [01:00<01:39, 393.70 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17952/47780 [01:00<01:41, 292.57 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18794/47780 [01:00<01:16, 380.34 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16756/47780 [01:00<01:43, 300.47 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18466/47780 [01:00<01:27, 333.23 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17359/47780 [01:00<01:53, 269.01 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17573/47780 [01:00<01:41, 296.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18010/47780 [01:00<01:31, 326.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8795/47780 [01:00<01:38, 397.14 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17985/47780 [01:00<01:39, 299.31 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16794/47780 [01:00<01:37, 319.40 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18502/47780 [01:00<01:26, 336.92 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17390/47780 [01:00<01:49, 277.39 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18834/47780 [01:00<01:22, 352.69 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17606/47780 [01:00<01:40, 300.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18046/47780 [01:00<01:29, 333.38 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8835/47780 [01:00<01:42, 381.28 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16828/47780 [01:00<01:35, 325.24 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18016/47780 [01:00<01:42, 289.49 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18537/47780 [01:00<01:28, 329.60 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17428/47780 [01:00<01:40, 303.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18081/47780 [01:00<01:27, 337.70 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18871/47780 [01:00<01:28, 327.33 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17637/47780 [01:00<01:46, 281.92 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8879/47780 [01:00<01:37, 397.12 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16863/47780 [01:00<01:33, 332.36 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18571/47780 [01:00<01:31, 318.48 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18046/47780 [01:00<01:50, 268.00 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17459/47780 [01:00<01:45, 288.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18117/47780 [01:00<01:28, 336.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18906/47780 [01:00<01:26, 333.00 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8924/47780 [01:00<01:34, 412.01 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17674/47780 [01:00<01:43, 289.91 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16897/47780 [01:00<01:42, 301.19 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18604/47780 [01:00<01:31, 318.26 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18075/47780 [01:00<01:50, 269.02 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17496/47780 [01:00<01:38, 307.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18152/47780 [01:00<01:28, 336.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18951/47780 [01:00<01:20, 360.06 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8968/47780 [01:00<01:38, 393.13 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17705/47780 [01:00<01:46, 283.40 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16935/47780 [01:00<01:35, 322.68 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18103/47780 [01:00<01:53, 260.62 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18637/47780 [01:00<01:36, 300.52 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17528/47780 [01:00<01:42, 295.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18988/47780 [01:00<01:20, 357.82 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18186/47780 [01:00<01:37, 302.86 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9008/47780 [01:00<01:39, 390.34 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17734/47780 [01:00<01:46, 281.70 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16977/47780 [01:00<01:28, 349.96 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18138/47780 [01:00<01:45, 281.82 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18681/47780 [01:00<01:27, 331.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19030/47780 [01:00<01:17, 371.82 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17558/47780 [01:00<01:45, 286.07 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18223/47780 [01:00<01:33, 317.41 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9048/47780 [01:00<01:40, 384.35 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17763/47780 [01:00<01:51, 269.60 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17014/47780 [01:00<01:27, 353.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18170/47780 [01:00<01:42, 289.15 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17587/47780 [01:00<01:45, 287.08 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19068/47780 [01:00<01:20, 358.28 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18715/47780 [01:00<01:32, 313.60 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18256/47780 [01:00<01:32, 317.83 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17791/47780 [01:00<01:50, 272.04 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9087/47780 [01:00<01:47, 361.40 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17050/47780 [01:00<01:29, 343.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18200/47780 [01:00<01:42, 288.29 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18756/47780 [01:00<01:25, 339.54 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17616/47780 [01:00<01:51, 269.60 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19105/47780 [01:00<01:24, 338.92 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18289/47780 [01:01<01:39, 297.02 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17819/47780 [01:01<01:54, 262.54 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9124/47780 [01:01<01:54, 337.65 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17085/47780 [01:00<01:33, 326.84 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18230/47780 [01:01<01:42, 289.07 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17648/47780 [01:01<01:47, 280.59 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18791/47780 [01:01<01:27, 329.59 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19141/47780 [01:01<01:24, 337.35 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17849/47780 [01:01<01:50, 270.33 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18327/47780 [01:01<01:35, 307.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9159/47780 [01:01<01:56, 330.81 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17119/47780 [01:01<01:35, 319.78 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18269/47780 [01:01<01:34, 310.87 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17686/47780 [01:01<01:37, 308.20 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18826/47780 [01:01<01:26, 333.38 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19176/47780 [01:01<01:26, 329.85 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18367/47780 [01:01<01:29, 328.63 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17877/47780 [01:01<01:52, 266.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9200/47780 [01:01<01:50, 348.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18306/47780 [01:01<01:31, 323.53 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17160/47780 [01:01<01:31, 333.72 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17720/47780 [01:01<01:36, 310.70 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18860/47780 [01:01<01:33, 310.79 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18404/47780 [01:01<01:26, 339.78 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19210/47780 [01:01<01:31, 312.76 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17904/47780 [01:01<01:57, 253.71 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9236/47780 [01:01<01:52, 344.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18342/47780 [01:01<01:28, 333.55 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17194/47780 [01:01<01:35, 320.98 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17759/47780 [01:01<01:31, 329.23 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18892/47780 [01:01<01:34, 306.60 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18440/47780 [01:01<01:25, 342.03 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19242/47780 [01:01<01:31, 313.54 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17932/47780 [01:01<01:55, 258.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9271/47780 [01:01<01:51, 345.68 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18376/47780 [01:01<01:29, 328.64 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17228/47780 [01:01<01:35, 319.22 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17798/47780 [01:01<01:27, 342.71 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19274/47780 [01:01<01:32, 308.90 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18924/47780 [01:01<01:39, 290.86 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17960/47780 [01:01<01:52, 264.19 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9306/47780 [01:01<01:52, 343.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18475/47780 [01:01<01:34, 308.97 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18410/47780 [01:01<01:29, 327.76 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17261/47780 [01:01<01:36, 317.48 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17834/47780 [01:01<01:32, 324.97 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18955/47780 [01:01<01:37, 295.00 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17992/47780 [01:01<01:46, 280.09 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19306/47780 [01:01<01:35, 298.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9344/47780 [01:01<01:49, 349.61 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18507/47780 [01:01<01:38, 295.74 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18443/47780 [01:01<01:34, 310.41 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17873/47780 [01:01<01:28, 339.60 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17293/47780 [01:01<01:42, 296.21 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18021/47780 [01:01<01:47, 276.80 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18985/47780 [01:01<01:40, 287.82 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19351/47780 [01:01<01:24, 336.88 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9387/47780 [01:01<01:44, 367.95 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18475/47780 [01:01<01:35, 306.44 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18538/47780 [01:01<01:40, 290.18 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17326/47780 [01:01<01:39, 305.28 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18052/47780 [01:01<01:44, 283.15 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19016/47780 [01:01<01:39, 287.76 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19385/47780 [01:01<01:25, 331.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9424/47780 [01:01<01:45, 364.40 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17909/47780 [01:01<01:45, 284.41 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18509/47780 [01:01<01:32, 315.76 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18570/47780 [01:01<01:38, 295.25 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17369/47780 [01:01<01:31, 332.88 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18085/47780 [01:01<01:41, 293.20 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19048/47780 [01:01<01:37, 293.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9466/47780 [01:02<01:41, 376.67 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19420/47780 [01:01<01:27, 324.51 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18550/47780 [01:02<01:27, 333.07 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17956/47780 [01:02<01:32, 321.16 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18600/47780 [01:02<01:43, 281.26 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17409/47780 [01:01<01:27, 347.79 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18117/47780 [01:02<01:39, 297.46 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9520/47780 [01:02<01:31, 419.34 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19078/47780 [01:02<01:40, 285.65 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19453/47780 [01:02<01:29, 315.56 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18586/47780 [01:02<01:25, 340.71 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18630/47780 [01:02<01:42, 283.18 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17449/47780 [01:02<01:26, 350.69 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17990/47780 [01:02<01:41, 292.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18147/47780 [01:02<01:42, 290.08 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19107/47780 [01:02<01:41, 283.70 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9562/47780 [01:02<01:34, 405.45 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19494/47780 [01:02<01:23, 338.11 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18621/47780 [01:02<01:30, 322.94 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18664/47780 [01:02<01:39, 292.44 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17488/47780 [01:02<01:25, 353.79 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18021/47780 [01:02<01:41, 292.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18177/47780 [01:02<01:42, 287.48 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19528/47780 [01:02<01:23, 338.29 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19136/47780 [01:02<01:45, 272.71 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9603/47780 [01:02<01:38, 388.72 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18654/47780 [01:02<01:31, 318.40 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18698/47780 [01:02<01:35, 304.85 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18052/47780 [01:02<01:41, 292.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17524/47780 [01:02<01:29, 336.58 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18206/47780 [01:02<01:46, 278.78 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19562/47780 [01:02<01:24, 334.81 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19171/47780 [01:02<01:39, 288.20 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9643/47780 [01:02<01:41, 374.71 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18736/47780 [01:02<01:29, 323.56 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17562/47780 [01:02<01:27, 346.41 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18686/47780 [01:02<01:41, 286.48 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18082/47780 [01:02<01:44, 282.99 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18238/47780 [01:02<01:44, 284.02 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19204/47780 [01:02<01:36, 296.62 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19596/47780 [01:02<01:27, 321.84 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9685/47780 [01:02<01:39, 383.47 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18769/47780 [01:02<01:36, 301.14 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17597/47780 [01:02<01:28, 341.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18118/47780 [01:02<01:38, 299.93 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19632/47780 [01:02<01:24, 332.05 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19238/47780 [01:02<01:34, 302.06 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18716/47780 [01:02<01:51, 261.55 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18267/47780 [01:02<01:50, 267.50 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9724/47780 [01:02<01:42, 372.70 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18800/47780 [01:02<01:39, 290.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18149/47780 [01:02<01:37, 302.48 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17632/47780 [01:02<01:30, 332.95 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19666/47780 [01:02<01:24, 330.91 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18762/47780 [01:02<01:33, 309.90 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19277/47780 [01:02<01:28, 323.50 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18299/47780 [01:02<01:45, 279.11 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9765/47780 [01:02<01:41, 374.77 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18180/47780 [01:02<01:37, 304.50 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17666/47780 [01:02<01:31, 327.51 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18830/47780 [01:02<01:44, 278.19 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19700/47780 [01:02<01:28, 319.04 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18332/47780 [01:02<01:42, 286.67 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18795/47780 [01:02<01:37, 296.33 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9803/47780 [01:02<01:43, 367.66 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19310/47780 [01:02<01:35, 298.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18211/47780 [01:02<01:40, 294.12 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17699/47780 [01:02<01:37, 307.50 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18832/47780 [01:02<01:31, 315.64 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18859/47780 [01:02<01:55, 251.38 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18361/47780 [01:02<01:44, 281.05 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19733/47780 [01:02<01:30, 308.99 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19343/47780 [01:02<01:33, 303.45 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9845/47780 [01:03<01:41, 374.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18241/47780 [01:02<01:41, 290.51 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17730/47780 [01:02<01:38, 304.40 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18886/47780 [01:03<01:55, 251.17 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19770/47780 [01:03<01:27, 321.60 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18390/47780 [01:03<01:47, 273.06 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18865/47780 [01:03<01:34, 305.60 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19380/47780 [01:03<01:31, 311.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9883/47780 [01:03<01:48, 348.32 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18271/47780 [01:03<01:44, 283.34 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17761/47780 [01:03<01:40, 299.52 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18928/47780 [01:03<01:38, 292.63 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19803/47780 [01:03<01:28, 316.81 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18423/47780 [01:03<01:44, 281.20 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19414/47780 [01:03<01:29, 316.00 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18903/47780 [01:03<01:32, 312.87 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9919/47780 [01:03<01:47, 351.20 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18307/47780 [01:03<01:38, 299.16 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17792/47780 [01:03<01:39, 302.33 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19842/47780 [01:03<01:25, 326.39 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19446/47780 [01:03<01:30, 313.60 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18452/47780 [01:03<01:49, 268.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9956/47780 [01:03<01:48, 348.92 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18935/47780 [01:03<01:41, 284.00 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17831/47780 [01:03<01:31, 327.39 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18338/47780 [01:03<01:44, 282.78 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19882/47780 [01:03<01:20, 346.73 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18959/47780 [01:03<02:08, 224.25 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19478/47780 [01:03<01:31, 308.31 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18485/47780 [01:03<01:44, 279.35 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18967/47780 [01:03<01:39, 290.26 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9992/47780 [01:03<01:54, 329.52 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17869/47780 [01:03<01:29, 335.17 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18369/47780 [01:03<01:42, 287.37 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19030/47780 [01:03<01:26, 331.34 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19520/47780 [01:03<01:24, 336.33 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19917/47780 [01:03<01:27, 316.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18514/47780 [01:03<01:49, 267.35 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18998/47780 [01:03<01:37, 295.35 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10030/47780 [01:03<01:50, 342.11 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17903/47780 [01:03<01:34, 317.83 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18398/47780 [01:03<01:46, 275.57 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19555/47780 [01:03<01:23, 336.31 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19070/47780 [01:03<01:28, 325.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19950/47780 [01:03<01:29, 312.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19032/47780 [01:03<01:34, 304.58 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10076/47780 [01:03<01:42, 368.52 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18548/47780 [01:03<01:46, 275.45 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18426/47780 [01:03<01:48, 270.48 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17936/47780 [01:03<01:35, 310.89 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19590/47780 [01:03<01:23, 339.12 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19063/47780 [01:03<01:34, 305.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19982/47780 [01:03<01:30, 306.44 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19107/47780 [01:03<01:29, 321.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10115/47780 [01:03<01:40, 374.46 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18580/47780 [01:03<01:43, 281.31 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17968/47780 [01:03<01:37, 306.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18454/47780 [01:03<01:49, 267.39 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19103/47780 [01:03<01:28, 325.87 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19624/47780 [01:03<01:32, 304.77 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18616/47780 [01:03<01:36, 302.83 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19142/47780 [01:03<01:30, 315.65 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20013/47780 [01:03<01:35, 291.85 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10153/47780 [01:03<01:45, 355.84 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18481/47780 [01:03<01:51, 262.63 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17999/47780 [01:03<01:42, 291.30 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19136/47780 [01:03<01:27, 326.84 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19656/47780 [01:03<01:31, 305.83 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20047/47780 [01:03<01:31, 302.38 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10189/47780 [01:04<01:45, 355.83 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19176/47780 [01:03<01:32, 309.19 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18647/47780 [01:03<01:45, 276.82 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18508/47780 [01:03<01:54, 255.97 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18034/47780 [01:03<01:37, 304.34 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10230/47780 [01:04<01:43, 364.05 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20078/47780 [01:04<01:33, 294.72 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19178/47780 [01:04<01:27, 327.37 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19688/47780 [01:04<01:36, 290.16 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19209/47780 [01:04<01:35, 299.55 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18676/47780 [01:04<01:44, 277.50 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18537/47780 [01:04<01:50, 265.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18076/47780 [01:04<01:29, 333.04 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20110/47780 [01:04<01:31, 301.74 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19216/47780 [01:04<01:24, 338.24 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10267/47780 [01:04<01:45, 357.22 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19724/47780 [01:04<01:32, 302.78 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19240/47780 [01:04<01:38, 289.60 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18565/47780 [01:04<01:49, 266.65 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18705/47780 [01:04<01:51, 260.83 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18116/47780 [01:04<01:24, 351.94 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20147/47780 [01:04<01:27, 317.57 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19250/47780 [01:04<01:25, 335.09 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10311/47780 [01:04<01:39, 375.44 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19755/47780 [01:04<01:35, 294.11 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19271/47780 [01:04<01:37, 292.07 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18732/47780 [01:04<01:50, 263.13 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18598/47780 [01:04<01:43, 281.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18158/47780 [01:04<01:20, 367.39 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20186/47780 [01:04<01:22, 334.53 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19285/47780 [01:04<01:24, 339.19 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19789/47780 [01:04<01:31, 306.63 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10351/47780 [01:04<01:44, 359.13 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19303/47780 [01:04<01:36, 296.25 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18198/47780 [01:04<01:18, 376.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18628/47780 [01:04<01:45, 276.87 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20220/47780 [01:04<01:24, 324.94 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18759/47780 [01:04<02:12, 219.25 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19820/47780 [01:04<01:32, 301.87 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10392/47780 [01:04<01:41, 369.20 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19320/47780 [01:04<01:30, 313.45 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19333/47780 [01:04<01:35, 297.01 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18656/47780 [01:04<01:47, 271.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18236/47780 [01:04<01:21, 360.37 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20255/47780 [01:04<01:22, 331.99 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10438/47780 [01:04<01:36, 386.11 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19367/47780 [01:04<01:31, 309.15 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19353/47780 [01:04<01:32, 307.81 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19851/47780 [01:04<01:41, 276.05 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18276/47780 [01:04<01:20, 367.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18687/47780 [01:04<01:47, 270.53 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18783/47780 [01:04<02:32, 190.60 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20289/47780 [01:04<01:23, 329.92 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10478/47780 [01:04<01:37, 381.45 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19399/47780 [01:04<01:32, 305.45 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19385/47780 [01:04<01:32, 307.75 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19888/47780 [01:04<01:33, 297.94 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18320/47780 [01:04<01:15, 388.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18718/47780 [01:04<01:43, 280.34 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20326/47780 [01:04<01:22, 334.26 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18804/47780 [01:04<02:44, 175.67 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19421/47780 [01:04<01:28, 318.85 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10517/47780 [01:04<01:40, 371.32 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19430/47780 [01:04<01:35, 296.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19919/47780 [01:04<01:32, 299.79 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18360/47780 [01:04<01:21, 362.58 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18747/47780 [01:04<01:49, 266.11 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20368/47780 [01:04<01:17, 354.98 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19464/47780 [01:04<01:21, 346.50 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10559/47780 [01:05<01:36, 384.96 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18823/47780 [01:04<02:50, 169.64 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19957/47780 [01:04<01:26, 320.34 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19460/47780 [01:04<01:38, 287.95 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18397/47780 [01:04<01:21, 360.62 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18774/47780 [01:04<01:52, 256.83 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20404/47780 [01:05<01:17, 352.00 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19501/47780 [01:05<01:20, 349.24 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18841/47780 [01:05<02:50, 170.17 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10598/47780 [01:05<01:39, 373.57 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19990/47780 [01:05<01:31, 302.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19489/47780 [01:05<01:44, 269.92 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18437/47780 [01:05<01:19, 371.37 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18800/47780 [01:05<01:53, 256.40 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20440/47780 [01:05<01:17, 354.15 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19542/47780 [01:05<01:17, 366.50 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18942/47780 [01:05<01:16, 377.15 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10636/47780 [01:05<01:44, 355.28 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20025/47780 [01:05<01:29, 309.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19517/47780 [01:05<01:45, 267.26 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18475/47780 [01:05<01:24, 348.85 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18826/47780 [01:05<01:57, 246.61 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20478/47780 [01:05<01:16, 358.10 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19579/47780 [01:05<01:19, 355.25 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10673/47780 [01:05<01:43, 359.27 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19549/47780 [01:05<01:40, 281.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20057/47780 [01:05<01:29, 308.11 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18852/47780 [01:05<01:55, 250.33 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20514/47780 [01:05<01:17, 350.42 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18984/47780 [01:05<01:31, 315.65 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19616/47780 [01:05<01:18, 359.40 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18511/47780 [01:05<01:35, 307.75 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10710/47780 [01:05<01:42, 362.08 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19578/47780 [01:05<01:39, 283.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20089/47780 [01:05<01:30, 307.51 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18879/47780 [01:05<01:52, 255.82 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20550/47780 [01:05<01:18, 348.76 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19653/47780 [01:05<01:18, 358.43 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19020/47780 [01:05<01:32, 311.12 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18547/47780 [01:05<01:32, 317.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10747/47780 [01:05<01:46, 347.24 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19607/47780 [01:05<01:43, 273.30 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20120/47780 [01:05<01:32, 298.73 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18909/47780 [01:05<01:48, 265.63 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20585/47780 [01:05<01:19, 341.49 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18580/47780 [01:05<01:33, 312.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10801/47780 [01:05<01:32, 398.63 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19637/47780 [01:05<01:41, 277.71 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20153/47780 [01:05<01:30, 304.20 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19689/47780 [01:05<01:29, 314.96 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19055/47780 [01:05<01:40, 285.08 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18936/47780 [01:05<01:52, 257.17 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20620/47780 [01:05<01:20, 336.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18613/47780 [01:05<01:33, 310.47 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10844/47780 [01:05<01:33, 393.48 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19728/47780 [01:05<01:23, 334.92 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19668/47780 [01:05<01:39, 283.63 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20184/47780 [01:05<01:33, 295.58 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19086/47780 [01:05<01:41, 283.16 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18963/47780 [01:05<01:51, 258.75 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20654/47780 [01:05<01:24, 322.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18647/47780 [01:05<01:31, 318.50 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19764/47780 [01:05<01:23, 334.44 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20215/47780 [01:05<01:32, 296.51 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19697/47780 [01:05<01:43, 270.83 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19116/47780 [01:05<01:44, 273.13 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18989/47780 [01:05<01:57, 244.48 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20687/47780 [01:05<01:23, 324.01 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10884/47780 [01:05<01:54, 321.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18680/47780 [01:05<01:34, 309.31 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19801/47780 [01:05<01:22, 340.53 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20248/47780 [01:05<01:30, 305.77 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19726/47780 [01:05<01:44, 269.32 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19146/47780 [01:05<01:43, 277.54 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19014/47780 [01:05<02:01, 235.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10923/47780 [01:06<01:49, 336.53 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20720/47780 [01:06<01:34, 286.99 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18712/47780 [01:05<01:36, 300.45 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19838/47780 [01:06<01:22, 337.49 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20279/47780 [01:06<01:33, 293.34 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19754/47780 [01:06<01:48, 257.97 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19176/47780 [01:06<01:43, 277.69 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19052/47780 [01:06<01:46, 269.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10959/47780 [01:06<01:49, 335.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20755/47780 [01:06<01:29, 303.58 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18743/47780 [01:06<01:43, 281.56 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20314/47780 [01:06<01:30, 302.93 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19782/47780 [01:06<01:46, 263.97 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19873/47780 [01:06<01:27, 319.39 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19208/47780 [01:06<01:39, 286.07 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19080/47780 [01:06<01:51, 257.84 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10996/47780 [01:06<01:49, 335.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20789/47780 [01:06<01:26, 313.50 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18774/47780 [01:06<01:41, 286.17 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20355/47780 [01:06<01:23, 329.55 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19906/47780 [01:06<01:28, 315.43 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19811/47780 [01:06<01:45, 265.29 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19239/47780 [01:06<01:48, 263.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19114/47780 [01:06<01:43, 277.88 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20821/47780 [01:06<01:28, 305.17 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11031/47780 [01:06<01:53, 323.66 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18810/47780 [01:06<01:34, 306.48 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20389/47780 [01:06<01:26, 318.04 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19840/47780 [01:06<01:42, 272.26 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19938/47780 [01:06<01:27, 316.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19277/47780 [01:06<01:38, 288.02 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19143/47780 [01:06<01:46, 269.20 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20855/47780 [01:06<01:26, 311.44 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11071/47780 [01:06<01:47, 340.40 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18848/47780 [01:06<01:30, 319.98 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19871/47780 [01:06<01:39, 279.94 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19984/47780 [01:06<01:17, 357.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20421/47780 [01:06<01:27, 311.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19308/47780 [01:06<01:39, 284.83 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19171/47780 [01:06<01:45, 272.18 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20887/47780 [01:06<01:26, 310.24 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11106/47780 [01:06<01:50, 332.49 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18889/47780 [01:06<01:25, 337.79 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19902/47780 [01:06<01:37, 285.32 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20021/47780 [01:06<01:18, 351.50 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20453/47780 [01:06<01:34, 287.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19347/47780 [01:06<01:30, 313.20 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20926/47780 [01:06<01:21, 329.34 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19199/47780 [01:06<01:50, 259.73 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11141/47780 [01:06<01:49, 333.63 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18924/47780 [01:06<01:27, 330.06 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19931/47780 [01:06<01:39, 280.24 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20057/47780 [01:06<01:25, 325.43 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20489/47780 [01:06<01:31, 297.88 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19381/47780 [01:06<01:28, 320.65 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20962/47780 [01:06<01:19, 338.12 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11184/47780 [01:06<01:41, 360.49 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19228/47780 [01:06<01:48, 262.26 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19963/47780 [01:06<01:35, 291.30 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18958/47780 [01:06<01:29, 322.01 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20091/47780 [01:06<01:25, 325.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19414/47780 [01:06<01:27, 323.17 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20528/47780 [01:06<01:28, 306.29 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20999/47780 [01:06<01:17, 343.45 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11229/47780 [01:06<01:34, 386.09 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19257/47780 [01:06<01:45, 270.00 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19993/47780 [01:06<01:37, 284.24 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18991/47780 [01:06<01:34, 303.81 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20124/47780 [01:06<01:26, 319.54 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20559/47780 [01:06<01:29, 304.12 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21041/47780 [01:06<01:14, 357.47 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11269/47780 [01:07<01:35, 381.39 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19447/47780 [01:06<01:39, 285.20 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20022/47780 [01:07<01:39, 278.07 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19022/47780 [01:06<01:35, 301.44 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20159/47780 [01:07<01:24, 328.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19288/47780 [01:06<02:00, 235.54 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20600/47780 [01:07<01:21, 333.30 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11313/47780 [01:07<01:31, 398.03 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21077/47780 [01:07<01:18, 341.93 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19480/47780 [01:07<01:38, 288.21 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20050/47780 [01:07<01:42, 271.14 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19330/47780 [01:07<01:41, 279.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19053/47780 [01:07<01:37, 294.04 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20193/47780 [01:07<01:29, 307.50 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20637/47780 [01:07<01:19, 339.79 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11354/47780 [01:07<01:32, 392.26 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19510/47780 [01:07<01:42, 276.16 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21112/47780 [01:07<01:26, 309.67 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20081/47780 [01:07<01:39, 279.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19360/47780 [01:07<01:41, 278.78 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19083/47780 [01:07<01:43, 277.62 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20672/47780 [01:07<01:20, 335.07 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11396/47780 [01:07<01:31, 399.18 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19546/47780 [01:07<01:35, 295.95 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21151/47780 [01:07<01:20, 330.85 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20225/47780 [01:07<01:46, 259.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20113/47780 [01:07<01:36, 286.84 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19392/47780 [01:07<01:40, 281.17 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20709/47780 [01:07<01:18, 345.02 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19118/47780 [01:07<01:38, 291.34 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11437/47780 [01:07<01:39, 364.51 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21187/47780 [01:07<01:19, 335.23 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19577/47780 [01:07<01:36, 292.71 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20264/47780 [01:07<01:35, 286.88 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20142/47780 [01:07<01:40, 275.10 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20744/47780 [01:07<01:18, 342.25 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19421/47780 [01:07<01:48, 260.97 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19148/47780 [01:07<01:45, 272.59 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11486/47780 [01:07<01:31, 395.60 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19607/47780 [01:07<01:37, 288.82 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20295/47780 [01:07<01:36, 285.06 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21222/47780 [01:07<01:24, 314.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20172/47780 [01:07<01:38, 280.80 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20779/47780 [01:07<01:21, 333.16 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19448/47780 [01:07<01:49, 259.92 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19180/47780 [01:07<01:41, 282.20 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11527/47780 [01:07<01:31, 394.44 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21268/47780 [01:07<01:15, 352.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20325/47780 [01:07<01:37, 281.33 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20201/47780 [01:07<01:41, 272.27 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19637/47780 [01:07<01:49, 256.09 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19477/47780 [01:07<01:49, 257.57 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20813/47780 [01:07<01:26, 310.17 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19209/47780 [01:07<01:47, 265.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11568/47780 [01:07<01:34, 382.40 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21306/47780 [01:07<01:16, 345.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20354/47780 [01:07<01:40, 271.88 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20229/47780 [01:07<01:48, 254.33 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20846/47780 [01:07<01:25, 315.35 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19504/47780 [01:07<01:49, 258.13 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11607/47780 [01:07<01:39, 364.19 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19664/47780 [01:07<02:12, 212.58 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19236/47780 [01:07<02:00, 236.94 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20393/47780 [01:07<01:30, 302.92 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20258/47780 [01:07<01:46, 258.40 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21342/47780 [01:07<01:25, 309.42 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19532/47780 [01:07<01:47, 264.00 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20878/47780 [01:07<01:35, 281.78 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11644/47780 [01:08<01:44, 346.67 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19700/47780 [01:07<01:55, 242.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19271/47780 [01:07<01:49, 260.87 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20424/47780 [01:07<01:32, 295.82 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20293/47780 [01:07<01:38, 279.09 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19559/47780 [01:07<01:47, 263.02 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21382/47780 [01:07<01:20, 329.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20907/47780 [01:08<01:34, 283.93 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19726/47780 [01:08<01:58, 236.57 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19310/47780 [01:08<01:41, 280.08 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20455/47780 [01:08<01:36, 283.88 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11679/47780 [01:08<01:53, 318.39 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19590/47780 [01:08<01:43, 273.26 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21418/47780 [01:08<01:19, 333.68 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20322/47780 [01:08<01:42, 268.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20936/47780 [01:08<01:37, 273.92 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19771/47780 [01:08<01:38, 285.50 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19344/47780 [01:08<01:36, 295.59 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20492/47780 [01:08<01:29, 305.69 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11716/47780 [01:08<01:50, 327.56 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21455/47780 [01:08<01:16, 343.33 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19619/47780 [01:08<01:42, 274.98 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20353/47780 [01:08<01:38, 277.07 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20964/47780 [01:08<01:42, 261.43 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19377/47780 [01:08<01:34, 301.88 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20524/47780 [01:08<01:30, 301.39 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19654/47780 [01:08<01:34, 296.62 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19802/47780 [01:08<01:41, 274.52 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11751/47780 [01:08<01:51, 321.79 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20382/47780 [01:08<01:37, 280.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21491/47780 [01:08<01:23, 313.06 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20994/47780 [01:08<01:39, 268.83 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19410/47780 [01:08<01:31, 309.49 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20556/47780 [01:08<01:28, 306.50 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19685/47780 [01:08<01:33, 300.51 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19832/47780 [01:08<01:40, 278.45 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11788/47780 [01:08<01:48, 331.76 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20420/47780 [01:08<01:29, 305.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21526/47780 [01:08<01:22, 319.84 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21028/47780 [01:08<01:34, 282.32 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19443/47780 [01:08<01:31, 308.70 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20595/47780 [01:08<01:24, 323.02 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11828/47780 [01:08<01:42, 350.43 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19720/47780 [01:08<01:31, 307.89 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20451/47780 [01:08<01:30, 303.47 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21560/47780 [01:08<01:25, 305.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19861/47780 [01:08<01:55, 242.43 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21072/47780 [01:08<01:23, 320.25 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19475/47780 [01:08<01:33, 301.23 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20640/47780 [01:08<01:15, 359.17 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19751/47780 [01:08<01:30, 308.46 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20483/47780 [01:08<01:29, 304.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11864/47780 [01:08<01:48, 330.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19902/47780 [01:08<01:40, 278.56 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21113/47780 [01:08<01:18, 340.23 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21592/47780 [01:08<01:32, 281.68 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19511/47780 [01:08<01:29, 314.45 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19782/47780 [01:08<01:30, 308.58 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20677/47780 [01:08<01:20, 338.26 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11902/47780 [01:08<01:45, 339.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20514/47780 [01:08<01:43, 263.58 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19933/47780 [01:08<01:38, 283.75 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21149/47780 [01:08<01:19, 335.61 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21627/47780 [01:08<01:27, 298.41 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19545/47780 [01:08<01:28, 318.20 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19813/47780 [01:08<01:32, 301.91 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11938/47780 [01:08<01:45, 338.50 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20712/47780 [01:08<01:24, 321.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20551/47780 [01:08<01:34, 288.32 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19964/47780 [01:08<01:40, 276.01 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21661/47780 [01:08<01:24, 307.89 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21186/47780 [01:08<01:19, 336.56 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19578/47780 [01:08<01:28, 317.96 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19844/47780 [01:08<01:37, 287.72 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11973/47780 [01:09<01:52, 317.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20745/47780 [01:08<01:30, 299.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20586/47780 [01:08<01:30, 299.45 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19993/47780 [01:09<01:43, 268.27 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19610/47780 [01:08<01:30, 311.00 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21220/47780 [01:09<01:22, 323.03 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19873/47780 [01:09<01:37, 285.14 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21693/47780 [01:09<01:33, 280.14 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12011/47780 [01:09<01:49, 327.11 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20776/47780 [01:09<01:30, 299.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20620/47780 [01:09<01:27, 309.66 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19645/47780 [01:09<01:28, 318.92 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21253/47780 [01:09<01:22, 321.32 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20021/47780 [01:09<01:47, 257.57 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19902/47780 [01:09<01:37, 286.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21727/47780 [01:09<01:29, 289.64 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12049/47780 [01:09<01:48, 330.67 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20652/47780 [01:09<01:27, 309.12 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20807/47780 [01:09<01:38, 272.59 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19682/47780 [01:09<01:24, 333.42 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21286/47780 [01:09<01:23, 316.52 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19936/47780 [01:09<01:33, 298.67 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21757/47780 [01:09<01:31, 282.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20048/47780 [01:09<01:57, 235.83 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12083/47780 [01:09<01:48, 329.61 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20684/47780 [01:09<01:32, 293.68 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20850/47780 [01:09<01:27, 307.49 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19717/47780 [01:09<01:24, 330.23 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21318/47780 [01:09<01:24, 313.87 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19971/47780 [01:09<01:28, 313.47 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20078/47780 [01:09<01:49, 252.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21787/47780 [01:09<01:33, 278.53 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12117/47780 [01:09<01:48, 328.39 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19751/47780 [01:09<01:24, 332.19 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21359/47780 [01:09<01:18, 337.69 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20714/47780 [01:09<01:40, 270.01 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20883/47780 [01:09<01:29, 300.38 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20003/47780 [01:09<01:34, 294.55 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21819/47780 [01:09<01:30, 287.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20104/47780 [01:09<01:52, 246.51 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12150/47780 [01:09<01:56, 304.64 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20752/47780 [01:09<01:31, 296.31 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19785/47780 [01:09<01:27, 320.82 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21405/47780 [01:09<01:12, 364.31 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20914/47780 [01:09<01:31, 294.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21850/47780 [01:09<01:30, 287.09 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20033/47780 [01:09<01:42, 271.77 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20130/47780 [01:09<01:56, 237.33 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12192/47780 [01:09<01:46, 333.00 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21453/47780 [01:09<01:06, 395.46 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20783/47780 [01:09<01:33, 287.49 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20944/47780 [01:09<01:34, 285.48 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19818/47780 [01:09<01:32, 302.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21888/47780 [01:09<01:22, 313.02 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20061/47780 [01:09<01:42, 271.13 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20155/47780 [01:09<02:00, 228.95 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12226/47780 [01:09<01:46, 334.54 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20815/47780 [01:09<01:31, 293.12 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19851/47780 [01:09<01:30, 310.27 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20973/47780 [01:09<01:36, 278.09 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21493/47780 [01:09<01:11, 368.84 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21920/47780 [01:09<01:22, 314.39 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20089/47780 [01:09<01:45, 261.98 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20188/47780 [01:09<01:48, 255.22 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12260/47780 [01:09<01:49, 325.09 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19887/47780 [01:09<01:27, 320.61 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20850/47780 [01:09<01:32, 292.66 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21004/47780 [01:09<01:35, 280.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21531/47780 [01:09<01:12, 363.83 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21952/47780 [01:09<01:28, 292.98 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20116/47780 [01:09<01:44, 264.17 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20215/47780 [01:09<01:47, 256.47 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12303/47780 [01:10<01:40, 351.50 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19920/47780 [01:09<01:26, 323.12 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21576/47780 [01:10<01:08, 383.79 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20884/47780 [01:10<01:29, 299.08 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21033/47780 [01:10<01:37, 274.22 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21986/47780 [01:10<01:26, 299.37 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20246/47780 [01:10<01:43, 265.63 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20143/47780 [01:10<01:49, 251.75 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12340/47780 [01:10<01:40, 352.31 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19953/47780 [01:10<01:26, 321.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21061/47780 [01:10<01:37, 272.66 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20915/47780 [01:10<01:33, 286.20 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21616/47780 [01:10<01:11, 363.61 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22020/47780 [01:10<01:23, 307.34 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20279/47780 [01:10<01:40, 274.48 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12379/47780 [01:10<01:38, 359.03 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19986/47780 [01:10<01:28, 312.58 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20170/47780 [01:10<02:06, 218.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21091/47780 [01:10<01:36, 277.45 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20946/47780 [01:10<01:32, 289.53 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22051/47780 [01:10<01:27, 294.37 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20321/47780 [01:10<01:28, 311.80 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12419/47780 [01:10<01:35, 369.70 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21653/47780 [01:10<01:21, 319.83 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20021/47780 [01:10<01:27, 316.60 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20224/47780 [01:10<01:32, 298.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21123/47780 [01:10<01:33, 286.22 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20976/47780 [01:10<01:37, 274.20 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22087/47780 [01:10<01:22, 310.98 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20353/47780 [01:10<01:32, 296.99 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12457/47780 [01:10<01:43, 341.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20257/47780 [01:10<01:32, 297.48 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20056/47780 [01:10<01:30, 306.47 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21152/47780 [01:10<01:38, 271.63 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22120/47780 [01:10<01:26, 298.01 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20391/47780 [01:10<01:26, 316.76 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12492/47780 [01:10<01:44, 339.26 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21005/47780 [01:10<01:50, 243.36 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21687/47780 [01:10<01:49, 237.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20294/47780 [01:10<01:27, 313.68 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21187/47780 [01:10<01:30, 293.48 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20088/47780 [01:10<01:31, 301.69 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22151/47780 [01:10<01:26, 297.01 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20423/47780 [01:10<01:26, 317.50 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12527/47780 [01:10<01:44, 336.67 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21040/47780 [01:10<01:42, 260.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21771/47780 [01:10<01:12, 358.57 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21217/47780 [01:10<01:30, 294.99 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20124/47780 [01:10<01:29, 308.44 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20327/47780 [01:10<01:32, 295.60 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22185/47780 [01:10<01:23, 306.88 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20455/47780 [01:10<01:26, 314.73 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12568/47780 [01:10<01:38, 357.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21075/47780 [01:10<01:35, 280.75 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21247/47780 [01:10<01:30, 293.24 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21814/47780 [01:10<01:13, 355.33 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20168/47780 [01:10<01:20, 344.83 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20362/47780 [01:10<01:28, 310.05 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20491/47780 [01:10<01:24, 323.96 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22216/47780 [01:10<01:25, 297.46 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21110/47780 [01:10<01:30, 296.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12604/47780 [01:10<01:46, 331.53 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21280/47780 [01:10<01:28, 300.73 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20203/47780 [01:10<01:23, 331.06 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20395/47780 [01:10<01:32, 296.01 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21855/47780 [01:10<01:17, 336.43 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20533/47780 [01:10<01:17, 350.86 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22246/47780 [01:10<01:31, 279.50 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21144/47780 [01:10<01:26, 308.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12640/47780 [01:11<01:44, 334.77 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21311/47780 [01:10<01:32, 286.68 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20241/47780 [01:10<01:21, 337.36 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20426/47780 [01:10<01:35, 286.64 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20570/47780 [01:11<01:19, 341.38 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21892/47780 [01:11<01:20, 320.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12674/47780 [01:11<01:47, 326.92 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21176/47780 [01:11<01:30, 294.26 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20275/47780 [01:11<01:25, 323.23 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20456/47780 [01:11<01:35, 287.49 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21340/47780 [01:11<01:40, 263.45 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22275/47780 [01:11<01:54, 223.54 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20605/47780 [01:11<01:22, 328.78 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21928/47780 [01:11<01:20, 323.13 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21208/47780 [01:11<01:28, 298.86 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12708/47780 [01:11<01:50, 318.31 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20313/47780 [01:11<01:21, 335.62 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21367/47780 [01:11<01:40, 262.80 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20488/47780 [01:11<01:33, 290.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22300/47780 [01:11<01:59, 213.42 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20639/47780 [01:11<01:28, 307.73 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12744/47780 [01:11<01:47, 326.35 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21239/47780 [01:11<01:32, 285.82 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21962/47780 [01:11<01:26, 297.67 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20347/47780 [01:11<01:22, 333.13 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21401/47780 [01:11<01:32, 284.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20518/47780 [01:11<01:34, 289.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22410/47780 [01:11<01:00, 421.61 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20671/47780 [01:11<01:29, 304.45 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12785/47780 [01:11<01:40, 349.58 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22000/47780 [01:11<01:21, 314.88 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21268/47780 [01:11<01:36, 274.90 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21432/47780 [01:11<01:30, 291.20 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20381/47780 [01:11<01:24, 323.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20550/47780 [01:11<01:32, 295.08 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20708/47780 [01:11<01:23, 322.30 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12834/47780 [01:11<01:29, 389.86 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22038/47780 [01:11<01:17, 331.59 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21296/47780 [01:11<01:35, 276.27 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22458/47780 [01:11<01:03, 399.33 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21462/47780 [01:11<01:31, 288.87 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20582/47780 [01:11<01:31, 298.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20414/47780 [01:11<01:31, 298.86 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20745/47780 [01:11<01:21, 332.50 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12874/47780 [01:11<01:30, 384.33 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22073/47780 [01:11<01:20, 319.49 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21329/47780 [01:11<01:33, 281.90 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22502/47780 [01:11<01:07, 372.21 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21492/47780 [01:11<01:37, 268.91 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20612/47780 [01:11<01:37, 279.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20449/47780 [01:11<01:29, 306.17 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20780/47780 [01:11<01:25, 315.67 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12913/47780 [01:11<01:36, 360.86 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21363/47780 [01:11<01:31, 288.49 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22106/47780 [01:11<01:23, 308.32 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21524/47780 [01:11<01:35, 273.95 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22543/47780 [01:11<01:09, 360.86 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20486/47780 [01:11<01:25, 320.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20641/47780 [01:11<01:41, 267.86 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20817/47780 [01:11<01:21, 330.33 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12950/47780 [01:11<01:40, 348.00 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21394/47780 [01:11<01:29, 294.45 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22146/47780 [01:11<01:18, 326.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21552/47780 [01:11<01:36, 272.26 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20669/47780 [01:11<01:43, 262.32 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20519/47780 [01:11<01:30, 302.18 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22582/47780 [01:11<01:14, 337.87 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20853/47780 [01:11<01:21, 331.58 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21424/47780 [01:11<01:30, 292.76 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12986/47780 [01:11<01:42, 339.45 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22180/47780 [01:11<01:20, 319.94 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21586/47780 [01:11<01:30, 288.38 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20702/47780 [01:11<01:37, 278.15 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20555/47780 [01:11<01:26, 314.85 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22618/47780 [01:11<01:16, 330.60 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20887/47780 [01:12<01:25, 316.11 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22213/47780 [01:12<01:20, 315.74 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21454/47780 [01:12<01:35, 275.77 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13021/47780 [01:12<01:46, 324.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21622/47780 [01:12<01:25, 305.22 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20588/47780 [01:12<01:25, 318.80 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22653/47780 [01:12<01:17, 325.61 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20919/47780 [01:12<01:26, 310.29 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20731/47780 [01:12<01:51, 242.96 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22248/47780 [01:12<01:18, 325.13 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21482/47780 [01:12<01:37, 270.93 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13054/47780 [01:12<01:47, 322.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21654/47780 [01:12<01:26, 303.42 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20625/47780 [01:12<01:22, 329.85 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20953/47780 [01:12<01:25, 315.06 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22687/47780 [01:12<01:18, 319.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22283/47780 [01:12<01:16, 332.01 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20757/47780 [01:12<01:51, 242.90 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21516/47780 [01:12<01:30, 290.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13087/47780 [01:12<01:50, 315.04 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21685/47780 [01:12<01:29, 291.10 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20659/47780 [01:12<01:22, 328.85 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20994/47780 [01:12<01:19, 338.18 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22733/47780 [01:12<01:11, 349.28 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20782/47780 [01:12<01:50, 244.66 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22323/47780 [01:12<01:13, 347.88 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21546/47780 [01:12<01:31, 286.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13120/47780 [01:12<01:48, 318.57 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20693/47780 [01:12<01:24, 320.82 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21720/47780 [01:12<01:28, 294.31 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22772/47780 [01:12<01:10, 356.43 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22358/47780 [01:12<01:13, 348.05 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13163/47780 [01:12<01:38, 350.13 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20807/47780 [01:12<01:58, 228.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21028/47780 [01:12<01:28, 300.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21575/47780 [01:12<01:38, 266.51 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21751/47780 [01:12<01:28, 295.01 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20726/47780 [01:12<01:28, 306.35 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22814/47780 [01:12<01:07, 369.96 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22393/47780 [01:12<01:15, 337.29 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20838/47780 [01:12<01:48, 247.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13211/47780 [01:12<01:33, 370.55 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21621/47780 [01:12<01:24, 309.21 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21060/47780 [01:12<01:34, 281.44 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21791/47780 [01:12<01:21, 320.49 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20761/47780 [01:12<01:25, 315.01 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22853/47780 [01:12<01:07, 371.36 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22427/47780 [01:12<01:15, 338.02 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13253/47780 [01:12<01:31, 376.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20864/47780 [01:12<01:49, 245.63 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21654/47780 [01:12<01:25, 305.00 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21828/47780 [01:12<01:18, 331.84 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21100/47780 [01:12<01:27, 306.41 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20793/47780 [01:12<01:29, 302.46 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22462/47780 [01:12<01:15, 333.43 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22891/47780 [01:12<01:12, 342.80 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13296/47780 [01:12<01:28, 391.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20892/47780 [01:12<01:46, 252.39 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21690/47780 [01:12<01:21, 320.04 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21862/47780 [01:12<01:20, 323.52 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20824/47780 [01:12<01:28, 304.50 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21132/47780 [01:12<01:36, 277.26 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22496/47780 [01:12<01:16, 332.01 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22930/47780 [01:12<01:10, 351.65 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13339/47780 [01:12<01:25, 402.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20921/47780 [01:12<01:42, 262.74 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21723/47780 [01:12<01:23, 310.71 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21895/47780 [01:12<01:22, 313.61 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20856/47780 [01:12<01:32, 292.37 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21161/47780 [01:12<01:35, 277.69 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20948/47780 [01:12<01:41, 263.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22530/47780 [01:12<01:20, 312.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13380/47780 [01:13<01:27, 390.95 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22968/47780 [01:12<01:12, 343.89 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21757/47780 [01:13<01:23, 313.51 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21927/47780 [01:13<01:28, 292.79 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21191/47780 [01:13<01:35, 279.13 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20897/47780 [01:13<01:24, 317.80 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22571/47780 [01:13<01:14, 339.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20975/47780 [01:13<01:44, 257.73 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23006/47780 [01:13<01:11, 345.11 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13420/47780 [01:13<01:34, 364.41 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21793/47780 [01:13<01:20, 323.00 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20930/47780 [01:13<01:24, 318.07 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21957/47780 [01:13<01:29, 288.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21220/47780 [01:13<01:37, 271.74 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22606/47780 [01:13<01:16, 327.67 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21001/47780 [01:13<01:46, 252.58 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21828/47780 [01:13<01:18, 330.63 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23041/47780 [01:13<01:15, 325.73 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13457/47780 [01:13<01:37, 350.52 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20969/47780 [01:13<01:20, 334.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21255/47780 [01:13<01:31, 290.23 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21987/47780 [01:13<01:35, 270.94 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22640/47780 [01:13<01:15, 330.96 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21029/47780 [01:13<01:42, 260.35 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21867/47780 [01:13<01:16, 339.89 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23075/47780 [01:13<01:17, 319.63 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13494/47780 [01:13<01:41, 337.43 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21005/47780 [01:13<01:21, 330.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22018/47780 [01:13<01:31, 281.27 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22674/47780 [01:13<01:16, 329.93 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21285/47780 [01:13<01:37, 271.33 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21057/47780 [01:13<01:48, 246.41 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21904/47780 [01:13<01:15, 344.70 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23110/47780 [01:13<01:16, 324.50 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13529/47780 [01:13<01:43, 330.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21042/47780 [01:13<01:19, 337.89 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22708/47780 [01:13<01:16, 328.57 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22047/47780 [01:13<01:34, 271.64 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21313/47780 [01:13<01:39, 265.53 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21083/47780 [01:13<01:47, 247.45 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23145/47780 [01:13<01:15, 324.28 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13572/47780 [01:13<01:35, 357.04 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21939/47780 [01:13<01:24, 306.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21078/47780 [01:13<01:17, 343.86 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22741/47780 [01:13<01:17, 322.08 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21341/47780 [01:13<01:41, 260.95 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21112/47780 [01:13<01:43, 256.44 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22075/47780 [01:13<01:48, 237.55 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23178/47780 [01:13<01:19, 308.73 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13610/47780 [01:13<01:37, 351.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21981/47780 [01:13<01:17, 333.95 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21113/47780 [01:13<01:21, 326.42 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22775/47780 [01:13<01:16, 327.14 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21370/47780 [01:13<01:38, 268.68 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21146/47780 [01:13<01:36, 277.03 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23210/47780 [01:13<01:19, 308.42 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13649/47780 [01:13<01:37, 350.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22016/47780 [01:13<01:17, 334.35 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21404/47780 [01:13<01:31, 288.64 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22808/47780 [01:13<01:19, 313.13 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21146/47780 [01:13<01:27, 304.09 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22100/47780 [01:13<02:10, 196.77 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21174/47780 [01:13<01:41, 262.94 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13692/47780 [01:13<01:31, 372.69 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23241/47780 [01:13<01:23, 295.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22050/47780 [01:13<01:19, 325.30 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21435/47780 [01:13<01:30, 292.26 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21181/47780 [01:13<01:24, 313.29 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22840/47780 [01:13<01:23, 298.43 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21202/47780 [01:13<01:39, 267.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23285/47780 [01:13<01:13, 332.04 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13730/47780 [01:14<01:39, 343.80 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22084/47780 [01:14<01:22, 311.50 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22122/47780 [01:14<02:26, 174.93 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22875/47780 [01:14<01:19, 312.73 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21216/47780 [01:13<01:26, 306.16 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21229/47780 [01:14<01:42, 259.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21465/47780 [01:14<01:38, 266.24 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13765/47780 [01:14<01:39, 341.71 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22121/47780 [01:14<01:20, 317.58 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23319/47780 [01:14<01:22, 297.54 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22226/47780 [01:14<01:11, 356.06 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22913/47780 [01:14<01:14, 331.59 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21249/47780 [01:14<01:25, 309.50 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21262/47780 [01:14<01:38, 270.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21493/47780 [01:14<01:46, 246.14 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13800/47780 [01:14<01:39, 339.81 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23357/47780 [01:14<01:16, 319.10 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22158/47780 [01:14<01:18, 328.12 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22956/47780 [01:14<01:09, 356.08 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21281/47780 [01:14<01:24, 312.19 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22267/47780 [01:14<01:14, 342.48 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21291/47780 [01:14<01:37, 272.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21522/47780 [01:14<01:41, 257.48 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13835/47780 [01:14<01:41, 335.60 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23399/47780 [01:14<01:10, 346.41 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22202/47780 [01:14<01:12, 351.88 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22995/47780 [01:14<01:08, 359.89 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21313/47780 [01:14<01:26, 307.66 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21320/47780 [01:14<01:37, 271.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21549/47780 [01:14<01:40, 260.76 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22305/47780 [01:14<01:23, 304.82 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13879/47780 [01:14<01:34, 360.63 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23435/47780 [01:14<01:11, 342.82 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22238/47780 [01:14<01:12, 353.68 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21345/47780 [01:14<01:24, 311.13 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23032/47780 [01:14<01:10, 352.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21349/47780 [01:14<01:36, 273.66 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21577/47780 [01:14<01:46, 246.76 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13916/47780 [01:14<01:34, 357.00 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22274/47780 [01:14<01:12, 351.49 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23484/47780 [01:14<01:04, 376.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22339/47780 [01:14<01:29, 282.98 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21384/47780 [01:14<01:21, 322.74 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23068/47780 [01:14<01:12, 340.92 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21377/47780 [01:14<01:41, 260.42 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13953/47780 [01:14<01:34, 359.29 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22318/47780 [01:14<01:08, 373.16 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21603/47780 [01:14<01:51, 235.32 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23523/47780 [01:14<01:09, 348.49 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21422/47780 [01:14<01:18, 337.16 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22370/47780 [01:14<01:33, 271.28 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23103/47780 [01:14<01:18, 313.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21405/47780 [01:14<01:39, 265.88 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13990/47780 [01:14<01:33, 361.99 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22357/47780 [01:14<01:10, 361.33 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21627/47780 [01:14<01:55, 226.90 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23576/47780 [01:14<01:01, 393.05 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21456/47780 [01:14<01:21, 324.69 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22406/47780 [01:14<01:28, 286.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21443/47780 [01:14<01:29, 295.23 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23135/47780 [01:14<01:21, 301.68 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14028/47780 [01:14<01:37, 347.32 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21658/47780 [01:14<01:44, 249.09 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22394/47780 [01:14<01:17, 328.75 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22438/47780 [01:14<01:25, 294.86 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21489/47780 [01:14<01:26, 305.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21473/47780 [01:14<01:29, 293.25 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23617/47780 [01:14<01:08, 351.22 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14068/47780 [01:15<01:33, 362.17 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23166/47780 [01:14<01:27, 280.30 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21685/47780 [01:14<01:44, 249.30 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22428/47780 [01:15<01:16, 329.43 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21504/47780 [01:15<01:29, 294.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21520/47780 [01:14<01:29, 293.01 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22470/47780 [01:15<01:30, 278.18 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14109/47780 [01:15<01:29, 375.61 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23195/47780 [01:15<01:29, 275.13 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23654/47780 [01:15<01:16, 316.87 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21711/47780 [01:15<01:47, 241.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22469/47780 [01:15<01:12, 348.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21550/47780 [01:15<01:30, 288.87 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21534/47780 [01:15<01:34, 276.74 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14147/47780 [01:15<01:29, 374.30 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22499/47780 [01:15<01:35, 264.78 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23223/47780 [01:15<01:30, 272.56 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23688/47780 [01:15<01:14, 322.18 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21736/47780 [01:15<01:52, 230.94 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22505/47780 [01:15<01:15, 334.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21583/47780 [01:15<01:28, 297.64 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21564/47780 [01:15<01:33, 280.26 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14187/47780 [01:15<01:29, 375.46 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22528/47780 [01:15<01:35, 263.49 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23251/47780 [01:15<01:32, 265.68 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23722/47780 [01:15<01:19, 301.84 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22542/47780 [01:15<01:13, 342.51 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21760/47780 [01:15<01:55, 226.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21615/47780 [01:15<01:27, 300.58 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21594/47780 [01:15<01:37, 267.34 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22564/47780 [01:15<01:28, 285.76 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23278/47780 [01:15<01:34, 259.67 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14225/47780 [01:15<01:37, 344.54 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22577/47780 [01:15<01:13, 340.70 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23754/47780 [01:15<01:23, 288.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21784/47780 [01:15<01:57, 220.39 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21646/47780 [01:15<01:28, 295.40 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21622/47780 [01:15<01:37, 268.32 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22607/47780 [01:15<01:18, 321.26 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14272/47780 [01:15<01:29, 375.60 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23309/47780 [01:15<01:30, 269.45 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22613/47780 [01:15<01:13, 342.37 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23788/47780 [01:15<01:19, 299.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21816/47780 [01:15<01:44, 247.34 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21704/47780 [01:15<01:09, 373.22 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21652/47780 [01:15<01:35, 274.06 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22647/47780 [01:15<01:14, 335.63 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14313/47780 [01:15<01:27, 381.17 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23339/47780 [01:15<01:29, 271.90 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22651/47780 [01:15<01:12, 345.22 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23819/47780 [01:15<01:21, 295.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21842/47780 [01:15<01:45, 245.54 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21743/47780 [01:15<01:12, 361.21 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22692/47780 [01:15<01:09, 363.51 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21680/47780 [01:15<01:38, 266.28 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23370/47780 [01:15<01:27, 279.58 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14353/47780 [01:15<01:32, 361.83 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23852/47780 [01:15<01:20, 298.14 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21871/47780 [01:15<01:43, 249.96 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22687/47780 [01:15<01:16, 327.02 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21780/47780 [01:15<01:13, 355.40 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23402/47780 [01:15<01:23, 291.01 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22729/47780 [01:15<01:15, 331.64 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14399/47780 [01:15<01:27, 382.52 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21707/47780 [01:15<01:52, 231.43 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23887/47780 [01:15<01:17, 308.93 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21898/47780 [01:15<01:41, 255.26 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22720/47780 [01:15<01:17, 324.22 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21823/47780 [01:15<01:09, 372.70 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23432/47780 [01:15<01:25, 283.71 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22765/47780 [01:15<01:14, 335.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14438/47780 [01:16<01:29, 373.25 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21731/47780 [01:15<01:54, 228.23 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23924/47780 [01:15<01:14, 318.97 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22753/47780 [01:16<01:18, 317.93 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21861/47780 [01:15<01:16, 339.40 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21924/47780 [01:16<02:00, 214.84 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23461/47780 [01:16<01:31, 267.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22800/47780 [01:16<01:18, 318.72 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21781/47780 [01:16<01:29, 289.60 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23958/47780 [01:16<01:16, 310.54 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22789/47780 [01:16<01:17, 323.32 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14476/47780 [01:16<01:40, 332.25 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21899/47780 [01:16<01:14, 347.22 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21960/47780 [01:16<01:43, 249.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23491/47780 [01:16<01:28, 273.33 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22840/47780 [01:16<01:14, 333.28 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21820/47780 [01:16<01:22, 315.43 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22822/47780 [01:16<01:17, 321.64 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23990/47780 [01:16<01:18, 303.40 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14518/47780 [01:16<01:34, 350.66 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21938/47780 [01:16<01:13, 351.28 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21988/47780 [01:16<01:41, 253.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23522/47780 [01:16<01:25, 283.54 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22874/47780 [01:16<01:16, 327.58 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24026/47780 [01:16<01:14, 318.90 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21853/47780 [01:16<01:26, 299.60 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22855/47780 [01:16<01:21, 306.53 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14554/47780 [01:16<01:42, 324.91 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22018/47780 [01:16<01:37, 264.63 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21974/47780 [01:16<01:17, 331.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23554/47780 [01:16<01:24, 287.34 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24062/47780 [01:16<01:13, 323.48 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22893/47780 [01:16<01:16, 326.90 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21884/47780 [01:16<01:30, 287.10 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14594/47780 [01:16<01:38, 337.74 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22008/47780 [01:16<01:18, 330.28 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23586/47780 [01:16<01:21, 296.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22909/47780 [01:16<01:34, 264.12 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22046/47780 [01:16<01:47, 239.68 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22931/47780 [01:16<01:12, 341.61 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24095/47780 [01:16<01:15, 313.20 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21914/47780 [01:16<01:29, 290.17 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14631/47780 [01:16<01:35, 346.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22042/47780 [01:16<01:20, 320.14 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22071/47780 [01:16<01:48, 237.38 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22938/47780 [01:16<01:36, 257.17 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23616/47780 [01:16<01:28, 273.22 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22966/47780 [01:16<01:13, 336.67 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24128/47780 [01:16<01:14, 315.82 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14671/47780 [01:16<01:34, 349.34 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21944/47780 [01:16<01:37, 263.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22076/47780 [01:16<01:19, 324.01 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22097/47780 [01:16<01:45, 242.92 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23661/47780 [01:16<01:15, 318.84 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22966/47780 [01:16<01:35, 258.60 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23000/47780 [01:16<01:15, 330.04 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24165/47780 [01:16<01:15, 313.24 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21971/47780 [01:16<01:38, 262.78 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14707/47780 [01:16<01:37, 337.67 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22112/47780 [01:16<01:18, 326.95 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22123/47780 [01:16<01:43, 247.45 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23040/47780 [01:16<01:05, 377.77 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23695/47780 [01:16<01:16, 316.32 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24208/47780 [01:16<01:08, 345.54 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23034/47780 [01:16<01:19, 311.45 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22003/47780 [01:16<01:35, 269.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14742/47780 [01:16<01:41, 326.74 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22145/47780 [01:16<01:19, 323.94 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22149/47780 [01:16<01:44, 246.17 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23081/47780 [01:16<01:07, 366.81 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23728/47780 [01:16<01:19, 303.17 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23073/47780 [01:16<01:14, 329.57 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24244/47780 [01:16<01:11, 330.61 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22036/47780 [01:16<01:31, 280.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14781/47780 [01:17<01:36, 343.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22187/47780 [01:16<01:12, 351.18 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22174/47780 [01:17<01:47, 238.53 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23121/47780 [01:17<01:06, 371.11 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23759/47780 [01:17<01:21, 296.03 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23110/47780 [01:17<01:12, 339.28 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24280/47780 [01:17<01:09, 337.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22066/47780 [01:17<01:30, 284.15 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22223/47780 [01:17<01:13, 345.86 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14816/47780 [01:17<01:40, 327.46 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22203/47780 [01:17<01:45, 242.67 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23168/47780 [01:17<01:01, 397.78 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23790/47780 [01:17<01:21, 296.06 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23145/47780 [01:17<01:15, 328.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24315/47780 [01:17<01:14, 314.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22095/47780 [01:17<01:32, 277.85 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14854/47780 [01:17<01:36, 341.70 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22260/47780 [01:17<01:18, 326.83 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22233/47780 [01:17<01:39, 255.82 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23209/47780 [01:17<01:02, 390.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23820/47780 [01:17<01:24, 284.32 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23179/47780 [01:17<01:20, 304.95 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22136/47780 [01:17<01:22, 311.51 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24347/47780 [01:17<01:17, 302.66 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14889/47780 [01:17<01:35, 343.94 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22294/47780 [01:17<01:19, 319.13 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23253/47780 [01:17<01:01, 398.23 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22259/47780 [01:17<01:49, 233.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22175/47780 [01:17<01:16, 333.83 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24378/47780 [01:17<01:16, 303.97 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14927/47780 [01:17<01:34, 346.63 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23849/47780 [01:17<01:36, 247.44 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23210/47780 [01:17<01:27, 279.49 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22329/47780 [01:17<01:20, 314.43 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22292/47780 [01:17<01:38, 259.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23294/47780 [01:17<01:05, 373.16 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22209/47780 [01:17<01:19, 320.81 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23878/47780 [01:17<01:32, 258.29 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14962/47780 [01:17<01:38, 332.49 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24409/47780 [01:17<01:21, 287.32 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23239/47780 [01:17<01:30, 270.75 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22361/47780 [01:17<01:21, 312.44 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22319/47780 [01:17<01:42, 248.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23332/47780 [01:17<01:10, 347.18 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23909/47780 [01:17<01:29, 266.43 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24440/47780 [01:17<01:20, 290.24 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22242/47780 [01:17<01:23, 306.15 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14997/47780 [01:17<01:39, 329.89 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23267/47780 [01:17<01:29, 272.63 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22393/47780 [01:17<01:24, 301.23 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22345/47780 [01:17<01:46, 238.62 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23944/47780 [01:17<01:22, 289.11 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15036/47780 [01:17<01:34, 345.15 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24470/47780 [01:17<01:22, 283.53 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23300/47780 [01:17<01:24, 288.25 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23368/47780 [01:17<01:19, 305.28 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22426/47780 [01:17<01:22, 305.78 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22373/47780 [01:17<01:41, 249.69 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23975/47780 [01:17<01:22, 288.27 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15074/47780 [01:17<01:32, 352.99 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22273/47780 [01:17<01:48, 236.07 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24503/47780 [01:17<01:19, 293.17 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23408/47780 [01:17<01:16, 319.47 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23330/47780 [01:17<01:27, 278.99 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22460/47780 [01:17<01:20, 315.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22401/47780 [01:17<01:39, 255.43 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24011/47780 [01:17<01:17, 305.39 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15110/47780 [01:18<01:32, 354.35 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22327/47780 [01:17<01:24, 301.80 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24533/47780 [01:17<01:21, 285.34 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23367/47780 [01:17<01:21, 301.37 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23441/47780 [01:17<01:16, 318.84 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22496/47780 [01:17<01:17, 324.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22428/47780 [01:18<01:37, 259.45 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15146/47780 [01:18<01:34, 344.24 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22361/47780 [01:18<01:24, 302.32 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24563/47780 [01:18<01:21, 286.32 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24043/47780 [01:18<01:22, 286.58 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23399/47780 [01:18<01:20, 303.21 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22532/47780 [01:18<01:15, 334.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23474/47780 [01:18<01:18, 308.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22455/47780 [01:18<01:39, 253.76 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15183/47780 [01:18<01:34, 344.02 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24593/47780 [01:18<01:19, 289.93 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24074/47780 [01:18<01:21, 289.86 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22399/47780 [01:18<01:21, 312.50 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22572/47780 [01:18<01:12, 347.99 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23506/47780 [01:18<01:20, 303.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23430/47780 [01:18<01:30, 268.58 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22481/47780 [01:18<01:41, 249.92 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15219/47780 [01:18<01:34, 344.63 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24623/47780 [01:18<01:20, 289.43 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22432/47780 [01:18<01:21, 310.31 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24104/47780 [01:18<01:26, 275.14 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22611/47780 [01:18<01:11, 353.62 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23541/47780 [01:18<01:17, 311.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23485/47780 [01:18<01:11, 339.18 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22507/47780 [01:18<01:43, 244.49 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15256/47780 [01:18<01:33, 347.94 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24653/47780 [01:18<01:19, 292.14 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22469/47780 [01:18<01:20, 316.36 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24132/47780 [01:18<01:26, 272.55 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22647/47780 [01:18<01:14, 336.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23573/47780 [01:18<01:20, 299.82 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22533/47780 [01:18<01:41, 248.75 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15302/47780 [01:18<01:26, 375.97 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24690/47780 [01:18<01:15, 304.94 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23524/47780 [01:18<01:20, 302.84 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24160/47780 [01:18<01:26, 274.39 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22687/47780 [01:18<01:12, 346.34 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22503/47780 [01:18<01:24, 299.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23612/47780 [01:18<01:15, 318.26 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22558/47780 [01:18<01:42, 246.16 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15340/47780 [01:18<01:28, 368.41 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24721/47780 [01:18<01:16, 302.59 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24193/47780 [01:18<01:21, 290.15 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23583/47780 [01:18<01:07, 360.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22722/47780 [01:18<01:14, 336.00 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23646/47780 [01:18<01:16, 313.87 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22588/47780 [01:18<01:36, 261.03 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22534/47780 [01:18<01:29, 281.71 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15388/47780 [01:18<01:21, 395.52 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24753/47780 [01:18<01:15, 304.46 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23632/47780 [01:18<01:01, 393.44 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24223/47780 [01:18<01:25, 277.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23681/47780 [01:18<01:14, 323.68 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22758/47780 [01:18<01:14, 335.25 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22618/47780 [01:18<01:33, 269.99 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22563/47780 [01:18<01:30, 278.37 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24792/47780 [01:18<01:11, 321.43 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23674/47780 [01:18<01:02, 385.52 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24256/47780 [01:18<01:21, 289.08 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15428/47780 [01:18<01:30, 359.37 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23716/47780 [01:18<01:14, 324.08 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22792/47780 [01:18<01:16, 326.51 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22592/47780 [01:18<01:32, 272.77 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22646/47780 [01:18<01:37, 257.90 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24825/47780 [01:18<01:13, 313.86 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24286/47780 [01:18<01:22, 285.35 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15465/47780 [01:19<01:34, 340.67 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23714/47780 [01:18<01:06, 360.94 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22620/47780 [01:18<01:31, 274.55 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22825/47780 [01:18<01:19, 312.05 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22677/47780 [01:18<01:34, 266.59 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23749/47780 [01:19<01:23, 289.03 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24857/47780 [01:19<01:15, 303.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24325/47780 [01:19<01:15, 309.75 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15500/47780 [01:19<01:36, 335.74 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23754/47780 [01:19<01:09, 347.46 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22649/47780 [01:19<01:30, 277.27 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22708/47780 [01:19<01:31, 272.92 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22857/47780 [01:19<01:24, 295.24 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23781/47780 [01:19<01:23, 288.66 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24890/47780 [01:19<01:14, 308.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24357/47780 [01:19<01:15, 310.89 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15534/47780 [01:19<01:36, 333.32 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23798/47780 [01:19<01:04, 370.04 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22677/47780 [01:19<01:30, 276.50 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23814/47780 [01:19<01:21, 293.44 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22887/47780 [01:19<01:32, 269.99 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24932/47780 [01:19<01:08, 331.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22736/47780 [01:19<01:44, 239.15 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24389/47780 [01:19<01:20, 290.46 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15569/47780 [01:19<01:39, 323.43 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22705/47780 [01:19<01:37, 256.81 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23838/47780 [01:19<01:08, 347.99 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23844/47780 [01:19<01:22, 288.93 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22915/47780 [01:19<01:33, 267.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22771/47780 [01:19<01:34, 265.74 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24966/47780 [01:19<01:12, 313.90 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24419/47780 [01:19<01:24, 277.98 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15609/47780 [01:19<01:36, 333.83 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22737/47780 [01:19<01:33, 268.54 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23874/47780 [01:19<01:21, 291.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23874/47780 [01:19<01:11, 336.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22803/47780 [01:19<01:32, 271.41 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22942/47780 [01:19<01:39, 249.34 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24999/47780 [01:19<01:14, 307.84 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15644/47780 [01:19<01:35, 337.74 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24448/47780 [01:19<01:29, 261.11 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22771/47780 [01:19<01:27, 285.24 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23907/47780 [01:19<01:19, 299.46 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23909/47780 [01:19<01:14, 320.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22832/47780 [01:19<01:31, 273.57 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25035/47780 [01:19<01:11, 318.95 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15681/47780 [01:19<01:33, 343.57 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24475/47780 [01:19<01:30, 256.47 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22808/47780 [01:19<01:22, 302.40 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23940/47780 [01:19<01:17, 308.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23942/47780 [01:19<01:16, 312.92 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22860/47780 [01:19<01:32, 270.46 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25075/47780 [01:19<01:07, 334.28 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22968/47780 [01:19<02:08, 193.37 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15716/47780 [01:19<01:36, 333.53 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24510/47780 [01:19<01:22, 280.50 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22852/47780 [01:19<01:15, 331.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23971/47780 [01:19<01:19, 298.35 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22890/47780 [01:19<01:31, 271.58 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23974/47780 [01:19<01:21, 292.83 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25113/47780 [01:19<01:08, 328.58 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15752/47780 [01:19<01:33, 340.79 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24539/47780 [01:19<01:22, 281.80 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22892/47780 [01:19<01:11, 349.31 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22990/47780 [01:19<02:23, 173.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24002/47780 [01:19<01:24, 282.34 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22925/47780 [01:19<01:24, 293.32 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24009/47780 [01:19<01:17, 307.75 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25155/47780 [01:19<01:03, 353.77 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15795/47780 [01:19<01:28, 363.02 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24572/47780 [01:19<01:19, 293.46 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22928/47780 [01:19<01:16, 326.25 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24032/47780 [01:19<01:23, 283.99 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23086/47780 [01:19<01:14, 331.89 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15832/47780 [01:20<01:27, 364.48 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22955/47780 [01:20<01:33, 265.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25191/47780 [01:20<01:08, 329.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24604/47780 [01:20<01:26, 267.03 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22962/47780 [01:20<01:19, 312.49 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23124/47780 [01:20<01:15, 327.47 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24061/47780 [01:20<01:33, 254.07 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24041/47780 [01:20<01:41, 232.86 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22983/47780 [01:20<01:33, 266.05 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15869/47780 [01:20<01:33, 341.97 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25225/47780 [01:20<01:08, 328.82 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24635/47780 [01:20<01:24, 272.96 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22996/47780 [01:20<01:19, 310.59 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23161/47780 [01:20<01:15, 325.43 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24100/47780 [01:20<01:21, 289.37 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24097/47780 [01:20<01:17, 303.74 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23013/47780 [01:20<01:31, 269.62 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15904/47780 [01:20<01:38, 322.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25259/47780 [01:20<01:12, 309.12 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24663/47780 [01:20<01:27, 263.52 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24130/47780 [01:20<01:23, 283.61 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23028/47780 [01:20<01:25, 290.39 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23197/47780 [01:20<01:18, 315.08 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23043/47780 [01:20<01:30, 274.43 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24132/47780 [01:20<01:21, 289.26 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15950/47780 [01:20<01:29, 356.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25295/47780 [01:20<01:11, 314.84 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24697/47780 [01:20<01:23, 278.03 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24163/47780 [01:20<01:20, 293.16 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23235/47780 [01:20<01:14, 328.55 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23066/47780 [01:20<01:21, 304.69 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23082/47780 [01:20<01:21, 304.31 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15987/47780 [01:20<01:33, 341.38 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25329/47780 [01:20<01:11, 314.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24164/47780 [01:20<01:25, 277.83 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24726/47780 [01:20<01:23, 275.37 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24193/47780 [01:20<01:21, 288.42 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23270/47780 [01:20<01:14, 329.91 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23098/47780 [01:20<01:26, 285.40 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23113/47780 [01:20<01:27, 280.34 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25362/47780 [01:20<01:10, 318.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16022/47780 [01:20<01:35, 333.55 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24202/47780 [01:20<01:21, 290.18 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24759/47780 [01:20<01:20, 284.23 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24223/47780 [01:20<01:23, 282.46 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23320/47780 [01:20<01:07, 364.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23130/47780 [01:20<01:25, 286.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16062/47780 [01:20<01:30, 351.00 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25395/47780 [01:20<01:13, 304.51 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23143/47780 [01:20<01:33, 262.81 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24237/47780 [01:20<01:18, 300.56 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24788/47780 [01:20<01:24, 273.61 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24257/47780 [01:20<01:18, 298.53 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23364/47780 [01:20<01:04, 377.35 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23163/47780 [01:20<01:23, 295.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16103/47780 [01:20<01:29, 355.61 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25427/47780 [01:20<01:13, 304.30 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24269/47780 [01:20<01:18, 299.65 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23170/47780 [01:20<01:36, 256.15 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24821/47780 [01:20<01:20, 285.97 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24288/47780 [01:20<01:18, 298.54 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23193/47780 [01:20<01:25, 287.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23403/47780 [01:20<01:10, 346.09 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16157/47780 [01:20<01:19, 398.42 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24303/47780 [01:20<01:16, 307.44 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23196/47780 [01:20<01:37, 252.19 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24321/47780 [01:20<01:16, 307.40 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25458/47780 [01:20<01:22, 270.32 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24850/47780 [01:21<01:31, 250.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23446/47780 [01:20<01:06, 364.56 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23222/47780 [01:21<01:29, 275.90 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24336/47780 [01:21<01:14, 313.52 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16198/47780 [01:21<01:23, 380.06 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23230/47780 [01:21<01:32, 264.63 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25498/47780 [01:21<01:13, 301.60 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24362/47780 [01:21<01:11, 329.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23484/47780 [01:21<01:05, 368.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24891/47780 [01:21<01:21, 280.33 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23251/47780 [01:21<01:28, 276.53 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24374/47780 [01:21<01:11, 328.66 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23260/47780 [01:21<01:31, 268.05 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16237/47780 [01:21<01:27, 358.72 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25536/47780 [01:21<01:09, 319.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24396/47780 [01:21<01:12, 321.38 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24922/47780 [01:21<01:21, 282.15 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23522/47780 [01:21<01:09, 348.78 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23289/47780 [01:21<01:22, 295.65 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23291/47780 [01:21<01:28, 276.91 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24410/47780 [01:21<01:16, 305.65 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16274/47780 [01:21<01:28, 354.43 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25569/47780 [01:21<01:11, 308.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24434/47780 [01:21<01:09, 334.46 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24952/47780 [01:21<01:20, 284.01 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23322/47780 [01:21<01:20, 301.96 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23558/47780 [01:21<01:14, 326.54 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23324/47780 [01:21<01:23, 291.39 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24447/47780 [01:21<01:13, 316.83 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16311/47780 [01:21<01:29, 351.02 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25602/47780 [01:21<01:11, 311.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24470/47780 [01:21<01:11, 327.28 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24981/47780 [01:21<01:20, 282.27 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23353/47780 [01:21<01:24, 287.45 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23594/47780 [01:21<01:12, 333.41 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23354/47780 [01:21<01:24, 287.54 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24488/47780 [01:21<01:08, 338.48 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25639/47780 [01:21<01:07, 327.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16347/47780 [01:21<01:36, 326.65 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24503/47780 [01:21<01:17, 300.26 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25011/47780 [01:21<01:24, 269.39 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23631/47780 [01:21<01:10, 342.15 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23383/47780 [01:21<01:24, 287.42 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23385/47780 [01:21<01:23, 293.54 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24524/47780 [01:21<01:08, 340.60 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25678/47780 [01:21<01:06, 330.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16380/47780 [01:21<01:39, 315.67 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24534/47780 [01:21<01:21, 284.59 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25043/47780 [01:21<01:21, 280.19 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23420/47780 [01:21<01:19, 308.04 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23673/47780 [01:21<01:07, 356.00 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24563/47780 [01:21<01:05, 354.42 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23415/47780 [01:21<01:27, 279.78 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25713/47780 [01:21<01:06, 329.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16412/47780 [01:21<01:40, 313.25 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24565/47780 [01:21<01:19, 291.26 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23453/47780 [01:21<01:19, 307.27 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25074/47780 [01:21<01:21, 278.66 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24599/47780 [01:21<01:05, 352.95 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23716/47780 [01:21<01:06, 360.61 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23444/47780 [01:21<01:29, 273.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25747/47780 [01:21<01:08, 320.64 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16445/47780 [01:21<01:46, 295.27 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24596/47780 [01:21<01:18, 296.08 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23489/47780 [01:21<01:15, 322.19 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25103/47780 [01:21<01:21, 279.17 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23757/47780 [01:21<01:04, 374.12 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23474/47780 [01:21<01:26, 280.78 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24635/47780 [01:21<01:07, 342.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25780/47780 [01:21<01:09, 316.16 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16475/47780 [01:22<01:51, 280.80 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25134/47780 [01:21<01:19, 284.66 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23522/47780 [01:21<01:17, 313.33 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23801/47780 [01:21<01:01, 388.66 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24673/47780 [01:22<01:06, 344.94 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23503/47780 [01:22<01:27, 276.74 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24627/47780 [01:22<01:30, 256.78 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25812/47780 [01:22<01:15, 290.77 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16508/47780 [01:22<01:48, 288.47 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25163/47780 [01:22<01:20, 279.83 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23535/47780 [01:22<01:25, 284.09 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24708/47780 [01:22<01:08, 338.93 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24657/47780 [01:22<01:28, 262.66 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23554/47780 [01:22<01:25, 283.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23841/47780 [01:22<01:07, 354.99 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25842/47780 [01:22<01:16, 286.90 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16541/47780 [01:22<01:45, 296.55 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25192/47780 [01:22<01:26, 261.93 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24747/47780 [01:22<01:05, 349.50 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23565/47780 [01:22<01:25, 284.26 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23583/47780 [01:22<01:24, 285.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24688/47780 [01:22<01:24, 272.27 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23878/47780 [01:22<01:10, 340.88 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16575/47780 [01:22<01:42, 305.15 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25871/47780 [01:22<01:20, 273.02 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25223/47780 [01:22<01:22, 272.14 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24717/47780 [01:22<01:23, 277.09 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24783/47780 [01:22<01:07, 340.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23612/47780 [01:22<01:27, 276.90 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23594/47780 [01:22<01:31, 264.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23916/47780 [01:22<01:08, 348.48 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25905/47780 [01:22<01:16, 285.22 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16606/47780 [01:22<01:44, 299.46 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25251/47780 [01:22<01:23, 270.07 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24818/47780 [01:22<01:09, 332.08 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23646/47780 [01:22<01:23, 288.27 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24746/47780 [01:22<01:29, 257.66 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23621/47780 [01:22<01:37, 247.14 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23952/47780 [01:22<01:13, 325.66 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25938/47780 [01:22<01:13, 297.26 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16637/47780 [01:22<01:44, 298.87 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25279/47780 [01:22<01:25, 262.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24858/47780 [01:22<01:07, 339.80 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23676/47780 [01:22<01:25, 282.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24785/47780 [01:22<01:18, 291.41 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23652/47780 [01:22<01:34, 255.75 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23986/47780 [01:22<01:13, 322.23 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25968/47780 [01:22<01:14, 294.12 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16681/47780 [01:22<01:32, 335.89 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24894/47780 [01:22<01:06, 345.22 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25306/47780 [01:22<01:28, 253.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23706/47780 [01:22<01:23, 286.92 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24019/47780 [01:22<01:16, 311.27 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23678/47780 [01:22<01:38, 243.71 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26002/47780 [01:22<01:12, 301.35 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16720/47780 [01:22<01:30, 344.73 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24815/47780 [01:22<01:39, 231.48 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24930/47780 [01:22<01:06, 345.71 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23736/47780 [01:22<01:23, 289.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25335/47780 [01:22<01:26, 260.42 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24052/47780 [01:22<01:15, 312.69 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26038/47780 [01:22<01:08, 315.97 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23703/47780 [01:22<01:41, 237.05 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16756/47780 [01:22<01:32, 336.33 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23770/47780 [01:22<01:19, 301.99 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24965/47780 [01:22<01:07, 338.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25363/47780 [01:22<01:25, 262.61 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26075/47780 [01:22<01:05, 329.71 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24084/47780 [01:22<01:17, 304.88 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23735/47780 [01:22<01:33, 257.45 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16805/47780 [01:23<01:21, 378.14 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24841/47780 [01:22<01:53, 201.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23804/47780 [01:22<01:17, 309.42 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24999/47780 [01:22<01:08, 331.93 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25390/47780 [01:23<01:31, 245.27 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26112/47780 [01:23<01:04, 337.53 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24116/47780 [01:22<01:17, 305.63 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23766/47780 [01:23<01:28, 271.95 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24914/47780 [01:23<01:12, 313.81 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16844/47780 [01:23<01:28, 350.91 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23839/47780 [01:23<01:17, 307.58 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25033/47780 [01:23<01:11, 316.02 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25419/47780 [01:23<01:27, 254.93 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23807/47780 [01:23<01:17, 310.25 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26146/47780 [01:23<01:06, 326.79 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24147/47780 [01:23<01:19, 296.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24951/47780 [01:23<01:11, 318.26 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16880/47780 [01:23<01:32, 333.18 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25068/47780 [01:23<01:09, 325.20 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23871/47780 [01:23<01:20, 296.98 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25445/47780 [01:23<01:33, 237.86 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26187/47780 [01:23<01:01, 350.38 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24180/47780 [01:23<01:17, 302.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23839/47780 [01:23<01:22, 290.02 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24987/47780 [01:23<01:13, 309.91 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16914/47780 [01:23<01:34, 326.30 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23908/47780 [01:23<01:16, 313.98 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25101/47780 [01:23<01:11, 316.30 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25473/47780 [01:23<01:29, 249.12 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26223/47780 [01:23<01:02, 345.50 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24213/47780 [01:23<01:16, 307.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23871/47780 [01:23<01:21, 292.42 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16949/47780 [01:23<01:32, 332.56 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23940/47780 [01:23<01:16, 312.02 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25021/47780 [01:23<01:17, 293.95 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25146/47780 [01:23<01:04, 349.37 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25505/47780 [01:23<01:22, 268.54 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26258/47780 [01:23<01:02, 342.90 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24249/47780 [01:23<01:13, 318.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23901/47780 [01:23<01:23, 287.64 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23972/47780 [01:23<01:15, 314.29 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25053/47780 [01:23<01:15, 300.27 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25184/47780 [01:23<01:03, 354.70 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25533/47780 [01:23<01:23, 265.75 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16983/47780 [01:23<01:44, 295.16 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26295/47780 [01:23<01:01, 349.00 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24282/47780 [01:23<01:13, 321.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23935/47780 [01:23<01:19, 299.42 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25085/47780 [01:23<01:15, 299.46 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25220/47780 [01:23<01:04, 347.91 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24004/47780 [01:23<01:20, 295.34 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25566/47780 [01:23<01:19, 281.13 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17019/47780 [01:23<01:40, 305.82 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24315/47780 [01:23<01:17, 303.08 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26330/47780 [01:23<01:06, 320.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23966/47780 [01:23<01:21, 292.43 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25128/47780 [01:23<01:07, 334.49 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25255/47780 [01:23<01:05, 344.80 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24037/47780 [01:23<01:18, 301.74 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25599/47780 [01:23<01:16, 288.53 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17051/47780 [01:23<01:39, 308.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26365/47780 [01:23<01:07, 318.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23996/47780 [01:23<01:23, 284.77 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24346/47780 [01:23<01:23, 279.52 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25290/47780 [01:23<01:05, 341.72 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25166/47780 [01:23<01:08, 328.89 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24071/47780 [01:23<01:17, 305.64 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17090/47780 [01:23<01:33, 328.34 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25629/47780 [01:23<01:18, 282.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26398/47780 [01:23<01:07, 317.19 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24413/47780 [01:23<01:02, 376.70 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24025/47780 [01:23<01:26, 273.60 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25202/47780 [01:23<01:06, 337.04 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25325/47780 [01:23<01:07, 333.24 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24103/47780 [01:23<01:18, 302.83 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17131/47780 [01:24<01:28, 347.06 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25658/47780 [01:23<01:19, 278.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26430/47780 [01:23<01:07, 315.83 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24053/47780 [01:24<01:28, 267.05 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24453/47780 [01:23<01:03, 366.79 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25363/47780 [01:24<01:04, 346.36 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25237/47780 [01:24<01:08, 329.26 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24141/47780 [01:24<01:13, 321.07 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17168/47780 [01:24<01:27, 349.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25690/47780 [01:24<01:17, 286.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26462/47780 [01:24<01:08, 312.97 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24081/47780 [01:24<01:28, 267.64 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24492/47780 [01:24<01:03, 365.08 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25399/47780 [01:24<01:06, 335.05 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25271/47780 [01:24<01:09, 321.65 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17204/47780 [01:24<01:29, 341.10 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24174/47780 [01:24<01:17, 305.92 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25719/47780 [01:24<01:18, 281.04 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26494/47780 [01:24<01:10, 300.65 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24117/47780 [01:24<01:20, 293.45 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24533/47780 [01:24<01:02, 373.66 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25434/47780 [01:24<01:06, 335.42 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17250/47780 [01:24<01:22, 370.58 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25312/47780 [01:24<01:07, 331.99 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24205/47780 [01:24<01:18, 300.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25748/47780 [01:24<01:18, 280.21 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26525/47780 [01:24<01:13, 289.11 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24147/47780 [01:24<01:22, 285.73 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24571/47780 [01:24<01:05, 355.27 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24240/47780 [01:24<01:14, 314.39 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25468/47780 [01:24<01:10, 315.15 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25781/47780 [01:24<01:15, 291.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17288/47780 [01:24<01:26, 353.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25346/47780 [01:24<01:13, 306.64 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26557/47780 [01:24<01:13, 289.67 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24608/47780 [01:24<01:07, 343.81 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24275/47780 [01:24<01:12, 324.48 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25811/47780 [01:24<01:15, 291.78 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25500/47780 [01:24<01:11, 312.51 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17324/47780 [01:24<01:25, 354.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24177/47780 [01:24<01:36, 245.34 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25381/47780 [01:24<01:11, 315.32 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24314/47780 [01:24<01:08, 343.23 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25849/47780 [01:24<01:09, 313.74 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25532/47780 [01:24<01:11, 311.29 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24643/47780 [01:24<01:10, 327.63 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24223/47780 [01:24<01:18, 300.09 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26587/47780 [01:24<01:24, 250.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17360/47780 [01:24<01:28, 344.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25413/47780 [01:24<01:10, 316.24 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25567/47780 [01:24<01:09, 318.04 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25881/47780 [01:24<01:12, 303.60 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24267/47780 [01:24<01:11, 330.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26627/47780 [01:24<01:15, 280.08 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17396/47780 [01:24<01:30, 337.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24349/47780 [01:24<01:15, 312.11 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24677/47780 [01:24<01:15, 305.09 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25445/47780 [01:24<01:23, 268.49 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25600/47780 [01:24<01:10, 314.94 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25916/47780 [01:24<01:09, 313.56 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24302/47780 [01:24<01:11, 329.83 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24381/47780 [01:24<01:15, 311.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17433/47780 [01:24<01:28, 342.84 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26656/47780 [01:24<01:17, 274.07 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24709/47780 [01:24<01:15, 305.90 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25492/47780 [01:24<01:14, 299.23 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25632/47780 [01:24<01:10, 312.77 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25951/47780 [01:24<01:08, 320.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17470/47780 [01:25<01:26, 350.28 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24740/47780 [01:24<01:15, 306.99 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24336/47780 [01:24<01:13, 319.44 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26685/47780 [01:24<01:17, 272.72 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24413/47780 [01:24<01:18, 298.71 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25523/47780 [01:25<01:15, 293.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25664/47780 [01:25<01:11, 308.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17506/47780 [01:25<01:26, 349.06 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25984/47780 [01:25<01:12, 302.23 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26713/47780 [01:25<01:18, 268.16 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24771/47780 [01:24<01:19, 288.20 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24444/47780 [01:25<01:23, 279.84 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24369/47780 [01:25<01:22, 285.42 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25696/47780 [01:25<01:11, 307.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17541/47780 [01:25<01:27, 345.32 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25553/47780 [01:25<01:21, 272.16 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26016/47780 [01:25<01:13, 297.12 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24803/47780 [01:25<01:18, 293.87 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26741/47780 [01:25<01:23, 252.64 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24475/47780 [01:25<01:25, 271.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24399/47780 [01:25<01:24, 277.82 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17577/47780 [01:25<01:28, 341.88 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25727/47780 [01:25<01:16, 288.56 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25583/47780 [01:25<01:20, 276.53 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26047/47780 [01:25<01:13, 297.27 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24833/47780 [01:25<01:21, 283.04 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26771/47780 [01:25<01:20, 262.48 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24507/47780 [01:25<01:23, 277.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24428/47780 [01:25<01:26, 270.05 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17615/47780 [01:25<01:26, 348.78 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25763/47780 [01:25<01:11, 308.21 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26077/47780 [01:25<01:14, 291.36 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25612/47780 [01:25<01:21, 271.44 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26801/47780 [01:25<01:16, 272.73 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24870/47780 [01:25<01:15, 304.01 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24456/47780 [01:25<01:26, 269.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24535/47780 [01:25<01:27, 266.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17658/47780 [01:25<01:20, 372.19 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25799/47780 [01:25<01:08, 319.54 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25641/47780 [01:25<01:21, 270.51 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26840/47780 [01:25<01:08, 305.52 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26107/47780 [01:25<01:16, 284.06 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24901/47780 [01:25<01:18, 291.61 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24484/47780 [01:25<01:25, 272.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24562/47780 [01:25<01:31, 253.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17703/47780 [01:25<01:16, 394.85 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25832/47780 [01:25<01:12, 301.87 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25670/47780 [01:25<01:20, 275.48 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26871/47780 [01:25<01:09, 301.11 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24932/47780 [01:25<01:18, 290.64 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26137/47780 [01:25<01:21, 264.94 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24514/47780 [01:25<01:27, 265.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24592/47780 [01:25<01:27, 265.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17743/47780 [01:25<01:16, 391.63 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25863/47780 [01:25<01:12, 300.68 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26904/47780 [01:25<01:07, 308.37 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25701/47780 [01:25<01:19, 279.28 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26173/47780 [01:25<01:15, 287.67 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24962/47780 [01:25<01:21, 280.96 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17790/47780 [01:25<01:13, 410.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24542/47780 [01:25<01:30, 257.50 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24619/47780 [01:25<01:33, 247.39 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25730/47780 [01:25<01:18, 279.26 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26937/47780 [01:25<01:06, 311.13 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25894/47780 [01:25<01:17, 284.13 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26207/47780 [01:25<01:12, 298.71 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24991/47780 [01:25<01:21, 280.35 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17833/47780 [01:25<01:12, 411.30 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24568/47780 [01:25<01:30, 256.11 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24648/47780 [01:25<01:31, 253.75 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26972/47780 [01:25<01:05, 318.56 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25759/47780 [01:25<01:22, 267.06 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25927/47780 [01:25<01:15, 290.33 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26238/47780 [01:25<01:12, 298.56 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25022/47780 [01:25<01:19, 285.50 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17875/47780 [01:26<01:12, 413.33 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24594/47780 [01:25<01:31, 254.38 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27004/47780 [01:26<01:07, 308.01 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24675/47780 [01:25<01:37, 238.02 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25960/47780 [01:26<01:13, 298.13 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25786/47780 [01:26<01:23, 264.38 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25069/47780 [01:25<01:07, 334.08 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26269/47780 [01:26<01:16, 282.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24620/47780 [01:26<01:30, 255.44 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17917/47780 [01:26<01:19, 375.54 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27041/47780 [01:26<01:03, 325.41 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25992/47780 [01:26<01:11, 303.97 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24702/47780 [01:26<01:37, 235.86 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25813/47780 [01:26<01:25, 257.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26302/47780 [01:26<01:12, 295.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24646/47780 [01:26<01:31, 254.08 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25104/47780 [01:26<01:15, 300.75 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27075/47780 [01:26<01:05, 315.71 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17956/47780 [01:26<01:25, 349.06 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25845/47780 [01:26<01:20, 272.23 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24732/47780 [01:26<01:32, 248.48 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26023/47780 [01:26<01:15, 286.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26332/47780 [01:26<01:12, 293.84 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24673/47780 [01:26<01:32, 250.26 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25135/47780 [01:26<01:17, 293.84 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27115/47780 [01:26<01:00, 339.49 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17998/47780 [01:26<01:21, 364.02 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24759/47780 [01:26<01:31, 250.66 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25873/47780 [01:26<01:25, 256.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26362/47780 [01:26<01:15, 282.01 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24704/47780 [01:26<01:26, 267.13 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26052/47780 [01:26<01:29, 244.13 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27156/47780 [01:26<00:57, 355.92 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25165/47780 [01:26<01:26, 262.41 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18036/47780 [01:26<01:22, 360.56 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24786/47780 [01:26<01:30, 253.08 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25901/47780 [01:26<01:24, 257.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26391/47780 [01:26<01:16, 278.58 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24731/47780 [01:26<01:27, 264.71 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18075/47780 [01:26<01:20, 368.60 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27192/47780 [01:26<01:01, 337.36 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25193/47780 [01:26<01:29, 253.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24812/47780 [01:26<01:37, 236.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26078/47780 [01:26<01:43, 210.09 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25927/47780 [01:26<01:29, 244.72 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24758/47780 [01:26<01:26, 266.06 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26420/47780 [01:26<01:20, 264.09 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18116/47780 [01:26<01:18, 380.01 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27227/47780 [01:26<01:00, 337.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25223/47780 [01:26<01:25, 262.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24845/47780 [01:26<01:30, 253.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24789/47780 [01:26<01:23, 276.28 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26457/47780 [01:26<01:12, 293.05 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25958/47780 [01:26<01:27, 248.95 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26101/47780 [01:26<01:47, 201.55 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18155/47780 [01:26<01:18, 378.49 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25254/47780 [01:26<01:22, 272.25 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27261/47780 [01:26<01:05, 315.47 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24871/47780 [01:26<01:31, 249.98 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24817/47780 [01:26<01:23, 274.16 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26487/47780 [01:26<01:13, 291.35 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26146/47780 [01:26<01:23, 258.30 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25984/47780 [01:26<01:33, 234.31 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18196/47780 [01:26<01:16, 387.50 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25283/47780 [01:26<01:22, 271.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24897/47780 [01:26<01:30, 252.53 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27293/47780 [01:26<01:09, 295.10 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24845/47780 [01:26<01:27, 263.10 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26520/47780 [01:26<01:11, 296.01 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26210/47780 [01:26<01:00, 354.47 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26012/47780 [01:26<01:28, 246.26 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18235/47780 [01:27<01:19, 371.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25314/47780 [01:26<01:21, 275.78 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24923/47780 [01:26<01:32, 246.40 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27334/47780 [01:27<01:03, 322.11 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26559/47780 [01:27<01:05, 322.64 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24873/47780 [01:27<01:28, 259.28 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26249/47780 [01:27<01:00, 355.71 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26039/47780 [01:27<01:26, 250.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18275/47780 [01:27<01:20, 367.63 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24949/47780 [01:27<01:31, 250.20 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25342/47780 [01:27<01:27, 254.98 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26592/47780 [01:27<01:06, 320.97 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27367/47780 [01:27<01:05, 310.78 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24901/47780 [01:27<01:28, 259.48 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26065/47780 [01:27<01:29, 241.96 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26287/47780 [01:27<01:06, 321.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18322/47780 [01:27<01:14, 395.89 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24976/47780 [01:27<01:30, 253.24 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26628/47780 [01:27<01:03, 332.11 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27405/47780 [01:27<01:01, 329.65 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25368/47780 [01:27<01:31, 245.07 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24928/47780 [01:27<01:28, 259.33 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26090/47780 [01:27<01:29, 242.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18364/47780 [01:27<01:13, 398.29 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26323/47780 [01:27<01:10, 303.06 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25007/47780 [01:27<01:26, 263.42 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27440/47780 [01:27<01:00, 334.43 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25396/47780 [01:27<01:28, 251.88 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26663/47780 [01:27<01:06, 318.06 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24954/47780 [01:27<01:30, 250.88 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26116/47780 [01:27<01:32, 233.25 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18405/47780 [01:27<01:19, 371.53 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25034/47780 [01:27<01:26, 264.30 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25427/47780 [01:27<01:24, 264.78 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27474/47780 [01:27<01:03, 318.83 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24980/47780 [01:27<01:31, 247.99 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26355/47780 [01:27<01:18, 273.76 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26696/47780 [01:27<01:13, 285.87 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26140/47780 [01:27<01:35, 227.63 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25064/47780 [01:27<01:24, 269.13 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18443/47780 [01:27<01:23, 350.72 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25455/47780 [01:27<01:23, 266.17 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27507/47780 [01:27<01:04, 314.62 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26385/47780 [01:27<01:16, 278.13 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25009/47780 [01:27<01:29, 254.11 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26733/47780 [01:27<01:08, 305.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26168/47780 [01:27<01:29, 241.93 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25091/47780 [01:27<01:26, 263.29 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18479/47780 [01:27<01:26, 338.08 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25485/47780 [01:27<01:21, 272.60 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25040/47780 [01:27<01:25, 267.08 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27539/47780 [01:27<01:06, 302.38 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26767/47780 [01:27<01:08, 305.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26199/47780 [01:27<01:24, 255.41 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26414/47780 [01:27<01:26, 248.27 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25118/47780 [01:27<01:29, 253.62 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25514/47780 [01:27<01:21, 274.45 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25067/47780 [01:27<01:25, 265.91 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18515/47780 [01:27<01:31, 320.09 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27573/47780 [01:27<01:05, 309.30 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26226/47780 [01:27<01:23, 256.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26799/47780 [01:27<01:09, 302.01 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26440/47780 [01:27<01:30, 235.21 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25148/47780 [01:27<01:26, 262.21 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25554/47780 [01:27<01:13, 303.57 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18552/47780 [01:27<01:27, 333.19 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27605/47780 [01:27<01:05, 309.08 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25094/47780 [01:27<01:31, 247.95 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26256/47780 [01:27<01:20, 268.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26830/47780 [01:27<01:10, 298.27 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26467/47780 [01:27<01:28, 241.39 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25589/47780 [01:27<01:10, 316.83 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25178/47780 [01:27<01:26, 262.79 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27652/47780 [01:27<00:57, 351.28 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26284/47780 [01:28<01:21, 263.09 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26864/47780 [01:28<01:07, 307.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18586/47780 [01:28<01:38, 296.54 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25120/47780 [01:28<01:38, 231.17 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26494/47780 [01:28<01:27, 243.73 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25621/47780 [01:27<01:10, 314.14 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25212/47780 [01:28<01:20, 281.21 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27688/47780 [01:28<00:59, 340.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26312/47780 [01:28<01:20, 267.78 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18647/47780 [01:28<01:19, 365.61 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25175/47780 [01:28<01:12, 310.15 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26896/47780 [01:28<01:10, 295.81 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25653/47780 [01:28<01:11, 308.67 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25241/47780 [01:28<01:19, 283.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26519/47780 [01:28<01:34, 223.99 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27723/47780 [01:28<01:03, 316.00 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26339/47780 [01:28<01:22, 259.62 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26928/47780 [01:28<01:09, 299.73 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18685/47780 [01:28<01:20, 361.86 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25209/47780 [01:28<01:13, 308.01 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25685/47780 [01:28<01:11, 308.35 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25270/47780 [01:28<01:23, 269.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26543/47780 [01:28<01:35, 223.21 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27761/47780 [01:28<01:00, 329.79 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26367/47780 [01:28<01:22, 259.60 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18725/47780 [01:28<01:18, 368.13 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25242/47780 [01:28<01:12, 310.94 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26961/47780 [01:28<01:09, 298.18 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25716/47780 [01:28<01:11, 307.09 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26574/47780 [01:28<01:26, 243.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25298/47780 [01:28<01:26, 260.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27796/47780 [01:28<00:59, 334.94 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26400/47780 [01:28<01:16, 279.63 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18767/47780 [01:28<01:15, 382.26 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25279/47780 [01:28<01:08, 327.34 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 26996/47780 [01:28<01:07, 309.23 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25748/47780 [01:28<01:17, 285.90 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26599/47780 [01:28<01:30, 232.88 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25325/47780 [01:28<01:30, 247.24 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27832/47780 [01:28<00:59, 335.02 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25314/47780 [01:28<01:08, 330.13 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18806/47780 [01:28<01:19, 364.05 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27028/47780 [01:28<01:10, 295.34 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26429/47780 [01:28<01:25, 250.65 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26634/47780 [01:28<01:20, 264.23 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25781/47780 [01:28<01:16, 288.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25354/47780 [01:28<01:27, 256.10 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27866/47780 [01:28<01:00, 328.30 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25349/47780 [01:28<01:07, 331.84 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18846/47780 [01:28<01:17, 373.93 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26455/47780 [01:28<01:25, 250.26 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27058/47780 [01:28<01:15, 275.12 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26663/47780 [01:28<01:18, 268.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25820/47780 [01:28<01:10, 313.08 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25381/47780 [01:28<01:28, 253.80 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27899/47780 [01:28<01:03, 311.29 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25383/47780 [01:28<01:11, 312.70 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26488/47780 [01:28<01:19, 269.48 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18884/47780 [01:28<01:21, 355.01 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27096/47780 [01:28<01:08, 300.47 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26691/47780 [01:28<01:17, 271.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25852/47780 [01:28<01:10, 311.67 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25414/47780 [01:28<01:22, 272.41 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27931/47780 [01:28<01:04, 306.87 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26516/47780 [01:28<01:18, 272.01 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25415/47780 [01:28<01:12, 307.86 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27140/47780 [01:28<01:02, 329.47 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26719/47780 [01:28<01:18, 268.22 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18920/47780 [01:29<01:30, 317.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25884/47780 [01:28<01:10, 311.64 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25452/47780 [01:28<01:13, 302.55 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25449/47780 [01:28<01:11, 313.41 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26544/47780 [01:29<01:23, 254.41 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27174/47780 [01:29<01:02, 331.03 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27962/47780 [01:29<01:15, 263.93 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18961/47780 [01:29<01:25, 338.95 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25916/47780 [01:28<01:09, 312.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26747/47780 [01:29<01:20, 262.45 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25490/47780 [01:29<01:09, 321.05 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26570/47780 [01:29<01:24, 250.35 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27208/47780 [01:29<01:03, 322.49 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19001/47780 [01:29<01:20, 355.38 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25953/47780 [01:29<01:06, 329.38 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28004/47780 [01:29<01:05, 303.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25481/47780 [01:29<01:21, 271.98 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26774/47780 [01:29<01:22, 253.11 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25523/47780 [01:29<01:16, 290.44 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26597/47780 [01:29<01:24, 250.26 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27248/47780 [01:29<01:00, 340.50 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28036/47780 [01:29<01:04, 304.61 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19039/47780 [01:29<01:22, 346.56 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25987/47780 [01:29<01:08, 317.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25513/47780 [01:29<01:19, 281.59 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26800/47780 [01:29<01:24, 246.93 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25553/47780 [01:29<01:16, 289.40 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26625/47780 [01:29<01:23, 252.98 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19079/47780 [01:29<01:20, 357.60 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26026/47780 [01:29<01:06, 327.19 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28068/47780 [01:29<01:09, 283.66 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26832/47780 [01:29<01:19, 264.23 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27283/47780 [01:29<01:06, 307.53 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25583/47780 [01:29<01:17, 284.61 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25542/47780 [01:29<01:31, 242.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26655/47780 [01:29<01:22, 257.48 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26062/47780 [01:29<01:05, 332.77 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19116/47780 [01:29<01:22, 348.58 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27315/47780 [01:29<01:06, 308.17 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26861/47780 [01:29<01:19, 264.07 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28098/47780 [01:29<01:11, 276.77 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25568/47780 [01:29<01:31, 241.89 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25612/47780 [01:29<01:21, 273.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26683/47780 [01:29<01:20, 263.56 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19152/47780 [01:29<01:22, 344.96 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26893/47780 [01:29<01:15, 275.26 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26096/47780 [01:29<01:11, 303.55 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27347/47780 [01:29<01:11, 286.39 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28127/47780 [01:29<01:14, 263.35 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25595/47780 [01:29<01:29, 246.58 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25640/47780 [01:29<01:28, 250.87 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26710/47780 [01:29<01:22, 254.01 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19197/47780 [01:29<01:16, 374.39 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26935/47780 [01:29<01:08, 305.79 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26132/47780 [01:29<01:09, 312.18 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27388/47780 [01:29<01:04, 316.95 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28154/47780 [01:29<01:18, 249.36 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25621/47780 [01:29<01:31, 242.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26740/47780 [01:29<01:18, 266.68 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19235/47780 [01:29<01:17, 366.85 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25666/47780 [01:29<01:35, 230.72 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26967/47780 [01:29<01:07, 306.48 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26164/47780 [01:29<01:11, 304.25 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27429/47780 [01:29<01:01, 330.12 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28185/47780 [01:29<01:14, 262.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25646/47780 [01:29<01:32, 240.23 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26769/47780 [01:29<01:17, 270.42 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19279/47780 [01:29<01:14, 384.07 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25692/47780 [01:29<01:33, 235.67 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27004/47780 [01:29<01:04, 320.96 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27472/47780 [01:29<00:58, 349.88 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28214/47780 [01:29<01:12, 269.93 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26195/47780 [01:29<01:14, 289.90 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25671/47780 [01:29<01:36, 229.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26798/47780 [01:29<01:16, 275.79 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19327/47780 [01:30<01:09, 411.35 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25718/47780 [01:29<01:32, 239.73 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27037/47780 [01:30<01:04, 321.79 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28245/47780 [01:30<01:09, 281.02 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27510/47780 [01:30<00:57, 350.46 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26227/47780 [01:29<01:13, 294.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25706/47780 [01:30<01:25, 259.24 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26832/47780 [01:30<01:13, 284.84 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19370/47780 [01:30<01:10, 402.65 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25743/47780 [01:30<01:34, 232.41 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26260/47780 [01:30<01:10, 304.55 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27071/47780 [01:30<01:11, 290.65 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28283/47780 [01:30<01:06, 293.45 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27546/47780 [01:30<00:59, 337.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25744/47780 [01:30<01:16, 289.43 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26861/47780 [01:30<01:18, 265.11 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19411/47780 [01:30<01:13, 387.38 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25775/47780 [01:30<01:30, 242.97 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26291/47780 [01:30<01:11, 299.39 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27101/47780 [01:30<01:11, 290.35 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28315/47780 [01:30<01:05, 296.63 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27581/47780 [01:30<01:01, 327.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25778/47780 [01:30<01:12, 303.62 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26893/47780 [01:30<01:15, 277.13 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19458/47780 [01:30<01:09, 410.37 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25804/47780 [01:30<01:26, 255.43 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26329/47780 [01:30<01:06, 322.05 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27133/47780 [01:30<01:11, 289.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25817/47780 [01:30<01:07, 324.77 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28345/47780 [01:30<01:10, 274.43 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26922/47780 [01:30<01:14, 280.71 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27614/47780 [01:30<01:09, 292.22 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19500/47780 [01:30<01:11, 395.23 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25837/47780 [01:30<01:21, 270.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26365/47780 [01:30<01:04, 332.90 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27164/47780 [01:30<01:13, 279.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28376/47780 [01:30<01:08, 283.57 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25850/47780 [01:30<01:10, 311.61 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26954/47780 [01:30<01:11, 291.93 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27653/47780 [01:30<01:03, 314.62 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19540/47780 [01:30<01:11, 393.32 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26399/47780 [01:30<01:05, 323.98 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25865/47780 [01:30<01:28, 247.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27196/47780 [01:30<01:12, 284.97 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28408/47780 [01:30<01:06, 289.31 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25882/47780 [01:30<01:11, 305.11 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26984/47780 [01:30<01:14, 280.91 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27686/47780 [01:30<01:08, 293.59 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19580/47780 [01:30<01:18, 360.99 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26432/47780 [01:30<01:07, 318.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27242/47780 [01:30<01:01, 332.70 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25895/47780 [01:30<01:27, 251.29 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28444/47780 [01:30<01:04, 299.27 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25917/47780 [01:30<01:09, 312.82 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27013/47780 [01:30<01:14, 277.58 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27717/47780 [01:30<01:08, 291.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19627/47780 [01:30<01:12, 390.38 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25922/47780 [01:30<01:26, 253.58 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26464/47780 [01:30<01:13, 290.18 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25953/47780 [01:30<01:07, 322.54 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28475/47780 [01:30<01:06, 289.20 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27042/47780 [01:30<01:17, 268.80 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19667/47780 [01:30<01:13, 380.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27747/47780 [01:30<01:13, 273.24 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25953/47780 [01:30<01:21, 268.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27276/47780 [01:30<01:20, 256.10 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26494/47780 [01:30<01:14, 285.06 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25986/47780 [01:30<01:07, 321.16 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28505/47780 [01:30<01:07, 285.66 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27070/47780 [01:30<01:19, 260.33 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19706/47780 [01:31<01:14, 378.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27776/47780 [01:30<01:12, 275.05 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25984/47780 [01:30<01:18, 277.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27317/47780 [01:31<01:10, 290.08 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26526/47780 [01:30<01:12, 293.14 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26022/47780 [01:31<01:05, 329.67 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28535/47780 [01:31<01:07, 283.63 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27106/47780 [01:31<01:13, 281.70 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27807/47780 [01:31<01:10, 284.22 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19745/47780 [01:31<01:16, 368.21 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27353/47780 [01:31<01:06, 307.36 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26559/47780 [01:31<01:10, 302.14 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28567/47780 [01:31<01:05, 293.81 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26013/47780 [01:31<01:26, 251.61 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26056/47780 [01:31<01:14, 293.31 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27146/47780 [01:31<01:06, 311.29 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19785/47780 [01:31<01:15, 370.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27838/47780 [01:31<01:09, 285.33 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27387/47780 [01:31<01:05, 312.92 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26595/47780 [01:31<01:07, 315.05 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28597/47780 [01:31<01:04, 295.33 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26039/47780 [01:31<01:28, 246.57 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19830/47780 [01:31<01:11, 388.30 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26088/47780 [01:31<01:19, 274.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27867/47780 [01:31<01:11, 278.12 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27421/47780 [01:31<01:04, 316.96 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26627/47780 [01:31<01:07, 312.90 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28631/47780 [01:31<01:02, 305.56 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27178/47780 [01:31<01:18, 263.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26065/47780 [01:31<01:32, 234.92 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26124/47780 [01:31<01:15, 287.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19872/47780 [01:31<01:12, 384.06 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27895/47780 [01:31<01:14, 265.81 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27454/47780 [01:31<01:06, 306.62 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28664/47780 [01:31<01:01, 308.43 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27206/47780 [01:31<01:17, 264.70 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26664/47780 [01:31<01:08, 307.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26098/47780 [01:31<01:24, 256.28 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19911/47780 [01:31<01:15, 369.44 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27922/47780 [01:31<01:15, 264.18 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26154/47780 [01:31<01:18, 276.58 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27486/47780 [01:31<01:06, 307.25 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28712/47780 [01:31<00:53, 354.25 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27234/47780 [01:31<01:18, 262.86 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26707/47780 [01:31<01:04, 327.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26126/47780 [01:31<01:22, 260.92 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27952/47780 [01:31<01:13, 268.25 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27518/47780 [01:31<01:06, 303.95 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26183/47780 [01:31<01:20, 268.75 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19949/47780 [01:31<01:19, 349.00 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28748/47780 [01:31<00:54, 351.53 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27262/47780 [01:31<01:16, 267.45 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26740/47780 [01:31<01:06, 314.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26153/47780 [01:31<01:25, 253.61 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27553/47780 [01:31<01:04, 313.38 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26212/47780 [01:31<01:19, 271.25 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19985/47780 [01:31<01:20, 344.57 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28785/47780 [01:31<00:56, 333.86 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27290/47780 [01:31<01:21, 251.85 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26772/47780 [01:31<01:09, 303.98 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26183/47780 [01:31<01:21, 265.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27979/47780 [01:31<01:29, 221.14 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27589/47780 [01:31<01:01, 326.47 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26243/47780 [01:31<01:17, 279.13 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20023/47780 [01:31<01:19, 347.98 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27317/47780 [01:31<01:21, 251.09 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28820/47780 [01:31<00:58, 323.65 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28031/47780 [01:31<01:06, 295.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26803/47780 [01:31<01:12, 290.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26211/47780 [01:31<01:24, 254.93 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26272/47780 [01:31<01:17, 279.06 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27622/47780 [01:31<01:04, 313.30 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20061/47780 [01:32<01:17, 355.42 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27367/47780 [01:32<01:04, 315.74 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28858/47780 [01:31<00:56, 332.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26833/47780 [01:31<01:13, 284.76 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26240/47780 [01:32<01:22, 261.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28063/47780 [01:32<01:08, 288.55 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27655/47780 [01:32<01:03, 317.75 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26303/47780 [01:32<01:17, 278.20 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20097/47780 [01:32<01:26, 320.47 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28892/47780 [01:32<00:57, 326.63 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26270/47780 [01:32<01:19, 269.63 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27400/47780 [01:32<01:10, 290.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26867/47780 [01:32<01:11, 290.52 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28095/47780 [01:32<01:08, 289.22 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26333/47780 [01:32<01:17, 278.26 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27689/47780 [01:32<01:06, 300.19 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20130/47780 [01:32<01:30, 305.31 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26299/47780 [01:32<01:18, 275.39 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26899/47780 [01:32<01:10, 295.25 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28129/47780 [01:32<01:05, 299.64 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27439/47780 [01:32<01:06, 307.14 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28926/47780 [01:32<01:02, 300.14 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27722/47780 [01:32<01:05, 304.94 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26365/47780 [01:32<01:17, 277.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20180/47780 [01:32<01:17, 356.75 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28957/47780 [01:32<01:02, 302.75 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28164/47780 [01:32<01:03, 310.17 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27471/47780 [01:32<01:06, 307.34 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26929/47780 [01:32<01:14, 280.29 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26328/47780 [01:32<01:24, 253.24 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26393/47780 [01:32<01:17, 274.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27759/47780 [01:32<01:03, 316.13 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28988/47780 [01:32<01:03, 296.59 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28196/47780 [01:32<01:04, 305.95 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27503/47780 [01:32<01:06, 303.49 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26961/47780 [01:32<01:12, 285.66 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26428/47780 [01:32<01:13, 289.79 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26354/47780 [01:32<01:34, 225.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27792/47780 [01:32<01:06, 299.87 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20217/47780 [01:32<01:43, 266.69 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27535/47780 [01:32<01:06, 305.34 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28228/47780 [01:32<01:04, 303.22 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29019/47780 [01:32<01:04, 292.56 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26466/47780 [01:32<01:07, 315.28 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26990/47780 [01:32<01:21, 255.36 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26400/47780 [01:32<01:16, 279.94 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27825/47780 [01:32<01:04, 308.06 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20285/47780 [01:32<01:17, 356.94 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27568/47780 [01:32<01:04, 312.20 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28259/47780 [01:32<01:03, 305.06 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29052/47780 [01:32<01:02, 299.59 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27033/47780 [01:32<01:09, 298.16 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26430/47780 [01:32<01:15, 281.48 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26498/47780 [01:32<01:13, 289.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27857/47780 [01:32<01:08, 291.39 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27605/47780 [01:32<01:02, 325.22 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28293/47780 [01:32<01:02, 311.54 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29088/47780 [01:32<01:00, 309.68 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20327/47780 [01:32<01:18, 349.48 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27064/47780 [01:32<01:10, 294.83 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26459/47780 [01:32<01:17, 275.49 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26528/47780 [01:32<01:13, 289.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27887/47780 [01:32<01:08, 290.62 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27638/47780 [01:32<01:03, 319.10 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29121/47780 [01:32<00:59, 311.90 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28326/47780 [01:32<01:07, 286.99 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20366/47780 [01:33<01:23, 327.37 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26488/47780 [01:32<01:17, 276.32 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26561/47780 [01:32<01:10, 300.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27095/47780 [01:32<01:13, 283.12 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27917/47780 [01:32<01:09, 285.88 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29158/47780 [01:32<00:57, 321.12 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27676/47780 [01:33<01:02, 320.72 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28356/47780 [01:33<01:12, 269.72 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26592/47780 [01:33<01:10, 299.86 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20402/47780 [01:33<01:27, 314.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26518/47780 [01:33<01:18, 271.04 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27132/47780 [01:32<01:10, 291.33 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27946/47780 [01:33<01:14, 267.35 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27709/47780 [01:33<01:02, 321.02 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29191/47780 [01:33<01:02, 295.16 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28386/47780 [01:33<01:10, 275.17 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20441/47780 [01:33<01:22, 332.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26548/47780 [01:33<01:16, 276.04 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27171/47780 [01:33<01:05, 314.44 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26623/47780 [01:33<01:14, 283.53 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27742/47780 [01:33<01:03, 316.34 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27974/47780 [01:33<01:16, 259.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29226/47780 [01:33<01:02, 298.59 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28414/47780 [01:33<01:16, 254.27 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26580/47780 [01:33<01:16, 278.75 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27203/47780 [01:33<01:07, 302.72 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26654/47780 [01:33<01:15, 281.42 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20476/47780 [01:33<01:31, 299.82 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27774/47780 [01:33<01:05, 303.63 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28001/47780 [01:33<01:19, 248.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29267/47780 [01:33<00:57, 321.89 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28440/47780 [01:33<01:16, 253.12 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26609/47780 [01:33<01:17, 272.94 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27240/47780 [01:33<01:04, 317.67 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26686/47780 [01:33<01:13, 285.88 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20512/47780 [01:33<01:29, 304.15 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28030/47780 [01:33<01:17, 254.52 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27805/47780 [01:33<01:08, 291.83 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29301/47780 [01:33<00:57, 319.58 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28472/47780 [01:33<01:12, 265.57 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27275/47780 [01:33<01:02, 326.10 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26637/47780 [01:33<01:21, 260.37 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26715/47780 [01:33<01:19, 263.45 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20554/47780 [01:33<01:22, 328.64 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27835/47780 [01:33<01:09, 285.02 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29334/47780 [01:33<00:57, 319.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28056/47780 [01:33<01:24, 233.23 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28506/47780 [01:33<01:08, 282.93 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26742/47780 [01:33<01:19, 265.04 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27308/47780 [01:33<01:10, 291.10 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27868/47780 [01:33<01:06, 297.37 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26664/47780 [01:33<01:28, 239.20 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20590/47780 [01:33<01:25, 316.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29367/47780 [01:33<00:57, 318.65 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28080/47780 [01:33<01:25, 229.44 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28535/47780 [01:33<01:07, 284.55 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26769/47780 [01:33<01:21, 258.46 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27338/47780 [01:33<01:10, 290.30 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27899/47780 [01:33<01:06, 297.81 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26689/47780 [01:33<01:28, 237.27 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20629/47780 [01:33<01:22, 328.97 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29399/47780 [01:33<00:58, 315.46 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28124/47780 [01:33<01:09, 281.30 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28574/47780 [01:33<01:01, 314.56 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27369/47780 [01:33<01:09, 292.79 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26807/47780 [01:33<01:12, 288.48 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26713/47780 [01:33<01:28, 237.75 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27929/47780 [01:33<01:07, 294.56 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29433/47780 [01:33<00:57, 318.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20674/47780 [01:33<01:18, 346.73 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28608/47780 [01:33<01:00, 318.69 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28153/47780 [01:33<01:11, 273.72 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27402/47780 [01:33<01:08, 296.53 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26837/47780 [01:33<01:14, 281.65 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26737/47780 [01:33<01:30, 233.45 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27959/47780 [01:33<01:09, 283.17 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20720/47780 [01:34<01:12, 373.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29472/47780 [01:33<00:55, 331.58 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28641/47780 [01:34<01:03, 300.72 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28181/47780 [01:34<01:14, 264.22 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26868/47780 [01:34<01:12, 286.93 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27433/47780 [01:33<01:11, 285.89 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26770/47780 [01:34<01:22, 254.72 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27988/47780 [01:34<01:10, 279.25 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20766/47780 [01:34<01:09, 388.52 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28677/47780 [01:34<01:00, 315.51 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29506/47780 [01:34<01:04, 284.52 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28208/47780 [01:34<01:22, 237.34 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26900/47780 [01:34<01:10, 295.36 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27462/47780 [01:34<01:11, 282.32 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20806/47780 [01:34<01:08, 391.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26796/47780 [01:34<01:25, 245.17 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29550/47780 [01:34<00:56, 322.12 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28709/47780 [01:34<01:06, 286.21 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26930/47780 [01:34<01:11, 293.46 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28017/47780 [01:34<01:28, 224.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28233/47780 [01:34<01:24, 231.07 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27491/47780 [01:34<01:15, 268.38 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26824/47780 [01:34<01:25, 245.24 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20846/47780 [01:34<01:11, 376.99 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29593/47780 [01:34<00:52, 343.53 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28740/47780 [01:34<01:05, 292.41 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26965/47780 [01:34<01:07, 307.09 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28072/47780 [01:34<01:06, 296.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28281/47780 [01:34<01:07, 290.03 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27525/47780 [01:34<01:12, 279.89 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20885/47780 [01:34<01:12, 373.33 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26849/47780 [01:34<01:29, 234.98 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28771/47780 [01:34<01:04, 294.02 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 26996/47780 [01:34<01:08, 304.29 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28321/47780 [01:34<01:00, 319.42 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28115/47780 [01:34<01:00, 327.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29629/47780 [01:34<00:58, 310.79 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27558/47780 [01:34<01:09, 290.55 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20923/47780 [01:34<01:12, 369.95 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26875/47780 [01:34<01:26, 241.44 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27028/47780 [01:34<01:08, 303.25 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28801/47780 [01:34<01:07, 279.71 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28150/47780 [01:34<01:02, 313.30 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28354/47780 [01:34<01:04, 303.00 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27589/47780 [01:34<01:08, 295.64 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29662/47780 [01:34<01:00, 297.33 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20961/47780 [01:34<01:16, 349.00 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28833/47780 [01:34<01:05, 288.09 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26901/47780 [01:34<01:40, 207.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27061/47780 [01:34<01:09, 299.01 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27619/47780 [01:34<01:10, 287.40 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28386/47780 [01:34<01:05, 294.12 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28183/47780 [01:34<01:04, 304.76 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29694/47780 [01:34<01:00, 297.02 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20997/47780 [01:34<01:16, 351.52 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28863/47780 [01:34<01:06, 284.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26923/47780 [01:34<01:42, 202.53 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27648/47780 [01:34<01:09, 288.09 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27091/47780 [01:34<01:15, 274.31 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21033/47780 [01:34<01:17, 346.66 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28215/47780 [01:34<01:07, 290.74 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28416/47780 [01:34<01:09, 277.26 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29725/47780 [01:34<01:07, 266.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28894/47780 [01:34<01:05, 288.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26945/47780 [01:34<01:42, 202.81 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27135/47780 [01:34<01:05, 312.91 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27678/47780 [01:34<01:12, 275.65 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21069/47780 [01:35<01:16, 350.40 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28445/47780 [01:34<01:15, 257.49 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29759/47780 [01:34<01:04, 279.51 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28245/47780 [01:35<01:14, 262.44 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28925/47780 [01:35<01:05, 288.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26973/47780 [01:34<01:34, 220.94 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27167/47780 [01:35<01:06, 307.93 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27706/47780 [01:34<01:13, 273.33 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21105/47780 [01:35<01:16, 349.12 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29790/47780 [01:35<01:02, 287.23 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28472/47780 [01:35<01:15, 254.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28275/47780 [01:35<01:13, 264.08 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 26998/47780 [01:35<01:31, 226.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28954/47780 [01:35<01:08, 276.31 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27199/47780 [01:35<01:07, 303.37 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27734/47780 [01:35<01:13, 272.41 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21146/47780 [01:35<01:14, 358.43 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28498/47780 [01:35<01:15, 255.70 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29820/47780 [01:35<01:06, 270.37 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28303/47780 [01:35<01:15, 257.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28983/47780 [01:35<01:07, 279.95 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27022/47780 [01:35<01:33, 222.73 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27767/47780 [01:35<01:09, 285.93 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21182/47780 [01:35<01:15, 354.39 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27230/47780 [01:35<01:10, 289.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28524/47780 [01:35<01:16, 251.47 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29854/47780 [01:35<01:04, 280.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28330/47780 [01:35<01:15, 258.33 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29012/47780 [01:35<01:09, 270.31 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27050/47780 [01:35<01:29, 230.90 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27796/47780 [01:35<01:11, 280.73 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21224/47780 [01:35<01:11, 369.54 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27260/47780 [01:35<01:16, 269.31 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28550/47780 [01:35<01:19, 242.73 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28363/47780 [01:35<01:10, 274.78 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29885/47780 [01:35<01:02, 284.88 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27081/47780 [01:35<01:22, 250.10 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29040/47780 [01:35<01:11, 261.45 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21262/47780 [01:35<01:11, 372.57 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27825/47780 [01:35<01:14, 267.84 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27288/47780 [01:35<01:17, 263.33 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28582/47780 [01:35<01:14, 257.58 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28399/47780 [01:35<01:04, 298.25 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29914/47780 [01:35<01:03, 282.97 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27107/47780 [01:35<01:24, 244.59 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29067/47780 [01:35<01:15, 247.55 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21300/47780 [01:35<01:14, 354.00 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27853/47780 [01:35<01:16, 259.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27317/47780 [01:35<01:17, 265.17 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28608/47780 [01:35<01:16, 251.21 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28434/47780 [01:35<01:03, 305.99 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27133/47780 [01:35<01:22, 248.89 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29943/47780 [01:35<01:09, 256.44 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29097/47780 [01:35<01:13, 253.47 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21342/47780 [01:35<01:13, 360.40 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27884/47780 [01:35<01:14, 267.65 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27351/47780 [01:35<01:12, 282.64 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28470/47780 [01:35<01:00, 321.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28636/47780 [01:35<01:14, 256.29 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29971/47780 [01:35<01:07, 262.49 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29124/47780 [01:35<01:13, 255.28 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27160/47780 [01:35<01:34, 217.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27911/47780 [01:35<01:17, 257.52 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28503/47780 [01:35<01:00, 316.48 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28670/47780 [01:35<01:10, 270.72 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27380/47780 [01:35<01:17, 263.47 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29998/47780 [01:35<01:08, 258.86 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21379/47780 [01:35<01:32, 286.01 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29159/47780 [01:35<01:06, 278.56 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27938/47780 [01:35<01:16, 260.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27195/47780 [01:35<01:24, 244.30 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28537/47780 [01:35<01:00, 319.79 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27432/47780 [01:35<01:01, 331.88 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28701/47780 [01:35<01:08, 278.83 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30027/47780 [01:35<01:07, 264.44 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29188/47780 [01:36<01:08, 269.53 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27223/47780 [01:36<01:21, 253.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27965/47780 [01:35<01:18, 251.73 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28570/47780 [01:36<01:02, 305.10 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28734/47780 [01:36<01:07, 283.46 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27467/47780 [01:36<01:04, 313.93 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21411/47780 [01:36<01:48, 242.82 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30054/47780 [01:36<01:08, 257.73 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29218/47780 [01:36<01:08, 271.88 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27260/47780 [01:36<01:12, 282.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27996/47780 [01:36<01:13, 267.87 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28601/47780 [01:36<01:03, 302.84 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21517/47780 [01:36<01:02, 423.20 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27500/47780 [01:36<01:07, 301.92 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30080/47780 [01:36<01:10, 252.64 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29246/47780 [01:36<01:10, 262.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28763/47780 [01:36<01:20, 234.89 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27289/47780 [01:36<01:17, 263.45 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28023/47780 [01:36<01:26, 227.16 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30111/47780 [01:36<01:05, 268.66 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28632/47780 [01:36<01:08, 279.64 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27535/47780 [01:36<01:05, 308.28 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29278/47780 [01:36<01:07, 275.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28813/47780 [01:36<01:03, 297.44 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21569/47780 [01:36<01:08, 380.70 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27325/47780 [01:36<01:11, 286.84 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28662/47780 [01:36<01:07, 281.70 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30139/47780 [01:36<01:07, 260.12 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27567/47780 [01:36<01:11, 283.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29311/47780 [01:36<01:04, 287.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28047/47780 [01:36<01:37, 201.54 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28845/47780 [01:36<01:04, 291.36 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27355/47780 [01:36<01:12, 281.64 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21614/47780 [01:36<01:13, 354.41 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28692/47780 [01:36<01:06, 286.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30166/47780 [01:36<01:07, 262.72 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27597/47780 [01:36<01:11, 281.98 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28070/47780 [01:36<01:35, 205.77 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27395/47780 [01:36<01:05, 310.47 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28876/47780 [01:36<01:07, 281.97 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29340/47780 [01:36<01:14, 248.47 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21654/47780 [01:36<01:13, 355.36 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28721/47780 [01:36<01:08, 278.77 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30193/47780 [01:36<01:07, 259.05 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28115/47780 [01:36<01:13, 266.11 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27427/47780 [01:36<01:05, 312.98 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28906/47780 [01:36<01:05, 286.56 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27626/47780 [01:36<01:17, 261.60 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29378/47780 [01:36<01:07, 271.47 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28750/47780 [01:36<01:09, 272.24 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30220/47780 [01:36<01:10, 250.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21693/47780 [01:36<01:18, 332.03 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28936/47780 [01:36<01:04, 290.05 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27653/47780 [01:36<01:16, 263.18 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28144/47780 [01:36<01:16, 258.02 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27459/47780 [01:36<01:10, 288.42 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28782/47780 [01:36<01:08, 276.82 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29406/47780 [01:36<01:12, 254.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30252/47780 [01:36<01:06, 264.22 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21729/47780 [01:36<01:19, 326.19 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27680/47780 [01:36<01:18, 257.27 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28966/47780 [01:36<01:07, 277.30 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28171/47780 [01:36<01:18, 248.73 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27490/47780 [01:36<01:09, 291.42 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29433/47780 [01:36<01:11, 256.38 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28810/47780 [01:36<01:09, 271.67 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30283/47780 [01:36<01:03, 277.05 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21764/47780 [01:37<01:21, 318.18 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27710/47780 [01:36<01:15, 266.15 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28996/47780 [01:37<01:06, 283.42 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27527/47780 [01:37<01:05, 309.81 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28197/47780 [01:36<01:25, 227.75 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28844/47780 [01:37<01:05, 290.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30323/47780 [01:37<00:59, 295.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29462/47780 [01:37<01:14, 246.92 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21797/47780 [01:37<01:22, 313.23 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27738/47780 [01:37<01:15, 267.04 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29025/47780 [01:37<01:07, 275.93 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27560/47780 [01:37<01:06, 303.21 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28222/47780 [01:37<01:24, 230.95 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28874/47780 [01:37<01:08, 277.21 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30353/47780 [01:37<00:58, 296.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29493/47780 [01:37<01:09, 263.46 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21840/47780 [01:37<01:16, 339.92 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27765/47780 [01:37<01:15, 264.95 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29055/47780 [01:37<01:07, 276.88 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28246/47780 [01:37<01:25, 227.42 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27591/47780 [01:37<01:10, 284.79 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28904/47780 [01:37<01:06, 283.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30387/47780 [01:37<00:57, 302.38 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29521/47780 [01:37<01:11, 256.71 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27797/47780 [01:37<01:11, 280.31 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21876/47780 [01:37<01:15, 341.24 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29088/47780 [01:37<01:05, 285.31 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27628/47780 [01:37<01:06, 304.58 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28935/47780 [01:37<01:05, 288.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28276/47780 [01:37<01:22, 235.43 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30419/47780 [01:37<00:58, 297.35 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29554/47780 [01:37<01:08, 267.88 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27827/47780 [01:37<01:09, 285.98 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21913/47780 [01:37<01:17, 334.77 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29122/47780 [01:37<01:02, 300.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28972/47780 [01:37<01:00, 311.81 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28301/47780 [01:37<01:23, 232.00 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30457/47780 [01:37<00:54, 320.67 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27659/47780 [01:37<01:12, 278.15 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29584/47780 [01:37<01:05, 276.49 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27862/47780 [01:37<01:05, 304.60 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21950/47780 [01:37<01:15, 344.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29153/47780 [01:37<01:04, 290.34 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27895/47780 [01:37<01:04, 308.85 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29004/47780 [01:37<01:06, 284.41 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28325/47780 [01:37<01:27, 221.43 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29612/47780 [01:37<01:08, 265.77 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30490/47780 [01:37<00:58, 295.82 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21985/47780 [01:37<01:16, 338.52 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27688/47780 [01:37<01:18, 257.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29185/47780 [01:37<01:02, 298.44 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27934/47780 [01:37<01:01, 325.08 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28352/47780 [01:37<01:26, 225.46 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29646/47780 [01:37<01:04, 279.93 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27722/47780 [01:37<01:13, 272.66 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29034/47780 [01:37<01:11, 262.51 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29221/47780 [01:37<00:59, 312.90 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30521/47780 [01:37<01:02, 278.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22021/47780 [01:37<01:22, 312.76 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28376/47780 [01:37<01:25, 226.91 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29680/47780 [01:37<01:02, 290.20 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27967/47780 [01:37<01:04, 308.56 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29061/47780 [01:37<01:11, 261.56 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30556/47780 [01:37<00:59, 291.29 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22054/47780 [01:37<01:21, 314.82 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29253/47780 [01:37<01:05, 282.34 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27750/47780 [01:37<01:22, 243.64 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28399/47780 [01:37<01:26, 225.11 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29710/47780 [01:37<01:01, 292.82 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27999/47780 [01:37<01:05, 301.65 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29088/47780 [01:37<01:11, 261.05 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27778/47780 [01:37<01:19, 252.70 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22086/47780 [01:38<01:26, 295.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29283/47780 [01:38<01:06, 278.12 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30586/47780 [01:38<01:06, 257.49 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29741/47780 [01:38<01:01, 291.32 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28427/47780 [01:37<01:23, 232.85 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28030/47780 [01:38<01:05, 303.63 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29115/47780 [01:38<01:13, 252.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22117/47780 [01:38<01:26, 296.51 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27806/47780 [01:38<01:21, 244.44 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30613/47780 [01:38<01:09, 248.13 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29312/47780 [01:38<01:10, 261.35 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29772/47780 [01:38<01:00, 296.60 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28462/47780 [01:38<01:12, 265.41 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28061/47780 [01:38<01:07, 291.83 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29142/47780 [01:38<01:13, 252.03 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22155/47780 [01:38<01:22, 309.26 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27832/47780 [01:38<01:21, 245.98 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30642/47780 [01:38<01:07, 253.60 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29349/47780 [01:38<01:05, 281.16 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28489/47780 [01:38<01:14, 257.99 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28098/47780 [01:38<01:02, 313.36 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29803/47780 [01:38<01:06, 271.97 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29168/47780 [01:38<01:14, 251.42 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27866/47780 [01:38<01:14, 268.50 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30674/47780 [01:38<01:03, 268.23 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22187/47780 [01:38<01:29, 286.93 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29380/47780 [01:38<01:05, 279.99 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28515/47780 [01:38<01:17, 247.41 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28132/47780 [01:38<01:03, 311.31 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29842/47780 [01:38<01:00, 297.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29202/47780 [01:38<01:08, 270.29 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27910/47780 [01:38<01:04, 309.11 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30705/47780 [01:38<01:01, 279.44 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22227/47780 [01:38<01:22, 311.40 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29409/47780 [01:38<01:05, 279.72 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28542/47780 [01:38<01:15, 253.65 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28164/47780 [01:38<01:03, 306.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29248/47780 [01:38<00:57, 320.14 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27942/47780 [01:38<01:04, 308.75 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29442/47780 [01:38<01:02, 293.49 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22259/47780 [01:38<01:23, 305.83 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30738/47780 [01:38<01:01, 275.31 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28568/47780 [01:38<01:16, 252.63 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29873/47780 [01:38<01:15, 236.18 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29281/47780 [01:38<00:57, 322.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28195/47780 [01:38<01:08, 284.73 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27974/47780 [01:38<01:06, 297.20 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29472/47780 [01:38<01:04, 285.68 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22290/47780 [01:38<01:26, 294.38 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28596/47780 [01:38<01:13, 260.13 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30766/47780 [01:38<01:05, 261.10 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28229/47780 [01:38<01:05, 298.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29899/47780 [01:38<01:19, 224.29 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29314/47780 [01:38<01:04, 288.49 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28004/47780 [01:38<01:07, 292.71 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29501/47780 [01:38<01:05, 280.64 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28626/47780 [01:38<01:12, 265.83 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22320/47780 [01:38<01:29, 283.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30795/47780 [01:38<01:04, 264.48 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29960/47780 [01:38<00:57, 310.98 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28262/47780 [01:38<01:07, 289.67 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29344/47780 [01:38<01:04, 284.91 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28034/47780 [01:38<01:10, 279.09 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29530/47780 [01:38<01:05, 276.68 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28655/47780 [01:38<01:10, 269.66 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22351/47780 [01:38<01:27, 290.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30822/47780 [01:38<01:03, 265.77 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29375/47780 [01:38<01:04, 286.01 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28292/47780 [01:38<01:13, 266.08 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29994/47780 [01:38<01:02, 283.58 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28685/47780 [01:38<01:09, 275.44 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30855/47780 [01:38<01:00, 280.95 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22383/47780 [01:39<01:26, 292.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28063/47780 [01:38<01:14, 264.48 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29558/47780 [01:39<01:14, 244.74 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29410/47780 [01:39<01:00, 303.34 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28323/47780 [01:39<01:10, 274.88 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30025/47780 [01:39<01:02, 281.99 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22422/47780 [01:39<01:20, 316.33 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30884/47780 [01:39<01:01, 274.00 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28091/47780 [01:39<01:14, 265.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28713/47780 [01:39<01:14, 255.87 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29590/47780 [01:39<01:08, 264.46 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29441/47780 [01:39<01:05, 280.26 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28356/47780 [01:39<01:08, 283.48 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30055/47780 [01:39<01:03, 278.18 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22458/47780 [01:39<01:17, 326.87 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28118/47780 [01:39<01:16, 258.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28739/47780 [01:39<01:14, 256.89 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30912/47780 [01:39<01:05, 258.37 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29619/47780 [01:39<01:07, 268.46 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29470/47780 [01:39<01:05, 279.39 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28385/47780 [01:39<01:09, 279.90 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30084/47780 [01:39<01:03, 277.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22491/47780 [01:39<01:18, 322.31 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30942/47780 [01:39<01:02, 269.77 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28155/47780 [01:39<01:10, 277.07 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29653/47780 [01:39<01:03, 285.34 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28769/47780 [01:39<01:20, 237.07 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29506/47780 [01:39<01:01, 298.88 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28415/47780 [01:39<01:07, 284.82 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30118/47780 [01:39<01:00, 292.43 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22527/47780 [01:39<01:15, 332.95 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28190/47780 [01:39<01:07, 290.69 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30970/47780 [01:39<01:04, 260.07 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29682/47780 [01:39<01:07, 268.07 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28794/47780 [01:39<01:20, 235.41 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28445/47780 [01:39<01:07, 285.52 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29537/47780 [01:39<01:01, 295.30 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22561/47780 [01:39<01:16, 331.31 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30148/47780 [01:39<01:02, 281.91 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28223/47780 [01:39<01:05, 298.31 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30998/47780 [01:39<01:03, 263.52 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29710/47780 [01:39<01:07, 265.88 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28818/47780 [01:39<01:25, 222.11 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28474/47780 [01:39<01:09, 277.67 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22598/47780 [01:39<01:17, 323.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30177/47780 [01:39<01:05, 266.86 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29567/47780 [01:39<01:10, 258.72 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28257/47780 [01:39<01:03, 306.70 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31028/47780 [01:39<01:01, 270.75 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29737/47780 [01:39<01:07, 266.21 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28846/47780 [01:39<01:22, 230.36 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28502/47780 [01:39<01:12, 266.18 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22633/47780 [01:39<01:15, 330.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30211/47780 [01:39<01:01, 284.35 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29602/47780 [01:39<01:04, 282.44 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28296/47780 [01:39<00:58, 330.36 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31056/47780 [01:39<01:01, 270.05 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29764/47780 [01:39<01:08, 264.63 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28876/47780 [01:39<01:16, 246.53 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28529/47780 [01:39<01:14, 258.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22669/47780 [01:39<01:14, 335.60 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29635/47780 [01:39<01:01, 293.11 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31085/47780 [01:39<01:00, 275.47 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30240/47780 [01:39<01:04, 272.24 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28330/47780 [01:39<01:03, 304.55 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29798/47780 [01:39<01:05, 274.10 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28902/47780 [01:39<01:17, 244.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28555/47780 [01:39<01:15, 256.25 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31113/47780 [01:39<01:01, 271.07 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29666/47780 [01:40<01:07, 269.94 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30268/47780 [01:40<01:09, 250.40 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29834/47780 [01:40<01:01, 291.71 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28361/47780 [01:40<01:08, 281.80 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28931/47780 [01:39<01:14, 254.55 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28588/47780 [01:40<01:09, 277.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22703/47780 [01:40<01:37, 257.39 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31144/47780 [01:40<00:58, 282.31 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29694/47780 [01:40<01:06, 272.01 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28392/47780 [01:40<01:07, 289.20 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29864/47780 [01:40<01:04, 278.37 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30294/47780 [01:40<01:15, 230.53 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28957/47780 [01:40<01:15, 247.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28617/47780 [01:40<01:09, 277.55 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31173/47780 [01:40<00:59, 277.79 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22733/47780 [01:40<01:40, 249.90 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29723/47780 [01:40<01:09, 260.35 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28422/47780 [01:40<01:06, 288.93 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29900/47780 [01:40<01:00, 294.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30332/47780 [01:40<01:05, 266.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28982/47780 [01:40<01:20, 232.51 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31203/47780 [01:40<00:59, 278.12 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22794/47780 [01:40<01:16, 328.11 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28645/47780 [01:40<01:19, 241.80 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29753/47780 [01:40<01:06, 270.96 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28452/47780 [01:40<01:07, 285.66 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29934/47780 [01:40<00:58, 303.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30365/47780 [01:40<01:01, 283.38 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29013/47780 [01:40<01:15, 248.28 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22834/47780 [01:40<01:12, 345.48 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28682/47780 [01:40<01:09, 272.91 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31231/47780 [01:40<01:02, 266.11 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28487/47780 [01:40<01:03, 303.65 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29781/47780 [01:40<01:08, 263.97 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29971/47780 [01:40<00:55, 319.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30395/47780 [01:40<01:01, 284.52 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29039/47780 [01:40<01:20, 233.30 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31258/47780 [01:40<01:03, 261.33 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28711/47780 [01:40<01:12, 263.22 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29812/47780 [01:40<01:05, 274.51 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30004/47780 [01:40<00:55, 318.55 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22871/47780 [01:40<01:21, 304.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30425/47780 [01:40<01:02, 276.74 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28518/47780 [01:40<01:13, 260.88 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29068/47780 [01:40<01:16, 246.05 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31285/47780 [01:40<01:03, 261.04 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29842/47780 [01:40<01:05, 275.37 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28740/47780 [01:40<01:14, 256.34 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22918/47780 [01:40<01:12, 344.86 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30468/47780 [01:40<00:54, 315.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30036/47780 [01:40<01:00, 292.01 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28562/47780 [01:40<01:03, 300.91 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29095/47780 [01:40<01:15, 247.18 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31312/47780 [01:40<01:02, 262.87 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29870/47780 [01:40<01:05, 273.67 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28767/47780 [01:40<01:15, 252.21 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22957/47780 [01:40<01:12, 342.71 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30501/47780 [01:40<00:57, 302.56 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30066/47780 [01:40<01:02, 282.34 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28594/47780 [01:40<01:02, 305.68 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29121/47780 [01:40<01:16, 245.32 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31339/47780 [01:40<01:09, 235.55 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29898/47780 [01:40<01:08, 262.50 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22993/47780 [01:40<01:11, 347.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28793/47780 [01:40<01:17, 246.11 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30532/47780 [01:40<00:57, 301.39 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30095/47780 [01:40<01:03, 277.88 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28627/47780 [01:40<01:02, 305.52 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29148/47780 [01:40<01:13, 252.10 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31365/47780 [01:40<01:08, 241.20 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29937/47780 [01:40<01:00, 295.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23032/47780 [01:41<01:09, 355.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28826/47780 [01:40<01:13, 257.87 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30123/47780 [01:41<01:04, 275.57 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30569/47780 [01:41<00:56, 306.80 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28659/47780 [01:40<01:03, 303.23 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29175/47780 [01:40<01:13, 251.68 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31396/47780 [01:41<01:03, 258.81 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29980/47780 [01:41<00:53, 330.38 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28875/47780 [01:41<01:01, 307.56 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23069/47780 [01:41<01:14, 332.86 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30604/47780 [01:41<00:53, 318.59 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30151/47780 [01:41<01:07, 259.33 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29203/47780 [01:41<01:11, 259.55 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28690/47780 [01:41<01:06, 288.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30014/47780 [01:41<00:54, 325.21 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23105/47780 [01:41<01:14, 333.40 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28911/47780 [01:41<01:00, 311.64 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29230/47780 [01:41<01:10, 262.51 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30181/47780 [01:41<01:06, 264.60 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28727/47780 [01:41<01:01, 311.16 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31423/47780 [01:41<01:16, 213.58 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30637/47780 [01:41<00:58, 292.13 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23139/47780 [01:41<01:13, 334.80 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30047/47780 [01:41<00:58, 302.42 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28943/47780 [01:41<01:02, 300.82 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29259/47780 [01:41<01:09, 267.79 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30208/47780 [01:41<01:06, 263.23 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28760/47780 [01:41<01:03, 299.66 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30667/47780 [01:41<01:03, 271.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31446/47780 [01:41<01:24, 192.84 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23179/47780 [01:41<01:10, 349.65 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30078/47780 [01:41<00:59, 298.30 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28974/47780 [01:41<01:04, 293.76 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29288/47780 [01:41<01:08, 270.92 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30241/47780 [01:41<01:03, 275.68 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28791/47780 [01:41<01:04, 292.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30695/47780 [01:41<01:05, 260.67 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23216/47780 [01:41<01:09, 355.37 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31467/47780 [01:41<01:29, 182.98 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29322/47780 [01:41<01:03, 289.55 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29004/47780 [01:41<01:04, 288.95 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30273/47780 [01:41<01:00, 287.33 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30109/47780 [01:41<01:03, 279.23 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28821/47780 [01:41<01:05, 288.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30722/47780 [01:41<01:05, 259.34 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23256/47780 [01:41<01:06, 368.21 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31535/47780 [01:41<00:53, 302.30 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29352/47780 [01:41<01:04, 287.51 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30302/47780 [01:41<01:01, 285.75 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30149/47780 [01:41<00:57, 305.65 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29035/47780 [01:41<01:05, 285.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28852/47780 [01:41<01:05, 291.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30753/47780 [01:41<01:03, 267.27 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23294/47780 [01:41<01:08, 358.82 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29388/47780 [01:41<01:00, 305.13 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31569/47780 [01:41<00:55, 293.62 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30331/47780 [01:41<01:01, 283.71 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29064/47780 [01:41<01:06, 280.51 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28884/47780 [01:41<01:03, 299.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30180/47780 [01:41<01:06, 266.22 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30785/47780 [01:41<01:00, 278.85 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23340/47780 [01:41<01:03, 383.86 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29419/47780 [01:41<00:59, 306.10 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30364/47780 [01:41<00:58, 296.80 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29094/47780 [01:41<01:06, 282.29 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28918/47780 [01:41<01:01, 307.68 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31601/47780 [01:41<00:58, 275.42 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30818/47780 [01:41<00:57, 293.08 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30212/47780 [01:41<01:03, 276.96 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23379/47780 [01:42<01:03, 385.57 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30394/47780 [01:41<00:59, 291.07 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28950/47780 [01:41<01:01, 307.62 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29450/47780 [01:41<01:06, 275.26 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31631/47780 [01:41<00:58, 278.32 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29125/47780 [01:41<01:09, 269.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30241/47780 [01:42<01:02, 280.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30856/47780 [01:42<00:54, 310.81 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23418/47780 [01:42<01:03, 382.38 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30428/47780 [01:42<00:57, 301.97 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28982/47780 [01:42<01:02, 300.78 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31661/47780 [01:42<00:59, 270.34 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29163/47780 [01:42<01:04, 289.92 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30276/47780 [01:42<00:58, 298.87 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30888/47780 [01:42<00:55, 302.86 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23478/47780 [01:42<00:55, 440.88 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29479/47780 [01:42<01:16, 239.56 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30460/47780 [01:42<00:57, 301.95 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29014/47780 [01:42<01:02, 299.43 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30312/47780 [01:42<00:55, 313.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29193/47780 [01:42<01:04, 286.51 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31696/47780 [01:42<00:56, 285.15 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30920/47780 [01:42<00:54, 307.65 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29522/47780 [01:42<01:04, 285.09 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23523/47780 [01:42<01:01, 397.13 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30497/47780 [01:42<00:54, 314.43 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29045/47780 [01:42<01:03, 295.74 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31731/47780 [01:42<00:53, 299.34 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30346/47780 [01:42<00:58, 300.40 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29222/47780 [01:42<01:09, 266.79 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30954/47780 [01:42<00:56, 298.99 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29553/47780 [01:42<01:04, 282.33 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23564/47780 [01:42<01:00, 399.76 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30532/47780 [01:42<00:53, 322.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29075/47780 [01:42<01:03, 296.71 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31766/47780 [01:42<00:51, 309.86 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30386/47780 [01:42<00:53, 327.82 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29249/47780 [01:42<01:10, 264.54 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30985/47780 [01:42<00:57, 293.20 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29583/47780 [01:42<01:06, 274.02 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30565/47780 [01:42<00:53, 320.89 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23605/47780 [01:42<01:02, 386.21 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29105/47780 [01:42<01:04, 287.90 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31798/47780 [01:42<00:52, 304.12 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30420/47780 [01:42<00:52, 331.25 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29276/47780 [01:42<01:11, 257.79 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31016/47780 [01:42<00:56, 294.63 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29612/47780 [01:42<01:05, 275.97 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23651/47780 [01:42<00:59, 402.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30598/47780 [01:42<00:53, 319.32 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29135/47780 [01:42<01:05, 284.83 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30462/47780 [01:42<00:48, 356.75 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31830/47780 [01:42<00:52, 306.53 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29302/47780 [01:42<01:12, 255.41 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31046/47780 [01:42<00:57, 289.37 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29646/47780 [01:42<01:02, 291.43 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23693/47780 [01:42<01:01, 393.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30633/47780 [01:42<00:55, 307.44 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30501/47780 [01:42<00:47, 366.18 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29167/47780 [01:42<01:05, 285.07 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31869/47780 [01:42<00:50, 316.26 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29328/47780 [01:42<01:18, 235.48 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29676/47780 [01:42<01:03, 286.69 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31075/47780 [01:42<01:02, 268.29 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30665/47780 [01:42<00:55, 307.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23733/47780 [01:42<01:03, 378.77 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30538/47780 [01:42<00:48, 359.20 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29205/47780 [01:42<01:00, 305.07 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31902/47780 [01:42<00:50, 316.72 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29352/47780 [01:42<01:19, 232.00 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31104/47780 [01:42<01:01, 271.25 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29706/47780 [01:42<01:05, 275.62 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30705/47780 [01:42<00:51, 333.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23772/47780 [01:43<01:05, 369.30 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31936/47780 [01:42<00:49, 319.58 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29239/47780 [01:42<01:02, 298.04 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30575/47780 [01:42<00:51, 334.80 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31132/47780 [01:43<01:01, 270.88 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30740/47780 [01:43<00:50, 338.11 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29376/47780 [01:43<01:21, 226.26 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29734/47780 [01:42<01:05, 273.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23824/47780 [01:43<00:58, 406.85 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31971/47780 [01:43<00:49, 317.39 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29270/47780 [01:43<01:02, 298.09 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30612/47780 [01:43<00:50, 340.99 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30782/47780 [01:43<00:47, 358.24 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31160/47780 [01:43<01:03, 262.46 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29399/47780 [01:43<01:24, 218.28 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29762/47780 [01:43<01:07, 266.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23867/47780 [01:43<00:58, 408.45 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29300/47780 [01:43<01:01, 298.45 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30648/47780 [01:43<00:51, 331.39 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32003/47780 [01:43<00:55, 285.91 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30824/47780 [01:43<00:46, 367.69 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29429/47780 [01:43<01:17, 238.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31187/47780 [01:43<01:05, 251.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29789/47780 [01:43<01:09, 258.91 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23909/47780 [01:43<01:02, 381.32 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29336/47780 [01:43<00:59, 309.55 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30694/47780 [01:43<00:46, 367.12 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32039/47780 [01:43<00:52, 302.28 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31227/47780 [01:43<00:57, 290.20 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30861/47780 [01:43<00:48, 351.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29456/47780 [01:43<01:16, 238.81 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29816/47780 [01:43<01:10, 256.22 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29367/47780 [01:43<00:59, 309.28 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23949/47780 [01:43<01:04, 370.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32070/47780 [01:43<00:53, 292.06 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30732/47780 [01:43<00:53, 319.89 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31257/47780 [01:43<00:58, 283.47 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29491/47780 [01:43<01:09, 263.66 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29844/47780 [01:43<01:09, 257.17 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30897/47780 [01:43<00:53, 315.25 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23993/47780 [01:43<01:02, 381.11 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29398/47780 [01:43<01:05, 280.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32101/47780 [01:43<00:54, 287.08 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29874/47780 [01:43<01:07, 266.26 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31291/47780 [01:43<00:57, 286.37 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29518/47780 [01:43<01:11, 254.06 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24034/47780 [01:43<01:01, 384.40 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30766/47780 [01:43<00:59, 286.62 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30930/47780 [01:43<00:55, 306.11 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29427/47780 [01:43<01:06, 276.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32133/47780 [01:43<00:52, 295.99 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29906/47780 [01:43<01:03, 281.50 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31321/47780 [01:43<00:57, 286.92 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29551/47780 [01:43<01:08, 266.33 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30798/47780 [01:43<00:58, 288.99 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24073/47780 [01:43<01:04, 369.88 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29455/47780 [01:43<01:06, 274.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30963/47780 [01:43<00:59, 282.40 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29937/47780 [01:43<01:01, 289.61 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32163/47780 [01:43<00:55, 281.32 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31355/47780 [01:43<00:55, 298.02 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29580/47780 [01:43<01:06, 272.73 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24116/47780 [01:43<01:03, 370.08 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30828/47780 [01:43<01:01, 277.38 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29485/47780 [01:43<01:07, 272.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30996/47780 [01:43<00:58, 288.63 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32196/47780 [01:43<00:53, 291.64 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29977/47780 [01:43<00:58, 304.21 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31385/47780 [01:43<00:58, 279.39 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29608/47780 [01:43<01:10, 257.24 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24168/47780 [01:44<00:57, 411.10 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30857/47780 [01:43<01:02, 269.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29513/47780 [01:43<01:07, 271.96 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31026/47780 [01:43<01:01, 271.24 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32226/47780 [01:43<00:56, 275.45 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30008/47780 [01:43<01:00, 292.72 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31418/47780 [01:44<00:56, 290.81 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29639/47780 [01:44<01:06, 271.64 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24210/47780 [01:44<00:58, 404.66 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29548/47780 [01:44<01:02, 294.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30885/47780 [01:44<01:03, 266.70 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31054/47780 [01:44<01:02, 268.02 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30043/47780 [01:44<00:57, 308.56 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32263/47780 [01:44<00:52, 294.82 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31448/47780 [01:44<00:58, 280.47 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29670/47780 [01:44<01:07, 267.77 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24251/47780 [01:44<00:58, 401.71 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29582/47780 [01:44<01:00, 298.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30912/47780 [01:44<01:05, 259.21 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31090/47780 [01:44<00:57, 291.90 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30074/47780 [01:44<00:58, 305.27 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32293/47780 [01:44<00:52, 293.05 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31478/47780 [01:44<00:57, 283.02 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29706/47780 [01:44<01:02, 290.10 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24292/47780 [01:44<00:58, 403.67 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30941/47780 [01:44<01:03, 264.86 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29612/47780 [01:44<01:06, 272.30 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30106/47780 [01:44<00:58, 302.76 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31121/47780 [01:44<00:59, 279.35 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32324/47780 [01:44<00:54, 284.97 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29736/47780 [01:44<01:05, 274.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31507/47780 [01:44<01:02, 258.71 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30968/47780 [01:44<01:04, 260.18 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24333/47780 [01:44<01:05, 358.98 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29649/47780 [01:44<01:01, 295.92 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30137/47780 [01:44<00:58, 304.13 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31150/47780 [01:44<00:59, 279.25 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32354/47780 [01:44<00:53, 285.99 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29772/47780 [01:44<01:01, 290.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31534/47780 [01:44<01:03, 256.35 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31002/47780 [01:44<00:59, 282.20 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24370/47780 [01:44<01:05, 357.84 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29680/47780 [01:44<01:04, 281.15 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31183/47780 [01:44<00:57, 290.01 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30168/47780 [01:44<00:58, 299.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32383/47780 [01:44<00:54, 280.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31031/47780 [01:44<00:59, 281.80 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24409/47780 [01:44<01:04, 364.08 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31560/47780 [01:44<01:07, 239.14 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29802/47780 [01:44<01:07, 267.41 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30201/47780 [01:44<00:57, 307.99 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29709/47780 [01:44<01:04, 280.48 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32415/47780 [01:44<00:53, 285.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31213/47780 [01:44<01:00, 274.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31064/47780 [01:44<00:57, 292.36 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24448/47780 [01:44<01:02, 371.05 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31585/47780 [01:44<01:07, 239.38 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30239/47780 [01:44<00:54, 322.06 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29830/47780 [01:44<01:12, 246.99 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32451/47780 [01:44<00:51, 299.69 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31246/47780 [01:44<00:57, 286.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29738/47780 [01:44<01:08, 262.77 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31098/47780 [01:44<00:55, 299.09 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31611/47780 [01:44<01:06, 242.38 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24486/47780 [01:44<01:05, 353.43 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30272/47780 [01:44<00:55, 313.28 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31275/47780 [01:44<00:59, 275.84 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29856/47780 [01:44<01:17, 231.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32482/47780 [01:44<00:54, 280.21 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29765/47780 [01:44<01:15, 240.03 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31134/47780 [01:44<00:52, 315.62 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24525/47780 [01:44<01:03, 363.59 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31643/47780 [01:44<01:02, 258.27 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30305/47780 [01:44<00:55, 314.57 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31305/47780 [01:44<01:00, 272.94 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29880/47780 [01:44<01:18, 226.81 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29791/47780 [01:44<01:13, 244.14 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31171/47780 [01:45<00:51, 324.90 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32511/47780 [01:45<00:58, 262.77 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31680/47780 [01:45<00:55, 289.48 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24562/47780 [01:45<01:05, 354.84 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30337/47780 [01:44<00:56, 309.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31339/47780 [01:45<00:57, 288.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29903/47780 [01:45<01:20, 221.04 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31206/47780 [01:45<00:50, 328.33 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32541/47780 [01:45<00:55, 272.61 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29816/47780 [01:45<01:17, 232.91 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24598/47780 [01:45<01:06, 351.15 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31714/47780 [01:45<00:54, 292.11 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30368/47780 [01:45<00:56, 309.01 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31373/47780 [01:45<00:54, 302.58 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29927/47780 [01:45<01:19, 225.55 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31239/47780 [01:45<00:50, 328.61 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29848/47780 [01:45<01:10, 253.72 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32570/47780 [01:45<00:56, 267.57 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31744/47780 [01:45<00:55, 286.45 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24634/47780 [01:45<01:09, 334.47 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30399/47780 [01:45<00:58, 299.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29950/47780 [01:45<01:18, 226.54 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31404/47780 [01:45<00:56, 288.06 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31279/47780 [01:45<00:47, 345.64 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29878/47780 [01:45<01:07, 266.28 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32605/47780 [01:45<00:54, 279.28 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31779/47780 [01:45<00:54, 294.42 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30435/47780 [01:45<00:55, 313.05 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24668/47780 [01:45<01:13, 314.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29973/47780 [01:45<01:19, 225.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31438/47780 [01:45<00:54, 299.48 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29910/47780 [01:45<01:04, 278.31 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31314/47780 [01:45<00:51, 317.01 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31809/47780 [01:45<00:53, 295.90 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32635/47780 [01:45<00:56, 267.12 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30472/47780 [01:45<00:53, 322.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24700/47780 [01:45<01:17, 297.15 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29996/47780 [01:45<01:22, 214.50 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29941/47780 [01:45<01:03, 283.13 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31470/47780 [01:45<00:59, 274.12 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31846/47780 [01:45<00:51, 309.96 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32663/47780 [01:45<00:58, 259.68 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30505/47780 [01:45<00:56, 306.49 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24744/47780 [01:45<01:09, 331.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31347/47780 [01:45<00:59, 274.38 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30018/47780 [01:45<01:22, 215.95 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29970/47780 [01:45<01:05, 273.55 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31502/47780 [01:45<00:57, 283.37 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31881/47780 [01:45<00:50, 317.72 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32696/47780 [01:45<00:54, 278.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30536/47780 [01:45<00:56, 304.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31393/47780 [01:45<00:51, 315.88 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24778/47780 [01:45<01:11, 322.76 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30042/47780 [01:45<01:20, 221.15 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29999/47780 [01:45<01:05, 272.09 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31535/47780 [01:45<00:54, 296.06 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31914/47780 [01:45<00:50, 317.31 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32735/47780 [01:45<00:49, 302.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31430/47780 [01:45<00:49, 329.90 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24811/47780 [01:45<01:12, 318.42 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30567/47780 [01:45<00:59, 289.57 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30074/47780 [01:45<01:11, 248.19 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30047/47780 [01:45<00:54, 324.06 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31946/47780 [01:45<00:50, 311.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31566/47780 [01:45<01:00, 269.53 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32766/47780 [01:45<00:54, 274.28 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31465/47780 [01:45<00:51, 318.29 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30598/47780 [01:45<00:59, 288.84 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30102/47780 [01:45<01:10, 251.91 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24844/47780 [01:46<01:18, 292.37 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30081/47780 [01:45<00:57, 307.18 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31595/47780 [01:46<01:01, 263.99 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31978/47780 [01:46<00:55, 286.95 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30128/47780 [01:46<01:09, 254.07 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30627/47780 [01:45<01:00, 285.69 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31498/47780 [01:46<00:53, 304.51 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24885/47780 [01:46<01:12, 316.87 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32796/47780 [01:46<01:00, 246.14 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30114/47780 [01:46<00:56, 309.97 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31627/47780 [01:46<00:58, 276.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32008/47780 [01:46<00:56, 281.55 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30666/47780 [01:46<00:54, 311.92 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30154/47780 [01:46<01:12, 241.82 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31530/47780 [01:46<00:54, 296.39 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24918/47780 [01:46<01:11, 320.10 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32856/47780 [01:46<00:44, 331.93 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30146/47780 [01:46<00:59, 295.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31661/47780 [01:46<00:55, 290.30 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30698/47780 [01:46<00:55, 309.97 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32037/47780 [01:46<00:59, 266.36 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30183/47780 [01:46<01:11, 247.21 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24951/47780 [01:46<01:12, 315.69 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31561/47780 [01:46<00:56, 287.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30183/47780 [01:46<00:56, 313.06 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32892/47780 [01:46<00:49, 301.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31691/47780 [01:46<00:57, 280.58 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30735/47780 [01:46<00:54, 313.54 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32066/47780 [01:46<00:59, 264.32 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30216/47780 [01:46<01:05, 269.84 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24983/47780 [01:46<01:12, 313.85 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31591/47780 [01:46<00:58, 276.11 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30215/47780 [01:46<00:58, 300.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32940/47780 [01:46<00:43, 342.85 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31720/47780 [01:46<00:59, 271.21 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30771/47780 [01:46<00:52, 326.39 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32093/47780 [01:46<00:59, 265.62 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30244/47780 [01:46<01:07, 261.49 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25015/47780 [01:46<01:17, 295.25 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31621/47780 [01:46<00:57, 279.49 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30246/47780 [01:46<01:00, 288.28 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31750/47780 [01:46<00:57, 279.05 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30804/47780 [01:46<00:52, 324.00 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32124/47780 [01:46<00:58, 269.34 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32977/47780 [01:46<00:47, 310.98 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25046/47780 [01:46<01:16, 296.09 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30271/47780 [01:46<01:13, 239.58 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31656/47780 [01:46<00:55, 292.50 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30841/47780 [01:46<00:50, 333.48 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32154/47780 [01:46<00:56, 277.79 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33010/47780 [01:46<00:48, 305.63 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31779/47780 [01:46<01:04, 248.65 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30278/47780 [01:46<01:06, 262.72 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31686/47780 [01:46<00:54, 294.19 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30296/47780 [01:46<01:12, 241.78 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25076/47780 [01:46<01:19, 284.64 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32194/47780 [01:46<00:50, 310.53 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30875/47780 [01:46<00:52, 323.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31816/47780 [01:46<00:57, 277.38 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30310/47780 [01:46<01:04, 269.13 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33043/47780 [01:46<00:49, 297.36 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31720/47780 [01:46<00:52, 304.24 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30332/47780 [01:46<01:04, 269.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25105/47780 [01:46<01:21, 279.55 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32230/47780 [01:46<00:48, 323.23 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31857/47780 [01:46<00:51, 309.70 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30339/47780 [01:46<01:04, 271.84 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33081/47780 [01:46<00:46, 315.66 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30908/47780 [01:46<00:57, 295.34 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30360/47780 [01:46<01:04, 272.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25141/47780 [01:47<01:17, 293.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31753/47780 [01:46<00:55, 287.82 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32264/47780 [01:46<00:48, 320.74 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31889/47780 [01:47<00:52, 305.42 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30373/47780 [01:46<01:00, 286.54 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30941/47780 [01:46<00:55, 301.64 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30392/47780 [01:47<01:02, 279.40 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33114/47780 [01:47<00:49, 297.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25171/47780 [01:47<01:17, 290.96 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31783/47780 [01:47<00:58, 272.94 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30409/47780 [01:47<00:56, 304.78 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32297/47780 [01:47<00:54, 285.59 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31921/47780 [01:47<00:54, 293.63 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30421/47780 [01:47<01:02, 275.87 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30972/47780 [01:47<00:58, 284.92 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33147/47780 [01:47<00:47, 305.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25210/47780 [01:47<01:10, 318.70 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31812/47780 [01:47<00:58, 272.46 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32346/47780 [01:47<00:45, 338.23 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31958/47780 [01:47<00:50, 314.21 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25249/47780 [01:47<01:06, 339.12 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31006/47780 [01:47<00:56, 296.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30440/47780 [01:47<01:01, 280.32 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30449/47780 [01:47<01:06, 262.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33179/47780 [01:47<00:49, 293.79 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31849/47780 [01:47<00:53, 299.14 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32381/47780 [01:47<00:47, 326.48 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25287/47780 [01:47<01:04, 347.21 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31044/47780 [01:47<00:52, 316.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31990/47780 [01:47<00:52, 298.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33210/47780 [01:47<00:48, 297.64 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30476/47780 [01:47<01:07, 256.06 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31880/47780 [01:47<00:52, 302.16 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30469/47780 [01:47<01:07, 257.70 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32417/47780 [01:47<00:46, 332.53 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31080/47780 [01:47<00:50, 328.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25324/47780 [01:47<01:04, 349.84 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32022/47780 [01:47<00:54, 290.31 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30502/47780 [01:47<01:08, 253.27 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33241/47780 [01:47<00:50, 288.68 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30496/47780 [01:47<01:07, 255.65 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31911/47780 [01:47<00:59, 267.70 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25369/47780 [01:47<00:59, 379.03 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31114/47780 [01:47<00:51, 324.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32451/47780 [01:47<00:47, 320.19 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32052/47780 [01:47<00:54, 285.99 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33271/47780 [01:47<00:50, 288.70 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30536/47780 [01:47<01:03, 269.55 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30530/47780 [01:47<01:02, 275.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31943/47780 [01:47<00:57, 275.63 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32485/47780 [01:47<00:48, 317.43 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32090/47780 [01:47<00:50, 308.40 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25408/47780 [01:47<01:04, 348.22 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30563/47780 [01:47<01:05, 263.79 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33301/47780 [01:47<00:51, 281.83 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31147/47780 [01:47<00:58, 286.64 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30559/47780 [01:47<01:03, 270.92 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31973/47780 [01:47<00:57, 273.45 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32127/47780 [01:47<00:48, 323.86 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32518/47780 [01:47<00:49, 305.38 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30590/47780 [01:47<01:04, 265.29 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33336/47780 [01:47<00:49, 294.68 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25444/47780 [01:47<01:06, 333.53 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31178/47780 [01:47<00:56, 292.46 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30587/47780 [01:47<01:03, 269.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32001/47780 [01:47<00:58, 270.73 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32162/47780 [01:47<00:48, 324.32 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32552/47780 [01:47<00:48, 314.82 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30618/47780 [01:47<01:06, 257.95 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31216/47780 [01:47<00:52, 313.57 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33370/47780 [01:47<00:47, 300.65 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25478/47780 [01:47<01:07, 328.76 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30619/47780 [01:47<01:01, 280.83 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32033/47780 [01:47<00:59, 265.41 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32585/47780 [01:48<00:50, 302.11 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32195/47780 [01:48<00:50, 306.24 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30644/47780 [01:48<01:07, 253.15 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31249/47780 [01:47<00:53, 311.08 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33401/47780 [01:48<00:49, 293.27 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25512/47780 [01:48<01:12, 308.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30648/47780 [01:48<01:07, 254.64 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32621/47780 [01:48<00:47, 316.41 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30670/47780 [01:48<01:07, 251.90 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32226/47780 [01:48<00:52, 295.89 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33431/47780 [01:48<00:49, 288.97 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25544/47780 [01:48<01:12, 304.73 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32060/47780 [01:48<01:11, 221.34 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31281/47780 [01:48<00:59, 279.31 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30675/47780 [01:48<01:10, 243.17 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30699/47780 [01:48<01:05, 259.71 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32653/47780 [01:48<00:49, 305.06 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33460/47780 [01:48<00:49, 289.23 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32256/47780 [01:48<00:53, 291.62 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25576/47780 [01:48<01:15, 295.93 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31310/47780 [01:48<00:59, 275.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30700/47780 [01:48<01:09, 244.91 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33496/47780 [01:48<00:46, 309.28 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32084/47780 [01:48<01:23, 187.69 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32288/47780 [01:48<00:52, 296.86 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32684/47780 [01:48<00:50, 296.25 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30726/47780 [01:48<01:09, 245.84 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25610/47780 [01:48<01:12, 307.87 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31339/47780 [01:48<00:59, 274.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30730/47780 [01:48<01:06, 257.17 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33530/47780 [01:48<00:44, 317.88 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32157/47780 [01:48<00:50, 308.59 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32323/47780 [01:48<00:50, 304.95 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32715/47780 [01:48<00:50, 295.69 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30752/47780 [01:48<01:10, 241.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25642/47780 [01:48<01:13, 300.85 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31367/47780 [01:48<01:02, 264.39 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30758/47780 [01:48<01:06, 256.14 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33572/47780 [01:48<00:41, 344.45 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32194/47780 [01:48<00:48, 320.42 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32355/47780 [01:48<00:49, 308.87 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32745/47780 [01:48<00:51, 291.96 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30777/47780 [01:48<01:12, 235.83 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25673/47780 [01:48<01:13, 300.11 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31400/47780 [01:48<00:59, 276.23 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30784/47780 [01:48<01:13, 232.64 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33608/47780 [01:48<00:41, 340.15 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32231/47780 [01:48<00:47, 330.34 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32386/47780 [01:48<00:52, 295.93 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32775/47780 [01:48<00:53, 278.01 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30804/47780 [01:48<01:09, 243.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25704/47780 [01:48<01:14, 296.55 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31428/47780 [01:48<01:00, 271.01 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30809/47780 [01:48<01:13, 232.47 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33645/47780 [01:48<00:40, 345.65 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32267/47780 [01:48<00:47, 326.64 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32417/47780 [01:48<00:52, 293.22 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30832/47780 [01:48<01:06, 253.31 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32803/47780 [01:48<00:54, 275.94 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25738/47780 [01:48<01:12, 305.38 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31462/47780 [01:48<00:56, 287.11 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33680/47780 [01:48<00:40, 346.54 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30833/47780 [01:48<01:14, 226.96 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32309/47780 [01:48<00:44, 346.86 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32450/47780 [01:48<00:50, 303.63 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30860/47780 [01:48<01:05, 257.95 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32831/47780 [01:48<00:55, 268.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25770/47780 [01:48<01:11, 306.03 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31492/47780 [01:48<00:57, 285.06 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30856/47780 [01:48<01:15, 225.45 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33715/47780 [01:48<00:41, 335.58 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30890/47780 [01:48<01:03, 266.99 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32481/47780 [01:49<00:53, 288.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32858/47780 [01:49<00:57, 259.69 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25802/47780 [01:49<01:12, 302.77 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32347/47780 [01:49<00:48, 318.57 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31526/47780 [01:48<00:54, 299.71 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30883/47780 [01:49<01:11, 237.69 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33753/47780 [01:49<00:40, 348.27 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30922/47780 [01:49<01:00, 279.16 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32511/47780 [01:49<00:54, 282.36 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32885/47780 [01:49<00:57, 259.58 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32393/47780 [01:49<00:43, 352.86 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25836/47780 [01:49<01:11, 306.74 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31566/47780 [01:49<00:49, 328.51 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30907/47780 [01:49<01:11, 236.39 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33788/47780 [01:49<00:42, 325.40 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30950/47780 [01:49<01:01, 275.78 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32540/47780 [01:49<00:54, 281.63 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32914/47780 [01:49<00:56, 262.44 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25876/47780 [01:49<01:07, 325.95 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31601/47780 [01:49<00:48, 331.01 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32430/47780 [01:49<00:47, 324.83 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30934/47780 [01:49<01:09, 242.66 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33821/47780 [01:49<00:43, 324.39 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30979/47780 [01:49<01:00, 277.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32569/47780 [01:49<00:53, 283.61 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32947/47780 [01:49<00:54, 272.31 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25909/47780 [01:49<01:08, 319.70 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31635/47780 [01:49<00:49, 324.98 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32464/47780 [01:49<00:48, 316.05 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30965/47780 [01:49<01:04, 259.16 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33854/47780 [01:49<00:43, 319.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32598/47780 [01:49<00:53, 282.81 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31007/47780 [01:49<01:03, 262.45 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32982/47780 [01:49<00:50, 291.04 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25941/47780 [01:49<01:09, 315.97 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31668/47780 [01:49<00:50, 320.31 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32497/47780 [01:49<00:48, 313.13 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30992/47780 [01:49<01:07, 247.77 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33887/47780 [01:49<00:43, 321.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32634/47780 [01:49<00:50, 301.20 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33012/47780 [01:49<00:50, 289.90 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31034/47780 [01:49<01:08, 242.94 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25973/47780 [01:49<01:13, 296.71 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31701/47780 [01:49<00:53, 298.79 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31018/47780 [01:49<01:07, 249.56 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32529/47780 [01:49<00:52, 293.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33930/47780 [01:49<00:39, 349.00 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32665/47780 [01:49<00:52, 287.26 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33042/47780 [01:49<00:50, 292.51 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31059/47780 [01:49<01:14, 223.15 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31732/47780 [01:49<00:55, 289.41 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26003/47780 [01:49<01:22, 265.10 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33966/47780 [01:49<00:39, 347.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31054/47780 [01:49<01:01, 270.56 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32559/47780 [01:49<00:56, 269.37 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32706/47780 [01:49<00:47, 318.26 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33072/47780 [01:49<00:55, 267.19 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31090/47780 [01:49<01:09, 240.66 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31762/47780 [01:49<00:56, 283.06 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26034/47780 [01:49<01:19, 274.37 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34001/47780 [01:49<00:40, 340.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31082/47780 [01:49<01:02, 267.26 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32739/47780 [01:49<00:46, 321.54 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32587/47780 [01:49<00:57, 264.00 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33100/47780 [01:49<00:57, 257.14 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31791/47780 [01:49<00:56, 281.94 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26062/47780 [01:49<01:20, 270.05 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31113/47780 [01:49<01:00, 276.23 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 34036/47780 [01:49<00:41, 328.45 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31115/47780 [01:49<01:15, 220.78 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32614/47780 [01:49<00:58, 260.00 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32772/47780 [01:49<00:49, 305.20 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33127/47780 [01:49<00:56, 257.41 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26093/47780 [01:50<01:18, 278.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31141/47780 [01:50<01:00, 274.27 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34076/47780 [01:50<00:39, 348.39 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31144/47780 [01:50<01:11, 232.58 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32651/47780 [01:50<00:52, 289.43 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32803/47780 [01:50<00:50, 297.35 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31820/47780 [01:50<01:13, 217.95 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33153/47780 [01:50<00:59, 247.00 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31170/47780 [01:50<01:00, 275.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34113/47780 [01:50<00:38, 350.89 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26122/47780 [01:50<01:21, 266.45 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31168/47780 [01:50<01:12, 229.42 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32681/47780 [01:50<00:53, 283.05 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32833/47780 [01:50<00:52, 282.59 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31864/47780 [01:50<00:59, 267.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33184/47780 [01:50<00:56, 259.66 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31198/47780 [01:50<01:02, 264.26 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31193/47780 [01:50<01:11, 232.67 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26149/47780 [01:50<01:25, 252.58 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34149/47780 [01:50<00:43, 310.17 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32711/47780 [01:50<00:55, 269.73 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32862/47780 [01:50<00:54, 272.62 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33215/47780 [01:50<00:53, 273.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31894/47780 [01:50<00:58, 272.75 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31233/47780 [01:50<00:58, 282.54 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31219/47780 [01:50<01:09, 240.00 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26181/47780 [01:50<01:20, 268.92 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34187/47780 [01:50<00:41, 328.64 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32748/47780 [01:50<00:53, 282.67 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33246/47780 [01:50<00:51, 280.23 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31925/47780 [01:50<00:57, 274.23 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32890/47780 [01:50<00:57, 257.41 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31247/47780 [01:50<01:06, 248.76 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26214/47780 [01:50<01:17, 279.64 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31262/47780 [01:50<01:02, 266.34 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34223/47780 [01:50<00:42, 320.04 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32778/47780 [01:50<00:52, 287.26 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33275/47780 [01:50<00:51, 280.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31956/47780 [01:50<00:55, 283.54 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32916/47780 [01:50<01:00, 245.29 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31276/47780 [01:50<01:03, 260.49 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31292/47780 [01:50<00:59, 275.46 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26244/47780 [01:50<01:17, 278.27 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34257/47780 [01:50<00:42, 321.92 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32808/47780 [01:50<00:53, 277.43 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33321/47780 [01:50<00:44, 327.88 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31990/47780 [01:50<00:52, 298.89 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31306/47780 [01:50<01:00, 271.82 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31324/47780 [01:50<00:58, 282.00 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26275/47780 [01:50<01:15, 284.75 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32941/47780 [01:50<01:07, 218.69 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34292/47780 [01:50<00:41, 326.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32847/47780 [01:50<00:48, 305.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32021/47780 [01:50<00:55, 285.60 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33355/47780 [01:50<00:47, 302.46 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31334/47780 [01:50<01:04, 256.49 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31353/47780 [01:50<00:59, 277.96 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26304/47780 [01:50<01:17, 276.93 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32985/47780 [01:50<00:54, 271.74 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34325/47780 [01:50<00:42, 320.01 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32879/47780 [01:50<00:48, 309.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32058/47780 [01:50<00:51, 306.35 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33400/47780 [01:50<00:42, 340.14 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31360/47780 [01:50<01:05, 251.78 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31381/47780 [01:50<00:59, 275.43 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26334/47780 [01:50<01:16, 280.25 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33029/47780 [01:50<00:46, 315.95 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34358/47780 [01:50<00:42, 312.26 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32911/47780 [01:50<00:48, 308.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32094/47780 [01:50<00:49, 317.90 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33435/47780 [01:50<00:42, 339.07 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31409/47780 [01:50<00:59, 276.57 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33063/47780 [01:51<00:45, 322.04 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26363/47780 [01:51<01:17, 276.56 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34399/47780 [01:51<00:39, 339.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31386/47780 [01:51<01:15, 217.31 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32137/47780 [01:50<00:45, 345.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32943/47780 [01:51<00:51, 288.84 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33479/47780 [01:51<00:39, 359.60 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31445/47780 [01:51<00:54, 300.02 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26393/47780 [01:51<01:15, 281.90 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33097/47780 [01:51<00:47, 306.83 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34435/47780 [01:51<00:41, 323.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31416/47780 [01:51<01:09, 233.99 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32178/47780 [01:51<00:43, 360.09 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32975/47780 [01:51<00:51, 287.91 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31477/47780 [01:51<00:55, 291.79 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33516/47780 [01:51<00:43, 325.51 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26424/47780 [01:51<01:17, 275.37 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33130/47780 [01:51<00:48, 303.27 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34468/47780 [01:51<00:41, 321.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31444/47780 [01:51<01:06, 245.80 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33007/47780 [01:51<00:50, 290.45 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32215/47780 [01:51<00:46, 335.70 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31510/47780 [01:51<00:54, 300.64 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33551/47780 [01:51<00:43, 326.79 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26459/47780 [01:51<01:12, 294.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33167/47780 [01:51<00:47, 308.09 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31473/47780 [01:51<01:05, 249.72 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34502/47780 [01:51<00:42, 312.78 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32250/47780 [01:51<00:46, 335.19 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33037/47780 [01:51<00:54, 271.41 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31541/47780 [01:51<00:56, 286.73 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26489/47780 [01:51<01:14, 286.98 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33585/47780 [01:51<00:46, 308.28 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31511/47780 [01:51<00:57, 282.33 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34534/47780 [01:51<00:43, 304.66 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33199/47780 [01:51<00:51, 283.48 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32284/47780 [01:51<00:47, 322.96 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33078/47780 [01:51<00:48, 306.03 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31571/47780 [01:51<00:55, 290.30 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26522/47780 [01:51<01:12, 293.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33619/47780 [01:51<00:46, 307.23 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34565/47780 [01:51<00:43, 306.00 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33233/47780 [01:51<00:49, 292.12 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31540/47780 [01:51<01:02, 258.35 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33110/47780 [01:51<00:49, 296.77 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31601/47780 [01:51<00:55, 289.62 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32317/47780 [01:51<00:51, 298.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26553/47780 [01:51<01:11, 297.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33651/47780 [01:51<00:47, 300.32 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34602/47780 [01:51<00:41, 320.63 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33265/47780 [01:51<00:49, 290.37 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31579/47780 [01:51<00:55, 290.51 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33147/47780 [01:51<00:46, 316.61 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32351/47780 [01:51<00:50, 303.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26589/47780 [01:51<01:09, 305.92 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33684/47780 [01:51<00:46, 302.47 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31632/47780 [01:51<01:04, 249.90 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34635/47780 [01:51<00:42, 306.78 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31616/47780 [01:51<00:51, 312.24 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33182/47780 [01:51<00:45, 322.64 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33295/47780 [01:51<00:52, 275.03 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32382/47780 [01:51<00:50, 304.81 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26624/47780 [01:51<01:07, 315.07 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33715/47780 [01:51<00:47, 296.82 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31668/47780 [01:51<00:58, 275.35 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31649/47780 [01:51<00:51, 313.57 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34666/47780 [01:51<00:45, 290.55 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33227/47780 [01:51<00:41, 354.52 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32416/47780 [01:51<00:49, 307.80 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26664/47780 [01:52<01:02, 335.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33323/47780 [01:51<00:56, 254.68 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31697/47780 [01:52<01:00, 265.11 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33745/47780 [01:52<00:53, 263.43 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34705/47780 [01:52<00:42, 307.60 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31681/47780 [01:52<00:55, 288.64 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33349/47780 [01:52<00:58, 248.62 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32447/47780 [01:52<00:52, 292.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33263/47780 [01:52<00:45, 316.32 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26698/47780 [01:52<01:12, 292.58 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31725/47780 [01:52<01:00, 263.47 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34741/47780 [01:52<00:40, 318.54 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33776/47780 [01:52<00:51, 269.97 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31711/47780 [01:52<00:58, 276.37 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33296/47780 [01:52<00:46, 313.48 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33375/47780 [01:52<01:00, 238.39 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32477/47780 [01:52<00:54, 278.63 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26729/47780 [01:52<01:14, 283.50 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31754/47780 [01:52<00:59, 267.79 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34780/47780 [01:52<00:38, 334.87 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33809/47780 [01:52<00:49, 283.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31740/47780 [01:52<00:59, 269.30 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33403/47780 [01:52<00:58, 247.16 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33328/47780 [01:52<00:48, 298.72 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32506/47780 [01:52<00:57, 267.39 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26759/47780 [01:52<01:13, 286.88 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31782/47780 [01:52<01:00, 262.43 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34817/47780 [01:52<00:38, 337.03 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33846/47780 [01:52<00:45, 303.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31768/47780 [01:52<00:59, 266.97 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33430/47780 [01:52<00:57, 250.51 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33359/47780 [01:52<00:49, 292.35 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32533/47780 [01:52<00:57, 265.01 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26790/47780 [01:52<01:14, 282.39 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34860/47780 [01:52<00:35, 359.38 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33877/47780 [01:52<00:46, 301.56 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31809/47780 [01:52<01:07, 238.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31802/47780 [01:52<00:55, 286.51 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33459/47780 [01:52<00:55, 259.21 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33389/47780 [01:52<00:50, 285.34 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32560/47780 [01:52<01:00, 252.79 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26831/47780 [01:52<01:06, 317.13 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33908/47780 [01:52<00:45, 301.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34897/47780 [01:52<00:35, 358.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31848/47780 [01:52<00:58, 272.27 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31831/47780 [01:52<00:57, 275.15 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33490/47780 [01:52<00:52, 269.92 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32587/47780 [01:52<01:00, 251.87 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33419/47780 [01:52<00:52, 274.30 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34933/47780 [01:52<00:37, 346.25 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26865/47780 [01:52<01:09, 301.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33939/47780 [01:52<00:48, 287.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31881/47780 [01:52<00:55, 284.73 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33518/47780 [01:52<00:52, 269.71 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31860/47780 [01:52<00:59, 267.16 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33447/47780 [01:52<00:52, 273.00 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32619/47780 [01:52<00:56, 267.83 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26899/47780 [01:52<01:06, 311.94 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33978/47780 [01:52<00:44, 308.70 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31912/47780 [01:52<00:54, 288.54 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34968/47780 [01:52<00:40, 318.86 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31892/47780 [01:52<00:57, 277.93 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33549/47780 [01:52<00:52, 271.92 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32649/47780 [01:52<00:55, 273.79 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33480/47780 [01:52<00:50, 285.53 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34011/47780 [01:52<00:44, 311.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26931/47780 [01:52<01:10, 294.57 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35007/47780 [01:52<00:39, 327.50 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31942/47780 [01:52<00:56, 280.69 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31922/47780 [01:52<00:56, 281.72 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33577/47780 [01:52<00:52, 270.75 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32681/47780 [01:52<00:52, 286.59 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33524/47780 [01:52<00:43, 325.23 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34048/47780 [01:52<00:41, 327.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26961/47780 [01:53<01:11, 290.36 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31972/47780 [01:53<00:57, 276.35 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31951/47780 [01:53<00:55, 283.98 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33605/47780 [01:53<00:54, 261.46 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35041/47780 [01:53<00:43, 295.27 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32710/47780 [01:53<00:54, 278.12 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33557/47780 [01:53<00:46, 305.51 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34085/47780 [01:53<00:40, 339.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26991/47780 [01:53<01:11, 292.42 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32004/47780 [01:53<00:54, 287.44 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31982/47780 [01:53<00:55, 285.17 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35072/47780 [01:53<00:44, 287.38 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32738/47780 [01:53<00:54, 275.42 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33632/47780 [01:53<00:58, 242.39 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33605/47780 [01:53<00:41, 338.82 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27031/47780 [01:53<01:04, 322.63 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34120/47780 [01:53<00:41, 327.33 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32037/47780 [01:53<00:54, 290.69 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32011/47780 [01:53<00:56, 276.95 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35112/47780 [01:53<00:40, 313.63 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32772/47780 [01:53<00:52, 287.57 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33666/47780 [01:53<00:53, 263.03 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33642/47780 [01:53<00:40, 347.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34155/47780 [01:53<00:41, 330.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27064/47780 [01:53<01:05, 313.91 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32067/47780 [01:53<00:55, 285.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32039/47780 [01:53<00:59, 262.96 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32806/47780 [01:53<00:49, 302.33 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35144/47780 [01:53<00:40, 308.58 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33677/47780 [01:53<00:40, 344.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33693/47780 [01:53<00:57, 245.58 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27097/47780 [01:53<01:05, 315.06 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34193/47780 [01:53<00:42, 318.82 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32069/47780 [01:53<00:57, 273.11 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32096/47780 [01:53<00:58, 268.87 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35189/47780 [01:53<00:37, 339.95 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32837/47780 [01:53<00:51, 288.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33717/47780 [01:53<00:39, 352.13 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33722/47780 [01:53<00:55, 252.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27129/47780 [01:53<01:06, 312.25 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34231/47780 [01:53<00:40, 332.44 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32125/47780 [01:53<00:57, 274.64 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32098/47780 [01:53<00:57, 274.72 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35231/47780 [01:53<00:34, 362.11 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32867/47780 [01:53<00:52, 281.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33755/47780 [01:53<00:39, 356.06 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27169/47780 [01:53<01:01, 334.29 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33748/47780 [01:53<00:57, 243.93 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34266/47780 [01:53<00:42, 319.30 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32127/47780 [01:53<00:56, 276.15 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35274/47780 [01:53<00:33, 372.89 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32154/47780 [01:53<01:01, 255.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32907/47780 [01:53<00:47, 311.48 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33791/47780 [01:53<00:41, 337.86 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33776/47780 [01:53<00:55, 250.99 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27204/47780 [01:53<01:04, 320.22 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34299/47780 [01:53<00:43, 308.64 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32156/47780 [01:53<00:55, 279.88 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35318/47780 [01:53<00:31, 391.64 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32181/47780 [01:53<01:00, 258.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32939/47780 [01:53<00:47, 310.37 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33805/47780 [01:53<00:53, 258.94 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33828/47780 [01:53<00:41, 339.13 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27246/47780 [01:53<00:59, 344.58 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32185/47780 [01:53<00:57, 273.30 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34331/47780 [01:53<00:44, 301.65 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35359/47780 [01:53<00:31, 392.77 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32208/47780 [01:53<01:03, 244.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32971/47780 [01:53<00:49, 300.67 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33847/47780 [01:53<00:46, 298.98 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27282/47780 [01:54<00:59, 344.98 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33863/47780 [01:53<00:42, 324.07 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32214/47780 [01:54<00:57, 268.99 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34362/47780 [01:54<00:45, 293.91 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35402/47780 [01:54<00:31, 389.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32233/47780 [01:54<01:03, 243.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33002/47780 [01:53<00:49, 298.56 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33878/47780 [01:54<00:47, 294.13 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27318/47780 [01:54<00:59, 345.38 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33898/47780 [01:54<00:42, 327.66 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32241/47780 [01:54<00:58, 266.32 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34393/47780 [01:54<00:45, 292.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35444/47780 [01:54<00:32, 385.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32261/47780 [01:54<01:02, 249.29 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33909/47780 [01:54<00:46, 298.54 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27353/47780 [01:54<00:59, 342.78 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33032/47780 [01:54<00:53, 277.04 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33932/47780 [01:54<00:43, 316.61 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32268/47780 [01:54<00:58, 264.42 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34423/47780 [01:54<00:46, 287.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35484/47780 [01:54<00:32, 380.86 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32287/47780 [01:54<01:04, 240.12 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33939/47780 [01:54<00:47, 291.81 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27388/47780 [01:54<01:01, 329.62 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33061/47780 [01:54<00:54, 268.70 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33967/47780 [01:54<00:42, 325.81 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32302/47780 [01:54<00:54, 285.96 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34452/47780 [01:54<00:51, 259.36 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32332/47780 [01:54<00:53, 288.66 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35523/47780 [01:54<00:35, 344.53 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34001/47780 [01:54<00:42, 322.83 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33969/47780 [01:54<00:50, 272.21 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27422/47780 [01:54<01:04, 314.35 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32332/47780 [01:54<00:53, 289.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33089/47780 [01:54<00:59, 247.60 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34481/47780 [01:54<00:50, 265.04 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32363/47780 [01:54<00:52, 294.21 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34034/47780 [01:54<00:42, 324.65 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35560/47780 [01:54<00:36, 336.46 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27463/47780 [01:54<01:00, 336.37 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32364/47780 [01:54<00:52, 292.18 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33997/47780 [01:54<00:52, 260.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33115/47780 [01:54<01:01, 238.08 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34508/47780 [01:54<00:50, 260.72 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32394/47780 [01:54<00:53, 285.42 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35596/47780 [01:54<00:36, 336.03 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34067/47780 [01:54<00:43, 315.68 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27498/47780 [01:54<01:01, 330.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 34024/47780 [01:54<00:55, 248.30 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32394/47780 [01:54<00:58, 263.50 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33140/47780 [01:54<01:04, 227.27 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34535/47780 [01:54<00:50, 260.20 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32423/47780 [01:54<00:55, 277.71 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35631/47780 [01:54<00:36, 336.29 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34100/47780 [01:54<00:43, 315.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27541/47780 [01:54<00:57, 354.19 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32433/47780 [01:54<00:51, 297.73 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33168/47780 [01:54<01:00, 240.86 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34050/47780 [01:54<00:59, 232.59 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34564/47780 [01:54<00:49, 268.23 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32454/47780 [01:54<00:53, 286.69 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34132/47780 [01:54<00:44, 309.75 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27587/47780 [01:54<00:53, 379.84 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35665/47780 [01:54<00:38, 312.89 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32464/47780 [01:54<00:52, 292.28 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33199/47780 [01:54<00:57, 254.30 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34074/47780 [01:54<00:59, 232.06 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34597/47780 [01:54<00:48, 273.92 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32485/47780 [01:54<00:53, 286.80 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34165/47780 [01:54<00:44, 305.62 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27626/47780 [01:55<00:53, 373.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35697/47780 [01:54<00:40, 298.78 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32496/47780 [01:54<00:51, 296.25 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33225/47780 [01:54<00:56, 255.44 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34100/47780 [01:54<00:58, 234.80 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34626/47780 [01:55<00:49, 266.31 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32514/47780 [01:55<00:55, 275.16 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34203/47780 [01:55<00:42, 319.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27665/47780 [01:55<00:57, 350.49 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33258/47780 [01:55<00:53, 273.75 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34124/47780 [01:55<00:57, 236.22 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32529/47780 [01:55<00:51, 295.70 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35728/47780 [01:55<00:45, 264.92 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34665/47780 [01:55<00:44, 297.57 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34235/47780 [01:55<00:43, 311.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32542/47780 [01:55<00:59, 256.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27714/47780 [01:55<00:52, 384.88 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34148/47780 [01:55<00:59, 229.58 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33287/47780 [01:55<00:56, 257.85 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35761/47780 [01:55<00:42, 281.23 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32559/47780 [01:55<00:53, 284.06 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34695/47780 [01:55<00:46, 278.92 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32569/47780 [01:55<00:58, 259.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34267/47780 [01:55<00:44, 304.45 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27758/47780 [01:55<00:51, 387.19 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34173/47780 [01:55<00:57, 235.28 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32591/47780 [01:55<00:52, 290.72 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35790/47780 [01:55<00:42, 282.69 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33319/47780 [01:55<00:53, 271.90 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34724/47780 [01:55<00:48, 269.05 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32596/47780 [01:55<00:57, 262.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34300/47780 [01:55<00:43, 308.18 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34197/47780 [01:55<00:57, 236.08 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27798/47780 [01:55<00:54, 366.27 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35819/47780 [01:55<00:42, 284.42 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32622/47780 [01:55<00:55, 271.83 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33349/47780 [01:55<00:55, 259.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34331/47780 [01:55<00:43, 308.62 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32623/47780 [01:55<01:01, 245.42 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34752/47780 [01:55<00:51, 251.61 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34226/47780 [01:55<00:53, 251.19 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35848/47780 [01:55<00:43, 274.91 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27836/47780 [01:55<00:58, 342.70 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32656/47780 [01:55<00:52, 290.00 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33381/47780 [01:55<00:52, 275.66 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34362/47780 [01:55<00:43, 306.21 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34778/47780 [01:55<00:51, 253.79 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32657/47780 [01:55<00:57, 262.61 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34252/47780 [01:55<00:53, 251.90 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35876/47780 [01:55<00:43, 276.28 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27887/47780 [01:55<00:51, 384.33 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33411/47780 [01:55<00:50, 282.20 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32686/47780 [01:55<00:54, 276.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34394/47780 [01:55<00:43, 306.13 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34804/47780 [01:55<00:52, 247.51 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34280/47780 [01:55<00:51, 260.09 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32692/47780 [01:55<00:54, 275.01 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33441/47780 [01:55<00:50, 281.31 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27927/47780 [01:55<00:53, 373.77 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35904/47780 [01:55<00:46, 256.84 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32716/47780 [01:55<00:53, 280.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34425/47780 [01:55<00:43, 306.78 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34835/47780 [01:55<00:48, 264.62 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32726/47780 [01:55<00:51, 292.23 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34308/47780 [01:55<00:56, 237.93 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35938/47780 [01:55<00:42, 276.45 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32753/47780 [01:55<00:50, 299.05 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33470/47780 [01:55<00:53, 265.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27965/47780 [01:55<00:55, 354.44 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34456/47780 [01:55<00:47, 281.69 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34865/47780 [01:55<00:48, 266.45 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32760/47780 [01:55<00:49, 302.59 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34342/47780 [01:55<00:51, 263.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32790/47780 [01:55<00:48, 311.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33497/47780 [01:55<00:57, 250.27 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34899/47780 [01:56<00:45, 283.07 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28001/47780 [01:56<01:01, 321.51 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35967/47780 [01:56<00:48, 242.51 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32791/47780 [01:56<00:49, 300.82 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34486/47780 [01:56<00:49, 268.46 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34372/47780 [01:56<00:49, 272.34 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32822/47780 [01:56<00:49, 302.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33525/47780 [01:56<00:55, 258.28 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34928/47780 [01:56<00:46, 278.74 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28036/47780 [01:56<01:01, 322.26 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35993/47780 [01:56<00:49, 239.60 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32822/47780 [01:56<00:52, 287.26 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34401/47780 [01:56<00:50, 263.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34514/47780 [01:56<00:53, 247.91 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32853/47780 [01:56<00:50, 296.94 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33552/47780 [01:56<00:55, 255.12 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34967/47780 [01:56<00:41, 306.72 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36019/47780 [01:56<00:48, 242.89 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28069/47780 [01:56<01:03, 308.03 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32851/47780 [01:56<00:53, 278.70 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34431/47780 [01:56<00:48, 273.43 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34540/47780 [01:56<00:53, 245.87 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32884/47780 [01:56<00:49, 299.55 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33590/47780 [01:56<00:51, 278.21 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28101/47780 [01:56<01:03, 307.67 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34998/47780 [01:56<00:44, 287.88 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32883/47780 [01:56<00:51, 290.19 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34463/47780 [01:56<00:46, 283.49 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36045/47780 [01:56<00:53, 220.84 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34565/47780 [01:56<00:53, 245.98 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32917/47780 [01:56<00:48, 307.12 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33626/47780 [01:56<00:47, 300.67 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28134/47780 [01:56<01:03, 307.11 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35032/47780 [01:56<00:44, 289.39 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32913/47780 [01:56<00:53, 277.19 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34492/47780 [01:56<00:47, 278.98 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34592/47780 [01:56<00:54, 243.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36078/47780 [01:56<00:48, 241.32 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32949/47780 [01:56<00:50, 292.43 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33663/47780 [01:56<00:45, 310.08 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28165/47780 [01:56<01:05, 298.28 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35075/47780 [01:56<00:39, 324.47 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32941/47780 [01:56<00:53, 277.71 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34521/47780 [01:56<00:48, 275.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36112/47780 [01:56<00:43, 267.18 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34617/47780 [01:56<00:58, 224.54 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33695/47780 [01:56<00:46, 306.09 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32979/47780 [01:56<00:53, 275.49 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28200/47780 [01:56<01:04, 305.80 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32970/47780 [01:56<00:53, 275.27 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34553/47780 [01:56<00:46, 285.23 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36140/47780 [01:56<00:44, 259.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35108/47780 [01:56<00:42, 299.17 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34648/47780 [01:56<00:53, 244.94 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33010/47780 [01:56<00:52, 281.80 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33728/47780 [01:56<00:47, 295.06 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28231/47780 [01:56<01:06, 293.92 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33002/47780 [01:56<00:52, 281.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34583/47780 [01:56<00:48, 273.62 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36167/47780 [01:56<00:46, 248.68 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34676/47780 [01:56<00:52, 251.74 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35139/47780 [01:56<00:48, 262.43 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33759/47780 [01:56<00:48, 291.66 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33039/47780 [01:56<00:56, 260.77 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28270/47780 [01:56<01:01, 316.95 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34612/47780 [01:56<00:47, 275.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33031/47780 [01:56<00:56, 262.74 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36193/47780 [01:56<00:46, 249.14 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34705/47780 [01:56<00:49, 262.25 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35167/47780 [01:56<00:47, 263.06 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33789/47780 [01:56<00:50, 277.57 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28309/47780 [01:57<00:58, 333.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33066/47780 [01:56<00:57, 257.34 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33058/47780 [01:57<00:57, 256.59 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34641/47780 [01:57<00:49, 267.19 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34732/47780 [01:57<00:50, 258.42 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36219/47780 [01:57<00:48, 236.08 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35195/47780 [01:57<00:51, 245.86 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33818/47780 [01:57<00:50, 274.84 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28346/47780 [01:57<00:57, 339.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33092/47780 [01:57<00:59, 244.94 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34761/47780 [01:57<00:49, 264.79 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33084/47780 [01:57<00:58, 249.35 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34668/47780 [01:57<00:50, 258.95 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36248/47780 [01:57<00:47, 243.14 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35221/47780 [01:57<00:50, 247.00 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28382/47780 [01:57<00:56, 344.82 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33848/47780 [01:57<00:50, 275.81 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33128/47780 [01:57<00:54, 267.61 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34699/47780 [01:57<00:47, 273.11 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34791/47780 [01:57<00:47, 271.72 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36274/47780 [01:57<00:46, 245.10 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33110/47780 [01:57<01:03, 231.87 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35247/47780 [01:57<00:50, 250.36 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28417/47780 [01:57<00:56, 343.43 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33879/47780 [01:57<00:49, 282.15 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33159/47780 [01:57<00:53, 273.19 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34728/47780 [01:57<00:47, 272.19 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36299/47780 [01:57<00:47, 240.67 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33140/47780 [01:57<01:00, 243.40 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34819/47780 [01:57<00:53, 242.94 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28456/47780 [01:57<00:55, 348.79 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33908/47780 [01:57<00:52, 263.46 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35273/47780 [01:57<00:54, 227.94 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33188/47780 [01:57<00:53, 271.93 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34756/47780 [01:57<00:49, 265.13 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33167/47780 [01:57<00:58, 249.36 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36325/47780 [01:57<00:48, 238.48 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34868/47780 [01:57<00:42, 306.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28498/47780 [01:57<00:53, 361.02 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35297/47780 [01:57<00:54, 229.15 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33225/47780 [01:57<00:48, 299.14 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33935/47780 [01:57<00:54, 253.61 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34789/47780 [01:57<00:46, 280.54 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33196/47780 [01:57<00:57, 254.92 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36350/47780 [01:57<00:47, 241.47 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34900/47780 [01:57<00:43, 293.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28535/47780 [01:57<00:54, 351.57 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33256/47780 [01:57<00:48, 298.76 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35327/47780 [01:57<00:50, 245.22 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34824/47780 [01:57<00:43, 300.25 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33961/47780 [01:57<00:56, 242.84 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33228/47780 [01:57<00:53, 271.69 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34936/47780 [01:57<00:42, 305.18 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36375/47780 [01:57<00:53, 212.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28571/47780 [01:57<00:54, 349.29 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33288/47780 [01:57<00:49, 294.76 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34856/47780 [01:57<00:42, 302.60 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35352/47780 [01:57<00:53, 232.36 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33995/47780 [01:57<00:51, 265.98 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33261/47780 [01:57<00:52, 277.00 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34968/47780 [01:57<00:42, 299.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28606/47780 [01:57<00:55, 345.97 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36397/47780 [01:57<00:55, 203.87 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33325/47780 [01:57<00:46, 312.50 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35376/47780 [01:57<00:53, 230.75 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34029/47780 [01:57<00:48, 286.17 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34895/47780 [01:57<00:40, 320.40 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33289/47780 [01:57<00:52, 277.71 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35000/47780 [01:57<00:41, 304.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28649/47780 [01:58<00:52, 366.16 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36418/47780 [01:57<00:57, 199.31 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33357/47780 [01:57<00:46, 307.39 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34932/47780 [01:57<00:38, 331.02 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34064/47780 [01:57<00:46, 294.49 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35400/47780 [01:58<00:56, 218.81 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35031/47780 [01:58<00:43, 292.97 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33317/47780 [01:58<00:58, 247.55 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28686/47780 [01:58<00:53, 358.95 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36440/47780 [01:58<00:55, 203.78 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34966/47780 [01:58<00:39, 325.96 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34098/47780 [01:58<00:44, 307.12 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33388/47780 [01:58<00:50, 282.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35423/47780 [01:58<00:56, 219.28 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33346/47780 [01:58<00:55, 258.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35066/47780 [01:58<00:41, 304.00 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28730/47780 [01:58<00:51, 369.55 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34999/47780 [01:58<00:39, 322.62 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34129/47780 [01:58<00:45, 297.77 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36461/47780 [01:58<01:00, 185.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35446/47780 [01:58<00:57, 213.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35099/47780 [01:58<00:40, 309.59 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33378/47780 [01:58<00:53, 267.38 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33417/47780 [01:58<00:59, 242.21 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28767/47780 [01:58<00:53, 353.67 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35032/47780 [01:58<00:41, 310.73 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34159/47780 [01:58<00:46, 291.90 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36485/47780 [01:58<00:58, 192.12 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35468/47780 [01:58<00:58, 209.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35133/47780 [01:58<00:39, 318.03 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33406/47780 [01:58<00:55, 258.68 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28803/47780 [01:58<00:54, 351.22 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33447/47780 [01:58<00:59, 239.43 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36510/47780 [01:58<00:54, 207.32 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34189/47780 [01:58<00:48, 278.52 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35498/47780 [01:58<00:52, 232.87 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35064/47780 [01:58<00:44, 287.77 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35172/47780 [01:58<00:38, 324.01 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28839/47780 [01:58<00:54, 350.04 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33433/47780 [01:58<00:55, 256.27 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33473/47780 [01:58<00:59, 240.47 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36537/47780 [01:58<00:50, 222.24 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34218/47780 [01:58<00:50, 269.62 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35523/47780 [01:58<00:54, 225.08 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35094/47780 [01:58<00:45, 278.86 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35206/47780 [01:58<00:40, 314.30 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33460/47780 [01:58<00:55, 257.26 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28876/47780 [01:58<00:56, 332.65 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33498/47780 [01:58<01:03, 226.47 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36560/47780 [01:58<00:53, 210.25 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34246/47780 [01:58<00:50, 266.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35550/47780 [01:58<00:53, 229.84 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33486/47780 [01:58<00:55, 257.89 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35123/47780 [01:58<00:50, 249.70 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35238/47780 [01:58<00:41, 305.48 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28911/47780 [01:58<00:58, 323.09 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33526/47780 [01:58<00:59, 237.79 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36591/47780 [01:58<00:48, 232.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34276/47780 [01:58<00:49, 270.13 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35574/47780 [01:58<00:55, 220.04 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33518/47780 [01:58<00:52, 272.78 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35274/47780 [01:58<00:39, 317.50 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35154/47780 [01:58<00:48, 262.43 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28945/47780 [01:58<00:58, 324.45 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33557/47780 [01:58<00:55, 257.00 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34305/47780 [01:58<00:49, 272.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36618/47780 [01:58<00:47, 237.43 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35615/47780 [01:58<00:45, 268.93 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33547/47780 [01:58<00:51, 274.56 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35184/47780 [01:58<00:46, 272.24 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35307/47780 [01:58<00:39, 313.80 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33594/47780 [01:58<00:49, 288.04 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28978/47780 [01:59<01:00, 309.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36646/47780 [01:58<00:45, 246.65 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35648/47780 [01:58<00:42, 285.41 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34333/47780 [01:58<00:53, 253.28 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33578/47780 [01:58<00:51, 278.38 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35217/47780 [01:59<00:44, 285.00 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35345/47780 [01:59<00:38, 325.25 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33624/47780 [01:59<00:50, 281.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29010/47780 [01:59<01:02, 301.51 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34372/47780 [01:59<00:46, 288.72 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35677/47780 [01:59<00:43, 276.72 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36671/47780 [01:59<00:50, 218.05 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35246/47780 [01:59<00:44, 279.65 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33606/47780 [01:59<00:53, 266.59 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33655/47780 [01:59<00:50, 280.43 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35378/47780 [01:59<00:42, 292.94 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29046/47780 [01:59<00:59, 314.36 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35706/47780 [01:59<00:43, 275.34 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34402/47780 [01:59<00:47, 281.90 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33641/47780 [01:59<00:48, 290.05 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35275/47780 [01:59<00:45, 276.77 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36694/47780 [01:59<00:51, 214.42 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33686/47780 [01:59<00:48, 288.52 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35408/47780 [01:59<00:41, 294.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29080/47780 [01:59<00:58, 317.94 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35734/47780 [01:59<00:44, 270.85 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35305/47780 [01:59<00:44, 280.29 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34431/47780 [01:59<00:49, 269.65 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33671/47780 [01:59<00:49, 282.92 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36716/47780 [01:59<00:53, 204.99 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29114/47780 [01:59<00:57, 324.17 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35439/47780 [01:59<00:42, 289.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33716/47780 [01:59<00:51, 275.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35762/47780 [01:59<00:44, 272.83 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34467/47780 [01:59<00:45, 294.09 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35335/47780 [01:59<00:44, 282.18 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33700/47780 [01:59<00:51, 275.52 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36737/47780 [01:59<00:54, 203.72 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35481/47780 [01:59<00:38, 322.54 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29151/47780 [01:59<00:56, 329.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33744/47780 [01:59<00:51, 274.40 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35367/47780 [01:59<00:43, 286.88 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34498/47780 [01:59<00:46, 283.01 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33735/47780 [01:59<00:48, 290.28 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36767/47780 [01:59<00:50, 218.49 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35790/47780 [01:59<00:51, 232.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33772/47780 [01:59<00:50, 275.23 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35514/47780 [01:59<00:39, 310.67 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29185/47780 [01:59<00:59, 311.30 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35398/47780 [01:59<00:42, 293.36 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33768/47780 [01:59<00:46, 301.32 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34527/47780 [01:59<00:48, 275.77 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35821/47780 [01:59<00:47, 249.91 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36795/47780 [01:59<00:47, 230.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33802/47780 [01:59<00:49, 279.87 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35546/47780 [01:59<00:39, 312.88 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29217/47780 [01:59<00:59, 310.31 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33799/47780 [01:59<00:47, 297.11 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35428/47780 [01:59<00:44, 275.73 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34555/47780 [01:59<00:48, 272.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36828/47780 [01:59<00:42, 254.71 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33831/47780 [01:59<00:50, 276.40 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29251/47780 [01:59<00:58, 317.94 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35847/47780 [01:59<00:50, 234.87 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35578/47780 [01:59<00:43, 283.11 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33836/47780 [01:59<00:44, 314.46 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35465/47780 [01:59<00:41, 299.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34583/47780 [01:59<00:49, 266.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36855/47780 [01:59<00:43, 253.38 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29283/47780 [01:59<00:59, 311.72 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35872/47780 [01:59<00:50, 233.54 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33859/47780 [01:59<00:54, 254.10 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35609/47780 [01:59<00:42, 287.22 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33870/47780 [01:59<00:43, 318.15 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34620/47780 [01:59<00:44, 294.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35496/47780 [02:00<00:43, 280.03 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29317/47780 [02:00<00:58, 316.57 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35899/47780 [02:00<00:49, 241.43 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36881/47780 [02:00<00:46, 234.18 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33887/47780 [02:00<00:53, 258.33 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35641/47780 [02:00<00:41, 289.79 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34650/47780 [02:00<00:45, 290.67 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33902/47780 [02:00<00:46, 297.88 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35525/47780 [02:00<00:44, 273.92 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29349/47780 [02:00<00:58, 317.27 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33924/47780 [02:00<00:48, 286.27 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35678/47780 [02:00<00:39, 308.75 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35924/47780 [02:00<00:51, 230.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36905/47780 [02:00<00:49, 221.47 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33933/47780 [02:00<00:49, 281.52 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35553/47780 [02:00<00:45, 266.65 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34680/47780 [02:00<00:49, 263.47 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29381/47780 [02:00<00:59, 307.56 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35953/47780 [02:00<00:48, 245.72 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36928/47780 [02:00<00:49, 218.62 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33954/47780 [02:00<00:51, 268.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35710/47780 [02:00<00:40, 298.08 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35585/47780 [02:00<00:44, 275.42 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33962/47780 [02:00<00:51, 269.73 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34707/47780 [02:00<00:51, 254.13 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35981/47780 [02:00<00:46, 253.97 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29412/47780 [02:00<01:02, 292.36 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36951/47780 [02:00<00:50, 215.24 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33982/47780 [02:00<00:51, 266.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35741/47780 [02:00<00:45, 265.68 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35613/47780 [02:00<00:44, 273.73 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33990/47780 [02:00<00:51, 267.14 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36007/47780 [02:00<00:46, 252.74 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29445/47780 [02:00<01:01, 298.63 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36980/47780 [02:00<00:46, 230.51 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34009/47780 [02:00<00:53, 258.43 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34733/47780 [02:00<00:56, 229.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35785/47780 [02:00<00:38, 308.29 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36036/47780 [02:00<00:45, 260.60 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29482/47780 [02:00<00:58, 311.82 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34018/47780 [02:00<00:53, 258.77 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34042/47780 [02:00<00:49, 277.90 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37005/47780 [02:00<00:46, 233.36 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35641/47780 [02:00<00:51, 237.96 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34767/47780 [02:00<00:52, 247.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35817/47780 [02:00<00:38, 311.36 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36063/47780 [02:00<00:45, 259.02 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34055/47780 [02:00<00:49, 277.55 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29514/47780 [02:00<01:01, 297.33 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37043/47780 [02:00<00:39, 274.49 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34793/47780 [02:00<00:53, 242.97 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34071/47780 [02:00<00:53, 256.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35666/47780 [02:00<00:54, 223.34 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35854/47780 [02:00<00:37, 317.08 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36094/47780 [02:00<00:43, 268.63 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34099/47780 [02:00<00:43, 314.90 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29544/47780 [02:00<01:01, 294.78 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37092/47780 [02:00<00:32, 328.52 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34101/47780 [02:00<00:51, 267.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35724/47780 [02:00<00:38, 314.06 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34818/47780 [02:00<00:57, 225.67 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35887/47780 [02:00<00:39, 297.39 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36121/47780 [02:00<00:45, 257.30 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29579/47780 [02:00<00:59, 303.38 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37128/47780 [02:00<00:31, 333.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34131/47780 [02:00<00:46, 290.77 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34140/47780 [02:00<00:46, 294.90 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35758/47780 [02:00<00:39, 303.40 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34841/47780 [02:00<01:00, 215.51 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35918/47780 [02:00<00:41, 288.69 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36147/47780 [02:01<00:46, 249.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29613/47780 [02:01<00:57, 313.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37162/47780 [02:01<00:35, 300.98 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34170/47780 [02:01<00:47, 286.57 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35790/47780 [02:01<00:41, 289.78 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34868/47780 [02:01<00:56, 227.58 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34161/47780 [02:01<00:52, 257.27 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29648/47780 [02:01<00:56, 320.58 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36177/47780 [02:01<00:44, 260.77 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35948/47780 [02:01<00:44, 268.57 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34199/47780 [02:01<00:48, 281.44 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37193/47780 [02:01<00:37, 282.21 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34898/47780 [02:01<00:52, 246.94 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34203/47780 [02:01<00:45, 297.66 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35821/47780 [02:01<00:41, 285.78 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36209/47780 [02:01<00:42, 274.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29681/47780 [02:01<00:57, 316.06 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34228/47780 [02:01<00:49, 274.22 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37222/47780 [02:01<00:38, 275.55 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35976/47780 [02:01<00:52, 226.39 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34925/47780 [02:01<00:52, 242.56 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35851/47780 [02:01<00:43, 275.05 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34235/47780 [02:01<00:48, 277.85 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29717/47780 [02:01<00:56, 317.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36241/47780 [02:01<00:42, 268.99 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34256/47780 [02:01<00:49, 273.15 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36024/47780 [02:01<00:41, 284.17 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34954/47780 [02:01<00:50, 255.50 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35891/47780 [02:01<00:38, 308.21 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34265/47780 [02:01<00:48, 280.65 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29758/47780 [02:01<00:52, 340.12 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37250/47780 [02:01<00:43, 242.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36273/47780 [02:01<00:41, 280.19 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34284/47780 [02:01<00:49, 275.09 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34982/47780 [02:01<00:49, 259.55 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36055/47780 [02:01<00:42, 275.67 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35923/47780 [02:01<00:38, 304.37 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29799/47780 [02:01<00:50, 356.13 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37276/47780 [02:01<00:42, 244.79 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34294/47780 [02:01<00:50, 266.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36303/47780 [02:01<00:40, 284.96 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34312/47780 [02:01<00:48, 276.40 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35018/47780 [02:01<00:44, 288.17 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35954/47780 [02:01<00:39, 299.71 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36085/47780 [02:01<00:45, 259.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34322/47780 [02:01<00:51, 262.51 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37302/47780 [02:01<00:44, 237.86 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36332/47780 [02:01<00:42, 268.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29835/47780 [02:01<00:54, 327.90 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34340/47780 [02:01<00:50, 265.21 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35052/47780 [02:01<00:42, 299.83 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35986/47780 [02:01<00:39, 298.70 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34352/47780 [02:01<00:49, 271.52 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36113/47780 [02:01<00:45, 256.67 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29872/47780 [02:01<00:52, 339.07 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37331/47780 [02:01<00:42, 247.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36360/47780 [02:01<00:42, 265.90 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34373/47780 [02:01<00:48, 277.36 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35083/47780 [02:01<00:43, 288.83 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36019/47780 [02:01<00:38, 303.91 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34383/47780 [02:01<00:48, 279.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36393/47780 [02:01<00:40, 283.77 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29908/47780 [02:01<00:53, 336.81 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37362/47780 [02:01<00:40, 255.97 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36140/47780 [02:01<00:47, 242.64 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34401/47780 [02:01<00:51, 261.94 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35113/47780 [02:01<00:43, 288.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34412/47780 [02:01<00:49, 270.03 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29942/47780 [02:02<00:53, 334.00 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37396/47780 [02:01<00:37, 275.83 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36422/47780 [02:01<00:40, 277.06 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36050/47780 [02:01<00:44, 266.59 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36165/47780 [02:02<00:50, 228.84 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35145/47780 [02:01<00:43, 288.25 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34428/47780 [02:02<00:53, 251.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29979/47780 [02:02<00:52, 340.39 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37424/47780 [02:02<00:38, 270.84 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36082/47780 [02:02<00:42, 277.55 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34440/47780 [02:02<00:51, 258.48 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36450/47780 [02:02<00:42, 267.84 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35175/47780 [02:02<00:43, 289.93 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34469/47780 [02:02<00:46, 288.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36189/47780 [02:02<00:54, 213.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30015/47780 [02:02<00:52, 339.17 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36111/47780 [02:02<00:41, 280.90 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37453/47780 [02:02<00:37, 273.22 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34468/47780 [02:02<00:50, 264.30 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36477/47780 [02:02<00:44, 253.88 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35205/47780 [02:02<00:43, 290.60 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34499/47780 [02:02<00:46, 288.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36214/47780 [02:02<00:52, 220.59 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34498/47780 [02:02<00:48, 271.31 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30050/47780 [02:02<00:53, 329.73 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37481/47780 [02:02<00:38, 266.17 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36140/47780 [02:02<00:42, 274.04 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36503/47780 [02:02<00:44, 252.91 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34535/47780 [02:02<00:43, 305.14 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36238/47780 [02:02<00:51, 225.50 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35235/47780 [02:02<00:45, 274.76 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34533/47780 [02:02<00:45, 291.82 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37509/47780 [02:02<00:38, 270.02 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30084/47780 [02:02<00:55, 318.38 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36530/47780 [02:02<00:44, 252.01 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36168/47780 [02:02<00:45, 256.04 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36261/47780 [02:02<00:50, 226.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35263/47780 [02:02<00:46, 270.25 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34564/47780 [02:02<00:45, 287.82 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30120/47780 [02:02<00:54, 326.38 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34566/47780 [02:02<00:52, 252.20 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37537/47780 [02:02<00:40, 255.31 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36556/47780 [02:02<00:44, 251.40 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36195/47780 [02:02<00:45, 257.10 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36288/47780 [02:02<00:49, 233.84 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35295/47780 [02:02<00:44, 277.98 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34595/47780 [02:02<00:45, 291.88 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30153/47780 [02:02<00:55, 320.07 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37568/47780 [02:02<00:38, 267.59 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36593/47780 [02:02<00:39, 285.04 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36222/47780 [02:02<00:45, 254.88 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34593/47780 [02:02<00:54, 240.79 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36314/47780 [02:02<00:47, 239.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35325/47780 [02:02<00:44, 277.60 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34629/47780 [02:02<00:44, 298.85 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30186/47780 [02:02<00:55, 319.13 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36623/47780 [02:02<00:38, 286.33 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36256/47780 [02:02<00:42, 272.61 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34666/47780 [02:02<00:36, 358.47 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37597/47780 [02:02<00:40, 251.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36339/47780 [02:02<00:50, 226.05 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35353/47780 [02:02<00:48, 258.18 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34660/47780 [02:02<00:43, 301.87 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36662/47780 [02:02<00:35, 312.88 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30238/47780 [02:02<00:47, 368.31 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36286/47780 [02:02<00:41, 280.26 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34705/47780 [02:02<00:36, 362.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36363/47780 [02:02<00:50, 224.85 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35381/47780 [02:02<00:47, 261.28 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37623/47780 [02:02<00:46, 220.14 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30281/47780 [02:03<00:45, 385.58 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34691/47780 [02:02<00:46, 284.52 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36321/47780 [02:02<00:39, 290.19 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36695/47780 [02:02<00:37, 294.00 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36389/47780 [02:03<00:49, 232.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34744/47780 [02:02<00:39, 333.80 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37658/47780 [02:03<00:40, 250.52 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35409/47780 [02:02<00:48, 254.95 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30320/47780 [02:03<00:45, 382.42 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34721/47780 [02:03<00:45, 285.26 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36366/47780 [02:03<00:34, 331.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36730/47780 [02:03<00:36, 302.75 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34779/47780 [02:03<00:40, 321.89 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37694/47780 [02:03<00:36, 273.49 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35440/47780 [02:03<00:46, 267.20 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36413/47780 [02:03<00:54, 208.45 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30369/47780 [02:03<00:43, 400.09 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36766/47780 [02:03<00:34, 315.25 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34750/47780 [02:03<00:48, 265.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36400/47780 [02:03<00:36, 312.68 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35469/47780 [02:03<00:45, 273.57 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34814/47780 [02:03<00:41, 312.88 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36440/47780 [02:03<00:50, 223.87 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37723/47780 [02:03<00:38, 260.43 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36798/47780 [02:03<00:34, 316.31 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34784/47780 [02:03<00:46, 280.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30409/47780 [02:03<00:47, 362.67 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35497/47780 [02:03<00:45, 269.43 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36432/47780 [02:03<00:41, 272.31 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36463/47780 [02:03<00:50, 223.65 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37758/47780 [02:03<00:36, 275.92 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34848/47780 [02:03<00:44, 293.53 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34817/47780 [02:03<00:44, 289.36 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30449/47780 [02:03<00:46, 372.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36830/47780 [02:03<00:38, 281.82 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36462/47780 [02:03<00:40, 276.78 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35525/47780 [02:03<00:45, 269.32 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36489/47780 [02:03<00:49, 228.12 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37789/47780 [02:03<00:35, 282.10 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34879/47780 [02:03<00:45, 285.01 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34848/47780 [02:03<00:44, 289.98 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30488/47780 [02:03<00:46, 373.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36860/47780 [02:03<00:38, 283.79 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35557/47780 [02:03<00:43, 280.69 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36516/47780 [02:03<00:47, 238.10 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36491/47780 [02:03<00:42, 268.57 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37818/47780 [02:03<00:36, 269.33 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30526/47780 [02:03<00:46, 367.18 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36891/47780 [02:03<00:37, 290.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34908/47780 [02:03<00:49, 261.92 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35586/47780 [02:03<00:43, 282.67 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36542/47780 [02:03<00:46, 243.95 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36529/47780 [02:03<00:37, 298.16 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34878/47780 [02:03<00:53, 238.99 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30566/47780 [02:03<00:46, 372.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36928/47780 [02:03<00:35, 309.70 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37846/47780 [02:03<00:41, 238.69 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34938/47780 [02:03<00:48, 262.08 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35617/47780 [02:03<00:42, 287.91 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36571/47780 [02:03<00:44, 251.81 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36560/47780 [02:03<00:40, 274.55 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30604/47780 [02:03<00:48, 357.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34905/47780 [02:03<01:00, 212.97 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37872/47780 [02:03<00:41, 239.01 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36960/47780 [02:03<00:37, 292.12 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34965/47780 [02:03<00:50, 253.03 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35647/47780 [02:03<00:45, 263.79 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36597/47780 [02:03<00:48, 232.75 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36595/47780 [02:03<00:38, 293.77 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30649/47780 [02:04<00:46, 371.49 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37898/47780 [02:03<00:40, 244.37 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36993/47780 [02:03<00:36, 296.87 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34991/47780 [02:03<00:50, 254.38 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34929/47780 [02:03<01:05, 195.51 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35675/47780 [02:03<00:45, 268.17 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36621/47780 [02:04<00:49, 224.80 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36626/47780 [02:04<00:38, 286.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30690/47780 [02:04<00:45, 378.04 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37924/47780 [02:04<00:41, 236.14 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35017/47780 [02:04<00:51, 248.75 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37024/47780 [02:04<00:37, 287.36 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36648/47780 [02:04<00:47, 236.43 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35704/47780 [02:04<00:47, 254.01 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36657/47780 [02:04<00:39, 280.64 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30728/47780 [02:04<00:45, 378.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34950/47780 [02:04<01:12, 177.64 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35042/47780 [02:04<00:51, 247.96 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37951/47780 [02:04<00:40, 242.60 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37058/47780 [02:04<00:35, 298.65 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35733/47780 [02:04<00:46, 261.27 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34986/47780 [02:04<00:58, 216.99 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30769/47780 [02:04<00:44, 379.08 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36672/47780 [02:04<00:52, 213.10 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36686/47780 [02:04<00:42, 262.99 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35073/47780 [02:04<00:48, 262.61 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37978/47780 [02:04<00:39, 247.50 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37089/47780 [02:04<00:36, 294.53 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35760/47780 [02:04<00:48, 247.80 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35068/47780 [02:04<00:34, 363.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30810/47780 [02:04<00:43, 387.69 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36713/47780 [02:04<00:42, 259.19 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38008/47780 [02:04<00:37, 261.97 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35100/47780 [02:04<00:48, 262.61 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36694/47780 [02:04<00:55, 201.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37119/47780 [02:04<00:38, 277.21 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30849/47780 [02:04<00:45, 371.03 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35786/47780 [02:04<00:50, 237.67 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36741/47780 [02:04<00:42, 262.04 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38036/47780 [02:04<00:36, 264.31 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35129/47780 [02:04<00:47, 267.91 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36721/47780 [02:04<00:53, 206.23 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35110/47780 [02:04<00:39, 318.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37147/47780 [02:04<00:40, 264.27 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35811/47780 [02:04<00:50, 238.40 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30887/47780 [02:04<00:46, 361.21 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36768/47780 [02:04<00:42, 258.63 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38066/47780 [02:04<00:35, 274.32 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35163/47780 [02:04<00:44, 283.95 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36752/47780 [02:04<00:47, 230.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37174/47780 [02:04<00:41, 257.47 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35839/47780 [02:04<00:48, 247.14 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30934/47780 [02:04<00:43, 388.30 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36799/47780 [02:04<00:41, 267.04 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38094/47780 [02:04<00:36, 266.19 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35192/47780 [02:04<00:46, 270.08 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36777/47780 [02:04<00:48, 228.68 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35147/47780 [02:04<00:49, 255.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37204/47780 [02:04<00:39, 266.10 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35864/47780 [02:04<00:48, 245.14 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30976/47780 [02:04<00:42, 392.50 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36828/47780 [02:04<00:40, 269.97 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35220/47780 [02:04<00:46, 272.74 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38121/47780 [02:04<00:38, 253.46 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36806/47780 [02:04<00:44, 245.29 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35207/47780 [02:04<00:38, 324.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37247/47780 [02:04<00:34, 301.59 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35890/47780 [02:04<00:47, 248.03 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31026/47780 [02:04<00:39, 419.24 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35248/47780 [02:04<00:46, 268.41 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38150/47780 [02:04<00:36, 260.78 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36857/47780 [02:04<00:43, 253.21 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36831/47780 [02:04<00:47, 231.21 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35246/47780 [02:04<00:37, 330.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37278/47780 [02:04<00:34, 300.74 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35915/47780 [02:04<00:50, 236.32 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38182/47780 [02:05<00:34, 274.56 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35275/47780 [02:05<00:47, 265.14 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31069/47780 [02:05<00:44, 377.24 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36887/47780 [02:05<00:41, 260.17 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36864/47780 [02:05<00:42, 257.12 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35289/47780 [02:05<00:35, 354.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37309/47780 [02:05<00:35, 296.24 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35942/47780 [02:05<00:48, 243.12 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31109/47780 [02:05<00:44, 376.05 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35302/47780 [02:05<00:48, 255.35 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38210/47780 [02:05<00:36, 263.20 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36914/47780 [02:05<00:42, 254.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36891/47780 [02:05<00:43, 252.94 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37343/47780 [02:05<00:34, 305.37 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35329/47780 [02:05<00:37, 335.05 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35968/47780 [02:05<00:48, 244.67 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31148/47780 [02:05<00:45, 367.79 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36941/47780 [02:05<00:42, 254.61 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38237/47780 [02:05<00:38, 248.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35328/47780 [02:05<00:51, 240.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36917/47780 [02:05<00:45, 238.98 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37374/47780 [02:05<00:34, 297.91 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35366/47780 [02:05<00:37, 327.04 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35993/47780 [02:05<00:49, 235.79 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36967/47780 [02:05<00:42, 251.88 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31196/47780 [02:05<00:42, 385.94 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35362/47780 [02:05<00:47, 262.57 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38263/47780 [02:05<00:38, 244.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36946/47780 [02:05<00:42, 252.73 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37411/47780 [02:05<00:32, 317.08 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36023/47780 [02:05<00:46, 251.03 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35401/47780 [02:05<00:40, 307.80 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37002/47780 [02:05<00:38, 279.36 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31242/47780 [02:05<00:40, 406.29 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35390/47780 [02:05<00:46, 267.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38291/47780 [02:05<00:37, 253.75 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36974/47780 [02:05<00:42, 254.93 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37443/47780 [02:05<00:33, 310.44 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36055/47780 [02:05<00:43, 268.02 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31287/47780 [02:05<00:40, 410.62 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35417/47780 [02:05<00:46, 267.80 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37045/47780 [02:05<00:34, 308.50 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38317/47780 [02:05<00:37, 249.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35434/47780 [02:05<00:43, 285.27 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37478/47780 [02:05<00:33, 309.56 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37000/47780 [02:05<00:45, 237.91 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36082/47780 [02:05<00:44, 262.12 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35444/47780 [02:05<00:46, 265.51 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37076/47780 [02:05<00:35, 305.57 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31329/47780 [02:05<00:41, 398.58 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38344/47780 [02:05<00:36, 255.52 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37512/47780 [02:05<00:32, 316.48 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35464/47780 [02:05<00:46, 263.01 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37025/47780 [02:05<00:47, 226.20 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36112/47780 [02:05<00:43, 269.65 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35477/47780 [02:05<00:43, 281.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31374/47780 [02:05<00:39, 412.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37107/47780 [02:05<00:36, 290.39 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38370/47780 [02:05<00:39, 240.43 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37546/47780 [02:05<00:32, 315.94 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37051/47780 [02:05<00:45, 235.06 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36140/47780 [02:05<00:42, 272.49 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35492/47780 [02:05<00:48, 251.81 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35509/47780 [02:05<00:42, 289.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31416/47780 [02:05<00:39, 414.72 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38395/47780 [02:05<00:39, 240.47 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37137/47780 [02:05<00:37, 280.27 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37582/47780 [02:05<00:31, 328.50 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35527/47780 [02:05<00:44, 275.96 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36171/47780 [02:05<00:42, 274.27 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37078/47780 [02:05<00:45, 237.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35546/47780 [02:05<00:39, 308.91 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31458/47780 [02:06<00:42, 380.64 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38422/47780 [02:06<00:38, 243.33 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37616/47780 [02:06<00:31, 324.34 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37175/47780 [02:06<00:36, 291.91 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37112/47780 [02:06<00:40, 265.41 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35556/47780 [02:06<00:45, 269.00 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36200/47780 [02:06<00:43, 266.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35577/47780 [02:06<00:39, 305.85 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31501/47780 [02:06<00:41, 390.54 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38458/47780 [02:06<00:34, 270.18 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37649/47780 [02:06<00:31, 322.31 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37210/47780 [02:06<00:34, 304.42 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36232/47780 [02:06<00:41, 275.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35584/47780 [02:06<00:46, 263.44 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31541/47780 [02:06<00:41, 388.24 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38492/47780 [02:06<00:32, 289.73 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37139/47780 [02:06<00:49, 215.60 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35608/47780 [02:06<00:45, 269.07 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37689/47780 [02:06<00:30, 333.08 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37242/47780 [02:06<00:36, 291.25 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36260/47780 [02:06<00:43, 267.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35611/47780 [02:06<00:48, 251.76 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31582/47780 [02:06<00:41, 390.59 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35636/47780 [02:06<00:45, 266.58 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37163/47780 [02:06<00:49, 216.43 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37723/47780 [02:06<00:30, 331.32 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38522/47780 [02:06<00:33, 273.48 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37273/47780 [02:06<00:36, 288.23 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35637/47780 [02:06<00:48, 248.97 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36287/47780 [02:06<00:46, 246.29 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31622/47780 [02:06<00:42, 376.05 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37191/47780 [02:06<00:46, 229.03 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38550/47780 [02:06<00:34, 269.95 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37757/47780 [02:06<00:31, 319.20 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35664/47780 [02:06<00:47, 256.25 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37309/47780 [02:06<00:34, 307.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35663/47780 [02:06<00:48, 251.83 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36312/47780 [02:06<00:47, 241.97 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31662/47780 [02:06<00:42, 382.68 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38584/47780 [02:06<00:32, 286.17 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37794/47780 [02:06<00:29, 333.51 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37216/47780 [02:06<00:46, 227.31 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37341/47780 [02:06<00:33, 311.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35691/47780 [02:06<00:48, 250.67 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35690/47780 [02:06<00:50, 240.86 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36339/47780 [02:06<00:45, 249.59 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31701/47780 [02:06<00:43, 367.91 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37247/47780 [02:06<00:43, 244.19 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38613/47780 [02:06<00:33, 274.89 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37828/47780 [02:06<00:31, 319.53 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35719/47780 [02:06<00:47, 254.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37373/47780 [02:06<00:35, 296.92 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35718/47780 [02:06<00:47, 251.35 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31739/47780 [02:06<00:44, 358.71 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36365/47780 [02:06<00:50, 226.08 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37275/47780 [02:06<00:41, 251.14 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38641/47780 [02:06<00:33, 276.02 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37405/47780 [02:06<00:34, 299.91 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35745/47780 [02:06<00:48, 247.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37862/47780 [02:06<00:33, 299.27 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35744/47780 [02:06<00:48, 248.36 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37301/47780 [02:06<00:41, 250.91 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31776/47780 [02:06<00:45, 350.34 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36398/47780 [02:06<00:45, 249.12 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35774/47780 [02:06<00:46, 256.67 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38669/47780 [02:06<00:35, 259.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37436/47780 [02:06<00:37, 274.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37893/47780 [02:06<00:34, 286.89 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35772/47780 [02:06<00:46, 257.16 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31812/47780 [02:07<00:45, 349.36 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37331/47780 [02:06<00:39, 261.81 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36424/47780 [02:06<00:45, 247.09 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35802/47780 [02:07<00:46, 260.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38701/47780 [02:06<00:33, 273.34 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37465/47780 [02:07<00:38, 267.49 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37922/47780 [02:07<00:35, 275.61 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35798/47780 [02:07<00:48, 249.51 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37359/47780 [02:07<00:39, 263.93 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31850/47780 [02:07<00:46, 342.62 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36450/47780 [02:07<00:47, 240.01 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35830/47780 [02:07<00:44, 265.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38729/47780 [02:07<00:33, 266.24 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37502/47780 [02:07<00:35, 291.90 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37953/47780 [02:07<00:34, 284.71 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35824/47780 [02:07<00:48, 246.85 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31901/47780 [02:07<00:40, 388.93 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37391/47780 [02:07<00:38, 267.76 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35857/47780 [02:07<00:46, 258.18 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38758/47780 [02:07<00:33, 272.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36475/47780 [02:07<00:48, 232.62 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37989/47780 [02:07<00:32, 299.48 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37548/47780 [02:07<00:32, 317.18 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35849/47780 [02:07<00:50, 236.82 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31947/47780 [02:07<00:39, 404.93 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35889/47780 [02:07<00:44, 266.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36499/47780 [02:07<00:49, 229.03 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37418/47780 [02:07<00:43, 236.53 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38786/47780 [02:07<00:36, 246.93 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38021/47780 [02:07<00:31, 305.11 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37580/47780 [02:07<00:32, 314.65 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35875/47780 [02:07<00:50, 235.51 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35916/47780 [02:07<00:44, 264.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31988/47780 [02:07<00:42, 372.26 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37473/47780 [02:07<00:32, 318.54 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38820/47780 [02:07<00:33, 266.19 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36523/47780 [02:07<00:53, 211.43 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38052/47780 [02:07<00:33, 290.00 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37612/47780 [02:07<00:32, 309.44 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35905/47780 [02:07<00:46, 253.38 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35943/47780 [02:07<00:45, 257.50 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32026/47780 [02:07<00:43, 366.08 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38859/47780 [02:07<00:29, 299.90 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37507/47780 [02:07<00:33, 310.85 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35931/47780 [02:07<00:46, 252.40 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38082/47780 [02:07<00:34, 280.30 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36545/47780 [02:07<00:57, 195.09 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37643/47780 [02:07<00:35, 283.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32064/47780 [02:07<00:43, 361.74 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35971/47780 [02:07<00:46, 254.44 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37541/47780 [02:07<00:32, 311.87 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38890/47780 [02:07<00:32, 277.75 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38114/47780 [02:07<00:33, 287.96 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35960/47780 [02:07<00:45, 257.33 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36571/47780 [02:07<00:53, 207.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37689/47780 [02:07<00:30, 327.92 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32107/47780 [02:07<00:42, 372.88 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35997/47780 [02:07<00:46, 251.02 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38143/47780 [02:07<00:34, 283.20 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38921/47780 [02:07<00:32, 274.55 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37723/47780 [02:07<00:30, 327.60 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35986/47780 [02:07<00:50, 234.12 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36593/47780 [02:07<00:57, 194.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37574/47780 [02:07<00:37, 269.56 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32147/47780 [02:07<00:41, 376.37 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36023/47780 [02:07<00:48, 240.05 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38173/47780 [02:07<00:34, 280.65 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38951/47780 [02:07<00:31, 278.53 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36010/47780 [02:07<00:50, 233.21 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36615/47780 [02:07<00:56, 197.11 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37603/47780 [02:07<00:38, 266.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37757/47780 [02:07<00:32, 306.75 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32185/47780 [02:08<00:41, 373.13 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36048/47780 [02:07<00:49, 234.84 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38206/47780 [02:08<00:33, 288.00 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38980/47780 [02:08<00:32, 272.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36644/47780 [02:07<00:51, 217.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36035/47780 [02:08<00:53, 220.81 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32226/47780 [02:08<00:41, 379.31 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37790/47780 [02:08<00:33, 294.28 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37631/47780 [02:08<00:42, 238.19 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36072/47780 [02:08<00:51, 226.41 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36672/47780 [02:08<00:47, 234.08 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39008/47780 [02:08<00:34, 255.06 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32271/47780 [02:08<00:38, 399.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38235/47780 [02:08<00:37, 251.58 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36058/47780 [02:08<00:53, 218.36 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37822/47780 [02:08<00:33, 300.81 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36095/47780 [02:08<00:52, 222.15 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39038/47780 [02:08<00:33, 264.30 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36701/47780 [02:08<00:44, 246.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37656/47780 [02:08<00:47, 211.66 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32324/47780 [02:08<00:35, 430.16 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38265/47780 [02:08<00:36, 260.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36086/47780 [02:08<00:50, 233.20 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37856/47780 [02:08<00:32, 305.24 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36120/47780 [02:08<00:51, 227.75 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36734/47780 [02:08<00:40, 270.32 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37680/47780 [02:08<00:47, 214.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39066/47780 [02:08<00:33, 262.94 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32370/47780 [02:08<00:36, 425.59 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38307/47780 [02:08<00:32, 294.58 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37893/47780 [02:08<00:30, 319.71 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36110/47780 [02:08<00:54, 213.04 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36143/47780 [02:08<00:52, 221.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36769/47780 [02:08<00:38, 286.83 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32417/47780 [02:08<00:35, 434.30 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37929/47780 [02:08<00:30, 323.75 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38345/47780 [02:08<00:30, 311.54 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39093/47780 [02:08<00:35, 245.15 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36141/47780 [02:08<00:49, 236.61 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37703/47780 [02:08<00:52, 193.48 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36169/47780 [02:08<00:51, 226.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36801/47780 [02:08<00:37, 296.23 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32463/47780 [02:08<00:34, 441.69 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39139/47780 [02:08<00:29, 297.16 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38377/47780 [02:08<00:30, 304.21 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37724/47780 [02:08<00:52, 193.24 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36166/47780 [02:08<00:49, 232.76 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37962/47780 [02:08<00:33, 292.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36192/47780 [02:08<00:52, 222.04 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32515/47780 [02:08<00:33, 459.24 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36831/47780 [02:08<00:40, 269.15 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39170/47780 [02:08<00:29, 294.78 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38408/47780 [02:08<00:31, 296.38 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37785/47780 [02:08<00:33, 295.34 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36190/47780 [02:08<00:52, 222.49 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36217/47780 [02:08<00:50, 227.87 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37992/47780 [02:08<00:35, 279.28 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36863/47780 [02:08<00:39, 276.79 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32561/47780 [02:08<00:35, 434.03 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38438/47780 [02:08<00:31, 293.24 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39200/47780 [02:08<00:31, 274.16 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36213/47780 [02:08<00:51, 223.84 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36249/47780 [02:08<00:45, 252.69 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38023/47780 [02:08<00:34, 284.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37818/47780 [02:08<00:36, 275.57 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36900/47780 [02:08<00:36, 299.36 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32614/47780 [02:08<00:33, 456.04 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38470/47780 [02:08<00:31, 297.38 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39229/47780 [02:08<00:31, 275.71 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36236/47780 [02:08<00:52, 221.27 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38060/47780 [02:08<00:32, 301.41 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37848/47780 [02:08<00:35, 276.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36276/47780 [02:08<00:47, 240.84 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36932/47780 [02:08<00:36, 298.31 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38500/47780 [02:09<00:32, 285.54 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39258/47780 [02:09<00:31, 273.59 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36259/47780 [02:09<00:51, 223.45 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38091/47780 [02:09<00:32, 299.94 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32661/47780 [02:09<00:38, 389.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36301/47780 [02:09<00:49, 234.08 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37877/47780 [02:09<00:39, 248.64 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39286/47780 [02:09<00:30, 274.79 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38529/47780 [02:09<00:32, 283.28 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36963/47780 [02:09<00:39, 277.06 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36282/47780 [02:09<00:52, 219.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38129/47780 [02:09<00:30, 315.84 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32702/47780 [02:09<00:39, 378.62 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36325/47780 [02:09<00:50, 225.91 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37913/47780 [02:09<00:35, 276.30 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38558/47780 [02:09<00:32, 281.29 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39324/47780 [02:09<00:28, 301.93 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36993/47780 [02:09<00:38, 280.34 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36305/47780 [02:09<00:53, 216.07 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38174/47780 [02:09<00:27, 349.74 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32761/47780 [02:09<00:34, 429.37 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36348/47780 [02:09<00:53, 215.38 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37943/47780 [02:09<00:37, 263.15 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38587/47780 [02:09<00:33, 278.03 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37022/47780 [02:09<00:38, 277.87 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39355/47780 [02:09<00:28, 291.15 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38210/47780 [02:09<00:27, 348.47 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36328/47780 [02:09<00:53, 212.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32807/47780 [02:09<00:34, 437.28 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36374/47780 [02:09<00:50, 227.46 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37053/47780 [02:09<00:37, 285.49 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39390/47780 [02:09<00:27, 307.48 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37972/47780 [02:09<00:38, 254.44 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38615/47780 [02:09<00:34, 263.52 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38247/47780 [02:09<00:27, 350.90 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36355/47780 [02:09<00:49, 228.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32854/47780 [02:09<00:33, 446.25 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36398/47780 [02:09<00:49, 228.40 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37082/47780 [02:09<00:37, 282.41 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39422/47780 [02:09<00:27, 309.19 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38657/47780 [02:09<00:30, 300.71 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38000/47780 [02:09<00:38, 255.59 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38286/47780 [02:09<00:26, 358.13 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36382/47780 [02:09<00:47, 237.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32900/47780 [02:09<00:33, 445.64 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36421/47780 [02:09<00:50, 223.90 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37112/47780 [02:09<00:37, 282.13 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38027/47780 [02:09<00:37, 256.79 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38692/47780 [02:09<00:29, 311.10 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39454/47780 [02:09<00:28, 296.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38322/47780 [02:09<00:27, 342.19 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36406/47780 [02:09<00:50, 225.52 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32946/47780 [02:09<00:34, 429.98 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36453/47780 [02:09<00:45, 251.09 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37151/47780 [02:09<00:35, 302.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38724/47780 [02:09<00:29, 306.11 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38357/47780 [02:09<00:28, 333.55 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32990/47780 [02:09<00:34, 423.32 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36429/47780 [02:09<00:52, 217.10 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38054/47780 [02:09<00:42, 230.00 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39484/47780 [02:09<00:32, 254.86 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36482/47780 [02:09<00:44, 253.02 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37184/47780 [02:09<00:34, 307.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38760/47780 [02:09<00:28, 318.31 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38391/47780 [02:09<00:28, 324.32 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33034/47780 [02:10<00:35, 418.56 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36463/47780 [02:09<00:46, 243.06 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38080/47780 [02:09<00:41, 235.17 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39533/47780 [02:09<00:26, 311.84 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36508/47780 [02:09<00:44, 252.40 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37216/47780 [02:09<00:34, 310.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38793/47780 [02:10<00:28, 314.50 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38428/47780 [02:10<00:28, 329.84 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36488/47780 [02:10<00:46, 244.88 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33077/47780 [02:10<00:36, 407.95 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38107/47780 [02:10<00:40, 237.15 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39569/47780 [02:10<00:25, 321.22 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36534/47780 [02:10<00:46, 243.37 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37251/47780 [02:10<00:33, 318.23 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38828/47780 [02:10<00:27, 324.60 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38462/47780 [02:10<00:28, 330.76 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36514/47780 [02:10<00:47, 238.36 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38132/47780 [02:10<00:40, 237.72 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33119/47780 [02:10<00:36, 397.69 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39603/47780 [02:10<00:27, 300.13 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36559/47780 [02:10<00:49, 227.58 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37283/47780 [02:10<00:34, 304.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38870/47780 [02:10<00:25, 344.29 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38496/47780 [02:10<00:29, 314.91 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33162/47780 [02:10<00:36, 402.48 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38165/47780 [02:10<00:37, 257.89 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36538/47780 [02:10<00:48, 233.71 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36583/47780 [02:10<00:48, 230.83 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39635/47780 [02:10<00:27, 292.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37314/47780 [02:10<00:34, 306.05 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38905/47780 [02:10<00:26, 330.72 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38528/47780 [02:10<00:29, 314.87 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33203/47780 [02:10<00:36, 400.09 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38192/47780 [02:10<00:39, 244.90 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36562/47780 [02:10<00:51, 218.40 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37349/47780 [02:10<00:33, 315.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36607/47780 [02:10<00:51, 218.66 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38946/47780 [02:10<00:25, 352.76 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39665/47780 [02:10<00:30, 269.14 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33250/47780 [02:10<00:34, 415.22 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38227/47780 [02:10<00:35, 270.55 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38560/47780 [02:10<00:31, 292.54 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36588/47780 [02:10<00:49, 227.14 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37381/47780 [02:10<00:33, 309.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36633/47780 [02:10<00:48, 227.53 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38982/47780 [02:10<00:25, 342.66 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39693/47780 [02:10<00:30, 263.33 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33302/47780 [02:10<00:33, 430.51 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36613/47780 [02:10<00:48, 230.92 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38255/47780 [02:10<00:35, 267.23 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38590/47780 [02:10<00:34, 268.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36663/47780 [02:10<00:45, 244.72 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37412/47780 [02:10<00:35, 289.56 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39017/47780 [02:10<00:27, 323.88 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39720/47780 [02:10<00:32, 249.84 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33350/47780 [02:10<00:32, 444.10 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36639/47780 [02:10<00:46, 238.35 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38283/47780 [02:10<00:35, 266.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36689/47780 [02:10<00:44, 246.49 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38618/47780 [02:10<00:35, 260.52 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37450/47780 [02:10<00:33, 311.28 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39051/47780 [02:10<00:26, 324.22 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39751/47780 [02:10<00:30, 260.02 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33395/47780 [02:10<00:32, 436.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38310/47780 [02:10<00:36, 259.90 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36715/47780 [02:10<00:47, 234.41 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37482/47780 [02:10<00:33, 306.54 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36663/47780 [02:10<00:55, 199.09 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39086/47780 [02:10<00:27, 320.60 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39781/47780 [02:10<00:29, 270.51 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38646/47780 [02:10<00:38, 238.40 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33440/47780 [02:10<00:33, 434.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38339/47780 [02:10<00:35, 265.37 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37515/47780 [02:10<00:33, 306.55 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36739/47780 [02:10<00:48, 228.40 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36703/47780 [02:10<00:44, 246.91 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38671/47780 [02:11<00:38, 238.45 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39119/47780 [02:11<00:28, 309.22 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33484/47780 [02:11<00:34, 417.92 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39809/47780 [02:11<00:31, 253.78 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38366/47780 [02:11<00:35, 263.58 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37551/47780 [02:11<00:31, 321.32 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36764/47780 [02:11<00:47, 231.79 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36730/47780 [02:11<00:45, 242.80 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38703/47780 [02:11<00:35, 257.64 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33530/47780 [02:11<00:33, 429.34 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39838/47780 [02:11<00:30, 263.44 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39151/47780 [02:11<00:29, 293.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38395/47780 [02:11<00:36, 259.38 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36789/47780 [02:11<00:46, 234.18 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37584/47780 [02:11<00:33, 307.40 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38737/47780 [02:11<00:32, 277.05 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36756/47780 [02:11<00:48, 227.93 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39865/47780 [02:11<00:30, 256.31 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39181/47780 [02:11<00:31, 277.00 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33574/47780 [02:11<00:36, 391.50 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38422/47780 [02:11<00:36, 253.85 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36819/47780 [02:11<00:43, 249.96 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37622/47780 [02:11<00:31, 319.63 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38766/47780 [02:11<00:32, 280.03 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36784/47780 [02:11<00:46, 236.51 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39896/47780 [02:11<00:29, 265.77 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33632/47780 [02:11<00:31, 442.61 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39211/47780 [02:11<00:30, 280.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38456/47780 [02:11<00:33, 277.73 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36847/47780 [02:11<00:42, 255.82 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37657/47780 [02:11<00:32, 314.05 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38801/47780 [02:11<00:30, 290.55 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36809/47780 [02:11<00:46, 237.27 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39923/47780 [02:11<00:30, 261.10 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33679/47780 [02:11<00:31, 449.92 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39246/47780 [02:11<00:28, 295.93 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38485/47780 [02:11<00:33, 275.21 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36877/47780 [02:11<00:40, 268.36 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38840/47780 [02:11<00:28, 318.53 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37694/47780 [02:11<00:30, 329.30 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36841/47780 [02:11<00:42, 257.48 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33725/47780 [02:11<00:31, 443.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39950/47780 [02:11<00:31, 252.30 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38513/47780 [02:11<00:34, 267.39 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39276/47780 [02:11<00:30, 275.05 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36904/47780 [02:11<00:43, 248.77 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37728/47780 [02:11<00:32, 305.09 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36868/47780 [02:11<00:42, 255.19 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38873/47780 [02:11<00:30, 290.98 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39980/47780 [02:11<00:29, 262.58 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38541/47780 [02:11<00:34, 267.87 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33770/47780 [02:11<00:35, 399.70 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39304/47780 [02:11<00:31, 265.52 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36930/47780 [02:11<00:43, 251.81 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37759/47780 [02:11<00:33, 302.85 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38907/47780 [02:11<00:29, 301.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36899/47780 [02:11<00:41, 264.68 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40007/47780 [02:11<00:30, 255.74 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38584/47780 [02:11<00:29, 310.80 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39331/47780 [02:11<00:32, 258.35 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36956/47780 [02:11<00:44, 245.70 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33812/47780 [02:11<00:38, 362.47 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38938/47780 [02:11<00:29, 301.43 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36928/47780 [02:11<00:41, 264.33 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40039/47780 [02:11<00:29, 265.32 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38616/47780 [02:11<00:30, 299.59 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37790/47780 [02:11<00:37, 269.09 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39357/47780 [02:11<00:34, 245.43 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36981/47780 [02:11<00:44, 243.97 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33850/47780 [02:12<00:38, 359.62 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38969/47780 [02:11<00:29, 296.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36955/47780 [02:11<00:41, 261.24 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40075/47780 [02:11<00:27, 285.13 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37826/47780 [02:11<00:34, 289.78 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38648/47780 [02:12<00:32, 282.82 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39395/47780 [02:12<00:30, 278.67 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37006/47780 [02:12<00:45, 237.79 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33892/47780 [02:12<00:37, 375.30 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36984/47780 [02:12<00:40, 266.72 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38999/47780 [02:12<00:32, 272.74 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37865/47780 [02:12<00:31, 316.38 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40105/47780 [02:12<00:27, 280.75 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39424/47780 [02:12<00:29, 278.75 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38677/47780 [02:12<00:34, 264.87 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37033/47780 [02:12<00:44, 241.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33931/47780 [02:12<00:37, 371.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37012/47780 [02:12<00:40, 264.42 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39027/47780 [02:12<00:32, 269.12 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40135/47780 [02:12<00:27, 273.15 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37898/47780 [02:12<00:33, 291.42 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39456/47780 [02:12<00:28, 290.26 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38704/47780 [02:12<00:34, 266.17 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37063/47780 [02:12<00:41, 257.83 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33969/47780 [02:12<00:38, 357.37 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37040/47780 [02:12<00:41, 257.14 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39055/47780 [02:12<00:32, 266.21 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40163/47780 [02:12<00:29, 257.86 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38734/47780 [02:12<00:33, 272.59 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39487/47780 [02:12<00:29, 282.23 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34008/47780 [02:12<00:37, 363.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37089/47780 [02:12<00:45, 236.88 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39082/47780 [02:12<00:32, 266.63 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37929/47780 [02:12<00:43, 228.62 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40191/47780 [02:12<00:29, 255.61 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39517/47780 [02:12<00:29, 278.60 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37066/47780 [02:12<00:51, 208.83 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38762/47780 [02:12<00:35, 254.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37118/47780 [02:12<00:42, 248.70 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34045/47780 [02:12<00:41, 331.61 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39110/47780 [02:12<00:32, 265.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40225/47780 [02:12<00:28, 266.91 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37097/47780 [02:12<00:45, 233.46 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37955/47780 [02:12<00:46, 210.37 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38788/47780 [02:12<00:37, 240.63 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34079/47780 [02:12<00:41, 330.30 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39546/47780 [02:12<00:33, 246.10 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39151/47780 [02:12<00:28, 302.92 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37144/47780 [02:12<00:50, 211.77 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40258/47780 [02:12<00:26, 283.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37129/47780 [02:12<00:42, 248.17 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38817/47780 [02:12<00:35, 253.31 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38022/47780 [02:12<00:32, 302.66 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39601/47780 [02:12<00:25, 324.59 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34113/47780 [02:12<00:43, 312.49 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39182/47780 [02:12<00:30, 284.51 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40287/47780 [02:12<00:26, 282.69 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37158/47780 [02:12<00:40, 259.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37167/47780 [02:12<00:56, 188.04 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38072/47780 [02:12<00:28, 343.13 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39636/47780 [02:12<00:25, 314.09 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34145/47780 [02:12<00:44, 307.44 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38843/47780 [02:12<00:40, 221.43 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40316/47780 [02:12<00:26, 284.11 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39212/47780 [02:12<00:32, 263.34 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37185/47780 [02:12<00:42, 251.28 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37227/47780 [02:12<00:37, 283.09 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39675/47780 [02:12<00:24, 331.30 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38110/47780 [02:12<00:29, 329.44 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34178/47780 [02:13<00:43, 309.42 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38867/47780 [02:12<00:39, 224.53 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40345/47780 [02:13<00:28, 262.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37213/47780 [02:13<00:41, 256.22 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37262/47780 [02:13<00:35, 296.99 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39239/47780 [02:13<00:35, 237.47 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34213/47780 [02:13<00:42, 318.46 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38894/47780 [02:13<00:37, 235.90 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39710/47780 [02:13<00:26, 309.20 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38146/47780 [02:13<00:30, 311.92 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40374/47780 [02:13<00:28, 264.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37294/47780 [02:13<00:34, 302.58 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39268/47780 [02:13<00:33, 250.74 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37240/47780 [02:13<00:41, 251.24 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34246/47780 [02:13<00:42, 321.70 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38920/47780 [02:13<00:37, 237.22 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39745/47780 [02:13<00:25, 313.35 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38184/47780 [02:13<00:29, 325.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37327/47780 [02:13<00:33, 309.08 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40401/47780 [02:13<00:29, 251.60 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39294/47780 [02:13<00:34, 242.57 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37266/47780 [02:13<00:44, 235.82 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34282/47780 [02:13<00:42, 318.14 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38949/47780 [02:13<00:35, 249.15 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39778/47780 [02:13<00:25, 311.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38218/47780 [02:13<00:30, 315.19 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40427/47780 [02:13<00:29, 246.09 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37299/47780 [02:13<00:40, 261.03 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37360/47780 [02:13<00:36, 287.16 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34321/47780 [02:13<00:39, 338.26 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38977/47780 [02:13<00:34, 254.90 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39813/47780 [02:13<00:25, 318.32 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38251/47780 [02:13<00:30, 317.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39319/47780 [02:13<00:41, 203.42 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40458/47780 [02:13<00:28, 260.69 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37392/47780 [02:13<00:35, 292.94 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37326/47780 [02:13<00:41, 252.14 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34357/47780 [02:13<00:40, 333.11 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39005/47780 [02:13<00:33, 261.93 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39847/47780 [02:13<00:24, 320.77 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38284/47780 [02:13<00:30, 313.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39341/47780 [02:13<00:41, 205.63 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40486/47780 [02:13<00:28, 254.77 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37352/47780 [02:13<00:41, 251.55 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34392/47780 [02:13<00:39, 337.87 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37423/47780 [02:13<00:37, 273.64 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39883/47780 [02:13<00:24, 328.13 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39363/47780 [02:13<00:40, 209.24 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39032/47780 [02:13<00:37, 234.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38319/47780 [02:13<00:30, 307.00 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40516/47780 [02:13<00:27, 267.10 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34429/47780 [02:13<00:39, 339.26 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37378/47780 [02:13<00:43, 238.26 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39918/47780 [02:13<00:24, 323.35 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37452/47780 [02:13<00:39, 263.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39385/47780 [02:13<00:41, 203.25 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38351/47780 [02:13<00:31, 300.50 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39057/47780 [02:13<00:39, 222.04 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40545/47780 [02:13<00:26, 270.67 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34464/47780 [02:13<00:40, 331.04 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37405/47780 [02:13<00:42, 244.28 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37479/47780 [02:13<00:39, 257.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39951/47780 [02:13<00:24, 314.58 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39413/47780 [02:13<00:38, 219.30 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38387/47780 [02:13<00:29, 313.58 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40577/47780 [02:13<00:25, 278.36 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39080/47780 [02:13<00:42, 206.50 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37441/47780 [02:13<00:38, 267.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34498/47780 [02:13<00:41, 322.27 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39436/47780 [02:13<00:37, 219.76 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38419/47780 [02:13<00:30, 304.89 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39984/47780 [02:13<00:27, 286.12 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37506/47780 [02:13<00:44, 233.44 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40605/47780 [02:13<00:25, 278.83 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39103/47780 [02:14<00:42, 206.43 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34541/47780 [02:14<00:37, 352.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37470/47780 [02:14<00:38, 267.72 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39459/47780 [02:14<00:38, 217.89 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38456/47780 [02:13<00:28, 322.89 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37551/47780 [02:14<00:35, 288.62 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40017/47780 [02:14<00:26, 292.06 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39124/47780 [02:14<00:41, 207.10 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40633/47780 [02:14<00:27, 258.05 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34580/47780 [02:14<00:36, 359.63 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37507/47780 [02:14<00:35, 293.20 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39483/47780 [02:14<00:37, 221.65 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37585/47780 [02:14<00:33, 302.18 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40055/47780 [02:14<00:24, 315.70 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38489/47780 [02:14<00:29, 314.21 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39145/47780 [02:14<00:41, 206.00 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40665/47780 [02:14<00:26, 272.43 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34617/47780 [02:14<00:36, 362.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37539/47780 [02:14<00:34, 300.73 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38521/47780 [02:14<00:29, 314.90 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37617/47780 [02:14<00:34, 294.26 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40088/47780 [02:14<00:25, 302.74 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39506/47780 [02:14<00:40, 203.30 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39168/47780 [02:14<00:40, 212.63 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40699/47780 [02:14<00:24, 291.35 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34658/47780 [02:14<00:35, 372.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37573/47780 [02:14<00:32, 311.95 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38553/47780 [02:14<00:30, 303.66 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39536/47780 [02:14<00:36, 226.66 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40744/47780 [02:14<00:20, 336.75 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40119/47780 [02:14<00:26, 292.17 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37648/47780 [02:14<00:36, 274.46 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39191/47780 [02:14<00:41, 208.07 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37608/47780 [02:14<00:31, 319.50 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34697/47780 [02:14<00:35, 364.54 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39563/47780 [02:14<00:34, 235.04 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38587/47780 [02:14<00:30, 296.77 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37681/47780 [02:14<00:35, 286.66 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40159/47780 [02:14<00:24, 308.19 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40779/47780 [02:14<00:21, 325.50 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34734/47780 [02:14<00:36, 362.00 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39219/47780 [02:14<00:39, 216.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37641/47780 [02:14<00:32, 307.93 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38617/47780 [02:14<00:31, 294.78 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39587/47780 [02:14<00:35, 229.64 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40812/47780 [02:14<00:21, 326.62 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37717/47780 [02:14<00:33, 296.45 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40191/47780 [02:14<00:25, 298.38 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34773/47780 [02:14<00:36, 360.99 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37672/47780 [02:14<00:33, 305.25 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39244/47780 [02:14<00:39, 215.93 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38652/47780 [02:14<00:29, 306.95 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37753/47780 [02:14<00:32, 307.10 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39611/47780 [02:14<00:37, 218.03 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34811/47780 [02:14<00:35, 362.98 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40223/47780 [02:14<00:25, 293.21 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39267/47780 [02:14<00:39, 217.55 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37705/47780 [02:14<00:33, 298.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40845/47780 [02:14<00:23, 293.85 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38683/47780 [02:14<00:30, 294.42 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37785/47780 [02:14<00:32, 303.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34856/47780 [02:14<00:33, 383.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37737/47780 [02:14<00:33, 301.32 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40877/47780 [02:14<00:23, 294.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40253/47780 [02:14<00:26, 280.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39291/47780 [02:14<00:40, 211.75 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39634/47780 [02:14<00:44, 183.34 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38717/47780 [02:14<00:29, 307.15 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37830/47780 [02:14<00:28, 344.34 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34896/47780 [02:15<00:33, 383.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40283/47780 [02:14<00:26, 283.65 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40907/47780 [02:14<00:24, 284.66 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37768/47780 [02:14<00:34, 287.19 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39313/47780 [02:15<00:40, 207.03 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39677/47780 [02:15<00:33, 241.10 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38748/47780 [02:14<00:30, 300.73 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37865/47780 [02:15<00:29, 336.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34935/47780 [02:15<00:34, 376.63 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40312/47780 [02:15<00:26, 277.73 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37801/47780 [02:15<00:33, 298.82 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39342/47780 [02:15<00:37, 225.90 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40939/47780 [02:15<00:23, 286.91 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39703/47780 [02:15<00:33, 241.03 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38779/47780 [02:15<00:30, 293.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34975/47780 [02:15<00:34, 370.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37899/47780 [02:15<00:31, 318.15 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40343/47780 [02:15<00:26, 281.93 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40973/47780 [02:15<00:22, 301.52 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39370/47780 [02:15<00:35, 235.03 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37832/47780 [02:15<00:35, 282.73 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39731/47780 [02:15<00:32, 251.29 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38814/47780 [02:15<00:29, 306.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35014/47780 [02:15<00:34, 372.30 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41004/47780 [02:15<00:22, 300.66 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39396/47780 [02:15<00:34, 241.93 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37932/47780 [02:15<00:33, 298.17 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40372/47780 [02:15<00:28, 263.19 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37861/47780 [02:15<00:35, 276.05 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39768/47780 [02:15<00:28, 280.79 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38853/47780 [02:15<00:27, 326.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35059/47780 [02:15<00:32, 394.52 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39422/47780 [02:15<00:34, 244.31 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37968/47780 [02:15<00:31, 311.49 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41036/47780 [02:15<00:23, 292.80 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37891/47780 [02:15<00:36, 273.47 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40399/47780 [02:15<00:29, 251.76 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39799/47780 [02:15<00:28, 279.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38886/47780 [02:15<00:27, 327.01 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35099/47780 [02:15<00:33, 374.39 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39449/47780 [02:15<00:33, 250.13 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38001/47780 [02:15<00:31, 312.80 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41069/47780 [02:15<00:22, 299.86 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37919/47780 [02:15<00:36, 269.45 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40425/47780 [02:15<00:29, 250.87 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39831/47780 [02:15<00:27, 287.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38919/47780 [02:15<00:27, 320.84 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35143/47780 [02:15<00:32, 388.52 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38041/47780 [02:15<00:29, 333.90 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39476/47780 [02:15<00:33, 248.78 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41100/47780 [02:15<00:23, 286.52 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40451/47780 [02:15<00:29, 247.97 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38959/47780 [02:15<00:25, 340.10 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39861/47780 [02:15<00:30, 261.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37947/47780 [02:15<00:40, 240.32 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35184/47780 [02:15<00:32, 390.20 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38078/47780 [02:15<00:28, 344.01 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39509/47780 [02:15<00:30, 269.09 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41131/47780 [02:15<00:22, 292.95 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40482/47780 [02:15<00:27, 261.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37982/47780 [02:15<00:36, 266.02 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39889/47780 [02:15<00:31, 253.03 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38994/47780 [02:15<00:28, 306.90 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35224/47780 [02:15<00:33, 379.93 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41163/47780 [02:15<00:22, 300.33 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38113/47780 [02:15<00:30, 320.02 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39536/47780 [02:15<00:33, 245.42 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40511/47780 [02:15<00:27, 267.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38022/47780 [02:15<00:32, 298.78 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39032/47780 [02:15<00:26, 326.52 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39919/47780 [02:15<00:30, 259.85 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35263/47780 [02:16<00:32, 379.36 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41194/47780 [02:15<00:22, 293.27 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38146/47780 [02:15<00:30, 314.96 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40540/47780 [02:15<00:26, 273.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39568/47780 [02:15<00:31, 264.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38053/47780 [02:15<00:32, 294.87 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39066/47780 [02:15<00:27, 316.47 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39947/47780 [02:16<00:30, 254.37 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35302/47780 [02:16<00:34, 364.83 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40571/47780 [02:16<00:25, 277.87 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41224/47780 [02:16<00:23, 282.14 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39595/47780 [02:16<00:33, 244.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38179/47780 [02:16<00:33, 290.67 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38089/47780 [02:16<00:32, 300.10 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39974/47780 [02:16<00:30, 253.25 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39099/47780 [02:16<00:28, 306.57 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35339/47780 [02:16<00:36, 344.40 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41257/47780 [02:16<00:22, 289.19 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40599/47780 [02:16<00:27, 265.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39621/47780 [02:16<00:34, 238.17 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38209/47780 [02:16<00:34, 275.73 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38126/47780 [02:16<00:31, 309.13 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35378/47780 [02:16<00:34, 354.97 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39132/47780 [02:16<00:29, 293.68 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41291/47780 [02:16<00:21, 300.29 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40626/47780 [02:16<00:27, 261.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39647/47780 [02:16<00:34, 237.83 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40000/47780 [02:16<00:37, 207.33 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38238/47780 [02:16<00:35, 271.00 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38158/47780 [02:16<00:32, 298.84 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39170/47780 [02:16<00:27, 313.58 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41327/47780 [02:16<00:20, 313.55 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35414/47780 [02:16<00:36, 337.39 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40656/47780 [02:16<00:26, 267.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39674/47780 [02:16<00:33, 245.02 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40047/47780 [02:16<00:28, 270.74 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38266/47780 [02:16<00:35, 267.63 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38191/47780 [02:16<00:31, 306.88 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39207/47780 [02:16<00:26, 328.89 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35450/47780 [02:16<00:36, 336.80 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41359/47780 [02:16<00:21, 298.05 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40683/47780 [02:16<00:27, 255.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39701/47780 [02:16<00:32, 251.94 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40078/47780 [02:16<00:28, 269.65 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38293/47780 [02:16<00:36, 262.55 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38224/47780 [02:16<00:30, 310.83 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39241/47780 [02:16<00:27, 313.92 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35501/47780 [02:16<00:32, 380.69 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41398/47780 [02:16<00:19, 320.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40712/47780 [02:16<00:26, 262.41 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39729/47780 [02:16<00:31, 254.04 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40110/47780 [02:16<00:27, 282.57 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38320/47780 [02:16<00:36, 255.92 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38256/47780 [02:16<00:30, 309.16 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39273/47780 [02:16<00:26, 315.45 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41439/47780 [02:16<00:18, 341.92 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40742/47780 [02:16<00:26, 269.16 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39755/47780 [02:16<00:31, 253.13 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40141/47780 [02:16<00:26, 287.20 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38349/47780 [02:16<00:35, 262.68 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38293/47780 [02:16<00:30, 316.15 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39305/47780 [02:16<00:26, 313.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35540/47780 [02:16<00:41, 296.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39781/47780 [02:16<00:31, 254.91 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40783/47780 [02:16<00:23, 298.83 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40171/47780 [02:16<00:26, 290.34 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41476/47780 [02:16<00:19, 317.23 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38377/47780 [02:16<00:36, 258.63 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38330/47780 [02:16<00:28, 327.85 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39340/47780 [02:16<00:26, 324.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39807/47780 [02:16<00:31, 256.32 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41514/47780 [02:16<00:18, 330.68 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40813/47780 [02:16<00:24, 281.91 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40203/47780 [02:16<00:26, 285.87 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38403/47780 [02:16<00:37, 248.15 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35573/47780 [02:17<00:48, 249.85 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38364/47780 [02:16<00:30, 312.06 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39373/47780 [02:16<00:26, 316.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39834/47780 [02:17<00:30, 257.33 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40846/47780 [02:17<00:24, 284.99 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40238/47780 [02:17<00:26, 287.90 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41549/47780 [02:17<00:20, 308.33 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38430/47780 [02:17<00:37, 251.37 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35735/47780 [02:17<00:21, 548.11 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38396/47780 [02:17<00:31, 298.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39405/47780 [02:17<00:27, 301.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39860/47780 [02:17<00:31, 255.20 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40883/47780 [02:17<00:22, 304.99 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40272/47780 [02:17<00:25, 298.98 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41583/47780 [02:17<00:19, 313.73 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38461/47780 [02:17<00:35, 259.22 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38429/47780 [02:17<00:30, 304.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39441/47780 [02:17<00:26, 315.01 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39886/47780 [02:17<00:31, 247.87 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35805/47780 [02:17<00:23, 516.20 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40918/47780 [02:17<00:21, 314.12 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40303/47780 [02:17<00:25, 298.74 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41615/47780 [02:17<00:19, 308.86 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38488/47780 [02:17<00:36, 256.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39474/47780 [02:17<00:27, 305.38 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39912/47780 [02:17<00:31, 248.53 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38460/47780 [02:17<00:35, 264.11 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40950/47780 [02:17<00:21, 315.25 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35867/47780 [02:17<00:24, 485.36 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41647/47780 [02:17<00:20, 302.03 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38514/47780 [02:17<00:36, 254.35 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39508/47780 [02:17<00:26, 311.59 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40334/47780 [02:17<00:29, 255.23 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39939/47780 [02:17<00:31, 248.94 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38489/47780 [02:17<00:34, 268.30 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40984/47780 [02:17<00:22, 302.25 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41681/47780 [02:17<00:19, 312.33 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35923/47780 [02:17<00:24, 476.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38540/47780 [02:17<00:36, 252.96 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39540/47780 [02:17<00:26, 306.67 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39964/47780 [02:17<00:31, 247.75 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40370/47780 [02:17<00:27, 271.23 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38517/47780 [02:17<00:36, 255.13 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41019/47780 [02:17<00:21, 315.38 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41722/47780 [02:17<00:18, 336.34 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38566/47780 [02:17<00:38, 238.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35976/47780 [02:17<00:25, 457.98 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39572/47780 [02:17<00:26, 304.03 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39989/47780 [02:17<00:31, 243.75 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40400/47780 [02:17<00:28, 259.65 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41053/47780 [02:17<00:21, 318.65 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38544/47780 [02:17<00:36, 251.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41756/47780 [02:17<00:19, 314.98 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38593/47780 [02:17<00:39, 234.43 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39603/47780 [02:17<00:27, 298.77 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40015/47780 [02:17<00:31, 246.16 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36025/47780 [02:17<00:27, 429.53 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38572/47780 [02:17<00:35, 258.82 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40427/47780 [02:17<00:29, 249.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41086/47780 [02:17<00:22, 298.04 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41788/47780 [02:17<00:20, 291.14 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38617/47780 [02:17<00:39, 231.92 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39637/47780 [02:17<00:26, 307.04 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36076/47780 [02:17<00:26, 448.49 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40040/47780 [02:17<00:32, 236.25 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40464/47780 [02:17<00:26, 277.94 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41117/47780 [02:17<00:22, 294.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38599/47780 [02:17<00:40, 228.99 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41826/47780 [02:17<00:19, 311.64 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38649/47780 [02:17<00:36, 252.50 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39668/47780 [02:17<00:26, 304.03 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40069/47780 [02:18<00:31, 243.18 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36123/47780 [02:18<00:28, 415.70 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40494/47780 [02:18<00:26, 275.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41148/47780 [02:18<00:22, 297.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38625/47780 [02:18<00:39, 234.59 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41860/47780 [02:18<00:18, 315.81 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38676/47780 [02:18<00:36, 249.02 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40100/47780 [02:18<00:29, 261.92 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39699/47780 [02:18<00:29, 274.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40522/47780 [02:18<00:27, 262.03 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41178/47780 [02:18<00:24, 271.84 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38711/47780 [02:18<00:33, 274.23 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38650/47780 [02:18<00:42, 215.69 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40128/47780 [02:18<00:29, 258.02 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36167/47780 [02:18<00:34, 337.69 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41892/47780 [02:18<00:20, 282.57 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39737/47780 [02:18<00:26, 299.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40549/47780 [02:18<00:27, 258.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41208/47780 [02:18<00:23, 279.29 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38739/47780 [02:18<00:33, 268.79 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38685/47780 [02:18<00:36, 247.55 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40157/47780 [02:18<00:28, 264.48 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41928/47780 [02:18<00:19, 302.68 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39772/47780 [02:18<00:25, 310.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40580/47780 [02:18<00:27, 265.51 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41241/47780 [02:18<00:23, 281.13 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38767/47780 [02:18<00:34, 261.12 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36204/47780 [02:18<00:40, 283.49 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41964/47780 [02:18<00:18, 311.60 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39816/47780 [02:18<00:23, 345.34 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38711/47780 [02:18<00:38, 238.19 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40185/47780 [02:18<00:29, 257.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40611/47780 [02:18<00:26, 270.26 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41276/47780 [02:18<00:21, 299.99 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36322/47780 [02:18<00:24, 467.43 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38794/47780 [02:18<00:34, 257.80 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42000/47780 [02:18<00:18, 314.64 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38736/47780 [02:18<00:38, 236.23 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40212/47780 [02:18<00:29, 254.66 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39852/47780 [02:18<00:24, 321.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40649/47780 [02:18<00:23, 300.32 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41307/47780 [02:18<00:22, 283.32 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38820/47780 [02:18<00:36, 244.73 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38765/47780 [02:18<00:35, 250.60 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36379/47780 [02:18<00:24, 459.90 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39888/47780 [02:18<00:24, 324.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40239/47780 [02:18<00:31, 237.85 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40680/47780 [02:18<00:24, 286.38 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42032/47780 [02:18<00:21, 266.15 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41341/47780 [02:18<00:22, 289.58 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38847/47780 [02:18<00:35, 251.51 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38793/47780 [02:18<00:35, 253.40 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39922/47780 [02:18<00:24, 321.93 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36432/47780 [02:18<00:25, 443.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40264/47780 [02:18<00:31, 238.54 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40719/47780 [02:18<00:22, 308.96 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42061/47780 [02:18<00:22, 251.69 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41378/47780 [02:18<00:21, 298.58 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38873/47780 [02:18<00:35, 248.16 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38819/47780 [02:18<00:35, 249.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40293/47780 [02:18<00:30, 247.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39955/47780 [02:18<00:25, 303.45 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36482/47780 [02:18<00:26, 428.39 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40751/47780 [02:18<00:24, 283.48 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42126/47780 [02:18<00:16, 344.03 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41417/47780 [02:18<00:19, 320.19 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38903/47780 [02:18<00:34, 260.21 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38848/47780 [02:18<00:34, 260.94 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40319/47780 [02:19<00:30, 245.35 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39986/47780 [02:18<00:26, 289.87 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36529/47780 [02:19<00:26, 422.32 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41456/47780 [02:19<00:18, 339.58 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38930/47780 [02:19<00:33, 262.43 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40780/47780 [02:19<00:26, 260.52 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42163/47780 [02:19<00:17, 319.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38875/47780 [02:19<00:37, 236.44 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40345/47780 [02:19<00:31, 236.19 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40021/47780 [02:19<00:25, 302.73 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41492/47780 [02:19<00:18, 341.48 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38957/47780 [02:19<00:34, 259.15 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36575/47780 [02:19<00:28, 388.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42209/47780 [02:19<00:15, 349.17 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40807/47780 [02:19<00:28, 241.67 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40372/47780 [02:19<00:30, 243.00 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40058/47780 [02:19<00:24, 320.91 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38900/47780 [02:19<00:41, 212.76 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41528/47780 [02:19<00:18, 345.73 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38991/47780 [02:19<00:31, 282.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36617/47780 [02:19<00:29, 381.42 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42246/47780 [02:19<00:16, 330.60 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40832/47780 [02:19<00:30, 230.80 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40397/47780 [02:19<00:32, 229.40 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40091/47780 [02:19<00:25, 303.36 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38939/47780 [02:19<00:35, 252.48 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41563/47780 [02:19<00:18, 328.61 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39020/47780 [02:19<00:34, 256.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36659/47780 [02:19<00:30, 369.34 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40128/47780 [02:19<00:24, 318.10 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42283/47780 [02:19<00:17, 314.12 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40421/47780 [02:19<00:32, 224.99 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38968/47780 [02:19<00:33, 259.66 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40856/47780 [02:19<00:32, 209.87 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39057/47780 [02:19<00:30, 282.37 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41597/47780 [02:19<00:20, 304.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36697/47780 [02:19<00:30, 368.23 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38995/47780 [02:19<00:33, 262.44 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40161/47780 [02:19<00:24, 313.93 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42350/47780 [02:19<00:13, 389.34 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40444/47780 [02:19<00:35, 204.35 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40896/47780 [02:19<00:27, 246.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41631/47780 [02:19<00:19, 310.85 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39090/47780 [02:19<00:30, 286.30 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36735/47780 [02:19<00:31, 356.10 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42406/47780 [02:19<00:12, 433.04 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39022/47780 [02:19<00:34, 253.12 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40193/47780 [02:19<00:25, 302.03 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40467/47780 [02:19<00:35, 203.97 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40922/47780 [02:19<00:28, 240.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41670/47780 [02:19<00:18, 329.13 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39130/47780 [02:19<00:27, 310.72 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36776/47780 [02:19<00:30, 359.36 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39048/47780 [02:19<00:34, 254.91 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40230/47780 [02:19<00:23, 318.59 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42451/47780 [02:19<00:13, 407.30 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40489/47780 [02:19<00:35, 204.20 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41705/47780 [02:19<00:18, 323.68 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40953/47780 [02:19<00:27, 248.09 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39176/47780 [02:19<00:24, 348.65 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36826/47780 [02:19<00:27, 397.01 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40270/47780 [02:19<00:22, 337.00 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39074/47780 [02:19<00:35, 248.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40515/47780 [02:19<00:33, 216.97 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40980/47780 [02:19<00:27, 246.18 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41738/47780 [02:19<00:19, 308.61 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36868/47780 [02:20<00:27, 390.38 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42493/47780 [02:19<00:15, 351.46 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39212/47780 [02:19<00:26, 319.37 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40309/47780 [02:19<00:21, 349.45 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39101/47780 [02:19<00:35, 243.34 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40541/47780 [02:20<00:31, 226.35 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41007/47780 [02:20<00:27, 249.82 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36918/47780 [02:20<00:25, 420.56 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41780/47780 [02:20<00:18, 331.71 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42531/47780 [02:20<00:14, 356.80 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40345/47780 [02:20<00:22, 336.23 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39245/47780 [02:20<00:29, 293.53 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39126/47780 [02:20<00:36, 239.58 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40564/47780 [02:20<00:32, 219.93 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41038/47780 [02:20<00:25, 260.58 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36961/47780 [02:20<00:25, 417.31 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41814/47780 [02:20<00:18, 320.00 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42571/47780 [02:20<00:15, 337.39 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40384/47780 [02:20<00:21, 339.49 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39158/47780 [02:20<00:34, 251.63 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39277/47780 [02:20<00:30, 280.12 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40587/47780 [02:20<00:33, 213.28 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41070/47780 [02:20<00:24, 274.05 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37004/47780 [02:20<00:26, 399.55 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41847/47780 [02:20<00:18, 322.32 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42607/47780 [02:20<00:15, 340.38 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40431/47780 [02:20<00:19, 371.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39184/47780 [02:20<00:34, 250.67 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40609/47780 [02:20<00:33, 212.83 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39306/47780 [02:20<00:32, 263.79 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41880/47780 [02:20<00:18, 320.79 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41098/47780 [02:20<00:26, 255.41 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37046/47780 [02:20<00:27, 385.57 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40470/47780 [02:20<00:19, 368.69 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39212/47780 [02:20<00:33, 253.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42642/47780 [02:20<00:16, 307.33 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39334/47780 [02:20<00:31, 267.76 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40631/47780 [02:20<00:34, 205.58 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41125/47780 [02:20<00:25, 256.50 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41915/47780 [02:20<00:18, 321.71 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37088/47780 [02:20<00:27, 388.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40508/47780 [02:20<00:19, 371.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39239/47780 [02:20<00:33, 255.12 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42675/47780 [02:20<00:17, 297.72 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39363/47780 [02:20<00:33, 254.95 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40652/47780 [02:20<00:36, 197.99 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41156/47780 [02:20<00:24, 268.70 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41949/47780 [02:20<00:18, 319.95 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37128/47780 [02:20<00:28, 367.43 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39270/47780 [02:20<00:32, 264.67 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40547/47780 [02:20<00:20, 345.27 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42706/47780 [02:20<00:17, 289.20 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39389/47780 [02:20<00:32, 256.00 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40672/47780 [02:20<00:36, 196.26 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41982/47780 [02:20<00:18, 305.69 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41184/47780 [02:20<00:26, 251.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37167/47780 [02:20<00:30, 349.79 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39302/47780 [02:20<00:30, 274.28 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40582/47780 [02:20<00:21, 332.07 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42739/47780 [02:20<00:16, 296.85 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40699/47780 [02:20<00:33, 209.93 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39415/47780 [02:20<00:34, 239.03 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41210/47780 [02:20<00:26, 250.97 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42013/47780 [02:20<00:20, 284.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37205/47780 [02:20<00:29, 354.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39333/47780 [02:20<00:29, 284.34 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40627/47780 [02:20<00:19, 360.34 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42770/47780 [02:20<00:17, 284.70 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40723/47780 [02:20<00:33, 211.26 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39442/47780 [02:20<00:34, 244.80 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41238/47780 [02:20<00:26, 251.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42046/47780 [02:20<00:19, 293.83 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37241/47780 [02:21<00:31, 337.66 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39362/47780 [02:20<00:30, 276.01 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40664/47780 [02:20<00:20, 347.60 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42801/47780 [02:21<00:17, 282.69 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40750/47780 [02:21<00:31, 225.64 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39467/47780 [02:21<00:35, 231.05 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41264/47780 [02:21<00:26, 247.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42085/47780 [02:21<00:17, 316.84 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39394/47780 [02:21<00:29, 287.13 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37286/47780 [02:21<00:29, 360.46 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42834/47780 [02:21<00:16, 292.36 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40775/47780 [02:21<00:30, 232.00 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40700/47780 [02:21<00:21, 325.82 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42118/47780 [02:21<00:17, 317.57 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41293/47780 [02:21<00:25, 254.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39491/47780 [02:21<00:37, 221.51 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37327/47780 [02:21<00:27, 373.77 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39423/47780 [02:21<00:31, 265.31 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42865/47780 [02:21<00:16, 293.93 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42153/47780 [02:21<00:17, 318.91 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40734/47780 [02:21<00:23, 300.68 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41319/47780 [02:21<00:26, 247.48 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39517/47780 [02:21<00:36, 229.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40799/47780 [02:21<00:33, 205.90 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37365/47780 [02:21<00:28, 359.63 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42896/47780 [02:21<00:16, 294.92 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40766/47780 [02:21<00:23, 299.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42186/47780 [02:21<00:17, 314.69 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40824/47780 [02:21<00:32, 215.35 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41345/47780 [02:21<00:26, 245.52 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39450/47780 [02:21<00:38, 216.82 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39541/47780 [02:21<00:37, 220.33 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37402/47780 [02:21<00:28, 358.54 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42926/47780 [02:21<00:17, 283.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40799/47780 [02:21<00:22, 304.31 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39566/47780 [02:21<00:35, 228.27 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40847/47780 [02:21<00:32, 210.16 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39487/47780 [02:21<00:33, 251.10 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41370/47780 [02:21<00:27, 233.40 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37440/47780 [02:21<00:29, 353.33 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42218/47780 [02:21<00:19, 281.25 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42956/47780 [02:21<00:18, 264.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40833/47780 [02:21<00:22, 310.71 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40875/47780 [02:21<00:30, 226.60 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41400/47780 [02:21<00:25, 246.52 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39590/47780 [02:21<00:36, 221.48 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39516/47780 [02:21<00:33, 248.32 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42248/47780 [02:21<00:19, 283.25 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37476/47780 [02:21<00:31, 328.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42983/47780 [02:21<00:18, 263.34 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40901/47780 [02:21<00:29, 233.31 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40865/47780 [02:21<00:23, 293.53 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39615/47780 [02:21<00:36, 224.57 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41427/47780 [02:21<00:25, 244.88 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39543/47780 [02:21<00:32, 249.90 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42277/47780 [02:21<00:19, 278.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37523/47780 [02:21<00:27, 366.96 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43012/47780 [02:21<00:17, 264.90 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40929/47780 [02:21<00:28, 243.76 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40900/47780 [02:21<00:22, 305.73 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41458/47780 [02:21<00:24, 262.59 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39639/47780 [02:21<00:35, 226.39 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39569/47780 [02:21<00:32, 251.45 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42306/47780 [02:21<00:19, 281.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37561/47780 [02:21<00:27, 367.83 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40963/47780 [02:21<00:25, 268.08 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40933/47780 [02:21<00:21, 312.43 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39598/47780 [02:21<00:31, 262.00 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41486/47780 [02:21<00:24, 262.04 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43039/47780 [02:21<00:19, 241.80 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42343/47780 [02:21<00:17, 303.80 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37600/47780 [02:22<00:27, 372.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39662/47780 [02:21<00:39, 206.39 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40966/47780 [02:21<00:21, 313.36 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40994/47780 [02:22<00:25, 267.85 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41513/47780 [02:22<00:23, 261.37 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42380/47780 [02:22<00:16, 319.01 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43072/47780 [02:22<00:18, 259.89 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39628/47780 [02:22<00:31, 260.88 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37645/47780 [02:22<00:25, 390.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39689/47780 [02:22<00:36, 223.33 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41021/47780 [02:22<00:25, 264.18 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41000/47780 [02:22<00:22, 301.13 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41541/47780 [02:22<00:24, 255.06 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39656/47780 [02:22<00:30, 263.28 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43100/47780 [02:22<00:17, 262.28 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42414/47780 [02:22<00:17, 310.72 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37695/47780 [02:22<00:23, 421.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39712/47780 [02:22<00:37, 215.78 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41033/47780 [02:22<00:21, 308.84 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41051/47780 [02:22<00:25, 266.67 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39683/47780 [02:22<00:30, 262.28 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41572/47780 [02:22<00:23, 267.49 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43127/47780 [02:22<00:17, 258.54 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42455/47780 [02:22<00:16, 331.19 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37738/47780 [02:22<00:25, 390.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39742/47780 [02:22<00:34, 231.47 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43158/47780 [02:22<00:17, 270.36 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41083/47780 [02:22<00:24, 269.40 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39711/47780 [02:22<00:31, 255.53 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41065/47780 [02:22<00:23, 282.76 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41599/47780 [02:22<00:25, 245.85 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39770/47780 [02:22<00:32, 244.63 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37778/47780 [02:22<00:25, 390.67 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42491/47780 [02:22<00:16, 317.95 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43188/47780 [02:22<00:16, 275.62 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41112/47780 [02:22<00:24, 272.10 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39737/47780 [02:22<00:31, 251.53 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41098/47780 [02:22<00:22, 292.64 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39796/47780 [02:22<00:32, 248.95 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41631/47780 [02:22<00:23, 260.17 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37834/47780 [02:22<00:23, 428.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42526/47780 [02:22<00:17, 306.47 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43223/47780 [02:22<00:15, 293.52 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41140/47780 [02:22<00:25, 259.74 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39764/47780 [02:22<00:32, 248.06 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41128/47780 [02:22<00:23, 287.49 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39823/47780 [02:22<00:31, 252.05 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37878/47780 [02:22<00:23, 417.86 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42557/47780 [02:22<00:16, 307.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41658/47780 [02:22<00:24, 246.79 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43257/47780 [02:22<00:14, 302.18 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41167/47780 [02:22<00:25, 259.71 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39790/47780 [02:22<00:32, 248.67 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39849/47780 [02:22<00:31, 251.52 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41158/47780 [02:22<00:23, 285.16 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37921/47780 [02:22<00:23, 413.20 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41691/47780 [02:22<00:22, 269.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42589/47780 [02:22<00:17, 304.12 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41194/47780 [02:22<00:25, 258.95 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39826/47780 [02:22<00:28, 277.06 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43288/47780 [02:22<00:15, 282.65 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41187/47780 [02:22<00:23, 280.57 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37972/47780 [02:22<00:22, 439.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39875/47780 [02:22<00:33, 236.94 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41719/47780 [02:22<00:22, 263.84 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42620/47780 [02:22<00:17, 292.72 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41221/47780 [02:22<00:25, 259.90 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39857/47780 [02:22<00:27, 286.31 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43318/47780 [02:22<00:15, 281.30 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41221/47780 [02:22<00:22, 290.87 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38034/47780 [02:22<00:19, 490.82 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42658/47780 [02:22<00:16, 310.02 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41747/47780 [02:22<00:23, 255.73 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39900/47780 [02:22<00:35, 219.63 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41257/47780 [02:23<00:22, 285.34 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39887/47780 [02:22<00:28, 280.72 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43347/47780 [02:23<00:16, 274.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41253/47780 [02:22<00:22, 288.93 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42706/47780 [02:23<00:14, 353.65 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41773/47780 [02:23<00:24, 248.94 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39928/47780 [02:23<00:34, 230.21 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38084/47780 [02:23<00:23, 404.49 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41287/47780 [02:23<00:22, 282.98 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39916/47780 [02:23<00:28, 275.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43376/47780 [02:23<00:16, 272.82 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41282/47780 [02:23<00:23, 276.96 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42747/47780 [02:23<00:13, 366.29 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41800/47780 [02:23<00:23, 252.45 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39952/47780 [02:23<00:33, 232.77 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38128/47780 [02:23<00:23, 410.28 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41319/47780 [02:23<00:22, 287.13 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39957/47780 [02:23<00:25, 308.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43409/47780 [02:23<00:15, 286.69 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41310/47780 [02:23<00:24, 265.89 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42785/47780 [02:23<00:13, 359.05 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41834/47780 [02:23<00:21, 270.96 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39976/47780 [02:23<00:34, 227.11 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38194/47780 [02:23<00:20, 475.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41353/47780 [02:23<00:21, 302.06 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43439/47780 [02:23<00:15, 273.89 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39988/47780 [02:23<00:27, 285.72 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41339/47780 [02:23<00:23, 272.44 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41867/47780 [02:23<00:21, 281.25 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40001/47780 [02:23<00:33, 231.17 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42823/47780 [02:23<00:14, 339.84 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38244/47780 [02:23<00:19, 480.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41389/47780 [02:23<00:20, 315.44 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43476/47780 [02:23<00:14, 297.17 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41371/47780 [02:23<00:22, 284.90 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40018/47780 [02:23<00:28, 274.89 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41898/47780 [02:23<00:20, 285.69 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40026/47780 [02:23<00:33, 233.79 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42858/47780 [02:23<00:15, 324.46 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38294/47780 [02:23<00:20, 464.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41421/47780 [02:23<00:20, 316.53 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43509/47780 [02:23<00:13, 305.22 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40046/47780 [02:23<00:28, 272.89 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41401/47780 [02:23<00:23, 271.90 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40052/47780 [02:23<00:32, 235.86 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41927/47780 [02:23<00:22, 260.59 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42896/47780 [02:23<00:14, 329.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38342/47780 [02:23<00:20, 450.63 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43541/47780 [02:23<00:13, 307.10 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41453/47780 [02:23<00:22, 281.13 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41429/47780 [02:23<00:23, 273.49 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40074/47780 [02:23<00:28, 266.17 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42938/47780 [02:23<00:13, 350.02 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41954/47780 [02:23<00:22, 257.20 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38389/47780 [02:23<00:20, 455.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40076/47780 [02:23<00:36, 212.71 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41486/47780 [02:23<00:21, 291.39 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43572/47780 [02:23<00:14, 291.20 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40105/47780 [02:23<00:28, 270.28 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41457/47780 [02:23<00:23, 265.17 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41992/47780 [02:23<00:20, 287.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38450/47780 [02:23<00:18, 493.74 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40098/47780 [02:23<00:39, 195.67 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43602/47780 [02:23<00:14, 293.62 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41516/47780 [02:23<00:22, 281.31 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42974/47780 [02:23<00:16, 296.81 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40133/47780 [02:23<00:28, 266.46 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41485/47780 [02:23<00:24, 256.53 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42023/47780 [02:23<00:19, 292.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38501/47780 [02:24<00:19, 476.23 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40135/47780 [02:23<00:31, 240.69 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43639/47780 [02:23<00:13, 315.31 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41545/47780 [02:24<00:22, 274.58 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43016/47780 [02:23<00:14, 324.20 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41513/47780 [02:23<00:24, 259.95 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42053/47780 [02:24<00:19, 292.92 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40161/47780 [02:24<00:31, 240.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38550/47780 [02:24<00:19, 465.00 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43672/47780 [02:24<00:13, 315.99 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40161/47780 [02:24<00:33, 228.89 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41574/47780 [02:24<00:22, 275.93 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43050/47780 [02:24<00:14, 327.95 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41548/47780 [02:24<00:21, 284.97 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42083/47780 [02:24<00:19, 285.06 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40189/47780 [02:24<00:30, 249.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38604/47780 [02:24<00:19, 480.60 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40190/47780 [02:24<00:30, 245.00 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43705/47780 [02:24<00:13, 302.69 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41602/47780 [02:24<00:22, 271.95 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41578/47780 [02:24<00:21, 288.95 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43084/47780 [02:24<00:15, 301.81 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42112/47780 [02:24<00:20, 277.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38656/47780 [02:24<00:18, 487.48 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40215/47780 [02:24<00:31, 238.53 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40216/47780 [02:24<00:30, 248.85 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43736/47780 [02:24<00:13, 300.94 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41633/47780 [02:24<00:22, 269.43 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41613/47780 [02:24<00:21, 290.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43119/47780 [02:24<00:15, 308.29 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42140/47780 [02:24<00:21, 261.28 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38705/47780 [02:24<00:19, 470.47 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40240/47780 [02:24<00:31, 238.87 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40242/47780 [02:24<00:30, 249.53 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43769/47780 [02:24<00:12, 309.13 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41662/47780 [02:24<00:22, 274.86 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41649/47780 [02:24<00:19, 306.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43157/47780 [02:24<00:14, 320.57 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42169/47780 [02:24<00:20, 268.11 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40270/47780 [02:24<00:29, 253.09 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40269/47780 [02:24<00:29, 252.46 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38753/47780 [02:24<00:20, 443.41 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43804/47780 [02:24<00:12, 320.30 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41691/47780 [02:24<00:23, 254.42 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41680/47780 [02:24<00:20, 291.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43191/47780 [02:24<00:15, 302.80 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40299/47780 [02:24<00:28, 263.28 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42197/47780 [02:24<00:21, 256.50 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40302/47780 [02:24<00:27, 271.48 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38798/47780 [02:24<00:20, 431.04 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43845/47780 [02:24<00:11, 335.73 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41713/47780 [02:24<00:20, 295.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41717/47780 [02:24<00:24, 247.03 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43222/47780 [02:24<00:15, 292.27 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40329/47780 [02:24<00:28, 260.23 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42254/47780 [02:24<00:16, 328.86 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40333/47780 [02:24<00:27, 273.18 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38842/47780 [02:24<00:21, 424.21 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43880/47780 [02:24<00:11, 331.88 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41746/47780 [02:24<00:19, 304.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41749/47780 [02:24<00:22, 264.05 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43252/47780 [02:24<00:16, 279.25 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40361/47780 [02:24<00:27, 272.02 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40356/47780 [02:24<00:30, 242.89 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42287/47780 [02:24<00:17, 315.17 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38885/47780 [02:24<00:21, 412.00 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43917/47780 [02:24<00:11, 328.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41777/47780 [02:24<00:20, 299.19 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43282/47780 [02:24<00:15, 281.52 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40392/47780 [02:24<00:26, 282.79 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40387/47780 [02:24<00:28, 258.05 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38930/47780 [02:25<00:20, 422.15 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41776/47780 [02:24<00:26, 223.63 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43952/47780 [02:24<00:11, 330.52 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42319/47780 [02:24<00:18, 294.31 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41809/47780 [02:24<00:19, 302.04 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40421/47780 [02:25<00:27, 272.15 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38973/47780 [02:25<00:21, 414.15 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40414/47780 [02:25<00:29, 253.00 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43311/47780 [02:25<00:17, 256.06 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41840/47780 [02:25<00:19, 300.88 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42349/47780 [02:25<00:19, 278.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41800/47780 [02:25<00:29, 205.15 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43991/47780 [02:25<00:12, 299.91 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40457/47780 [02:25<00:25, 287.51 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43345/47780 [02:25<00:16, 272.57 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40440/47780 [02:25<00:30, 241.63 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39016/47780 [02:25<00:22, 388.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41872/47780 [02:25<00:18, 327.11 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42377/47780 [02:25<00:20, 264.70 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41871/47780 [02:25<00:20, 286.59 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40486/47780 [02:25<00:25, 284.85 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40474/47780 [02:25<00:27, 268.21 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43374/47780 [02:25<00:16, 274.36 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39057/47780 [02:25<00:22, 390.81 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44022/47780 [02:25<00:15, 245.97 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42417/47780 [02:25<00:18, 297.21 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41908/47780 [02:25<00:18, 319.22 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41900/47780 [02:25<00:23, 254.66 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40515/47780 [02:25<00:25, 282.89 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40503/47780 [02:25<00:27, 265.24 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39097/47780 [02:25<00:22, 383.73 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43407/47780 [02:25<00:15, 274.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44100/47780 [02:25<00:10, 366.62 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42449/47780 [02:25<00:17, 296.86 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41943/47780 [02:25<00:18, 320.53 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41929/47780 [02:25<00:22, 257.50 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40548/47780 [02:25<00:24, 293.44 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40531/47780 [02:25<00:27, 263.78 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43436/47780 [02:25<00:15, 275.63 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39141/47780 [02:25<00:22, 387.47 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42479/47780 [02:25<00:18, 291.05 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41979/47780 [02:25<00:17, 324.14 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44144/47780 [02:25<00:10, 347.05 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41956/47780 [02:25<00:22, 258.09 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40578/47780 [02:25<00:24, 293.42 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43473/47780 [02:25<00:14, 298.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39181/47780 [02:25<00:22, 386.33 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40558/47780 [02:25<00:28, 250.99 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42509/47780 [02:25<00:18, 278.24 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42014/47780 [02:25<00:18, 314.13 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44182/47780 [02:25<00:10, 338.56 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40619/47780 [02:25<00:21, 325.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41983/47780 [02:25<00:22, 257.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43504/47780 [02:25<00:14, 291.34 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40584/47780 [02:25<00:29, 240.68 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39220/47780 [02:25<00:24, 355.54 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42047/47780 [02:25<00:18, 302.27 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42538/47780 [02:25<00:20, 261.60 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40654/47780 [02:25<00:21, 325.18 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42015/47780 [02:25<00:21, 267.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44219/47780 [02:25<00:11, 320.97 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43535/47780 [02:25<00:14, 293.77 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39257/47780 [02:25<00:24, 351.80 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40609/47780 [02:25<00:30, 233.06 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42569/47780 [02:25<00:19, 271.67 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40687/47780 [02:25<00:21, 326.53 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42079/47780 [02:25<00:19, 296.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42052/47780 [02:25<00:19, 292.48 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43565/47780 [02:25<00:15, 279.17 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44255/47780 [02:25<00:11, 295.74 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40643/47780 [02:25<00:27, 259.30 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39293/47780 [02:26<00:24, 342.47 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42598/47780 [02:25<00:19, 271.80 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42110/47780 [02:26<00:19, 288.34 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42082/47780 [02:25<00:20, 281.92 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40722/47780 [02:25<00:22, 311.49 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43594/47780 [02:26<00:14, 279.63 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44288/47780 [02:26<00:12, 286.73 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40679/47780 [02:26<00:25, 274.97 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39329/47780 [02:26<00:25, 335.16 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42626/47780 [02:26<00:18, 273.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42112/47780 [02:26<00:20, 280.67 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42140/47780 [02:26<00:21, 265.55 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40755/47780 [02:26<00:24, 284.27 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43623/47780 [02:26<00:15, 267.17 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40718/47780 [02:26<00:23, 306.41 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44352/47780 [02:26<00:09, 370.24 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39364/47780 [02:26<00:26, 322.84 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42655/47780 [02:26<00:18, 271.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42145/47780 [02:26<00:19, 291.16 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42171/47780 [02:26<00:20, 276.27 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40784/47780 [02:26<00:26, 266.34 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40750/47780 [02:26<00:23, 300.30 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39407/47780 [02:26<00:24, 344.46 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44392/47780 [02:26<00:09, 348.84 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42683/47780 [02:26<00:18, 270.79 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43651/47780 [02:26<00:17, 234.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42175/47780 [02:26<00:19, 293.40 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42201/47780 [02:26<00:20, 274.95 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40782/47780 [02:26<00:23, 292.61 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44429/47780 [02:26<00:09, 344.03 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42711/47780 [02:26<00:19, 261.66 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39442/47780 [02:26<00:25, 324.67 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42205/47780 [02:26<00:19, 292.34 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40812/47780 [02:26<00:29, 235.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43676/47780 [02:26<00:17, 229.35 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42238/47780 [02:26<00:18, 300.67 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40812/47780 [02:26<00:24, 284.84 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44468/47780 [02:26<00:09, 348.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42740/47780 [02:26<00:19, 263.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40846/47780 [02:26<00:27, 256.04 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42235/47780 [02:26<00:20, 275.28 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42282/47780 [02:26<00:16, 332.54 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43701/47780 [02:26<00:18, 214.77 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39476/47780 [02:26<00:30, 272.79 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40841/47780 [02:26<00:25, 274.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42767/47780 [02:26<00:19, 259.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40878/47780 [02:26<00:25, 269.61 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42263/47780 [02:26<00:20, 270.03 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44504/47780 [02:26<00:10, 323.28 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43728/47780 [02:26<00:17, 228.60 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42321/47780 [02:26<00:16, 330.12 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39567/47780 [02:26<00:19, 423.06 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40869/47780 [02:26<00:25, 267.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40912/47780 [02:26<00:23, 288.08 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42296/47780 [02:26<00:19, 286.35 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42794/47780 [02:26<00:20, 240.41 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43766/47780 [02:26<00:15, 260.62 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42356/47780 [02:26<00:16, 320.98 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44538/47780 [02:26<00:11, 294.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40899/47780 [02:26<00:25, 270.19 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42326/47780 [02:26<00:19, 282.41 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39614/47780 [02:26<00:21, 374.53 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42822/47780 [02:26<00:19, 248.77 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43796/47780 [02:26<00:14, 271.09 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40942/47780 [02:26<00:26, 257.71 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44570/47780 [02:26<00:10, 294.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42389/47780 [02:26<00:18, 294.53 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39670/47780 [02:27<00:19, 418.15 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40927/47780 [02:26<00:27, 250.59 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42355/47780 [02:26<00:19, 274.50 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42849/47780 [02:26<00:19, 248.77 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43826/47780 [02:26<00:14, 273.00 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40969/47780 [02:26<00:27, 250.53 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44604/47780 [02:27<00:10, 291.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42419/47780 [02:27<00:18, 288.68 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39720/47780 [02:27<00:18, 434.27 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40958/47780 [02:27<00:25, 266.44 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42877/47780 [02:27<00:19, 254.85 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42390/47780 [02:27<00:18, 289.27 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43854/47780 [02:27<00:14, 271.60 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41005/47780 [02:27<00:24, 273.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44639/47780 [02:27<00:10, 300.67 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42449/47780 [02:27<00:19, 275.28 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40986/47780 [02:27<00:25, 267.46 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42427/47780 [02:27<00:17, 311.97 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39767/47780 [02:27<00:18, 421.75 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43885/47780 [02:27<00:14, 276.61 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42904/47780 [02:27<00:21, 228.42 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44673/47780 [02:27<00:09, 311.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41034/47780 [02:27<00:26, 258.10 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41015/47780 [02:27<00:24, 270.73 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42459/47780 [02:27<00:17, 306.90 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42477/47780 [02:27<00:20, 252.62 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43913/47780 [02:27<00:15, 254.46 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42949/47780 [02:27<00:17, 283.37 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41063/47780 [02:27<00:25, 258.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44705/47780 [02:27<00:10, 297.04 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41045/47780 [02:27<00:24, 275.96 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42491/47780 [02:27<00:17, 307.50 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42508/47780 [02:27<00:19, 264.66 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39814/47780 [02:27<00:24, 319.67 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42983/47780 [02:27<00:16, 292.43 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43940/47780 [02:27<00:15, 245.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44742/47780 [02:27<00:09, 316.80 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41090/47780 [02:27<00:27, 243.40 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41075/47780 [02:27<00:23, 282.80 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42549/47780 [02:27<00:17, 301.56 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42522/47780 [02:27<00:17, 301.11 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43969/47780 [02:27<00:14, 254.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44779/47780 [02:27<00:09, 328.27 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43013/47780 [02:27<00:17, 273.16 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41121/47780 [02:27<00:26, 255.65 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42582/47780 [02:27<00:16, 307.97 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42559/47780 [02:27<00:16, 320.77 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41104/47780 [02:27<00:24, 271.26 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44822/47780 [02:27<00:08, 356.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39851/47780 [02:27<00:31, 255.23 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43048/47780 [02:27<00:16, 290.89 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43997/47780 [02:27<00:15, 241.92 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42614/47780 [02:27<00:16, 307.96 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41147/47780 [02:27<00:27, 243.33 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41138/47780 [02:27<00:23, 285.30 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42593/47780 [02:27<00:16, 308.87 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43079/47780 [02:27<00:16, 289.83 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44859/47780 [02:27<00:08, 334.25 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44022/47780 [02:27<00:15, 241.28 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41174/47780 [02:27<00:26, 248.24 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41172/47780 [02:27<00:21, 300.80 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42646/47780 [02:27<00:17, 297.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39883/47780 [02:27<00:33, 235.03 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44893/47780 [02:27<00:08, 325.06 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42625/47780 [02:27<00:20, 254.57 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44047/47780 [02:27<00:15, 234.56 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41200/47780 [02:27<00:27, 243.30 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43109/47780 [02:27<00:18, 252.99 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41203/47780 [02:27<00:23, 283.76 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42677/47780 [02:27<00:17, 285.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39910/47780 [02:28<00:35, 222.75 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44075/47780 [02:28<00:15, 246.87 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44927/47780 [02:27<00:08, 318.55 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42686/47780 [02:27<00:15, 335.88 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41225/47780 [02:28<00:27, 240.03 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41236/47780 [02:28<00:23, 283.59 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43136/47780 [02:28<00:19, 243.33 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39936/47780 [02:28<00:35, 221.31 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42707/47780 [02:28<00:20, 246.19 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44103/47780 [02:28<00:14, 256.10 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44960/47780 [02:28<00:08, 314.77 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41253/47780 [02:28<00:26, 245.70 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41265/47780 [02:28<00:22, 284.31 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42723/47780 [02:28<00:17, 292.59 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43162/47780 [02:28<00:20, 230.72 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44129/47780 [02:28<00:14, 257.19 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44992/47780 [02:28<00:08, 312.35 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42735/47780 [02:28<00:21, 237.99 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39960/47780 [02:28<00:38, 204.42 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41295/47780 [02:28<00:22, 286.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41278/47780 [02:28<00:27, 233.57 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42793/47780 [02:28<00:13, 383.25 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43186/47780 [02:28<00:20, 228.30 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44155/47780 [02:28<00:14, 252.48 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45026/47780 [02:28<00:08, 313.47 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42773/47780 [02:28<00:18, 273.47 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41305/47780 [02:28<00:26, 241.18 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39982/47780 [02:28<00:39, 196.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41332/47780 [02:28<00:21, 294.15 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43210/47780 [02:28<00:20, 223.98 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42836/47780 [02:28<00:13, 374.86 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44184/47780 [02:28<00:13, 260.24 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45066/47780 [02:28<00:08, 336.17 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42812/47780 [02:28<00:16, 304.01 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40143/47780 [02:28<00:14, 512.81 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41330/47780 [02:28<00:27, 235.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41362/47780 [02:28<00:22, 285.82 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43233/47780 [02:28<00:20, 216.68 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42876/47780 [02:28<00:13, 366.94 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45105/47780 [02:28<00:07, 345.53 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42844/47780 [02:28<00:16, 304.83 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44212/47780 [02:28<00:15, 233.11 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40325/47780 [02:28<00:09, 823.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41354/47780 [02:28<00:27, 234.19 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41392/47780 [02:28<00:23, 266.28 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43255/47780 [02:28<00:21, 215.27 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42876/47780 [02:28<00:16, 305.63 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45140/47780 [02:28<00:07, 337.94 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42915/47780 [02:28<00:13, 354.08 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44246/47780 [02:28<00:13, 259.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41383/47780 [02:28<00:26, 244.59 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40420/47780 [02:28<00:09, 762.20 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41419/47780 [02:28<00:24, 264.38 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43283/47780 [02:28<00:19, 230.43 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45184/47780 [02:28<00:07, 364.16 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42952/47780 [02:28<00:14, 328.44 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44273/47780 [02:28<00:14, 248.76 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41415/47780 [02:28<00:23, 265.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42908/47780 [02:28<00:17, 274.42 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43308/47780 [02:28<00:18, 235.80 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41447/47780 [02:28<00:24, 260.39 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45222/47780 [02:28<00:07, 340.60 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40506/47780 [02:28<00:10, 684.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41446/47780 [02:28<00:22, 275.52 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44309/47780 [02:28<00:12, 270.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42986/47780 [02:28<00:15, 312.37 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42937/47780 [02:28<00:19, 250.33 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41475/47780 [02:28<00:23, 265.76 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43332/47780 [02:28<00:20, 217.42 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45269/47780 [02:28<00:06, 372.86 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41475/47780 [02:28<00:22, 276.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44337/47780 [02:29<00:12, 269.73 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43018/47780 [02:28<00:15, 299.09 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40584/47780 [02:29<00:11, 619.93 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42979/47780 [02:29<00:17, 282.33 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41502/47780 [02:29<00:24, 252.72 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43355/47780 [02:29<00:20, 213.80 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45308/47780 [02:29<00:06, 377.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41505/47780 [02:29<00:22, 273.74 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44365/47780 [02:29<00:13, 258.18 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43049/47780 [02:29<00:16, 292.56 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43009/47780 [02:29<00:18, 264.97 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43379/47780 [02:29<00:20, 218.51 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45360/47780 [02:29<00:05, 417.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41528/47780 [02:29<00:27, 227.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41549/47780 [02:29<00:19, 317.69 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40653/47780 [02:29<00:13, 538.47 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44392/47780 [02:29<00:13, 242.93 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43079/47780 [02:29<00:16, 282.50 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45404/47780 [02:29<00:05, 419.42 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43037/47780 [02:29<00:18, 262.61 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43402/47780 [02:29<00:20, 210.71 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41552/47780 [02:29<00:27, 225.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41581/47780 [02:29<00:19, 314.40 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40715/47780 [02:29<00:12, 556.01 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44421/47780 [02:29<00:13, 255.46 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43110/47780 [02:29<00:16, 287.29 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43068/47780 [02:29<00:17, 270.39 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43424/47780 [02:29<00:21, 204.10 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41617/47780 [02:29<00:18, 327.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41586/47780 [02:29<00:24, 248.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45447/47780 [02:29<00:06, 383.26 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40778/47780 [02:29<00:12, 562.80 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44448/47780 [02:29<00:12, 256.60 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43143/47780 [02:29<00:15, 295.60 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43100/47780 [02:29<00:16, 280.48 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41614/47780 [02:29<00:24, 256.70 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45499/47780 [02:29<00:05, 411.43 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43446/47780 [02:29<00:21, 197.24 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41650/47780 [02:29<00:20, 303.58 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44483/47780 [02:29<00:11, 279.68 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43174/47780 [02:29<00:15, 293.12 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40840/47780 [02:29<00:12, 534.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43132/47780 [02:29<00:15, 291.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41640/47780 [02:29<00:24, 252.07 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43468/47780 [02:29<00:21, 203.35 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41683/47780 [02:29<00:21, 285.42 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43204/47780 [02:29<00:16, 285.57 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45541/47780 [02:29<00:06, 355.13 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44512/47780 [02:29<00:12, 261.77 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43169/47780 [02:29<00:15, 306.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41667/47780 [02:29<00:24, 254.19 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40896/47780 [02:29<00:15, 455.56 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43489/47780 [02:29<00:21, 200.70 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41714/47780 [02:29<00:20, 289.27 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43233/47780 [02:29<00:16, 277.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44539/47780 [02:29<00:13, 246.65 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41696/47780 [02:29<00:23, 256.39 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40963/47780 [02:29<00:13, 504.55 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43201/47780 [02:29<00:16, 281.98 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45580/47780 [02:29<00:07, 305.22 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43510/47780 [02:29<00:22, 192.64 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43271/47780 [02:29<00:15, 295.94 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44565/47780 [02:29<00:13, 243.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41744/47780 [02:29<00:23, 258.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43231/47780 [02:29<00:15, 286.28 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41727/47780 [02:29<00:22, 264.70 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41017/47780 [02:30<00:14, 471.39 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43544/47780 [02:29<00:19, 218.57 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43307/47780 [02:29<00:14, 310.54 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44594/47780 [02:30<00:12, 255.92 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45615/47780 [02:30<00:07, 272.53 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43263/47780 [02:30<00:15, 292.95 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41771/47780 [02:30<00:24, 246.07 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41764/47780 [02:30<00:20, 291.15 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41080/47780 [02:30<00:13, 509.89 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43576/47780 [02:30<00:18, 229.67 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43340/47780 [02:30<00:14, 305.59 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44620/47780 [02:30<00:12, 256.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45717/47780 [02:30<00:04, 435.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43299/47780 [02:30<00:14, 308.39 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41797/47780 [02:30<00:20, 298.85 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41797/47780 [02:30<00:25, 235.11 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41134/47780 [02:30<00:13, 507.05 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43605/47780 [02:30<00:17, 242.09 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44653/47780 [02:30<00:11, 275.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43379/47780 [02:30<00:13, 318.57 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45767/47780 [02:30<00:04, 418.07 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41831/47780 [02:30<00:19, 300.30 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43331/47780 [02:30<00:15, 294.43 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41825/47780 [02:30<00:24, 246.62 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41188/47780 [02:30<00:13, 484.74 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44681/47780 [02:30<00:11, 261.56 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43630/47780 [02:30<00:19, 212.03 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43364/47780 [02:30<00:14, 298.07 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41862/47780 [02:30<00:20, 292.87 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43411/47780 [02:30<00:15, 275.95 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41856/47780 [02:30<00:23, 253.12 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45814/47780 [02:30<00:04, 399.93 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41240/47780 [02:30<00:13, 489.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44708/47780 [02:30<00:11, 263.04 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43652/47780 [02:30<00:20, 205.76 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41892/47780 [02:30<00:20, 285.43 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41886/47780 [02:30<00:22, 259.79 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43399/47780 [02:30<00:14, 296.05 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43455/47780 [02:30<00:14, 308.34 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41292/47780 [02:30<00:13, 497.37 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45857/47780 [02:30<00:05, 365.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44742/47780 [02:30<00:10, 277.03 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43431/47780 [02:30<00:14, 299.33 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41921/47780 [02:30<00:21, 278.36 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43673/47780 [02:30<00:21, 194.84 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41921/47780 [02:30<00:21, 268.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41343/47780 [02:30<00:13, 479.90 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44770/47780 [02:30<00:11, 268.47 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43487/47780 [02:30<00:16, 259.79 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45897/47780 [02:30<00:05, 342.54 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43724/47780 [02:30<00:14, 272.87 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41952/47780 [02:30<00:21, 275.05 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41950/47780 [02:30<00:21, 265.75 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41394/47780 [02:30<00:13, 462.77 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43462/47780 [02:30<00:16, 261.30 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43518/47780 [02:30<00:15, 271.59 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44807/47780 [02:30<00:10, 290.06 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45933/47780 [02:30<00:05, 326.47 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41982/47780 [02:30<00:20, 281.73 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43753/47780 [02:30<00:15, 266.04 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41977/47780 [02:30<00:22, 255.52 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41464/47780 [02:30<00:12, 515.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43502/47780 [02:30<00:14, 294.13 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43547/47780 [02:30<00:16, 252.80 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42011/47780 [02:30<00:20, 277.87 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45967/47780 [02:30<00:05, 311.45 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44840/47780 [02:30<00:11, 255.40 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43781/47780 [02:30<00:15, 256.12 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41518/47780 [02:31<00:12, 507.96 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42003/47780 [02:30<00:23, 240.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43535/47780 [02:30<00:14, 292.84 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43579/47780 [02:30<00:15, 267.24 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42042/47780 [02:31<00:20, 286.76 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43808/47780 [02:31<00:15, 248.68 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45999/47780 [02:31<00:06, 290.66 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42029/47780 [02:31<00:23, 243.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41571/47780 [02:31<00:12, 506.26 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44868/47780 [02:31<00:13, 223.07 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43607/47780 [02:31<00:15, 270.33 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43566/47780 [02:31<00:15, 264.70 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42072/47780 [02:31<00:19, 287.45 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41627/47780 [02:31<00:11, 521.27 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42054/47780 [02:31<00:23, 245.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43834/47780 [02:31<00:15, 249.38 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44925/47780 [02:31<00:09, 302.21 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43636/47780 [02:31<00:15, 266.93 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42101/47780 [02:31<00:19, 284.81 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46029/47780 [02:31<00:07, 247.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43594/47780 [02:31<00:17, 232.85 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43861/47780 [02:31<00:15, 245.69 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42079/47780 [02:31<00:24, 231.04 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41681/47780 [02:31<00:12, 487.26 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44958/47780 [02:31<00:09, 294.36 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43666/47780 [02:31<00:15, 264.90 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42131/47780 [02:31<00:19, 282.81 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46081/47780 [02:31<00:05, 306.66 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43888/47780 [02:31<00:15, 251.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43654/47780 [02:31<00:13, 314.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42107/47780 [02:31<00:23, 241.80 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41735/47780 [02:31<00:12, 496.61 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43693/47780 [02:31<00:15, 258.57 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44990/47780 [02:31<00:09, 286.31 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42160/47780 [02:31<00:20, 280.14 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46115/47780 [02:31<00:05, 286.77 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42135/47780 [02:31<00:22, 252.29 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41790/47780 [02:31<00:11, 509.57 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43689/47780 [02:31<00:13, 305.31 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43919/47780 [02:31<00:15, 253.27 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42201/47780 [02:31<00:17, 315.64 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45020/47780 [02:31<00:09, 286.70 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43720/47780 [02:31<00:15, 254.82 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46146/47780 [02:31<00:05, 289.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42162/47780 [02:31<00:22, 254.65 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43958/47780 [02:31<00:13, 287.91 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43726/47780 [02:31<00:12, 319.35 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41843/47780 [02:31<00:12, 481.35 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42238/47780 [02:31<00:16, 327.54 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43751/47780 [02:31<00:14, 269.69 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45054/47780 [02:31<00:09, 289.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46179/47780 [02:31<00:05, 293.78 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43761/47780 [02:31<00:12, 326.33 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42188/47780 [02:31<00:24, 232.19 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41892/47780 [02:31<00:12, 466.96 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43988/47780 [02:31<00:14, 259.08 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43789/47780 [02:31<00:13, 296.13 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42271/47780 [02:31<00:17, 313.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45084/47780 [02:31<00:10, 265.93 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42213/47780 [02:31<00:23, 236.89 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41941/47780 [02:31<00:12, 472.22 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43795/47780 [02:31<00:13, 306.28 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46210/47780 [02:31<00:05, 262.39 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43830/47780 [02:31<00:12, 327.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44015/47780 [02:31<00:14, 251.19 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45112/47780 [02:31<00:10, 256.32 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42003/47780 [02:32<00:11, 502.63 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42238/47780 [02:31<00:24, 227.86 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42304/47780 [02:31<00:21, 250.15 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44053/47780 [02:31<00:13, 285.11 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43827/47780 [02:31<00:13, 289.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43864/47780 [02:31<00:12, 323.68 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45139/47780 [02:32<00:10, 259.67 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42375/47780 [02:32<00:14, 361.23 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46238/47780 [02:32<00:07, 204.30 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43897/47780 [02:32<00:11, 325.06 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42054/47780 [02:32<00:12, 467.91 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43858/47780 [02:32<00:13, 284.69 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44083/47780 [02:32<00:13, 276.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42262/47780 [02:32<00:26, 205.08 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45167/47780 [02:32<00:10, 244.25 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46295/47780 [02:32<00:05, 278.38 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43930/47780 [02:32<00:12, 319.10 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43893/47780 [02:32<00:12, 301.82 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42416/47780 [02:32<00:15, 354.94 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42104/47780 [02:32<00:12, 447.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44113/47780 [02:32<00:13, 266.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42284/47780 [02:32<00:27, 202.75 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45193/47780 [02:32<00:10, 240.79 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43928/47780 [02:32<00:12, 312.51 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43963/47780 [02:32<00:11, 318.57 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46329/47780 [02:32<00:05, 273.53 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42311/47780 [02:32<00:24, 219.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44145/47780 [02:32<00:13, 272.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42150/47780 [02:32<00:13, 422.88 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42455/47780 [02:32<00:17, 310.17 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43960/47780 [02:32<00:12, 314.36 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43995/47780 [02:32<00:11, 318.30 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45220/47780 [02:32<00:10, 235.93 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42335/47780 [02:32<00:24, 224.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42202/47780 [02:32<00:12, 444.88 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44173/47780 [02:32<00:14, 257.57 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42501/47780 [02:32<00:15, 345.87 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46360/47780 [02:32<00:05, 242.99 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43992/47780 [02:32<00:12, 312.47 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44027/47780 [02:32<00:12, 304.65 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42369/47780 [02:32<00:21, 254.74 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45244/47780 [02:32<00:11, 214.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42248/47780 [02:32<00:12, 448.28 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42540/47780 [02:32<00:15, 339.17 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44201/47780 [02:32<00:14, 242.90 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46387/47780 [02:32<00:05, 242.34 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44058/47780 [02:32<00:12, 296.90 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44024/47780 [02:32<00:13, 282.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45278/47780 [02:32<00:10, 243.86 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42396/47780 [02:32<00:22, 242.46 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42295/47780 [02:32<00:12, 431.87 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44229/47780 [02:32<00:14, 246.05 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44088/47780 [02:32<00:12, 294.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42577/47780 [02:32<00:16, 312.01 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42345/47780 [02:32<00:12, 449.26 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42422/47780 [02:32<00:21, 244.54 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46413/47780 [02:32<00:06, 210.69 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44053/47780 [02:32<00:14, 261.97 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45305/47780 [02:32<00:11, 222.50 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44261/47780 [02:32<00:13, 263.34 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44120/47780 [02:32<00:12, 295.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42610/47780 [02:32<00:16, 310.75 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42393/47780 [02:32<00:12, 442.95 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46461/47780 [02:32<00:04, 268.14 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42447/47780 [02:32<00:23, 230.75 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44080/47780 [02:32<00:15, 245.73 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44296/47780 [02:32<00:12, 281.99 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45336/47780 [02:32<00:10, 235.04 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44165/47780 [02:32<00:10, 335.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42643/47780 [02:32<00:16, 309.34 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42439/47780 [02:33<00:12, 442.88 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46494/47780 [02:32<00:04, 278.70 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42479/47780 [02:32<00:20, 255.01 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44325/47780 [02:33<00:12, 280.81 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45361/47780 [02:33<00:10, 234.01 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44107/47780 [02:33<00:16, 228.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44199/47780 [02:32<00:11, 318.45 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42675/47780 [02:33<00:17, 291.91 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42491/47780 [02:33<00:11, 464.72 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42506/47780 [02:33<00:21, 245.49 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46524/47780 [02:33<00:04, 258.04 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44357/47780 [02:33<00:11, 285.71 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45385/47780 [02:33<00:10, 222.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44141/47780 [02:33<00:14, 256.41 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42711/47780 [02:33<00:16, 308.22 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44232/47780 [02:33<00:11, 304.54 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42538/47780 [02:33<00:11, 450.47 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42531/47780 [02:33<00:21, 241.35 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46557/47780 [02:33<00:04, 273.01 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44390/47780 [02:33<00:11, 293.12 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45408/47780 [02:33<00:10, 223.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44171/47780 [02:33<00:14, 251.89 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44266/47780 [02:33<00:11, 313.95 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42584/47780 [02:33<00:11, 433.13 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42743/47780 [02:33<00:18, 275.46 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42559/47780 [02:33<00:20, 249.41 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44423/47780 [02:33<00:11, 295.29 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46588/47780 [02:33<00:04, 274.10 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45431/47780 [02:33<00:10, 217.83 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44198/47780 [02:33<00:14, 254.29 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44314/47780 [02:33<00:09, 353.12 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42587/47780 [02:33<00:20, 255.17 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42774/47780 [02:33<00:18, 276.74 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42628/47780 [02:33<00:12, 399.62 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45456/47780 [02:33<00:10, 224.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44453/47780 [02:33<00:12, 269.23 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46617/47780 [02:33<00:04, 249.33 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44355/47780 [02:33<00:09, 365.13 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44224/47780 [02:33<00:14, 240.12 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42625/47780 [02:33<00:18, 280.99 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42807/47780 [02:33<00:17, 289.86 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42684/47780 [02:33<00:11, 438.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45479/47780 [02:33<00:10, 222.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44481/47780 [02:33<00:12, 268.08 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46644/47780 [02:33<00:04, 254.12 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44250/47780 [02:33<00:14, 244.98 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44397/47780 [02:33<00:08, 376.38 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42659/47780 [02:33<00:17, 297.40 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42837/47780 [02:33<00:17, 290.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42750/47780 [02:33<00:10, 487.77 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44510/47780 [02:33<00:12, 257.47 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46671/47780 [02:33<00:04, 242.89 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44435/47780 [02:33<00:09, 363.66 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44275/47780 [02:33<00:15, 226.75 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42689/47780 [02:33<00:17, 295.76 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42874/47780 [02:33<00:15, 311.35 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45502/47780 [02:33<00:12, 182.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42801/47780 [02:33<00:10, 469.99 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44537/47780 [02:33<00:12, 250.66 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46696/47780 [02:33<00:04, 237.68 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44302/47780 [02:33<00:15, 231.22 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42719/47780 [02:33<00:17, 289.66 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45522/47780 [02:33<00:12, 182.09 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44473/47780 [02:33<00:10, 318.89 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42850/47780 [02:33<00:10, 474.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42906/47780 [02:33<00:17, 276.70 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44563/47780 [02:33<00:12, 250.44 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46721/47780 [02:33<00:04, 235.57 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44336/47780 [02:33<00:13, 260.36 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42749/47780 [02:33<00:17, 282.80 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45542/47780 [02:33<00:12, 180.35 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42901/47780 [02:34<00:10, 482.83 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44513/47780 [02:33<00:09, 333.58 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42936/47780 [02:33<00:17, 270.92 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46753/47780 [02:34<00:04, 256.08 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44363/47780 [02:34<00:13, 257.21 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42784/47780 [02:34<00:16, 298.51 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44589/47780 [02:34<00:14, 227.83 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45567/47780 [02:34<00:11, 196.74 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42958/47780 [02:34<00:09, 503.32 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44549/47780 [02:34<00:09, 332.52 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42986/47780 [02:34<00:14, 330.31 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46779/47780 [02:34<00:03, 251.52 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44390/47780 [02:34<00:13, 260.54 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42822/47780 [02:34<00:15, 311.07 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45591/47780 [02:34<00:10, 206.00 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43009/47780 [02:34<00:09, 497.31 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44615/47780 [02:34<00:14, 224.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44585/47780 [02:34<00:09, 326.02 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43022/47780 [02:34<00:14, 335.94 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44418/47780 [02:34<00:13, 257.33 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46805/47780 [02:34<00:04, 234.77 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42860/47780 [02:34<00:14, 330.30 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45613/47780 [02:34<00:10, 209.76 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44639/47780 [02:34<00:13, 225.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43059/47780 [02:34<00:10, 470.82 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43062/47780 [02:34<00:13, 350.25 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44619/47780 [02:34<00:10, 306.50 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44445/47780 [02:34<00:12, 258.20 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42900/47780 [02:34<00:14, 348.44 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45636/47780 [02:34<00:10, 208.47 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44662/47780 [02:34<00:14, 222.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46830/47780 [02:34<00:04, 222.86 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43106/47780 [02:34<00:12, 372.80 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43108/47780 [02:34<00:10, 444.77 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44652/47780 [02:34<00:10, 309.71 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44474/47780 [02:34<00:12, 258.71 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42935/47780 [02:34<00:13, 346.27 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45662/47780 [02:34<00:09, 220.38 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44686/47780 [02:34<00:13, 226.99 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46856/47780 [02:34<00:04, 227.85 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43144/47780 [02:34<00:12, 362.95 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44687/47780 [02:34<00:09, 315.13 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43157/47780 [02:34<00:10, 434.06 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44501/47780 [02:34<00:12, 258.81 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42976/47780 [02:34<00:13, 361.65 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45685/47780 [02:34<00:09, 222.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44709/47780 [02:34<00:13, 223.27 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46881/47780 [02:34<00:04, 213.10 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43181/47780 [02:34<00:13, 347.21 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43203/47780 [02:34<00:10, 434.56 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44719/47780 [02:34<00:10, 288.58 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43017/47780 [02:34<00:12, 371.24 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44532/47780 [02:34<00:12, 267.23 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44738/47780 [02:34<00:12, 236.70 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45713/47780 [02:34<00:09, 229.12 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43247/47780 [02:34<00:10, 421.95 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43217/47780 [02:34<00:13, 328.78 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46904/47780 [02:34<00:04, 188.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44559/47780 [02:34<00:13, 245.68 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44762/47780 [02:34<00:13, 229.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45736/47780 [02:34<00:09, 219.54 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44749/47780 [02:34<00:12, 250.23 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43055/47780 [02:34<00:14, 318.25 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43251/47780 [02:34<00:13, 328.33 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43291/47780 [02:34<00:11, 404.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46924/47780 [02:34<00:04, 178.91 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44584/47780 [02:34<00:13, 234.23 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44793/47780 [02:34<00:12, 240.43 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43097/47780 [02:34<00:13, 344.90 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44798/47780 [02:34<00:10, 297.25 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45759/47780 [02:34<00:09, 208.02 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43286/47780 [02:34<00:13, 327.19 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43342/47780 [02:35<00:10, 431.25 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46950/47780 [02:35<00:04, 196.74 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44613/47780 [02:35<00:12, 246.50 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44818/47780 [02:35<00:12, 239.12 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43143/47780 [02:35<00:12, 372.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44835/47780 [02:34<00:09, 312.57 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45781/47780 [02:35<00:09, 203.80 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43392/47780 [02:35<00:09, 443.38 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43320/47780 [02:35<00:14, 316.50 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43182/47780 [02:35<00:12, 373.08 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44842/47780 [02:35<00:12, 227.26 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44638/47780 [02:35<00:13, 232.12 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45807/47780 [02:35<00:09, 212.64 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46972/47780 [02:35<00:04, 180.47 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43446/47780 [02:35<00:09, 459.85 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44869/47780 [02:35<00:10, 286.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43352/47780 [02:35<00:14, 303.49 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43235/47780 [02:35<00:11, 412.48 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44866/47780 [02:35<00:12, 229.99 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44671/47780 [02:35<00:12, 252.94 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45832/47780 [02:35<00:08, 221.29 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46991/47780 [02:35<00:04, 182.67 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43494/47780 [02:35<00:09, 445.04 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44899/47780 [02:35<00:10, 268.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43384/47780 [02:35<00:15, 287.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43286/47780 [02:35<00:10, 439.78 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44890/47780 [02:35<00:12, 227.53 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47012/47780 [02:35<00:04, 188.11 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44705/47780 [02:35<00:11, 271.04 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43544/47780 [02:35<00:09, 459.34 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45855/47780 [02:35<00:09, 201.30 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44934/47780 [02:35<00:10, 283.05 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43413/47780 [02:35<00:16, 270.04 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43338/47780 [02:35<00:09, 458.31 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44915/47780 [02:35<00:12, 231.45 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47032/47780 [02:35<00:03, 190.78 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44734/47780 [02:35<00:11, 265.04 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43593/47780 [02:35<00:09, 455.48 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45879/47780 [02:35<00:09, 207.29 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44965/47780 [02:35<00:10, 280.87 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43444/47780 [02:35<00:15, 274.66 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44947/47780 [02:35<00:11, 256.52 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47052/47780 [02:35<00:03, 191.30 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43386/47780 [02:35<00:10, 427.01 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44763/47780 [02:35<00:11, 268.36 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45901/47780 [02:35<00:08, 209.82 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43639/47780 [02:35<00:09, 437.47 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44998/47780 [02:35<00:09, 288.23 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43472/47780 [02:35<00:15, 274.31 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44977/47780 [02:35<00:10, 266.20 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47073/47780 [02:35<00:03, 193.25 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43430/47780 [02:35<00:10, 424.03 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44794/47780 [02:35<00:11, 262.39 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45924/47780 [02:35<00:08, 206.93 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43684/47780 [02:35<00:09, 426.01 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45029/47780 [02:35<00:09, 293.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43504/47780 [02:35<00:15, 284.01 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45008/47780 [02:35<00:10, 269.55 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43482/47780 [02:35<00:09, 445.73 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47093/47780 [02:35<00:03, 186.89 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44822/47780 [02:35<00:11, 264.91 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45946/47780 [02:35<00:08, 208.26 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43746/47780 [02:35<00:08, 471.41 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45062/47780 [02:35<00:09, 297.48 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43533/47780 [02:35<00:15, 277.48 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45037/47780 [02:35<00:09, 275.29 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43528/47780 [02:35<00:10, 416.32 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45093/47780 [02:35<00:09, 297.97 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43795/47780 [02:36<00:08, 462.25 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45967/47780 [02:35<00:09, 196.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47112/47780 [02:35<00:04, 158.29 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44849/47780 [02:35<00:12, 229.92 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43561/47780 [02:36<00:16, 253.25 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45065/47780 [02:36<00:10, 255.98 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43571/47780 [02:36<00:10, 406.70 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45987/47780 [02:36<00:09, 192.22 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45123/47780 [02:36<00:09, 288.22 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47130/47780 [02:36<00:04, 160.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43850/47780 [02:36<00:08, 466.28 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44873/47780 [02:36<00:12, 229.23 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45091/47780 [02:36<00:11, 243.46 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43615/47780 [02:36<00:10, 411.87 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43588/47780 [02:36<00:17, 237.08 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43897/47780 [02:36<00:08, 465.25 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47158/47780 [02:36<00:03, 188.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45155/47780 [02:36<00:09, 290.94 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46008/47780 [02:36<00:09, 187.91 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44898/47780 [02:36<00:14, 205.57 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43635/47780 [02:36<00:14, 291.80 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45116/47780 [02:36<00:11, 229.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43658/47780 [02:36<00:10, 394.37 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47178/47780 [02:36<00:03, 184.80 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45185/47780 [02:36<00:09, 280.47 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43947/47780 [02:36<00:08, 444.62 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46028/47780 [02:36<00:09, 182.33 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44936/47780 [02:36<00:11, 244.98 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45143/47780 [02:36<00:11, 238.58 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43666/47780 [02:36<00:14, 287.42 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43700/47780 [02:36<00:11, 365.40 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45214/47780 [02:36<00:09, 273.21 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43993/47780 [02:36<00:08, 439.02 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46049/47780 [02:36<00:09, 183.75 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47197/47780 [02:36<00:03, 166.92 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44963/47780 [02:36<00:11, 250.11 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45168/47780 [02:36<00:11, 236.35 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43696/47780 [02:36<00:14, 276.15 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43738/47780 [02:36<00:11, 365.30 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44039/47780 [02:36<00:08, 437.60 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45242/47780 [02:36<00:09, 258.72 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45012/47780 [02:36<00:08, 309.77 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46068/47780 [02:36<00:10, 166.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47215/47780 [02:36<00:03, 161.78 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45205/47780 [02:36<00:09, 267.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43726/47780 [02:36<00:14, 277.54 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43775/47780 [02:36<00:11, 348.80 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44090/47780 [02:36<00:08, 457.46 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45049/47780 [02:36<00:08, 324.95 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45269/47780 [02:36<00:10, 245.97 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46085/47780 [02:36<00:10, 161.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45235/47780 [02:36<00:09, 267.57 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47232/47780 [02:36<00:03, 148.14 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43755/47780 [02:36<00:15, 268.30 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43811/47780 [02:36<00:11, 346.89 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44136/47780 [02:36<00:08, 435.69 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45304/47780 [02:36<00:09, 272.30 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45086/47780 [02:36<00:08, 320.46 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46102/47780 [02:36<00:10, 158.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45263/47780 [02:36<00:09, 268.19 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47248/47780 [02:36<00:03, 144.55 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43783/47780 [02:36<00:15, 265.70 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43847/47780 [02:36<00:11, 345.01 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44181/47780 [02:36<00:08, 419.93 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45120/47780 [02:36<00:08, 322.83 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45334/47780 [02:36<00:09, 264.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46119/47780 [02:36<00:10, 160.89 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43828/47780 [02:36<00:12, 313.04 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43890/47780 [02:36<00:10, 367.55 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47263/47780 [02:36<00:03, 140.57 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45290/47780 [02:36<00:10, 237.59 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44225/47780 [02:37<00:08, 396.09 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45366/47780 [02:36<00:08, 276.51 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46137/47780 [02:36<00:09, 164.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45153/47780 [02:37<00:08, 300.40 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43935/47780 [02:37<00:09, 390.65 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43862/47780 [02:37<00:12, 313.05 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45318/47780 [02:37<00:09, 247.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47278/47780 [02:37<00:03, 134.37 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44278/47780 [02:37<00:08, 426.60 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45396/47780 [02:37<00:08, 280.59 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45196/47780 [02:37<00:07, 334.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46156/47780 [02:37<00:09, 165.45 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43978/47780 [02:37<00:09, 398.46 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43894/47780 [02:37<00:12, 309.64 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45344/47780 [02:37<00:09, 250.36 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47292/47780 [02:37<00:03, 128.99 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44332/47780 [02:37<00:07, 452.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45425/47780 [02:37<00:08, 278.62 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46183/47780 [02:37<00:08, 187.46 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45233/47780 [02:37<00:07, 327.84 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44033/47780 [02:37<00:08, 437.61 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43927/47780 [02:37<00:12, 308.59 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45378/47780 [02:37<00:08, 270.97 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47305/47780 [02:37<00:03, 126.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44380/47780 [02:37<00:07, 456.03 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46209/47780 [02:37<00:07, 202.50 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45268/47780 [02:37<00:07, 328.37 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45455/47780 [02:37<00:09, 253.23 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44081/47780 [02:37<00:08, 443.70 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43964/47780 [02:37<00:11, 325.75 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45406/47780 [02:37<00:09, 255.42 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44427/47780 [02:37<00:07, 457.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47318/47780 [02:37<00:03, 123.04 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46231/47780 [02:37<00:07, 201.65 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45313/47780 [02:37<00:06, 353.60 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45507/47780 [02:37<00:07, 319.35 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44126/47780 [02:37<00:08, 441.01 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43997/47780 [02:37<00:11, 317.55 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45432/47780 [02:37<00:09, 246.59 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47331/47780 [02:37<00:03, 124.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44475/47780 [02:37<00:07, 449.50 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45351/47780 [02:37<00:06, 360.64 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44171/47780 [02:37<00:08, 434.40 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45541/47780 [02:37<00:07, 315.13 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44035/47780 [02:37<00:11, 333.88 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46254/47780 [02:37<00:08, 187.09 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45459/47780 [02:37<00:09, 249.50 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47344/47780 [02:37<00:03, 124.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44521/47780 [02:37<00:07, 438.13 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45388/47780 [02:37<00:06, 361.66 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44219/47780 [02:37<00:08, 441.97 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44074/47780 [02:37<00:10, 346.12 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45575/47780 [02:37<00:07, 313.64 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46284/47780 [02:37<00:06, 213.75 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45491/47780 [02:37<00:08, 267.29 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47364/47780 [02:37<00:02, 141.50 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44567/47780 [02:37<00:07, 431.97 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45425/47780 [02:37<00:06, 344.67 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44269/47780 [02:37<00:07, 454.17 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44112/47780 [02:37<00:10, 349.76 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45608/47780 [02:37<00:07, 301.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46314/47780 [02:37<00:06, 227.62 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45518/47780 [02:37<00:09, 242.97 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44611/47780 [02:37<00:07, 422.71 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47379/47780 [02:37<00:03, 130.32 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44317/47780 [02:37<00:07, 455.02 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44148/47780 [02:37<00:10, 337.78 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45460/47780 [02:37<00:07, 302.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45639/47780 [02:37<00:07, 282.49 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44660/47780 [02:38<00:07, 437.16 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45545/47780 [02:37<00:09, 238.45 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47394/47780 [02:37<00:02, 135.43 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46338/47780 [02:37<00:07, 201.88 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44365/47780 [02:37<00:07, 442.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44182/47780 [02:37<00:10, 327.13 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45669/47780 [02:37<00:07, 267.56 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44704/47780 [02:38<00:07, 437.21 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45492/47780 [02:38<00:08, 277.26 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45570/47780 [02:38<00:09, 232.57 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46367/47780 [02:38<00:06, 216.90 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47408/47780 [02:38<00:02, 130.26 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44412/47780 [02:38<00:07, 446.67 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44231/47780 [02:38<00:09, 365.41 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45701/47780 [02:38<00:07, 280.99 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45604/47780 [02:38<00:08, 260.70 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44748/47780 [02:38<00:07, 395.06 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47422/47780 [02:38<00:02, 129.74 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46390/47780 [02:38<00:06, 212.66 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45521/47780 [02:38<00:09, 250.53 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44270/47780 [02:38<00:09, 369.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44457/47780 [02:38<00:07, 417.13 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45730/47780 [02:38<00:07, 279.68 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45631/47780 [02:38<00:08, 255.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47436/47780 [02:38<00:02, 130.18 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46416/47780 [02:38<00:06, 220.54 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44790/47780 [02:38<00:07, 389.15 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44308/47780 [02:38<00:09, 363.30 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45547/47780 [02:38<00:09, 239.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44501/47780 [02:38<00:08, 391.52 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45759/47780 [02:38<00:07, 268.48 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45659/47780 [02:38<00:08, 246.50 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44830/47780 [02:38<00:07, 374.43 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46446/47780 [02:38<00:05, 227.88 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44345/47780 [02:38<00:09, 361.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45572/47780 [02:38<00:09, 240.08 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44543/47780 [02:38<00:08, 390.21 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47451/47780 [02:38<00:03, 108.30 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45787/47780 [02:38<00:07, 259.46 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45684/47780 [02:38<00:08, 246.31 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44875/47780 [02:38<00:07, 394.35 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44383/47780 [02:38<00:09, 363.31 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45600/47780 [02:38<00:08, 248.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46470/47780 [02:38<00:05, 218.97 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44594/47780 [02:38<00:08, 397.18 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45814/47780 [02:38<00:07, 254.33 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45710/47780 [02:38<00:08, 241.11 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44918/47780 [02:38<00:07, 394.50 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44421/47780 [02:38<00:09, 365.85 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45628/47780 [02:38<00:08, 252.35 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47463/47780 [02:38<00:03, 96.10 examples/s] 
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44640/47780 [02:38<00:07, 413.16 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46494/47780 [02:38<00:06, 200.67 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45840/47780 [02:38<00:07, 246.18 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45744/47780 [02:38<00:07, 262.48 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44964/47780 [02:38<00:06, 403.63 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44463/47780 [02:38<00:08, 372.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45658/47780 [02:38<00:08, 256.71 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44684/47780 [02:38<00:07, 418.12 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45865/47780 [02:38<00:07, 245.46 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46518/47780 [02:38<00:06, 194.77 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47475/47780 [02:38<00:03, 86.63 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45773/47780 [02:38<00:07, 268.26 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45012/47780 [02:38<00:06, 421.21 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44517/47780 [02:38<00:07, 410.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45703/47780 [02:38<00:06, 305.51 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44728/47780 [02:38<00:07, 413.51 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46540/47780 [02:38<00:06, 198.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47486/47780 [02:38<00:03, 88.31 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45055/47780 [02:39<00:06, 412.32 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45890/47780 [02:38<00:08, 227.01 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45800/47780 [02:38<00:07, 250.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44559/47780 [02:38<00:08, 396.51 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45735/47780 [02:39<00:07, 277.33 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44774/47780 [02:38<00:07, 409.55 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45921/47780 [02:38<00:07, 248.75 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45098/47780 [02:39<00:06, 409.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47499/47780 [02:39<00:02, 94.47 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45830/47780 [02:39<00:08, 239.83 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46563/47780 [02:39<00:07, 173.26 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44600/47780 [02:39<00:08, 362.23 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45764/47780 [02:39<00:07, 278.06 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44817/47780 [02:39<00:07, 411.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45947/47780 [02:39<00:07, 242.37 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45142/47780 [02:39<00:06, 391.95 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47509/47780 [02:39<00:03, 88.74 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45855/47780 [02:39<00:08, 233.27 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44642/47780 [02:39<00:08, 361.07 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45793/47780 [02:39<00:07, 263.39 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44859/47780 [02:39<00:07, 386.98 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46587/47780 [02:39<00:07, 162.03 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45182/47780 [02:39<00:06, 374.39 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45972/47780 [02:39<00:08, 223.81 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45879/47780 [02:39<00:08, 229.77 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44679/47780 [02:39<00:09, 341.47 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45820/47780 [02:39<00:07, 258.25 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44899/47780 [02:39<00:07, 375.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47520/47780 [02:39<00:03, 78.07 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46605/47780 [02:39<00:07, 156.26 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45220/47780 [02:39<00:06, 371.67 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45995/47780 [02:39<00:08, 219.71 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44714/47780 [02:39<00:08, 342.29 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45847/47780 [02:39<00:07, 254.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45903/47780 [02:39<00:09, 207.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44937/47780 [02:39<00:08, 346.05 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45258/47780 [02:39<00:06, 373.29 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46024/47780 [02:39<00:07, 235.40 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46626/47780 [02:39<00:07, 155.98 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45879/47780 [02:39<00:07, 271.49 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47529/47780 [02:39<00:03, 67.63 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44750/47780 [02:39<00:09, 328.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45925/47780 [02:39<00:08, 209.34 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44973/47780 [02:39<00:08, 332.68 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45297/47780 [02:39<00:06, 374.49 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46049/47780 [02:39<00:07, 235.41 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45910/47780 [02:39<00:06, 280.42 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44785/47780 [02:39<00:09, 327.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45947/47780 [02:39<00:08, 207.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46642/47780 [02:39<00:08, 139.07 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47537/47780 [02:39<00:03, 66.20 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45007/47780 [02:39<00:08, 333.21 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45342/47780 [02:39<00:06, 395.19 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46073/47780 [02:39<00:07, 232.25 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45942/47780 [02:39<00:06, 282.73 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44820/47780 [02:39<00:08, 332.31 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45968/47780 [02:39<00:08, 204.58 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45046/47780 [02:39<00:07, 344.29 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46657/47780 [02:39<00:08, 131.82 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45396/47780 [02:39<00:05, 413.74 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47545/47780 [02:39<00:03, 63.38 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46097/47780 [02:39<00:07, 224.28 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44855/47780 [02:39<00:08, 334.47 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45985/47780 [02:39<00:05, 310.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45989/47780 [02:39<00:08, 204.39 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45082/47780 [02:39<00:07, 344.54 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45442/47780 [02:39<00:05, 423.11 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46673/47780 [02:39<00:08, 131.63 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46121/47780 [02:39<00:07, 222.46 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44899/47780 [02:39<00:07, 362.99 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47552/47780 [02:39<00:03, 58.21 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46017/47780 [02:39<00:05, 309.67 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46012/47780 [02:39<00:08, 207.74 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45135/47780 [02:39<00:06, 391.39 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45487/47780 [02:40<00:05, 425.66 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46688/47780 [02:40<00:08, 135.50 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46154/47780 [02:39<00:06, 250.43 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44939/47780 [02:40<00:07, 360.73 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46048/47780 [02:40<00:05, 297.39 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46036/47780 [02:40<00:08, 211.04 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47559/47780 [02:40<00:03, 57.03 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45175/47780 [02:40<00:06, 389.36 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45534/47780 [02:40<00:05, 434.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46182/47780 [02:40<00:06, 258.53 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46702/47780 [02:40<00:08, 121.86 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44978/47780 [02:40<00:07, 365.09 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46063/47780 [02:40<00:07, 220.61 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46078/47780 [02:40<00:06, 275.31 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47565/47780 [02:40<00:03, 55.05 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45215/47780 [02:40<00:06, 368.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45579/47780 [02:40<00:05, 417.11 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46209/47780 [02:40<00:06, 241.50 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46717/47780 [02:40<00:08, 128.61 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45017/47780 [02:40<00:07, 370.47 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46088/47780 [02:40<00:07, 226.53 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47573/47780 [02:40<00:03, 59.01 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45254/47780 [02:40<00:06, 363.58 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45622/47780 [02:40<00:05, 416.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46107/47780 [02:40<00:06, 258.04 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46234/47780 [02:40<00:06, 236.39 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45057/47780 [02:40<00:07, 347.55 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46111/47780 [02:40<00:08, 205.22 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46732/47780 [02:40<00:09, 114.43 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45664/47780 [02:40<00:05, 415.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45291/47780 [02:40<00:06, 357.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47580/47780 [02:40<00:03, 59.33 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46152/47780 [02:40<00:05, 300.50 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46258/47780 [02:40<00:06, 228.45 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45099/47780 [02:40<00:07, 352.27 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46132/47780 [02:40<00:08, 205.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45709/47780 [02:40<00:04, 417.51 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46185/47780 [02:40<00:05, 308.32 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45327/47780 [02:40<00:07, 344.52 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46745/47780 [02:40<00:09, 112.91 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47589/47780 [02:40<00:03, 62.34 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46285/47780 [02:40<00:06, 226.78 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45152/47780 [02:40<00:06, 396.53 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46153/47780 [02:40<00:08, 194.74 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45363/47780 [02:40<00:07, 339.51 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45755/47780 [02:40<00:05, 391.73 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46757/47780 [02:40<00:09, 107.97 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46218/47780 [02:40<00:05, 289.13 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47597/47780 [02:40<00:02, 64.89 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46311/47780 [02:40<00:06, 235.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45196/47780 [02:40<00:06, 406.61 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45401/47780 [02:40<00:06, 350.12 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46175/47780 [02:40<00:08, 198.44 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45797/47780 [02:40<00:04, 398.85 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46772/47780 [02:40<00:08, 114.51 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46248/47780 [02:40<00:05, 267.11 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46335/47780 [02:40<00:06, 231.84 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47606/47780 [02:40<00:02, 65.26 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45238/47780 [02:40<00:06, 375.89 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46198/47780 [02:40<00:07, 204.14 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45438/47780 [02:40<00:06, 350.22 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45838/47780 [02:40<00:04, 399.16 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46787/47780 [02:40<00:08, 120.67 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46280/47780 [02:40<00:05, 271.34 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46360/47780 [02:40<00:06, 228.21 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47619/47780 [02:40<00:02, 78.73 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45880/47780 [02:41<00:04, 400.07 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46221/47780 [02:41<00:07, 202.37 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45277/47780 [02:41<00:07, 347.20 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45474/47780 [02:40<00:07, 319.79 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46800/47780 [02:41<00:08, 115.97 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46384/47780 [02:40<00:06, 228.76 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46312/47780 [02:41<00:05, 279.85 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47631/47780 [02:41<00:01, 89.28 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45921/47780 [02:41<00:04, 401.94 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46243/47780 [02:41<00:07, 205.05 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45317/47780 [02:41<00:06, 356.45 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45507/47780 [02:41<00:07, 301.10 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46813/47780 [02:41<00:08, 116.78 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46407/47780 [02:41<00:06, 226.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46341/47780 [02:41<00:05, 265.51 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45965/47780 [02:41<00:04, 391.16 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46265/47780 [02:41<00:07, 199.19 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45354/47780 [02:41<00:06, 350.59 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45538/47780 [02:41<00:07, 290.47 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46830/47780 [02:41<00:07, 125.54 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46431/47780 [02:41<00:06, 218.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46371/47780 [02:41<00:05, 273.89 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46286/47780 [02:41<00:07, 199.72 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45393/47780 [02:41<00:06, 357.25 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46007/47780 [02:41<00:04, 381.27 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47641/47780 [02:41<00:02, 61.44 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45571/47780 [02:41<00:07, 299.13 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46846/47780 [02:41<00:07, 132.25 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46402/47780 [02:41<00:04, 281.81 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46457/47780 [02:41<00:05, 222.25 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46307/47780 [02:41<00:07, 198.00 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46046/47780 [02:41<00:04, 373.24 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45430/47780 [02:41<00:07, 325.94 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45611/47780 [02:41<00:06, 325.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46864/47780 [02:41<00:06, 141.91 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46480/47780 [02:41<00:05, 221.57 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47649/47780 [02:41<00:02, 58.32 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46432/47780 [02:41<00:05, 268.74 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46333/47780 [02:41<00:06, 210.41 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46086/47780 [02:41<00:04, 367.27 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45466/47780 [02:41<00:07, 329.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45645/47780 [02:41<00:06, 315.47 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46465/47780 [02:41<00:04, 277.41 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47658/47780 [02:41<00:01, 61.09 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46503/47780 [02:41<00:06, 198.98 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46359/47780 [02:41<00:06, 220.35 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46124/47780 [02:41<00:04, 368.64 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46880/47780 [02:41<00:07, 120.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45503/47780 [02:41<00:06, 334.52 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45692/47780 [02:41<00:05, 353.25 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46493/47780 [02:41<00:05, 248.76 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46527/47780 [02:41<00:06, 198.87 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46382/47780 [02:41<00:06, 217.44 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46161/47780 [02:41<00:04, 365.82 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45542/47780 [02:41<00:06, 346.06 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46893/47780 [02:41<00:07, 116.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45731/47780 [02:41<00:05, 361.64 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47666/47780 [02:41<00:02, 53.23 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46405/47780 [02:41<00:06, 220.65 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46519/47780 [02:41<00:05, 245.49 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46199/47780 [02:41<00:04, 367.81 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46554/47780 [02:41<00:05, 207.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45577/47780 [02:41<00:06, 345.42 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45769/47780 [02:41<00:05, 354.99 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46907/47780 [02:41<00:08, 104.07 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46430/47780 [02:41<00:05, 226.51 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46552/47780 [02:41<00:04, 263.43 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47674/47780 [02:41<00:02, 52.67 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45624/47780 [02:41<00:05, 376.63 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46237/47780 [02:42<00:04, 346.54 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45805/47780 [02:41<00:05, 352.38 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46575/47780 [02:41<00:06, 191.43 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46920/47780 [02:42<00:07, 109.28 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46458/47780 [02:42<00:05, 237.45 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46592/47780 [02:42<00:03, 299.21 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45672/47780 [02:42<00:05, 401.31 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46279/47780 [02:42<00:04, 363.86 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47680/47780 [02:42<00:01, 52.34 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45841/47780 [02:42<00:05, 341.66 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46597/47780 [02:42<00:06, 190.21 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46932/47780 [02:42<00:07, 107.78 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46483/47780 [02:42<00:05, 237.48 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46623/47780 [02:42<00:04, 285.47 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45713/47780 [02:42<00:05, 393.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46316/47780 [02:42<00:04, 357.78 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46621/47780 [02:42<00:05, 203.10 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45877/47780 [02:42<00:06, 305.91 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47687/47780 [02:42<00:01, 48.31 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46508/47780 [02:42<00:05, 237.23 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46661/47780 [02:42<00:03, 310.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46356/47780 [02:42<00:03, 365.84 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46944/47780 [02:42<00:08, 101.60 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46645/47780 [02:42<00:05, 205.55 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45753/47780 [02:42<00:06, 326.49 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45913/47780 [02:42<00:05, 312.66 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46536/47780 [02:42<00:05, 239.95 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46695/47780 [02:42<00:03, 311.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46400/47780 [02:42<00:03, 386.81 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46955/47780 [02:42<00:08, 102.07 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47693/47780 [02:42<00:01, 44.64 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46666/47780 [02:42<00:05, 190.21 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45789/47780 [02:42<00:06, 325.37 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45945/47780 [02:42<00:06, 303.88 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46563/47780 [02:42<00:04, 248.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46439/47780 [02:42<00:03, 381.95 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46968/47780 [02:42<00:07, 107.31 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46727/47780 [02:42<00:03, 292.92 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47698/47780 [02:42<00:01, 42.67 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46596/47780 [02:42<00:04, 265.34 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46687/47780 [02:42<00:06, 179.69 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45979/47780 [02:42<00:06, 295.35 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46980/47780 [02:42<00:07, 108.95 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45823/47780 [02:42<00:06, 295.42 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46478/47780 [02:42<00:03, 359.95 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46757/47780 [02:42<00:03, 283.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46631/47780 [02:42<00:04, 286.36 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46011/47780 [02:42<00:05, 294.98 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47704/47780 [02:42<00:01, 41.36 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46708/47780 [02:42<00:06, 165.85 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46786/47780 [02:42<00:03, 273.84 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46515/47780 [02:42<00:03, 338.14 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46992/47780 [02:42<00:08, 97.55 examples/s] 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45854/47780 [02:42<00:07, 253.53 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46661/47780 [02:42<00:04, 272.38 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46041/47780 [02:42<00:06, 287.24 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46726/47780 [02:42<00:06, 168.01 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46553/47780 [02:42<00:03, 342.77 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47003/47780 [02:42<00:07, 100.50 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46814/47780 [02:42<00:03, 255.98 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47711/47780 [02:42<00:01, 40.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45881/47780 [02:42<00:07, 248.44 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46689/47780 [02:42<00:04, 267.59 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46073/47780 [02:42<00:05, 289.69 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46589/47780 [02:43<00:03, 342.16 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47016/47780 [02:42<00:07, 107.01 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46744/47780 [02:42<00:06, 151.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46840/47780 [02:43<00:03, 239.62 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46107/47780 [02:43<00:05, 298.23 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46716/47780 [02:43<00:04, 246.23 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45907/47780 [02:43<00:08, 216.88 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46634/47780 [02:43<00:03, 353.69 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47027/47780 [02:43<00:07, 106.58 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46767/47780 [02:43<00:05, 169.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47716/47780 [02:43<00:01, 34.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46866/47780 [02:43<00:03, 236.71 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46137/47780 [02:43<00:05, 281.81 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45931/47780 [02:43<00:08, 221.77 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46673/47780 [02:43<00:03, 360.54 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46743/47780 [02:43<00:04, 236.10 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47039/47780 [02:43<00:06, 108.58 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46788/47780 [02:43<00:05, 179.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47720/47780 [02:43<00:01, 35.00 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46893/47780 [02:43<00:03, 228.63 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46168/47780 [02:43<00:05, 287.70 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46768/47780 [02:43<00:04, 239.72 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45955/47780 [02:43<00:08, 217.39 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46719/47780 [02:43<00:02, 378.42 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47053/47780 [02:43<00:06, 111.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46807/47780 [02:43<00:05, 177.49 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47726/47780 [02:43<00:01, 37.55 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46917/47780 [02:43<00:03, 220.03 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46198/47780 [02:43<00:05, 280.99 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46799/47780 [02:43<00:03, 252.87 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45986/47780 [02:43<00:07, 236.34 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46758/47780 [02:43<00:02, 377.77 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47067/47780 [02:43<00:06, 114.57 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46826/47780 [02:43<00:05, 164.54 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46228/47780 [02:43<00:05, 274.49 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46941/47780 [02:43<00:03, 210.78 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47732/47780 [02:43<00:01, 39.22 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46826/47780 [02:43<00:03, 247.66 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46801/47780 [02:43<00:02, 378.78 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46014/47780 [02:43<00:07, 238.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47080/47780 [02:43<00:05, 118.61 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46846/47780 [02:43<00:05, 170.89 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46262/47780 [02:43<00:05, 289.34 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46964/47780 [02:43<00:03, 204.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46851/47780 [02:43<00:03, 237.06 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46039/47780 [02:43<00:07, 230.04 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47737/47780 [02:43<00:01, 37.71 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47104/47780 [02:43<00:04, 144.50 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46840/47780 [02:43<00:02, 332.13 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46867/47780 [02:43<00:05, 176.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46295/47780 [02:43<00:05, 296.09 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46985/47780 [02:43<00:04, 193.08 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46063/47780 [02:43<00:07, 223.18 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47122/47780 [02:43<00:04, 151.11 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46900/47780 [02:43<00:04, 217.78 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46876/47780 [02:43<00:04, 203.42 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46327/47780 [02:43<00:04, 297.70 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47741/47780 [02:43<00:01, 32.77 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46876/47780 [02:43<00:02, 301.36 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47007/47780 [02:43<00:03, 195.91 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46097/47780 [02:43<00:06, 252.28 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46898/47780 [02:43<00:04, 206.56 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47138/47780 [02:43<00:04, 135.38 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46360/47780 [02:43<00:04, 300.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46924/47780 [02:43<00:04, 192.10 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47031/47780 [02:43<00:03, 207.29 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46908/47780 [02:44<00:03, 279.32 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46127/47780 [02:43<00:06, 260.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47745/47780 [02:43<00:01, 29.48 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47152/47780 [02:44<00:04, 136.33 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46921/47780 [02:44<00:04, 196.52 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46392/47780 [02:44<00:05, 276.84 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46946/47780 [02:43<00:04, 187.27 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47054/47780 [02:44<00:03, 210.99 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46159/47780 [02:44<00:05, 271.90 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46939/47780 [02:44<00:03, 275.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47169/47780 [02:44<00:04, 135.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46942/47780 [02:44<00:04, 193.19 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46424/47780 [02:44<00:04, 278.39 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46196/47780 [02:44<00:05, 296.84 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47076/47780 [02:44<00:03, 201.13 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46966/47780 [02:44<00:04, 174.75 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46970/47780 [02:44<00:03, 252.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47750/47780 [02:44<00:01, 25.94 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47183/47780 [02:44<00:04, 130.53 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46969/47780 [02:44<00:03, 208.40 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47103/47780 [02:44<00:03, 212.17 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46227/47780 [02:44<00:05, 279.76 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46453/47780 [02:44<00:05, 257.34 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46997/47780 [02:44<00:03, 256.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46985/47780 [02:44<00:04, 159.92 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46991/47780 [02:44<00:03, 203.22 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47203/47780 [02:44<00:04, 139.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47134/47780 [02:44<00:02, 238.39 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47754/47780 [02:44<00:01, 25.71 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46260/47780 [02:44<00:05, 280.82 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46491/47780 [02:44<00:04, 278.74 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47026/47780 [02:44<00:02, 253.18 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47002/47780 [02:44<00:05, 149.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47219/47780 [02:44<00:03, 142.47 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47012/47780 [02:44<00:04, 180.68 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46542/47780 [02:44<00:03, 334.39 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46289/47780 [02:44<00:05, 273.42 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47058/47780 [02:44<00:02, 267.92 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47159/47780 [02:44<00:02, 210.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47758/47780 [02:44<00:00, 25.15 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47018/47780 [02:44<00:05, 150.14 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47238/47780 [02:44<00:03, 151.88 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47033/47780 [02:44<00:03, 187.77 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46322/47780 [02:44<00:05, 280.73 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47089/47780 [02:44<00:02, 262.83 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46577/47780 [02:44<00:04, 299.79 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47039/47780 [02:44<00:04, 160.32 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47762/47780 [02:44<00:00, 25.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47254/47780 [02:44<00:03, 139.57 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47181/47780 [02:44<00:03, 171.58 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47053/47780 [02:44<00:04, 176.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46358/47780 [02:44<00:04, 290.80 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47119/47780 [02:44<00:02, 265.39 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46609/47780 [02:44<00:04, 291.06 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47056/47780 [02:44<00:04, 161.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47766/47780 [02:44<00:00, 27.34 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47200/47780 [02:44<00:03, 170.77 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47271/47780 [02:44<00:03, 137.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46393/47780 [02:44<00:04, 299.09 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47073/47780 [02:44<00:04, 174.14 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47148/47780 [02:44<00:02, 266.80 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47074/47780 [02:44<00:04, 162.89 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46639/47780 [02:44<00:04, 257.79 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47285/47780 [02:44<00:03, 137.14 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47220/47780 [02:44<00:03, 167.71 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47092/47780 [02:44<00:03, 172.89 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47770/47780 [02:44<00:00, 26.86 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46423/47780 [02:44<00:04, 278.80 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47177/47780 [02:45<00:02, 262.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46670/47780 [02:45<00:04, 269.17 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47092/47780 [02:44<00:04, 149.52 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47239/47780 [02:45<00:03, 167.24 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46452/47780 [02:45<00:04, 278.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47110/47780 [02:45<00:03, 169.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47299/47780 [02:45<00:03, 124.04 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47204/47780 [02:45<00:02, 253.56 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [02:45<00:00, 26.88 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47109/47780 [02:45<00:04, 152.13 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46698/47780 [02:45<00:04, 252.88 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46480/47780 [02:45<00:04, 264.08 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47246/47780 [02:45<00:01, 297.38 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47128/47780 [02:45<00:04, 160.82 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47312/47780 [02:45<00:04, 114.84 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47258/47780 [02:45<00:03, 154.19 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47125/47780 [02:45<00:04, 150.26 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46729/47780 [02:45<00:04, 257.44 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47777/47780 [02:45<00:00, 23.61 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46513/47780 [02:45<00:04, 271.46 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47145/47780 [02:45<00:04, 152.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47285/47780 [02:45<00:02, 176.26 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47277/47780 [02:45<00:01, 273.55 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47326/47780 [02:45<00:03, 113.53 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47141/47780 [02:45<00:04, 150.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46768/47780 [02:45<00:03, 290.80 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46542/47780 [02:45<00:04, 271.03 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47175/47780 [02:45<00:03, 184.50 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47305/47780 [02:45<00:01, 259.81 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47160/47780 [02:45<00:03, 157.31 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47351/47780 [02:45<00:03, 141.87 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47305/47780 [02:45<00:02, 168.94 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46798/47780 [02:45<00:03, 291.45 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47196/47780 [02:45<00:03, 185.97 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46570/47780 [02:45<00:05, 238.45 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47323/47780 [02:45<00:02, 169.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47366/47780 [02:45<00:02, 138.55 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47334/47780 [02:45<00:01, 240.65 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46829/47780 [02:45<00:03, 272.90 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47177/47780 [02:45<00:04, 141.51 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47216/47780 [02:45<00:03, 173.98 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47341/47780 [02:45<00:02, 162.97 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46596/47780 [02:45<00:05, 229.30 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47381/47780 [02:45<00:02, 135.16 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46857/47780 [02:45<00:03, 269.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47193/47780 [02:45<00:04, 143.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47360/47780 [02:45<00:02, 208.77 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47398/47780 [02:45<00:02, 141.62 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46625/47780 [02:45<00:04, 234.84 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47359/47780 [02:45<00:02, 157.10 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46885/47780 [02:45<00:03, 265.31 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47213/47780 [02:45<00:03, 152.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47235/47780 [02:45<00:03, 157.74 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47414/47780 [02:45<00:02, 146.30 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47385/47780 [02:46<00:01, 198.52 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46650/47780 [02:45<00:04, 234.48 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46918/47780 [02:45<00:03, 279.86 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47378/47780 [02:45<00:02, 160.27 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47230/47780 [02:45<00:03, 156.51 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47252/47780 [02:46<00:03, 148.01 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47408/47780 [02:46<00:01, 200.55 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46676/47780 [02:46<00:04, 236.34 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47253/47780 [02:45<00:03, 173.75 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46947/47780 [02:46<00:03, 267.90 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47429/47780 [02:46<00:02, 121.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47395/47780 [02:46<00:02, 141.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47269/47780 [02:46<00:03, 134.65 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46705/47780 [02:46<00:04, 241.98 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47431/47780 [02:46<00:01, 197.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47272/47780 [02:46<00:02, 170.68 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46981/47780 [02:46<00:02, 278.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47442/47780 [02:46<00:02, 121.15 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47284/47780 [02:46<00:03, 130.42 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47014/47780 [02:46<00:02, 291.03 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46731/47780 [02:46<00:04, 226.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47454/47780 [02:46<00:01, 183.70 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47291/47780 [02:46<00:03, 156.75 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47410/47780 [02:46<00:03, 108.50 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47455/47780 [02:46<00:02, 112.59 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47298/47780 [02:46<00:03, 127.04 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47044/47780 [02:46<00:02, 283.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46756/47780 [02:46<00:04, 228.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47307/47780 [02:46<00:03, 153.33 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47474/47780 [02:46<00:01, 175.90 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47423/47780 [02:46<00:03, 105.37 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47312/47780 [02:46<00:03, 129.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47468/47780 [02:46<00:03, 102.17 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46781/47780 [02:46<00:04, 215.94 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47073/47780 [02:46<00:02, 251.42 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47323/47780 [02:46<00:03, 142.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47496/47780 [02:46<00:01, 176.06 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47436/47780 [02:46<00:03, 108.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47482/47780 [02:46<00:02, 109.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47326/47780 [02:46<00:03, 121.59 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46803/47780 [02:46<00:04, 212.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47103/47780 [02:46<00:02, 262.46 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47338/47780 [02:46<00:03, 137.50 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47448/47780 [02:46<00:03, 107.61 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47499/47780 [02:46<00:02, 117.55 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47342/47780 [02:46<00:03, 128.65 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47135/47780 [02:46<00:02, 268.59 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47515/47780 [02:46<00:01, 140.25 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46825/47780 [02:46<00:05, 189.69 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47352/47780 [02:46<00:03, 134.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47462/47780 [02:46<00:02, 115.21 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47519/47780 [02:46<00:01, 136.08 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47358/47780 [02:46<00:03, 129.37 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47165/47780 [02:46<00:02, 272.18 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46856/47780 [02:46<00:04, 220.12 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47367/47780 [02:46<00:03, 135.63 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47475/47780 [02:46<00:02, 115.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47531/47780 [02:47<00:01, 131.12 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47195/47780 [02:46<00:02, 271.98 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47373/47780 [02:47<00:03, 124.57 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46880/47780 [02:46<00:04, 223.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47383/47780 [02:46<00:02, 136.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47535/47780 [02:47<00:02, 117.32 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47545/47780 [02:47<00:01, 124.84 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47488/47780 [02:47<00:02, 102.51 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47225/47780 [02:47<00:02, 277.49 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46905/47780 [02:47<00:04, 215.83 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47389/47780 [02:47<00:03, 123.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47402/47780 [02:47<00:02, 147.37 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47549/47780 [02:47<00:02, 114.74 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47499/47780 [02:47<00:02, 103.72 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47253/47780 [02:47<00:01, 275.20 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47562/47780 [02:47<00:01, 119.94 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46929/47780 [02:47<00:03, 216.29 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47418/47780 [02:47<00:02, 136.99 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47563/47780 [02:47<00:01, 115.74 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47402/47780 [02:47<00:03, 109.29 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47283/47780 [02:47<00:01, 278.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47511/47780 [02:47<00:02, 100.37 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46955/47780 [02:47<00:03, 216.02 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47576/47780 [02:47<00:01, 113.70 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47311/47780 [02:47<00:01, 265.53 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47522/47780 [02:47<00:02, 102.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47433/47780 [02:47<00:02, 125.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47576/47780 [02:47<00:01, 107.04 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47414/47780 [02:47<00:03, 98.63 examples/s] 
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46982/47780 [02:47<00:03, 225.76 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47588/47780 [02:47<00:01, 108.88 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47533/47780 [02:47<00:02, 102.86 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47450/47780 [02:47<00:02, 133.85 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47588/47780 [02:47<00:01, 101.86 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47338/47780 [02:47<00:01, 231.86 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47427/47780 [02:47<00:03, 99.49 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47007/47780 [02:47<00:03, 227.24 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47547/47780 [02:47<00:02, 108.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47465/47780 [02:47<00:02, 130.58 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47599/47780 [02:47<00:01, 100.02 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47031/47780 [02:47<00:03, 218.48 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47440/47780 [02:47<00:03, 101.21 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47362/47780 [02:47<00:02, 207.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47600/47780 [02:47<00:02, 84.40 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47566/47780 [02:47<00:01, 124.74 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47480/47780 [02:47<00:02, 131.68 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47610/47780 [02:47<00:01, 98.78 examples/s] 
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47062/47780 [02:47<00:02, 239.65 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47454/47780 [02:47<00:03, 105.64 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47615/47780 [02:47<00:01, 94.44 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47384/47780 [02:47<00:02, 190.82 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47581/47780 [02:47<00:01, 129.28 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47088/47780 [02:47<00:02, 244.66 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47620/47780 [02:47<00:01, 95.20 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47468/47780 [02:47<00:02, 112.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47495/47780 [02:47<00:02, 114.16 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47404/47780 [02:47<00:02, 182.65 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47117/47780 [02:48<00:02, 245.89 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47632/47780 [02:48<00:01, 97.55 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47626/47780 [02:48<00:01, 81.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47594/47780 [02:48<00:01, 105.07 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47480/47780 [02:48<00:02, 103.64 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47508/47780 [02:48<00:02, 103.69 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47148/47780 [02:48<00:02, 260.91 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47423/47780 [02:48<00:02, 164.44 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47644/47780 [02:48<00:01, 98.00 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47606/47780 [02:48<00:01, 100.34 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47493/47780 [02:48<00:02, 104.18 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47635/47780 [02:48<00:01, 72.72 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47175/47780 [02:48<00:02, 260.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47655/47780 [02:48<00:01, 100.88 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47440/47780 [02:48<00:02, 159.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47520/47780 [02:48<00:02, 93.19 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47620/47780 [02:48<00:01, 100.99 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47504/47780 [02:48<00:02, 96.77 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47202/47780 [02:48<00:02, 250.48 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47643/47780 [02:48<00:02, 68.42 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47458/47780 [02:48<00:02, 158.97 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47667/47780 [02:48<00:01, 91.63 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47631/47780 [02:48<00:01, 99.21 examples/s] 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47229/47780 [02:48<00:02, 255.77 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47531/47780 [02:48<00:03, 75.65 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47515/47780 [02:48<00:03, 83.82 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47477/47780 [02:48<00:02, 150.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47652/47780 [02:48<00:02, 61.22 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47677/47780 [02:48<00:01, 79.91 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47643/47780 [02:48<00:01, 94.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47255/47780 [02:48<00:02, 234.67 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47524/47780 [02:48<00:03, 84.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47502/47780 [02:48<00:01, 174.87 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47541/47780 [02:48<00:03, 67.98 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47280/47780 [02:48<00:02, 226.91 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47657/47780 [02:48<00:01, 96.78 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47521/47780 [02:48<00:01, 169.47 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47534/47780 [02:48<00:03, 80.63 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47688/47780 [02:48<00:01, 73.04 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47303/47780 [02:48<00:02, 226.35 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47549/47780 [02:48<00:03, 63.76 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47668/47780 [02:48<00:01, 96.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47540/47780 [02:48<00:01, 173.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47545/47780 [02:48<00:02, 82.59 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47660/47780 [02:48<00:02, 43.40 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47330/47780 [02:48<00:02, 222.90 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47697/47780 [02:48<00:01, 64.83 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47679/47780 [02:48<00:01, 95.47 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47563/47780 [02:48<00:01, 178.76 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47556/47780 [02:48<00:03, 59.54 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47554/47780 [02:48<00:02, 82.80 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47353/47780 [02:49<00:01, 224.28 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47706/47780 [02:49<00:01, 68.03 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47689/47780 [02:49<00:00, 95.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47589/47780 [02:49<00:00, 198.35 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47668/47780 [02:49<00:02, 42.23 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47564/47780 [02:49<00:02, 79.69 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47565/47780 [02:49<00:03, 58.56 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47377/47780 [02:49<00:01, 208.35 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47714/47780 [02:49<00:00, 67.53 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47700/47780 [02:49<00:00, 93.06 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47612/47780 [02:49<00:00, 186.08 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47571/47780 [02:49<00:03, 58.29 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47673/47780 [02:49<00:02, 39.96 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47575/47780 [02:49<00:02, 79.92 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47399/47780 [02:49<00:01, 211.13 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47722/47780 [02:49<00:00, 64.58 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47710/47780 [02:49<00:00, 82.58 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47577/47780 [02:49<00:03, 54.62 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47678/47780 [02:49<00:02, 39.32 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47633/47780 [02:49<00:00, 158.02 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47587/47780 [02:49<00:02, 80.74 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47730/47780 [02:49<00:00, 64.20 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47422/47780 [02:49<00:02, 174.96 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47721/47780 [02:49<00:00, 85.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47583/47780 [02:49<00:03, 54.84 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47650/47780 [02:49<00:00, 154.77 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47687/47780 [02:49<00:02, 44.20 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47597/47780 [02:49<00:02, 73.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47731/47780 [02:49<00:00, 83.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47668/47780 [02:49<00:00, 154.62 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47595/47780 [02:49<00:02, 65.02 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47737/47780 [02:49<00:00, 54.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47442/47780 [02:49<00:02, 139.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47605/47780 [02:49<00:02, 69.64 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47685/47780 [02:49<00:00, 153.27 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47608/47780 [02:49<00:02, 78.65 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47693/47780 [02:49<00:02, 38.80 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47460/47780 [02:49<00:02, 144.89 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47741/47780 [02:49<00:00, 68.96 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47743/47780 [02:49<00:00, 45.26 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47614/47780 [02:49<00:02, 69.24 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47703/47780 [02:49<00:00, 149.78 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47618/47780 [02:49<00:02, 71.88 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47476/47780 [02:49<00:02, 140.79 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47622/47780 [02:49<00:02, 71.15 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47720/47780 [02:49<00:00, 146.14 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47749/47780 [02:50<00:00, 55.77 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47749/47780 [02:50<00:00, 40.07 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47631/47780 [02:50<00:02, 73.06 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47493/47780 [02:50<00:02, 131.37 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47699/47780 [02:50<00:02, 30.24 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47626/47780 [02:50<00:02, 51.68 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47639/47780 [02:50<00:02, 69.12 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47509/47780 [02:50<00:02, 126.73 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47736/47780 [02:50<00:00, 110.06 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [02:50<00:00, 48.32 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47755/47780 [02:50<00:00, 35.72 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47704/47780 [02:50<00:02, 28.86 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47647/47780 [02:50<00:01, 68.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47523/47780 [02:50<00:02, 126.72 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47711/47780 [02:50<00:02, 34.15 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47759/47780 [02:50<00:00, 32.23 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47763/47780 [02:50<00:00, 44.14 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47654/47780 [02:50<00:01, 64.59 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47537/47780 [02:50<00:02, 118.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47634/47780 [02:50<00:03, 43.15 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47764/47780 [02:50<00:00, 33.74 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47551/47780 [02:50<00:01, 123.13 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47665/47780 [02:50<00:01, 71.06 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47715/47780 [02:50<00:02, 31.43 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47768/47780 [02:50<00:00, 41.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47720/47780 [02:50<00:01, 33.89 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47768/47780 [02:50<00:00, 32.83 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47564/47780 [02:50<00:01, 111.93 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47674/47780 [02:50<00:01, 68.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47644/47780 [02:50<00:03, 40.93 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47750/47780 [02:50<00:00, 57.84 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47725/47780 [02:50<00:01, 35.43 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47683/47780 [02:50<00:01, 71.81 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47577/47780 [02:50<00:01, 110.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47772/47780 [02:50<00:00, 31.23 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47734/47780 [02:50<00:01, 45.71 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47650/47780 [02:50<00:03, 37.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47590/47780 [02:50<00:01, 102.60 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47742/47780 [02:51<00:00, 50.46 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47693/47780 [02:51<00:01, 56.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47601/47780 [02:51<00:01, 100.25 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47760/47780 [02:51<00:00, 49.76 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47656/47780 [02:51<00:03, 36.23 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47615/47780 [02:51<00:01, 100.53 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47701/47780 [02:51<00:01, 53.19 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47661/47780 [02:51<00:03, 36.61 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47750/47780 [02:51<00:00, 44.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47626/47780 [02:51<00:01, 97.84 examples/s] 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47768/47780 [02:51<00:00, 43.67 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47755/47780 [02:51<00:00, 42.43 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47666/47780 [02:51<00:03, 35.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47708/47780 [02:51<00:01, 44.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47636/47780 [02:51<00:01, 83.72 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47762/47780 [02:51<00:00, 45.36 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47670/47780 [02:51<00:03, 33.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47714/47780 [02:51<00:01, 46.81 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47674/47780 [02:51<00:03, 31.22 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47646/47780 [02:51<00:01, 68.88 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47720/47780 [02:51<00:01, 42.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47654/47780 [02:51<00:01, 70.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47678/47780 [02:51<00:03, 29.72 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47727/47780 [02:51<00:01, 40.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47662/47780 [02:51<00:01, 64.17 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47682/47780 [02:51<00:03, 26.31 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47674/47780 [02:52<00:01, 75.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47732/47780 [02:52<00:01, 35.69 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47686/47780 [02:52<00:03, 26.23 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47688/47780 [02:52<00:01, 88.35 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47738/47780 [02:52<00:01, 36.09 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47690/47780 [02:52<00:03, 26.72 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47698/47780 [02:52<00:01, 81.14 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47742/47780 [02:52<00:01, 35.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47694/47780 [02:52<00:03, 28.12 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47708/47780 [02:52<00:01, 70.94 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47746/47780 [02:52<00:01, 33.65 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47700/47780 [02:52<00:02, 33.53 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47716/47780 [02:52<00:00, 68.03 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47750/47780 [02:52<00:00, 32.39 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47706/47780 [02:52<00:01, 37.41 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47755/47780 [02:52<00:00, 33.49 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47725/47780 [02:52<00:00, 62.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47712/47780 [02:52<00:01, 39.37 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47759/47780 [02:52<00:00, 32.87 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47718/47780 [02:52<00:01, 40.07 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47733/47780 [02:53<00:00, 53.75 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47764/47780 [02:53<00:00, 36.31 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47724/47780 [02:53<00:01, 42.82 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47768/47780 [02:53<00:01, 10.83 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47769/47780 [02:53<00:00, 36.42 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47730/47780 [02:53<00:01, 46.13 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47740/47780 [02:53<00:00, 45.66 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47736/47780 [02:53<00:00, 44.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47746/47780 [02:53<00:00, 38.60 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47742/47780 [02:53<00:01, 37.56 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47752/47780 [02:53<00:00, 36.08 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47748/47780 [02:53<00:01, 31.99 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [02:53<00:00, 34.59 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47760/47780 [02:53<00:00, 34.95 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47752/47780 [02:53<00:00, 31.13 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47764/47780 [02:54<00:00, 33.81 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [02:54<00:00, 30.91 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47768/47780 [02:54<00:00, 33.43 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47760/47780 [02:54<00:00, 30.89 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47764/47780 [02:54<00:00, 32.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47768/47780 [02:54<00:00, 31.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47772/47780 [02:54<00:00, 32.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47773/47780 [02:54<00:00,  8.17 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [02:56<00:00,  5.49 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [02:57<00:00,  1.10s/ examples]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [02:58<00:00, 268.18 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:27, 1702.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):   6%|▋         | 3000/47780 [00:00<00:08, 5055.82 examples/s]
Truncating train dataset (num_proc=32):  48%|████▊     | 22988/47780 [00:00<00:00, 45471.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47773/47780 [02:59<00:02,  2.44 examples/s]
Truncating train dataset (num_proc=32):  85%|████████▍ | 40385/47780 [00:00<00:00, 74767.23 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47772/47780 [02:59<00:03,  2.53 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47775/47780 [03:01<00:02,  2.10 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47777/47780 [03:02<00:01,  2.39 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [03:02<00:00,  2.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [03:02<00:03,  1.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47777/47780 [03:02<00:02,  1.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [03:03<00:02,  1.42 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47775/47780 [03:03<00:02,  1.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [03:03<00:00,  1.52 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [03:03<00:00,  2.99 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [03:03<00:00,  2.19 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00,  1.32 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00,  1.52 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00, 257.88 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00,  1.71 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00,  2.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00, 257.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00, 257.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00, 256.99 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:06<00:00,  2.59 examples/s]
Truncating train dataset (num_proc=32):   6%|▌         | 2986/47780 [00:00<?, ? examples/s]
Truncating train dataset (num_proc=32):   6%|▌         | 2986/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):   6%|▌         | 2986/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:06<00:00, 256.28 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:46, 1010.06 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  15%|█▍        | 7000/47780 [00:01<00:04, 8384.84 examples/s]
Truncating train dataset (num_proc=32):  71%|███████   | 33975/47780 [00:01<00:00, 47278.02 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  28%|██▊       | 13438/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  99%|█████████▉| 47287/47780 [00:01<00:00, 49559.53 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:07<00:00, 255.27 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Truncating train dataset (num_proc=32):   8%|▊         | 3986/47780 [00:01<00:56, 781.09 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  31%|███       | 14931/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:08<00:00, 254.07 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  10%|█         | 4986/47780 [00:02<00:42, 1010.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  13%|█▎        | 5986/47780 [00:02<00:25, 1661.32 examples/s]
Truncating train dataset (num_proc=32):  16%|█▌        | 7480/47780 [00:02<00:16, 2416.93 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):   8%|▊         | 3986/47780 [00:02<01:52, 388.55 examples/s]
Truncating train dataset (num_proc=32):  17%|█▋        | 7986/47780 [00:02<00:16, 2461.44 examples/s]
Truncating train dataset (num_proc=32):  24%|██▍       | 11480/47780 [00:02<00:05, 6184.55 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):   8%|▊         | 3986/47780 [00:02<01:55, 378.17 examples/s]
Truncating train dataset (num_proc=32):  34%|███▍      | 16480/47780 [00:02<00:02, 11694.04 examples/s]
Truncating train dataset (num_proc=32):  27%|██▋       | 12986/47780 [00:02<00:06, 5740.03 examples/s]
Truncating train dataset (num_proc=32):  15%|█▍        | 6986/47780 [00:02<00:21, 1880.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  30%|███       | 14438/47780 [00:02<01:15, 440.34 examples/s]
Truncating train dataset (num_proc=32):  48%|████▊     | 22986/47780 [00:02<00:01, 14223.80 examples/s]
Truncating train dataset (num_proc=32):  55%|█████▌    | 26468/47780 [00:02<00:00, 24892.16 examples/s]
Truncating train dataset (num_proc=32):  37%|███▋      | 17917/47780 [00:00<?, ? examples/s]
Truncating train dataset (num_proc=32):  31%|███▏      | 14986/47780 [00:02<00:04, 7005.54 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  45%|████▍     | 21438/47780 [00:02<00:05, 4544.23 examples/s]
Truncating train dataset (num_proc=32):  61%|██████    | 28986/47780 [00:03<00:00, 19143.00 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  69%|██████▉   | 32961/47780 [00:02<00:00, 30921.58 examples/s]
Truncating train dataset (num_proc=32):  57%|█████▋    | 27438/47780 [00:02<00:02, 8038.64 examples/s]
Truncating train dataset (num_proc=32):  42%|████▏     | 19986/47780 [00:03<00:02, 9445.22 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  73%|███████▎  | 34945/47780 [00:03<00:00, 20055.53 examples/s]
Truncating train dataset (num_proc=32):  74%|███████▍  | 35438/47780 [00:02<00:00, 14542.54 examples/s]
Truncating train dataset (num_proc=32):  65%|██████▍   | 30972/47780 [00:03<00:00, 18850.57 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  80%|████████  | 38399/47780 [00:03<00:00, 24028.33 examples/s]
Truncating train dataset (num_proc=32):  83%|████████▎ | 39877/47780 [00:03<00:00, 22046.40 examples/s]
Truncating train dataset (num_proc=32):  76%|███████▌  | 36411/47780 [00:03<00:00, 22905.05 examples/s]
Truncating train dataset (num_proc=32):  86%|████████▌ | 40877/47780 [00:02<00:00, 18151.20 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  93%|█████████▎| 44315/47780 [00:03<00:00, 29506.34 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  40%|███▉      | 18917/47780 [00:00<00:22, 1271.98 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  53%|█████▎    | 25411/47780 [00:00<00:02, 10976.16 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  85%|████████▌ | 40849/47780 [00:00<00:00, 36541.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:15<00:00, 74767.23 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:17<00:00, 1832.08 examples/s] 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:17<00:00, 2764.14 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m [2025-08-02 19:28:12,804] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m df: /root/.triton/autotune: No such file or directory
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  33%|███▎      | 15931/47780 [00:13<07:01, 75.58 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  69%|██████▉   | 32931/47780 [00:14<00:08, 1737.88 examples/s]
Truncating train dataset (num_proc=32):  94%|█████████▍| 44794/47780 [00:16<00:00, 22905.05 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  95%|█████████▍| 45315/47780 [00:15<00:00, 2950.45 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  97%|█████████▋| 46287/47780 [00:17<00:00, 29506.34 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:18<00:00, 49559.53 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:17<00:00, 18151.20 examples/s]
Truncating train dataset (num_proc=32):  94%|█████████▍| 44794/47780 [00:14<00:00, 36541.73 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  97%|█████████▋| 46287/47780 [00:18<00:00, 22046.40 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  98%|█████████▊| 46794/47780 [00:18<00:00, 2222.48 examples/s]
Truncating train dataset (num_proc=32):  94%|█████████▍| 44794/47780 [00:18<00:02, 1012.51 examples/s] 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:22<00:00, 1164.47 examples/s] 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:23<00:00, 1281.38 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  97%|█████████▋| 46287/47780 [00:25<00:02, 655.51 examples/s]  [2025-08-02 19:28:29,602] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:28<00:00, 700.83 examples/s]  
Truncating train dataset (num_proc=32):  97%|█████████▋| 46287/47780 [00:29<00:02, 694.38 examples/s]  
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Truncating train dataset (num_proc=32):  94%|█████████▍| 44794/47780 [00:29<00:03, 811.61 examples/s]  
Truncating train dataset (num_proc=32):  94%|█████████▍| 44794/47780 [00:26<00:02, 997.90 examples/s] 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m [2025-08-02 19:28:32,863] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m [2025-08-02 19:28:35,215] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:33<00:00, 1020.36 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Truncating train dataset (num_proc=32):  94%|█████████▍| 44794/47780 [00:34<00:02, 1212.77 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Truncating train dataset (num_proc=32):  97%|█████████▋| 46287/47780 [00:34<00:01, 1250.11 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Truncating train dataset (num_proc=32):  97%|█████████▋| 46287/47780 [00:34<00:01, 1239.21 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m [2025-08-02 19:28:37,228] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m [2025-08-02 19:28:37,714] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:36<00:00, 1318.35 examples/s]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m [2025-08-02 19:28:37,897] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m [2025-08-02 19:28:38,202] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m [2025-08-02 19:28:38,563] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m [2025-08-02 19:28:38,840] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m [2025-08-02 19:28:39,091] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m [2025-08-02 19:28:39,457] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:35<00:00, 917.68 examples/s] 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m [2025-08-02 19:28:39,795] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m [2025-08-02 19:28:40,340] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m [2025-08-02 19:28:40,342] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m [2025-08-02 19:28:41,550] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m   0%|          | 0/10 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3447)[0m  10%|█         | 1/10 [00:45<06:48, 45.41s/it]
[36m(head, rank=0, pid=3447)[0m  20%|██        | 2/10 [01:25<05:36, 42.03s/it]
[36m(head, rank=0, pid=3447)[0m  30%|███       | 3/10 [02:04<04:45, 40.74s/it]
[36m(head, rank=0, pid=3447)[0m  40%|████      | 4/10 [02:43<04:01, 40.21s/it]
[36m(head, rank=0, pid=3447)[0m  50%|█████     | 5/10 [03:23<03:20, 40.08s/it]
[36m(head, rank=0, pid=3447)[0m  60%|██████    | 6/10 [04:01<02:37, 39.44s/it]
[36m(head, rank=0, pid=3447)[0m  70%|███████   | 7/10 [04:41<01:58, 39.44s/it]
[36m(head, rank=0, pid=3447)[0m  80%|████████  | 8/10 [05:20<01:19, 39.53s/it]
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3447)[0m  90%|█████████ | 9/10 [05:59<00:39, 39.18s/it]
100%|██████████| 10/10 [06:36<00:00, 38.47s/it]Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3447)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3447)[0m 
                                               
{'loss': 124.4492, 'grad_norm': 35.656002044677734, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3447)[0m 
100%|██████████| 10/10 [06:36<00:00, 38.47s/it]Starting Save checkpoint...
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Save checkpoint in 181.29 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint save time: 181.29s (Total: 181.29s)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Save checkpoint in 181.29 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint save time: 181.29s (Total: 181.29s)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Save checkpoint in 181.29 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Save checkpoint in 181.29 secondsCheckpoint save time: 181.29s (Total: 181.29s)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint save time: 181.29s (Total: 181.29s)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Save checkpoint in 181.29 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint save time: 181.29s (Total: 181.29s)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Save checkpoint in 181.29 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint save time: 181.29s (Total: 181.29s)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Save checkpoint in 181.29 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint save time: 181.29s (Total: 181.29s)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Save checkpoint in 181.29 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint save time: 181.29s (Total: 181.29s)
[36m(head, rank=0, pid=3447)[0m Completed Save checkpoint in 181.29 seconds
[36m(head, rank=0, pid=3447)[0m Completed Save checkpoint in 181.29 seconds
[36m(head, rank=0, pid=3447)[0m Checkpoint save time: 181.29s (Total: 181.29s)
[36m(head, rank=0, pid=3447)[0m Checkpoint save time: 181.29s (Total: 181.29s)
[36m(head, rank=0, pid=3447)[0m Completed Save checkpoint in 181.29 seconds
[36m(head, rank=0, pid=3447)[0m Checkpoint save time: 181.29s (Total: 181.29s)
[36m(head, rank=0, pid=3447)[0m Completed Save checkpoint in 181.29 seconds
[36m(head, rank=0, pid=3447)[0m Checkpoint save time: 181.29s (Total: 181.29s)
[36m(head, rank=0, pid=3447)[0m Completed Save checkpoint in 181.29 seconds
[36m(head, rank=0, pid=3447)[0m Checkpoint save time: 181.29s (Total: 181.29s)
[36m(head, rank=0, pid=3447)[0m Completed Save checkpoint in 181.29 seconds
[36m(head, rank=0, pid=3447)[0m Checkpoint save time: 181.29s (Total: 181.29s)
[36m(head, rank=0, pid=3447)[0m Completed Save checkpoint in 181.29 seconds
[36m(head, rank=0, pid=3447)[0m Checkpoint save time: 181.29s (Total: 181.29s)
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Training in 1066.78 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total checkpoint save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average save time per checkpoint: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total training step time: 356.03s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average training step time: 4.45s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min training step time: 3.67s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max training step time: 9.28s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Training in 1047.42 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total checkpoint save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average save time per checkpoint: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total batch sample time: 0.39s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max batch sample time: 0.12s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total training step time: 355.39s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average training step time: 4.44s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min training step time: 3.67s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max training step time: 8.00s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Training in 1066.24 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Training in 1066.24 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Saved training info to: /tmp/checkpoint/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Training in 1066.29 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total checkpoint save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Training in 1066.24 seconds  - Average save time per checkpoint: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total batch sample time: 0.40s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min batch sample time: 0.02s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max batch sample time: 0.13s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total training step time: 356.82s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average training step time: 4.46s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min training step time: 3.67s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max training step time: 9.23s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total checkpoint save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average save time per checkpoint: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min batch sample time: 0.02s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total training step time: 356.75s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average training step time: 4.46s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min training step time: 3.67s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max training step time: 9.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint Save Statistics:  - Total checkpoint save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average save time per checkpoint: 181.29s  - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total checkpoint save time: 181.29s  - Max save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average save time per checkpoint: 181.29sBatch Sampling Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min save time: 181.29s  - Number of batch samples: 10
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total batch sample time: 0.38s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max batch sample time: 0.12s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total batch sample time: 0.35s  - Total training step time: 356.44s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average training step time: 4.46s  - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min training step time: 3.67s  - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max training step time: 9.25s  - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training Step Performance:Training completed successfully for run 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total training step time: 356.66s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average training step time: 4.46s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min training step time: 3.67s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max training step time: 9.28s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Training in 1066.24 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total checkpoint save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average save time per checkpoint: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total training step time: 356.48s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average training step time: 4.46s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min training step time: 3.67s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max training step time: 9.28s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed Training in 1066.70 seconds
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Saved training info to: /tmp/checkpoint/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total checkpoint save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average save time per checkpoint: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max batch sample time: 0.09s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Total training step time: 356.47s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Average training step time: 4.46s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Min training step time: 3.67s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   - Max training step time: 9.27s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Saved training info to: /tmp/checkpoint/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Saved training info to: /tmp/checkpoint/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Saved training info to: /tmp/checkpoint/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Saved training info to: /tmp/checkpoint/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Saved training info to: /tmp/checkpoint/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Saved training info to: /tmp/checkpoint/training_run_6_1_info.json
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m ================================================================================
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m ================================================================================
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Average time: 2.30s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Min time: 2.30s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Max time: 2.30s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Total time: 2.30s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Average time: 20.09s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Min time: 20.09s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Max time: 20.09s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Total time: 20.09s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Average time: 1047.42s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Min time: 1047.42s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Max time: 1047.42s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Total time: 1047.42s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Average step time per step: 4.44s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Min step time: 3.67s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Max step time: 8.00s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Total training step time: 355.39s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Max sample time: 0.12s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Total batch sample time: 0.39s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Average save time per checkpoint: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Min save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Max save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Total checkpoint save time: 181.29s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Average total time per run: 1069.81s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Min total time: 1069.81s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Max total time: 1069.81s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Total time across all runs: 1069.81s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m ================================================================================
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3447)[0m Completed Save checkpoint in 312.70 seconds
[36m(head, rank=0, pid=3447)[0m Checkpoint save time: 312.70s (Total: 312.70s)
[36m(head, rank=0, pid=3447)[0m 
                                               
{'train_runtime': 708.907, 'train_samples_per_second': 1.806, 'train_steps_per_second': 0.014, 'train_loss': 124.44921875, 'epoch': 0.03}
[36m(head, rank=0, pid=3447)[0m 
100%|██████████| 10/10 [11:48<00:00, 38.47s/it]
100%|██████████| 10/10 [11:48<00:00, 70.89s/it]
[36m(head, rank=0, pid=3447)[0m Completed Training in 1047.75 seconds
[36m(head, rank=0, pid=3447)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3447)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3447)[0m   - Total checkpoint save time: 312.70s
[36m(head, rank=0, pid=3447)[0m   - Average save time per checkpoint: 312.70s
[36m(head, rank=0, pid=3447)[0m   - Min save time: 312.70s
[36m(head, rank=0, pid=3447)[0m   - Max save time: 312.70s
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3447)[0m   - Total batch sample time: 0.35s
[36m(head, rank=0, pid=3447)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3447)[0m   - Total training step time: 355.83s
[36m(head, rank=0, pid=3447)[0m   - Average training step time: 4.45s
[36m(head, rank=0, pid=3447)[0m   - Min training step time: 3.67s
[36m(head, rank=0, pid=3447)[0m   - Max training step time: 8.19s
[36m(head, rank=0, pid=3447)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3447)[0m Saved training info to: /tmp/checkpoint/training_run_0_1_info.json
[36m(head, rank=0, pid=3447)[0m Completed run 1/1
[36m(head, rank=0, pid=3447)[0m Completed Training in 1066.33 seconds
[36m(head, rank=0, pid=3447)[0m Checkpoint Save Statistics:Completed Training in 1066.34 seconds
[36m(head, rank=0, pid=3447)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m   - Total checkpoint save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Average save time per checkpoint: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Min save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Max save time: 181.29s
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3447)[0m   - Total batch sample time: 0.33s
[36m(head, rank=0, pid=3447)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   - Max batch sample time: 0.06s
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3447)[0m   - Total training step time: 356.05s
[36m(head, rank=0, pid=3447)[0m   - Average training step time: 4.45s
[36m(head, rank=0, pid=3447)[0m   - Min training step time: 3.67s
[36m(head, rank=0, pid=3447)[0m   - Max training step time: 9.31s
[36m(head, rank=0, pid=3447)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3447)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3447)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3447)[0m   - Total checkpoint save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Average save time per checkpoint: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Min save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Max save time: 181.29s
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3447)[0m   - Total batch sample time: 0.34s
[36m(head, rank=0, pid=3447)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3447)[0m   - Total training step time: 356.96s
[36m(head, rank=0, pid=3447)[0m   - Average training step time: 4.46s
[36m(head, rank=0, pid=3447)[0m   - Min training step time: 3.67s
[36m(head, rank=0, pid=3447)[0m   - Max training step time: 9.31s
[36m(head, rank=0, pid=3447)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3447)[0m Completed Training in 1066.42 seconds
[36m(head, rank=0, pid=3447)[0m Completed Training in 1066.33 seconds
[36m(head, rank=0, pid=3447)[0m Completed Training in 1066.46 seconds
[36m(head, rank=0, pid=3447)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3447)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3447)[0m   - Total checkpoint save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Average save time per checkpoint: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Min save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Max save time: 181.29s
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3447)[0m   - Total batch sample time: 0.34s
[36m(head, rank=0, pid=3447)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3447)[0m   - Total training step time: 356.49s
[36m(head, rank=0, pid=3447)[0m   - Average training step time: 4.46s
[36m(head, rank=0, pid=3447)[0m   - Min training step time: 3.67s
[36m(head, rank=0, pid=3447)[0m   - Max training step time: 9.30s
[36m(head, rank=0, pid=3447)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3447)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3447)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3447)[0m   - Total checkpoint save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Average save time per checkpoint: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Min save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Max save time: 181.29s
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   - Number of batch samples: 10Checkpoint Save Statistics:
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m   - Total batch sample time: 0.33s
[36m(head, rank=0, pid=3447)[0m   - Number of checkpoints saved: 1  - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m   - Min batch sample time: 0.03s  - Total checkpoint save time: 181.29s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m   - Max batch sample time: 0.07s  - Average save time per checkpoint: 181.29s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   - Min save time: 181.29s  - Number of training steps: 80
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m   - Max save time: 181.29s  - Total training step time: 356.20s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   - Average training step time: 4.45s  - Number of batch samples: 10
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m   - Min training step time: 3.67s
[36m(head, rank=0, pid=3447)[0m   - Total batch sample time: 0.35s  - Max training step time: 9.30s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m   - Average batch sample time: 0.04sTraining completed successfully for run 1
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3447)[0m   - Total training step time: 357.08s
[36m(head, rank=0, pid=3447)[0m   - Average training step time: 4.46s
[36m(head, rank=0, pid=3447)[0m   - Min training step time: 3.67s
[36m(head, rank=0, pid=3447)[0m   - Max training step time: 9.29s
[36m(head, rank=0, pid=3447)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3447)[0m Completed Training in 1066.32 seconds
[36m(head, rank=0, pid=3447)[0m Completed Training in 1066.39 secondsSaved training info to: /tmp/checkpoint/training_run_7_1_info.json
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Completed run 1/1
[36m(head, rank=0, pid=3447)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3447)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3447)[0m   - Total checkpoint save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Average save time per checkpoint: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Min save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Max save time: 181.29s
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3447)[0m   - Total batch sample time: 0.33s
[36m(head, rank=0, pid=3447)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   - Min batch sample time: 0.02s
[36m(head, rank=0, pid=3447)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3447)[0m   - Total training step time: 355.62s
[36m(head, rank=0, pid=3447)[0m   - Average training step time: 4.45s
[36m(head, rank=0, pid=3447)[0m   - Min training step time: 3.66s
[36m(head, rank=0, pid=3447)[0m   - Max training step time: 9.31s
[36m(head, rank=0, pid=3447)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3447)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3447)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3447)[0m   - Total checkpoint save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Average save time per checkpoint: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Min save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   - Max save time: 181.29s
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3447)[0m   - Total batch sample time: 0.33s
[36m(head, rank=0, pid=3447)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3447)[0m   - Total training step time: 356.41s
[36m(head, rank=0, pid=3447)[0m   - Average training step time: 4.46s
[36m(head, rank=0, pid=3447)[0m   - Min training step time: 3.67s
[36m(head, rank=0, pid=3447)[0m   - Max training step time: 9.30s
[36m(head, rank=0, pid=3447)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3447)[0m Saved training info to: /tmp/checkpoint/training_run_3_1_info.json
[36m(head, rank=0, pid=3447)[0m Completed run 1/1
[36m(head, rank=0, pid=3447)[0m Saved training info to: /tmp/checkpoint/training_run_6_1_info.json
[36m(head, rank=0, pid=3447)[0m Completed run 1/1
[36m(head, rank=0, pid=3447)[0m Saved training info to: /tmp/checkpoint/training_run_1_1_info.json
[36m(head, rank=0, pid=3447)[0m Completed run 1/1
[36m(head, rank=0, pid=3447)[0m Saved training info to: /tmp/checkpoint/training_run_5_1_info.json
[36m(head, rank=0, pid=3447)[0m Completed run 1/1
[36m(head, rank=0, pid=3447)[0m Saved training info to: /tmp/checkpoint/training_run_2_1_info.json
[36m(head, rank=0, pid=3447)[0m Completed run 1/1
[36m(head, rank=0, pid=3447)[0m Saved training info to: /tmp/checkpoint/training_run_4_1_info.json
[36m(head, rank=0, pid=3447)[0m Completed run 1/1
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 2.27s
[36m(head, rank=0, pid=3447)[0m   • Min time: 2.27s
[36m(head, rank=0, pid=3447)[0m   • Max time: 2.27s
[36m(head, rank=0, pid=3447)[0m   • Total time: 2.27s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Model Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 0.88s
[36m(head, rank=0, pid=3447)[0m   • Min time: 0.88s
[36m(head, rank=0, pid=3447)[0m   • Max time: 0.88s
[36m(head, rank=0, pid=3447)[0m   • Total time: 0.88s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 1066.33s
[36m(head, rank=0, pid=3447)[0m   • Min time: 1066.33s
[36m(head, rank=0, pid=3447)[0m   • Max time: 1066.33s
[36m(head, rank=0, pid=3447)[0m   • Total time: 1066.33s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3447)[0m   • Average step time per step: 4.45s
[36m(head, rank=0, pid=3447)[0m   • Min step time: 3.67s
[36m(head, rank=0, pid=3447)[0m   • Max step time: 9.31s
[36m(head, rank=0, pid=3447)[0m   • Total training step time: 356.05s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3447)[0m   • Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3447)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   • Max sample time: 0.06s
[36m(head, rank=0, pid=3447)[0m   • Total batch sample time: 0.33s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3447)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3447)[0m   • Average save time per checkpoint: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Min save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Max save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Total checkpoint save time: 181.29s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Overall Run Performance:
[36m(head, rank=0, pid=3447)[0m   • Average total time per run: 1069.47s
[36m(head, rank=0, pid=3447)[0m   • Min total time: 1069.47s
[36m(head, rank=0, pid=3447)[0m   • Max total time: 1069.47s
[36m(head, rank=0, pid=3447)[0m   • Total time across all runs: 1069.47s
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m Saved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 2.07s
[36m(head, rank=0, pid=3447)[0m   • Min time: 2.07s
[36m(head, rank=0, pid=3447)[0m   • Max time: 2.07s
[36m(head, rank=0, pid=3447)[0m   • Total time: 2.07s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Model Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 0.91s
[36m(head, rank=0, pid=3447)[0m   • Min time: 0.91s
[36m(head, rank=0, pid=3447)[0m   • Max time: 0.91s
[36m(head, rank=0, pid=3447)[0m   • Total time: 0.91s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 1066.46s
[36m(head, rank=0, pid=3447)[0m   • Min time: 1066.46s
[36m(head, rank=0, pid=3447)[0m   • Max time: 1066.46s
[36m(head, rank=0, pid=3447)[0m   • Total time: 1066.46s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3447)[0m   • Average step time per step: 4.46s
[36m(head, rank=0, pid=3447)[0m   • Min step time: 3.67s
[36m(head, rank=0, pid=3447)[0m   • Max step time: 9.29s
[36m(head, rank=0, pid=3447)[0m   • Total training step time: 357.08s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3447)[0m   • Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3447)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   • Max sample time: 0.07s
[36m(head, rank=0, pid=3447)[0m   • Total batch sample time: 0.35s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3447)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3447)[0m   • Average save time per checkpoint: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Min save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Max save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Total checkpoint save time: 181.29s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Overall Run Performance:
[36m(head, rank=0, pid=3447)[0m   • Average total time per run: 1069.43s
[36m(head, rank=0, pid=3447)[0m   • Min total time: 1069.43s
[36m(head, rank=0, pid=3447)[0m   • Max total time: 1069.43s
[36m(head, rank=0, pid=3447)[0m   • Total time across all runs: 1069.43s
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m Saved timing summary to: timing_summary_5.json
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 2.12s
[36m(head, rank=0, pid=3447)[0m   • Min time: 2.12s
[36m(head, rank=0, pid=3447)[0m   • Max time: 2.12s
[36m(head, rank=0, pid=3447)[0m   • Total time: 2.12s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Model Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 0.91s
[36m(head, rank=0, pid=3447)[0m   • Min time: 0.91s
[36m(head, rank=0, pid=3447)[0m   • Max time: 0.91s
[36m(head, rank=0, pid=3447)[0m   • Total time: 0.91s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 1066.42s
[36m(head, rank=0, pid=3447)[0m   • Min time: 1066.42s
[36m(head, rank=0, pid=3447)[0m   • Max time: 1066.42s
[36m(head, rank=0, pid=3447)[0m   • Total time: 1066.42s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3447)[0m   • Average step time per step: 4.46s
[36m(head, rank=0, pid=3447)[0m   • Min step time: 3.67s
[36m(head, rank=0, pid=3447)[0m   • Max step time: 9.30s
[36m(head, rank=0, pid=3447)[0m   • Total training step time: 356.49s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3447)[0m   • Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3447)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   • Max sample time: 0.07s
[36m(head, rank=0, pid=3447)[0m   • Total batch sample time: 0.34s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3447)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3447)[0m   • Average save time per checkpoint: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Min save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Max save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Total checkpoint save time: 181.29s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Overall Run Performance:
[36m(head, rank=0, pid=3447)[0m   • Average total time per run: 1069.45s
[36m(head, rank=0, pid=3447)[0m   • Min total time: 1069.45s
[36m(head, rank=0, pid=3447)[0m   • Max total time: 1069.45s
[36m(head, rank=0, pid=3447)[0m   • Total time across all runs: 1069.45s
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 2.30s
[36m(head, rank=0, pid=3447)[0m   • Min time: 2.30s
[36m(head, rank=0, pid=3447)[0m   • Max time: 2.30s
[36m(head, rank=0, pid=3447)[0m   • Total time: 2.30s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Model Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 0.95s
[36m(head, rank=0, pid=3447)[0m Saved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3447)[0m   • Min time: 0.95s
[36m(head, rank=0, pid=3447)[0m   • Max time: 0.95s
[36m(head, rank=0, pid=3447)[0m   • Total time: 0.95s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 1066.32s
[36m(head, rank=0, pid=3447)[0m   • Min time: 1066.32s
[36m(head, rank=0, pid=3447)[0m   • Max time: 1066.32s
[36m(head, rank=0, pid=3447)[0m   • Total time: 1066.32s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3447)[0m   • Average step time per step: 4.45s
[36m(head, rank=0, pid=3447)[0m   • Min step time: 3.66s
[36m(head, rank=0, pid=3447)[0m   • Max step time: 9.31s
[36m(head, rank=0, pid=3447)[0m   • Total training step time: 355.62s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3447)[0m   • Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3447)[0m   • Min sample time: 0.02s
[36m(head, rank=0, pid=3447)[0m   • Max sample time: 0.07s
[36m(head, rank=0, pid=3447)[0m   • Total batch sample time: 0.33s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3447)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3447)[0m   • Average save time per checkpoint: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Min save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Max save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Total checkpoint save time: 181.29s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Overall Run Performance:
[36m(head, rank=0, pid=3447)[0m   • Average total time per run: 1069.56s
[36m(head, rank=0, pid=3447)[0m   • Min total time: 1069.56s
[36m(head, rank=0, pid=3447)[0m   • Max total time: 1069.56s
[36m(head, rank=0, pid=3447)[0m   • Total time across all runs: 1069.56s
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 2.26s
[36m(head, rank=0, pid=3447)[0m   • Min time: 2.26s
[36m(head, rank=0, pid=3447)[0m   • Max time: 2.26s
[36m(head, rank=0, pid=3447)[0m   • Total time: 2.26s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Model Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 0.92s
[36m(head, rank=0, pid=3447)[0m   • Min time: 0.92s
[36m(head, rank=0, pid=3447)[0m   • Max time: 0.92s
[36m(head, rank=0, pid=3447)[0m   • Total time: 0.92s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 1066.34s
[36m(head, rank=0, pid=3447)[0m   • Min time: 1066.34s
[36m(head, rank=0, pid=3447)[0m   • Max time: 1066.34s
[36m(head, rank=0, pid=3447)[0m   • Total time: 1066.34s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3447)[0m   • Average step time per step: 4.46s
[36m(head, rank=0, pid=3447)[0m   • Min step time: 3.67s
[36m(head, rank=0, pid=3447)[0m   • Max step time: 9.31s
[36m(head, rank=0, pid=3447)[0m   • Total training step time: 356.96s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3447)[0m   • Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3447)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   • Max sample time: 0.07s
[36m(head, rank=0, pid=3447)[0m   • Total batch sample time: 0.34s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3447)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3447)[0m   • Average save time per checkpoint: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Min save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Max save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Total checkpoint save time: 181.29s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Overall Run Performance:
[36m(head, rank=0, pid=3447)[0m   • Average total time per run: 1069.52s
[36m(head, rank=0, pid=3447)[0m   • Min total time: 1069.52s
[36m(head, rank=0, pid=3447)[0m   • Max total time: 1069.52s
[36m(head, rank=0, pid=3447)[0m   • Total time across all runs: 1069.52s
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 2.07s
[36m(head, rank=0, pid=3447)[0m   • Min time: 2.07s
[36m(head, rank=0, pid=3447)[0m   • Max time: 2.07s
[36m(head, rank=0, pid=3447)[0m   • Total time: 2.07s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Model Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 1.01s
[36m(head, rank=0, pid=3447)[0m   • Min time: 1.01s
[36m(head, rank=0, pid=3447)[0m   • Max time: 1.01s
[36m(head, rank=0, pid=3447)[0m   • Total time: 1.01s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 1066.39s
[36m(head, rank=0, pid=3447)[0m   • Min time: 1066.39s
[36m(head, rank=0, pid=3447)[0m   • Max time: 1066.39s
[36m(head, rank=0, pid=3447)[0m   • Total time: 1066.39s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3447)[0m   • Average step time per step: 4.46s
[36m(head, rank=0, pid=3447)[0m   • Min step time: 3.67s
[36m(head, rank=0, pid=3447)[0m   • Max step time: 9.30s
[36m(head, rank=0, pid=3447)[0m   • Total training step time: 356.41s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3447)[0m   • Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3447)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   • Max sample time: 0.07s
[36m(head, rank=0, pid=3447)[0m   • Total batch sample time: 0.33s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3447)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3447)[0m   • Average save time per checkpoint: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Min save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Max save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Total checkpoint save time: 181.29s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Overall Run Performance:
[36m(head, rank=0, pid=3447)[0m   • Average total time per run: 1069.47s
[36m(head, rank=0, pid=3447)[0m   • Min total time: 1069.47s
[36m(head, rank=0, pid=3447)[0m   • Max total time: 1069.47s
[36m(head, rank=0, pid=3447)[0m   • Total time across all runs: 1069.47s
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 2.27s
[36m(head, rank=0, pid=3447)[0m   • Min time: 2.27s
[36m(head, rank=0, pid=3447)[0m   • Max time: 2.27s
[36m(head, rank=0, pid=3447)[0m   • Total time: 2.27s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Model Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 0.91s
[36m(head, rank=0, pid=3447)[0m   • Min time: 0.91s
[36m(head, rank=0, pid=3447)[0m   • Max time: 0.91s
[36m(head, rank=0, pid=3447)[0m   • Total time: 0.91s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 1066.33s
[36m(head, rank=0, pid=3447)[0m   • Min time: 1066.33s
[36m(head, rank=0, pid=3447)[0m   • Max time: 1066.33s
[36m(head, rank=0, pid=3447)[0m   • Total time: 1066.33s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3447)[0m   • Average step time per step: 4.45s
[36m(head, rank=0, pid=3447)[0m   • Min step time: 3.67s
[36m(head, rank=0, pid=3447)[0m   • Max step time: 9.30s
[36m(head, rank=0, pid=3447)[0m   • Total training step time: 356.20s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3447)[0m   • Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3447)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   • Max sample time: 0.07s
[36m(head, rank=0, pid=3447)[0m   • Total batch sample time: 0.33s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3447)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3447)[0m   • Average save time per checkpoint: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Min save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Max save time: 181.29s
[36m(head, rank=0, pid=3447)[0m   • Total checkpoint save time: 181.29s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Overall Run Performance:
[36m(head, rank=0, pid=3447)[0m   • Average total time per run: 1069.51s
[36m(head, rank=0, pid=3447)[0m   • Min total time: 1069.51s
[36m(head, rank=0, pid=3447)[0m   • Max total time: 1069.51s
[36m(head, rank=0, pid=3447)[0m   • Total time across all runs: 1069.51s
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 2.06s
[36m(head, rank=0, pid=3447)[0m   • Min time: 2.06s
[36m(head, rank=0, pid=3447)[0m   • Max time: 2.06s
[36m(head, rank=0, pid=3447)[0m   • Total time: 2.06s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Model Loading Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 20.05s
[36m(head, rank=0, pid=3447)[0m   • Min time: 20.05s
[36m(head, rank=0, pid=3447)[0m   • Max time: 20.05s
[36m(head, rank=0, pid=3447)[0m   • Total time: 20.05s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Performance:
[36m(head, rank=0, pid=3447)[0m   • Average time: 1047.75s
[36m(head, rank=0, pid=3447)[0m   • Min time: 1047.75s
[36m(head, rank=0, pid=3447)[0m   • Max time: 1047.75s
[36m(head, rank=0, pid=3447)[0m   • Total time: 1047.75s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Training Step Performance:
[36m(head, rank=0, pid=3447)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3447)[0m   • Average step time per step: 4.45s
[36m(head, rank=0, pid=3447)[0m   • Min step time: 3.67s
[36m(head, rank=0, pid=3447)[0m   • Max step time: 8.19s
[36m(head, rank=0, pid=3447)[0m   • Total training step time: 355.83s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3447)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3447)[0m   • Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3447)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3447)[0m   • Max sample time: 0.07s
[36m(head, rank=0, pid=3447)[0m   • Total batch sample time: 0.35s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3447)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3447)[0m   • Average save time per checkpoint: 312.70s
[36m(head, rank=0, pid=3447)[0m   • Min save time: 312.70s
[36m(head, rank=0, pid=3447)[0m   • Max save time: 312.70s
[36m(head, rank=0, pid=3447)[0m   • Total checkpoint save time: 312.70s
[36m(head, rank=0, pid=3447)[0m 
[36m(head, rank=0, pid=3447)[0m Overall Run Performance:
[36m(head, rank=0, pid=3447)[0m   • Average total time per run: 1069.86s
[36m(head, rank=0, pid=3447)[0m   • Min total time: 1069.86s
[36m(head, rank=0, pid=3447)[0m   • Max total time: 1069.86s
[36m(head, rank=0, pid=3447)[0m   • Total time across all runs: 1069.86s
[36m(head, rank=0, pid=3447)[0m ================================================================================
[36m(head, rank=0, pid=3447)[0m Saved timing summary to: timing_summary_0.json
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m ================================================================================
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m ================================================================================
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Average time: 2.09s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Min time: 2.09s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Max time: 2.09s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Total time: 2.09s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Average time: 0.86s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Min time: 0.86s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Max time: 0.86s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m   • Total time: 0.86s
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m 
[36m(worker1, rank=1, pid=2571, ip=10.102.30.23)[0m Training Performance:
