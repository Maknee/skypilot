[33mTailing logs of the last job on cluster 'cc'...[0m
Job ID not provided. Streaming the logs of the latest job.
[2m├── [0m[2mWaiting for task resources on 2 nodes.[0m
[2m└── [0mJob started. Streaming logs... [2m(Ctrl-C to exit log streaming; job will not be killed)[0m
[36m(setup pid=2319)[0m Channels:
[36m(setup pid=2319)[0m  - nvidia
[36m(setup pid=2319)[0m  - defaults
[36m(setup pid=2319)[0m Platform: linux-64
[36m(setup pid=1615, ip=10.113.50.240)[0m Channels:
[36m(setup pid=1615, ip=10.113.50.240)[0m  - nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m  - defaults
[36m(setup pid=1615, ip=10.113.50.240)[0m Platform: linux-64
[36m(setup pid=2319)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=1615, ip=10.113.50.240)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=2319)[0m Solving environment: ...working... done
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m ## Package Plan ##
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m   environment location: /home/sky/miniconda3
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m   added / updated specs:
[36m(setup pid=2319)[0m     - cuda
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m The following packages will be downloaded:
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m     package                    |            build
[36m(setup pid=2319)[0m     ---------------------------|-----------------
[36m(setup pid=2319)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=2319)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=2319)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=2319)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=2319)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=2319)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=2319)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=2319)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=2319)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=2319)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=2319)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=2319)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=2319)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=2319)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=2319)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=2319)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2319)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=2319)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=2319)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=2319)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=2319)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=2319)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=2319)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=2319)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=2319)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2319)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=2319)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=2319)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=2319)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=2319)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=2319)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=2319)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=2319)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=2319)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=2319)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=2319)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=2319)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=2319)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=2319)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=2319)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=2319)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=2319)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=2319)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=2319)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=2319)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=2319)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=2319)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=2319)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=2319)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=2319)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2319)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=2319)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2319)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=2319)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=2319)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=2319)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=2319)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=2319)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=2319)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=2319)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=2319)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=2319)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=2319)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=2319)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=2319)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=2319)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=2319)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=2319)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=2319)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=2319)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=2319)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=2319)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=2319)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=2319)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=2319)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=2319)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=2319)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=2319)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=2319)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=2319)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=2319)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=2319)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=2319)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=2319)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=2319)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=2319)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=2319)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=2319)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=2319)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=2319)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=2319)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=2319)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=2319)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=2319)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=2319)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=2319)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=2319)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=2319)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=2319)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=2319)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=2319)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=2319)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=2319)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=2319)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=2319)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=2319)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=2319)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=2319)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=2319)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=2319)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=2319)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=2319)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=2319)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=2319)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=2319)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=2319)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=2319)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=2319)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=2319)[0m     ------------------------------------------------------------
[36m(setup pid=2319)[0m                                            Total:        2.06 GB
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=2319)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=2319)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=2319)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=2319)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=2319)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=2319)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=2319)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=2319)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=2319)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=2319)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=2319)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=2319)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=2319)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=2319)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=2319)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=2319)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=2319)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=2319)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=2319)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=2319)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=2319)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=2319)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=2319)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=2319)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=2319)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=2319)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=2319)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=2319)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=2319)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=2319)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=2319)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=2319)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=2319)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=2319)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=2319)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=2319)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=2319)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=2319)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=2319)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=2319)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=2319)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=2319)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=2319)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=2319)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=2319)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=2319)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=2319)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=2319)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=2319)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=2319)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=2319)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=2319)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=2319)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=2319)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=2319)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=2319)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2319)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=2319)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=2319)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=2319)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=2319)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=2319)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2319)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=2319)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=2319)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=2319)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=2319)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=2319)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=2319)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=2319)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=2319)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=2319)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=2319)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=2319)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=2319)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=2319)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=2319)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=2319)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2319)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=2319)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=2319)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=2319)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=2319)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=2319)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=2319)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=2319)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=2319)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=2319)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=2319)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=2319)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2319)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=2319)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=2319)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=2319)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=2319)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=2319)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=2319)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=2319)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=2319)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=2319)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=2319)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=2319)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=2319)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=2319)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=2319)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=2319)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m The following packages will be UPDATED:
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=2319)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=2319)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=2319)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=2319)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=2319)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=2319)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=2319)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=2319)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=2319)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=2319)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m Proceed ([y]/n)? 
[36m(setup pid=2319)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m Solving environment: ...working... done
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m ## Package Plan ##
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m   environment location: /home/sky/miniconda3
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m   added / updated specs:
[36m(setup pid=1615, ip=10.113.50.240)[0m     - cuda
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m The following packages will be downloaded:
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m     package                    |            build
[36m(setup pid=1615, ip=10.113.50.240)[0m     ---------------------------|-----------------
[36m(setup pid=1615, ip=10.113.50.240)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=1615, ip=10.113.50.240)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=1615, ip=10.113.50.240)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=1615, ip=10.113.50.240)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=1615, ip=10.113.50.240)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=1615, ip=10.113.50.240)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=1615, ip=10.113.50.240)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=1615, ip=10.113.50.240)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=1615, ip=10.113.50.240)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=1615, ip=10.113.50.240)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=1615, ip=10.113.50.240)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=1615, ip=10.113.50.240)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=1615, ip=10.113.50.240)[0m     ------------------------------------------------------------
[36m(setup pid=1615, ip=10.113.50.240)[0m                                            Total:        2.06 GB
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=1615, ip=10.113.50.240)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=1615, ip=10.113.50.240)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=1615, ip=10.113.50.240)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=1615, ip=10.113.50.240)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=1615, ip=10.113.50.240)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m The following packages will be UPDATED:
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=1615, ip=10.113.50.240)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=1615, ip=10.113.50.240)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m Proceed ([y]/n)? 
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=2319)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=2319)[0m Preparing transaction: ...working... done
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing transaction: ...working... done
[36m(setup pid=2319)[0m Verifying transaction: ...working... done
[36m(setup pid=1615, ip=10.113.50.240)[0m Verifying transaction: ...working... done
[36m(setup pid=2319)[0m Executing transaction: ...working... done
[36m(setup pid=1615, ip=10.113.50.240)[0m Executing transaction: ...working... done
[36m(setup pid=2319)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=1615, ip=10.113.50.240)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=2319)[0m Using CPython 3.10.13 interpreter at: /home/sky/miniconda3/bin/python3.10
[36m(setup pid=2319)[0m Creating virtual environment with seed packages at: /home/sky/training
[36m(setup pid=2319)[0m  + pip==25.2
[36m(setup pid=2319)[0m  + setuptools==80.9.0
[36m(setup pid=2319)[0m  + wheel==0.45.1
[36m(setup pid=2319)[0m Using Python 3.10.13 environment at: /home/sky/training
[36m(setup pid=2319)[0m Resolved 29 packages in 186ms
[36m(setup pid=2319)[0m Downloading pillow (6.3MiB)
[36m(setup pid=2319)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=2319)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=2319)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=2319)[0m Downloading torch (783.1MiB)
[36m(setup pid=2319)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=2319)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=2319)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=2319)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=2319)[0m Downloading numpy (16.0MiB)
[36m(setup pid=2319)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=2319)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=2319)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=2319)[0m Downloading sympy (6.0MiB)
[36m(setup pid=2319)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=2319)[0m Downloading triton (148.4MiB)
[36m(setup pid=2319)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=2319)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=2319)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Using CPython 3.10.13 interpreter at: /home/sky/miniconda3/bin/python3.10
[36m(setup pid=1615, ip=10.113.50.240)[0m Creating virtual environment with seed packages at: /home/sky/training
[36m(setup pid=1615, ip=10.113.50.240)[0m  + pip==25.2
[36m(setup pid=1615, ip=10.113.50.240)[0m  + setuptools==80.9.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + wheel==0.45.1
[36m(setup pid=1615, ip=10.113.50.240)[0m Using Python 3.10.13 environment at: /home/sky/training
[36m(setup pid=2319)[0m  Downloaded nvidia-cufile-cu12
[36m(setup pid=1615, ip=10.113.50.240)[0m Resolved 29 packages in 92ms
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading numpy (16.0MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading pillow (6.3MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading sympy (6.0MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading triton (148.4MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading torch (783.1MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded nvidia-cufile-cu12
[36m(setup pid=2319)[0m  Downloaded torchaudio
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded torchaudio
[36m(setup pid=2319)[0m  Downloaded torchvision
[36m(setup pid=2319)[0m  Downloaded pillow
[36m(setup pid=2319)[0m  Downloaded nvidia-cuda-cupti-cu12
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded torchvision
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded pillow
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded nvidia-cuda-cupti-cu12
[36m(setup pid=2319)[0m  Downloaded numpy
[36m(setup pid=2319)[0m  Downloaded nvidia-nvjitlink-cu12
[36m(setup pid=2319)[0m  Downloaded nvidia-cuda-nvrtc-cu12
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded nvidia-nvjitlink-cu12
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded numpy
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded nvidia-cuda-nvrtc-cu12
[36m(setup pid=2319)[0m  Downloaded nvidia-curand-cu12
[36m(setup pid=2319)[0m  Downloaded sympy
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded nvidia-curand-cu12
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded sympy
[36m(setup pid=2319)[0m  Downloaded nvidia-cusolver-cu12
[36m(setup pid=2319)[0m  Downloaded nvidia-cusparselt-cu12
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded nvidia-cusolver-cu12
[36m(setup pid=2319)[0m  Downloaded triton
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded nvidia-cusparselt-cu12
[36m(setup pid=2319)[0m  Downloaded nvidia-cufft-cu12
[36m(setup pid=2319)[0m  Downloaded nvidia-nccl-cu12
[36m(setup pid=2319)[0m  Downloaded nvidia-cusparse-cu12
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded triton
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded nvidia-cufft-cu12
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded nvidia-nccl-cu12
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded nvidia-cusparse-cu12
[36m(setup pid=2319)[0m  Downloaded nvidia-cublas-cu12
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded nvidia-cublas-cu12
[36m(setup pid=2319)[0m  Downloaded nvidia-cudnn-cu12
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded nvidia-cudnn-cu12
[36m(setup pid=2319)[0m  Downloaded torch
[36m(setup pid=2319)[0m Prepared 26 packages in 24.94s
[36m(setup pid=2319)[0m Installed 28 packages in 631ms
[36m(setup pid=2319)[0m  + filelock==3.18.0
[36m(setup pid=2319)[0m  + fsspec==2025.7.0
[36m(setup pid=2319)[0m  + jinja2==3.1.6
[36m(setup pid=2319)[0m  + markupsafe==3.0.2
[36m(setup pid=2319)[0m  + mpmath==1.3.0
[36m(setup pid=2319)[0m  + networkx==3.4.2
[36m(setup pid=2319)[0m  + numpy==2.2.6
[36m(setup pid=2319)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=2319)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=2319)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=2319)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=2319)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=2319)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=2319)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=2319)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=2319)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=2319)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=2319)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=2319)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=2319)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=2319)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=2319)[0m  + pillow==11.3.0
[36m(setup pid=2319)[0m  + sympy==1.14.0
[36m(setup pid=2319)[0m  + torch==2.7.1
[36m(setup pid=2319)[0m  + torchaudio==2.7.1
[36m(setup pid=2319)[0m  + torchvision==0.22.1
[36m(setup pid=2319)[0m  + triton==3.3.1
[36m(setup pid=2319)[0m  + typing-extensions==4.14.1
[36m(setup pid=2319)[0m Using Python 3.10.13 environment at: /home/sky/training
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded torch
[36m(setup pid=1615, ip=10.113.50.240)[0m Prepared 26 packages in 25.77s
[36m(setup pid=2319)[0m Resolved 73 packages in 476ms
[36m(setup pid=2319)[0m    Building deepspeed==0.17.4
[36m(setup pid=2319)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=2319)[0m Downloading transformers (10.7MiB)
[36m(setup pid=2319)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=2319)[0m Downloading pydantic-core (1.9MiB)
[36m(setup pid=2319)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=2319)[0m Downloading aiohttp (1.6MiB)
[36m(setup pid=2319)[0m Downloading pandas (11.8MiB)
[36m(setup pid=2319)[0m  Downloaded pydantic-core
[36m(setup pid=2319)[0m  Downloaded tokenizers
[36m(setup pid=2319)[0m  Downloaded hf-xet
[36m(setup pid=2319)[0m  Downloaded aiohttp
[36m(setup pid=1615, ip=10.113.50.240)[0m Installed 28 packages in 661ms
[36m(setup pid=1615, ip=10.113.50.240)[0m  + filelock==3.18.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + fsspec==2025.7.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + jinja2==3.1.6
[36m(setup pid=1615, ip=10.113.50.240)[0m  + markupsafe==3.0.2
[36m(setup pid=1615, ip=10.113.50.240)[0m  + mpmath==1.3.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + networkx==3.4.2
[36m(setup pid=1615, ip=10.113.50.240)[0m  + numpy==2.2.6
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=1615, ip=10.113.50.240)[0m  + pillow==11.3.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + sympy==1.14.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + torch==2.7.1
[36m(setup pid=1615, ip=10.113.50.240)[0m  + torchaudio==2.7.1
[36m(setup pid=1615, ip=10.113.50.240)[0m  + torchvision==0.22.1
[36m(setup pid=1615, ip=10.113.50.240)[0m  + triton==3.3.1
[36m(setup pid=1615, ip=10.113.50.240)[0m  + typing-extensions==4.14.1
[36m(setup pid=1615, ip=10.113.50.240)[0m Using Python 3.10.13 environment at: /home/sky/training
[36m(setup pid=2319)[0m  Downloaded pyarrow
[36m(setup pid=1615, ip=10.113.50.240)[0m Resolved 73 packages in 397ms
[36m(setup pid=2319)[0m  Downloaded pandas
[36m(setup pid=1615, ip=10.113.50.240)[0m    Building deepspeed==0.17.4
[36m(setup pid=2319)[0m  Downloaded transformers
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading aiohttp (1.6MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading pandas (11.8MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading transformers (10.7MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading pydantic-core (1.9MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=1615, ip=10.113.50.240)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=2319)[0m       Built deepspeed==0.17.4
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded pydantic-core
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded tokenizers
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded hf-xet
[36m(setup pid=2319)[0m Prepared 41 packages in 1.40s
[36m(setup pid=2319)[0m Uninstalled 1 package in 0.92ms
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded aiohttp
[36m(setup pid=2319)[0m Installed 48 packages in 151ms
[36m(setup pid=2319)[0m  + accelerate==1.9.0
[36m(setup pid=2319)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=2319)[0m  + aiohttp==3.12.15
[36m(setup pid=2319)[0m  + aiosignal==1.4.0
[36m(setup pid=2319)[0m  + annotated-types==0.7.0
[36m(setup pid=2319)[0m  + async-timeout==5.0.1
[36m(setup pid=2319)[0m  + attrs==25.3.0
[36m(setup pid=2319)[0m  + certifi==2025.7.14
[36m(setup pid=2319)[0m  + charset-normalizer==3.4.2
[36m(setup pid=2319)[0m  + datasets==4.0.0
[36m(setup pid=2319)[0m  + deepspeed==0.17.4
[36m(setup pid=2319)[0m  + dill==0.3.8
[36m(setup pid=2319)[0m  + einops==0.8.1
[36m(setup pid=2319)[0m  + frozenlist==1.7.0
[36m(setup pid=2319)[0m  - fsspec==2025.7.0
[36m(setup pid=2319)[0m  + fsspec==2025.3.0
[36m(setup pid=2319)[0m  + hf-xet==1.1.5
[36m(setup pid=2319)[0m  + hjson==3.1.0
[36m(setup pid=2319)[0m  + huggingface-hub==0.34.3
[36m(setup pid=2319)[0m  + idna==3.10
[36m(setup pid=2319)[0m  + liger-kernel==0.6.1
[36m(setup pid=2319)[0m  + msgpack==1.1.1
[36m(setup pid=2319)[0m  + multidict==6.6.3
[36m(setup pid=2319)[0m  + multiprocess==0.70.16
[36m(setup pid=2319)[0m  + ninja==1.11.1.4
[36m(setup pid=2319)[0m  + packaging==25.0
[36m(setup pid=2319)[0m  + pandas==2.3.1
[36m(setup pid=2319)[0m  + propcache==0.3.2
[36m(setup pid=2319)[0m  + psutil==7.0.0
[36m(setup pid=2319)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=2319)[0m  + pyarrow==21.0.0
[36m(setup pid=2319)[0m  + pydantic==2.11.7
[36m(setup pid=2319)[0m  + pydantic-core==2.33.2
[36m(setup pid=2319)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=2319)[0m  + pytz==2025.2
[36m(setup pid=2319)[0m  + pyyaml==6.0.2
[36m(setup pid=2319)[0m  + regex==2025.7.34
[36m(setup pid=2319)[0m  + requests==2.32.4
[36m(setup pid=2319)[0m  + safetensors==0.5.3
[36m(setup pid=2319)[0m  + six==1.17.0
[36m(setup pid=2319)[0m  + tokenizers==0.21.4
[36m(setup pid=2319)[0m  + tqdm==4.67.1
[36m(setup pid=2319)[0m  + transformers==4.54.1
[36m(setup pid=2319)[0m  + trl==0.20.0
[36m(setup pid=2319)[0m  + typing-inspection==0.4.1
[36m(setup pid=2319)[0m  + tzdata==2025.2
[36m(setup pid=2319)[0m  + urllib3==2.5.0
[36m(setup pid=2319)[0m  + xxhash==3.5.0
[36m(setup pid=2319)[0m  + yarl==1.20.1
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2319)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded pyarrow
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded pandas
[36m(setup pid=1615, ip=10.113.50.240)[0m  Downloaded transformers
[36m(setup pid=2319)[0m Reading package lists...
[36m(setup pid=1615, ip=10.113.50.240)[0m       Built deepspeed==0.17.4
[36m(setup pid=1615, ip=10.113.50.240)[0m Prepared 41 packages in 1.38s
[36m(setup pid=1615, ip=10.113.50.240)[0m Uninstalled 1 package in 1ms
[36m(setup pid=2319)[0m Building dependency tree...
[36m(setup pid=2319)[0m Reading state information...
[36m(setup pid=2319)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2319)[0m   libfuse2
[36m(setup pid=2319)[0m Use 'sudo apt autoremove' to remove it.
[36m(setup pid=2319)[0m The following NEW packages will be installed:
[36m(setup pid=2319)[0m   vmtouch
[36m(setup pid=1615, ip=10.113.50.240)[0m Installed 48 packages in 331ms
[36m(setup pid=1615, ip=10.113.50.240)[0m  + accelerate==1.9.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=1615, ip=10.113.50.240)[0m  + aiohttp==3.12.15
[36m(setup pid=1615, ip=10.113.50.240)[0m  + aiosignal==1.4.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + annotated-types==0.7.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + async-timeout==5.0.1
[36m(setup pid=1615, ip=10.113.50.240)[0m  + attrs==25.3.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + certifi==2025.7.14
[36m(setup pid=1615, ip=10.113.50.240)[0m  + charset-normalizer==3.4.2
[36m(setup pid=1615, ip=10.113.50.240)[0m  + datasets==4.0.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + deepspeed==0.17.4
[36m(setup pid=1615, ip=10.113.50.240)[0m  + dill==0.3.8
[36m(setup pid=1615, ip=10.113.50.240)[0m  + einops==0.8.1
[36m(setup pid=1615, ip=10.113.50.240)[0m  + frozenlist==1.7.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  - fsspec==2025.7.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + fsspec==2025.3.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + hf-xet==1.1.5
[36m(setup pid=1615, ip=10.113.50.240)[0m  + hjson==3.1.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + huggingface-hub==0.34.3
[36m(setup pid=1615, ip=10.113.50.240)[0m  + idna==3.10
[36m(setup pid=1615, ip=10.113.50.240)[0m  + liger-kernel==0.6.1
[36m(setup pid=1615, ip=10.113.50.240)[0m  + msgpack==1.1.1
[36m(setup pid=1615, ip=10.113.50.240)[0m  + multidict==6.6.3
[36m(setup pid=1615, ip=10.113.50.240)[0m  + multiprocess==0.70.16
[36m(setup pid=1615, ip=10.113.50.240)[0m  + ninja==1.11.1.4
[36m(setup pid=1615, ip=10.113.50.240)[0m  + packaging==25.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + pandas==2.3.1
[36m(setup pid=1615, ip=10.113.50.240)[0m  + propcache==0.3.2
[36m(setup pid=1615, ip=10.113.50.240)[0m  + psutil==7.0.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + pyarrow==21.0.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + pydantic==2.11.7
[36m(setup pid=1615, ip=10.113.50.240)[0m  + pydantic-core==2.33.2
[36m(setup pid=1615, ip=10.113.50.240)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + pytz==2025.2
[36m(setup pid=1615, ip=10.113.50.240)[0m  + pyyaml==6.0.2
[36m(setup pid=1615, ip=10.113.50.240)[0m  + regex==2025.7.34
[36m(setup pid=1615, ip=10.113.50.240)[0m  + requests==2.32.4
[36m(setup pid=1615, ip=10.113.50.240)[0m  + safetensors==0.5.3
[36m(setup pid=1615, ip=10.113.50.240)[0m  + six==1.17.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + tokenizers==0.21.4
[36m(setup pid=1615, ip=10.113.50.240)[0m  + tqdm==4.67.1
[36m(setup pid=1615, ip=10.113.50.240)[0m  + transformers==4.54.1
[36m(setup pid=1615, ip=10.113.50.240)[0m  + trl==0.20.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + typing-inspection==0.4.1
[36m(setup pid=1615, ip=10.113.50.240)[0m  + tzdata==2025.2
[36m(setup pid=1615, ip=10.113.50.240)[0m  + urllib3==2.5.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + xxhash==3.5.0
[36m(setup pid=1615, ip=10.113.50.240)[0m  + yarl==1.20.1
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=2319)[0m 0 upgraded, 1 newly installed, 0 to remove and 77 not upgraded.
[36m(setup pid=2319)[0m Need to get 21.8 kB of archives.
[36m(setup pid=2319)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=2319)[0m Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 vmtouch amd64 1.3.1-1 [21.8 kB]
[36m(setup pid=2319)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2319)[0m Fetched 21.8 kB in 0s (157 kB/s)
[36m(setup pid=2319)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=2319)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 20379 files and directories currently installed.)
[36m(setup pid=2319)[0m Preparing to unpack .../vmtouch_1.3.1-1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking vmtouch (1.3.1-1) ...
[36m(setup pid=2319)[0m Setting up vmtouch (1.3.1-1) ...
[36m(setup pid=2319)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=2319)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=2319)[0m Processing triggers for systemd (245.4-4ubuntu3.24) ...
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2319)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m Reading package lists...
[36m(setup pid=1615, ip=10.113.50.240)[0m Building dependency tree...
[36m(setup pid=1615, ip=10.113.50.240)[0m Reading state information...
[36m(setup pid=2319)[0m Reading package lists...
[36m(setup pid=1615, ip=10.113.50.240)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=1615, ip=10.113.50.240)[0m   libfuse2
[36m(setup pid=1615, ip=10.113.50.240)[0m Use 'sudo apt autoremove' to remove it.
[36m(setup pid=1615, ip=10.113.50.240)[0m The following NEW packages will be installed:
[36m(setup pid=1615, ip=10.113.50.240)[0m   vmtouch
[36m(setup pid=2319)[0m Building dependency tree...
[36m(setup pid=2319)[0m Reading state information...
[36m(setup pid=1615, ip=10.113.50.240)[0m 0 upgraded, 1 newly installed, 0 to remove and 77 not upgraded.
[36m(setup pid=1615, ip=10.113.50.240)[0m Need to get 21.8 kB of archives.
[36m(setup pid=1615, ip=10.113.50.240)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 vmtouch amd64 1.3.1-1 [21.8 kB]
[36m(setup pid=2319)[0m E: Unable to locate package python3.10-dev
[36m(setup pid=2319)[0m E: Couldn't find any package by glob 'python3.10-dev'
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2319)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=1615, ip=10.113.50.240)[0m Fetched 21.8 kB in 0s (162 kB/s)
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=1615, ip=10.113.50.240)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 20379 files and directories currently installed.)
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../vmtouch_1.3.1-1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking vmtouch (1.3.1-1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up vmtouch (1.3.1-1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=1615, ip=10.113.50.240)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=1615, ip=10.113.50.240)[0m Processing triggers for systemd (245.4-4ubuntu3.24) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=2319)[0m Reading package lists...
[36m(setup pid=2319)[0m Building dependency tree...
[36m(setup pid=2319)[0m Reading state information...
[36m(setup pid=1615, ip=10.113.50.240)[0m Reading package lists...
[36m(setup pid=2319)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2319)[0m   libfuse2
[36m(setup pid=2319)[0m Use 'sudo apt autoremove' to remove it.
[36m(setup pid=2319)[0m The following additional packages will be installed:
[36m(setup pid=2319)[0m   alsa-topology-conf alsa-ucm-conf cron libasound2 libasound2-data libatm1
[36m(setup pid=2319)[0m   libcanberra0 libcap2-bin libelf1 libgpm2 libibmad5 libibnetdisc5 libibumad3
[36m(setup pid=2319)[0m   libltdl7 libmnl0 libogg0 libpam-cap libpython3.8 libpython3.8-minimal
[36m(setup pid=2319)[0m   libpython3.8-stdlib libsensors-config libsensors5 libtdb1 libvorbis0a
[36m(setup pid=2319)[0m   libvorbisfile3 libxtables12 python3.8 python3.8-minimal
[36m(setup pid=2319)[0m   sound-theme-freedesktop vim-common vim-runtime xxd
[36m(setup pid=2319)[0m Suggested packages:
[36m(setup pid=2319)[0m   anacron logrotate checksecurity default-mta | mail-transport-agent lsof
[36m(setup pid=2319)[0m   strace iproute2-doc libasound2-plugins alsa-utils libcanberra-gtk0
[36m(setup pid=2319)[0m   libcanberra-pulse gpm lm-sensors python3.8-venv python3.8-doc binfmt-support
[36m(setup pid=2319)[0m   isag ctags vim-doc vim-scripts
[36m(setup pid=1615, ip=10.113.50.240)[0m Building dependency tree...
[36m(setup pid=1615, ip=10.113.50.240)[0m Reading state information...
[36m(setup pid=2319)[0m The following NEW packages will be installed:
[36m(setup pid=2319)[0m   alsa-topology-conf alsa-ucm-conf cron htop infiniband-diags iproute2
[36m(setup pid=2319)[0m   libasound2 libasound2-data libatm1 libcanberra0 libcap2-bin libelf1 libgpm2
[36m(setup pid=2319)[0m   libibmad5 libibnetdisc5 libibumad3 libltdl7 libmnl0 libogg0 libpam-cap
[36m(setup pid=2319)[0m   libpython3.8 libsensors-config libsensors5 libtdb1 libvorbis0a
[36m(setup pid=2319)[0m   libvorbisfile3 libxtables12 net-tools sound-theme-freedesktop sysstat vim
[36m(setup pid=2319)[0m   vim-common vim-runtime xxd
[36m(setup pid=2319)[0m The following packages will be upgraded:
[36m(setup pid=2319)[0m   libpython3.8-minimal libpython3.8-stdlib python3.8 python3.8-minimal
[36m(setup pid=1615, ip=10.113.50.240)[0m E: Unable to locate package python3.10-dev
[36m(setup pid=1615, ip=10.113.50.240)[0m E: Couldn't find any package by glob 'python3.10-dev'
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=2319)[0m 4 upgraded, 34 newly installed, 0 to remove and 73 not upgraded.
[36m(setup pid=2319)[0m Need to get 16.7 MB of archives.
[36m(setup pid=2319)[0m After this operation, 52.2 MB of additional disk space will be used.
[36m(setup pid=2319)[0m Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3.8 amd64 3.8.10-0ubuntu1~20.04.18 [387 kB]
[36m(setup pid=2319)[0m Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpython3.8-stdlib amd64 3.8.10-0ubuntu1~20.04.18 [1676 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Reading package lists...
[36m(setup pid=1615, ip=10.113.50.240)[0m Building dependency tree...
[36m(setup pid=1615, ip=10.113.50.240)[0m Reading state information...
[36m(setup pid=1615, ip=10.113.50.240)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=1615, ip=10.113.50.240)[0m   libfuse2
[36m(setup pid=1615, ip=10.113.50.240)[0m Use 'sudo apt autoremove' to remove it.
[36m(setup pid=1615, ip=10.113.50.240)[0m The following additional packages will be installed:
[36m(setup pid=1615, ip=10.113.50.240)[0m   alsa-topology-conf alsa-ucm-conf cron libasound2 libasound2-data libatm1
[36m(setup pid=1615, ip=10.113.50.240)[0m   libcanberra0 libcap2-bin libelf1 libgpm2 libibmad5 libibnetdisc5 libibumad3
[36m(setup pid=1615, ip=10.113.50.240)[0m   libltdl7 libmnl0 libogg0 libpam-cap libpython3.8 libpython3.8-minimal
[36m(setup pid=1615, ip=10.113.50.240)[0m   libpython3.8-stdlib libsensors-config libsensors5 libtdb1 libvorbis0a
[36m(setup pid=1615, ip=10.113.50.240)[0m   libvorbisfile3 libxtables12 python3.8 python3.8-minimal
[36m(setup pid=1615, ip=10.113.50.240)[0m   sound-theme-freedesktop vim-common vim-runtime xxd
[36m(setup pid=1615, ip=10.113.50.240)[0m Suggested packages:
[36m(setup pid=1615, ip=10.113.50.240)[0m   anacron logrotate checksecurity default-mta | mail-transport-agent lsof
[36m(setup pid=1615, ip=10.113.50.240)[0m   strace iproute2-doc libasound2-plugins alsa-utils libcanberra-gtk0
[36m(setup pid=1615, ip=10.113.50.240)[0m   libcanberra-pulse gpm lm-sensors python3.8-venv python3.8-doc binfmt-support
[36m(setup pid=1615, ip=10.113.50.240)[0m   isag ctags vim-doc vim-scripts
[36m(setup pid=2319)[0m Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3.8-minimal amd64 3.8.10-0ubuntu1~20.04.18 [1900 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m The following NEW packages will be installed:
[36m(setup pid=1615, ip=10.113.50.240)[0m   alsa-topology-conf alsa-ucm-conf cron htop infiniband-diags iproute2
[36m(setup pid=1615, ip=10.113.50.240)[0m   libasound2 libasound2-data libatm1 libcanberra0 libcap2-bin libelf1 libgpm2
[36m(setup pid=1615, ip=10.113.50.240)[0m   libibmad5 libibnetdisc5 libibumad3 libltdl7 libmnl0 libogg0 libpam-cap
[36m(setup pid=1615, ip=10.113.50.240)[0m   libpython3.8 libsensors-config libsensors5 libtdb1 libvorbis0a
[36m(setup pid=1615, ip=10.113.50.240)[0m   libvorbisfile3 libxtables12 net-tools sound-theme-freedesktop sysstat vim
[36m(setup pid=1615, ip=10.113.50.240)[0m   vim-common vim-runtime xxd
[36m(setup pid=1615, ip=10.113.50.240)[0m The following packages will be upgraded:
[36m(setup pid=1615, ip=10.113.50.240)[0m   libpython3.8-minimal libpython3.8-stdlib python3.8 python3.8-minimal
[36m(setup pid=2319)[0m Get:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpython3.8-minimal amd64 3.8.10-0ubuntu1~20.04.18 [721 kB]
[36m(setup pid=2319)[0m Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 cron amd64 3.0pl1-136ubuntu1 [71.5 kB]
[36m(setup pid=2319)[0m Get:6 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libelf1 amd64 0.176-1.1ubuntu0.1 [44.2 kB]
[36m(setup pid=2319)[0m Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 libmnl0 amd64 1.0.4-2 [12.3 kB]
[36m(setup pid=2319)[0m Get:8 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libxtables12 amd64 1.8.4-3ubuntu2.1 [28.7 kB]
[36m(setup pid=2319)[0m Get:9 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libcap2-bin amd64 1:2.32-1ubuntu0.2 [26.2 kB]
[36m(setup pid=2319)[0m Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 iproute2 amd64 5.5.0-1ubuntu1 [858 kB]
[36m(setup pid=2319)[0m Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 libatm1 amd64 1:2.5.1-4 [21.8 kB]
[36m(setup pid=2319)[0m Get:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpam-cap amd64 1:2.32-1ubuntu0.2 [8376 B]
[36m(setup pid=2319)[0m Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xxd amd64 2:8.1.2269-1ubuntu5.32 [50.0 kB]
[36m(setup pid=2319)[0m Get:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 vim-common all 2:8.1.2269-1ubuntu5.32 [84.9 kB]
[36m(setup pid=2319)[0m Get:15 http://archive.ubuntu.com/ubuntu focal/main amd64 alsa-topology-conf all 1.2.2-1 [7364 B]
[36m(setup pid=2319)[0m Get:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 alsa-ucm-conf all 1.2.2-1ubuntu0.13 [27.0 kB]
[36m(setup pid=2319)[0m Get:17 http://archive.ubuntu.com/ubuntu focal/main amd64 htop amd64 2.2.0-2build1 [80.5 kB]
[36m(setup pid=2319)[0m Get:18 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libasound2-data all 1.2.2-2.1ubuntu2.5 [20.1 kB]
[36m(setup pid=2319)[0m Get:19 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libasound2 amd64 1.2.2-2.1ubuntu2.5 [335 kB]
[36m(setup pid=2319)[0m Get:20 http://archive.ubuntu.com/ubuntu focal/main amd64 libltdl7 amd64 2.4.6-14 [38.5 kB]
[36m(setup pid=2319)[0m Get:21 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libtdb1 amd64 1.4.5-0ubuntu0.20.04.1 [44.2 kB]
[36m(setup pid=2319)[0m Get:22 http://archive.ubuntu.com/ubuntu focal/main amd64 libogg0 amd64 1.3.4-0ubuntu1 [24.0 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m 4 upgraded, 34 newly installed, 0 to remove and 73 not upgraded.
[36m(setup pid=1615, ip=10.113.50.240)[0m Need to get 16.7 MB of archives.
[36m(setup pid=1615, ip=10.113.50.240)[0m After this operation, 52.2 MB of additional disk space will be used.
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3.8 amd64 3.8.10-0ubuntu1~20.04.18 [387 kB]
[36m(setup pid=2319)[0m Get:23 http://archive.ubuntu.com/ubuntu focal/main amd64 libvorbis0a amd64 1.3.6-2ubuntu1 [87.0 kB]
[36m(setup pid=2319)[0m Get:24 http://archive.ubuntu.com/ubuntu focal/main amd64 libvorbisfile3 amd64 1.3.6-2ubuntu1 [16.1 kB]
[36m(setup pid=2319)[0m Get:25 http://archive.ubuntu.com/ubuntu focal/main amd64 sound-theme-freedesktop all 0.8-2ubuntu1 [384 kB]
[36m(setup pid=2319)[0m Get:26 http://archive.ubuntu.com/ubuntu focal/main amd64 libcanberra0 amd64 0.30-7ubuntu1 [38.1 kB]
[36m(setup pid=2319)[0m Get:27 http://archive.ubuntu.com/ubuntu focal/main amd64 libgpm2 amd64 1.20.7-5 [15.1 kB]
[36m(setup pid=2319)[0m Get:28 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpython3.8 amd64 3.8.10-0ubuntu1~20.04.18 [1625 kB]
[36m(setup pid=2319)[0m Get:29 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libsensors-config all 1:3.6.0-2ubuntu1.1 [6052 B]
[36m(setup pid=2319)[0m Get:30 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libsensors5 amd64 1:3.6.0-2ubuntu1.1 [27.2 kB]
[36m(setup pid=2319)[0m Get:31 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 net-tools amd64 1.60+git20180626.aebd88e-1ubuntu1.3 [192 kB]
[36m(setup pid=2319)[0m Get:32 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 sysstat amd64 12.2.0-2ubuntu0.3 [448 kB]
[36m(setup pid=2319)[0m Get:33 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 vim-runtime all 2:8.1.2269-1ubuntu5.32 [5876 kB]
[36m(setup pid=2319)[0m Get:34 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 vim amd64 2:8.1.2269-1ubuntu5.32 [1241 kB]
[36m(setup pid=2319)[0m Get:35 http://archive.ubuntu.com/ubuntu focal/main amd64 libibumad3 amd64 28.0-1ubuntu1 [25.8 kB]
[36m(setup pid=2319)[0m Get:36 http://archive.ubuntu.com/ubuntu focal/main amd64 libibmad5 amd64 28.0-1ubuntu1 [39.7 kB]
[36m(setup pid=2319)[0m Get:37 http://archive.ubuntu.com/ubuntu focal/main amd64 libibnetdisc5 amd64 28.0-1ubuntu1 [30.5 kB]
[36m(setup pid=2319)[0m Get:38 http://archive.ubuntu.com/ubuntu focal/universe amd64 infiniband-diags amd64 28.0-1ubuntu1 [224 kB]
[36m(setup pid=2319)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2319)[0m Fetched 16.7 MB in 2s (8783 kB/s)
[36m(setup pid=2319)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 20389 files and directories currently installed.)
[36m(setup pid=2319)[0m Preparing to unpack .../00-python3.8_3.8.10-0ubuntu1~20.04.18_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking python3.8 (3.8.10-0ubuntu1~20.04.18) over (3.8.10-0ubuntu1~20.04.15) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpython3.8-stdlib amd64 3.8.10-0ubuntu1~20.04.18 [1676 kB]
[36m(setup pid=2319)[0m Preparing to unpack .../01-libpython3.8-stdlib_3.8.10-0ubuntu1~20.04.18_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libpython3.8-stdlib:amd64 (3.8.10-0ubuntu1~20.04.18) over (3.8.10-0ubuntu1~20.04.15) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3.8-minimal amd64 3.8.10-0ubuntu1~20.04.18 [1900 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpython3.8-minimal amd64 3.8.10-0ubuntu1~20.04.18 [721 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 cron amd64 3.0pl1-136ubuntu1 [71.5 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:6 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libelf1 amd64 0.176-1.1ubuntu0.1 [44.2 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 libmnl0 amd64 1.0.4-2 [12.3 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:8 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libxtables12 amd64 1.8.4-3ubuntu2.1 [28.7 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:9 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libcap2-bin amd64 1:2.32-1ubuntu0.2 [26.2 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 iproute2 amd64 5.5.0-1ubuntu1 [858 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 libatm1 amd64 1:2.5.1-4 [21.8 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpam-cap amd64 1:2.32-1ubuntu0.2 [8376 B]
[36m(setup pid=2319)[0m Preparing to unpack .../02-python3.8-minimal_3.8.10-0ubuntu1~20.04.18_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking python3.8-minimal (3.8.10-0ubuntu1~20.04.18) over (3.8.10-0ubuntu1~20.04.15) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xxd amd64 2:8.1.2269-1ubuntu5.32 [50.0 kB]
[36m(setup pid=2319)[0m Preparing to unpack .../03-libpython3.8-minimal_3.8.10-0ubuntu1~20.04.18_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 vim-common all 2:8.1.2269-1ubuntu5.32 [84.9 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:15 http://archive.ubuntu.com/ubuntu focal/main amd64 alsa-topology-conf all 1.2.2-1 [7364 B]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 alsa-ucm-conf all 1.2.2-1ubuntu0.13 [27.0 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:17 http://archive.ubuntu.com/ubuntu focal/main amd64 htop amd64 2.2.0-2build1 [80.5 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:18 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libasound2-data all 1.2.2-2.1ubuntu2.5 [20.1 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:19 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libasound2 amd64 1.2.2-2.1ubuntu2.5 [335 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:20 http://archive.ubuntu.com/ubuntu focal/main amd64 libltdl7 amd64 2.4.6-14 [38.5 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:21 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libtdb1 amd64 1.4.5-0ubuntu0.20.04.1 [44.2 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:22 http://archive.ubuntu.com/ubuntu focal/main amd64 libogg0 amd64 1.3.4-0ubuntu1 [24.0 kB]
[36m(setup pid=2319)[0m Unpacking libpython3.8-minimal:amd64 (3.8.10-0ubuntu1~20.04.18) over (3.8.10-0ubuntu1~20.04.15) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:23 http://archive.ubuntu.com/ubuntu focal/main amd64 libvorbis0a amd64 1.3.6-2ubuntu1 [87.0 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:24 http://archive.ubuntu.com/ubuntu focal/main amd64 libvorbisfile3 amd64 1.3.6-2ubuntu1 [16.1 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:25 http://archive.ubuntu.com/ubuntu focal/main amd64 sound-theme-freedesktop all 0.8-2ubuntu1 [384 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:26 http://archive.ubuntu.com/ubuntu focal/main amd64 libcanberra0 amd64 0.30-7ubuntu1 [38.1 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:27 http://archive.ubuntu.com/ubuntu focal/main amd64 libgpm2 amd64 1.20.7-5 [15.1 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:28 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpython3.8 amd64 3.8.10-0ubuntu1~20.04.18 [1625 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:29 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libsensors-config all 1:3.6.0-2ubuntu1.1 [6052 B]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:30 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libsensors5 amd64 1:3.6.0-2ubuntu1.1 [27.2 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:31 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 net-tools amd64 1.60+git20180626.aebd88e-1ubuntu1.3 [192 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:32 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 sysstat amd64 12.2.0-2ubuntu0.3 [448 kB]
[36m(setup pid=2319)[0m Selecting previously unselected package cron.
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:33 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 vim-runtime all 2:8.1.2269-1ubuntu5.32 [5876 kB]
[36m(setup pid=2319)[0m Preparing to unpack .../04-cron_3.0pl1-136ubuntu1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking cron (3.0pl1-136ubuntu1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../05-libelf1_0.176-1.1ubuntu0.1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libelf1:amd64 (0.176-1.1ubuntu0.1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../06-libmnl0_1.0.4-2_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libmnl0:amd64 (1.0.4-2) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../07-libxtables12_1.8.4-3ubuntu2.1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libxtables12:amd64 (1.8.4-3ubuntu2.1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libcap2-bin.
[36m(setup pid=2319)[0m Preparing to unpack .../08-libcap2-bin_1%3a2.32-1ubuntu0.2_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libcap2-bin (1:2.32-1ubuntu0.2) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:34 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 vim amd64 2:8.1.2269-1ubuntu5.32 [1241 kB]
[36m(setup pid=2319)[0m Selecting previously unselected package iproute2.
[36m(setup pid=2319)[0m Preparing to unpack .../09-iproute2_5.5.0-1ubuntu1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking iproute2 (5.5.0-1ubuntu1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../10-libatm1_1%3a2.5.1-4_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libatm1:amd64 (1:2.5.1-4) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:35 http://archive.ubuntu.com/ubuntu focal/main amd64 libibumad3 amd64 28.0-1ubuntu1 [25.8 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:36 http://archive.ubuntu.com/ubuntu focal/main amd64 libibmad5 amd64 28.0-1ubuntu1 [39.7 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:37 http://archive.ubuntu.com/ubuntu focal/main amd64 libibnetdisc5 amd64 28.0-1ubuntu1 [30.5 kB]
[36m(setup pid=1615, ip=10.113.50.240)[0m Get:38 http://archive.ubuntu.com/ubuntu focal/universe amd64 infiniband-diags amd64 28.0-1ubuntu1 [224 kB]
[36m(setup pid=2319)[0m Selecting previously unselected package libpam-cap:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../11-libpam-cap_1%3a2.32-1ubuntu0.2_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libpam-cap:amd64 (1:2.32-1ubuntu0.2) ...
[36m(setup pid=2319)[0m Selecting previously unselected package xxd.
[36m(setup pid=2319)[0m Preparing to unpack .../12-xxd_2%3a8.1.2269-1ubuntu5.32_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking xxd (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=2319)[0m Selecting previously unselected package vim-common.
[36m(setup pid=2319)[0m Preparing to unpack .../13-vim-common_2%3a8.1.2269-1ubuntu5.32_all.deb ...
[36m(setup pid=2319)[0m Unpacking vim-common (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=2319)[0m Selecting previously unselected package alsa-topology-conf.
[36m(setup pid=2319)[0m Preparing to unpack .../14-alsa-topology-conf_1.2.2-1_all.deb ...
[36m(setup pid=2319)[0m Unpacking alsa-topology-conf (1.2.2-1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package alsa-ucm-conf.
[36m(setup pid=2319)[0m Preparing to unpack .../15-alsa-ucm-conf_1.2.2-1ubuntu0.13_all.deb ...
[36m(setup pid=2319)[0m Unpacking alsa-ucm-conf (1.2.2-1ubuntu0.13) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=1615, ip=10.113.50.240)[0m Fetched 16.7 MB in 2s (8490 kB/s)
[36m(setup pid=2319)[0m Selecting previously unselected package htop.
[36m(setup pid=2319)[0m Preparing to unpack .../16-htop_2.2.0-2build1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking htop (2.2.0-2build1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libasound2-data.
[36m(setup pid=2319)[0m Preparing to unpack .../17-libasound2-data_1.2.2-2.1ubuntu2.5_all.deb ...
[36m(setup pid=2319)[0m Unpacking libasound2-data (1.2.2-2.1ubuntu2.5) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libasound2:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../18-libasound2_1.2.2-2.1ubuntu2.5_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libasound2:amd64 (1.2.2-2.1ubuntu2.5) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libltdl7:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../19-libltdl7_2.4.6-14_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 20389 files and directories currently installed.)
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../00-python3.8_3.8.10-0ubuntu1~20.04.18_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libltdl7:amd64 (2.4.6-14) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libtdb1:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../20-libtdb1_1.4.5-0ubuntu0.20.04.1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libtdb1:amd64 (1.4.5-0ubuntu0.20.04.1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libogg0:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../21-libogg0_1.3.4-0ubuntu1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libogg0:amd64 (1.3.4-0ubuntu1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libvorbis0a:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../22-libvorbis0a_1.3.6-2ubuntu1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libvorbis0a:amd64 (1.3.6-2ubuntu1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libvorbisfile3:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../23-libvorbisfile3_1.3.6-2ubuntu1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libvorbisfile3:amd64 (1.3.6-2ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking python3.8 (3.8.10-0ubuntu1~20.04.18) over (3.8.10-0ubuntu1~20.04.15) ...
[36m(setup pid=2319)[0m Selecting previously unselected package sound-theme-freedesktop.
[36m(setup pid=2319)[0m Preparing to unpack .../24-sound-theme-freedesktop_0.8-2ubuntu1_all.deb ...
[36m(setup pid=2319)[0m Unpacking sound-theme-freedesktop (0.8-2ubuntu1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libcanberra0:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../25-libcanberra0_0.30-7ubuntu1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libcanberra0:amd64 (0.30-7ubuntu1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libgpm2:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../26-libgpm2_1.20.7-5_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libgpm2:amd64 (1.20.7-5) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libpython3.8:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../27-libpython3.8_3.8.10-0ubuntu1~20.04.18_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libpython3.8:amd64 (3.8.10-0ubuntu1~20.04.18) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=2319)[0m Preparing to unpack .../28-libsensors-config_1%3a3.6.0-2ubuntu1.1_all.deb ...
[36m(setup pid=2319)[0m Unpacking libsensors-config (1:3.6.0-2ubuntu1.1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../29-libsensors5_1%3a3.6.0-2ubuntu1.1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libsensors5:amd64 (1:3.6.0-2ubuntu1.1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package net-tools.
[36m(setup pid=2319)[0m Preparing to unpack .../30-net-tools_1.60+git20180626.aebd88e-1ubuntu1.3_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking net-tools (1.60+git20180626.aebd88e-1ubuntu1.3) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../01-libpython3.8-stdlib_3.8.10-0ubuntu1~20.04.18_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libpython3.8-stdlib:amd64 (3.8.10-0ubuntu1~20.04.18) over (3.8.10-0ubuntu1~20.04.15) ...
[36m(setup pid=2319)[0m Selecting previously unselected package sysstat.
[36m(setup pid=2319)[0m Preparing to unpack .../31-sysstat_12.2.0-2ubuntu0.3_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking sysstat (12.2.0-2ubuntu0.3) ...
[36m(setup pid=2319)[0m Selecting previously unselected package vim-runtime.
[36m(setup pid=2319)[0m Preparing to unpack .../32-vim-runtime_2%3a8.1.2269-1ubuntu5.32_all.deb ...
[36m(setup pid=2319)[0m Adding 'diversion of /usr/share/vim/vim81/doc/help.txt to /usr/share/vim/vim81/doc/help.txt.vim-tiny by vim-runtime'
[36m(setup pid=2319)[0m Adding 'diversion of /usr/share/vim/vim81/doc/tags to /usr/share/vim/vim81/doc/tags.vim-tiny by vim-runtime'
[36m(setup pid=2319)[0m Unpacking vim-runtime (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../02-python3.8-minimal_3.8.10-0ubuntu1~20.04.18_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking python3.8-minimal (3.8.10-0ubuntu1~20.04.18) over (3.8.10-0ubuntu1~20.04.15) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../03-libpython3.8-minimal_3.8.10-0ubuntu1~20.04.18_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libpython3.8-minimal:amd64 (3.8.10-0ubuntu1~20.04.18) over (3.8.10-0ubuntu1~20.04.15) ...
[36m(setup pid=2319)[0m Selecting previously unselected package vim.
[36m(setup pid=2319)[0m Preparing to unpack .../33-vim_2%3a8.1.2269-1ubuntu5.32_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking vim (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package cron.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../04-cron_3.0pl1-136ubuntu1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking cron (3.0pl1-136ubuntu1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libibumad3:amd64.
[36m(setup pid=2319)[0m Preparing to unpack .../34-libibumad3_28.0-1ubuntu1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libibumad3:amd64 (28.0-1ubuntu1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libibmad5.
[36m(setup pid=2319)[0m Preparing to unpack .../35-libibmad5_28.0-1ubuntu1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libibmad5 (28.0-1ubuntu1) ...
[36m(setup pid=2319)[0m Selecting previously unselected package libibnetdisc5.
[36m(setup pid=2319)[0m Preparing to unpack .../36-libibnetdisc5_28.0-1ubuntu1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking libibnetdisc5 (28.0-1ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../05-libelf1_0.176-1.1ubuntu0.1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libelf1:amd64 (0.176-1.1ubuntu0.1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../06-libmnl0_1.0.4-2_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libmnl0:amd64 (1.0.4-2) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../07-libxtables12_1.8.4-3ubuntu2.1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libxtables12:amd64 (1.8.4-3ubuntu2.1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libcap2-bin.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../08-libcap2-bin_1%3a2.32-1ubuntu0.2_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libcap2-bin (1:2.32-1ubuntu0.2) ...
[36m(setup pid=2319)[0m Selecting previously unselected package infiniband-diags.
[36m(setup pid=2319)[0m Preparing to unpack .../37-infiniband-diags_28.0-1ubuntu1_amd64.deb ...
[36m(setup pid=2319)[0m Unpacking infiniband-diags (28.0-1ubuntu1) ...
[36m(setup pid=2319)[0m Setting up net-tools (1.60+git20180626.aebd88e-1ubuntu1.3) ...
[36m(setup pid=2319)[0m Setting up libpython3.8-minimal:amd64 (3.8.10-0ubuntu1~20.04.18) ...
[36m(setup pid=2319)[0m Setting up libgpm2:amd64 (1.20.7-5) ...
[36m(setup pid=2319)[0m Setting up libogg0:amd64 (1.3.4-0ubuntu1) ...
[36m(setup pid=2319)[0m Setting up alsa-ucm-conf (1.2.2-1ubuntu0.13) ...
[36m(setup pid=2319)[0m Setting up htop (2.2.0-2build1) ...
[36m(setup pid=2319)[0m Setting up libtdb1:amd64 (1.4.5-0ubuntu0.20.04.1) ...
[36m(setup pid=2319)[0m Setting up cron (3.0pl1-136ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package iproute2.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../09-iproute2_5.5.0-1ubuntu1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking iproute2 (5.5.0-1ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../10-libatm1_1%3a2.5.1-4_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libatm1:amd64 (1:2.5.1-4) ...
[36m(setup pid=2319)[0m Adding group `crontab' (GID 107) ...
[36m(setup pid=2319)[0m Done.
[36m(setup pid=2319)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=2319)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libpam-cap:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../11-libpam-cap_1%3a2.32-1ubuntu0.2_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libpam-cap:amd64 (1:2.32-1ubuntu0.2) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package xxd.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../12-xxd_2%3a8.1.2269-1ubuntu5.32_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking xxd (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package vim-common.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../13-vim-common_2%3a8.1.2269-1ubuntu5.32_all.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking vim-common (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package alsa-topology-conf.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../14-alsa-topology-conf_1.2.2-1_all.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking alsa-topology-conf (1.2.2-1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package alsa-ucm-conf.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../15-alsa-ucm-conf_1.2.2-1ubuntu0.13_all.deb ...
[36m(setup pid=2319)[0m Created symlink /etc/systemd/system/multi-user.target.wants/cron.service → /lib/systemd/system/cron.service.
[36m(setup pid=2319)[0m Setting up libsensors-config (1:3.6.0-2ubuntu1.1) ...
[36m(setup pid=2319)[0m Setting up libibumad3:amd64 (28.0-1ubuntu1) ...
[36m(setup pid=2319)[0m Setting up libibmad5 (28.0-1ubuntu1) ...
[36m(setup pid=2319)[0m Setting up libatm1:amd64 (1:2.5.1-4) ...
[36m(setup pid=2319)[0m Setting up xxd (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=2319)[0m Setting up libcap2-bin (1:2.32-1ubuntu0.2) ...
[36m(setup pid=2319)[0m Setting up libasound2-data (1.2.2-2.1ubuntu2.5) ...
[36m(setup pid=2319)[0m Setting up vim-common (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=2319)[0m Setting up libmnl0:amd64 (1.0.4-2) ...
[36m(setup pid=2319)[0m Setting up libvorbis0a:amd64 (1.3.6-2ubuntu1) ...
[36m(setup pid=2319)[0m Setting up libibnetdisc5 (28.0-1ubuntu1) ...
[36m(setup pid=2319)[0m Setting up libsensors5:amd64 (1:3.6.0-2ubuntu1.1) ...
[36m(setup pid=2319)[0m Setting up libxtables12:amd64 (1.8.4-3ubuntu2.1) ...
[36m(setup pid=2319)[0m Setting up libltdl7:amd64 (2.4.6-14) ...
[36m(setup pid=2319)[0m Setting up alsa-topology-conf (1.2.2-1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking alsa-ucm-conf (1.2.2-1ubuntu0.13) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package htop.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../16-htop_2.2.0-2build1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking htop (2.2.0-2build1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libasound2-data.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../17-libasound2-data_1.2.2-2.1ubuntu2.5_all.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libasound2-data (1.2.2-2.1ubuntu2.5) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libasound2:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../18-libasound2_1.2.2-2.1ubuntu2.5_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libasound2:amd64 (1.2.2-2.1ubuntu2.5) ...
[36m(setup pid=2319)[0m Setting up python3.8-minimal (3.8.10-0ubuntu1~20.04.18) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libltdl7:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../19-libltdl7_2.4.6-14_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libltdl7:amd64 (2.4.6-14) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libtdb1:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../20-libtdb1_1.4.5-0ubuntu0.20.04.1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libtdb1:amd64 (1.4.5-0ubuntu0.20.04.1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libogg0:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../21-libogg0_1.3.4-0ubuntu1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libogg0:amd64 (1.3.4-0ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libvorbis0a:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../22-libvorbis0a_1.3.6-2ubuntu1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libvorbis0a:amd64 (1.3.6-2ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libvorbisfile3:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../23-libvorbisfile3_1.3.6-2ubuntu1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libvorbisfile3:amd64 (1.3.6-2ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package sound-theme-freedesktop.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../24-sound-theme-freedesktop_0.8-2ubuntu1_all.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking sound-theme-freedesktop (0.8-2ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libcanberra0:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../25-libcanberra0_0.30-7ubuntu1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libcanberra0:amd64 (0.30-7ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libgpm2:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../26-libgpm2_1.20.7-5_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libgpm2:amd64 (1.20.7-5) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libpython3.8:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../27-libpython3.8_3.8.10-0ubuntu1~20.04.18_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libpython3.8:amd64 (3.8.10-0ubuntu1~20.04.18) ...
[36m(setup pid=2319)[0m Setting up sound-theme-freedesktop (0.8-2ubuntu1) ...
[36m(setup pid=2319)[0m Setting up libasound2:amd64 (1.2.2-2.1ubuntu2.5) ...
[36m(setup pid=2319)[0m Setting up vim-runtime (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../28-libsensors-config_1%3a3.6.0-2ubuntu1.1_all.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libsensors-config (1:3.6.0-2ubuntu1.1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../29-libsensors5_1%3a3.6.0-2ubuntu1.1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libsensors5:amd64 (1:3.6.0-2ubuntu1.1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package net-tools.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../30-net-tools_1.60+git20180626.aebd88e-1ubuntu1.3_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking net-tools (1.60+git20180626.aebd88e-1ubuntu1.3) ...
[36m(setup pid=2319)[0m Setting up libpython3.8-stdlib:amd64 (3.8.10-0ubuntu1~20.04.18) ...
[36m(setup pid=2319)[0m Setting up python3.8 (3.8.10-0ubuntu1~20.04.18) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package sysstat.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../31-sysstat_12.2.0-2ubuntu0.3_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking sysstat (12.2.0-2ubuntu0.3) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package vim-runtime.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../32-vim-runtime_2%3a8.1.2269-1ubuntu5.32_all.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Adding 'diversion of /usr/share/vim/vim81/doc/help.txt to /usr/share/vim/vim81/doc/help.txt.vim-tiny by vim-runtime'
[36m(setup pid=1615, ip=10.113.50.240)[0m Adding 'diversion of /usr/share/vim/vim81/doc/tags to /usr/share/vim/vim81/doc/tags.vim-tiny by vim-runtime'
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking vim-runtime (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=2319)[0m Setting up libelf1:amd64 (0.176-1.1ubuntu0.1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package vim.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../33-vim_2%3a8.1.2269-1ubuntu5.32_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking vim (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=2319)[0m Setting up libpam-cap:amd64 (1:2.32-1ubuntu0.2) ...
[36m(setup pid=2319)[0m Setting up sysstat (12.2.0-2ubuntu0.3) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libibumad3:amd64.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../34-libibumad3_28.0-1ubuntu1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libibumad3:amd64 (28.0-1ubuntu1) ...
[36m(setup pid=2319)[0m 
[36m(setup pid=2319)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=2319)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libibmad5.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../35-libibmad5_28.0-1ubuntu1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libibmad5 (28.0-1ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package libibnetdisc5.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../36-libibnetdisc5_28.0-1ubuntu1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking libibnetdisc5 (28.0-1ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Selecting previously unselected package infiniband-diags.
[36m(setup pid=1615, ip=10.113.50.240)[0m Preparing to unpack .../37-infiniband-diags_28.0-1ubuntu1_amd64.deb ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Unpacking infiniband-diags (28.0-1ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up net-tools (1.60+git20180626.aebd88e-1ubuntu1.3) ...
[36m(setup pid=2319)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.
[36m(setup pid=2319)[0m Setting up infiniband-diags (28.0-1ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libpython3.8-minimal:amd64 (3.8.10-0ubuntu1~20.04.18) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libgpm2:amd64 (1.20.7-5) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libogg0:amd64 (1.3.4-0ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up alsa-ucm-conf (1.2.2-1ubuntu0.13) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up htop (2.2.0-2build1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libtdb1:amd64 (1.4.5-0ubuntu0.20.04.1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up cron (3.0pl1-136ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Adding group `crontab' (GID 107) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Done.
[36m(setup pid=1615, ip=10.113.50.240)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=1615, ip=10.113.50.240)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=2319)[0m Setting up iproute2 (5.5.0-1ubuntu1) ...
[36m(setup pid=2319)[0m Setting up libvorbisfile3:amd64 (1.3.6-2ubuntu1) ...
[36m(setup pid=2319)[0m Setting up libpython3.8:amd64 (3.8.10-0ubuntu1~20.04.18) ...
[36m(setup pid=2319)[0m Setting up libcanberra0:amd64 (0.30-7ubuntu1) ...
[36m(setup pid=2319)[0m Setting up vim (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=2319)[0m update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/vim (vim) in auto mode
[36m(setup pid=2319)[0m update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/vimdiff (vimdiff) in auto mode
[36m(setup pid=2319)[0m update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/rvim (rvim) in auto mode
[36m(setup pid=2319)[0m update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/rview (rview) in auto mode
[36m(setup pid=2319)[0m update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/vi (vi) in auto mode
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/da/man1/vi.1.gz because associated file /usr/share/man/da/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/de/man1/vi.1.gz because associated file /usr/share/man/de/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/fr/man1/vi.1.gz because associated file /usr/share/man/fr/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/it/man1/vi.1.gz because associated file /usr/share/man/it/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/ja/man1/vi.1.gz because associated file /usr/share/man/ja/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/pl/man1/vi.1.gz because associated file /usr/share/man/pl/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/ru/man1/vi.1.gz because associated file /usr/share/man/ru/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/vi.1.gz because associated file /usr/share/man/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/view (view) in auto mode
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/da/man1/view.1.gz because associated file /usr/share/man/da/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/de/man1/view.1.gz because associated file /usr/share/man/de/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/fr/man1/view.1.gz because associated file /usr/share/man/fr/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/it/man1/view.1.gz because associated file /usr/share/man/it/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/ja/man1/view.1.gz because associated file /usr/share/man/ja/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/pl/man1/view.1.gz because associated file /usr/share/man/pl/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/ru/man1/view.1.gz because associated file /usr/share/man/ru/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/view.1.gz because associated file /usr/share/man/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/ex (ex) in auto mode
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/da/man1/ex.1.gz because associated file /usr/share/man/da/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/de/man1/ex.1.gz because associated file /usr/share/man/de/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/fr/man1/ex.1.gz because associated file /usr/share/man/fr/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/it/man1/ex.1.gz because associated file /usr/share/man/it/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/ja/man1/ex.1.gz because associated file /usr/share/man/ja/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/pl/man1/ex.1.gz because associated file /usr/share/man/pl/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/ru/man1/ex.1.gz because associated file /usr/share/man/ru/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=2319)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/ex.1.gz because associated file /usr/share/man/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m Created symlink /etc/systemd/system/multi-user.target.wants/cron.service → /lib/systemd/system/cron.service.
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libsensors-config (1:3.6.0-2ubuntu1.1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libibumad3:amd64 (28.0-1ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libibmad5 (28.0-1ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libatm1:amd64 (1:2.5.1-4) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up xxd (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=2319)[0m Processing triggers for libc-bin (2.31-0ubuntu9.12) ...
[36m(setup pid=2319)[0m Processing triggers for systemd (245.4-4ubuntu3.24) ...
[36m(setup pid=2319)[0m Processing triggers for mime-support (3.64ubuntu1) ...
[36m(setup pid=2319)[0m Using Python 3.10.13 environment at: /home/sky/training
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libcap2-bin (1:2.32-1ubuntu0.2) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libasound2-data (1.2.2-2.1ubuntu2.5) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up vim-common (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libmnl0:amd64 (1.0.4-2) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libvorbis0a:amd64 (1.3.6-2ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libibnetdisc5 (28.0-1ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libsensors5:amd64 (1:3.6.0-2ubuntu1.1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libxtables12:amd64 (1.8.4-3ubuntu2.1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libltdl7:amd64 (2.4.6-14) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up alsa-topology-conf (1.2.2-1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up python3.8-minimal (3.8.10-0ubuntu1~20.04.18) ...
[36m(setup pid=2319)[0m Resolved 3 packages in 152ms
[36m(setup pid=2319)[0m Prepared 2 packages in 11ms
[36m(setup pid=2319)[0m Installed 2 packages in 17ms
[36m(setup pid=2319)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=2319)[0m  + nvitop==1.5.2
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up sound-theme-freedesktop (0.8-2ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libasound2:amd64 (1.2.2-2.1ubuntu2.5) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up vim-runtime (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libpython3.8-stdlib:amd64 (3.8.10-0ubuntu1~20.04.18) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up python3.8 (3.8.10-0ubuntu1~20.04.18) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libelf1:amd64 (0.176-1.1ubuntu0.1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libpam-cap:amd64 (1:2.32-1ubuntu0.2) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up sysstat (12.2.0-2ubuntu0.3) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m 
[36m(setup pid=1615, ip=10.113.50.240)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up infiniband-diags (28.0-1ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up iproute2 (5.5.0-1ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libvorbisfile3:amd64 (1.3.6-2ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libpython3.8:amd64 (3.8.10-0ubuntu1~20.04.18) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up libcanberra0:amd64 (0.30-7ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Setting up vim (2:8.1.2269-1ubuntu5.32) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/vim (vim) in auto mode
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/vimdiff (vimdiff) in auto mode
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/rvim (rvim) in auto mode
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/rview (rview) in auto mode
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/vi (vi) in auto mode
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/da/man1/vi.1.gz because associated file /usr/share/man/da/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/de/man1/vi.1.gz because associated file /usr/share/man/de/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/fr/man1/vi.1.gz because associated file /usr/share/man/fr/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/it/man1/vi.1.gz because associated file /usr/share/man/it/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/ja/man1/vi.1.gz because associated file /usr/share/man/ja/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/pl/man1/vi.1.gz because associated file /usr/share/man/pl/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/ru/man1/vi.1.gz because associated file /usr/share/man/ru/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/vi.1.gz because associated file /usr/share/man/man1/vim.1.gz (of link group vi) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/view (view) in auto mode
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/da/man1/view.1.gz because associated file /usr/share/man/da/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/de/man1/view.1.gz because associated file /usr/share/man/de/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/fr/man1/view.1.gz because associated file /usr/share/man/fr/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/it/man1/view.1.gz because associated file /usr/share/man/it/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/ja/man1/view.1.gz because associated file /usr/share/man/ja/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/pl/man1/view.1.gz because associated file /usr/share/man/pl/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/ru/man1/view.1.gz because associated file /usr/share/man/ru/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/view.1.gz because associated file /usr/share/man/man1/vim.1.gz (of link group view) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/ex (ex) in auto mode
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/da/man1/ex.1.gz because associated file /usr/share/man/da/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/de/man1/ex.1.gz because associated file /usr/share/man/de/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/fr/man1/ex.1.gz because associated file /usr/share/man/fr/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/it/man1/ex.1.gz because associated file /usr/share/man/it/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/ja/man1/ex.1.gz because associated file /usr/share/man/ja/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/pl/man1/ex.1.gz because associated file /usr/share/man/pl/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/ru/man1/ex.1.gz because associated file /usr/share/man/ru/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/ex.1.gz because associated file /usr/share/man/man1/vim.1.gz (of link group ex) doesn't exist
[36m(setup pid=1615, ip=10.113.50.240)[0m Processing triggers for libc-bin (2.31-0ubuntu9.12) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Processing triggers for systemd (245.4-4ubuntu3.24) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Processing triggers for mime-support (3.64ubuntu1) ...
[36m(setup pid=1615, ip=10.113.50.240)[0m Using Python 3.10.13 environment at: /home/sky/training
[36m(setup pid=1615, ip=10.113.50.240)[0m Resolved 3 packages in 52ms
[36m(setup pid=1615, ip=10.113.50.240)[0m Prepared 2 packages in 9ms
[36m(setup pid=1615, ip=10.113.50.240)[0m Installed 2 packages in 16ms
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=1615, ip=10.113.50.240)[0m  + nvitop==1.5.2
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(head, rank=0, pid=2319)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(head, rank=0, pid=2319)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=2319)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m Setting num_proc from 32 to 10 for the train split as it only contains 10 shards.
[36m(head, rank=0, pid=2319)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Setting num_proc from 32 to 10 for the train split as it only contains 10 shards.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=2319)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Generating train split:   2%|▏         | 1000/47780 [00:00<00:24, 1921.92 examples/s]
[36m(head, rank=0, pid=2319)[0m Generating train split:   2%|▏         | 1000/47780 [00:00<00:25, 1844.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Generating train split:  15%|█▍        | 7000/47780 [00:00<00:02, 14262.76 examples/s]
[36m(head, rank=0, pid=2319)[0m Generating train split:  13%|█▎        | 6000/47780 [00:00<00:03, 11875.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Generating train split:  23%|██▎       | 11000/47780 [00:00<00:01, 20077.00 examples/s]
[36m(head, rank=0, pid=2319)[0m Generating train split:  23%|██▎       | 11000/47780 [00:00<00:01, 19703.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Generating train split:  36%|███▌      | 17000/47780 [00:00<00:01, 29597.49 examples/s]
[36m(head, rank=0, pid=2319)[0m Generating train split:  31%|███▏      | 15000/47780 [00:00<00:01, 24453.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Generating train split:  46%|████▌     | 22000/47780 [00:00<00:00, 31520.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Generating train split:  63%|██████▎   | 30000/47780 [00:01<00:00, 42943.69 examples/s]
[36m(head, rank=0, pid=2319)[0m Generating train split:  44%|████▍     | 21000/47780 [00:00<00:00, 31653.09 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Generating train split:  80%|████████  | 38334/47780 [00:01<00:00, 53314.23 examples/s]
[36m(head, rank=0, pid=2319)[0m Generating train split:  61%|██████    | 29000/47780 [00:01<00:00, 39833.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Generating train split:  98%|█████████▊| 47002/47780 [00:01<00:00, 62120.46 examples/s]
Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 34937.37 examples/s]
[36m(head, rank=0, pid=2319)[0m Generating train split:  79%|███████▉  | 37778/47780 [00:01<00:00, 50366.36 examples/s]
[36m(head, rank=0, pid=2319)[0m Generating train split:  97%|█████████▋| 46224/47780 [00:01<00:00, 57175.32 examples/s]
Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 32400.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=2319)[0m 
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=2319)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:  20%|██        | 1/5 [00:14<00:59, 14.95s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  2.99s/it]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Fetching 5 files:  20%|██        | 1/5 [00:14<00:59, 14.93s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  2.99s/it]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Fetching 5 files:  20%|██        | 1/5 [00:14<00:59, 14.90s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  2.98s/it]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Fetching 5 files:  20%|██        | 1/5 [00:14<00:59, 14.93s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  2.99s/it]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Fetching 5 files:  20%|██        | 1/5 [00:14<00:59, 14.94s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  2.99s/it]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Fetching 5 files:  20%|██        | 1/5 [00:14<00:58, 14.68s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  2.94s/it]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Fetching 5 files:  20%|██        | 1/5 [00:14<00:59, 14.98s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  3.00s/it]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Fetching 5 files:  20%|██        | 1/5 [00:14<00:59, 14.98s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:14<00:00,  3.00s/it]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 138.26it/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 139.17it/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 138.34it/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 135.10it/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 137.20it/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 138.60it/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 139.11it/s]
[36m(head, rank=0, pid=2319)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
Fetching 5 files:  20%|██        | 1/5 [00:16<01:05, 16.43s/it]
Fetching 5 files:  20%|██        | 1/5 [00:16<01:05, 16.41s/it]
Fetching 5 files:  20%|██        | 1/5 [00:16<01:05, 16.41s/it]
Fetching 5 files:  20%|██        | 1/5 [00:16<01:05, 16.38s/it]
Fetching 5 files:  20%|██        | 1/5 [00:16<01:05, 16.43s/it]
Fetching 5 files:  20%|██        | 1/5 [00:16<01:05, 16.44s/it]
Fetching 5 files:  20%|██        | 1/5 [00:16<01:05, 16.41s/it]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:16,  4.05s/it]
[36m(head, rank=0, pid=2319)[0m Fetching 5 files:  20%|██        | 1/5 [00:16<01:05, 16.43s/it]
Fetching 5 files:  60%|██████    | 3/5 [00:25<00:15,  7.60s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:25<00:00,  5.09s/it]
[36m(head, rank=0, pid=2319)[0m 
Fetching 5 files:  60%|██████    | 3/5 [00:25<00:15,  7.58s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:25<00:00,  5.08s/it]
[36m(head, rank=0, pid=2319)[0m 
Fetching 5 files:  60%|██████    | 3/5 [00:25<00:15,  7.59s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:25<00:00,  5.08s/it]
[36m(head, rank=0, pid=2319)[0m 
Fetching 5 files:  60%|██████    | 3/5 [00:25<00:15,  7.60s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:25<00:00,  5.09s/it]
[36m(head, rank=0, pid=2319)[0m 
Fetching 5 files:  60%|██████    | 3/5 [00:25<00:15,  7.60s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:25<00:00,  5.09s/it]
[36m(head, rank=0, pid=2319)[0m 
Fetching 5 files:  60%|██████    | 3/5 [00:25<00:15,  7.61s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:25<00:00,  5.09s/it]
[36m(head, rank=0, pid=2319)[0m 
Fetching 5 files:  60%|██████    | 3/5 [00:25<00:15,  7.61s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:25<00:00,  5.10s/it]
[36m(head, rank=0, pid=2319)[0m 
Fetching 5 files:  60%|██████    | 3/5 [00:25<00:15,  7.61s/it]
Fetching 5 files: 100%|██████████| 5/5 [00:25<00:00,  5.10s/it]
[36m(head, rank=0, pid=2319)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=2319)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 140.46it/s]
[36m(head, rank=0, pid=2319)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 138.54it/s]
[36m(head, rank=0, pid=2319)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 134.80it/s]
[36m(head, rank=0, pid=2319)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 136.14it/s]
[36m(head, rank=0, pid=2319)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 135.05it/s]
[36m(head, rank=0, pid=2319)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 137.41it/s]
[36m(head, rank=0, pid=2319)[0m 
Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 136.46it/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:07<00:11,  3.96s/it]
[36m(head, rank=0, pid=2319)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:11<00:07,  3.89s/it]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:15<00:03,  3.85s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.73s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.81s/it]
[36m(head, rank=0, pid=2319)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:16,  4.25s/it]
[36m(head, rank=0, pid=2319)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:08<00:12,  4.11s/it]
[36m(head, rank=0, pid=2319)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:12<00:07,  3.97s/it]
[36m(head, rank=0, pid=2319)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:15<00:03,  3.90s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.78s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.88s/it]
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:10<23:29:49,  1.77s/ examples]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   0%|          | 33/47780 [00:10<3:17:14,  4.03 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   0%|          | 62/47780 [00:11<1:29:18,  8.90 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   0%|          | 103/47780 [00:11<44:38, 17.80 examples/s] 
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   0%|          | 174/47780 [00:11<21:24, 37.08 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   1%|          | 250/47780 [00:12<13:06, 60.42 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   1%|          | 342/47780 [00:12<08:51, 89.27 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   1%|          | 469/47780 [00:13<05:50, 134.81 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 671/47780 [00:13<03:43, 210.32 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 900/47780 [00:13<02:30, 311.24 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1036/47780 [00:14<02:20, 332.39 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1197/47780 [00:14<02:05, 370.29 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1372/47780 [00:14<01:55, 403.16 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1571/47780 [00:15<01:43, 446.53 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1790/47780 [00:15<01:33, 493.32 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2017/47780 [00:15<01:25, 533.30 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2259/47780 [00:16<01:19, 573.96 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2490/47780 [00:16<01:15, 600.37 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2748/47780 [00:16<01:08, 654.20 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2980/47780 [00:17<01:06, 671.96 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3207/47780 [00:17<01:05, 677.98 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3491/47780 [00:17<01:00, 732.10 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3771/47780 [00:18<00:57, 767.06 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4075/47780 [00:18<00:53, 815.34 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4368/47780 [00:18<00:51, 840.62 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4671/47780 [00:19<00:49, 866.38 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5021/47780 [00:19<00:46, 923.79 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5416/47780 [00:19<00:33, 1271.05 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5599/47780 [00:19<00:34, 1221.61 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5760/47780 [00:19<00:34, 1213.33 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5911/47780 [00:20<00:34, 1218.05 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6052/47780 [00:20<00:35, 1190.04 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6183/47780 [00:20<00:35, 1173.02 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6309/47780 [00:20<00:34, 1187.79 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6435/47780 [00:20<00:35, 1155.50 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6555/47780 [00:20<00:36, 1126.40 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6672/47780 [00:20<00:36, 1129.22 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6804/47780 [00:20<00:34, 1177.09 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6927/47780 [00:20<00:34, 1191.56 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7049/47780 [00:21<00:34, 1189.02 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7170/47780 [00:21<00:34, 1170.59 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7308/47780 [00:21<00:32, 1227.71 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7441/47780 [00:21<00:32, 1248.64 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7569/47780 [00:21<00:32, 1235.48 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7703/47780 [00:21<00:31, 1264.18 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7830/47780 [00:21<00:32, 1231.66 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7959/47780 [00:21<00:31, 1245.93 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8086/47780 [00:21<00:32, 1214.23 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8209/47780 [00:22<00:33, 1170.67 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8339/47780 [00:22<00:32, 1202.96 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8464/47780 [00:22<00:33, 1158.90 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8585/47780 [00:22<00:34, 1140.02 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8727/47780 [00:22<00:32, 1186.25 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8857/47780 [00:22<00:31, 1217.10 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 8981/47780 [00:22<00:32, 1189.18 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9118/47780 [00:22<00:31, 1239.64 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9243/47780 [00:22<00:31, 1239.91 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9376/47780 [00:22<00:30, 1265.84 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9505/47780 [00:23<00:30, 1268.70 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9648/47780 [00:23<00:29, 1285.95 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9778/47780 [00:23<00:30, 1240.61 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9903/47780 [00:23<00:31, 1186.46 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10024/47780 [00:23<00:33, 1136.81 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10169/47780 [00:23<00:30, 1215.14 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10293/47780 [00:23<00:31, 1173.70 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10413/47780 [00:23<00:32, 1151.86 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10536/47780 [00:23<00:32, 1133.36 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10657/47780 [00:24<00:32, 1150.47 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10774/47780 [00:24<00:33, 1110.03 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10890/47780 [00:24<00:32, 1121.69 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11006/47780 [00:24<00:32, 1116.43 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11127/47780 [00:24<00:32, 1131.85 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11241/47780 [00:24<00:32, 1124.86 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11359/47780 [00:24<00:32, 1123.79 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11479/47780 [00:24<00:31, 1141.02 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11607/47780 [00:24<00:30, 1178.64 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11729/47780 [00:25<00:30, 1166.08 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11863/47780 [00:25<00:29, 1202.91 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 11996/47780 [00:25<00:29, 1227.67 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12121/47780 [00:25<00:29, 1192.96 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12248/47780 [00:25<00:29, 1211.28 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12370/47780 [00:25<00:30, 1152.53 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12486/47780 [00:25<00:31, 1133.65 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12606/47780 [00:25<00:30, 1149.28 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12722/47780 [00:25<00:30, 1151.92 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12839/47780 [00:25<00:31, 1115.61 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12972/47780 [00:26<00:29, 1168.07 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13097/47780 [00:26<00:29, 1184.79 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13218/47780 [00:26<00:29, 1171.84 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13342/47780 [00:26<00:29, 1185.04 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13503/47780 [00:26<00:26, 1307.26 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13639/47780 [00:26<00:27, 1242.01 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13765/47780 [00:26<00:27, 1228.09 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13904/47780 [00:26<00:27, 1246.70 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14043/47780 [00:26<00:26, 1286.68 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14174/47780 [00:27<00:26, 1267.80 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14302/47780 [00:27<00:26, 1258.39 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14431/47780 [00:27<00:27, 1192.27 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14553/47780 [00:27<00:28, 1157.68 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14682/47780 [00:27<00:28, 1181.18 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14811/47780 [00:27<00:27, 1207.60 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14936/47780 [00:27<00:27, 1214.40 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15061/47780 [00:27<00:27, 1178.88 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15193/47780 [00:27<00:26, 1215.99 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15317/47780 [00:28<00:28, 1145.57 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15447/47780 [00:28<00:27, 1188.36 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15567/47780 [00:28<00:28, 1146.43 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15683/47780 [00:28<00:28, 1125.33 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15797/47780 [00:28<00:28, 1127.88 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15915/47780 [00:28<00:28, 1130.76 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16048/47780 [00:28<00:26, 1184.76 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16169/47780 [00:28<00:26, 1184.68 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16314/47780 [00:28<00:24, 1261.80 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16442/47780 [00:28<00:26, 1176.44 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16563/47780 [00:29<00:26, 1181.93 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16683/47780 [00:29<00:26, 1186.33 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16812/47780 [00:29<00:25, 1210.01 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16944/47780 [00:29<00:25, 1213.89 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17085/47780 [00:29<00:24, 1252.71 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17211/47780 [00:29<00:24, 1246.84 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17336/47780 [00:29<00:24, 1231.40 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17461/47780 [00:29<00:24, 1230.38 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17588/47780 [00:29<00:25, 1162.78 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17720/47780 [00:30<00:24, 1205.67 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17842/47780 [00:30<00:24, 1205.07 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17966/47780 [00:30<00:24, 1215.02 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18091/47780 [00:30<00:24, 1215.22 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18213/47780 [00:30<00:24, 1195.84 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18336/47780 [00:30<00:24, 1203.04 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18471/47780 [00:30<00:23, 1243.66 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18596/47780 [00:30<00:24, 1204.14 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18729/47780 [00:30<00:24, 1201.60 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18851/47780 [00:30<00:24, 1183.29 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18973/47780 [00:31<00:24, 1187.38 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19092/47780 [00:31<00:24, 1179.00 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19212/47780 [00:31<00:25, 1111.66 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19325/47780 [00:31<00:25, 1097.52 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19446/47780 [00:31<00:25, 1120.13 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19581/47780 [00:31<00:23, 1185.33 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19702/47780 [00:31<00:23, 1187.16 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19822/47780 [00:31<00:24, 1146.87 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19940/47780 [00:31<00:24, 1139.72 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20056/47780 [00:32<00:24, 1124.68 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20193/47780 [00:32<00:23, 1189.03 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20313/47780 [00:32<00:23, 1155.55 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20437/47780 [00:32<00:23, 1179.10 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20556/47780 [00:32<00:23, 1140.34 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20679/47780 [00:32<00:23, 1149.11 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20796/47780 [00:32<00:23, 1127.80 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20911/47780 [00:32<00:24, 1114.83 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21028/47780 [00:32<00:23, 1127.49 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21171/47780 [00:32<00:21, 1214.51 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21293/47780 [00:33<00:22, 1201.52 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21417/47780 [00:33<00:22, 1163.85 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21542/47780 [00:33<00:22, 1168.33 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21667/47780 [00:33<00:22, 1162.69 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21786/47780 [00:33<00:22, 1167.42 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21903/47780 [00:33<00:22, 1139.18 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22027/47780 [00:33<00:22, 1165.56 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22166/47780 [00:33<00:20, 1221.48 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22291/47780 [00:33<00:20, 1218.30 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22414/47780 [00:34<00:21, 1190.18 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22535/47780 [00:34<00:21, 1169.97 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22653/47780 [00:34<00:21, 1150.89 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22773/47780 [00:34<00:21, 1163.06 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22896/47780 [00:34<00:21, 1148.21 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23023/47780 [00:34<00:21, 1172.64 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23141/47780 [00:34<00:21, 1155.59 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23261/47780 [00:34<00:21, 1167.43 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23378/47780 [00:34<00:21, 1113.96 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23518/47780 [00:34<00:20, 1171.43 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23642/47780 [00:35<00:20, 1188.30 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23767/47780 [00:35<00:20, 1199.08 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23888/47780 [00:35<00:19, 1199.43 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24031/47780 [00:35<00:18, 1264.20 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24158/47780 [00:35<00:20, 1179.58 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24279/47780 [00:35<00:20, 1138.02 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24394/47780 [00:35<00:20, 1124.45 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24508/47780 [00:35<00:21, 1078.04 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24618/47780 [00:35<00:21, 1064.00 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24730/47780 [00:36<00:21, 1076.05 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24838/47780 [00:36<00:21, 1055.13 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24954/47780 [00:36<00:21, 1082.10 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25070/47780 [00:36<00:20, 1095.36 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25181/47780 [00:36<00:20, 1098.29 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25303/47780 [00:36<00:19, 1133.28 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25418/47780 [00:36<00:20, 1102.66 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25531/47780 [00:36<00:20, 1103.21 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25659/47780 [00:36<00:19, 1154.56 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25775/47780 [00:37<00:19, 1110.47 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25887/47780 [00:37<00:20, 1060.40 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26002/47780 [00:37<00:20, 1072.87 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26111/47780 [00:37<00:20, 1039.74 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26217/47780 [00:37<00:20, 1040.88 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26324/47780 [00:37<00:20, 1048.99 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26441/47780 [00:37<00:19, 1077.54 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26550/47780 [00:37<00:19, 1072.25 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26658/47780 [00:37<00:19, 1071.58 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26768/47780 [00:37<00:20, 1049.84 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26874/47780 [00:38<00:19, 1046.45 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26979/47780 [00:38<00:19, 1043.13 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27086/47780 [00:38<00:20, 1030.61 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27193/47780 [00:38<00:20, 1020.30 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27323/47780 [00:38<00:18, 1095.68 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27438/47780 [00:38<00:19, 1022.54 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27542/47780 [00:38<00:20, 995.84 examples/s] 
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27647/47780 [00:38<00:19, 1009.96 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27775/47780 [00:38<00:18, 1070.90 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27884/47780 [00:39<00:18, 1055.98 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27993/47780 [00:39<00:18, 1047.28 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28118/47780 [00:39<00:17, 1101.08 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28246/47780 [00:39<00:16, 1149.36 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28363/47780 [00:39<00:17, 1139.61 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28482/47780 [00:39<00:16, 1151.08 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28610/47780 [00:39<00:16, 1171.61 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28753/47780 [00:39<00:15, 1241.68 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28898/47780 [00:39<00:14, 1302.27 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29033/47780 [00:39<00:14, 1289.35 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29164/47780 [00:40<00:14, 1248.33 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29290/47780 [00:40<00:15, 1169.99 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29410/47780 [00:40<00:15, 1153.86 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29528/47780 [00:40<00:15, 1159.78 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29646/47780 [00:40<00:15, 1137.35 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29764/47780 [00:40<00:15, 1130.51 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29881/47780 [00:40<00:15, 1124.88 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29999/47780 [00:40<00:15, 1125.54 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30120/47780 [00:40<00:15, 1149.69 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30237/47780 [00:41<00:16, 1090.37 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30362/47780 [00:41<00:15, 1131.08 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30479/47780 [00:41<00:15, 1124.43 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30593/47780 [00:41<00:15, 1108.03 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30712/47780 [00:41<00:15, 1129.22 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30827/47780 [00:41<00:15, 1096.29 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30943/47780 [00:41<00:15, 1103.25 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31055/47780 [00:41<00:15, 1079.47 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31166/47780 [00:41<00:16, 1024.28 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31281/47780 [00:42<00:15, 1051.23 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31402/47780 [00:42<00:14, 1093.87 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31516/47780 [00:42<00:15, 1028.28 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31627/47780 [00:42<00:15, 1049.47 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31733/47780 [00:42<00:15, 1006.14 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31835/47780 [00:42<00:15, 996.82 examples/s] 
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31937/47780 [00:42<00:15, 995.82 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32040/47780 [00:42<00:16, 969.88 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32138/47780 [00:42<00:16, 925.79 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32234/47780 [00:42<00:16, 931.39 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32348/47780 [00:43<00:15, 989.14 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32448/47780 [00:43<00:15, 983.58 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32547/47780 [00:43<00:16, 930.09 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32644/47780 [00:43<00:16, 940.92 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32759/47780 [00:43<00:15, 996.54 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32863/47780 [00:43<00:14, 998.30 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32966/47780 [00:43<00:14, 1006.35 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33067/47780 [00:43<00:15, 970.09 examples/s] 
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33182/47780 [00:43<00:14, 1013.33 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33289/47780 [00:44<00:14, 1020.06 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33399/47780 [00:44<00:13, 1029.69 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33510/47780 [00:44<00:13, 1049.48 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33617/47780 [00:44<00:13, 1046.75 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33727/47780 [00:44<00:13, 1059.81 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33834/47780 [00:44<00:13, 1050.45 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33941/47780 [00:44<00:13, 1041.51 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34048/47780 [00:44<00:13, 994.72 examples/s] 
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34149/47780 [00:44<00:14, 939.61 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34244/47780 [00:45<00:14, 925.33 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34338/47780 [00:45<00:15, 888.79 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34438/47780 [00:45<00:14, 906.30 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34554/47780 [00:45<00:13, 974.92 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34658/47780 [00:45<00:13, 992.20 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34759/47780 [00:45<00:13, 945.95 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34861/47780 [00:45<00:13, 953.80 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34959/47780 [00:45<00:13, 949.87 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35059/47780 [00:45<00:13, 956.45 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35163/47780 [00:45<00:12, 979.30 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35263/47780 [00:46<00:12, 966.34 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35360/47780 [00:46<00:13, 931.29 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35465/47780 [00:46<00:12, 961.50 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35566/47780 [00:46<00:12, 963.33 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35683/47780 [00:46<00:11, 1019.90 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35786/47780 [00:46<00:12, 997.63 examples/s] 
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35893/47780 [00:46<00:11, 1009.76 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35995/47780 [00:46<00:11, 988.10 examples/s] 
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36101/47780 [00:46<00:11, 998.30 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36202/47780 [00:47<00:11, 992.69 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36303/47780 [00:47<00:11, 988.15 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36407/47780 [00:47<00:11, 992.34 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36517/47780 [00:47<00:11, 1008.14 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36621/47780 [00:47<00:11, 1005.23 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36722/47780 [00:47<00:11, 975.69 examples/s] 
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36834/47780 [00:47<00:10, 999.85 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36942/47780 [00:47<00:10, 1021.78 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37045/47780 [00:47<00:10, 1008.19 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37147/47780 [00:47<00:10, 970.33 examples/s] 
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37246/47780 [00:48<00:11, 955.42 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37355/47780 [00:48<00:10, 990.89 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37469/47780 [00:48<00:10, 1023.05 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37572/47780 [00:48<00:10, 978.62 examples/s] 
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37671/47780 [00:48<00:10, 957.27 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37778/47780 [00:48<00:10, 979.04 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37895/47780 [00:48<00:09, 1031.72 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38016/47780 [00:48<00:09, 1079.97 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38125/47780 [00:48<00:09, 1072.39 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38234/47780 [00:49<00:09, 1028.67 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38350/47780 [00:49<00:08, 1065.38 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38462/47780 [00:49<00:08, 1067.37 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38589/47780 [00:49<00:08, 1118.73 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38705/47780 [00:49<00:08, 1129.37 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38824/47780 [00:49<00:08, 1090.59 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38939/47780 [00:49<00:08, 1095.64 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39054/47780 [00:49<00:07, 1099.42 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39168/47780 [00:49<00:07, 1100.39 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39282/47780 [00:49<00:07, 1106.88 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39395/47780 [00:50<00:07, 1108.33 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39506/47780 [00:50<00:07, 1062.25 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39617/47780 [00:50<00:08, 1007.89 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39732/47780 [00:50<00:07, 1040.82 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39840/47780 [00:50<00:07, 1048.77 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39949/47780 [00:50<00:07, 1044.09 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40056/47780 [00:50<00:07, 1041.07 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40161/47780 [00:50<00:07, 1029.43 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40265/47780 [00:50<00:07, 1023.07 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40379/47780 [00:51<00:07, 1054.44 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40493/47780 [00:51<00:06, 1079.26 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40602/47780 [00:51<00:06, 1033.18 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40707/47780 [00:51<00:07, 985.74 examples/s] 
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40808/47780 [00:51<00:07, 925.89 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40907/47780 [00:51<00:07, 937.35 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41020/47780 [00:51<00:06, 983.73 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41130/47780 [00:51<00:06, 1013.90 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41233/47780 [00:51<00:06, 980.79 examples/s] 
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41332/47780 [00:52<00:06, 975.83 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41440/47780 [00:52<00:06, 992.22 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41541/47780 [00:52<00:06, 983.15 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41641/47780 [00:52<00:06, 911.17 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41734/47780 [00:52<00:06, 916.02 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41851/47780 [00:52<00:06, 952.45 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41949/47780 [00:52<00:06, 928.76 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42054/47780 [00:52<00:05, 959.11 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42151/47780 [00:52<00:06, 893.96 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42248/47780 [00:53<00:06, 913.09 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42350/47780 [00:53<00:05, 939.34 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42446/47780 [00:53<00:05, 915.35 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42559/47780 [00:53<00:05, 959.39 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42660/47780 [00:53<00:05, 969.59 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42759/47780 [00:53<00:05, 944.58 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42855/47780 [00:53<00:05, 936.09 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42956/47780 [00:53<00:05, 937.17 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43050/47780 [00:53<00:05, 879.25 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43140/47780 [00:53<00:05, 828.35 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43229/47780 [00:54<00:05, 832.78 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43314/47780 [00:54<00:05, 796.98 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43408/47780 [00:54<00:05, 835.07 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43495/47780 [00:54<00:05, 840.16 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43584/47780 [00:54<00:05, 829.89 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43702/47780 [00:54<00:04, 927.67 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43796/47780 [00:54<00:04, 914.55 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43889/47780 [00:54<00:04, 906.07 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43995/47780 [00:54<00:04, 925.01 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44115/47780 [00:55<00:03, 975.20 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44222/47780 [00:55<00:03, 993.59 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44323/47780 [00:55<00:03, 974.38 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44421/47780 [00:55<00:03, 975.07 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44520/47780 [00:55<00:03, 920.11 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44614/47780 [00:55<00:03, 875.94 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44705/47780 [00:55<00:03, 841.96 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44790/47780 [00:55<00:03, 838.50 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44877/47780 [00:55<00:03, 795.34 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44962/47780 [00:56<00:03, 789.42 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45057/47780 [00:56<00:03, 829.36 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45143/47780 [00:56<00:03, 807.95 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45232/47780 [00:56<00:03, 819.92 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45315/47780 [00:56<00:03, 801.47 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45396/47780 [00:56<00:03, 783.70 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45480/47780 [00:56<00:02, 794.82 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45565/47780 [00:56<00:02, 803.48 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45647/47780 [00:56<00:02, 774.88 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45752/47780 [00:57<00:02, 813.32 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45834/47780 [00:57<00:02, 808.53 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45916/47780 [00:57<00:02, 764.03 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45993/47780 [00:57<00:02, 698.63 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46065/47780 [00:57<00:02, 666.18 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46135/47780 [00:57<00:02, 657.25 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46203/47780 [00:57<00:02, 641.55 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46268/47780 [00:57<00:02, 610.09 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46330/47780 [00:58<00:02, 572.45 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46388/47780 [00:58<00:02, 523.91 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46448/47780 [00:58<00:02, 542.83 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46505/47780 [00:58<00:02, 503.38 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46560/47780 [00:58<00:02, 488.64 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46611/47780 [00:58<00:02, 493.44 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46662/47780 [00:58<00:02, 457.92 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46712/47780 [00:58<00:02, 464.45 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46760/47780 [00:58<00:02, 404.56 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46802/47780 [00:59<00:02, 387.08 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46843/47780 [00:59<00:02, 367.12 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46881/47780 [00:59<00:02, 366.98 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46920/47780 [00:59<00:02, 355.96 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46956/47780 [00:59<00:02, 349.64 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46992/47780 [00:59<00:02, 339.45 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47028/47780 [00:59<00:02, 343.34 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47064/47780 [00:59<00:02, 330.91 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47098/47780 [01:00<00:02, 327.42 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47138/47780 [01:00<00:01, 342.32 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47174/47780 [01:00<00:02, 298.66 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47206/47780 [01:00<00:01, 291.69 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47237/47780 [01:00<00:02, 271.23 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47269/47780 [01:00<00:01, 282.68 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47300/47780 [01:00<00:01, 259.17 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47328/47780 [01:00<00:01, 238.09 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47354/47780 [01:01<00:01, 239.44 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47380/47780 [01:01<00:01, 210.23 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47406/47780 [01:01<00:01, 220.14 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47429/47780 [01:01<00:01, 214.21 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47458/47780 [01:01<00:01, 225.43 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47482/47780 [01:01<00:01, 214.18 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47505/47780 [01:01<00:01, 212.83 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47528/47780 [01:01<00:01, 206.59 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47550/47780 [01:01<00:01, 202.18 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47571/47780 [01:02<00:01, 188.65 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47592/47780 [01:02<00:01, 180.17 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47612/47780 [01:02<00:01, 156.96 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47630/47780 [01:02<00:01, 121.83 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47644/47780 [01:02<00:01, 104.26 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47657/47780 [01:03<00:01, 90.70 examples/s] 
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47668/47780 [01:03<00:01, 86.86 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47679/47780 [01:03<00:01, 81.00 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47688/47780 [01:03<00:01, 72.98 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47696/47780 [01:03<00:01, 58.45 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47703/47780 [01:03<00:01, 57.98 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47713/47780 [01:04<00:01, 57.72 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47720/47780 [01:04<00:01, 56.55 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47726/47780 [01:04<00:00, 55.02 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47734/47780 [01:04<00:00, 58.34 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47741/47780 [01:04<00:00, 56.91 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47747/47780 [01:04<00:00, 47.94 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47753/47780 [01:04<00:00, 40.65 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47759/47780 [01:05<00:00, 38.34 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47765/47780 [01:05<00:00, 37.64 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47771/47780 [01:05<00:00, 39.26 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [01:05<00:00, 36.55 examples/s]
[36m(head, rank=0, pid=2319)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [01:06<00:00, 12.21 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [01:08<00:00, 702.20 examples/s]
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=2319)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:09<07:13, 107.96 examples/s]
[36m(head, rank=0, pid=2319)[0m Truncating train dataset (num_proc=32):  23%|██▎       | 11000/47780 [00:09<00:22, 1624.55 examples/s]
[36m(head, rank=0, pid=2319)[0m Truncating train dataset (num_proc=32):  68%|██████▊   | 32440/47780 [00:09<00:02, 6136.94 examples/s]
[36m(head, rank=0, pid=2319)[0m Truncating train dataset (num_proc=32):  99%|█████████▉| 47287/47780 [00:09<00:00, 10314.08 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:16<00:00, 2973.56 examples/s] 
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:35,050] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=2319)[0m df: /home/sky/.triton/autotune: No such file or directory
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:35,708] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:35,712] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:35,726] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:35,734] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:35,740] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:35,746] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:35,753] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:01<4:24:16,  3.01 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<4:50:42,  2.74 examples/s]
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:37,430] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:37,431] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:37,431] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:37,431] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:37,431] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:37,431] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:37,431] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=2319)[0m [2025-08-02 07:37:37,431] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<4:53:42,  2.71 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:06:30,  2.60 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 20/47780 [00:02<1:17:26, 10.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:20:35,  2.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:14:39,  2.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 24/47780 [00:02<1:06:21, 11.99 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 16/47780 [00:02<1:49:13,  7.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 46/47780 [00:02<32:43, 24.30 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 18/47780 [00:02<1:38:29,  8.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 19/47780 [00:02<1:35:51,  8.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 24/47780 [00:02<1:14:02, 10.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 56/47780 [00:02<27:05, 29.36 examples/s]  
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 44/47780 [00:02<36:30, 21.80 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 89/47780 [00:03<17:03, 46.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 44/47780 [00:03<38:13, 20.82 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 52/47780 [00:03<32:24, 24.54 examples/s]  
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 47/47780 [00:03<37:38, 21.13 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:03<7:10:19,  1.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 91/47780 [00:03<18:06, 43.91 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 83/47780 [00:03<19:49, 40.10 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 81/47780 [00:03<20:35, 38.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 158/47780 [00:03<09:51, 80.58 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 75/47780 [00:03<24:04, 33.03 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 89/47780 [00:03<19:42, 40.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 177/47780 [00:03<08:26, 94.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 11/47780 [00:03<3:56:22,  3.37 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 130/47780 [00:03<13:02, 60.88 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 225/47780 [00:03<07:26, 106.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 159/47780 [00:03<10:41, 74.25 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 238/47780 [00:03<06:51, 115.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 132/47780 [00:03<13:06, 60.57 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 42/47780 [00:04<49:28, 16.08 examples/s]  
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 145/47780 [00:04<13:37, 58.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|          | 239/47780 [00:04<07:25, 106.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 213/47780 [00:04<08:39, 91.53 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 301/47780 [00:04<06:50, 115.77 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 311/47780 [00:04<06:20, 124.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 74/47780 [00:04<27:33, 28.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 195/47780 [00:04<10:14, 77.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 232/47780 [00:04<09:15, 85.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|          | 312/47780 [00:04<07:05, 111.55 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 318/47780 [00:04<06:25, 123.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|          | 449/47780 [00:04<04:35, 172.10 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 444/47780 [00:05<04:58, 158.52 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 141/47780 [00:05<14:28, 54.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|          | 294/47780 [00:05<07:17, 108.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 617/47780 [00:05<03:13, 243.39 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|          | 319/47780 [00:05<07:29, 105.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|          | 427/47780 [00:05<05:25, 145.30 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 441/47780 [00:05<05:31, 142.69 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 227/47780 [00:05<09:33, 82.88 examples/s]
Tokenizing train dataset (num_proc=32):   1%|▏         | 645/47780 [00:05<03:38, 215.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|          | 417/47780 [00:05<05:32, 142.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|          | 428/47780 [00:05<05:32, 142.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 763/47780 [00:05<03:06, 252.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|          | 585/47780 [00:06<04:14, 185.54 examples/s]
Tokenizing train dataset (num_proc=32):   1%|▏         | 636/47780 [00:06<03:56, 199.19 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 573/47780 [00:06<04:06, 191.35 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 349/47780 [00:06<06:33, 120.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 846/47780 [00:06<03:01, 258.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1025/47780 [00:06<02:07, 368.09 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 538/47780 [00:06<05:06, 154.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 962/47780 [00:06<02:38, 294.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 813/47780 [00:06<03:09, 248.07 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 735/47780 [00:06<03:48, 205.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|          | 450/47780 [00:06<05:39, 139.29 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 726/47780 [00:06<03:42, 211.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1101/47780 [00:06<02:41, 288.51 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1125/47780 [00:06<02:38, 294.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 673/47780 [00:07<04:28, 175.62 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 902/47780 [00:07<03:02, 256.83 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 936/47780 [00:07<03:23, 230.52 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|          | 565/47780 [00:07<04:47, 164.43 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1178/47780 [00:07<03:03, 253.84 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 894/47780 [00:07<03:29, 223.91 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1304/47780 [00:07<02:18, 335.51 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1312/47780 [00:07<02:14, 346.18 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 844/47780 [00:07<03:36, 216.91 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1013/47780 [00:07<03:16, 238.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 718/47780 [00:07<04:07, 190.16 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1111/47780 [00:07<03:11, 243.33 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1039/47780 [00:07<03:22, 230.40 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1468/47780 [00:07<02:26, 315.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1380/47780 [00:07<02:57, 260.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 988/47780 [00:08<03:55, 198.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1161/47780 [00:08<03:17, 235.83 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1669/47780 [00:08<02:23, 321.76 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 850/47780 [00:08<04:01, 194.15 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1185/47780 [00:08<03:22, 229.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1300/47780 [00:08<03:00, 257.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1475/47780 [00:08<02:10, 353.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1492/47780 [00:08<03:59, 193.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1784/47780 [00:09<01:58, 387.35 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1346/47780 [00:09<03:02, 254.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1879/47780 [00:09<02:17, 334.05 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1533/47780 [00:09<02:07, 362.98 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1371/47780 [00:09<03:06, 249.15 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1186/47780 [00:09<03:39, 212.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1032/47780 [00:09<03:33, 218.89 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1586/47780 [00:09<02:04, 369.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1210/47780 [00:09<02:25, 319.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1543/47780 [00:09<03:09, 244.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1738/47780 [00:09<02:05, 368.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1893/47780 [00:09<02:32, 300.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2117/47780 [00:09<02:09, 352.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2357/47780 [00:09<01:31, 494.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1262/47780 [00:09<04:13, 183.19 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1280/47780 [00:09<03:13, 240.57 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1605/47780 [00:09<03:09, 244.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1649/47780 [00:10<01:56, 396.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1844/47780 [00:10<01:55, 398.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1659/47780 [00:10<03:09, 243.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2004/47780 [00:10<03:06, 245.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1834/47780 [00:10<03:13, 237.34 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2449/47780 [00:10<02:08, 353.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1952/47780 [00:10<02:29, 306.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2097/47780 [00:10<01:55, 395.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1387/47780 [00:11<04:26, 173.79 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2066/47780 [00:11<04:12, 181.21 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1818/47780 [00:11<03:36, 212.77 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▎         | 1775/47780 [00:11<02:57, 258.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1763/47780 [00:11<02:00, 380.57 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2569/47780 [00:11<01:32, 490.51 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1925/47780 [00:11<02:55, 260.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2054/47780 [00:11<01:53, 403.39 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2651/47780 [00:11<02:27, 305.04 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2970/47780 [00:11<01:30, 495.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2194/47780 [00:11<02:39, 286.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2072/47780 [00:11<03:31, 216.34 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2509/47780 [00:11<01:45, 430.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1983/47780 [00:11<03:50, 198.76 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1889/47780 [00:11<02:33, 298.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2751/47780 [00:11<01:54, 393.84 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2502/47780 [00:12<01:22, 550.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 3102/47780 [00:12<02:03, 362.10 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2199/47780 [00:12<02:54, 260.93 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2654/47780 [00:12<02:07, 354.90 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2337/47780 [00:12<03:34, 212.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2775/47780 [00:12<01:49, 410.69 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2712/47780 [00:12<01:43, 433.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2685/47780 [00:12<01:46, 425.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2839/47780 [00:12<01:28, 509.30 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2884/47780 [00:13<02:48, 266.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1996/47780 [00:13<03:45, 202.77 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3130/47780 [00:13<01:54, 388.96 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3242/47780 [00:13<02:48, 264.78 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3336/47780 [00:13<02:26, 304.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2887/47780 [00:13<02:25, 308.55 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▋         | 3035/47780 [00:13<01:53, 393.21 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2979/47780 [00:13<01:52, 398.72 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2858/47780 [00:13<02:25, 309.18 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2465/47780 [00:13<03:03, 246.83 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▋         | 3053/47780 [00:13<01:47, 416.07 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2355/47780 [00:13<02:32, 297.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2784/47780 [00:13<01:57, 384.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3430/47780 [00:13<03:02, 243.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3615/47780 [00:14<02:04, 355.51 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3136/47780 [00:14<02:41, 276.24 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 3083/47780 [00:14<02:36, 285.43 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3260/47780 [00:14<02:07, 349.15 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3160/47780 [00:14<02:19, 320.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3275/47780 [00:14<02:52, 258.07 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2576/47780 [00:14<02:27, 307.38 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3185/47780 [00:14<02:21, 314.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3644/47780 [00:14<01:38, 447.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2767/47780 [00:14<01:53, 396.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3330/47780 [00:14<01:52, 394.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3326/47780 [00:14<02:29, 296.44 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2929/47780 [00:15<02:52, 259.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3510/47780 [00:15<01:44, 421.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3144/47780 [00:15<02:07, 350.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3752/47780 [00:15<03:15, 225.19 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2857/47780 [00:15<02:41, 278.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 4047/47780 [00:15<01:51, 392.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 2/47780 [00:15<102:19:02,  7.71s/ examples]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3350/47780 [00:15<04:03, 182.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3828/47780 [00:15<02:25, 302.58 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3791/47780 [00:15<01:41, 435.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4114/47780 [00:15<01:39, 440.42 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3274/47780 [00:15<02:30, 295.20 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3609/47780 [00:15<02:37, 280.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3439/47780 [00:15<03:24, 216.30 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3389/47780 [00:15<02:07, 347.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4181/47780 [00:15<02:10, 332.98 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4561/47780 [00:16<01:12, 594.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 16/47780 [00:16<9:50:44,  1.35 examples/s] 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3790/47780 [00:16<02:35, 282.24 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 4016/47780 [00:16<01:42, 425.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 3054/47780 [00:16<03:26, 216.47 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3182/47780 [00:16<02:46, 268.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4286/47780 [00:16<02:20, 309.20 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 28/47780 [00:16<5:10:19,  2.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4489/47780 [00:17<01:47, 404.19 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 48/47780 [00:17<2:19:56,  5.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4743/47780 [00:17<01:55, 372.53 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3490/47780 [00:17<03:29, 211.17 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3669/47780 [00:17<03:45, 195.23 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3775/47780 [00:17<02:01, 362.91 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3789/47780 [00:17<03:02, 241.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4119/47780 [00:17<02:25, 301.07 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3964/47780 [00:17<02:59, 243.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4166/47780 [00:17<01:34, 459.36 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4320/47780 [00:17<01:47, 404.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 58/47780 [00:17<1:57:54,  6.75 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4307/47780 [00:17<02:28, 293.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3389/47780 [00:18<03:20, 220.95 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4533/47780 [00:18<01:39, 433.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3841/47780 [00:18<01:40, 437.93 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4331/47780 [00:18<02:03, 352.93 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4609/47780 [00:18<01:24, 512.61 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4513/47780 [00:18<02:11, 330.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4991/47780 [00:18<02:29, 285.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5269/47780 [00:18<01:43, 412.50 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3908/47780 [00:18<03:13, 226.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4633/47780 [00:18<03:10, 226.44 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▊         | 4157/47780 [00:18<02:06, 346.09 examples/s]
Tokenizing train dataset (num_proc=32):  10%|█         | 4844/47780 [00:18<02:16, 315.69 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 69/47780 [00:18<1:40:35,  7.91 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4643/47780 [00:18<02:13, 323.00 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5114/47780 [00:18<01:31, 465.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   0%|          | 100/47780 [00:18<46:38, 17.04 examples/s] 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4796/47780 [00:18<01:42, 417.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 4014/47780 [00:18<02:05, 348.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4152/47780 [00:19<01:46, 410.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5422/47780 [00:19<02:09, 326.52 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5873/47780 [00:19<01:12, 580.94 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4654/47780 [00:19<03:17, 217.86 examples/s]
Tokenizing train dataset (num_proc=32):  10%|█         | 4898/47780 [00:19<02:54, 245.31 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4929/47780 [00:19<02:10, 327.96 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 112/47780 [00:19<53:43, 14.79 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5153/47780 [00:20<01:45, 404.87 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4764/47780 [00:20<02:49, 253.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6087/47780 [00:20<01:24, 491.25 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 187/47780 [00:20<18:06, 43.82 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5115/47780 [00:20<01:42, 417.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4282/47780 [00:20<02:40, 271.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4584/47780 [00:20<01:39, 435.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5286/47780 [00:20<02:42, 261.07 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█▏        | 5469/47780 [00:20<02:03, 341.24 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4294/47780 [00:20<03:48, 190.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6247/47780 [00:20<01:27, 472.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4632/47780 [00:20<02:10, 330.31 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6371/47780 [00:20<01:40, 412.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6466/47780 [00:21<01:36, 427.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5282/47780 [00:21<03:01, 233.80 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4739/47780 [00:21<02:25, 294.95 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 216/47780 [00:21<22:19, 35.52 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6548/47780 [00:21<01:40, 412.28 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5083/47780 [00:21<03:10, 224.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5591/47780 [00:21<01:45, 400.58 examples/s]
Tokenizing train dataset (num_proc=32):  10%|█         | 4970/47780 [00:21<01:43, 415.05 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 285/47780 [00:21<12:14, 64.63 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5298/47780 [00:21<02:32, 277.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5394/47780 [00:21<01:59, 353.47 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6619/47780 [00:21<01:41, 403.93 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5749/47780 [00:21<01:28, 472.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5612/47780 [00:21<01:40, 419.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6678/47780 [00:21<01:44, 392.29 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5608/47780 [00:21<03:05, 226.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4808/47780 [00:21<02:53, 248.21 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6047/47780 [00:21<01:35, 438.83 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6730/47780 [00:21<01:50, 372.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5187/47780 [00:21<01:41, 418.31 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5891/47780 [00:21<01:37, 431.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6776/47780 [00:22<01:50, 371.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5120/47780 [00:22<02:05, 339.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6819/47780 [00:22<01:53, 359.58 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6002/47780 [00:22<01:38, 425.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6860/47780 [00:22<01:54, 355.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6898/47780 [00:22<01:54, 357.64 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5565/47780 [00:22<02:27, 286.70 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6091/47780 [00:22<01:40, 415.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6936/47780 [00:22<01:59, 340.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6978/47780 [00:22<01:55, 353.18 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 321/47780 [00:22<16:08, 48.99 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7015/47780 [00:22<01:54, 357.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6165/47780 [00:22<01:45, 394.88 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 403/47780 [00:22<09:07, 86.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7057/47780 [00:22<01:51, 366.10 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6227/47780 [00:22<01:46, 389.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7098/47780 [00:22<01:47, 377.63 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5232/47780 [00:22<02:43, 260.65 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7142/47780 [00:23<01:43, 390.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6281/47780 [00:23<01:50, 376.98 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5535/47780 [00:23<01:37, 433.50 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5799/47780 [00:23<02:38, 264.90 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6250/47780 [00:23<02:15, 305.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7183/47780 [00:23<01:42, 395.88 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6330/47780 [00:23<01:54, 362.93 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 5997/47780 [00:23<02:01, 343.93 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6511/47780 [00:23<01:37, 423.06 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█▏        | 5387/47780 [00:23<02:26, 288.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7223/47780 [00:23<01:53, 356.51 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6373/47780 [00:23<01:58, 350.39 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5628/47780 [00:23<01:47, 391.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7260/47780 [00:23<01:56, 348.43 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6415/47780 [00:23<01:59, 345.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7300/47780 [00:23<01:51, 362.24 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7339/47780 [00:23<01:50, 366.52 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6453/47780 [00:23<02:03, 333.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7378/47780 [00:23<01:49, 368.86 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6491/47780 [00:23<02:01, 340.76 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7416/47780 [00:23<01:55, 348.22 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6527/47780 [00:23<02:03, 332.94 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|          | 446/47780 [00:23<11:41, 67.49 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7461/47780 [00:23<01:48, 372.33 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6562/47780 [00:23<02:05, 327.41 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|          | 530/47780 [00:23<07:13, 109.04 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7499/47780 [00:24<01:48, 370.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6596/47780 [00:24<02:07, 323.81 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7537/47780 [00:24<01:54, 352.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6631/47780 [00:24<02:05, 327.83 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7575/47780 [00:24<01:52, 355.98 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6678/47780 [00:24<01:52, 365.87 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6191/47780 [00:24<02:30, 276.86 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5682/47780 [00:24<02:39, 264.12 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6718/47780 [00:24<01:51, 366.66 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7611/47780 [00:24<01:58, 339.09 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6535/47780 [00:24<01:33, 440.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6764/47780 [00:24<01:46, 384.55 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7646/47780 [00:24<02:14, 298.95 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5759/47780 [00:24<03:50, 182.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6812/47780 [00:24<01:39, 411.15 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7679/47780 [00:24<02:10, 306.73 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6694/47780 [00:24<02:30, 272.31 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5869/47780 [00:24<03:15, 214.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6854/47780 [00:24<01:40, 409.23 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7713/47780 [00:24<02:08, 311.96 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6994/47780 [00:24<01:40, 404.92 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5801/47780 [00:24<02:42, 259.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6896/47780 [00:24<01:43, 394.30 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7748/47780 [00:24<02:04, 320.34 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6103/47780 [00:24<01:46, 390.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6936/47780 [00:24<01:44, 391.56 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7782/47780 [00:24<02:08, 310.96 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6976/47780 [00:24<01:46, 384.88 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7817/47780 [00:25<02:04, 321.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7016/47780 [00:25<01:48, 376.16 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7850/47780 [00:25<02:07, 313.59 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 5986/47780 [00:25<02:18, 301.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7054/47780 [00:25<01:51, 364.67 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7884/47780 [00:25<02:04, 320.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6272/47780 [00:25<01:34, 440.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7091/47780 [00:25<01:54, 354.91 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7925/47780 [00:25<01:55, 346.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7127/47780 [00:25<01:55, 351.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7965/47780 [00:25<01:55, 345.95 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7171/47780 [00:25<01:48, 373.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8003/47780 [00:25<01:54, 347.75 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7210/47780 [00:25<01:52, 361.36 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8042/47780 [00:25<01:50, 359.75 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6711/47780 [00:25<02:22, 288.79 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6418/47780 [00:25<01:41, 409.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   1%|          | 578/47780 [00:25<12:46, 61.62 examples/s] 
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7247/47780 [00:25<01:55, 351.90 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8079/47780 [00:25<01:50, 358.25 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7002/47780 [00:25<01:36, 421.52 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 810/47780 [00:25<04:51, 161.13 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7283/47780 [00:25<02:02, 331.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8116/47780 [00:25<01:53, 349.42 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7317/47780 [00:25<02:04, 324.18 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6530/47780 [00:25<01:42, 402.17 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8152/47780 [00:26<02:01, 326.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7175/47780 [00:26<02:24, 280.12 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7355/47780 [00:26<02:01, 331.47 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8192/47780 [00:26<01:54, 345.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7460/47780 [00:26<01:39, 407.22 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6279/47780 [00:26<02:33, 270.55 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6079/47780 [00:26<03:51, 180.42 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7391/47780 [00:26<02:00, 335.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8232/47780 [00:26<01:50, 358.16 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6573/47780 [00:26<01:42, 400.96 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6349/47780 [00:26<02:28, 279.44 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6620/47780 [00:26<01:47, 382.87 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7429/47780 [00:26<01:57, 344.32 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8279/47780 [00:26<01:42, 385.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7174/47780 [00:26<01:43, 393.29 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7464/47780 [00:26<01:59, 338.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8318/47780 [00:26<01:42, 386.57 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6692/47780 [00:26<01:50, 371.33 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7502/47780 [00:26<01:55, 349.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8357/47780 [00:26<01:45, 374.80 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7538/47780 [00:26<01:56, 345.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8396/47780 [00:26<01:43, 379.08 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6752/47780 [00:26<01:54, 358.95 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7307/47780 [00:26<01:45, 382.86 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7633/47780 [00:26<01:47, 372.43 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7581/47780 [00:26<01:51, 361.18 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8435/47780 [00:26<01:45, 373.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 893/47780 [00:26<05:45, 135.60 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7623/47780 [00:26<01:49, 365.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8473/47780 [00:26<01:49, 358.82 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6804/47780 [00:26<02:01, 338.24 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7662/47780 [00:26<01:48, 368.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8512/47780 [00:26<01:48, 363.57 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7409/47780 [00:26<01:46, 379.28 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6848/47780 [00:27<02:03, 330.76 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7700/47780 [00:27<01:49, 367.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8554/47780 [00:27<01:43, 379.37 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7763/47780 [00:27<01:48, 369.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8594/47780 [00:27<01:43, 376.84 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7737/47780 [00:27<01:57, 339.82 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6888/47780 [00:27<02:08, 317.78 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7491/47780 [00:27<01:44, 384.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8640/47780 [00:27<01:39, 391.87 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7772/47780 [00:27<02:03, 323.33 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6924/47780 [00:27<02:13, 306.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7865/47780 [00:27<01:48, 367.47 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7561/47780 [00:27<01:45, 381.54 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8681/47780 [00:27<01:42, 379.64 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7805/47780 [00:27<02:04, 320.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6958/47780 [00:27<02:12, 307.77 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8720/47780 [00:27<01:46, 366.07 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7841/47780 [00:27<02:01, 327.65 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6992/47780 [00:27<02:11, 310.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7621/47780 [00:27<01:47, 372.71 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8757/47780 [00:27<01:46, 366.92 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7947/47780 [00:27<01:50, 361.52 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7880/47780 [00:27<01:56, 341.38 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 954/47780 [00:27<06:53, 113.35 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6748/47780 [00:27<02:33, 266.56 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7028/47780 [00:27<02:07, 320.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6480/47780 [00:27<03:27, 198.84 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8796/47780 [00:27<01:46, 365.06 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7918/47780 [00:27<01:53, 352.26 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7674/47780 [00:27<01:49, 366.48 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1033/47780 [00:27<05:15, 148.16 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6933/47780 [00:27<01:59, 342.11 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7063/47780 [00:27<02:05, 324.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6662/47780 [00:27<02:33, 268.59 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8836/47780 [00:27<01:43, 374.95 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8015/47780 [00:27<01:52, 352.35 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7721/47780 [00:27<01:49, 366.23 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6832/47780 [00:27<01:56, 350.99 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7954/47780 [00:27<02:06, 314.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7097/47780 [00:27<02:06, 321.86 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8878/47780 [00:27<01:41, 384.00 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7201/47780 [00:27<01:07, 604.46 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7140/47780 [00:27<01:59, 339.91 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7987/47780 [00:27<02:10, 305.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7765/47780 [00:27<01:52, 354.69 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8072/47780 [00:28<01:54, 347.44 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8917/47780 [00:28<01:48, 356.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7175/47780 [00:28<01:58, 342.42 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8019/47780 [00:28<02:20, 282.35 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7805/47780 [00:28<01:55, 345.02 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8954/47780 [00:28<01:50, 352.66 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8122/47780 [00:28<01:55, 343.97 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7401/47780 [00:28<01:00, 667.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7210/47780 [00:28<02:04, 326.66 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7846/47780 [00:28<01:52, 355.68 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8061/47780 [00:28<02:11, 302.24 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8990/47780 [00:28<01:51, 346.81 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8167/47780 [00:28<01:55, 343.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7244/47780 [00:28<02:05, 322.55 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7904/47780 [00:28<01:40, 398.61 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8092/47780 [00:28<02:15, 291.86 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9031/47780 [00:28<01:46, 364.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8209/47780 [00:28<01:52, 350.94 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7279/47780 [00:28<02:09, 313.59 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8160/47780 [00:28<01:41, 390.15 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7947/47780 [00:28<01:45, 377.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9082/47780 [00:28<01:36, 401.73 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8250/47780 [00:28<01:53, 347.25 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7312/47780 [00:28<02:08, 314.55 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9125/47780 [00:28<01:35, 405.30 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8203/47780 [00:28<01:43, 384.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7987/47780 [00:28<01:55, 345.42 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7347/47780 [00:28<02:06, 320.83 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8289/47780 [00:28<01:58, 333.82 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8243/47780 [00:28<01:43, 380.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9166/47780 [00:28<01:39, 387.99 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8025/47780 [00:28<01:56, 341.28 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7381/47780 [00:28<02:05, 322.69 examples/s]
Tokenizing train dataset (num_proc=32):   2%|▏         | 1088/47780 [00:28<07:14, 107.48 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7570/47780 [00:28<01:19, 508.66 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8325/47780 [00:28<01:57, 336.47 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9206/47780 [00:28<01:39, 387.21 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8282/47780 [00:28<01:47, 366.92 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7419/47780 [00:28<02:00, 335.15 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8063/47780 [00:28<01:58, 335.08 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1195/47780 [00:28<04:48, 161.71 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8361/47780 [00:28<01:59, 329.91 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9256/47780 [00:28<01:31, 419.34 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8320/47780 [00:28<01:56, 339.99 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8104/47780 [00:28<01:53, 349.81 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7453/47780 [00:28<02:11, 307.30 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8396/47780 [00:29<02:02, 322.24 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9301/47780 [00:28<01:29, 428.13 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8355/47780 [00:29<01:57, 336.12 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8141/47780 [00:29<01:57, 338.38 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7485/47780 [00:29<02:15, 297.46 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8432/47780 [00:29<01:59, 328.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9350/47780 [00:29<01:28, 436.57 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7697/47780 [00:29<01:27, 460.41 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8389/47780 [00:29<01:58, 331.36 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8177/47780 [00:29<01:56, 339.69 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7523/47780 [00:29<02:07, 315.73 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8472/47780 [00:29<01:54, 343.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9394/47780 [00:29<01:33, 408.86 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8427/47780 [00:29<01:57, 336.09 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8219/47780 [00:29<01:50, 357.39 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8513/47780 [00:29<01:48, 361.31 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7555/47780 [00:29<02:09, 311.77 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9437/47780 [00:29<01:35, 401.16 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8463/47780 [00:29<01:55, 338.97 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8257/47780 [00:29<01:53, 348.39 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7595/47780 [00:29<01:59, 335.17 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8550/47780 [00:29<01:49, 359.43 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8499/47780 [00:29<01:53, 344.66 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9480/47780 [00:29<01:39, 385.56 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7796/47780 [00:29<01:35, 420.69 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8297/47780 [00:29<01:50, 357.74 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7639/47780 [00:29<01:50, 363.87 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8587/47780 [00:29<01:49, 359.01 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7074/47780 [00:29<03:28, 195.44 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9520/47780 [00:29<01:39, 383.73 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8534/47780 [00:29<02:01, 323.90 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8336/47780 [00:29<01:48, 363.37 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7679/47780 [00:29<01:47, 373.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8624/47780 [00:29<01:48, 361.75 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7296/47780 [00:29<02:24, 279.69 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9559/47780 [00:29<01:41, 376.84 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7876/47780 [00:29<01:37, 410.65 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8374/47780 [00:29<01:47, 367.89 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8567/47780 [00:29<02:09, 301.95 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8663/47780 [00:29<01:48, 361.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7717/47780 [00:29<01:50, 361.97 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7520/47780 [00:29<01:43, 389.46 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9597/47780 [00:29<01:45, 361.62 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8603/47780 [00:29<02:04, 314.55 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7754/47780 [00:29<01:51, 360.29 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8712/47780 [00:29<01:39, 391.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8412/47780 [00:29<01:59, 329.88 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7944/47780 [00:29<01:39, 399.41 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9639/47780 [00:29<01:40, 377.65 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1255/47780 [00:29<06:52, 112.89 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7794/47780 [00:29<01:49, 363.66 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8635/47780 [00:29<02:12, 296.39 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8752/47780 [00:29<01:43, 375.48 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8446/47780 [00:29<02:08, 306.15 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9678/47780 [00:29<01:41, 376.71 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8001/47780 [00:30<01:42, 387.58 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8670/47780 [00:30<02:07, 307.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7831/47780 [00:30<01:55, 345.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8790/47780 [00:30<01:46, 367.36 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7678/47780 [00:30<01:36, 417.19 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8486/47780 [00:30<02:01, 323.98 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9716/47780 [00:30<01:44, 365.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8702/47780 [00:30<02:07, 307.51 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7877/47780 [00:30<01:50, 361.77 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8051/47780 [00:30<01:42, 385.82 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8827/47780 [00:30<01:55, 336.93 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8523/47780 [00:30<01:57, 334.55 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9753/47780 [00:30<01:43, 366.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8738/47780 [00:30<02:05, 311.83 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7918/47780 [00:30<01:47, 370.79 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8869/47780 [00:30<01:50, 353.23 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8098/47780 [00:30<01:43, 384.66 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8558/47780 [00:30<02:02, 319.55 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9790/47780 [00:30<01:50, 344.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8770/47780 [00:30<02:05, 310.77 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7956/47780 [00:30<01:49, 365.22 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8596/47780 [00:30<01:56, 335.72 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8905/47780 [00:30<01:56, 333.08 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8142/47780 [00:30<01:46, 372.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9830/47780 [00:30<01:50, 344.33 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7805/47780 [00:30<01:43, 386.15 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7993/47780 [00:30<01:50, 358.49 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8802/47780 [00:30<02:12, 293.12 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8945/47780 [00:30<01:50, 350.88 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8632/47780 [00:30<01:58, 331.44 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1366/47780 [00:30<05:51, 132.08 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8183/47780 [00:30<01:45, 373.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9865/47780 [00:30<01:54, 331.42 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8032/47780 [00:30<01:48, 367.35 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8834/47780 [00:30<02:12, 294.40 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8981/47780 [00:30<01:54, 338.24 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8681/47780 [00:30<01:47, 363.49 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1445/47780 [00:30<04:30, 171.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8224/47780 [00:30<01:46, 372.52 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9899/47780 [00:30<01:59, 316.46 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8069/47780 [00:30<01:50, 357.85 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9016/47780 [00:30<01:53, 340.30 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8721/47780 [00:30<01:46, 365.64 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8864/47780 [00:30<02:33, 253.73 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7903/47780 [00:30<01:45, 377.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8263/47780 [00:30<01:51, 353.46 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9936/47780 [00:30<01:55, 327.40 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8108/47780 [00:30<01:49, 360.83 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9053/47780 [00:30<01:51, 346.37 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8759/47780 [00:30<01:48, 360.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8911/47780 [00:30<02:06, 306.87 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8309/47780 [00:30<01:45, 375.18 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9969/47780 [00:30<01:59, 316.63 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8148/47780 [00:30<01:46, 371.68 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9088/47780 [00:30<01:52, 343.29 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8947/47780 [00:30<02:01, 319.31 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7982/47780 [00:31<01:44, 379.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8796/47780 [00:30<01:53, 343.75 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10006/47780 [00:31<01:54, 328.62 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8349/47780 [00:31<01:51, 353.00 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8186/47780 [00:31<01:53, 349.65 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9137/47780 [00:31<01:43, 372.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 8981/47780 [00:31<02:04, 311.10 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8831/47780 [00:31<01:58, 327.67 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10040/47780 [00:31<01:54, 328.27 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8229/47780 [00:31<01:47, 368.46 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8386/47780 [00:31<01:55, 340.06 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9175/47780 [00:31<01:44, 370.61 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1493/47780 [00:31<05:18, 145.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9013/47780 [00:31<02:06, 307.03 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8049/47780 [00:31<01:51, 357.16 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8867/47780 [00:31<02:00, 322.09 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10079/47780 [00:31<01:50, 341.75 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8267/47780 [00:31<01:46, 371.32 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8422/47780 [00:31<01:55, 341.77 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9213/47780 [00:31<01:46, 360.71 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1545/47780 [00:31<04:26, 173.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9049/47780 [00:31<02:03, 314.65 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10116/47780 [00:31<01:51, 338.02 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8900/47780 [00:31<02:04, 311.43 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8457/47780 [00:31<01:55, 340.38 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8305/47780 [00:31<01:48, 365.34 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8105/47780 [00:31<01:53, 348.11 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9250/47780 [00:31<01:50, 347.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9081/47780 [00:31<02:02, 316.04 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8932/47780 [00:31<02:05, 310.42 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8499/47780 [00:31<01:48, 362.03 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8342/47780 [00:31<01:48, 362.53 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10150/47780 [00:31<01:59, 313.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8153/47780 [00:31<01:50, 360.21 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9113/47780 [00:31<02:05, 306.91 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9285/47780 [00:31<02:03, 312.78 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8964/47780 [00:31<02:10, 296.96 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8538/47780 [00:31<01:49, 357.67 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10191/47780 [00:31<01:51, 336.48 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8379/47780 [00:31<01:52, 349.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9146/47780 [00:31<02:03, 313.20 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9324/47780 [00:31<01:56, 330.47 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9000/47780 [00:31<02:04, 310.77 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8202/47780 [00:31<01:53, 349.32 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10226/47780 [00:31<01:51, 336.56 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8419/47780 [00:31<01:49, 360.12 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8575/47780 [00:31<01:53, 346.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9182/47780 [00:31<01:59, 323.24 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9358/47780 [00:31<02:02, 312.58 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9050/47780 [00:31<01:48, 356.94 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10260/47780 [00:31<01:53, 330.10 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8457/47780 [00:31<01:50, 356.86 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8610/47780 [00:31<01:55, 339.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8244/47780 [00:31<01:58, 333.96 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9220/47780 [00:31<02:00, 320.97 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9390/47780 [00:31<02:04, 307.59 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9101/47780 [00:31<01:39, 389.46 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10294/47780 [00:31<01:56, 321.88 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8645/47780 [00:31<01:56, 334.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8493/47780 [00:31<01:57, 334.88 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9254/47780 [00:31<01:58, 326.24 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8282/47780 [00:31<02:03, 321.03 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9424/47780 [00:32<02:02, 313.44 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9141/47780 [00:31<01:39, 388.14 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10332/47780 [00:31<01:51, 334.50 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8680/47780 [00:31<01:57, 331.96 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8531/47780 [00:31<01:54, 342.14 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9287/47780 [00:32<02:00, 319.44 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8328/47780 [00:32<01:54, 344.66 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9184/47780 [00:32<01:36, 399.77 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9467/47780 [00:32<01:53, 337.49 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10370/47780 [00:32<01:47, 347.15 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8717/47780 [00:32<01:54, 342.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8566/47780 [00:32<01:57, 334.46 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9321/47780 [00:32<01:59, 322.28 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8366/47780 [00:32<01:58, 333.31 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9225/47780 [00:32<01:36, 398.40 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9504/47780 [00:32<01:52, 339.88 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10405/47780 [00:32<01:49, 340.43 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8762/47780 [00:32<01:46, 367.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8600/47780 [00:32<01:57, 332.43 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9354/47780 [00:32<02:01, 316.36 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8409/47780 [00:32<01:52, 350.41 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9546/47780 [00:32<01:45, 361.10 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10448/47780 [00:32<01:43, 362.00 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9265/47780 [00:32<01:43, 372.63 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8802/47780 [00:32<01:46, 365.96 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8634/47780 [00:32<01:57, 334.52 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9388/47780 [00:32<01:59, 320.13 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8446/47780 [00:32<01:55, 340.13 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10495/47780 [00:32<01:35, 388.61 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9584/47780 [00:32<01:49, 347.24 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9305/47780 [00:32<01:44, 368.74 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8845/47780 [00:32<01:43, 375.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8668/47780 [00:32<01:59, 328.30 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9428/47780 [00:32<01:52, 339.90 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8482/47780 [00:32<01:56, 338.37 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10534/47780 [00:32<01:36, 385.73 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9620/47780 [00:32<01:50, 343.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8705/47780 [00:32<01:54, 339.86 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8883/47780 [00:32<01:49, 356.61 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9343/47780 [00:32<01:55, 334.17 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9463/47780 [00:32<01:53, 338.55 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10573/47780 [00:32<01:36, 385.88 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9659/47780 [00:32<01:46, 356.67 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8517/47780 [00:32<01:58, 330.67 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8744/47780 [00:32<01:52, 347.06 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8919/47780 [00:32<01:52, 345.59 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9378/47780 [00:32<01:54, 334.35 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9497/47780 [00:32<02:00, 316.58 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10612/47780 [00:32<01:39, 373.98 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8556/47780 [00:32<01:54, 343.47 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9695/47780 [00:32<01:51, 341.57 examples/s]
Tokenizing train dataset (num_proc=32):   3%|▎         | 1585/47780 [00:32<09:13, 83.51 examples/s] 
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8779/47780 [00:32<01:55, 336.27 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8965/47780 [00:32<01:42, 377.27 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9412/47780 [00:32<02:00, 318.70 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9529/47780 [00:32<02:07, 301.11 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8595/47780 [00:32<01:50, 355.91 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10650/47780 [00:32<01:39, 371.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9730/47780 [00:32<01:55, 330.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1759/47780 [00:32<04:18, 177.87 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8821/47780 [00:32<01:48, 359.91 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9004/47780 [00:32<01:52, 346.03 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9460/47780 [00:32<01:48, 354.77 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9570/47780 [00:32<01:56, 327.22 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8632/47780 [00:32<01:53, 344.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10689/47780 [00:32<01:43, 360.11 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9764/47780 [00:32<01:56, 325.00 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8858/47780 [00:32<01:55, 338.05 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9040/47780 [00:32<01:51, 346.35 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9496/47780 [00:32<01:48, 352.07 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9608/47780 [00:33<01:54, 334.59 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8677/47780 [00:33<01:45, 369.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10729/47780 [00:33<01:40, 368.73 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9797/47780 [00:33<01:56, 326.40 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8895/47780 [00:33<01:52, 344.65 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9532/47780 [00:33<01:51, 342.73 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9076/47780 [00:33<01:55, 334.66 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8716/47780 [00:33<01:45, 371.35 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9642/47780 [00:33<02:01, 314.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10766/47780 [00:33<01:41, 363.05 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9830/47780 [00:33<01:58, 320.14 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8930/47780 [00:33<01:59, 324.01 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9573/47780 [00:33<01:46, 357.93 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9114/47780 [00:33<01:54, 336.27 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8761/47780 [00:33<01:40, 389.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10804/47780 [00:33<01:41, 363.41 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9687/47780 [00:33<01:51, 340.46 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9863/47780 [00:33<02:01, 311.89 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9148/47780 [00:33<01:55, 333.80 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9610/47780 [00:33<01:51, 341.60 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8963/47780 [00:33<02:09, 300.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9723/47780 [00:33<01:50, 344.47 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10852/47780 [00:33<01:34, 388.84 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8802/47780 [00:33<01:42, 381.91 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9896/47780 [00:33<01:59, 316.75 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8994/47780 [00:33<02:08, 301.87 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9645/47780 [00:33<01:54, 332.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9182/47780 [00:33<02:04, 311.19 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10892/47780 [00:33<01:35, 385.04 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9931/47780 [00:33<01:57, 323.20 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8841/47780 [00:33<01:47, 363.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9758/47780 [00:33<01:59, 318.83 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9679/47780 [00:33<02:01, 314.26 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9025/47780 [00:33<02:20, 276.69 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9214/47780 [00:33<02:08, 300.42 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10932/47780 [00:33<01:36, 383.08 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9964/47780 [00:33<01:57, 321.39 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8880/47780 [00:33<01:45, 367.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9795/47780 [00:33<01:54, 332.39 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10973/47780 [00:33<01:35, 386.40 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9054/47780 [00:33<02:21, 274.33 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9711/47780 [00:33<02:05, 302.99 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9245/47780 [00:33<02:12, 290.51 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9997/47780 [00:33<01:58, 319.73 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9836/47780 [00:33<01:48, 350.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8922/47780 [00:33<01:44, 373.55 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11013/47780 [00:33<01:35, 385.90 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9087/47780 [00:33<02:15, 285.86 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9879/47780 [00:33<01:41, 372.81 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10044/47780 [00:33<01:46, 355.62 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8973/47780 [00:33<01:34, 411.80 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9742/47780 [00:33<02:15, 280.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9275/47780 [00:33<02:22, 269.82 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11052/47780 [00:33<01:37, 378.27 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9121/47780 [00:33<02:11, 294.76 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9018/47780 [00:33<01:31, 422.69 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9918/47780 [00:33<01:41, 373.46 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10085/47780 [00:33<01:42, 367.09 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9778/47780 [00:33<02:08, 295.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9310/47780 [00:33<02:19, 276.43 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9957/47780 [00:33<01:40, 377.83 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10123/47780 [00:34<01:43, 365.46 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9062/47780 [00:34<01:34, 409.04 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11090/47780 [00:34<01:44, 350.21 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9151/47780 [00:34<02:23, 268.94 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9341/47780 [00:34<02:16, 282.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9808/47780 [00:34<02:19, 271.64 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10160/47780 [00:34<01:45, 355.26 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9996/47780 [00:34<01:45, 358.21 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11127/47780 [00:34<01:44, 352.17 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9197/47780 [00:34<02:03, 313.34 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9372/47780 [00:34<02:14, 286.60 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9104/47780 [00:34<01:44, 370.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9836/47780 [00:34<02:20, 269.60 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10035/47780 [00:34<01:43, 365.67 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9234/47780 [00:34<01:57, 328.62 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11163/47780 [00:34<01:48, 338.80 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9406/47780 [00:34<02:08, 297.82 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 1832/47780 [00:34<06:55, 110.57 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10196/47780 [00:34<01:58, 317.06 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9154/47780 [00:34<01:37, 396.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9864/47780 [00:34<02:19, 272.36 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10072/47780 [00:34<01:44, 362.08 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9268/47780 [00:34<01:56, 331.48 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11206/47780 [00:34<01:42, 356.48 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9451/47780 [00:34<01:52, 340.47 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2046/47780 [00:34<03:33, 214.54 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9892/47780 [00:34<02:21, 267.23 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9196/47780 [00:34<01:42, 377.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10229/47780 [00:34<02:05, 299.94 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9303/47780 [00:34<01:54, 335.14 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10114/47780 [00:34<01:42, 366.83 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11244/47780 [00:34<01:43, 351.34 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9486/47780 [00:34<01:56, 329.92 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9919/47780 [00:34<02:22, 266.52 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10262/47780 [00:34<02:05, 300.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9235/47780 [00:34<01:45, 365.76 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9352/47780 [00:34<01:42, 373.46 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10151/47780 [00:34<01:49, 344.12 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9521/47780 [00:34<01:55, 330.45 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9951/47780 [00:34<02:14, 281.64 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11284/47780 [00:34<01:44, 349.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10295/47780 [00:34<02:01, 307.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9278/47780 [00:34<01:40, 382.96 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9391/47780 [00:34<01:43, 369.61 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10187/47780 [00:34<01:47, 348.46 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9560/47780 [00:34<01:50, 346.57 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9980/47780 [00:34<02:13, 283.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11330/47780 [00:34<01:37, 375.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10336/47780 [00:34<01:53, 328.61 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9317/47780 [00:34<01:46, 362.63 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9429/47780 [00:34<01:48, 352.42 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11369/47780 [00:34<01:36, 378.91 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10225/47780 [00:34<01:50, 339.60 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10011/47780 [00:34<02:13, 281.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9595/47780 [00:34<01:54, 332.92 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10370/47780 [00:34<01:55, 323.26 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9465/47780 [00:34<01:48, 354.23 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9629/47780 [00:34<01:55, 330.90 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9354/47780 [00:34<02:06, 303.81 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10049/47780 [00:34<02:04, 302.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11408/47780 [00:34<01:41, 357.81 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10403/47780 [00:34<01:57, 319.07 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10260/47780 [00:34<02:09, 289.99 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9505/47780 [00:34<01:48, 351.83 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9402/47780 [00:35<01:50, 346.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10083/47780 [00:34<02:01, 309.30 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11445/47780 [00:35<01:42, 353.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9663/47780 [00:35<02:00, 315.41 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10436/47780 [00:35<01:57, 318.64 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10307/47780 [00:35<01:52, 331.76 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9542/47780 [00:35<01:47, 356.70 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10123/47780 [00:35<01:53, 332.24 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9699/47780 [00:35<01:57, 324.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9439/47780 [00:35<01:56, 328.97 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11491/47780 [00:35<01:38, 367.05 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10472/47780 [00:35<01:55, 323.35 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10342/47780 [00:35<01:57, 319.77 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9578/47780 [00:35<01:51, 341.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10169/47780 [00:35<01:46, 352.92 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10508/47780 [00:35<01:52, 329.97 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11538/47780 [00:35<01:34, 382.79 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9732/47780 [00:35<02:04, 305.39 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9474/47780 [00:35<01:59, 321.06 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10376/47780 [00:35<02:04, 299.93 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9613/47780 [00:35<01:54, 332.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10211/47780 [00:35<01:42, 365.56 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10549/47780 [00:35<01:47, 344.86 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9763/47780 [00:35<02:09, 293.82 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11577/47780 [00:35<01:40, 360.43 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9508/47780 [00:35<02:07, 301.05 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10407/47780 [00:35<02:05, 297.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9647/47780 [00:35<01:56, 327.96 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10593/47780 [00:35<01:39, 371.89 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10248/47780 [00:35<01:47, 348.71 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9794/47780 [00:35<02:08, 294.92 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11621/47780 [00:35<01:35, 378.21 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9539/47780 [00:35<02:06, 303.24 examples/s]
Tokenizing train dataset (num_proc=32):   4%|▍         | 2145/47780 [00:35<04:52, 156.07 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10438/47780 [00:35<02:07, 293.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9683/47780 [00:35<01:53, 336.75 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10283/47780 [00:35<01:49, 343.48 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10631/47780 [00:35<01:41, 365.70 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9827/47780 [00:35<02:04, 304.43 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11660/47780 [00:35<01:37, 369.19 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9570/47780 [00:35<02:09, 295.66 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▍         | 2329/47780 [00:35<03:05, 245.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10468/47780 [00:35<02:07, 291.91 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9717/47780 [00:35<01:59, 319.72 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10670/47780 [00:35<01:41, 364.79 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10319/47780 [00:35<01:51, 335.26 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9858/47780 [00:35<02:07, 298.53 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9602/47780 [00:35<02:06, 302.20 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11698/47780 [00:35<01:39, 362.91 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10503/47780 [00:35<02:03, 300.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9764/47780 [00:35<01:45, 361.50 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9891/47780 [00:35<02:04, 305.02 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9637/47780 [00:35<02:00, 315.31 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10353/47780 [00:35<02:00, 311.55 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10707/47780 [00:35<01:50, 334.76 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11735/47780 [00:35<01:41, 354.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10539/47780 [00:35<01:59, 310.98 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9808/47780 [00:35<01:41, 375.41 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9922/47780 [00:35<02:06, 298.82 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9669/47780 [00:35<02:01, 313.36 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10768/47780 [00:35<01:30, 408.58 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10390/47780 [00:35<01:54, 325.68 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11772/47780 [00:35<01:40, 358.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10571/47780 [00:35<02:01, 306.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9853/47780 [00:35<01:35, 395.42 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9964/47780 [00:35<01:54, 330.49 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10810/47780 [00:36<01:32, 399.45 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10425/47780 [00:35<01:57, 317.38 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9701/47780 [00:36<02:11, 288.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11808/47780 [00:36<01:50, 325.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10609/47780 [00:36<01:56, 320.23 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9894/47780 [00:36<01:40, 375.85 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10008/47780 [00:36<01:46, 353.85 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10852/47780 [00:36<01:32, 399.70 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10464/47780 [00:36<01:50, 337.05 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9743/47780 [00:36<01:58, 321.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11842/47780 [00:36<01:50, 325.74 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10642/47780 [00:36<02:05, 296.22 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9932/47780 [00:36<01:48, 348.74 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10045/47780 [00:36<01:49, 345.23 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10893/47780 [00:36<01:32, 400.04 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9776/47780 [00:36<02:03, 307.71 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11880/47780 [00:36<01:47, 333.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10499/47780 [00:36<02:03, 302.42 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10672/47780 [00:36<02:04, 297.11 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9979/47780 [00:36<01:39, 381.18 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10086/47780 [00:36<01:44, 360.93 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10934/47780 [00:36<01:32, 398.33 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9808/47780 [00:36<02:03, 306.51 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11915/47780 [00:36<01:48, 331.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10544/47780 [00:36<01:49, 338.53 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10708/47780 [00:36<01:59, 311.34 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10124/47780 [00:36<01:46, 354.05 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10975/47780 [00:36<01:36, 379.87 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10018/47780 [00:36<01:49, 345.12 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9843/47780 [00:36<02:00, 315.11 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11950/47780 [00:36<01:47, 332.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10580/47780 [00:36<01:49, 340.28 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10741/47780 [00:36<01:57, 316.56 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10160/47780 [00:36<01:52, 333.32 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10054/47780 [00:36<01:50, 342.28 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9878/47780 [00:36<01:57, 321.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 11991/47780 [00:36<01:42, 350.59 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10617/47780 [00:36<01:48, 341.23 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11014/47780 [00:36<01:47, 340.85 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10773/47780 [00:36<02:02, 303.26 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10096/47780 [00:36<01:43, 363.09 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10194/47780 [00:36<01:54, 327.66 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9913/47780 [00:36<01:55, 327.36 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12028/47780 [00:36<01:40, 355.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2430/47780 [00:36<04:13, 178.85 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10652/47780 [00:36<01:49, 339.61 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11049/47780 [00:36<01:48, 339.61 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10805/47780 [00:36<02:02, 301.57 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10137/47780 [00:36<01:40, 375.00 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9947/47780 [00:36<01:54, 329.24 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12068/47780 [00:36<01:37, 364.73 examples/s]
Tokenizing train dataset (num_proc=32):   5%|▌         | 2615/47780 [00:36<02:45, 273.51 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10229/47780 [00:36<01:58, 316.28 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10687/47780 [00:36<01:53, 327.95 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11086/47780 [00:36<01:51, 329.29 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10838/47780 [00:36<02:03, 299.42 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10179/47780 [00:36<01:37, 384.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9982/47780 [00:36<01:52, 335.19 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12105/47780 [00:36<01:39, 357.33 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10261/47780 [00:36<02:03, 304.25 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10721/47780 [00:36<01:53, 327.89 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11120/47780 [00:36<01:57, 311.62 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10869/47780 [00:36<02:03, 298.99 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10017/47780 [00:36<01:55, 328.08 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10218/47780 [00:36<01:42, 364.94 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12141/47780 [00:36<01:40, 354.74 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10292/47780 [00:36<02:05, 298.76 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10761/47780 [00:36<01:51, 333.04 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11161/47780 [00:37<01:48, 337.20 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10899/47780 [00:37<02:03, 298.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10050/47780 [00:37<01:56, 322.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12177/47780 [00:37<01:41, 351.56 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10255/47780 [00:37<01:48, 346.77 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10322/47780 [00:37<02:06, 296.39 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10797/47780 [00:37<01:48, 340.22 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10935/47780 [00:37<01:57, 313.24 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11196/47780 [00:37<01:54, 320.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10086/47780 [00:37<01:54, 328.14 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12213/47780 [00:37<01:43, 342.28 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10293/47780 [00:37<01:47, 348.67 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10352/47780 [00:37<02:11, 284.63 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10832/47780 [00:37<01:50, 335.31 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10974/47780 [00:37<01:50, 331.80 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11230/47780 [00:37<01:56, 312.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10132/47780 [00:37<01:42, 365.99 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10347/47780 [00:37<01:35, 393.22 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12251/47780 [00:37<01:46, 334.27 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10391/47780 [00:37<02:01, 306.99 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10870/47780 [00:37<01:47, 341.78 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11014/47780 [00:37<01:47, 343.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11262/47780 [00:37<02:04, 292.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10169/47780 [00:37<01:47, 348.42 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10422/47780 [00:37<02:01, 307.66 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10387/47780 [00:37<01:41, 370.16 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10912/47780 [00:37<01:43, 354.84 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12285/47780 [00:37<01:52, 314.75 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11063/47780 [00:37<01:37, 377.01 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11292/47780 [00:37<02:03, 294.41 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10205/47780 [00:37<01:47, 350.40 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10457/47780 [00:37<01:56, 319.72 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10950/47780 [00:37<01:41, 361.88 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10430/47780 [00:37<01:37, 382.31 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12317/47780 [00:37<01:53, 312.82 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11108/47780 [00:37<01:32, 397.68 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11323/47780 [00:37<02:03, 295.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10242/47780 [00:37<01:46, 353.88 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10501/47780 [00:37<01:47, 346.87 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10473/47780 [00:37<01:34, 395.27 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10987/47780 [00:37<01:43, 356.18 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12349/47780 [00:37<02:03, 286.24 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11148/47780 [00:37<01:41, 360.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11362/47780 [00:37<01:54, 318.47 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10536/47780 [00:37<01:48, 343.37 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11023/47780 [00:37<01:44, 352.36 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10513/47780 [00:37<01:37, 383.86 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10278/47780 [00:37<02:04, 301.67 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12394/47780 [00:37<01:49, 322.83 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11185/47780 [00:37<01:43, 351.91 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11398/47780 [00:37<01:50, 329.98 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10572/47780 [00:37<01:48, 344.48 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11060/47780 [00:37<01:47, 342.51 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10310/47780 [00:37<02:02, 304.79 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10552/47780 [00:37<01:42, 364.92 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12436/47780 [00:37<01:42, 345.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11222/47780 [00:37<01:42, 356.62 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11433/47780 [00:37<01:58, 307.65 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10614/47780 [00:37<01:42, 362.28 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11099/47780 [00:37<01:43, 355.67 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10353/47780 [00:37<01:51, 336.55 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10589/47780 [00:37<01:41, 366.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12473/47780 [00:38<01:48, 326.84 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11259/47780 [00:38<01:46, 341.46 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11466/47780 [00:38<01:57, 308.36 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10651/47780 [00:38<01:49, 340.33 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10630/47780 [00:38<01:39, 374.70 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10396/47780 [00:38<01:44, 358.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11136/47780 [00:38<01:46, 343.91 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12509/47780 [00:38<01:47, 328.66 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11294/47780 [00:38<01:50, 328.91 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11498/47780 [00:38<01:59, 303.52 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10698/47780 [00:38<01:39, 372.88 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10668/47780 [00:38<01:39, 374.34 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10439/47780 [00:38<01:39, 374.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11171/47780 [00:38<01:50, 331.01 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12546/47780 [00:38<01:47, 329.14 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11337/47780 [00:38<01:44, 349.78 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2720/47780 [00:38<04:39, 161.26 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10738/47780 [00:38<01:39, 372.79 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10478/47780 [00:38<01:38, 378.70 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11529/47780 [00:38<02:09, 280.61 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11205/47780 [00:38<01:52, 326.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10706/47780 [00:38<01:46, 349.33 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12581/47780 [00:38<01:47, 327.81 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11373/47780 [00:38<01:51, 326.80 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10777/47780 [00:38<01:38, 376.96 examples/s]
Tokenizing train dataset (num_proc=32):   6%|▌         | 2984/47780 [00:38<02:38, 283.51 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11558/47780 [00:38<02:10, 276.91 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11243/47780 [00:38<01:47, 338.45 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10749/47780 [00:38<01:40, 367.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10517/47780 [00:38<01:48, 342.38 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12615/47780 [00:38<01:46, 331.07 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11420/47780 [00:38<01:40, 361.28 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10815/47780 [00:38<01:40, 369.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11586/47780 [00:38<02:11, 274.25 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11277/47780 [00:38<01:55, 315.79 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10553/47780 [00:38<01:52, 329.54 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10787/47780 [00:38<01:49, 336.32 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12650/47780 [00:38<01:44, 336.25 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11457/47780 [00:38<01:41, 358.88 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10863/47780 [00:38<01:32, 401.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11615/47780 [00:38<02:11, 275.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11311/47780 [00:38<01:54, 319.59 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10589/47780 [00:38<01:50, 337.55 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10826/47780 [00:38<01:46, 347.62 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12684/47780 [00:38<01:44, 336.97 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11494/47780 [00:38<01:44, 347.40 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11645/47780 [00:38<02:09, 279.75 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10904/47780 [00:38<01:39, 368.84 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11344/47780 [00:38<01:53, 321.90 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10624/47780 [00:38<01:51, 333.73 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12718/47780 [00:38<01:49, 319.70 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10862/47780 [00:38<01:51, 331.84 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11530/47780 [00:38<01:44, 347.00 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11676/47780 [00:38<02:07, 283.51 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10943/47780 [00:38<01:40, 367.08 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11377/47780 [00:38<01:56, 313.74 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10659/47780 [00:38<01:52, 330.86 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12763/47780 [00:38<01:38, 356.45 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10897/47780 [00:38<01:50, 334.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11716/47780 [00:38<01:54, 315.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11566/47780 [00:38<01:54, 315.30 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10981/47780 [00:38<01:44, 350.89 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11409/47780 [00:38<01:59, 305.53 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12800/47780 [00:38<01:40, 348.42 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10693/47780 [00:39<01:58, 312.36 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10931/47780 [00:38<01:55, 318.24 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11756/47780 [00:39<01:46, 339.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11622/47780 [00:39<01:36, 376.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11017/47780 [00:39<01:46, 345.92 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11440/47780 [00:39<01:58, 306.27 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12836/47780 [00:39<01:40, 346.68 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10725/47780 [00:39<02:04, 298.06 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10964/47780 [00:39<01:59, 307.73 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11793/47780 [00:39<01:43, 348.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11663/47780 [00:39<01:35, 377.15 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11475/47780 [00:39<01:58, 305.25 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11052/47780 [00:39<01:54, 321.89 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12873/47780 [00:39<01:39, 350.55 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10997/47780 [00:39<01:59, 307.21 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10756/47780 [00:39<02:08, 288.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11829/47780 [00:39<01:44, 343.44 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11702/47780 [00:39<01:39, 364.24 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11510/47780 [00:39<01:56, 310.94 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11085/47780 [00:39<01:56, 314.09 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12909/47780 [00:39<01:45, 330.33 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11039/47780 [00:39<01:48, 337.93 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10787/47780 [00:39<02:06, 291.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11865/47780 [00:39<01:51, 322.31 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11739/47780 [00:39<01:44, 343.62 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11548/47780 [00:39<01:53, 319.48 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11117/47780 [00:39<02:01, 302.84 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12943/47780 [00:39<01:44, 332.56 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10828/47780 [00:39<01:53, 324.25 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11075/47780 [00:39<01:51, 329.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11899/47780 [00:39<01:50, 323.51 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11586/47780 [00:39<01:48, 332.81 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11151/47780 [00:39<01:57, 312.79 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12978/47780 [00:39<01:44, 334.15 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10861/47780 [00:39<01:57, 314.93 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11774/47780 [00:39<01:55, 311.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11109/47780 [00:39<01:58, 309.67 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11932/47780 [00:39<02:00, 298.27 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11623/47780 [00:39<01:45, 343.31 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11187/47780 [00:39<01:53, 322.32 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13014/47780 [00:39<01:42, 337.77 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11818/47780 [00:39<01:44, 344.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10901/47780 [00:39<01:51, 331.74 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11141/47780 [00:39<02:02, 298.46 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11658/47780 [00:39<01:44, 345.00 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11963/47780 [00:39<02:05, 286.05 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11225/47780 [00:39<01:47, 338.50 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13049/47780 [00:39<01:44, 333.00 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10937/47780 [00:39<01:48, 339.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11854/47780 [00:39<01:47, 334.50 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11172/47780 [00:39<02:08, 285.86 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12001/47780 [00:39<01:56, 308.10 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11693/47780 [00:39<01:46, 338.68 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11260/47780 [00:39<01:48, 337.81 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13087/47780 [00:39<01:43, 335.44 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10975/47780 [00:39<01:45, 347.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11889/47780 [00:39<01:50, 324.52 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11201/47780 [00:39<02:11, 278.20 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11737/47780 [00:39<01:40, 359.47 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11297/47780 [00:39<01:46, 343.64 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12033/47780 [00:39<02:01, 295.19 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13131/47780 [00:39<01:35, 361.17 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3113/47780 [00:39<04:11, 177.89 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11011/47780 [00:39<01:47, 342.66 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11932/47780 [00:39<01:42, 349.35 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11231/47780 [00:39<02:09, 281.24 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11774/47780 [00:39<01:39, 362.12 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11332/47780 [00:40<01:51, 326.50 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3398/47780 [00:40<02:28, 299.75 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12063/47780 [00:40<02:08, 278.36 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11048/47780 [00:40<01:45, 347.03 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13168/47780 [00:40<01:38, 351.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 11971/47780 [00:40<01:40, 356.47 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11270/47780 [00:40<01:58, 308.00 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11814/47780 [00:40<01:39, 361.23 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11365/47780 [00:40<01:52, 323.44 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11088/47780 [00:40<01:41, 362.29 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12094/47780 [00:40<02:05, 283.76 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13204/47780 [00:40<01:40, 345.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12014/47780 [00:40<01:34, 376.97 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11853/47780 [00:40<01:38, 365.21 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11302/47780 [00:40<02:03, 294.68 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11403/47780 [00:40<01:47, 339.37 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12123/47780 [00:40<02:06, 282.05 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11125/47780 [00:40<01:43, 355.87 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13239/47780 [00:40<01:42, 335.53 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12053/47780 [00:40<01:41, 352.40 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11333/47780 [00:40<02:02, 298.65 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11890/47780 [00:40<01:44, 342.97 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11439/47780 [00:40<01:47, 337.62 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11163/47780 [00:40<01:41, 359.02 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13274/47780 [00:40<01:41, 339.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12152/47780 [00:40<02:12, 269.54 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12089/47780 [00:40<01:45, 339.83 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11364/47780 [00:40<02:00, 301.42 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11925/47780 [00:40<01:44, 344.56 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11477/47780 [00:40<01:44, 346.22 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11200/47780 [00:40<01:41, 361.97 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12189/47780 [00:40<02:01, 294.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13310/47780 [00:40<01:41, 338.10 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12133/47780 [00:40<01:38, 363.29 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11396/47780 [00:40<01:59, 304.04 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11961/47780 [00:40<01:43, 345.08 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11238/47780 [00:40<01:40, 363.64 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11512/47780 [00:40<01:50, 328.36 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12221/47780 [00:40<01:59, 297.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13344/47780 [00:40<01:44, 330.71 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12183/47780 [00:40<01:30, 392.66 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11427/47780 [00:40<02:00, 302.23 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11275/47780 [00:40<01:39, 365.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11553/47780 [00:40<01:44, 347.35 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13384/47780 [00:40<01:40, 343.07 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12251/47780 [00:40<02:03, 288.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 11996/47780 [00:40<01:55, 310.53 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12223/47780 [00:40<01:33, 381.89 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11465/47780 [00:40<01:52, 322.29 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11312/47780 [00:40<01:40, 362.35 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11588/47780 [00:40<01:46, 340.39 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13422/47780 [00:40<01:38, 349.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12028/47780 [00:40<01:55, 310.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12283/47780 [00:40<02:01, 293.04 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11498/47780 [00:40<01:52, 322.95 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12262/47780 [00:40<01:37, 363.94 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11357/47780 [00:40<01:34, 384.50 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12060/47780 [00:40<01:54, 312.88 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12317/47780 [00:40<01:56, 304.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11626/47780 [00:40<01:47, 336.33 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13458/47780 [00:40<01:44, 329.30 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11533/47780 [00:40<01:50, 327.48 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12299/47780 [00:40<01:38, 361.54 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11396/47780 [00:41<01:36, 376.31 examples/s]
Tokenizing train dataset (num_proc=32):   7%|▋         | 3546/47780 [00:40<02:59, 245.88 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12093/47780 [00:40<01:52, 317.51 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12348/47780 [00:41<01:57, 302.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11660/47780 [00:41<01:48, 333.13 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13492/47780 [00:41<01:45, 325.62 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11566/47780 [00:41<01:50, 327.90 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12336/47780 [00:41<01:42, 344.38 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12129/47780 [00:41<01:50, 322.80 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12380/47780 [00:41<01:55, 307.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11434/47780 [00:41<01:44, 348.64 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11696/47780 [00:41<01:51, 322.99 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13527/47780 [00:41<01:43, 332.26 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11607/47780 [00:41<01:47, 336.40 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12374/47780 [00:41<01:40, 350.61 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12412/47780 [00:41<01:53, 311.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12172/47780 [00:41<01:41, 349.51 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13572/47780 [00:41<01:34, 361.87 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11471/47780 [00:41<01:49, 332.59 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11729/47780 [00:41<01:53, 317.46 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11642/47780 [00:41<01:49, 329.00 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12410/47780 [00:41<01:45, 334.21 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12444/47780 [00:41<01:52, 313.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12212/47780 [00:41<01:39, 355.68 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11508/47780 [00:41<01:47, 338.37 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11761/47780 [00:41<01:56, 308.10 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13609/47780 [00:41<01:41, 336.81 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11675/47780 [00:41<01:54, 314.97 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12445/47780 [00:41<01:45, 334.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12476/47780 [00:41<01:54, 308.29 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12248/47780 [00:41<01:42, 345.10 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11796/47780 [00:41<01:54, 313.00 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13644/47780 [00:41<01:42, 332.98 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11543/47780 [00:41<01:56, 311.57 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11707/47780 [00:41<01:58, 305.54 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12480/47780 [00:41<01:46, 331.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12515/47780 [00:41<01:49, 321.08 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12285/47780 [00:41<01:43, 344.25 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11836/47780 [00:41<01:47, 333.64 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11593/47780 [00:41<01:40, 361.37 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13678/47780 [00:41<01:46, 321.13 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11742/47780 [00:41<01:58, 304.81 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12560/47780 [00:41<01:38, 358.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12514/47780 [00:41<01:48, 326.54 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11878/47780 [00:41<01:41, 354.01 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12320/47780 [00:41<01:51, 316.70 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11642/47780 [00:41<01:31, 396.48 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13716/47780 [00:41<01:43, 330.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11780/47780 [00:41<01:51, 322.18 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12596/47780 [00:41<01:42, 342.28 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12547/47780 [00:41<01:55, 303.87 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11918/47780 [00:41<01:38, 363.01 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11687/47780 [00:41<01:29, 402.60 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12353/47780 [00:41<01:54, 309.17 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13751/47780 [00:41<01:44, 324.68 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11813/47780 [00:41<01:58, 303.70 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12633/47780 [00:41<01:42, 342.82 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12580/47780 [00:41<01:53, 309.23 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11956/47780 [00:41<01:38, 363.80 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11728/47780 [00:41<01:30, 397.16 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12390/47780 [00:41<01:50, 319.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13785/47780 [00:41<01:48, 314.66 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11845/47780 [00:41<01:57, 305.86 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12668/47780 [00:42<01:45, 333.51 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12620/47780 [00:41<01:46, 329.05 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3655/47780 [00:41<03:43, 197.12 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11993/47780 [00:41<01:40, 356.96 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12423/47780 [00:41<01:50, 320.78 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11770/47780 [00:42<01:32, 389.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13819/47780 [00:42<01:46, 318.63 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11885/47780 [00:42<01:48, 331.19 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3827/47780 [00:42<02:40, 273.12 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12702/47780 [00:42<01:48, 324.30 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12655/47780 [00:42<01:48, 323.81 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12456/47780 [00:42<01:49, 322.23 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12029/47780 [00:42<01:45, 338.63 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11814/47780 [00:42<01:29, 403.24 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13868/47780 [00:42<01:33, 362.41 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11920/47780 [00:42<01:50, 325.44 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12702/47780 [00:42<01:38, 357.01 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12736/47780 [00:42<01:48, 321.53 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12064/47780 [00:42<01:48, 330.49 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12489/47780 [00:42<01:57, 300.40 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11856/47780 [00:42<01:33, 385.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13907/47780 [00:42<01:32, 366.07 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11954/47780 [00:42<01:48, 329.39 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12738/47780 [00:42<01:38, 357.38 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12769/47780 [00:42<01:49, 320.32 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12100/47780 [00:42<01:46, 335.34 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12521/47780 [00:42<01:55, 305.58 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11898/47780 [00:42<01:36, 370.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13944/47780 [00:42<01:35, 354.77 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11989/47780 [00:42<01:50, 324.24 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12804/47780 [00:42<01:47, 325.07 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12785/47780 [00:42<01:32, 376.99 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12557/47780 [00:42<01:49, 320.81 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12134/47780 [00:42<01:49, 325.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11938/47780 [00:42<01:35, 375.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13986/47780 [00:42<01:32, 365.27 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12030/47780 [00:42<01:43, 346.81 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12826/47780 [00:42<01:30, 385.97 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12838/47780 [00:42<01:48, 321.96 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12180/47780 [00:42<01:38, 362.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12590/47780 [00:42<01:56, 302.91 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14024/47780 [00:42<01:33, 361.26 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11976/47780 [00:42<01:40, 356.24 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12075/47780 [00:42<01:37, 364.93 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12872/47780 [00:42<01:26, 403.23 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12871/47780 [00:42<01:52, 309.35 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12217/47780 [00:42<01:41, 349.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12621/47780 [00:42<01:58, 297.95 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12012/47780 [00:42<01:43, 345.90 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14061/47780 [00:42<01:45, 319.84 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12903/47780 [00:42<01:52, 309.21 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12112/47780 [00:42<01:48, 329.21 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12913/47780 [00:42<01:37, 359.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12267/47780 [00:42<01:32, 383.28 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12652/47780 [00:42<02:01, 288.35 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12047/47780 [00:42<01:48, 328.76 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14098/47780 [00:42<01:42, 329.93 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12934/47780 [00:42<01:53, 306.03 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12147/47780 [00:42<01:47, 330.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12309/47780 [00:42<01:32, 384.61 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12685/47780 [00:42<01:57, 299.10 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12950/47780 [00:42<01:45, 329.73 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12083/47780 [00:42<01:46, 333.84 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14133/47780 [00:42<01:40, 335.25 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12967/47780 [00:42<01:52, 309.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12181/47780 [00:42<01:55, 307.25 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12716/47780 [00:42<01:56, 299.97 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12348/47780 [00:42<01:35, 369.42 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12991/47780 [00:42<01:41, 344.07 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12119/47780 [00:43<01:44, 340.88 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13003/47780 [00:43<01:47, 324.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14168/47780 [00:43<01:44, 321.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12214/47780 [00:43<01:54, 310.14 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12748/47780 [00:43<01:54, 305.45 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12387/47780 [00:43<01:34, 375.14 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12158/47780 [00:43<01:43, 343.37 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13027/47780 [00:43<01:48, 321.03 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14202/47780 [00:43<01:44, 322.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13036/47780 [00:43<01:57, 294.52 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12430/47780 [00:43<01:32, 382.44 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12246/47780 [00:43<02:01, 292.96 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12779/47780 [00:43<02:09, 269.59 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12196/47780 [00:43<01:42, 345.89 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13061/47780 [00:43<01:48, 319.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14236/47780 [00:43<01:43, 323.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13069/47780 [00:43<01:57, 295.02 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12477/47780 [00:43<01:26, 407.27 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12285/47780 [00:43<01:52, 316.20 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12821/47780 [00:43<01:52, 309.63 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12235/47780 [00:43<01:39, 356.80 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13094/47780 [00:43<01:54, 302.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13112/47780 [00:43<01:45, 328.33 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14269/47780 [00:43<01:57, 284.42 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12519/47780 [00:43<01:28, 397.27 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12318/47780 [00:43<01:52, 314.39 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12854/47780 [00:43<01:58, 295.70 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12277/47780 [00:43<01:39, 355.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13125/47780 [00:43<01:54, 301.60 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13149/47780 [00:43<01:46, 325.54 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14324/47780 [00:43<01:35, 349.91 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12567/47780 [00:43<01:25, 412.14 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12353/47780 [00:43<01:50, 319.31 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13158/47780 [00:43<01:51, 309.18 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12885/47780 [00:43<02:00, 290.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12314/47780 [00:43<01:42, 344.55 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13183/47780 [00:43<01:45, 329.32 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14363/47780 [00:43<01:33, 356.78 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12617/47780 [00:43<01:21, 431.59 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12394/47780 [00:43<01:44, 337.32 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13194/47780 [00:43<01:47, 323.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12349/47780 [00:43<01:44, 339.09 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13217/47780 [00:43<01:46, 324.91 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14403/47780 [00:43<01:31, 364.74 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12915/47780 [00:43<02:14, 258.90 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12663/47780 [00:43<01:22, 424.68 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12428/47780 [00:43<01:49, 323.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13231/47780 [00:43<01:44, 329.35 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12383/47780 [00:43<01:58, 298.89 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14441/47780 [00:43<01:33, 357.05 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12956/47780 [00:43<02:04, 280.40 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12461/47780 [00:43<01:49, 321.41 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13250/47780 [00:43<01:55, 298.79 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12706/47780 [00:43<01:28, 398.20 examples/s]
Tokenizing train dataset (num_proc=32):   8%|▊         | 3933/47780 [00:43<04:46, 152.84 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13270/47780 [00:43<01:42, 335.18 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12419/47780 [00:43<01:53, 311.47 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14478/47780 [00:43<01:34, 352.61 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13287/47780 [00:43<01:49, 315.37 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12994/47780 [00:43<01:57, 296.70 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12747/47780 [00:43<01:29, 389.80 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4252/47780 [00:43<02:34, 281.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13304/47780 [00:43<01:43, 332.57 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12453/47780 [00:44<01:51, 318.12 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14514/47780 [00:44<01:35, 347.09 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12495/47780 [00:44<02:19, 252.85 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13026/47780 [00:44<01:58, 293.42 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13321/47780 [00:44<01:55, 298.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12787/47780 [00:44<01:33, 376.02 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13339/47780 [00:44<01:48, 316.27 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12486/47780 [00:44<01:53, 311.81 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14549/47780 [00:44<01:36, 344.03 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12549/47780 [00:44<01:53, 309.18 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13056/47780 [00:44<02:01, 286.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12826/47780 [00:44<01:39, 352.82 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13352/47780 [00:44<02:05, 275.07 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13375/47780 [00:44<01:45, 324.62 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14584/47780 [00:44<01:36, 345.36 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12583/47780 [00:44<01:52, 313.77 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12521/47780 [00:44<01:57, 299.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13085/47780 [00:44<02:05, 275.54 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13414/47780 [00:44<01:40, 342.92 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12863/47780 [00:44<01:41, 345.11 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13383/47780 [00:44<02:05, 274.85 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14620/47780 [00:44<01:35, 345.80 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12617/47780 [00:44<01:51, 314.08 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12552/47780 [00:44<02:01, 289.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13113/47780 [00:44<02:05, 276.47 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13449/47780 [00:44<01:44, 329.71 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12913/47780 [00:44<01:35, 364.49 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14655/47780 [00:44<01:37, 338.50 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12650/47780 [00:44<01:50, 317.92 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13413/47780 [00:44<02:19, 245.83 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13143/47780 [00:44<02:03, 280.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12582/47780 [00:44<02:05, 280.44 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13484/47780 [00:44<01:42, 335.39 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12951/47780 [00:44<01:38, 355.08 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13458/47780 [00:44<01:56, 294.00 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12683/47780 [00:44<01:56, 301.75 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13177/47780 [00:44<01:57, 293.64 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14689/47780 [00:44<01:49, 301.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12618/47780 [00:44<01:58, 296.60 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13518/47780 [00:44<01:43, 332.01 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12988/47780 [00:44<01:38, 353.81 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13494/47780 [00:44<01:50, 311.11 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13217/47780 [00:44<01:49, 316.94 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12653/47780 [00:44<01:53, 310.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14720/47780 [00:44<01:52, 294.26 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12716/47780 [00:44<02:03, 284.77 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13560/47780 [00:44<01:38, 346.43 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13026/47780 [00:44<01:37, 356.87 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13529/47780 [00:44<01:47, 318.20 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13255/47780 [00:44<01:44, 330.87 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14757/47780 [00:44<01:46, 311.45 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12685/47780 [00:44<02:03, 284.02 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12746/47780 [00:44<02:07, 274.41 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13598/47780 [00:44<01:38, 348.14 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13062/47780 [00:44<01:38, 354.02 examples/s]
Tokenizing train dataset (num_proc=32):   9%|▉         | 4392/47780 [00:44<03:03, 236.98 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13570/47780 [00:44<01:39, 343.54 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13289/47780 [00:44<01:46, 322.66 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14789/47780 [00:44<01:47, 307.95 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12717/47780 [00:44<02:00, 290.53 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12775/47780 [00:44<02:07, 275.50 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13101/47780 [00:44<01:36, 360.21 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13633/47780 [00:44<01:43, 329.61 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4560/47780 [00:44<02:17, 313.45 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13606/47780 [00:45<01:45, 322.67 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13328/47780 [00:44<01:40, 341.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14821/47780 [00:45<01:46, 310.54 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12747/47780 [00:45<02:04, 280.53 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13668/47780 [00:45<01:41, 334.95 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12813/47780 [00:45<02:02, 285.23 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13138/47780 [00:45<01:39, 347.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13364/47780 [00:45<01:41, 339.06 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14853/47780 [00:45<01:47, 306.00 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13641/47780 [00:45<01:55, 294.83 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12776/47780 [00:45<02:04, 280.39 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12857/47780 [00:45<01:48, 323.08 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13702/47780 [00:45<01:43, 329.33 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13182/47780 [00:45<01:33, 369.01 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13403/47780 [00:45<01:38, 349.88 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14884/47780 [00:45<01:52, 293.51 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13683/47780 [00:45<01:44, 327.02 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12806/47780 [00:45<02:02, 285.71 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13736/47780 [00:45<01:42, 330.58 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12890/47780 [00:45<01:49, 317.38 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13221/47780 [00:45<01:34, 366.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13439/47780 [00:45<01:37, 352.68 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14918/47780 [00:45<01:48, 303.49 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12837/47780 [00:45<02:01, 287.22 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13717/47780 [00:45<01:49, 310.22 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13261/47780 [00:45<01:32, 371.86 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12923/47780 [00:45<01:54, 304.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13770/47780 [00:45<01:52, 303.36 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14949/47780 [00:45<01:48, 303.85 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13475/47780 [00:45<01:45, 324.50 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13753/47780 [00:45<01:48, 313.68 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12866/47780 [00:45<02:11, 265.60 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13303/47780 [00:45<01:30, 380.85 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13805/47780 [00:45<01:49, 309.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12954/47780 [00:45<01:59, 290.43 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14985/47780 [00:45<01:43, 317.86 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13510/47780 [00:45<01:43, 331.54 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13787/47780 [00:45<01:47, 315.74 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12902/47780 [00:45<02:02, 283.61 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13343/47780 [00:45<01:33, 369.64 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12987/47780 [00:45<01:56, 297.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13838/47780 [00:45<01:52, 301.72 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13544/47780 [00:45<01:42, 333.87 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15019/47780 [00:45<01:49, 299.92 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12937/47780 [00:45<01:55, 300.52 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13820/47780 [00:45<01:53, 298.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13381/47780 [00:45<01:34, 364.41 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13871/47780 [00:45<01:50, 306.40 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13018/47780 [00:45<02:06, 273.87 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13578/47780 [00:45<01:46, 320.88 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15050/47780 [00:45<01:49, 299.41 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12970/47780 [00:45<01:52, 308.73 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13860/47780 [00:45<01:45, 322.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13418/47780 [00:45<01:37, 354.04 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13902/47780 [00:45<01:55, 294.29 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13046/47780 [00:45<02:10, 266.95 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15085/47780 [00:45<01:44, 313.44 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13615/47780 [00:45<01:45, 323.91 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13006/47780 [00:45<01:47, 323.21 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13899/47780 [00:45<01:40, 336.94 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13454/47780 [00:45<01:39, 344.15 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13937/47780 [00:45<01:49, 309.68 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13074/47780 [00:45<02:12, 262.25 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13652/47780 [00:45<01:42, 332.87 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15117/47780 [00:46<01:50, 295.00 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13039/47780 [00:46<01:55, 300.66 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13935/47780 [00:46<01:44, 325.31 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13969/47780 [00:46<01:51, 302.38 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13489/47780 [00:46<01:46, 320.66 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13693/47780 [00:46<01:36, 354.75 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13101/47780 [00:46<02:14, 258.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15152/47780 [00:46<01:45, 307.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13972/47780 [00:46<01:42, 330.34 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13070/47780 [00:46<02:00, 287.41 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14004/47780 [00:46<01:48, 312.11 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13524/47780 [00:46<01:45, 325.01 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13738/47780 [00:46<01:30, 377.99 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13135/47780 [00:46<02:04, 278.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15192/47780 [00:46<01:37, 332.96 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14015/47780 [00:46<01:36, 350.15 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13100/47780 [00:46<02:01, 284.88 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14036/47780 [00:46<01:48, 311.03 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13165/47780 [00:46<02:01, 284.18 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13557/47780 [00:46<01:49, 312.63 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13777/47780 [00:46<01:30, 375.31 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15226/47780 [00:46<01:44, 310.14 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14051/47780 [00:46<01:36, 348.70 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13129/47780 [00:46<02:01, 285.99 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14069/47780 [00:46<01:51, 302.20 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13594/47780 [00:46<01:44, 328.18 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13196/47780 [00:46<02:02, 281.83 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13815/47780 [00:46<01:34, 357.85 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15258/47780 [00:46<01:48, 299.60 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13158/47780 [00:46<02:03, 281.07 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14087/47780 [00:46<01:38, 340.67 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14105/47780 [00:46<01:46, 315.18 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13628/47780 [00:46<01:45, 324.44 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13231/47780 [00:46<01:54, 300.99 examples/s]
Tokenizing train dataset (num_proc=32):  10%|▉         | 4681/47780 [00:46<03:51, 186.11 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13852/47780 [00:46<01:42, 331.32 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13189/47780 [00:46<02:00, 286.12 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15289/47780 [00:46<01:54, 283.92 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14122/47780 [00:46<01:38, 340.74 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13269/47780 [00:46<01:49, 316.59 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14137/47780 [00:46<01:54, 293.33 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13663/47780 [00:46<01:48, 313.37 examples/s]
Tokenizing train dataset (num_proc=32):  10%|█         | 4994/47780 [00:46<02:11, 325.01 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13886/47780 [00:46<01:42, 330.04 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13223/47780 [00:46<01:55, 298.13 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14157/47780 [00:46<01:39, 338.15 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15331/47780 [00:46<01:44, 310.36 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13306/47780 [00:46<01:45, 328.16 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14168/47780 [00:46<01:52, 297.75 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13706/47780 [00:46<01:40, 338.67 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13920/47780 [00:46<01:43, 328.61 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13254/47780 [00:46<01:57, 294.67 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14197/47780 [00:46<01:35, 351.88 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13342/47780 [00:46<01:42, 337.26 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15364/47780 [00:46<01:53, 285.31 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13748/47780 [00:46<01:34, 360.89 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14199/47780 [00:46<01:56, 287.92 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13954/47780 [00:46<01:47, 314.69 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13285/47780 [00:46<01:55, 297.58 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15406/47780 [00:46<01:41, 319.69 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13376/47780 [00:46<01:44, 329.96 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14233/47780 [00:46<01:46, 314.56 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13785/47780 [00:46<01:39, 342.99 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14229/47780 [00:46<02:02, 273.53 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13992/47780 [00:46<01:42, 329.25 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13322/47780 [00:47<01:48, 316.51 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14273/47780 [00:47<01:39, 337.27 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13410/47780 [00:47<01:45, 325.79 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15439/47780 [00:47<01:46, 302.63 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14273/47780 [00:47<01:45, 318.53 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13820/47780 [00:47<01:45, 321.02 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14040/47780 [00:47<01:32, 366.03 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13355/47780 [00:47<01:47, 320.42 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14315/47780 [00:47<01:34, 352.36 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13446/47780 [00:47<01:44, 327.87 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15471/47780 [00:47<01:45, 305.09 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14306/47780 [00:47<01:51, 301.23 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13857/47780 [00:47<01:43, 327.53 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14080/47780 [00:47<01:30, 372.62 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13388/47780 [00:47<01:48, 315.59 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13480/47780 [00:47<01:43, 331.24 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14351/47780 [00:47<01:37, 343.02 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15503/47780 [00:47<01:55, 280.31 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14337/47780 [00:47<01:53, 294.35 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13891/47780 [00:47<01:45, 320.26 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14118/47780 [00:47<01:34, 354.43 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13420/47780 [00:47<01:53, 302.62 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13514/47780 [00:47<01:51, 308.39 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14386/47780 [00:47<01:48, 307.46 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14367/47780 [00:47<01:54, 292.14 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13926/47780 [00:47<01:44, 323.27 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15533/47780 [00:47<01:58, 271.35 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13452/47780 [00:47<01:52, 304.19 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14154/47780 [00:47<01:38, 340.40 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13546/47780 [00:47<01:53, 302.15 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14431/47780 [00:47<01:37, 341.10 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13959/47780 [00:47<01:47, 316.03 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15561/47780 [00:47<01:59, 270.54 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14397/47780 [00:47<01:59, 279.31 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13484/47780 [00:47<01:51, 308.60 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14189/47780 [00:47<01:47, 311.88 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13578/47780 [00:47<01:55, 297.03 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13994/47780 [00:47<01:44, 322.16 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14433/47780 [00:47<01:51, 298.17 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14467/47780 [00:47<01:42, 324.52 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15589/47780 [00:47<02:01, 265.51 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13515/47780 [00:47<02:03, 276.93 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14228/47780 [00:47<01:43, 322.81 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13608/47780 [00:47<01:55, 294.74 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14037/47780 [00:47<01:36, 348.71 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15617/47780 [00:47<01:59, 268.93 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14507/47780 [00:47<01:37, 341.53 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14475/47780 [00:47<01:41, 328.40 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13544/47780 [00:47<02:02, 280.40 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14262/47780 [00:47<01:47, 310.85 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13641/47780 [00:47<01:53, 301.29 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14079/47780 [00:47<01:33, 362.14 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14550/47780 [00:47<01:31, 362.41 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15647/47780 [00:47<01:57, 274.59 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14509/47780 [00:47<01:47, 310.68 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13582/47780 [00:47<01:51, 307.52 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14294/47780 [00:47<01:46, 313.22 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13672/47780 [00:47<01:53, 300.37 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14591/47780 [00:47<01:30, 366.74 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15676/47780 [00:47<02:00, 266.73 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14116/47780 [00:47<01:37, 347.00 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14543/47780 [00:47<01:46, 311.88 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13614/47780 [00:48<01:51, 305.20 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█         | 5144/47780 [00:47<03:11, 223.00 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14326/47780 [00:47<01:49, 305.10 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13703/47780 [00:48<01:55, 296.32 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15713/47780 [00:48<01:49, 292.47 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14629/47780 [00:48<01:32, 358.03 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13646/47780 [00:48<01:50, 309.10 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14151/47780 [00:48<01:42, 328.79 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14577/47780 [00:48<01:48, 305.70 examples/s]
Tokenizing train dataset (num_proc=32):  11%|█▏        | 5376/47780 [00:48<02:11, 323.41 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14357/47780 [00:48<01:52, 297.21 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13737/47780 [00:48<01:51, 305.36 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15747/47780 [00:48<01:45, 302.49 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14666/47780 [00:48<01:35, 345.81 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14186/47780 [00:48<01:41, 331.82 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13679/47780 [00:48<01:50, 308.33 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14608/47780 [00:48<01:50, 300.72 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14392/47780 [00:48<01:47, 311.09 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13771/47780 [00:48<01:52, 303.37 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15778/47780 [00:48<01:48, 294.23 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14221/47780 [00:48<01:39, 336.88 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13711/47780 [00:48<01:49, 311.32 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14702/47780 [00:48<01:37, 339.05 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14639/47780 [00:48<01:57, 280.99 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14431/47780 [00:48<01:42, 325.94 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13802/47780 [00:48<01:54, 296.22 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15813/47780 [00:48<01:44, 306.85 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13743/47780 [00:48<01:49, 312.02 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14255/47780 [00:48<01:41, 330.22 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14737/47780 [00:48<01:42, 320.85 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14673/47780 [00:48<01:52, 294.14 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14465/47780 [00:48<01:41, 329.59 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13848/47780 [00:48<01:39, 342.28 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14289/47780 [00:48<01:45, 318.50 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13775/47780 [00:48<01:55, 293.78 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15844/47780 [00:48<01:53, 282.02 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14776/47780 [00:48<01:37, 339.34 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14499/47780 [00:48<01:44, 318.37 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14704/47780 [00:48<02:01, 271.28 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13883/47780 [00:48<01:41, 333.02 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14322/47780 [00:48<01:45, 318.13 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13818/47780 [00:48<01:42, 330.53 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14811/47780 [00:48<01:39, 331.43 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15877/47780 [00:48<01:52, 282.66 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14531/47780 [00:48<01:50, 301.76 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14732/47780 [00:48<02:05, 262.75 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13917/47780 [00:48<01:44, 324.05 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14356/47780 [00:48<01:43, 322.53 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13852/47780 [00:48<01:45, 322.25 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14845/47780 [00:48<01:40, 326.30 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15911/47780 [00:48<01:49, 291.98 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14566/47780 [00:48<01:46, 311.68 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13957/47780 [00:48<01:38, 342.12 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14770/47780 [00:48<01:54, 289.09 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14389/47780 [00:48<01:45, 315.32 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13895/47780 [00:48<01:37, 348.89 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14879/47780 [00:48<01:39, 330.00 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15958/47780 [00:48<01:33, 340.85 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14598/47780 [00:48<01:46, 310.48 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13992/47780 [00:48<01:38, 341.99 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14806/47780 [00:48<01:46, 308.22 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15997/47780 [00:48<01:30, 350.83 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14913/47780 [00:48<01:42, 321.92 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13932/47780 [00:48<01:40, 335.30 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14421/47780 [00:48<01:54, 290.44 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14630/47780 [00:48<01:45, 313.15 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14838/47780 [00:48<01:48, 303.26 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14027/47780 [00:49<01:53, 297.95 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16033/47780 [00:49<01:30, 352.72 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14956/47780 [00:49<01:35, 344.90 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13967/47780 [00:49<01:42, 328.72 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14451/47780 [00:49<01:58, 280.58 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14662/47780 [00:49<01:47, 307.19 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14870/47780 [00:49<01:49, 301.15 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14060/47780 [00:49<01:52, 300.33 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16069/47780 [00:49<01:32, 343.19 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14992/47780 [00:49<01:34, 348.72 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14480/47780 [00:49<01:58, 280.11 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14003/47780 [00:49<01:45, 319.64 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14694/47780 [00:49<01:53, 291.74 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14901/47780 [00:49<01:51, 293.64 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16106/47780 [00:49<01:32, 343.58 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15031/47780 [00:49<01:32, 352.99 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14092/47780 [00:49<01:58, 284.26 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14510/47780 [00:49<01:56, 285.58 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14037/47780 [00:49<01:45, 321.03 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14724/47780 [00:49<01:56, 284.69 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14931/47780 [00:49<01:54, 286.15 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15085/47780 [00:49<01:20, 406.65 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16141/47780 [00:49<01:34, 333.59 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14123/47780 [00:49<01:56, 288.28 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14076/47780 [00:49<01:39, 337.22 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14539/47780 [00:49<02:02, 271.74 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14755/47780 [00:49<01:53, 291.45 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14960/47780 [00:49<02:00, 271.97 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15128/47780 [00:49<01:19, 413.24 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14156/47780 [00:49<01:54, 292.49 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14112/47780 [00:49<01:37, 343.64 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16175/47780 [00:49<01:39, 317.22 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14574/47780 [00:49<01:54, 290.22 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14785/47780 [00:49<01:59, 275.12 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14988/47780 [00:49<02:02, 268.03 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15171/47780 [00:49<01:24, 386.83 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14186/47780 [00:49<01:58, 284.10 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16220/47780 [00:49<01:34, 332.39 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14604/47780 [00:49<01:59, 277.33 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14147/47780 [00:49<01:46, 316.38 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14818/47780 [00:49<01:54, 287.14 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15015/47780 [00:49<02:04, 262.19 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14217/47780 [00:49<01:55, 289.72 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14632/47780 [00:49<01:59, 277.74 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16262/47780 [00:49<01:30, 348.48 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14180/47780 [00:49<01:46, 316.33 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15211/47780 [00:49<01:33, 347.65 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14850/47780 [00:49<01:52, 293.35 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15046/47780 [00:49<01:59, 273.37 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14248/47780 [00:49<01:54, 292.79 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14661/47780 [00:49<01:58, 278.44 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14212/47780 [00:49<01:48, 310.34 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16297/47780 [00:49<01:33, 337.82 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5520/47780 [00:49<03:40, 191.89 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14881/47780 [00:49<01:50, 297.79 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15247/47780 [00:49<01:40, 323.74 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15077/47780 [00:49<01:57, 277.48 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14284/47780 [00:49<01:47, 311.01 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14691/47780 [00:49<01:56, 284.56 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16334/47780 [00:49<01:30, 346.63 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14244/47780 [00:49<01:48, 309.04 examples/s]
Tokenizing train dataset (num_proc=32):  12%|█▏        | 5856/47780 [00:49<02:08, 326.08 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15283/47780 [00:50<01:39, 326.44 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14911/47780 [00:49<01:59, 275.83 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15113/47780 [00:49<01:51, 293.58 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14326/47780 [00:49<01:37, 342.16 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14736/47780 [00:50<01:39, 332.24 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14277/47780 [00:50<01:46, 314.22 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15320/47780 [00:50<01:37, 334.31 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16369/47780 [00:50<01:40, 311.40 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15143/47780 [00:50<01:52, 289.23 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14943/47780 [00:50<01:57, 278.92 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14361/47780 [00:50<01:40, 333.18 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14770/47780 [00:50<01:42, 323.42 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14310/47780 [00:50<01:46, 313.26 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16401/47780 [00:50<01:42, 305.10 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15355/47780 [00:50<01:38, 327.68 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15172/47780 [00:50<01:53, 286.34 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14976/47780 [00:50<01:51, 292.91 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14395/47780 [00:50<01:46, 313.59 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14344/47780 [00:50<01:44, 320.67 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14803/47780 [00:50<01:46, 309.83 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16437/47780 [00:50<01:39, 316.36 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15011/47780 [00:50<01:46, 308.25 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15208/47780 [00:50<01:48, 301.35 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15390/47780 [00:50<01:40, 322.92 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14384/47780 [00:50<01:38, 340.25 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14431/47780 [00:50<01:44, 319.24 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14835/47780 [00:50<01:56, 281.86 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16470/47780 [00:50<01:42, 305.00 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15428/47780 [00:50<01:38, 328.17 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6023/47780 [00:50<02:05, 332.25 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15239/47780 [00:50<01:57, 277.80 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14429/47780 [00:50<01:29, 372.08 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15043/47780 [00:50<02:01, 269.10 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14464/47780 [00:50<01:50, 301.98 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14864/47780 [00:50<01:59, 274.99 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15467/47780 [00:50<01:33, 345.01 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16505/47780 [00:50<01:41, 308.58 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15268/47780 [00:50<01:58, 274.71 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14472/47780 [00:50<01:25, 389.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15082/47780 [00:50<01:49, 297.81 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14500/47780 [00:50<01:47, 311.01 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14899/47780 [00:50<01:56, 283.37 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16538/47780 [00:50<01:41, 306.92 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15502/47780 [00:50<01:40, 320.98 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15298/47780 [00:50<01:56, 278.94 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14514/47780 [00:50<01:23, 397.93 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15116/47780 [00:50<01:47, 302.65 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14532/47780 [00:50<01:51, 298.32 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14937/47780 [00:50<01:46, 309.36 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15336/47780 [00:50<01:45, 307.06 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14557/47780 [00:50<01:23, 398.41 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16569/47780 [00:50<01:50, 283.41 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15535/47780 [00:50<01:49, 294.96 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15148/47780 [00:50<01:52, 291.01 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14569/47780 [00:50<01:44, 316.60 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6151/47780 [00:50<02:05, 331.07 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14969/47780 [00:50<01:47, 305.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14597/47780 [00:50<01:23, 397.96 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16604/47780 [00:50<01:45, 295.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15368/47780 [00:50<01:51, 291.04 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15576/47780 [00:50<01:40, 321.61 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14602/47780 [00:50<01:43, 319.46 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15178/47780 [00:50<01:58, 275.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 15005/47780 [00:50<01:43, 317.21 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15407/47780 [00:50<01:42, 314.93 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14637/47780 [00:51<01:27, 376.73 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16634/47780 [00:50<01:48, 287.20 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15619/47780 [00:51<01:31, 350.65 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14635/47780 [00:50<01:44, 315.75 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15207/47780 [00:50<02:00, 271.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 15038/47780 [00:51<01:46, 306.60 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16675/47780 [00:51<01:37, 320.66 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15658/47780 [00:51<01:28, 361.49 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15439/47780 [00:51<01:49, 296.05 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14675/47780 [00:51<01:34, 350.17 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14667/47780 [00:51<01:46, 311.31 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15236/47780 [00:51<01:58, 273.77 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15077/47780 [00:51<01:40, 326.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6250/47780 [00:51<02:09, 319.67 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16709/47780 [00:51<01:35, 325.97 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15695/47780 [00:51<01:34, 340.59 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14699/47780 [00:51<01:45, 312.77 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14712/47780 [00:51<01:40, 329.92 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15470/47780 [00:51<01:59, 270.62 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15265/47780 [00:51<02:02, 266.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15111/47780 [00:51<01:41, 322.69 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16743/47780 [00:51<01:36, 322.78 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15733/47780 [00:51<01:33, 344.23 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14733/47780 [00:51<01:44, 316.90 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15307/47780 [00:51<01:46, 304.87 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15501/47780 [00:51<01:56, 277.95 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15146/47780 [00:51<01:39, 327.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14746/47780 [00:51<01:47, 306.81 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15768/47780 [00:51<01:32, 345.24 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16776/47780 [00:51<01:46, 291.59 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14765/47780 [00:51<01:48, 303.73 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15338/47780 [00:51<01:47, 302.91 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15533/47780 [00:51<01:56, 277.27 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15180/47780 [00:51<01:38, 330.80 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14779/47780 [00:51<01:45, 312.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6328/47780 [00:51<02:16, 304.69 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15803/47780 [00:51<01:34, 339.51 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16820/47780 [00:51<01:36, 320.81 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14799/47780 [00:51<01:46, 310.39 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15570/47780 [00:51<01:46, 302.07 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15370/47780 [00:51<01:50, 294.49 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15214/47780 [00:51<01:39, 325.93 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14811/47780 [00:51<01:50, 299.65 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15839/47780 [00:51<01:38, 325.78 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14834/47780 [00:51<01:43, 318.22 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16853/47780 [00:51<01:39, 311.76 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15403/47780 [00:51<01:46, 304.31 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15247/47780 [00:51<01:40, 323.37 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15601/47780 [00:51<01:50, 291.38 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6390/47780 [00:51<02:16, 303.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14850/47780 [00:51<01:43, 319.02 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15882/47780 [00:51<01:31, 347.93 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14868/47780 [00:51<01:44, 313.50 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15434/47780 [00:51<01:48, 299.11 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15633/47780 [00:51<01:47, 299.22 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16885/47780 [00:51<01:47, 287.14 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14884/47780 [00:51<01:42, 322.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15280/47780 [00:51<01:45, 307.21 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15919/47780 [00:51<01:32, 346.30 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14910/47780 [00:51<01:35, 343.45 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15666/47780 [00:51<01:44, 306.43 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15472/47780 [00:51<01:42, 314.78 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16923/47780 [00:51<01:40, 308.51 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14920/47780 [00:51<01:38, 332.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15311/47780 [00:51<01:47, 300.85 examples/s]
Tokenizing train dataset (num_proc=32):  13%|█▎        | 6443/47780 [00:51<02:22, 290.72 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15961/47780 [00:51<01:26, 366.67 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14946/47780 [00:51<01:35, 344.69 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15509/47780 [00:51<01:40, 319.77 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15697/47780 [00:51<01:50, 289.67 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14957/47780 [00:52<01:37, 335.34 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16956/47780 [00:51<01:40, 307.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15342/47780 [00:51<01:47, 300.74 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15998/47780 [00:52<01:27, 363.71 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14982/47780 [00:52<01:35, 345.14 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6487/47780 [00:52<02:25, 282.91 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15728/47780 [00:52<01:48, 294.81 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15542/47780 [00:52<01:42, 315.09 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14992/47780 [00:52<01:36, 338.65 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15373/47780 [00:52<01:48, 299.78 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16988/47780 [00:52<01:44, 294.69 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16038/47780 [00:52<01:25, 370.14 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15017/47780 [00:52<01:40, 327.51 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15576/47780 [00:52<01:42, 314.58 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15028/47780 [00:52<01:39, 330.40 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15404/47780 [00:52<01:49, 296.05 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17024/47780 [00:52<01:38, 312.35 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15758/47780 [00:52<01:55, 276.87 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6527/47780 [00:52<02:28, 277.76 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16076/47780 [00:52<01:26, 367.43 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15050/47780 [00:52<01:39, 327.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15618/47780 [00:52<01:34, 341.52 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15448/47780 [00:52<01:36, 333.43 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17058/47780 [00:52<01:36, 316.78 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15788/47780 [00:52<01:58, 269.02 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15062/47780 [00:52<01:46, 308.59 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▎        | 6562/47780 [00:52<02:28, 277.27 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16113/47780 [00:52<01:29, 353.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15085/47780 [00:52<01:39, 327.07 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15653/47780 [00:52<01:37, 328.83 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15487/47780 [00:52<01:34, 341.87 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17091/47780 [00:52<01:36, 316.68 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15098/47780 [00:52<01:41, 322.59 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15816/47780 [00:52<02:01, 263.19 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6596/47780 [00:52<02:23, 287.74 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15125/47780 [00:52<01:35, 340.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16149/47780 [00:52<01:33, 338.02 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15687/47780 [00:52<01:38, 324.64 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17123/47780 [00:52<01:39, 307.35 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15522/47780 [00:52<01:39, 325.29 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15132/47780 [00:52<01:41, 320.37 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15847/47780 [00:52<01:59, 267.40 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6629/47780 [00:52<02:23, 287.10 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15172/47780 [00:52<01:26, 377.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16187/47780 [00:52<01:31, 343.84 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15724/47780 [00:52<01:35, 337.32 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17156/47780 [00:52<01:37, 313.09 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15557/47780 [00:52<01:40, 321.67 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15166/47780 [00:52<01:42, 318.60 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15876/47780 [00:52<01:57, 270.63 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6662/47780 [00:52<02:20, 293.64 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16229/47780 [00:52<01:26, 365.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15212/47780 [00:52<01:26, 375.05 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17193/47780 [00:52<01:33, 326.43 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15758/47780 [00:52<01:40, 319.82 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15596/47780 [00:52<01:34, 340.51 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15200/47780 [00:52<01:40, 324.52 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15905/47780 [00:52<01:55, 275.88 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6699/47780 [00:52<02:14, 305.59 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15252/47780 [00:52<01:26, 377.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16267/47780 [00:52<01:29, 352.78 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17226/47780 [00:52<01:36, 316.52 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15238/47780 [00:52<01:35, 340.40 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15632/47780 [00:52<01:33, 342.42 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15938/47780 [00:52<01:50, 288.27 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15791/47780 [00:52<01:48, 295.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6732/47780 [00:52<02:22, 288.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15290/47780 [00:52<01:30, 357.80 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16303/47780 [00:52<01:32, 341.69 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15677/47780 [00:52<01:26, 373.23 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15278/47780 [00:52<01:32, 351.19 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15967/47780 [00:52<01:54, 279.00 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15832/47780 [00:52<01:37, 326.17 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17258/47780 [00:52<01:44, 291.94 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6766/47780 [00:52<02:16, 301.20 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16339/47780 [00:53<01:31, 345.02 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15327/47780 [00:53<01:31, 353.74 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15716/47780 [00:53<01:25, 373.42 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15314/47780 [00:53<01:33, 346.67 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15996/47780 [00:53<01:53, 279.17 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17292/47780 [00:53<01:41, 300.60 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15866/47780 [00:53<01:48, 294.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15363/47780 [00:53<01:31, 355.15 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6798/47780 [00:53<02:19, 293.97 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16374/47780 [00:53<01:37, 320.91 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15754/47780 [00:53<01:26, 371.02 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15356/47780 [00:53<01:29, 363.20 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16025/47780 [00:53<01:52, 282.15 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17323/47780 [00:53<01:41, 299.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15900/47780 [00:53<01:46, 300.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6834/47780 [00:53<02:11, 311.16 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15400/47780 [00:53<01:37, 332.59 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16407/47780 [00:53<01:39, 316.37 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16065/47780 [00:53<01:40, 316.09 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15792/47780 [00:53<01:30, 354.28 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17354/47780 [00:53<01:42, 296.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15393/47780 [00:53<01:38, 328.87 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15934/47780 [00:53<01:45, 301.33 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16441/47780 [00:53<01:37, 322.76 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6867/47780 [00:53<02:26, 279.93 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15434/47780 [00:53<01:44, 310.81 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15829/47780 [00:53<01:30, 353.29 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17394/47780 [00:53<01:34, 321.86 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15433/47780 [00:53<01:34, 341.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16097/47780 [00:53<01:50, 287.26 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15965/47780 [00:53<01:52, 282.27 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16474/47780 [00:53<01:37, 321.03 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15466/47780 [00:53<01:43, 313.21 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15866/47780 [00:53<01:29, 357.93 examples/s]
Tokenizing train dataset (num_proc=32):  14%|█▍        | 6905/47780 [00:53<02:16, 299.54 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17434/47780 [00:53<01:29, 340.18 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15472/47780 [00:53<01:34, 343.21 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16127/47780 [00:53<01:58, 267.26 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16507/47780 [00:53<01:40, 309.73 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15997/47780 [00:53<01:55, 275.00 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15903/47780 [00:53<01:29, 357.97 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15499/47780 [00:53<01:43, 311.02 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6937/47780 [00:53<02:18, 295.61 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17475/47780 [00:53<01:25, 356.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15507/47780 [00:53<01:36, 333.13 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16171/47780 [00:53<01:40, 313.04 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16025/47780 [00:53<01:54, 276.17 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16546/47780 [00:53<01:35, 328.60 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15531/47780 [00:53<01:42, 313.11 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 6969/47780 [00:53<02:15, 302.10 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15939/47780 [00:53<01:32, 342.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17516/47780 [00:53<01:22, 368.12 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15541/47780 [00:53<01:40, 321.29 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16205/47780 [00:53<01:47, 294.60 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16063/47780 [00:53<01:45, 301.17 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16584/47780 [00:53<01:31, 339.28 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7001/47780 [00:53<02:12, 307.00 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15563/47780 [00:53<01:44, 307.88 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17553/47780 [00:53<01:23, 363.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15974/47780 [00:53<01:34, 336.80 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15574/47780 [00:53<01:50, 292.08 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16619/47780 [00:53<01:31, 341.99 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▍        | 7044/47780 [00:53<01:59, 341.73 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16236/47780 [00:53<01:52, 280.47 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16094/47780 [00:53<01:47, 295.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15598/47780 [00:53<01:43, 311.94 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16008/47780 [00:53<01:46, 297.53 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17590/47780 [00:53<01:34, 320.90 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15610/47780 [00:54<01:44, 309.31 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16271/47780 [00:54<01:46, 295.91 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15630/47780 [00:54<01:43, 312.09 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16124/47780 [00:54<01:50, 285.58 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16655/47780 [00:54<01:37, 320.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7079/47780 [00:53<02:07, 318.27 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16061/47780 [00:54<01:28, 358.62 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17625/47780 [00:54<01:32, 325.11 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15642/47780 [00:54<01:45, 305.96 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16304/47780 [00:54<01:44, 301.85 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15662/47780 [00:54<01:43, 310.80 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16688/47780 [00:54<01:39, 313.82 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16153/47780 [00:54<01:56, 271.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7112/47780 [00:54<02:11, 308.15 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17667/47780 [00:54<01:26, 347.35 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16099/47780 [00:54<01:31, 345.57 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16343/47780 [00:54<01:37, 322.74 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15700/47780 [00:54<01:39, 323.24 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16734/47780 [00:54<01:27, 354.22 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15674/47780 [00:54<01:52, 284.69 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16186/47780 [00:54<01:52, 281.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7144/47780 [00:54<02:14, 301.53 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16137/47780 [00:54<01:29, 354.74 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17703/47780 [00:54<01:31, 328.83 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16376/47780 [00:54<01:41, 310.46 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15704/47780 [00:54<01:52, 285.92 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15734/47780 [00:54<01:41, 317.16 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16770/47780 [00:54<01:33, 332.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16215/47780 [00:54<01:55, 272.22 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7175/47780 [00:54<02:25, 279.25 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17738/47780 [00:54<01:30, 330.69 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16174/47780 [00:54<01:36, 328.83 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16408/47780 [00:54<01:41, 309.25 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15752/47780 [00:54<01:35, 335.29 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15767/47780 [00:54<01:41, 316.79 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16247/47780 [00:54<01:50, 284.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16804/47780 [00:54<01:34, 327.95 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7213/47780 [00:54<02:12, 305.85 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17781/47780 [00:54<01:25, 352.45 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16208/47780 [00:54<01:35, 329.02 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16449/47780 [00:54<01:34, 333.04 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15800/47780 [00:54<01:40, 317.37 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15787/47780 [00:54<01:36, 331.63 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16283/47780 [00:54<01:44, 302.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16846/47780 [00:54<01:27, 353.21 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7245/47780 [00:54<02:19, 290.59 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16488/47780 [00:54<01:30, 346.95 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17817/47780 [00:54<01:33, 320.49 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15841/47780 [00:54<01:33, 340.15 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16242/47780 [00:54<01:43, 305.10 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15826/47780 [00:54<01:31, 347.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16319/47780 [00:54<01:38, 318.62 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16882/47780 [00:54<01:30, 339.65 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7277/47780 [00:54<02:15, 298.02 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16530/47780 [00:54<01:24, 367.71 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15862/47780 [00:54<01:32, 343.96 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15876/47780 [00:54<01:35, 334.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17850/47780 [00:54<01:36, 309.52 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16274/47780 [00:54<01:50, 285.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16352/47780 [00:54<01:42, 307.86 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16917/47780 [00:54<01:32, 335.41 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7308/47780 [00:54<02:21, 285.57 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16572/47780 [00:54<01:22, 378.18 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15899/47780 [00:54<01:30, 350.46 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15910/47780 [00:54<01:35, 332.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17884/47780 [00:54<01:38, 301.99 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16310/47780 [00:54<01:44, 301.49 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16954/47780 [00:54<01:30, 341.35 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16384/47780 [00:54<01:45, 297.11 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7340/47780 [00:54<02:19, 289.35 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15936/47780 [00:55<01:31, 348.61 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17919/47780 [00:54<01:35, 311.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16610/47780 [00:54<01:30, 343.03 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15944/47780 [00:54<01:41, 312.56 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16344/47780 [00:54<01:41, 308.41 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16992/47780 [00:55<01:27, 352.33 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16425/47780 [00:54<01:36, 325.91 examples/s]
Tokenizing train dataset (num_proc=32):  15%|█▌        | 7375/47780 [00:55<02:12, 306.03 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15977/47780 [00:55<01:28, 358.46 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16650/47780 [00:55<01:27, 355.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17954/47780 [00:55<01:33, 318.50 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16387/47780 [00:55<01:32, 337.99 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17032/47780 [00:55<01:24, 365.86 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16458/47780 [00:55<01:35, 326.63 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15976/47780 [00:55<01:49, 289.29 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7407/47780 [00:55<02:10, 309.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16022/47780 [00:55<01:22, 384.65 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17069/47780 [00:55<01:23, 366.75 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16422/47780 [00:55<01:32, 337.33 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17988/47780 [00:55<01:35, 310.68 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16493/47780 [00:55<01:35, 326.23 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16689/47780 [00:55<01:34, 327.71 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16014/47780 [00:55<01:44, 304.13 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7439/47780 [00:55<02:13, 302.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16069/47780 [00:55<01:17, 409.44 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16469/47780 [00:55<01:23, 374.81 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18027/47780 [00:55<01:29, 332.56 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16528/47780 [00:55<01:34, 329.26 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17106/47780 [00:55<01:30, 337.86 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16045/47780 [00:55<01:45, 301.96 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16724/47780 [00:55<01:37, 317.29 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7471/47780 [00:55<02:14, 300.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16111/47780 [00:55<01:19, 397.67 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18061/47780 [00:55<01:29, 330.43 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16507/47780 [00:55<01:25, 364.19 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16562/47780 [00:55<01:35, 327.53 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17143/47780 [00:55<01:29, 341.65 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16076/47780 [00:55<01:47, 294.59 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7508/47780 [00:55<02:07, 316.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16757/47780 [00:55<01:45, 295.37 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16151/47780 [00:55<01:23, 377.38 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18095/47780 [00:55<01:31, 324.17 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16544/47780 [00:55<01:30, 346.11 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16604/47780 [00:55<01:30, 343.22 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17183/47780 [00:55<01:25, 357.79 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16108/47780 [00:55<01:46, 298.66 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7540/47780 [00:55<02:08, 314.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16788/47780 [00:55<01:47, 287.43 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16190/47780 [00:55<01:26, 364.62 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17220/47780 [00:55<01:24, 360.98 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18129/47780 [00:55<01:34, 314.92 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16580/47780 [00:55<01:30, 345.97 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16639/47780 [00:55<01:32, 337.69 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16138/47780 [00:55<01:45, 298.65 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7577/47780 [00:55<02:01, 330.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16819/47780 [00:55<01:46, 290.52 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16227/47780 [00:55<01:28, 355.88 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17258/47780 [00:55<01:24, 363.05 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16673/47780 [00:55<01:32, 337.94 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16615/47780 [00:55<01:33, 332.25 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16176/47780 [00:55<01:39, 318.62 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18162/47780 [00:55<01:38, 299.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7613/47780 [00:55<01:58, 338.52 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16849/47780 [00:55<01:54, 269.84 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16655/47780 [00:55<01:28, 350.87 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17295/47780 [00:55<01:28, 344.93 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16707/47780 [00:55<01:36, 323.21 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16263/47780 [00:55<01:36, 326.50 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18193/47780 [00:55<01:40, 293.43 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16208/47780 [00:55<01:42, 307.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7650/47780 [00:55<01:57, 341.80 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16884/47780 [00:55<01:46, 290.75 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16691/47780 [00:55<01:29, 346.01 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16740/47780 [00:55<01:36, 322.23 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17331/47780 [00:56<01:30, 338.15 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18232/47780 [00:55<01:33, 316.76 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16307/47780 [00:56<01:29, 353.00 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▌        | 7685/47780 [00:55<02:02, 327.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16239/47780 [00:55<01:50, 285.78 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16918/47780 [00:56<01:42, 300.50 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16736/47780 [00:56<01:22, 375.50 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18265/47780 [00:56<01:32, 320.09 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16345/47780 [00:56<01:28, 356.49 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16773/47780 [00:56<01:39, 310.22 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17366/47780 [00:56<01:32, 329.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16274/47780 [00:56<01:44, 300.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7718/47780 [00:56<02:10, 307.15 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16950/47780 [00:56<01:40, 305.87 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16774/47780 [00:56<01:22, 376.56 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18307/47780 [00:56<01:25, 345.09 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17408/47780 [00:56<01:26, 351.27 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16806/47780 [00:56<01:44, 295.61 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16382/47780 [00:56<01:34, 330.55 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16305/47780 [00:56<01:48, 290.01 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7750/47780 [00:56<02:08, 310.35 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16983/47780 [00:56<01:39, 309.77 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16821/47780 [00:56<01:17, 401.71 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18342/47780 [00:56<01:26, 338.67 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17444/47780 [00:56<01:29, 337.65 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16842/47780 [00:56<01:40, 306.78 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16416/47780 [00:56<01:38, 319.98 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7783/47780 [00:56<02:07, 313.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16337/47780 [00:56<01:48, 288.98 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17018/47780 [00:56<01:38, 311.44 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16862/47780 [00:56<01:22, 375.16 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17479/47780 [00:56<01:29, 338.82 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16877/47780 [00:56<01:37, 318.44 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18377/47780 [00:56<01:34, 309.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16463/47780 [00:56<01:27, 359.85 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16368/47780 [00:56<01:46, 294.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7818/47780 [00:56<02:06, 315.99 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17050/47780 [00:56<01:42, 299.24 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17514/47780 [00:56<01:31, 329.89 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16900/47780 [00:56<01:28, 349.15 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16910/47780 [00:56<01:39, 311.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16500/47780 [00:56<01:27, 358.03 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7851/47780 [00:56<02:07, 313.66 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18409/47780 [00:56<01:41, 290.46 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16398/47780 [00:56<01:52, 279.86 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17082/47780 [00:56<01:41, 301.72 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16938/47780 [00:56<01:26, 357.39 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16948/47780 [00:56<01:33, 330.48 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17554/47780 [00:56<01:28, 342.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16538/47780 [00:56<01:26, 360.83 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18441/47780 [00:56<01:39, 295.32 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16429/47780 [00:56<01:50, 282.49 examples/s]
Tokenizing train dataset (num_proc=32):  16%|█▋        | 7883/47780 [00:56<02:13, 299.51 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17121/47780 [00:56<01:34, 323.14 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16975/47780 [00:56<01:26, 357.39 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 16982/47780 [00:56<01:35, 321.54 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16579/47780 [00:56<01:25, 366.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17589/47780 [00:56<01:31, 329.53 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7921/47780 [00:56<02:06, 315.98 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18471/47780 [00:56<01:43, 283.81 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16459/47780 [00:56<01:56, 269.31 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17154/47780 [00:56<01:37, 313.30 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17012/47780 [00:56<01:27, 351.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17015/47780 [00:56<01:37, 316.55 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17626/47780 [00:56<01:29, 337.45 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16616/47780 [00:56<01:25, 363.32 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18500/47780 [00:56<01:46, 274.08 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16489/47780 [00:56<01:54, 273.37 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17189/47780 [00:56<01:35, 321.14 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7954/47780 [00:56<02:14, 296.96 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17048/47780 [00:56<01:27, 350.64 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16654/47780 [00:56<01:24, 368.09 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17049/47780 [00:56<01:35, 320.62 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17660/47780 [00:57<01:36, 313.16 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18528/47780 [00:56<01:46, 273.93 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17223/47780 [00:56<01:33, 326.49 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 7997/47780 [00:56<02:00, 329.59 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16518/47780 [00:56<01:56, 268.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17089/47780 [00:57<01:29, 341.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17085/47780 [00:57<01:30, 339.65 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16692/47780 [00:57<01:26, 359.07 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17697/47780 [00:57<01:31, 328.52 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18556/47780 [00:57<01:46, 274.27 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17256/47780 [00:57<01:33, 326.86 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8031/47780 [00:57<02:04, 318.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16546/47780 [00:57<02:00, 259.09 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17127/47780 [00:57<01:28, 346.44 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17125/47780 [00:57<01:27, 350.65 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16729/47780 [00:57<01:31, 338.93 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18603/47780 [00:57<01:31, 318.89 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17292/47780 [00:57<01:33, 325.88 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17731/47780 [00:57<01:38, 303.71 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16581/47780 [00:57<01:51, 280.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8064/47780 [00:57<02:13, 298.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17172/47780 [00:57<01:21, 376.31 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17161/47780 [00:57<01:34, 322.92 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16764/47780 [00:57<01:35, 323.71 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18643/47780 [00:57<01:26, 337.91 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17333/47780 [00:57<01:28, 345.63 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17767/47780 [00:57<01:35, 312.76 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16610/47780 [00:57<01:49, 283.47 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8095/47780 [00:57<02:13, 298.11 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17210/47780 [00:57<01:25, 358.18 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17208/47780 [00:57<01:24, 359.97 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18682/47780 [00:57<01:23, 348.81 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16797/47780 [00:57<01:37, 318.40 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17799/47780 [00:57<01:36, 311.48 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17370/47780 [00:57<01:29, 338.17 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16643/47780 [00:57<01:47, 290.01 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17252/47780 [00:57<01:21, 373.91 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8126/47780 [00:57<02:22, 278.72 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17246/47780 [00:57<01:26, 353.55 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17838/47780 [00:57<01:29, 333.30 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16830/47780 [00:57<01:40, 308.09 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17406/47780 [00:57<01:29, 339.78 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18718/47780 [00:57<01:28, 329.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16673/47780 [00:57<01:51, 279.80 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17290/47780 [00:57<01:24, 359.20 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8155/47780 [00:57<02:30, 263.44 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17282/47780 [00:57<01:27, 347.84 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17872/47780 [00:57<01:29, 334.73 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16865/47780 [00:57<01:36, 319.45 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18756/47780 [00:57<01:24, 343.34 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17445/47780 [00:57<01:28, 342.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16704/47780 [00:57<01:48, 285.46 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8182/47780 [00:57<02:30, 262.54 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17907/47780 [00:57<01:28, 335.83 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17327/47780 [00:57<01:32, 328.92 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17318/47780 [00:57<01:30, 336.04 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18795/47780 [00:57<01:21, 356.51 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16898/47780 [00:57<01:37, 315.59 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16733/47780 [00:57<01:48, 286.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17486/47780 [00:57<01:28, 342.13 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8212/47780 [00:57<02:25, 272.59 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17367/47780 [00:57<01:28, 344.24 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18831/47780 [00:57<01:21, 357.31 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17941/47780 [00:57<01:31, 325.37 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16938/47780 [00:57<01:33, 331.42 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17524/47780 [00:57<01:25, 352.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16762/47780 [00:57<01:52, 275.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17352/47780 [00:57<01:41, 300.37 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8240/47780 [00:57<02:27, 267.46 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17974/47780 [00:57<01:31, 326.44 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17402/47780 [00:57<01:30, 334.69 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18870/47780 [00:57<01:21, 353.84 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16972/47780 [00:57<01:34, 326.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16792/47780 [00:57<01:49, 281.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17385/47780 [00:57<01:39, 305.28 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17560/47780 [00:57<01:31, 328.74 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8267/47780 [00:57<02:33, 257.56 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18007/47780 [00:58<01:32, 320.25 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18912/47780 [00:58<01:19, 365.37 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17005/47780 [00:58<01:35, 320.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17436/47780 [00:58<01:34, 321.82 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17417/47780 [00:58<01:41, 299.48 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16821/47780 [00:58<01:57, 263.15 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17594/47780 [00:58<01:32, 327.86 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8296/47780 [00:58<02:31, 261.10 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18041/47780 [00:58<01:31, 325.89 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18952/47780 [00:58<01:17, 372.47 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17039/47780 [00:58<01:34, 326.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17472/47780 [00:58<01:31, 330.22 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17454/47780 [00:58<01:36, 315.37 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16853/47780 [00:58<01:52, 275.72 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17628/47780 [00:58<01:37, 308.50 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8324/47780 [00:58<02:29, 263.43 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18074/47780 [00:58<01:34, 312.90 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17075/47780 [00:58<01:32, 332.29 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17509/47780 [00:58<01:29, 339.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18990/47780 [00:58<01:18, 368.48 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16884/47780 [00:58<01:48, 285.31 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17486/47780 [00:58<01:37, 309.45 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17660/47780 [00:58<01:40, 300.83 examples/s]
Tokenizing train dataset (num_proc=32):  17%|█▋        | 8351/47780 [00:58<02:28, 265.28 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18107/47780 [00:58<01:34, 314.17 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17549/47780 [00:58<01:24, 356.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17111/47780 [00:58<01:33, 328.89 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16917/47780 [00:58<01:43, 298.05 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17524/47780 [00:58<01:32, 325.83 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19027/47780 [00:58<01:27, 327.67 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8380/47780 [00:58<02:26, 269.34 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17691/47780 [00:58<01:47, 279.08 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17585/47780 [00:58<01:25, 353.65 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17151/47780 [00:58<01:28, 345.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18140/47780 [00:58<01:38, 301.19 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19061/47780 [00:58<01:27, 329.53 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16951/47780 [00:58<01:42, 299.68 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17559/47780 [00:58<01:34, 318.24 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8416/47780 [00:58<02:13, 295.44 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17188/47780 [00:58<01:26, 352.35 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17622/47780 [00:58<01:28, 342.52 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18172/47780 [00:58<01:37, 303.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17720/47780 [00:58<01:52, 267.79 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16998/47780 [00:58<01:30, 340.54 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17596/47780 [00:58<01:31, 329.12 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19095/47780 [00:58<01:30, 316.13 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18205/47780 [00:58<01:35, 310.83 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17224/47780 [00:58<01:28, 345.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8447/47780 [00:58<02:28, 265.64 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17756/47780 [00:58<01:47, 280.31 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17657/47780 [00:58<01:33, 322.94 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17038/47780 [00:58<01:26, 353.69 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17630/47780 [00:58<01:30, 331.96 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19128/47780 [00:58<01:29, 319.90 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18247/47780 [00:58<01:27, 338.41 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8482/47780 [00:58<02:19, 282.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17788/47780 [00:58<01:44, 287.89 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17690/47780 [00:58<01:33, 321.36 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17259/47780 [00:58<01:33, 324.89 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17669/47780 [00:58<01:27, 344.78 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17074/47780 [00:58<01:30, 339.72 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19164/47780 [00:58<01:33, 307.07 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18285/47780 [00:58<01:26, 342.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8511/47780 [00:58<02:19, 281.41 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17295/47780 [00:58<01:32, 330.90 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17723/47780 [00:58<01:34, 317.48 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17818/47780 [00:58<01:47, 279.02 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17704/47780 [00:58<01:28, 338.56 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17117/47780 [00:58<01:24, 364.96 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19199/47780 [00:58<01:30, 315.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18320/47780 [00:59<01:26, 340.28 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8540/47780 [00:58<02:22, 274.69 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17331/47780 [00:59<01:29, 339.05 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17755/47780 [00:59<01:34, 317.16 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17847/47780 [00:59<01:49, 273.06 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17157/47780 [00:59<01:22, 371.05 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17740/47780 [00:59<01:29, 336.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19231/47780 [00:59<01:36, 296.21 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8578/47780 [00:59<02:10, 300.49 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18355/47780 [00:59<01:30, 324.01 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17787/47780 [00:59<01:38, 303.80 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17366/47780 [00:59<01:34, 320.57 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17875/47780 [00:59<01:51, 269.06 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17775/47780 [00:59<01:29, 336.92 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17195/47780 [00:59<01:23, 365.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19261/47780 [00:59<01:42, 279.55 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18388/47780 [00:59<01:32, 319.40 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17401/47780 [00:59<01:32, 328.63 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17809/47780 [00:59<01:28, 337.69 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17239/47780 [00:59<01:19, 386.58 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17818/47780 [00:59<01:42, 291.62 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8609/47780 [00:59<02:22, 275.22 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17902/47780 [00:59<01:55, 257.86 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19291/47780 [00:59<01:40, 284.37 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17435/47780 [00:59<01:33, 324.41 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18421/47780 [00:59<01:36, 305.11 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17850/47780 [00:59<01:40, 297.87 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17844/47780 [00:59<01:28, 337.35 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17282/47780 [00:59<01:18, 390.19 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8651/47780 [00:59<02:05, 310.67 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17938/47780 [00:59<01:46, 279.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19320/47780 [00:59<01:42, 277.92 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17468/47780 [00:59<01:34, 321.92 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17880/47780 [00:59<01:27, 339.95 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17323/47780 [00:59<01:17, 391.41 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18452/47780 [00:59<01:38, 296.38 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8683/47780 [00:59<02:06, 309.52 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17882/47780 [00:59<01:44, 287.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17967/47780 [00:59<01:49, 273.44 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19348/47780 [00:59<01:46, 266.43 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17502/47780 [00:59<01:34, 320.32 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18485/47780 [00:59<01:36, 302.63 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8717/47780 [00:59<02:06, 308.04 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17915/47780 [00:59<01:31, 327.42 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17912/47780 [00:59<01:43, 287.78 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17996/47780 [00:59<01:49, 272.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17365/47780 [00:59<01:22, 369.37 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19379/47780 [00:59<01:43, 275.51 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17542/47780 [00:59<01:29, 338.31 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18517/47780 [00:59<01:35, 307.43 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17945/47780 [00:59<01:39, 299.62 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17953/47780 [00:59<01:29, 335.02 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8749/47780 [00:59<02:09, 301.36 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18024/47780 [00:59<01:49, 270.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17412/47780 [00:59<01:18, 388.91 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19407/47780 [00:59<01:50, 256.22 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18553/47780 [00:59<01:31, 318.76 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17576/47780 [00:59<01:34, 318.38 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17987/47780 [00:59<01:29, 332.15 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17976/47780 [00:59<01:41, 294.46 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18056/47780 [00:59<01:45, 282.11 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8780/47780 [00:59<02:17, 283.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17452/47780 [00:59<01:22, 369.77 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19438/47780 [00:59<01:45, 267.50 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18585/47780 [00:59<01:33, 312.11 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18024/47780 [00:59<01:27, 339.71 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17619/47780 [00:59<01:28, 341.68 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18092/47780 [00:59<01:37, 304.32 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18014/47780 [00:59<01:35, 313.01 examples/s]
Tokenizing train dataset (num_proc=32):  18%|█▊        | 8810/47780 [00:59<02:23, 271.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17493/47780 [00:59<01:22, 366.31 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19472/47780 [00:59<01:41, 279.12 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18617/47780 [01:00<01:34, 307.26 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18059/47780 [00:59<01:26, 342.64 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18126/47780 [00:59<01:35, 311.05 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18048/47780 [00:59<01:34, 315.53 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17654/47780 [01:00<01:29, 336.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8851/47780 [01:00<02:08, 302.20 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17530/47780 [01:00<01:26, 348.26 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18100/47780 [01:00<01:22, 361.86 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19513/47780 [01:00<01:33, 303.75 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18648/47780 [01:00<01:37, 297.96 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18158/47780 [01:00<01:36, 306.57 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17694/47780 [01:00<01:25, 350.01 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18080/47780 [01:00<01:41, 291.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8884/47780 [01:00<02:05, 309.51 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17573/47780 [01:00<01:25, 355.12 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19553/47780 [01:00<01:25, 328.29 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18678/47780 [01:00<01:37, 298.41 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18138/47780 [01:00<01:23, 355.15 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17735/47780 [01:00<01:22, 362.97 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18189/47780 [01:00<01:39, 297.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18114/47780 [01:00<01:37, 304.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8921/47780 [01:00<02:00, 322.95 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17609/47780 [01:00<01:28, 341.13 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18709/47780 [01:00<01:36, 301.53 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18176/47780 [01:00<01:21, 362.13 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19587/47780 [01:00<01:26, 327.63 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18222/47780 [01:00<01:37, 303.06 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17772/47780 [01:00<01:26, 348.67 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18151/47780 [01:00<01:34, 312.77 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▊        | 8954/47780 [01:00<02:10, 298.07 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17644/47780 [01:00<01:28, 340.08 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18743/47780 [01:00<01:34, 305.71 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19630/47780 [01:00<01:21, 345.74 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18213/47780 [01:00<01:25, 344.51 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18258/47780 [01:00<01:33, 315.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17808/47780 [01:00<01:27, 344.34 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18183/47780 [01:00<01:40, 294.93 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 8988/47780 [01:00<02:05, 309.29 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17681/47780 [01:00<01:27, 344.89 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18776/47780 [01:00<01:33, 309.32 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18253/47780 [01:00<01:21, 360.14 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18290/47780 [01:00<01:35, 309.53 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19665/47780 [01:00<01:26, 324.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17843/47780 [01:00<01:30, 330.54 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18213/47780 [01:00<01:39, 296.29 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9020/47780 [01:00<02:12, 292.36 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17726/47780 [01:00<01:22, 362.26 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18809/47780 [01:00<01:37, 297.69 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18290/47780 [01:00<01:24, 350.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18322/47780 [01:00<01:39, 295.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19698/47780 [01:00<01:31, 308.35 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17877/47780 [01:00<01:37, 306.40 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18243/47780 [01:00<01:48, 272.84 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17764/47780 [01:00<01:21, 367.10 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9053/47780 [01:00<02:11, 293.57 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18333/47780 [01:00<01:19, 369.18 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18839/47780 [01:00<01:39, 291.99 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18352/47780 [01:00<01:40, 293.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19730/47780 [01:00<01:30, 311.04 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17930/47780 [01:00<01:22, 362.47 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18277/47780 [01:00<01:42, 287.81 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17801/47780 [01:00<01:21, 367.34 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9086/47780 [01:00<02:07, 303.35 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18872/47780 [01:00<01:36, 299.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18372/47780 [01:00<01:19, 370.78 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19762/47780 [01:00<01:34, 294.98 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17968/47780 [01:00<01:22, 359.34 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18382/47780 [01:00<01:49, 268.18 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18307/47780 [01:00<01:44, 281.19 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17838/47780 [01:00<01:26, 344.80 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9117/47780 [01:00<02:13, 288.80 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18913/47780 [01:00<01:28, 327.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18411/47780 [01:00<01:19, 367.87 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19792/47780 [01:00<01:34, 295.95 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18422/47780 [01:00<01:37, 300.36 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18005/47780 [01:01<01:25, 346.93 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18336/47780 [01:01<01:48, 272.32 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9149/47780 [01:01<02:11, 294.27 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18946/47780 [01:01<01:27, 328.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17873/47780 [01:01<01:30, 331.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18448/47780 [01:01<01:24, 348.03 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19822/47780 [01:01<01:35, 294.22 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18454/47780 [01:01<01:39, 296.01 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18041/47780 [01:01<01:26, 343.00 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18372/47780 [01:01<01:41, 289.99 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9181/47780 [01:01<02:08, 301.30 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17907/47780 [01:01<01:29, 333.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18984/47780 [01:01<01:25, 335.35 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18484/47780 [01:01<01:27, 333.21 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19852/47780 [01:01<01:37, 285.79 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18492/47780 [01:01<01:32, 315.61 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18076/47780 [01:01<01:28, 336.95 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18402/47780 [01:01<01:41, 289.53 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17942/47780 [01:01<01:29, 334.27 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19025/47780 [01:01<01:20, 356.67 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9212/47780 [01:01<02:17, 281.31 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18519/47780 [01:01<01:29, 328.72 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19883/47780 [01:01<01:37, 286.33 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18118/47780 [01:01<01:23, 356.58 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18524/47780 [01:01<01:38, 297.00 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17979/47780 [01:01<01:27, 341.20 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19069/47780 [01:01<01:16, 376.91 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9245/47780 [01:01<02:13, 289.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18432/47780 [01:01<01:50, 265.43 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18555/47780 [01:01<01:27, 335.53 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19916/47780 [01:01<01:33, 296.60 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18154/47780 [01:01<01:24, 351.30 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18019/47780 [01:01<01:23, 357.87 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19119/47780 [01:01<01:09, 412.81 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18555/47780 [01:01<01:43, 282.30 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9278/47780 [01:01<02:08, 299.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18460/47780 [01:01<01:48, 269.31 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18593/47780 [01:01<01:24, 344.26 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19952/47780 [01:01<01:28, 313.49 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18190/47780 [01:01<01:25, 344.32 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19161/47780 [01:01<01:09, 410.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18055/47780 [01:01<01:27, 338.63 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18488/47780 [01:01<01:49, 266.40 examples/s]
Tokenizing train dataset (num_proc=32):  19%|█▉        | 9309/47780 [01:01<02:13, 289.03 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18584/47780 [01:01<01:51, 261.50 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18633/47780 [01:01<01:24, 344.58 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19984/47780 [01:01<01:39, 279.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18228/47780 [01:01<01:25, 346.58 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18517/47780 [01:01<01:47, 272.86 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18090/47780 [01:01<01:29, 330.59 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19203/47780 [01:01<01:14, 381.36 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9339/47780 [01:01<02:12, 290.76 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18619/47780 [01:01<01:44, 278.87 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18671/47780 [01:01<01:22, 354.02 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20015/47780 [01:01<01:36, 287.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18263/47780 [01:01<01:28, 332.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18551/47780 [01:01<01:41, 288.65 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9371/47780 [01:01<02:09, 297.65 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18124/47780 [01:01<01:30, 326.39 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18654/47780 [01:01<01:37, 297.78 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18712/47780 [01:01<01:20, 362.88 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20052/47780 [01:01<01:30, 307.15 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19242/47780 [01:01<01:32, 308.36 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18299/47780 [01:01<01:29, 329.14 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18586/47780 [01:01<01:37, 299.15 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18686/47780 [01:01<01:36, 300.79 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18157/47780 [01:01<01:33, 316.00 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9402/47780 [01:01<02:20, 272.87 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18760/47780 [01:01<01:14, 391.15 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20087/47780 [01:01<01:29, 308.74 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19297/47780 [01:02<01:17, 366.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18333/47780 [01:02<01:29, 328.57 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18717/47780 [01:02<01:37, 296.58 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18617/47780 [01:01<01:40, 289.29 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18189/47780 [01:02<01:38, 301.03 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9430/47780 [01:02<02:24, 265.99 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18800/47780 [01:02<01:17, 376.27 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20120/47780 [01:02<01:28, 311.36 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18370/47780 [01:02<01:29, 329.12 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19337/47780 [01:02<01:20, 353.17 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18659/47780 [01:02<01:29, 326.01 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18223/47780 [01:02<01:34, 311.63 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18747/47780 [01:02<01:41, 287.37 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18838/47780 [01:02<01:20, 361.12 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9457/47780 [01:02<02:34, 248.29 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20152/47780 [01:02<01:29, 310.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18414/47780 [01:02<01:21, 360.23 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18694/47780 [01:02<01:27, 330.82 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19375/47780 [01:02<01:22, 346.03 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18260/47780 [01:02<01:30, 324.44 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18776/47780 [01:02<01:52, 256.98 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9488/47780 [01:02<02:27, 259.16 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20192/47780 [01:02<01:23, 328.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18875/47780 [01:02<01:26, 333.84 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18451/47780 [01:02<01:28, 332.68 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19412/47780 [01:02<01:27, 325.43 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18293/47780 [01:02<01:35, 308.01 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18728/47780 [01:02<01:36, 300.87 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18803/47780 [01:02<01:54, 252.31 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20240/47780 [01:02<01:14, 367.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9515/47780 [01:02<02:32, 251.22 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18911/47780 [01:02<01:30, 320.36 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18491/47780 [01:02<01:23, 350.03 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18334/47780 [01:02<01:29, 329.48 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18768/47780 [01:02<01:30, 320.79 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19446/47780 [01:02<01:30, 312.82 examples/s]
Tokenizing train dataset (num_proc=32):  20%|█▉        | 9549/47780 [01:02<02:18, 275.25 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18829/47780 [01:02<01:58, 244.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20277/47780 [01:02<01:19, 344.26 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18527/47780 [01:02<01:25, 342.22 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18944/47780 [01:02<01:35, 300.42 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18372/47780 [01:02<01:25, 343.10 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18801/47780 [01:02<01:32, 312.72 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19484/47780 [01:02<01:27, 323.73 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9580/47780 [01:02<02:14, 284.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18858/47780 [01:02<01:56, 248.38 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20312/47780 [01:02<01:23, 327.88 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18976/47780 [01:02<01:35, 302.56 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18562/47780 [01:02<01:28, 329.62 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18407/47780 [01:02<01:27, 333.91 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19518/47780 [01:02<01:27, 324.15 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18835/47780 [01:02<01:33, 310.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9610/47780 [01:02<02:13, 286.07 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18884/47780 [01:02<01:59, 241.04 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20346/47780 [01:02<01:24, 325.52 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19007/47780 [01:02<01:39, 288.96 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18445/47780 [01:02<01:25, 342.99 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18596/47780 [01:02<01:32, 314.82 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19555/47780 [01:02<01:24, 333.34 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9642/47780 [01:02<02:08, 295.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18869/47780 [01:02<01:34, 306.86 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18915/47780 [01:02<01:52, 256.42 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20379/47780 [01:02<01:24, 324.82 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18628/47780 [01:02<01:33, 313.14 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19037/47780 [01:02<01:40, 285.56 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19593/47780 [01:02<01:21, 346.23 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18480/47780 [01:02<01:30, 322.82 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18910/47780 [01:02<01:26, 333.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9672/47780 [01:02<02:11, 290.28 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18941/47780 [01:02<01:53, 254.95 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20413/47780 [01:02<01:23, 326.00 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19067/47780 [01:02<01:41, 283.62 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19633/47780 [01:03<01:18, 357.66 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18660/47780 [01:03<01:37, 298.47 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18524/47780 [01:02<01:24, 348.04 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9710/47780 [01:02<02:01, 314.16 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18944/47780 [01:03<01:33, 307.40 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18974/47780 [01:03<01:45, 273.05 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20451/47780 [01:03<01:20, 341.37 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19104/47780 [01:03<01:33, 307.15 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19670/47780 [01:03<01:22, 341.36 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9749/47780 [01:03<01:55, 330.70 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18693/47780 [01:03<01:39, 291.18 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18560/47780 [01:03<01:28, 329.70 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18980/47780 [01:03<01:29, 321.50 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19005/47780 [01:03<01:41, 283.46 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20486/47780 [01:03<01:26, 314.23 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19135/47780 [01:03<01:33, 307.76 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19706/47780 [01:03<01:21, 343.03 examples/s]
Tokenizing train dataset (num_proc=32):  20%|██        | 9793/47780 [01:03<01:46, 358.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18723/47780 [01:03<01:38, 293.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18596/47780 [01:03<01:26, 337.41 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19016/47780 [01:03<01:27, 328.69 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20518/47780 [01:03<01:26, 314.62 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19034/47780 [01:03<01:53, 253.41 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19173/47780 [01:03<01:27, 325.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19742/47780 [01:03<01:21, 342.58 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19050/47780 [01:03<01:28, 325.22 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9830/47780 [01:03<01:53, 334.55 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18753/47780 [01:03<01:46, 272.05 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18631/47780 [01:03<01:35, 306.63 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19061/47780 [01:03<01:52, 255.12 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20559/47780 [01:03<01:21, 335.60 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19209/47780 [01:03<01:25, 335.21 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19781/47780 [01:03<01:19, 353.64 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9865/47780 [01:03<01:53, 332.72 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18781/47780 [01:03<01:46, 273.13 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19083/47780 [01:03<01:32, 311.50 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18663/47780 [01:03<01:37, 297.65 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20594/47780 [01:03<01:20, 335.86 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19088/47780 [01:03<01:51, 256.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19245/47780 [01:03<01:25, 334.70 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18814/47780 [01:03<01:41, 285.86 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19817/47780 [01:03<01:26, 321.96 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9899/47780 [01:03<01:58, 319.13 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19116/47780 [01:03<01:34, 303.34 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18696/47780 [01:03<01:36, 302.85 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19119/47780 [01:03<01:46, 268.33 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20628/47780 [01:03<01:26, 312.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19280/47780 [01:03<01:27, 323.88 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18845/47780 [01:03<01:38, 292.61 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19854/47780 [01:03<01:24, 328.87 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9933/47780 [01:03<01:56, 324.72 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19148/47780 [01:03<01:36, 297.98 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18728/47780 [01:03<01:37, 297.89 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19147/47780 [01:03<01:50, 259.87 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19313/47780 [01:03<01:28, 321.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20663/47780 [01:03<01:25, 315.66 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18881/47780 [01:03<01:33, 307.76 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 9966/47780 [01:03<01:57, 322.77 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19888/47780 [01:03<01:29, 310.17 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19190/47780 [01:03<01:26, 331.58 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18767/47780 [01:03<01:29, 322.97 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19175/47780 [01:03<01:47, 265.29 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19347/47780 [01:03<01:28, 320.17 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20695/47780 [01:03<01:26, 313.14 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18912/47780 [01:03<01:34, 305.31 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10004/47780 [01:03<01:52, 335.27 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19925/47780 [01:03<01:25, 326.22 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19225/47780 [01:03<01:26, 328.97 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18801/47780 [01:03<01:28, 327.50 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19211/47780 [01:03<01:39, 285.99 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19385/47780 [01:03<01:24, 337.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20727/47780 [01:03<01:28, 305.07 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18944/47780 [01:04<01:35, 302.43 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10043/47780 [01:03<01:47, 350.98 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19267/47780 [01:03<01:21, 351.53 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18840/47780 [01:03<01:24, 342.03 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19959/47780 [01:04<01:28, 316.01 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19242/47780 [01:04<01:38, 289.50 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19421/47780 [01:04<01:22, 342.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20759/47780 [01:04<01:27, 308.75 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18982/47780 [01:04<01:29, 321.40 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10080/47780 [01:04<01:47, 352.28 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19991/47780 [01:04<01:28, 313.77 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19303/47780 [01:04<01:25, 334.81 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18875/47780 [01:04<01:27, 328.54 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19275/47780 [01:04<01:37, 291.10 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19456/47780 [01:04<01:23, 338.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20791/47780 [01:04<01:27, 308.83 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10117/47780 [01:04<01:45, 357.23 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19015/47780 [01:04<01:30, 316.56 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20034/47780 [01:04<01:21, 341.72 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18911/47780 [01:04<01:26, 334.19 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19305/47780 [01:04<01:38, 290.36 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19337/47780 [01:04<01:29, 318.49 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20822/47780 [01:04<01:27, 309.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19491/47780 [01:04<01:26, 326.24 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██        | 10153/47780 [01:04<01:47, 349.91 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19047/47780 [01:04<01:32, 310.07 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20070/47780 [01:04<01:20, 344.11 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18953/47780 [01:04<01:21, 354.62 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19337/47780 [01:04<01:37, 292.16 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20855/47780 [01:04<01:25, 313.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19371/47780 [01:04<01:29, 317.41 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19524/47780 [01:04<01:36, 293.91 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19079/47780 [01:04<01:36, 297.58 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10189/47780 [01:04<01:56, 323.07 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20105/47780 [01:04<01:21, 337.54 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18989/47780 [01:04<01:21, 351.67 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20889/47780 [01:04<01:24, 319.34 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19367/47780 [01:04<01:38, 287.80 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19405/47780 [01:04<01:32, 306.66 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19555/47780 [01:04<01:38, 286.02 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19118/47780 [01:04<01:29, 319.05 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10222/47780 [01:04<01:59, 314.39 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20139/47780 [01:04<01:25, 323.89 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20921/47780 [01:04<01:25, 312.48 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19397/47780 [01:04<01:38, 287.93 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19025/47780 [01:04<01:27, 328.06 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19155/47780 [01:04<01:26, 329.16 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19436/47780 [01:04<01:48, 260.52 examples/s]
Tokenizing train dataset (num_proc=32):  21%|██▏       | 10255/47780 [01:04<01:58, 315.37 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19585/47780 [01:04<01:44, 269.48 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20185/47780 [01:04<01:16, 361.86 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19429/47780 [01:04<01:35, 297.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20953/47780 [01:04<01:26, 310.83 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19063/47780 [01:04<01:25, 334.99 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19193/47780 [01:04<01:24, 339.75 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19630/47780 [01:04<01:29, 313.65 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10287/47780 [01:04<02:00, 312.35 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20222/47780 [01:04<01:16, 359.78 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19475/47780 [01:04<01:40, 282.95 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19462/47780 [01:04<01:33, 303.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20993/47780 [01:04<01:20, 332.80 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19097/47780 [01:04<01:28, 325.22 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19229/47780 [01:04<01:23, 341.66 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19664/47780 [01:04<01:28, 317.31 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10319/47780 [01:04<02:01, 308.23 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19505/47780 [01:04<01:38, 287.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20259/47780 [01:04<01:16, 358.55 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21027/47780 [01:04<01:22, 323.34 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19493/47780 [01:04<01:39, 285.22 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19130/47780 [01:04<01:30, 316.06 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19264/47780 [01:04<01:24, 338.72 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19697/47780 [01:04<01:28, 317.36 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20296/47780 [01:04<01:16, 358.32 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10350/47780 [01:04<02:06, 295.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19535/47780 [01:04<01:42, 276.07 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21061/47780 [01:04<01:22, 324.66 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19534/47780 [01:04<01:29, 316.73 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19171/47780 [01:04<01:24, 338.72 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19299/47780 [01:05<01:23, 339.50 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19734/47780 [01:05<01:24, 332.07 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20332/47780 [01:05<01:19, 346.75 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19569/47780 [01:05<01:36, 293.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10385/47780 [01:05<02:01, 307.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21094/47780 [01:05<01:22, 325.21 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19566/47780 [01:05<01:31, 307.10 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19207/47780 [01:05<01:25, 333.09 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19769/47780 [01:05<01:24, 333.34 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19333/47780 [01:05<01:27, 324.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19599/47780 [01:05<01:36, 291.25 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20367/47780 [01:05<01:23, 328.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10417/47780 [01:05<02:05, 297.37 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19597/47780 [01:05<01:34, 297.50 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21128/47780 [01:05<01:28, 301.74 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19248/47780 [01:05<01:22, 347.23 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19809/47780 [01:05<01:19, 352.36 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19371/47780 [01:05<01:24, 336.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19631/47780 [01:05<01:34, 296.53 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20405/47780 [01:05<01:21, 335.73 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10447/47780 [01:05<02:10, 285.04 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19284/47780 [01:05<01:21, 350.81 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19627/47780 [01:05<01:36, 292.05 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21160/47780 [01:05<01:30, 294.33 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19406/47780 [01:05<01:25, 332.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19845/47780 [01:05<01:24, 331.65 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19661/47780 [01:05<01:37, 287.50 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20439/47780 [01:05<01:22, 333.04 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10500/47780 [01:05<01:47, 345.48 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19658/47780 [01:05<01:35, 293.92 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19320/47780 [01:05<01:24, 336.66 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21191/47780 [01:05<01:31, 292.09 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19442/47780 [01:05<01:24, 336.74 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19693/47780 [01:05<01:35, 293.51 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19879/47780 [01:05<01:28, 316.23 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20473/47780 [01:05<01:22, 331.21 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10536/47780 [01:05<01:46, 349.41 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19688/47780 [01:05<01:38, 285.51 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21221/47780 [01:05<01:31, 290.64 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19354/47780 [01:05<01:30, 313.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19478/47780 [01:05<01:23, 339.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19726/47780 [01:05<01:32, 303.87 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19918/47780 [01:05<01:23, 332.93 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20507/47780 [01:05<01:30, 302.56 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19719/47780 [01:05<01:36, 289.37 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10572/47780 [01:05<01:56, 319.86 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21251/47780 [01:05<01:34, 281.22 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19389/47780 [01:05<01:28, 320.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19513/47780 [01:05<01:24, 334.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19762/47780 [01:05<01:28, 316.48 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19953/47780 [01:05<01:22, 335.83 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20538/47780 [01:05<01:30, 301.38 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19750/47780 [01:05<01:34, 295.09 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10605/47780 [01:05<02:02, 302.96 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21280/47780 [01:05<01:37, 271.64 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19551/47780 [01:05<01:23, 339.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19422/47780 [01:05<01:33, 302.89 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19798/47780 [01:05<01:27, 318.07 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20569/47780 [01:05<01:29, 303.41 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19781/47780 [01:05<01:34, 295.70 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21316/47780 [01:05<01:29, 295.88 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10636/47780 [01:05<02:03, 301.62 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19459/47780 [01:05<01:28, 320.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19987/47780 [01:05<01:45, 263.29 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19830/47780 [01:05<01:29, 311.35 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19586/47780 [01:05<01:28, 317.14 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19812/47780 [01:05<01:34, 296.53 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20609/47780 [01:05<01:24, 320.25 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21348/47780 [01:05<01:27, 302.44 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10670/47780 [01:05<02:00, 308.67 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19492/47780 [01:05<01:29, 316.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20034/47780 [01:06<01:29, 310.52 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19638/47780 [01:06<01:17, 365.09 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19862/47780 [01:06<01:35, 293.87 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19843/47780 [01:06<01:33, 297.39 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20644/47780 [01:06<01:23, 324.97 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21386/47780 [01:06<01:21, 324.47 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19524/47780 [01:06<01:28, 317.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10702/47780 [01:06<02:08, 289.28 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20071/47780 [01:06<01:26, 319.14 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19675/47780 [01:06<01:22, 340.51 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19892/47780 [01:06<01:37, 286.05 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20689/47780 [01:06<01:15, 360.29 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19878/47780 [01:06<01:31, 305.62 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21423/47780 [01:06<01:18, 334.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19556/47780 [01:06<01:31, 307.06 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20113/47780 [01:06<01:20, 341.91 examples/s]
Tokenizing train dataset (num_proc=32):  22%|██▏       | 10732/47780 [01:06<02:11, 282.76 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19719/47780 [01:06<01:17, 362.86 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19921/47780 [01:06<01:38, 283.86 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19909/47780 [01:06<01:33, 296.58 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20726/47780 [01:06<01:18, 346.51 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21457/47780 [01:06<01:21, 321.03 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20152/47780 [01:06<01:18, 351.17 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19588/47780 [01:06<01:33, 300.41 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10765/47780 [01:06<02:07, 289.62 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19950/47780 [01:06<01:37, 285.24 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19757/47780 [01:06<01:18, 358.50 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19945/47780 [01:06<01:28, 314.50 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20761/47780 [01:06<01:18, 344.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21490/47780 [01:06<01:21, 322.24 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20192/47780 [01:06<01:15, 364.66 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19619/47780 [01:06<01:33, 302.28 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10796/47780 [01:06<02:06, 292.06 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19979/47780 [01:06<01:39, 280.58 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20805/47780 [01:06<01:12, 371.23 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19977/47780 [01:06<01:30, 308.88 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19795/47780 [01:06<01:20, 347.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21523/47780 [01:06<01:25, 307.88 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19650/47780 [01:06<01:33, 301.62 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10836/47780 [01:06<01:57, 315.14 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20230/47780 [01:06<01:19, 345.48 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20008/47780 [01:06<01:39, 279.72 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20012/47780 [01:06<01:28, 313.73 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20843/47780 [01:06<01:17, 349.71 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21556/47780 [01:06<01:24, 311.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19831/47780 [01:06<01:26, 321.62 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19685/47780 [01:06<01:30, 309.52 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10873/47780 [01:06<01:52, 326.94 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20266/47780 [01:06<01:21, 336.55 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20041/47780 [01:06<01:37, 284.83 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20044/47780 [01:06<01:28, 311.99 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20879/47780 [01:06<01:18, 344.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19872/47780 [01:06<01:21, 341.41 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21590/47780 [01:06<01:24, 308.35 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19718/47780 [01:06<01:29, 311.87 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10912/47780 [01:06<01:49, 337.20 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20301/47780 [01:06<01:22, 334.52 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20081/47780 [01:06<01:27, 317.53 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20076/47780 [01:06<01:31, 303.80 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20917/47780 [01:06<01:16, 351.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19908/47780 [01:06<01:20, 346.44 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21625/47780 [01:06<01:23, 312.88 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10950/47780 [01:06<01:45, 349.37 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19750/47780 [01:06<01:32, 303.64 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20335/47780 [01:06<01:22, 332.59 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20109/47780 [01:06<01:28, 311.22 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20113/47780 [01:06<01:33, 297.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19952/47780 [01:06<01:15, 368.45 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21657/47780 [01:06<01:26, 302.73 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 10986/47780 [01:06<01:46, 344.26 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20953/47780 [01:07<01:26, 311.01 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19782/47780 [01:06<01:36, 291.41 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20373/47780 [01:06<01:20, 342.01 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20145/47780 [01:06<01:32, 297.41 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19992/47780 [01:07<01:13, 377.27 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20141/47780 [01:07<01:37, 284.17 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21688/47780 [01:07<01:27, 299.47 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11021/47780 [01:07<01:47, 341.86 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20410/47780 [01:07<01:19, 346.04 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19816/47780 [01:07<01:33, 297.73 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20986/47780 [01:07<01:29, 300.16 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20185/47780 [01:07<01:24, 325.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20036/47780 [01:07<01:10, 392.06 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20170/47780 [01:07<01:38, 279.34 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11058/47780 [01:07<01:46, 346.40 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21722/47780 [01:07<01:29, 291.64 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19846/47780 [01:07<01:34, 294.97 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21024/47780 [01:07<01:24, 318.02 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20445/47780 [01:07<01:21, 334.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20225/47780 [01:07<01:20, 343.43 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20076/47780 [01:07<01:14, 371.50 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20200/47780 [01:07<01:36, 285.02 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11093/47780 [01:07<01:49, 335.47 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19881/47780 [01:07<01:30, 308.00 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21758/47780 [01:07<01:27, 297.31 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20485/47780 [01:07<01:18, 346.08 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21057/47780 [01:07<01:27, 306.66 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20262/47780 [01:07<01:20, 342.94 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20114/47780 [01:07<01:17, 357.87 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20230/47780 [01:07<01:42, 268.31 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11127/47780 [01:07<01:49, 333.22 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19912/47780 [01:07<01:31, 305.01 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21793/47780 [01:07<01:27, 298.70 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21089/47780 [01:07<01:29, 298.64 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20520/47780 [01:07<01:22, 328.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20302/47780 [01:07<01:18, 351.31 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20259/47780 [01:07<01:41, 271.35 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20151/47780 [01:07<01:21, 340.84 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19948/47780 [01:07<01:26, 320.70 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20560/47780 [01:07<01:18, 348.53 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21135/47780 [01:07<01:18, 338.73 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21829/47780 [01:07<01:24, 305.41 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11161/47780 [01:07<02:03, 297.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20338/47780 [01:07<01:18, 349.57 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20292/47780 [01:07<01:36, 284.49 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20190/47780 [01:07<01:19, 348.32 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19981/47780 [01:07<01:27, 316.34 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20598/47780 [01:07<01:16, 353.46 examples/s]
Tokenizing train dataset (num_proc=32):  23%|██▎       | 11196/47780 [01:07<01:58, 308.32 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21867/47780 [01:07<01:21, 318.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21170/47780 [01:07<01:21, 327.05 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20374/47780 [01:07<01:22, 333.68 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20326/47780 [01:07<01:31, 299.55 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20014/47780 [01:07<01:26, 320.24 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20226/47780 [01:07<01:21, 336.52 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20635/47780 [01:07<01:18, 344.12 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21902/47780 [01:07<01:19, 323.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11229/47780 [01:07<02:01, 300.74 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21211/47780 [01:07<01:19, 335.34 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20408/47780 [01:07<01:27, 311.19 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20368/47780 [01:07<01:22, 330.92 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20047/47780 [01:07<01:26, 319.42 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20267/47780 [01:07<01:17, 352.98 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21935/47780 [01:07<01:19, 325.60 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20670/47780 [01:07<01:20, 336.37 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21249/47780 [01:07<01:17, 343.85 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11261/47780 [01:07<02:04, 293.32 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20441/47780 [01:07<01:28, 309.48 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20079/47780 [01:07<01:28, 312.06 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20403/47780 [01:07<01:27, 312.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20303/47780 [01:07<01:18, 350.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21968/47780 [01:07<01:23, 308.73 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20704/47780 [01:07<01:24, 319.51 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11291/47780 [01:07<02:07, 286.02 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21284/47780 [01:08<01:20, 330.56 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20480/47780 [01:07<01:23, 328.07 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20111/47780 [01:08<01:28, 311.19 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20435/47780 [01:08<01:31, 299.83 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20339/47780 [01:08<01:22, 330.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22001/47780 [01:08<01:22, 311.65 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21318/47780 [01:08<01:19, 332.83 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▎       | 11321/47780 [01:08<02:07, 286.59 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20737/47780 [01:08<01:28, 305.25 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20519/47780 [01:08<01:18, 345.36 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20149/47780 [01:08<01:23, 330.90 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20466/47780 [01:08<01:33, 292.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20373/47780 [01:08<01:24, 323.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22034/47780 [01:08<01:23, 309.80 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11352/47780 [01:08<02:05, 289.93 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20775/47780 [01:08<01:24, 319.22 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21352/47780 [01:08<01:26, 304.23 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20183/47780 [01:08<01:25, 322.28 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20554/47780 [01:08<01:29, 304.56 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20407/47780 [01:08<01:23, 327.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20496/47780 [01:08<01:37, 280.40 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22066/47780 [01:08<01:25, 301.44 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20815/47780 [01:08<01:20, 334.16 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11383/47780 [01:08<02:18, 262.74 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21384/47780 [01:08<01:30, 290.78 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20593/47780 [01:08<01:24, 320.74 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20527/47780 [01:08<01:35, 284.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20440/47780 [01:08<01:27, 310.92 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22101/47780 [01:08<01:22, 312.62 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20216/47780 [01:08<01:40, 273.60 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20849/47780 [01:08<01:23, 321.52 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11410/47780 [01:08<02:18, 261.96 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21414/47780 [01:08<01:31, 289.37 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20630/47780 [01:08<01:22, 330.33 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20481/47780 [01:08<01:20, 338.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20557/47780 [01:08<01:35, 285.34 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20255/47780 [01:08<01:31, 302.29 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22134/47780 [01:08<01:22, 310.13 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20882/47780 [01:08<01:27, 308.30 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11438/47780 [01:08<02:20, 258.27 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21444/47780 [01:08<01:38, 266.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20516/47780 [01:08<01:20, 338.42 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20664/47780 [01:08<01:29, 302.92 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20587/47780 [01:08<01:39, 274.07 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20289/47780 [01:08<01:29, 307.66 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22170/47780 [01:08<01:20, 317.35 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20914/47780 [01:08<01:26, 309.84 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11472/47780 [01:08<02:12, 273.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21480/47780 [01:08<01:31, 287.70 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20551/47780 [01:08<01:23, 325.76 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20623/47780 [01:08<01:34, 288.60 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22202/47780 [01:08<01:21, 314.34 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20321/47780 [01:08<01:32, 297.92 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20955/47780 [01:08<01:19, 336.03 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20696/47780 [01:08<01:40, 268.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11505/47780 [01:08<02:06, 287.35 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21510/47780 [01:08<01:34, 278.97 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20594/47780 [01:08<01:18, 347.60 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20658/47780 [01:08<01:28, 305.54 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22237/47780 [01:08<01:21, 314.04 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20352/47780 [01:08<01:32, 297.13 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20990/47780 [01:08<01:20, 334.40 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20734/47780 [01:08<01:31, 295.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11541/47780 [01:08<01:59, 302.05 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21541/47780 [01:08<01:31, 287.24 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20632/47780 [01:08<01:16, 352.80 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20393/47780 [01:08<01:24, 325.95 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22271/47780 [01:08<01:21, 314.77 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20689/47780 [01:08<01:33, 290.13 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20766/47780 [01:08<01:30, 298.56 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11574/47780 [01:08<01:57, 308.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21024/47780 [01:08<01:26, 308.01 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21571/47780 [01:09<01:33, 281.47 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20427/47780 [01:09<01:22, 329.89 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20668/47780 [01:09<01:22, 326.77 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20720/47780 [01:09<01:34, 286.04 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22303/47780 [01:09<01:24, 302.02 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11616/47780 [01:09<01:46, 340.69 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20797/47780 [01:09<01:31, 295.18 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21075/47780 [01:09<01:14, 358.91 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21605/47780 [01:09<01:28, 296.38 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20476/47780 [01:09<01:12, 375.84 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20752/47780 [01:09<01:31, 295.38 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20707/47780 [01:09<01:19, 338.59 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22336/47780 [01:09<01:26, 293.47 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11651/47780 [01:09<01:46, 340.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20828/47780 [01:09<01:36, 280.68 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21113/47780 [01:09<01:17, 345.53 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21636/47780 [01:09<01:27, 298.59 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20785/47780 [01:09<01:31, 295.55 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20515/47780 [01:09<01:17, 351.12 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22366/47780 [01:09<01:28, 285.84 examples/s]
Tokenizing train dataset (num_proc=32):  24%|██▍       | 11686/47780 [01:09<01:49, 330.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20743/47780 [01:09<01:27, 309.67 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21156/47780 [01:09<01:12, 368.38 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20857/47780 [01:09<01:43, 260.60 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21667/47780 [01:09<01:29, 291.57 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20552/47780 [01:09<01:17, 352.68 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20815/47780 [01:09<01:32, 293.07 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22395/47780 [01:09<01:30, 279.76 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11720/47780 [01:09<01:50, 325.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20781/47780 [01:09<01:24, 321.16 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21202/47780 [01:09<01:08, 386.29 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20898/47780 [01:09<01:30, 297.04 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21699/47780 [01:09<01:27, 299.59 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20588/47780 [01:09<01:16, 354.70 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20845/47780 [01:09<01:37, 276.60 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11757/47780 [01:09<01:47, 334.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22424/47780 [01:09<01:32, 274.21 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21244/47780 [01:09<01:07, 391.52 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21734/47780 [01:09<01:22, 313.91 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20931/47780 [01:09<01:29, 299.03 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20815/47780 [01:09<01:32, 292.21 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20624/47780 [01:09<01:16, 355.79 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22454/47780 [01:09<01:30, 278.67 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20873/47780 [01:09<01:42, 263.01 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11791/47780 [01:09<01:53, 317.65 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21285/47780 [01:09<01:07, 391.58 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21766/47780 [01:09<01:24, 308.74 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20976/47780 [01:09<01:19, 338.72 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20845/47780 [01:09<01:33, 288.33 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20661/47780 [01:09<01:18, 344.38 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22486/47780 [01:09<01:28, 286.96 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20900/47780 [01:09<01:43, 260.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11823/47780 [01:09<01:53, 315.63 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21328/47780 [01:09<01:05, 402.58 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21807/47780 [01:09<01:16, 338.01 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21019/47780 [01:09<01:14, 358.58 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20875/47780 [01:09<01:36, 279.57 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20700/47780 [01:09<01:16, 353.34 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22517/47780 [01:09<01:26, 293.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20929/47780 [01:09<01:41, 264.35 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21842/47780 [01:09<01:16, 341.03 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21369/47780 [01:09<01:12, 365.95 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20907/47780 [01:09<01:33, 287.52 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11855/47780 [01:09<02:10, 275.97 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21058/47780 [01:09<01:19, 338.18 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20736/47780 [01:09<01:18, 346.66 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22550/47780 [01:09<01:22, 303.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20956/47780 [01:09<01:43, 260.09 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21880/47780 [01:09<01:14, 348.07 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20937/47780 [01:09<01:32, 290.87 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11887/47780 [01:09<02:07, 281.10 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21093/47780 [01:09<01:21, 328.99 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20771/47780 [01:09<01:19, 339.89 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21407/47780 [01:09<01:19, 330.31 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22584/47780 [01:10<01:21, 311.03 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21918/47780 [01:10<01:12, 357.41 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20983/47780 [01:10<01:48, 246.29 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20973/47780 [01:10<01:27, 306.86 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▍       | 11916/47780 [01:10<02:07, 281.91 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21129/47780 [01:10<01:19, 334.15 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20806/47780 [01:10<01:20, 335.71 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22619/47780 [01:10<01:19, 315.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21443/47780 [01:10<01:21, 324.79 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21956/47780 [01:10<01:11, 360.79 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21013/47780 [01:10<01:44, 255.37 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21008/47780 [01:10<01:25, 312.01 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11949/47780 [01:10<02:01, 293.74 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21163/47780 [01:10<01:21, 326.00 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20840/47780 [01:10<01:21, 328.92 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22659/47780 [01:10<01:14, 335.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21477/47780 [01:10<01:21, 322.39 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21993/47780 [01:10<01:11, 358.90 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21039/47780 [01:10<01:46, 251.12 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21040/47780 [01:10<01:26, 310.76 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 11982/47780 [01:10<01:59, 300.59 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21196/47780 [01:10<01:24, 315.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21513/47780 [01:10<01:19, 332.16 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20873/47780 [01:10<01:28, 305.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22693/47780 [01:10<01:17, 321.75 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21073/47780 [01:10<01:37, 272.89 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22029/47780 [01:10<01:15, 339.32 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21072/47780 [01:10<01:25, 313.22 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12013/47780 [01:10<02:05, 283.91 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21231/47780 [01:10<01:22, 321.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20907/47780 [01:10<01:26, 311.38 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22726/47780 [01:10<01:18, 317.26 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21547/47780 [01:10<01:24, 309.99 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21106/47780 [01:10<01:32, 288.97 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22065/47780 [01:10<01:17, 330.14 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21105/47780 [01:10<01:28, 300.78 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12043/47780 [01:10<02:05, 285.17 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21264/47780 [01:10<01:26, 306.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20943/47780 [01:10<01:23, 321.47 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22758/47780 [01:10<01:20, 310.70 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21139/47780 [01:10<01:28, 300.77 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21579/47780 [01:10<01:26, 303.17 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22099/47780 [01:10<01:21, 316.19 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21140/47780 [01:10<01:25, 311.21 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12072/47780 [01:10<02:04, 286.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21301/47780 [01:10<01:22, 322.07 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22799/47780 [01:10<01:14, 335.37 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20976/47780 [01:10<01:26, 309.60 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21170/47780 [01:10<01:28, 299.70 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21610/47780 [01:10<01:35, 274.79 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22135/47780 [01:10<01:20, 317.22 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21172/47780 [01:10<01:26, 306.32 examples/s]
Tokenizing train dataset (num_proc=32):  25%|██▌       | 12102/47780 [01:10<02:05, 283.84 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21338/47780 [01:10<01:20, 328.90 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22836/47780 [01:10<01:12, 342.26 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21008/47780 [01:10<01:26, 309.19 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21204/47780 [01:10<01:28, 301.30 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22177/47780 [01:10<01:14, 345.37 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21209/47780 [01:10<01:22, 321.47 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21639/47780 [01:10<01:36, 270.66 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12139/47780 [01:10<01:58, 301.69 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22876/47780 [01:10<01:09, 357.90 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21372/47780 [01:10<01:23, 315.58 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21241/47780 [01:10<01:22, 320.51 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21040/47780 [01:10<01:33, 287.01 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21675/47780 [01:10<01:29, 291.17 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22213/47780 [01:10<01:15, 339.03 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21242/47780 [01:10<01:25, 309.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12170/47780 [01:10<01:59, 296.86 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22917/47780 [01:10<01:06, 372.80 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21410/47780 [01:10<01:19, 330.08 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21072/47780 [01:10<01:30, 295.37 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21274/47780 [01:10<01:25, 309.02 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21727/47780 [01:11<01:15, 345.96 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21274/47780 [01:11<01:25, 309.55 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22248/47780 [01:11<01:17, 330.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12200/47780 [01:11<02:03, 288.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22957/47780 [01:11<01:05, 380.78 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21445/47780 [01:11<01:19, 331.28 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21306/47780 [01:11<01:26, 305.31 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21102/47780 [01:11<01:35, 278.22 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21763/47780 [01:11<01:15, 342.33 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21309/47780 [01:11<01:22, 320.44 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22287/47780 [01:11<01:13, 346.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12231/47780 [01:11<02:02, 291.16 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23004/47780 [01:11<01:02, 398.14 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21479/47780 [01:11<01:20, 326.13 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21338/47780 [01:11<01:25, 309.35 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21137/47780 [01:11<01:29, 297.50 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21798/47780 [01:11<01:15, 344.46 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22325/47780 [01:11<01:11, 355.98 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21348/47780 [01:11<01:19, 332.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12263/47780 [01:11<02:01, 292.60 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23045/47780 [01:11<01:03, 387.63 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21513/47780 [01:11<01:22, 319.30 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21370/47780 [01:11<01:25, 309.17 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21168/47780 [01:11<01:32, 287.82 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22361/47780 [01:11<01:14, 341.21 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21383/47780 [01:11<01:20, 327.62 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21834/47780 [01:11<01:20, 323.09 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12298/47780 [01:11<01:57, 302.26 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23089/47780 [01:11<01:03, 389.53 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21546/47780 [01:11<01:24, 312.23 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21402/47780 [01:11<01:29, 295.00 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21199/47780 [01:11<01:31, 289.98 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21422/47780 [01:11<01:17, 340.34 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22396/47780 [01:11<01:15, 335.58 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21867/47780 [01:11<01:20, 321.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12330/47780 [01:11<01:56, 303.67 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23129/47780 [01:11<01:04, 383.81 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21578/47780 [01:11<01:25, 308.01 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21438/47780 [01:11<01:26, 303.24 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21233/47780 [01:11<01:28, 298.41 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21457/47780 [01:11<01:16, 343.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22430/47780 [01:11<01:15, 334.00 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12361/47780 [01:11<02:01, 291.85 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21900/47780 [01:11<01:28, 291.45 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23168/47780 [01:11<01:05, 376.72 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21471/47780 [01:11<01:24, 310.72 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21609/47780 [01:11<01:32, 282.65 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22470/47780 [01:11<01:12, 351.25 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21492/47780 [01:11<01:18, 333.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21264/47780 [01:11<01:34, 279.61 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21931/47780 [01:11<01:29, 290.24 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12393/47780 [01:11<02:07, 277.49 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23206/47780 [01:11<01:11, 343.71 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21641/47780 [01:11<01:30, 289.58 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21503/47780 [01:11<01:29, 293.29 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22507/47780 [01:11<01:11, 354.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21527/47780 [01:11<01:17, 338.23 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21299/47780 [01:11<01:30, 292.30 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12427/47780 [01:11<02:00, 294.40 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21966/47780 [01:11<01:26, 299.82 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23242/47780 [01:11<01:12, 339.86 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21689/47780 [01:11<01:17, 338.15 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22543/47780 [01:11<01:11, 355.29 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21534/47780 [01:11<01:30, 291.46 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21561/47780 [01:11<01:17, 338.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21334/47780 [01:11<01:25, 308.12 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12458/47780 [01:11<02:03, 286.84 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21734/47780 [01:11<01:11, 364.22 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21998/47780 [01:11<01:32, 277.83 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21567/47780 [01:11<01:29, 292.40 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21372/47780 [01:11<01:20, 328.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21596/47780 [01:12<01:19, 328.95 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23277/47780 [01:11<01:20, 305.60 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22579/47780 [01:12<01:18, 322.73 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12507/47780 [01:11<01:44, 339.15 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21781/47780 [01:12<01:06, 392.36 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22038/47780 [01:12<01:23, 309.87 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21603/47780 [01:12<01:24, 311.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21410/47780 [01:12<01:16, 343.05 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22617/47780 [01:12<01:15, 335.22 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23309/47780 [01:12<01:22, 297.38 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21629/47780 [01:12<01:27, 299.36 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21825/47780 [01:12<01:04, 404.84 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▌       | 12542/47780 [01:12<01:50, 320.28 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22075/47780 [01:12<01:20, 319.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21638/47780 [01:12<01:22, 315.13 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21445/47780 [01:12<01:19, 329.67 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23340/47780 [01:12<01:21, 300.63 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22652/47780 [01:12<01:17, 323.21 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21660/47780 [01:12<01:28, 296.08 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21866/47780 [01:12<01:05, 396.65 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22111/47780 [01:12<01:18, 328.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12579/47780 [01:12<01:48, 323.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21676/47780 [01:12<01:20, 326.03 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23372/47780 [01:12<01:20, 302.64 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21479/47780 [01:12<01:22, 318.58 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22685/47780 [01:12<01:20, 312.85 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21690/47780 [01:12<01:34, 275.72 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22145/47780 [01:12<01:17, 329.25 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21906/47780 [01:12<01:07, 381.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12612/47780 [01:12<01:52, 311.66 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21710/47780 [01:12<01:20, 322.55 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23408/47780 [01:12<01:17, 315.11 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21513/47780 [01:12<01:23, 313.93 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22717/47780 [01:12<01:21, 305.71 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21723/47780 [01:12<01:30, 287.40 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22180/47780 [01:12<01:17, 332.31 examples/s]
Tokenizing train dataset (num_proc=32):  26%|██▋       | 12647/47780 [01:12<01:51, 315.18 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21945/47780 [01:12<01:11, 362.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21745/47780 [01:12<01:19, 327.95 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23441/47780 [01:12<01:17, 312.30 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21553/47780 [01:12<01:17, 337.84 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22751/47780 [01:12<01:19, 314.04 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21753/47780 [01:12<01:32, 281.55 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22214/47780 [01:12<01:16, 334.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12682/47780 [01:12<01:48, 324.59 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21781/47780 [01:12<01:19, 327.13 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21983/47780 [01:12<01:14, 348.27 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23474/47780 [01:12<01:16, 316.85 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21588/47780 [01:12<01:19, 329.14 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22784/47780 [01:12<01:18, 318.36 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21785/47780 [01:12<01:29, 290.94 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22251/47780 [01:12<01:14, 341.05 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12715/47780 [01:12<01:54, 305.80 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21815/47780 [01:12<01:19, 328.15 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23515/47780 [01:12<01:10, 342.65 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21622/47780 [01:12<01:21, 322.00 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22019/47780 [01:12<01:20, 319.97 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22820/47780 [01:12<01:18, 319.60 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21815/47780 [01:12<01:29, 291.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22287/47780 [01:12<01:13, 346.55 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12746/47780 [01:12<01:56, 301.79 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23552/47780 [01:12<01:09, 347.26 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21848/47780 [01:12<01:22, 314.55 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21657/47780 [01:12<01:19, 326.58 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22861/47780 [01:12<01:12, 345.27 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22052/47780 [01:12<01:23, 306.29 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21845/47780 [01:12<01:29, 289.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22332/47780 [01:12<01:08, 372.70 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12780/47780 [01:12<01:52, 310.77 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23598/47780 [01:12<01:04, 376.51 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21693/47780 [01:12<01:19, 328.62 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22896/47780 [01:13<01:14, 335.00 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21880/47780 [01:12<01:31, 283.95 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21882/47780 [01:13<01:23, 311.55 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22084/47780 [01:12<01:23, 308.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22371/47780 [01:12<01:09, 364.65 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12812/47780 [01:13<01:56, 299.84 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23636/47780 [01:13<01:07, 359.53 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21731/47780 [01:13<01:16, 339.30 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22931/47780 [01:13<01:14, 335.40 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21916/47780 [01:13<01:21, 318.18 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22116/47780 [01:13<01:22, 309.51 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21909/47780 [01:13<01:33, 276.41 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22413/47780 [01:13<01:07, 376.42 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12843/47780 [01:13<01:55, 302.66 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23676/47780 [01:13<01:06, 363.85 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21953/47780 [01:13<01:17, 333.29 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22148/47780 [01:13<01:23, 306.05 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22965/47780 [01:13<01:18, 314.83 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22459/47780 [01:13<01:05, 384.70 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21766/47780 [01:13<01:27, 298.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21937/47780 [01:13<01:42, 252.88 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23715/47780 [01:13<01:04, 371.20 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21987/47780 [01:13<01:20, 319.34 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12874/47780 [01:13<02:14, 260.29 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22180/47780 [01:13<01:26, 296.91 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22504/47780 [01:13<01:03, 396.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22997/47780 [01:13<01:25, 290.86 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21976/47780 [01:13<01:31, 283.01 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21797/47780 [01:13<01:31, 283.28 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23761/47780 [01:13<01:01, 392.48 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12927/47780 [01:13<01:46, 326.55 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22023/47780 [01:13<01:20, 320.94 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22210/47780 [01:13<01:27, 293.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23027/47780 [01:13<01:24, 293.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22544/47780 [01:13<01:08, 369.16 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22005/47780 [01:13<01:37, 264.97 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23805/47780 [01:13<01:00, 397.02 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21827/47780 [01:13<01:40, 258.03 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 12969/47780 [01:13<01:40, 347.14 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22249/47780 [01:13<01:20, 318.21 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22056/47780 [01:13<01:23, 308.96 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23060/47780 [01:13<01:22, 297.86 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22043/47780 [01:13<01:28, 292.15 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22583/47780 [01:13<01:14, 340.45 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21861/47780 [01:13<01:33, 275.80 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23845/47780 [01:13<01:05, 368.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13006/47780 [01:13<01:42, 339.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22281/47780 [01:13<01:26, 295.08 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22088/47780 [01:13<01:28, 289.63 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23091/47780 [01:13<01:26, 284.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22618/47780 [01:13<01:14, 335.80 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21890/47780 [01:13<01:34, 273.78 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22074/47780 [01:13<01:34, 273.07 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13055/47780 [01:13<01:32, 376.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23883/47780 [01:13<01:12, 330.85 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22119/47780 [01:13<01:29, 286.08 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23120/47780 [01:13<01:28, 279.61 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22311/47780 [01:13<01:33, 272.54 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21921/47780 [01:13<01:31, 283.47 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22652/47780 [01:13<01:17, 325.52 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22114/47780 [01:13<01:27, 294.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23917/47780 [01:13<01:12, 329.70 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13094/47780 [01:13<01:37, 355.82 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22148/47780 [01:13<01:29, 287.07 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22347/47780 [01:13<01:26, 292.67 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23149/47780 [01:13<01:30, 271.24 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21953/47780 [01:13<01:30, 284.17 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22685/47780 [01:13<01:21, 307.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22144/47780 [01:13<01:30, 283.44 examples/s]
Tokenizing train dataset (num_proc=32):  27%|██▋       | 13131/47780 [01:13<01:37, 356.22 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22182/47780 [01:14<01:26, 295.65 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23951/47780 [01:13<01:17, 306.68 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22387/47780 [01:13<01:19, 318.37 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23182/47780 [01:14<01:25, 286.89 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21985/47780 [01:14<01:27, 294.06 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22730/47780 [01:14<01:12, 345.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22173/47780 [01:14<01:33, 274.88 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22212/47780 [01:14<01:27, 293.26 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22425/47780 [01:14<01:15, 335.47 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13168/47780 [01:14<01:44, 329.93 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23215/47780 [01:14<01:27, 280.06 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23983/47780 [01:14<01:23, 283.47 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22015/47780 [01:14<01:31, 282.66 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22766/47780 [01:14<01:11, 348.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22202/47780 [01:14<01:34, 272.05 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22242/47780 [01:14<01:27, 291.83 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13206/47780 [01:14<01:42, 336.89 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22460/47780 [01:14<01:18, 320.75 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24012/47780 [01:14<01:25, 276.42 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22802/47780 [01:14<01:11, 350.66 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22050/47780 [01:14<01:25, 299.36 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23244/47780 [01:14<01:31, 267.93 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22233/47780 [01:14<01:30, 282.26 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22273/47780 [01:14<01:26, 293.66 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22493/47780 [01:14<01:21, 310.01 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13242/47780 [01:14<01:47, 321.78 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22844/47780 [01:14<01:07, 368.64 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23278/47780 [01:14<01:26, 284.56 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24040/47780 [01:14<01:29, 266.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22262/47780 [01:14<01:29, 284.03 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22081/47780 [01:14<01:36, 267.36 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22303/47780 [01:14<01:37, 261.94 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23309/47780 [01:14<01:24, 288.54 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22885/47780 [01:14<01:06, 372.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22525/47780 [01:14<01:25, 294.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24070/47780 [01:14<01:27, 272.49 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22291/47780 [01:14<01:33, 273.58 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13275/47780 [01:14<02:01, 284.78 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22112/47780 [01:14<01:33, 273.66 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22332/47780 [01:14<01:35, 266.96 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23340/47780 [01:14<01:23, 294.14 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22558/47780 [01:14<01:24, 299.89 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22927/47780 [01:14<01:05, 377.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24107/47780 [01:14<01:20, 295.72 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22319/47780 [01:14<01:33, 272.52 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13305/47780 [01:14<02:01, 282.74 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22149/47780 [01:14<01:25, 298.45 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23374/47780 [01:14<01:21, 300.75 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22360/47780 [01:14<01:39, 256.18 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22590/47780 [01:14<01:25, 295.27 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22966/47780 [01:14<01:08, 363.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24137/47780 [01:14<01:23, 284.37 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22351/47780 [01:14<01:29, 282.80 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22181/47780 [01:14<01:26, 295.64 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13334/47780 [01:14<02:08, 267.88 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23408/47780 [01:14<01:19, 304.99 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22397/47780 [01:14<01:29, 284.25 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23008/47780 [01:14<01:05, 375.89 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22620/47780 [01:14<01:26, 290.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24177/47780 [01:14<01:15, 312.61 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22380/47780 [01:14<01:29, 284.52 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22212/47780 [01:14<01:27, 293.09 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13363/47780 [01:14<02:08, 267.97 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23442/47780 [01:14<01:18, 311.36 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22436/47780 [01:14<01:21, 310.08 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24210/47780 [01:14<01:14, 317.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23046/47780 [01:14<01:06, 372.28 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22409/47780 [01:14<01:29, 282.75 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22650/47780 [01:14<01:34, 266.64 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22248/47780 [01:14<01:22, 308.51 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13391/47780 [01:14<02:10, 263.01 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23477/47780 [01:15<01:16, 318.93 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22469/47780 [01:14<01:21, 312.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24243/47780 [01:14<01:13, 318.61 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23084/47780 [01:14<01:08, 358.62 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22438/47780 [01:14<01:31, 275.61 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22689/47780 [01:14<01:25, 293.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22282/47780 [01:15<01:21, 313.78 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13427/47780 [01:15<02:02, 280.12 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23514/47780 [01:15<01:13, 329.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22505/47780 [01:15<01:18, 322.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24278/47780 [01:15<01:13, 318.93 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22471/47780 [01:15<01:26, 291.15 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22314/47780 [01:15<01:20, 315.16 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22719/47780 [01:15<01:25, 291.85 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23121/47780 [01:15<01:15, 328.18 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13461/47780 [01:15<02:00, 283.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22542/47780 [01:15<01:15, 333.45 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23549/47780 [01:15<01:17, 313.54 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24311/47780 [01:15<01:16, 304.91 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22501/47780 [01:15<01:31, 277.75 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22346/47780 [01:15<01:22, 306.49 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22749/47780 [01:15<01:27, 284.71 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23155/47780 [01:15<01:17, 319.07 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13498/47780 [01:15<01:53, 300.86 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22581/47780 [01:15<01:13, 343.84 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23584/47780 [01:15<01:14, 323.26 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24343/47780 [01:15<01:16, 305.72 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22532/47780 [01:15<01:28, 286.80 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22780/47780 [01:15<01:27, 285.33 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23188/47780 [01:15<01:16, 319.88 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22377/47780 [01:15<01:33, 272.36 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13530/47780 [01:15<01:56, 293.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22618/47780 [01:15<01:13, 343.93 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23626/47780 [01:15<01:09, 347.72 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24377/47780 [01:15<01:16, 304.16 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22561/47780 [01:15<01:33, 268.98 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23226/47780 [01:15<01:14, 330.31 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22809/47780 [01:15<01:30, 277.28 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22411/47780 [01:15<01:29, 285.04 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13563/47780 [01:15<01:52, 303.09 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22666/47780 [01:15<01:06, 378.72 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23663/47780 [01:15<01:09, 346.05 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24408/47780 [01:15<01:17, 300.01 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22589/47780 [01:15<01:33, 269.22 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22840/47780 [01:15<01:29, 280.16 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23261/47780 [01:15<01:16, 321.52 examples/s]
Tokenizing train dataset (num_proc=32):  28%|██▊       | 13603/47780 [01:15<01:43, 330.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22443/47780 [01:15<01:26, 291.48 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22705/47780 [01:15<01:07, 368.93 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23698/47780 [01:15<01:10, 339.49 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24441/47780 [01:15<01:16, 304.97 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22617/47780 [01:15<01:34, 266.01 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22875/47780 [01:15<01:25, 291.81 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23294/47780 [01:15<01:17, 314.27 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22479/47780 [01:15<01:22, 306.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13637/47780 [01:15<01:44, 325.39 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22749/47780 [01:15<01:05, 385.09 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23738/47780 [01:15<01:08, 352.73 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24472/47780 [01:15<01:16, 302.88 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22644/47780 [01:15<01:36, 260.31 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23327/47780 [01:15<01:16, 317.75 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22511/47780 [01:15<01:21, 310.04 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22905/47780 [01:15<01:29, 276.81 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13670/47780 [01:15<01:49, 312.18 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22792/47780 [01:15<01:02, 397.93 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24507/47780 [01:15<01:14, 313.20 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23774/47780 [01:15<01:13, 324.95 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22680/47780 [01:15<01:27, 286.52 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22553/47780 [01:15<01:14, 338.84 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23359/47780 [01:15<01:21, 301.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22933/47780 [01:15<01:33, 266.07 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▊       | 13706/47780 [01:15<01:47, 315.51 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24539/47780 [01:15<01:13, 314.44 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23807/47780 [01:16<01:16, 312.31 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22832/47780 [01:16<01:14, 335.99 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22709/47780 [01:15<01:29, 281.04 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22588/47780 [01:15<01:17, 323.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23398/47780 [01:16<01:17, 315.48 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22960/47780 [01:16<01:38, 253.03 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13738/47780 [01:15<01:52, 303.16 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24571/47780 [01:16<01:15, 309.25 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23839/47780 [01:16<01:17, 308.65 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22745/47780 [01:16<01:23, 300.16 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22868/47780 [01:16<01:14, 334.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22623/47780 [01:16<01:16, 329.78 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22994/47780 [01:16<01:29, 275.97 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23430/47780 [01:16<01:21, 299.71 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13770/47780 [01:16<01:51, 304.52 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24602/47780 [01:16<01:16, 302.35 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23872/47780 [01:16<01:17, 309.91 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22776/47780 [01:16<01:24, 295.67 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22662/47780 [01:16<01:12, 345.01 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22903/47780 [01:16<01:21, 303.68 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23026/47780 [01:16<01:26, 285.91 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23465/47780 [01:16<01:18, 310.49 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13802/47780 [01:16<01:52, 302.07 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24638/47780 [01:16<01:14, 311.78 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22807/47780 [01:16<01:26, 290.34 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23904/47780 [01:16<01:20, 294.81 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22697/47780 [01:16<01:14, 337.21 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22935/47780 [01:16<01:21, 304.93 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23058/47780 [01:16<01:25, 288.98 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23498/47780 [01:16<01:19, 305.68 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13836/47780 [01:16<01:49, 310.67 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24673/47780 [01:16<01:12, 319.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22844/47780 [01:16<01:19, 312.92 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22734/47780 [01:16<01:13, 342.68 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23094/47780 [01:16<01:20, 307.35 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23934/47780 [01:16<01:29, 265.97 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22970/47780 [01:16<01:20, 307.08 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23532/47780 [01:16<01:19, 305.17 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13870/47780 [01:16<01:50, 307.07 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24712/47780 [01:16<01:08, 335.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22876/47780 [01:16<01:22, 300.81 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23127/47780 [01:16<01:19, 311.96 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22770/47780 [01:16<01:15, 332.00 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23002/47780 [01:16<01:20, 306.70 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23963/47780 [01:16<01:29, 266.64 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13911/47780 [01:16<01:41, 332.39 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24746/47780 [01:16<01:09, 332.69 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23565/47780 [01:16<01:23, 289.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22912/47780 [01:16<01:19, 314.18 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23163/47780 [01:16<01:16, 322.30 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23040/47780 [01:16<01:16, 323.91 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22804/47780 [01:16<01:16, 327.01 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23993/47780 [01:16<01:28, 269.77 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13946/47780 [01:16<01:41, 333.63 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24780/47780 [01:16<01:12, 316.83 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23595/47780 [01:16<01:28, 274.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22956/47780 [01:16<01:11, 346.20 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23196/47780 [01:16<01:15, 324.10 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23088/47780 [01:16<01:07, 364.05 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22842/47780 [01:16<01:13, 338.49 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24021/47780 [01:16<01:28, 268.64 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 13981/47780 [01:16<01:45, 319.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24812/47780 [01:16<01:14, 306.98 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22991/47780 [01:16<01:15, 327.97 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22881/47780 [01:16<01:10, 352.94 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23623/47780 [01:16<01:37, 246.70 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23127/47780 [01:16<01:10, 348.93 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23229/47780 [01:16<01:24, 289.06 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24049/47780 [01:16<01:34, 250.65 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14014/47780 [01:16<01:46, 315.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24843/47780 [01:16<01:15, 304.42 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23033/47780 [01:16<01:10, 348.74 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23663/47780 [01:16<01:25, 283.15 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22917/47780 [01:16<01:13, 338.91 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23261/47780 [01:16<01:22, 297.35 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23163/47780 [01:17<01:12, 338.94 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24081/47780 [01:17<01:28, 269.09 examples/s]
Tokenizing train dataset (num_proc=32):  29%|██▉       | 14047/47780 [01:16<01:46, 316.04 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24886/47780 [01:17<01:07, 337.45 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23069/47780 [01:17<01:11, 345.34 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23696/47780 [01:17<01:23, 289.46 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22952/47780 [01:17<01:15, 327.55 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23294/47780 [01:17<01:20, 302.99 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24114/47780 [01:17<01:24, 279.70 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23198/47780 [01:17<01:15, 327.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14081/47780 [01:17<01:52, 299.14 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24920/47780 [01:17<01:17, 296.62 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23726/47780 [01:17<01:24, 285.81 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23105/47780 [01:17<01:15, 327.16 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22985/47780 [01:17<01:16, 324.85 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24154/47780 [01:17<01:16, 309.78 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23325/47780 [01:17<01:23, 291.87 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23233/47780 [01:17<01:17, 316.34 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14112/47780 [01:17<01:52, 298.52 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24954/47780 [01:17<01:14, 304.90 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23145/47780 [01:17<01:11, 343.85 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23765/47780 [01:17<01:17, 307.91 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23018/47780 [01:17<01:17, 318.96 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24186/47780 [01:17<01:16, 309.18 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23356/47780 [01:17<01:22, 296.70 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23268/47780 [01:17<01:16, 319.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14148/47780 [01:17<01:47, 312.46 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24986/47780 [01:17<01:14, 305.66 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23802/47780 [01:17<01:13, 324.87 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24218/47780 [01:17<01:15, 311.93 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23180/47780 [01:17<01:17, 317.15 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23387/47780 [01:17<01:22, 296.48 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23050/47780 [01:17<01:24, 292.85 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23302/47780 [01:17<01:15, 324.31 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14182/47780 [01:17<01:44, 320.16 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25018/47780 [01:17<01:15, 302.89 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23835/47780 [01:17<01:13, 326.21 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23223/47780 [01:17<01:11, 343.78 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23423/47780 [01:17<01:18, 311.98 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23087/47780 [01:17<01:19, 310.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23335/47780 [01:17<01:16, 318.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14221/47780 [01:17<01:40, 332.70 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24250/47780 [01:17<01:23, 281.74 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23868/47780 [01:17<01:13, 323.51 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25049/47780 [01:17<01:18, 291.35 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23455/47780 [01:17<01:17, 313.90 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23119/47780 [01:17<01:18, 313.00 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23373/47780 [01:17<01:12, 335.47 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14256/47780 [01:17<01:39, 337.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23258/47780 [01:17<01:16, 320.54 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24279/47780 [01:17<01:26, 272.18 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23905/47780 [01:17<01:10, 336.89 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25089/47780 [01:17<01:12, 311.55 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23153/47780 [01:17<01:17, 317.13 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23413/47780 [01:17<01:09, 350.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23487/47780 [01:17<01:23, 291.78 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23291/47780 [01:17<01:19, 306.88 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14291/47780 [01:17<01:43, 322.53 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23947/47780 [01:17<01:07, 353.65 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24307/47780 [01:17<01:34, 247.70 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25122/47780 [01:17<01:12, 313.23 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23188/47780 [01:17<01:15, 326.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23449/47780 [01:17<01:08, 353.22 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23517/47780 [01:17<01:25, 283.80 examples/s]
Tokenizing train dataset (num_proc=32):  30%|██▉       | 14328/47780 [01:17<01:39, 335.72 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23324/47780 [01:17<01:22, 297.21 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24333/47780 [01:17<01:33, 250.77 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25154/47780 [01:17<01:11, 314.83 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23983/47780 [01:17<01:13, 325.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23221/47780 [01:17<01:18, 312.71 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23547/47780 [01:17<01:24, 286.35 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23485/47780 [01:17<01:12, 336.88 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14362/47780 [01:17<01:48, 308.16 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24363/47780 [01:18<01:29, 261.39 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23355/47780 [01:18<01:27, 279.78 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25189/47780 [01:18<01:10, 321.59 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24017/47780 [01:18<01:16, 311.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23255/47780 [01:18<01:18, 313.59 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23576/47780 [01:18<01:25, 283.82 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23519/47780 [01:18<01:14, 324.63 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14395/47780 [01:18<01:50, 301.62 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24397/47780 [01:18<01:24, 277.83 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23384/47780 [01:18<01:30, 268.93 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25222/47780 [01:18<01:13, 306.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24051/47780 [01:18<01:15, 316.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23295/47780 [01:18<01:13, 334.41 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23605/47780 [01:18<01:27, 276.02 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23555/47780 [01:18<01:13, 331.71 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14428/47780 [01:18<01:48, 306.13 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23419/47780 [01:18<01:24, 286.66 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24426/47780 [01:18<01:29, 262.09 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24084/47780 [01:18<01:14, 316.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25253/47780 [01:18<01:16, 293.70 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23643/47780 [01:18<01:20, 299.08 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23600/47780 [01:18<01:07, 357.12 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23329/47780 [01:18<01:17, 313.73 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14464/47780 [01:18<01:48, 307.26 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24480/47780 [01:18<01:09, 336.83 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23449/47780 [01:18<01:26, 280.84 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24116/47780 [01:18<01:14, 316.76 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25283/47780 [01:18<01:21, 274.71 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23638/47780 [01:18<01:06, 363.50 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23361/47780 [01:18<01:18, 309.28 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23674/47780 [01:18<01:24, 286.10 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14495/47780 [01:18<01:50, 301.12 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24515/47780 [01:18<01:09, 334.00 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23478/47780 [01:18<01:26, 281.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24155/47780 [01:18<01:12, 327.29 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25311/47780 [01:18<01:22, 270.91 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23678/47780 [01:18<01:04, 373.88 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23393/47780 [01:18<01:19, 308.56 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23717/47780 [01:18<01:14, 322.27 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23507/47780 [01:18<01:27, 276.81 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24192/47780 [01:18<01:10, 335.62 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14526/47780 [01:18<01:59, 278.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24550/47780 [01:18<01:13, 314.35 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25343/47780 [01:18<01:19, 280.53 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23716/47780 [01:18<01:06, 359.26 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23750/47780 [01:18<01:14, 323.66 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23425/47780 [01:18<01:22, 295.30 examples/s]
Tokenizing train dataset (num_proc=32):  30%|███       | 14558/47780 [01:18<01:54, 289.77 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23546/47780 [01:18<01:21, 298.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24238/47780 [01:18<01:04, 362.91 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24588/47780 [01:18<01:12, 318.27 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25374/47780 [01:18<01:18, 285.53 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23753/47780 [01:18<01:06, 362.27 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23784/47780 [01:18<01:13, 328.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23461/47780 [01:18<01:18, 309.85 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24277/47780 [01:18<01:04, 362.50 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23579/47780 [01:18<01:21, 297.46 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14588/47780 [01:18<01:58, 280.40 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24626/47780 [01:18<01:09, 331.56 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25410/47780 [01:18<01:14, 299.81 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23790/47780 [01:18<01:08, 351.72 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23820/47780 [01:18<01:14, 321.88 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23493/47780 [01:18<01:21, 298.64 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24314/47780 [01:18<01:04, 364.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23621/47780 [01:18<01:12, 331.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14618/47780 [01:18<01:56, 285.71 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25446/47780 [01:18<01:11, 313.30 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24660/47780 [01:18<01:11, 323.01 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23528/47780 [01:18<01:19, 306.59 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23853/47780 [01:18<01:19, 301.64 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23826/47780 [01:18<01:15, 318.38 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23661/47780 [01:18<01:09, 347.05 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24353/47780 [01:18<01:03, 367.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14656/47780 [01:18<01:47, 309.06 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25485/47780 [01:19<01:06, 334.95 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24693/47780 [01:19<01:15, 305.87 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23559/47780 [01:19<01:19, 304.18 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23871/47780 [01:19<01:09, 346.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23885/47780 [01:19<01:21, 293.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23698/47780 [01:19<01:08, 349.50 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24390/47780 [01:19<01:06, 351.23 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14688/47780 [01:19<01:53, 291.98 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25519/47780 [01:19<01:07, 328.30 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24724/47780 [01:19<01:18, 294.94 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23592/47780 [01:19<01:19, 304.61 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23907/47780 [01:19<01:11, 335.04 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23915/47780 [01:19<01:25, 280.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23734/47780 [01:19<01:09, 344.58 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24433/47780 [01:19<01:03, 370.19 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14718/47780 [01:19<01:54, 288.05 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24760/47780 [01:19<01:15, 304.00 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25552/47780 [01:19<01:15, 292.51 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23626/47780 [01:19<01:16, 314.33 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23944/47780 [01:19<01:25, 279.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23772/47780 [01:19<01:07, 354.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23941/47780 [01:19<01:15, 316.02 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14755/47780 [01:19<01:46, 310.84 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24471/47780 [01:19<01:09, 334.64 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24795/47780 [01:19<01:12, 316.52 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25591/47780 [01:19<01:09, 318.60 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23658/47780 [01:19<01:17, 312.79 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23810/47780 [01:19<01:06, 358.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23973/47780 [01:19<01:26, 273.65 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23974/47780 [01:19<01:16, 312.69 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24508/47780 [01:19<01:07, 343.92 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14787/47780 [01:19<01:54, 287.14 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24827/47780 [01:19<01:13, 311.50 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25629/47780 [01:19<01:06, 331.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23690/47780 [01:19<01:22, 290.81 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23846/47780 [01:19<01:11, 334.99 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24007/47780 [01:19<01:18, 304.56 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24001/47780 [01:19<01:34, 250.40 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25663/47780 [01:19<01:06, 330.44 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24861/47780 [01:19<01:12, 315.04 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24543/47780 [01:19<01:10, 327.41 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14818/47780 [01:19<01:58, 278.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23721/47780 [01:19<01:22, 293.29 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24041/47780 [01:19<01:16, 310.75 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23880/47780 [01:19<01:12, 331.29 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24037/47780 [01:19<01:25, 278.02 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24894/47780 [01:19<01:12, 315.01 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14847/47780 [01:19<01:58, 278.46 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24577/47780 [01:19<01:13, 313.99 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25697/47780 [01:19<01:10, 315.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23751/47780 [01:19<01:23, 288.17 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24073/47780 [01:19<01:18, 303.27 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24066/47780 [01:19<01:27, 270.74 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23914/47780 [01:19<01:17, 307.21 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25731/47780 [01:19<01:09, 318.67 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14876/47780 [01:19<02:00, 272.40 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24609/47780 [01:19<01:15, 308.91 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24926/47780 [01:19<01:17, 296.33 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23780/47780 [01:19<01:26, 276.54 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24104/47780 [01:19<01:22, 286.65 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23946/47780 [01:19<01:19, 301.03 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24094/47780 [01:19<01:35, 248.83 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███       | 14906/47780 [01:19<01:58, 277.24 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24641/47780 [01:19<01:15, 308.41 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24960/47780 [01:19<01:16, 298.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25764/47780 [01:19<01:12, 304.62 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23809/47780 [01:19<01:28, 271.40 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24134/47780 [01:19<01:21, 289.14 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24123/47780 [01:19<01:32, 254.51 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14937/47780 [01:19<01:55, 283.32 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23978/47780 [01:19<01:22, 287.30 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24676/47780 [01:20<01:14, 309.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25806/47780 [01:20<01:06, 332.77 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24991/47780 [01:20<01:19, 286.25 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23843/47780 [01:20<01:23, 287.30 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24168/47780 [01:20<01:18, 300.54 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24149/47780 [01:20<01:32, 255.79 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 14966/47780 [01:20<01:56, 281.99 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24009/47780 [01:20<01:23, 284.30 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24721/47780 [01:20<01:08, 337.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25840/47780 [01:20<01:07, 326.98 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25023/47780 [01:20<01:17, 292.26 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23876/47780 [01:20<01:19, 299.32 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24200/47780 [01:20<01:17, 302.73 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24175/47780 [01:20<01:35, 246.12 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24041/47780 [01:20<01:23, 284.69 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14995/47780 [01:20<02:01, 268.86 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25874/47780 [01:20<01:07, 323.92 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25053/47780 [01:20<01:18, 287.91 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24755/47780 [01:20<01:12, 317.17 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23907/47780 [01:20<01:22, 288.98 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24236/47780 [01:20<01:14, 315.36 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24076/47780 [01:20<01:18, 302.31 examples/s]
Tokenizing train dataset (num_proc=32):  31%|███▏      | 15025/47780 [01:20<01:58, 277.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25914/47780 [01:20<01:03, 345.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24200/47780 [01:20<01:40, 234.27 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25083/47780 [01:20<01:18, 288.01 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24791/47780 [01:20<01:09, 328.52 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23954/47780 [01:20<01:10, 336.32 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24269/47780 [01:20<01:13, 319.33 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24107/47780 [01:20<01:18, 301.31 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24229/47780 [01:20<01:34, 249.37 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25949/47780 [01:20<01:05, 330.79 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15053/47780 [01:20<02:06, 258.75 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24830/47780 [01:20<01:07, 338.55 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23988/47780 [01:20<01:10, 336.86 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25112/47780 [01:20<01:22, 273.16 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24309/47780 [01:20<01:10, 335.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24138/47780 [01:20<01:19, 297.59 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24869/47780 [01:20<01:04, 352.90 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25983/47780 [01:20<01:06, 326.70 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24264/47780 [01:20<01:29, 262.77 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25150/47780 [01:20<01:16, 296.28 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15080/47780 [01:20<02:14, 242.27 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24022/47780 [01:20<01:15, 313.03 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24347/47780 [01:20<01:08, 344.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24171/47780 [01:20<01:17, 306.42 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26017/47780 [01:20<01:05, 330.33 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24291/47780 [01:20<01:28, 264.56 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24905/47780 [01:20<01:08, 335.73 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25184/47780 [01:20<01:14, 304.95 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15105/47780 [01:20<02:18, 236.04 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24054/47780 [01:20<01:17, 304.80 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24384/47780 [01:20<01:08, 343.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24204/47780 [01:20<01:17, 305.84 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26051/47780 [01:20<01:08, 318.65 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24944/47780 [01:20<01:05, 350.85 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24318/47780 [01:20<01:33, 250.84 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25217/47780 [01:20<01:13, 308.60 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15129/47780 [01:20<02:23, 227.83 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24085/47780 [01:20<01:20, 293.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24419/47780 [01:20<01:14, 313.16 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24235/47780 [01:20<01:22, 286.83 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26084/47780 [01:20<01:08, 318.22 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24349/47780 [01:20<01:28, 265.59 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24980/47780 [01:20<01:05, 349.08 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25254/47780 [01:20<01:09, 322.42 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24115/47780 [01:20<01:21, 291.60 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15158/47780 [01:20<02:19, 234.60 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24457/47780 [01:20<01:10, 329.76 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24264/47780 [01:20<01:23, 281.99 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25024/47780 [01:20<01:01, 371.61 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25291/47780 [01:21<01:06, 335.94 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24376/47780 [01:20<01:30, 258.24 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26116/47780 [01:20<01:11, 301.56 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15183/47780 [01:20<02:16, 238.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24491/47780 [01:21<01:12, 319.78 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24145/47780 [01:21<01:29, 264.71 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25325/47780 [01:21<01:06, 336.66 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24406/47780 [01:21<01:26, 269.62 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26148/47780 [01:21<01:10, 306.13 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25062/47780 [01:21<01:06, 342.17 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24293/47780 [01:21<01:33, 250.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15207/47780 [01:21<02:20, 231.16 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24524/47780 [01:21<01:13, 315.41 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24181/47780 [01:21<01:23, 281.64 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25359/47780 [01:21<01:07, 330.57 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24435/47780 [01:21<01:26, 269.47 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26184/47780 [01:21<01:08, 314.77 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25097/47780 [01:21<01:06, 340.31 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24319/47780 [01:21<01:34, 247.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15231/47780 [01:21<02:23, 226.38 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24561/47780 [01:21<01:10, 327.29 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24210/47780 [01:21<01:27, 268.58 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25393/47780 [01:21<01:08, 325.51 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26221/47780 [01:21<01:05, 330.26 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24465/47780 [01:21<01:26, 268.96 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24352/47780 [01:21<01:28, 264.15 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15261/47780 [01:21<02:14, 241.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25132/47780 [01:21<01:13, 308.82 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24595/47780 [01:21<01:13, 316.52 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24238/47780 [01:21<01:26, 271.48 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25426/47780 [01:21<01:10, 316.02 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24493/47780 [01:21<01:25, 272.08 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26255/47780 [01:21<01:06, 325.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15287/47780 [01:21<02:13, 243.88 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25168/47780 [01:21<01:10, 321.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24380/47780 [01:21<01:32, 251.75 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24635/47780 [01:21<01:08, 336.09 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24266/47780 [01:21<01:28, 265.13 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26292/47780 [01:21<01:04, 334.81 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24521/47780 [01:21<01:27, 265.92 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25458/47780 [01:21<01:14, 300.12 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15318/47780 [01:21<02:05, 259.60 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24408/47780 [01:21<01:30, 256.89 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25202/47780 [01:21<01:12, 310.24 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24669/47780 [01:21<01:09, 333.42 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24296/47780 [01:21<01:26, 272.04 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26327/47780 [01:21<01:03, 338.68 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24552/47780 [01:21<01:24, 274.67 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15347/47780 [01:21<02:00, 268.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24434/47780 [01:21<01:30, 257.71 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25489/47780 [01:21<01:24, 264.60 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24703/47780 [01:21<01:08, 335.06 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25240/47780 [01:21<01:10, 318.92 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24333/47780 [01:21<01:18, 299.52 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26371/47780 [01:21<01:00, 356.16 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24580/47780 [01:21<01:24, 275.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15377/47780 [01:21<01:58, 274.45 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24460/47780 [01:21<01:34, 247.20 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25542/47780 [01:21<01:06, 332.82 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25273/47780 [01:21<01:11, 313.10 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24737/47780 [01:21<01:13, 314.42 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24364/47780 [01:21<01:24, 276.76 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24611/47780 [01:21<01:24, 273.40 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26407/47780 [01:21<01:03, 334.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15405/47780 [01:21<02:00, 269.35 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24490/47780 [01:21<01:29, 259.00 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25305/47780 [01:21<01:13, 306.98 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24770/47780 [01:21<01:12, 316.36 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25577/47780 [01:21<01:11, 310.88 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26449/47780 [01:21<01:00, 354.23 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24393/47780 [01:21<01:27, 266.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15438/47780 [01:21<01:55, 280.79 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24517/47780 [01:21<01:29, 258.96 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24639/47780 [01:22<01:43, 224.25 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25610/47780 [01:22<01:11, 309.12 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24802/47780 [01:22<01:16, 299.73 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25336/47780 [01:22<01:18, 285.33 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26486/47780 [01:22<01:00, 350.86 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24421/47780 [01:22<01:28, 264.21 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15470/47780 [01:22<01:51, 288.72 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24544/47780 [01:22<01:33, 248.87 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24676/47780 [01:22<01:28, 260.32 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25644/47780 [01:22<01:10, 311.78 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24833/47780 [01:22<01:18, 292.83 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25365/47780 [01:22<01:22, 272.41 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24452/47780 [01:22<01:24, 276.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26522/47780 [01:22<01:00, 352.97 examples/s]
Tokenizing train dataset (num_proc=32):  32%|███▏      | 15500/47780 [01:22<01:56, 276.17 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24577/47780 [01:22<01:25, 270.38 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24709/47780 [01:22<01:23, 276.36 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25677/47780 [01:22<01:12, 305.89 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24866/47780 [01:22<01:16, 299.43 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25397/47780 [01:22<01:18, 285.01 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26558/47780 [01:22<01:01, 343.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24480/47780 [01:22<01:29, 259.87 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15546/47780 [01:22<01:38, 327.65 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24612/47780 [01:22<01:20, 286.74 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24750/47780 [01:22<01:13, 311.60 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24899/47780 [01:22<01:15, 305.04 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25709/47780 [01:22<01:14, 296.57 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25432/47780 [01:22<01:14, 299.66 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26593/47780 [01:22<01:02, 337.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24511/47780 [01:22<01:26, 267.98 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15583/47780 [01:22<01:35, 335.67 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24645/47780 [01:22<01:18, 295.75 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25755/47780 [01:22<01:05, 337.66 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24783/47780 [01:22<01:19, 287.99 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25468/47780 [01:22<01:11, 313.08 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24932/47780 [01:22<01:19, 289.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26627/47780 [01:22<01:04, 327.27 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24539/47780 [01:22<01:28, 262.63 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15617/47780 [01:22<01:36, 332.87 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24680/47780 [01:22<01:15, 307.82 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25790/47780 [01:22<01:06, 330.12 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24963/47780 [01:22<01:17, 294.70 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25500/47780 [01:22<01:15, 294.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24814/47780 [01:22<01:23, 273.51 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26660/47780 [01:22<01:07, 313.87 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24566/47780 [01:22<01:28, 261.73 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15656/47780 [01:22<01:33, 341.96 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24711/47780 [01:22<01:18, 294.42 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25824/47780 [01:22<01:10, 312.01 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25530/47780 [01:22<01:16, 289.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24993/47780 [01:22<01:21, 280.50 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24843/47780 [01:22<01:26, 266.59 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24595/47780 [01:22<01:26, 266.77 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26692/47780 [01:22<01:08, 307.70 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15691/47780 [01:22<01:40, 318.37 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24741/47780 [01:22<01:23, 275.14 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25562/47780 [01:22<01:15, 296.17 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25858/47780 [01:22<01:09, 316.14 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25033/47780 [01:22<01:13, 309.94 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24872/47780 [01:22<01:24, 270.36 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24623/47780 [01:22<01:27, 264.42 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26731/47780 [01:22<01:04, 324.57 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15729/47780 [01:22<01:36, 331.85 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24769/47780 [01:22<01:27, 261.85 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25595/47780 [01:22<01:12, 304.53 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25895/47780 [01:22<01:06, 330.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25067/47780 [01:22<01:11, 318.35 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24900/47780 [01:22<01:23, 272.68 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24654/47780 [01:22<01:24, 274.28 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26764/47780 [01:22<01:05, 319.51 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15763/47780 [01:22<01:43, 309.63 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24812/47780 [01:22<01:14, 307.02 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25934/47780 [01:23<01:03, 344.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25632/47780 [01:23<01:09, 319.68 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24929/47780 [01:22<01:23, 274.61 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25101/47780 [01:23<01:15, 300.56 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24682/47780 [01:23<01:25, 269.50 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26799/47780 [01:23<01:04, 324.23 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15804/47780 [01:23<01:36, 329.92 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24845/47780 [01:23<01:13, 313.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25665/47780 [01:23<01:09, 319.04 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24958/47780 [01:23<01:22, 275.83 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25969/47780 [01:23<01:05, 330.50 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24710/47780 [01:23<01:25, 269.67 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26832/47780 [01:23<01:05, 318.10 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25138/47780 [01:23<01:13, 306.14 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24877/47780 [01:23<01:15, 304.18 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15838/47780 [01:23<01:43, 310.03 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25699/47780 [01:23<01:09, 317.69 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24986/47780 [01:23<01:24, 270.88 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24742/47780 [01:23<01:21, 283.88 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26003/47780 [01:23<01:08, 317.22 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25175/47780 [01:23<01:10, 321.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26864/47780 [01:23<01:08, 304.98 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25733/47780 [01:23<01:08, 320.37 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15875/47780 [01:23<01:40, 318.10 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25014/47780 [01:23<01:24, 270.47 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26044/47780 [01:23<01:03, 340.88 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24771/47780 [01:23<01:21, 282.41 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24908/47780 [01:23<01:23, 274.23 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25211/47780 [01:23<01:09, 323.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26895/47780 [01:23<01:10, 296.32 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25776/47780 [01:23<01:02, 352.02 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15913/47780 [01:23<01:36, 331.18 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25045/47780 [01:23<01:23, 272.35 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26082/47780 [01:23<01:01, 351.60 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24801/47780 [01:23<01:24, 271.02 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25247/47780 [01:23<01:08, 326.62 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26925/47780 [01:23<01:11, 290.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24937/47780 [01:23<01:32, 247.77 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15947/47780 [01:23<01:39, 319.74 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25073/47780 [01:23<01:25, 266.26 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26118/47780 [01:23<01:03, 342.57 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25814/47780 [01:23<01:07, 326.04 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25287/47780 [01:23<01:05, 343.41 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24829/47780 [01:23<01:26, 265.47 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26956/47780 [01:23<01:10, 296.05 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24963/47780 [01:23<01:39, 228.19 examples/s]
Tokenizing train dataset (num_proc=32):  33%|███▎      | 15983/47780 [01:23<01:37, 327.05 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25105/47780 [01:23<01:23, 271.86 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26153/47780 [01:23<01:06, 325.41 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24861/47780 [01:23<01:22, 277.73 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25322/47780 [01:23<01:07, 333.96 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25848/47780 [01:23<01:11, 306.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 26999/47780 [01:23<01:02, 330.69 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24990/47780 [01:23<01:38, 231.59 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16019/47780 [01:23<01:34, 336.02 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25139/47780 [01:23<01:18, 287.21 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26193/47780 [01:23<01:02, 343.79 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24889/47780 [01:23<01:23, 275.28 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25356/47780 [01:23<01:11, 314.66 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25880/47780 [01:23<01:15, 291.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27033/47780 [01:23<01:06, 311.66 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16054/47780 [01:23<01:33, 339.94 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25015/47780 [01:23<01:43, 220.51 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24917/47780 [01:23<01:22, 276.62 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25170/47780 [01:23<01:21, 277.97 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26228/47780 [01:23<01:05, 330.04 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25390/47780 [01:23<01:09, 321.24 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27071/47780 [01:23<01:03, 327.24 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25910/47780 [01:23<01:16, 284.38 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▎      | 16091/47780 [01:23<01:31, 345.08 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25047/47780 [01:23<01:33, 243.29 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24945/47780 [01:23<01:22, 277.58 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25198/47780 [01:23<01:21, 278.52 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26266/47780 [01:24<01:02, 343.87 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25428/47780 [01:24<01:06, 335.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25939/47780 [01:24<01:19, 274.43 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27105/47780 [01:24<01:07, 306.11 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16126/47780 [01:24<01:35, 330.38 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25072/47780 [01:24<01:34, 239.88 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25233/47780 [01:24<01:17, 292.18 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24973/47780 [01:24<01:28, 257.10 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25469/47780 [01:24<01:02, 356.43 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26301/47780 [01:24<01:08, 313.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25967/47780 [01:24<01:19, 275.90 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27143/47780 [01:24<01:03, 323.28 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16162/47780 [01:24<01:35, 331.58 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25098/47780 [01:24<01:34, 240.25 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25002/47780 [01:24<01:26, 263.35 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25263/47780 [01:24<01:20, 281.41 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25505/47780 [01:24<01:04, 347.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26333/47780 [01:24<01:08, 311.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25998/47780 [01:24<01:17, 282.19 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27176/47780 [01:24<01:06, 309.45 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25123/47780 [01:24<01:35, 237.54 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16196/47780 [01:24<01:43, 306.52 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25544/47780 [01:24<01:03, 352.09 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25296/47780 [01:24<01:19, 282.56 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25029/47780 [01:24<01:32, 245.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26027/47780 [01:24<01:17, 281.30 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26365/47780 [01:24<01:14, 288.62 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27214/47780 [01:24<01:04, 320.09 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25150/47780 [01:24<01:34, 238.74 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16228/47780 [01:24<01:45, 298.23 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25329/47780 [01:24<01:17, 289.19 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25580/47780 [01:24<01:05, 340.17 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26059/47780 [01:24<01:14, 292.27 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26398/47780 [01:24<01:12, 296.69 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25054/47780 [01:24<01:39, 229.53 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27250/47780 [01:24<01:02, 331.06 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25181/47780 [01:24<01:28, 255.71 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16261/47780 [01:24<01:43, 305.82 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25360/47780 [01:24<01:16, 291.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26090/47780 [01:24<01:13, 293.76 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25615/47780 [01:24<01:09, 320.80 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26430/47780 [01:24<01:10, 303.05 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25083/47780 [01:24<01:33, 243.08 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27285/47780 [01:24<01:03, 322.05 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25209/47780 [01:24<01:27, 256.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16292/47780 [01:24<01:43, 303.66 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25392/47780 [01:24<01:19, 280.48 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25648/47780 [01:24<01:09, 318.95 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26461/47780 [01:24<01:13, 291.58 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27319/47780 [01:24<01:02, 326.74 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26120/47780 [01:24<01:25, 252.06 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25108/47780 [01:24<01:45, 214.60 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16323/47780 [01:24<01:42, 305.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25250/47780 [01:24<01:16, 293.34 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25434/47780 [01:24<01:10, 315.59 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25690/47780 [01:24<01:04, 343.40 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26493/47780 [01:24<01:14, 287.64 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27353/47780 [01:24<01:04, 316.42 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26172/47780 [01:24<01:07, 321.68 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25144/47780 [01:24<01:29, 251.58 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16358/47780 [01:24<01:39, 314.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25280/47780 [01:24<01:18, 285.71 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25466/47780 [01:24<01:11, 313.10 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25729/47780 [01:24<01:01, 356.32 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26529/47780 [01:24<01:10, 300.30 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27385/47780 [01:24<01:05, 310.50 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26213/47780 [01:24<01:04, 335.03 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25171/47780 [01:24<01:32, 244.98 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16390/47780 [01:24<01:44, 301.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25309/47780 [01:24<01:22, 272.60 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25499/47780 [01:24<01:10, 315.78 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25771/47780 [01:25<00:59, 370.65 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26566/47780 [01:25<01:06, 319.61 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27418/47780 [01:25<01:06, 307.74 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26252/47780 [01:25<01:02, 346.12 examples/s]
Tokenizing train dataset (num_proc=32):  34%|███▍      | 16422/47780 [01:25<01:43, 303.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25342/47780 [01:25<01:18, 287.36 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25197/47780 [01:25<01:37, 232.53 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25531/47780 [01:25<01:10, 315.58 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25809/47780 [01:25<01:01, 356.49 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26599/47780 [01:25<01:06, 318.63 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26291/47780 [01:25<01:00, 354.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27449/47780 [01:25<01:08, 295.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16453/47780 [01:25<01:47, 292.05 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25372/47780 [01:25<01:19, 283.02 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25223/47780 [01:25<01:35, 237.28 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25563/47780 [01:25<01:11, 309.62 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25846/47780 [01:25<01:01, 356.45 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26640/47780 [01:25<01:01, 344.66 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27479/47780 [01:25<01:09, 290.66 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26328/47780 [01:25<01:02, 342.94 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16486/47780 [01:25<01:44, 299.63 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25401/47780 [01:25<01:20, 278.02 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25256/47780 [01:25<01:27, 256.74 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25595/47780 [01:25<01:17, 286.44 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25882/47780 [01:25<01:06, 328.65 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26675/47780 [01:25<01:05, 319.83 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26363/47780 [01:25<01:02, 341.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27513/47780 [01:25<01:07, 298.21 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25292/47780 [01:25<01:20, 279.12 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25429/47780 [01:25<01:23, 268.56 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16517/47780 [01:25<01:49, 285.83 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25627/47780 [01:25<01:15, 292.43 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25921/47780 [01:25<01:04, 340.63 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26708/47780 [01:25<01:05, 319.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26400/47780 [01:25<01:01, 345.79 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16547/47780 [01:25<01:48, 288.63 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25462/47780 [01:25<01:18, 282.58 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25322/47780 [01:25<01:22, 272.75 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27545/47780 [01:25<01:21, 248.40 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25657/47780 [01:25<01:17, 284.62 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25956/47780 [01:25<01:04, 339.30 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26744/47780 [01:25<01:04, 327.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26438/47780 [01:25<01:02, 343.13 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25492/47780 [01:25<01:17, 287.49 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16589/47780 [01:25<01:37, 320.35 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25350/47780 [01:25<01:26, 260.54 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27600/47780 [01:25<01:02, 322.75 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25994/47780 [01:25<01:02, 350.71 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25686/47780 [01:25<01:19, 279.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26778/47780 [01:25<01:07, 313.29 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26473/47780 [01:25<01:07, 316.91 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25525/47780 [01:25<01:15, 293.14 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16622/47780 [01:25<01:45, 296.25 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26031/47780 [01:25<01:01, 352.45 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25715/47780 [01:25<01:18, 280.04 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27635/47780 [01:25<01:03, 316.31 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25377/47780 [01:25<01:36, 232.38 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26810/47780 [01:25<01:11, 295.17 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26506/47780 [01:25<01:08, 308.55 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25556/47780 [01:25<01:17, 287.98 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16668/47780 [01:25<01:31, 340.59 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26067/47780 [01:25<01:02, 349.59 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25744/47780 [01:25<01:20, 273.60 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27670/47780 [01:25<01:07, 297.50 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25401/47780 [01:25<01:42, 219.02 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26840/47780 [01:25<01:14, 281.46 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26538/47780 [01:25<01:08, 309.87 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25586/47780 [01:25<01:17, 288.20 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▍      | 16703/47780 [01:25<01:35, 325.00 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25777/47780 [01:25<01:16, 289.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26103/47780 [01:26<01:05, 332.51 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27702/47780 [01:25<01:07, 296.50 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26570/47780 [01:26<01:10, 299.70 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26869/47780 [01:26<01:16, 271.71 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25615/47780 [01:26<01:20, 275.93 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25424/47780 [01:26<01:51, 201.33 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16738/47780 [01:26<01:33, 331.85 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25809/47780 [01:26<01:13, 298.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26137/47780 [01:26<01:07, 321.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27742/47780 [01:26<01:02, 321.17 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26605/47780 [01:26<01:08, 310.16 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26897/47780 [01:26<01:17, 268.46 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25648/47780 [01:26<01:16, 287.97 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25451/47780 [01:26<01:44, 214.20 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25852/47780 [01:26<01:05, 332.76 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16773/47780 [01:26<01:34, 327.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26173/47780 [01:26<01:06, 325.37 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27777/47780 [01:26<01:02, 318.16 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26640/47780 [01:26<01:06, 317.81 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26924/47780 [01:26<01:19, 262.56 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25678/47780 [01:26<01:17, 284.63 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25483/47780 [01:26<01:35, 234.12 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25886/47780 [01:26<01:05, 334.24 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16807/47780 [01:26<01:36, 322.20 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26211/47780 [01:26<01:06, 326.18 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27811/47780 [01:26<01:04, 307.67 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26954/47780 [01:26<01:17, 268.42 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26672/47780 [01:26<01:10, 301.29 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25709/47780 [01:26<01:17, 285.29 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25925/47780 [01:26<01:02, 347.09 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25507/47780 [01:26<01:36, 230.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16840/47780 [01:26<01:39, 310.20 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26244/47780 [01:26<01:06, 323.12 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27846/47780 [01:26<01:03, 315.68 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26703/47780 [01:26<01:10, 297.03 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25960/47780 [01:26<01:05, 335.25 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25531/47780 [01:26<01:37, 227.72 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25738/47780 [01:26<01:22, 268.39 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16876/47780 [01:26<01:36, 320.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26981/47780 [01:26<01:27, 238.63 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26281/47780 [01:26<01:04, 333.05 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27878/47780 [01:26<01:04, 309.61 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26739/47780 [01:26<01:07, 313.37 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25554/47780 [01:26<01:40, 221.81 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25994/47780 [01:26<01:07, 322.31 examples/s]
Tokenizing train dataset (num_proc=32):  35%|███▌      | 16909/47780 [01:26<01:36, 319.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27030/47780 [01:26<01:08, 301.53 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25766/47780 [01:26<01:30, 242.49 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26315/47780 [01:26<01:06, 320.44 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27910/47780 [01:26<01:05, 303.61 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26771/47780 [01:26<01:11, 293.21 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25581/47780 [01:26<01:35, 232.51 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26027/47780 [01:26<01:07, 324.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16942/47780 [01:26<01:36, 318.92 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25797/47780 [01:26<01:24, 259.99 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27062/47780 [01:26<01:12, 287.40 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26350/47780 [01:26<01:08, 314.22 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27941/47780 [01:26<01:05, 304.51 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26801/47780 [01:26<01:11, 295.06 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25605/47780 [01:26<01:35, 231.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26063/47780 [01:26<01:06, 327.53 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 16974/47780 [01:26<01:40, 305.44 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27097/47780 [01:26<01:08, 299.97 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25825/47780 [01:26<01:28, 247.21 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27972/47780 [01:26<01:07, 292.55 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26382/47780 [01:26<01:12, 296.30 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25645/47780 [01:26<01:20, 276.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26837/47780 [01:26<01:09, 299.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26097/47780 [01:26<01:08, 316.39 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17008/47780 [01:26<01:38, 311.69 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27129/47780 [01:26<01:08, 303.59 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25853/47780 [01:26<01:26, 252.69 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26412/47780 [01:27<01:12, 295.95 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28002/47780 [01:26<01:08, 288.47 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25677/47780 [01:27<01:18, 282.51 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26868/47780 [01:27<01:11, 291.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17050/47780 [01:26<01:30, 340.68 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26129/47780 [01:27<01:11, 302.61 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27160/47780 [01:27<01:09, 295.54 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25879/47780 [01:27<01:28, 246.64 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28033/47780 [01:27<01:07, 294.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26444/47780 [01:27<01:12, 294.50 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17087/47780 [01:27<01:29, 343.02 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25706/47780 [01:27<01:22, 268.67 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26899/47780 [01:27<01:12, 288.31 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26160/47780 [01:27<01:15, 286.92 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27190/47780 [01:27<01:13, 280.62 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25907/47780 [01:27<01:26, 252.91 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26475/47780 [01:27<01:12, 295.47 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28063/47780 [01:27<01:10, 280.02 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17122/47780 [01:27<01:29, 340.94 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25734/47780 [01:27<01:22, 266.09 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26199/47780 [01:27<01:08, 314.79 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26928/47780 [01:27<01:17, 268.05 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25937/47780 [01:27<01:22, 265.91 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27223/47780 [01:27<01:11, 286.36 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28099/47780 [01:27<01:05, 299.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26507/47780 [01:27<01:12, 292.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17165/47780 [01:27<01:23, 366.61 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25773/47780 [01:27<01:13, 300.66 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26969/47780 [01:27<01:07, 306.14 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25964/47780 [01:27<01:22, 264.26 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27253/47780 [01:27<01:11, 288.88 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26231/47780 [01:27<01:13, 293.14 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26542/47780 [01:27<01:08, 308.60 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28130/47780 [01:27<01:06, 295.34 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25804/47780 [01:27<01:15, 290.64 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17202/47780 [01:27<01:30, 336.45 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27001/47780 [01:27<01:09, 300.01 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25991/47780 [01:27<01:23, 259.95 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27283/47780 [01:27<01:12, 282.50 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26267/47780 [01:27<01:11, 301.61 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28166/47780 [01:27<01:03, 310.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26575/47780 [01:27<01:11, 297.74 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25834/47780 [01:27<01:17, 283.63 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17237/47780 [01:27<01:30, 336.18 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27318/47780 [01:27<01:07, 301.39 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26018/47780 [01:27<01:23, 259.65 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27033/47780 [01:27<01:13, 283.21 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28199/47780 [01:27<01:02, 315.74 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26298/47780 [01:27<01:13, 291.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26609/47780 [01:27<01:08, 309.50 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25866/47780 [01:27<01:15, 290.59 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17275/47780 [01:27<01:29, 341.08 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26047/47780 [01:27<01:22, 262.62 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27349/47780 [01:27<01:09, 293.68 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26328/47780 [01:27<01:13, 293.17 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28231/47780 [01:27<01:04, 302.69 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26641/47780 [01:27<01:09, 302.17 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27062/47780 [01:27<01:23, 247.96 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25896/47780 [01:27<01:18, 277.56 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▌      | 17310/47780 [01:27<01:31, 332.11 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26077/47780 [01:27<01:20, 270.16 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27379/47780 [01:27<01:11, 285.56 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26359/47780 [01:27<01:13, 291.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28262/47780 [01:27<01:05, 298.44 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27094/47780 [01:27<01:18, 263.44 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26672/47780 [01:27<01:17, 273.46 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25927/47780 [01:27<01:16, 286.35 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26107/47780 [01:27<01:17, 278.73 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17344/47780 [01:27<01:35, 319.94 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27412/47780 [01:27<01:09, 295.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26391/47780 [01:27<01:12, 293.22 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28292/47780 [01:27<01:10, 276.85 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26700/47780 [01:28<01:17, 272.35 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27122/47780 [01:27<01:21, 251.95 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25968/47780 [01:27<01:09, 314.47 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17377/47780 [01:27<01:35, 319.48 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27444/47780 [01:28<01:07, 301.96 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26135/47780 [01:28<01:23, 260.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26421/47780 [01:28<01:14, 288.40 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28322/47780 [01:28<01:08, 283.15 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26728/47780 [01:28<01:19, 265.69 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26001/47780 [01:28<01:09, 315.27 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27148/47780 [01:28<01:24, 243.77 examples/s]
Tokenizing train dataset (num_proc=32):  36%|███▋      | 17414/47780 [01:28<01:31, 333.43 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27475/47780 [01:28<01:06, 304.23 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26162/47780 [01:28<01:23, 260.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26452/47780 [01:28<01:13, 291.43 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28351/47780 [01:28<01:09, 280.13 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26755/47780 [01:28<01:22, 255.72 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27174/47780 [01:28<01:23, 245.58 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27514/47780 [01:28<01:01, 327.01 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17448/47780 [01:28<01:35, 317.10 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26033/47780 [01:28<01:13, 296.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26193/47780 [01:28<01:19, 271.62 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26482/47780 [01:28<01:14, 286.71 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28388/47780 [01:28<01:05, 297.27 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27554/47780 [01:28<00:58, 343.02 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27208/47780 [01:28<01:21, 252.13 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17483/47780 [01:28<01:33, 322.92 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26063/47780 [01:28<01:14, 290.96 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26782/47780 [01:28<01:28, 238.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26221/47780 [01:28<01:20, 267.11 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26511/47780 [01:28<01:17, 272.75 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28424/47780 [01:28<01:01, 313.93 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27240/47780 [01:28<01:16, 270.06 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17516/47780 [01:28<01:36, 314.08 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26808/47780 [01:28<01:28, 236.85 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26248/47780 [01:28<01:23, 258.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27589/47780 [01:28<01:04, 315.20 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26543/47780 [01:28<01:14, 285.60 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26093/47780 [01:28<01:23, 260.58 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28462/47780 [01:28<00:58, 330.25 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27272/47780 [01:28<01:12, 281.16 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17550/47780 [01:28<01:36, 314.51 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26274/47780 [01:28<01:23, 257.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27628/47780 [01:28<01:00, 332.65 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26833/47780 [01:28<01:33, 223.71 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26121/47780 [01:28<01:22, 260.97 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26572/47780 [01:28<01:20, 265.03 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28496/47780 [01:28<01:01, 314.04 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27308/47780 [01:28<01:08, 299.93 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17582/47780 [01:28<01:35, 315.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26302/47780 [01:28<01:22, 260.87 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26856/47780 [01:28<01:32, 225.16 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27663/47780 [01:28<01:05, 306.53 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26600/47780 [01:28<01:19, 267.19 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26148/47780 [01:28<01:27, 247.57 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28528/47780 [01:28<01:02, 305.91 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27339/47780 [01:28<01:08, 298.72 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17619/47780 [01:28<01:33, 324.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26329/47780 [01:28<01:22, 261.16 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26880/47780 [01:28<01:32, 226.84 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27697/47780 [01:28<01:03, 315.33 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26627/47780 [01:28<01:19, 265.00 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28559/47780 [01:28<01:04, 297.39 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26174/47780 [01:28<01:30, 238.21 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27370/47780 [01:28<01:08, 296.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17655/47780 [01:28<01:32, 327.03 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26356/47780 [01:28<01:24, 253.93 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26905/47780 [01:28<01:31, 228.14 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26655/47780 [01:28<01:18, 268.99 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27732/47780 [01:28<01:05, 304.60 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26199/47780 [01:28<01:29, 241.18 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27400/47780 [01:28<01:08, 295.94 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28589/47780 [01:28<01:10, 270.98 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26382/47780 [01:28<01:25, 250.20 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17688/47780 [01:28<01:38, 306.64 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26934/47780 [01:29<01:26, 240.21 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26684/47780 [01:28<01:17, 272.09 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27768/47780 [01:29<01:02, 319.35 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26224/47780 [01:29<01:33, 231.09 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27430/47780 [01:29<01:10, 290.70 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26414/47780 [01:29<01:19, 270.06 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28617/47780 [01:29<01:16, 251.92 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17726/47780 [01:29<01:33, 320.02 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26715/47780 [01:29<01:14, 282.92 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27805/47780 [01:29<00:59, 333.36 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26960/47780 [01:29<01:31, 227.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26251/47780 [01:29<01:29, 241.61 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26448/47780 [01:29<01:15, 283.77 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27460/47780 [01:29<01:16, 265.94 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28645/47780 [01:29<01:13, 259.10 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17759/47780 [01:29<01:36, 312.37 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26748/47780 [01:29<01:11, 293.39 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 26998/47780 [01:29<01:17, 269.08 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27839/47780 [01:29<01:02, 317.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26276/47780 [01:29<01:28, 242.71 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27495/47780 [01:29<01:11, 285.56 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26477/47780 [01:29<01:15, 281.82 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17805/47780 [01:29<01:25, 349.70 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28672/47780 [01:29<01:16, 248.71 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27026/47780 [01:29<01:17, 268.92 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26779/47780 [01:29<01:13, 284.15 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27875/47780 [01:29<01:01, 325.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26307/47780 [01:29<01:23, 257.34 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26507/47780 [01:29<01:14, 284.40 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27528/47780 [01:29<01:09, 291.52 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28698/47780 [01:29<01:17, 245.25 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27054/47780 [01:29<01:16, 269.25 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17841/47780 [01:29<01:28, 336.95 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26823/47780 [01:29<01:05, 318.84 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27908/47780 [01:29<01:00, 326.84 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26333/47780 [01:29<01:25, 252.16 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27566/47780 [01:29<01:03, 315.95 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26537/47780 [01:29<01:16, 279.04 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28723/47780 [01:29<01:19, 239.82 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27943/47780 [01:29<01:00, 329.99 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17875/47780 [01:29<01:33, 320.30 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26855/47780 [01:29<01:07, 308.44 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27082/47780 [01:29<01:20, 257.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26367/47780 [01:29<01:18, 271.20 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27599/47780 [01:29<01:03, 319.91 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26565/47780 [01:29<01:16, 275.86 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28757/47780 [01:29<01:11, 264.59 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27977/47780 [01:29<01:00, 328.82 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26887/47780 [01:29<01:07, 308.05 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26395/47780 [01:29<01:19, 267.47 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27110/47780 [01:29<01:26, 239.89 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27636/47780 [01:29<01:01, 326.95 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26606/47780 [01:29<01:08, 307.61 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28784/47780 [01:29<01:11, 266.04 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26919/47780 [01:29<01:07, 310.99 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28011/47780 [01:29<01:02, 314.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26425/47780 [01:29<01:17, 273.85 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27135/47780 [01:29<01:27, 235.14 examples/s]
Tokenizing train dataset (num_proc=32):  37%|███▋      | 17908/47780 [01:29<02:13, 224.39 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27669/47780 [01:29<01:01, 327.63 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28816/47780 [01:29<01:07, 281.17 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26637/47780 [01:29<01:14, 285.38 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26951/47780 [01:29<01:09, 299.93 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28048/47780 [01:29<01:00, 325.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26453/47780 [01:29<01:18, 272.40 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27162/47780 [01:29<01:24, 243.60 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 17977/47780 [01:29<01:32, 321.45 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27702/47780 [01:29<01:06, 300.54 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28847/47780 [01:29<01:08, 276.88 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26666/47780 [01:29<01:15, 280.65 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26982/47780 [01:29<01:11, 290.44 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28083/47780 [01:30<01:01, 322.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26492/47780 [01:29<01:11, 299.35 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27187/47780 [01:30<01:28, 233.31 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18016/47780 [01:30<01:34, 314.04 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27737/47780 [01:30<01:05, 304.15 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28875/47780 [01:30<01:08, 274.53 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26695/47780 [01:30<01:15, 279.56 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27017/47780 [01:30<01:08, 304.20 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28121/47780 [01:30<00:59, 330.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26522/47780 [01:30<01:11, 296.12 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27211/47780 [01:30<01:29, 230.06 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28903/47780 [01:30<01:09, 269.86 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18052/47780 [01:30<01:36, 307.90 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26724/47780 [01:30<01:18, 267.97 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27051/47780 [01:30<01:06, 309.96 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26556/47780 [01:30<01:09, 305.35 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28156/47780 [01:30<01:00, 321.81 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27768/47780 [01:30<01:15, 264.76 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27240/47780 [01:30<01:26, 238.73 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28933/47780 [01:30<01:08, 275.53 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18099/47780 [01:30<01:27, 339.96 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27091/47780 [01:30<01:01, 335.52 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26751/47780 [01:30<01:20, 259.86 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26593/47780 [01:30<01:06, 320.29 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27804/47780 [01:30<01:09, 286.13 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28194/47780 [01:30<01:00, 323.90 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27272/47780 [01:30<01:18, 261.18 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28961/47780 [01:30<01:09, 270.76 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18140/47780 [01:30<01:24, 350.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26782/47780 [01:30<01:17, 270.80 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27125/47780 [01:30<01:04, 318.44 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27834/47780 [01:30<01:08, 289.58 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26626/47780 [01:30<01:09, 305.35 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28230/47780 [01:30<00:59, 330.06 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27299/47780 [01:30<01:22, 246.93 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28989/47780 [01:30<01:11, 263.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26810/47780 [01:30<01:19, 264.46 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18179/47780 [01:30<01:28, 336.11 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27160/47780 [01:30<01:05, 313.21 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26658/47780 [01:30<01:10, 299.43 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27865/47780 [01:30<01:12, 273.98 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28264/47780 [01:30<01:03, 309.68 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27328/47780 [01:30<01:20, 253.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29016/47780 [01:30<01:11, 262.98 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26837/47780 [01:30<01:21, 257.10 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18215/47780 [01:30<01:30, 326.21 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26689/47780 [01:30<01:09, 302.19 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27898/47780 [01:30<01:09, 286.92 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27193/47780 [01:30<01:10, 291.96 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27360/47780 [01:30<01:15, 271.69 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28302/47780 [01:30<01:01, 317.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29056/47780 [01:30<01:02, 298.78 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26863/47780 [01:30<01:24, 247.04 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26723/47780 [01:30<01:07, 312.78 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27931/47780 [01:30<01:08, 289.57 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28352/47780 [01:30<00:53, 363.25 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27388/47780 [01:30<01:15, 269.83 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27224/47780 [01:30<01:14, 277.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29091/47780 [01:30<01:00, 309.88 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26890/47780 [01:30<01:24, 247.95 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18249/47780 [01:30<01:55, 254.97 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26755/47780 [01:30<01:09, 301.28 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27961/47780 [01:30<01:08, 288.02 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28390/47780 [01:30<00:53, 363.31 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27416/47780 [01:30<01:16, 264.66 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27253/47780 [01:30<01:16, 268.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29130/47780 [01:30<00:57, 321.83 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18295/47780 [01:30<01:38, 298.30 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26929/47780 [01:30<01:13, 284.44 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26788/47780 [01:30<01:07, 309.23 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28427/47780 [01:31<00:54, 357.22 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27444/47780 [01:31<01:18, 260.26 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27991/47780 [01:31<01:14, 264.94 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27296/47780 [01:30<01:06, 307.69 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29164/47780 [01:31<00:56, 326.67 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26963/47780 [01:31<01:10, 296.63 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18329/47780 [01:31<01:36, 304.92 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26825/47780 [01:31<01:04, 323.33 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27472/47780 [01:31<01:16, 265.65 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28026/47780 [01:31<01:09, 283.14 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28463/47780 [01:31<00:57, 333.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27328/47780 [01:31<01:06, 307.57 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29197/47780 [01:31<00:59, 313.52 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26995/47780 [01:31<01:08, 303.14 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26862/47780 [01:31<01:03, 329.08 examples/s]
Tokenizing train dataset (num_proc=32):  38%|███▊      | 18362/47780 [01:31<01:38, 299.27 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27368/47780 [01:31<01:01, 333.05 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27500/47780 [01:31<01:18, 257.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28055/47780 [01:31<01:11, 277.01 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29229/47780 [01:31<01:04, 288.92 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28498/47780 [01:31<01:05, 294.84 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18400/47780 [01:31<01:32, 317.14 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27026/47780 [01:31<01:12, 285.52 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26905/47780 [01:31<01:00, 346.18 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28086/47780 [01:31<01:09, 285.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27530/47780 [01:31<01:16, 264.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27402/47780 [01:31<01:04, 313.93 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28536/47780 [01:31<01:01, 313.32 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26947/47780 [01:31<00:57, 365.41 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18437/47780 [01:31<01:31, 321.06 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27059/47780 [01:31<01:11, 291.46 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29260/47780 [01:31<01:10, 261.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27563/47780 [01:31<01:11, 282.17 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28115/47780 [01:31<01:12, 270.01 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27434/47780 [01:31<01:10, 290.01 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28569/47780 [01:31<01:00, 317.39 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26987/47780 [01:31<00:56, 368.65 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18471/47780 [01:31<01:33, 312.26 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29293/47780 [01:31<01:06, 278.17 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27089/47780 [01:31<01:16, 272.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27593/47780 [01:31<01:10, 286.74 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28149/47780 [01:31<01:08, 285.64 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28602/47780 [01:31<01:01, 314.17 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27464/47780 [01:31<01:11, 283.31 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27026/47780 [01:31<00:56, 366.44 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29335/47780 [01:31<00:58, 312.99 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27121/47780 [01:31<01:13, 279.41 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▊      | 18503/47780 [01:31<01:39, 295.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27623/47780 [01:31<01:13, 275.31 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28178/47780 [01:31<01:10, 277.17 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28637/47780 [01:31<00:59, 320.76 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27493/47780 [01:31<01:15, 267.92 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29371/47780 [01:31<00:56, 325.66 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27063/47780 [01:31<00:59, 347.56 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18541/47780 [01:31<01:32, 314.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27150/47780 [01:31<01:15, 273.41 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27658/47780 [01:31<01:08, 293.48 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28209/47780 [01:31<01:09, 283.52 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28670/47780 [01:31<01:03, 299.21 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27521/47780 [01:31<01:16, 265.76 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18574/47780 [01:31<01:33, 312.02 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27100/47780 [01:31<01:02, 331.62 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27193/47780 [01:31<01:07, 306.24 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29405/47780 [01:31<01:01, 300.75 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27688/47780 [01:31<01:10, 285.42 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28238/47780 [01:31<01:09, 280.56 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27558/47780 [01:31<01:09, 290.82 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28701/47780 [01:31<01:07, 280.64 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18608/47780 [01:31<01:32, 316.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29440/47780 [01:31<00:58, 312.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27224/47780 [01:31<01:08, 300.38 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27134/47780 [01:31<01:05, 313.02 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28267/47780 [01:31<01:10, 278.58 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27717/47780 [01:32<01:13, 274.20 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27593/47780 [01:32<01:05, 307.18 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28732/47780 [01:32<01:07, 280.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29472/47780 [01:32<00:58, 311.37 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27258/47780 [01:32<01:07, 304.98 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27174/47780 [01:32<01:02, 329.61 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18640/47780 [01:32<01:39, 293.52 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27747/47780 [01:32<01:12, 275.47 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28296/47780 [01:32<01:11, 272.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28762/47780 [01:32<01:06, 285.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27293/47780 [01:32<01:04, 317.53 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27625/47780 [01:32<01:13, 273.59 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18676/47780 [01:32<01:34, 308.57 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29504/47780 [01:32<01:01, 296.51 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27777/47780 [01:32<01:12, 274.36 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28324/47780 [01:32<01:14, 260.02 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27208/47780 [01:32<01:08, 299.92 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28791/47780 [01:32<01:06, 286.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27325/47780 [01:32<01:04, 314.72 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27657/47780 [01:32<01:11, 282.78 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18712/47780 [01:32<01:30, 321.72 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29541/47780 [01:32<01:00, 303.91 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27813/47780 [01:32<01:07, 297.04 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28356/47780 [01:32<01:11, 270.72 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27239/47780 [01:32<01:08, 298.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28822/47780 [01:32<01:05, 290.30 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27357/47780 [01:32<01:08, 299.03 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29573/47780 [01:32<00:59, 307.83 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18746/47780 [01:32<01:33, 310.66 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27687/47780 [01:32<01:15, 267.34 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28396/47780 [01:32<01:03, 304.47 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27844/47780 [01:32<01:13, 272.65 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27270/47780 [01:32<01:14, 275.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28852/47780 [01:32<01:04, 292.83 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29608/47780 [01:32<00:57, 316.77 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27388/47780 [01:32<01:09, 292.31 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27720/47780 [01:32<01:10, 283.81 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18786/47780 [01:32<01:28, 328.21 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28427/47780 [01:32<01:04, 300.88 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27886/47780 [01:32<01:05, 305.85 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27299/47780 [01:32<01:14, 273.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28892/47780 [01:32<00:59, 315.68 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27756/47780 [01:32<01:06, 301.38 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27419/47780 [01:32<01:10, 290.68 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29640/47780 [01:32<00:59, 307.07 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18820/47780 [01:32<01:31, 317.34 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28458/47780 [01:32<01:05, 293.73 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27926/47780 [01:32<01:01, 324.50 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27329/47780 [01:32<01:12, 280.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28926/47780 [01:32<01:00, 313.01 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27791/47780 [01:32<01:04, 311.52 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29681/47780 [01:32<00:54, 332.50 examples/s]
Tokenizing train dataset (num_proc=32):  39%|███▉      | 18853/47780 [01:32<01:31, 317.35 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27449/47780 [01:32<01:14, 274.50 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27959/47780 [01:32<01:01, 322.30 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28489/47780 [01:32<01:08, 279.61 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28967/47780 [01:32<00:55, 336.86 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27358/47780 [01:32<01:16, 265.57 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29715/47780 [01:32<00:56, 320.04 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27823/47780 [01:32<01:07, 296.65 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27479/47780 [01:32<01:12, 278.72 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18885/47780 [01:32<01:36, 300.56 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28518/47780 [01:32<01:11, 270.67 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27992/47780 [01:32<01:07, 294.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27390/47780 [01:32<01:13, 277.38 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29001/47780 [01:32<00:56, 329.66 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27854/47780 [01:32<01:09, 287.58 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27514/47780 [01:32<01:10, 288.92 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29748/47780 [01:32<00:59, 302.46 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 18916/47780 [01:32<01:41, 285.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28546/47780 [01:32<01:10, 272.92 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28027/47780 [01:33<01:04, 306.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27421/47780 [01:32<01:11, 283.23 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29035/47780 [01:33<00:58, 321.66 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27884/47780 [01:33<01:10, 282.16 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27544/47780 [01:33<01:11, 282.63 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29779/47780 [01:33<01:01, 293.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18945/47780 [01:33<01:45, 274.25 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28060/47780 [01:33<01:04, 305.84 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28574/47780 [01:33<01:15, 255.07 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27450/47780 [01:33<01:13, 275.39 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29068/47780 [01:33<01:04, 288.45 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27573/47780 [01:33<01:11, 281.37 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29813/47780 [01:33<00:58, 305.22 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27913/47780 [01:33<01:13, 269.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18980/47780 [01:33<01:39, 289.67 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28100/47780 [01:33<00:59, 328.59 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28603/47780 [01:33<01:12, 264.44 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27480/47780 [01:33<01:13, 277.87 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29101/47780 [01:33<01:03, 296.28 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29849/47780 [01:33<00:56, 316.09 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27602/47780 [01:33<01:13, 274.62 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19010/47780 [01:33<01:41, 282.29 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27941/47780 [01:33<01:18, 253.03 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28631/47780 [01:33<01:11, 268.56 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27510/47780 [01:33<01:11, 282.65 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28134/47780 [01:33<01:05, 298.00 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29132/47780 [01:33<01:02, 296.48 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29882/47780 [01:33<00:57, 309.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27630/47780 [01:33<01:15, 267.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19046/47780 [01:33<01:35, 300.24 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27973/47780 [01:33<01:14, 265.26 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28659/47780 [01:33<01:12, 262.94 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27539/47780 [01:33<01:13, 275.41 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28167/47780 [01:33<01:05, 300.32 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29164/47780 [01:33<01:01, 302.92 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27660/47780 [01:33<01:13, 273.41 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29914/47780 [01:33<00:59, 302.03 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28004/47780 [01:33<01:12, 274.46 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28689/47780 [01:33<01:09, 273.34 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19077/47780 [01:33<01:39, 289.48 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27567/47780 [01:33<01:17, 261.92 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29195/47780 [01:33<01:01, 301.52 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28198/47780 [01:33<01:07, 290.34 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27691/47780 [01:33<01:11, 280.46 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28033/47780 [01:33<01:11, 275.68 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28717/47780 [01:33<01:10, 269.40 examples/s]
Tokenizing train dataset (num_proc=32):  40%|███▉      | 19108/47780 [01:33<01:40, 286.17 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29945/47780 [01:33<01:06, 268.22 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27595/47780 [01:33<01:16, 263.97 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29226/47780 [01:33<01:03, 290.96 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28233/47780 [01:33<01:04, 301.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27722/47780 [01:33<01:09, 288.79 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28061/47780 [01:33<01:12, 270.83 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28745/47780 [01:33<01:12, 263.07 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29977/47780 [01:33<01:03, 281.63 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19137/47780 [01:33<01:44, 274.72 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29257/47780 [01:33<01:02, 296.32 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28264/47780 [01:33<01:06, 295.57 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27622/47780 [01:33<01:23, 241.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27751/47780 [01:33<01:11, 281.57 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28089/47780 [01:33<01:12, 269.76 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28772/47780 [01:33<01:13, 259.25 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30008/47780 [01:33<01:02, 286.35 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29293/47780 [01:33<00:59, 311.12 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28296/47780 [01:33<01:04, 302.22 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19170/47780 [01:33<01:48, 264.24 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27662/47780 [01:33<01:12, 277.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27781/47780 [01:33<01:10, 284.83 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28118/47780 [01:33<01:12, 270.57 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28805/47780 [01:33<01:08, 276.43 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30038/47780 [01:33<01:03, 278.11 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29328/47780 [01:34<00:57, 318.66 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19203/47780 [01:33<01:42, 278.51 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27815/47780 [01:34<01:06, 300.67 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28327/47780 [01:34<01:08, 284.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27691/47780 [01:34<01:16, 261.12 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28146/47780 [01:34<01:13, 266.59 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28833/47780 [01:34<01:09, 273.91 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30067/47780 [01:34<01:04, 275.08 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29362/47780 [01:34<00:58, 317.50 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19237/47780 [01:34<01:39, 285.89 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27846/47780 [01:34<01:05, 303.34 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28359/47780 [01:34<01:06, 292.04 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27718/47780 [01:34<01:18, 255.22 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28179/47780 [01:34<01:10, 280.01 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29396/47780 [01:34<00:56, 323.73 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28861/47780 [01:34<01:16, 247.55 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30095/47780 [01:34<01:09, 253.79 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19269/47780 [01:34<01:37, 292.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27883/47780 [01:34<01:04, 309.04 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28389/47780 [01:34<01:10, 275.75 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27745/47780 [01:34<01:18, 256.64 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28208/47780 [01:34<01:11, 274.81 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28901/47780 [01:34<01:05, 288.62 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19299/47780 [01:34<01:37, 291.01 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30129/47780 [01:34<01:05, 268.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29429/47780 [01:34<01:01, 298.95 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27919/47780 [01:34<01:03, 311.10 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28417/47780 [01:34<01:10, 273.57 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27772/47780 [01:34<01:21, 244.05 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28236/47780 [01:34<01:12, 269.94 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28931/47780 [01:34<01:05, 287.95 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30160/47780 [01:34<01:03, 279.56 examples/s]
Tokenizing train dataset (num_proc=32):  40%|████      | 19329/47780 [01:34<01:41, 280.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29461/47780 [01:34<01:02, 294.05 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28445/47780 [01:34<01:11, 269.65 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27951/47780 [01:34<01:05, 301.14 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27801/47780 [01:34<01:18, 253.83 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28264/47780 [01:34<01:13, 266.76 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28961/47780 [01:34<01:11, 265.05 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19358/47780 [01:34<01:41, 280.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29499/47780 [01:34<00:57, 317.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30189/47780 [01:34<01:06, 264.65 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27982/47780 [01:34<01:06, 297.14 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28473/47780 [01:34<01:13, 260.92 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27832/47780 [01:34<01:15, 263.56 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28291/47780 [01:34<01:16, 253.53 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19388/47780 [01:34<01:40, 282.73 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29537/47780 [01:34<00:55, 331.63 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28989/47780 [01:34<01:11, 263.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30221/47780 [01:34<01:03, 276.94 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28502/47780 [01:34<01:11, 268.14 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28012/47780 [01:34<01:07, 294.44 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27861/47780 [01:34<01:13, 269.19 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28322/47780 [01:34<01:12, 269.05 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19425/47780 [01:34<01:32, 307.34 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29022/47780 [01:34<01:07, 278.43 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30251/47780 [01:34<01:02, 281.03 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29573/47780 [01:34<00:57, 318.59 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28532/47780 [01:34<01:10, 271.83 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28042/47780 [01:34<01:11, 274.41 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27896/47780 [01:34<01:11, 278.11 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28355/47780 [01:34<01:08, 283.31 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19457/47780 [01:34<01:32, 307.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30286/47780 [01:34<00:58, 298.33 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29064/47780 [01:34<01:00, 309.68 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28562/47780 [01:34<01:08, 279.81 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29606/47780 [01:34<00:58, 308.26 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27926/47780 [01:34<01:09, 284.17 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28077/47780 [01:34<01:06, 294.82 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28384/47780 [01:34<01:09, 279.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19488/47780 [01:34<01:32, 304.33 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30318/47780 [01:34<01:01, 286.18 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28591/47780 [01:35<01:09, 276.39 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29096/47780 [01:34<01:04, 290.86 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28107/47780 [01:34<01:07, 293.06 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27955/47780 [01:34<01:10, 279.58 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29638/47780 [01:35<01:02, 288.33 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28413/47780 [01:35<01:12, 266.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19520/47780 [01:35<01:31, 308.36 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28621/47780 [01:35<01:08, 280.01 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30353/47780 [01:35<00:59, 294.12 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29126/47780 [01:35<01:05, 283.04 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28143/47780 [01:35<01:02, 311.87 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29668/47780 [01:35<01:02, 288.76 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27984/47780 [01:35<01:16, 257.54 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28445/47780 [01:35<01:10, 272.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19552/47780 [01:35<01:32, 305.63 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30391/47780 [01:35<00:55, 314.52 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29166/47780 [01:35<00:59, 312.89 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28176/47780 [01:35<01:02, 313.79 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28650/47780 [01:35<01:13, 261.94 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29698/47780 [01:35<01:07, 268.24 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28011/47780 [01:35<01:17, 256.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28473/47780 [01:35<01:14, 260.68 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30423/47780 [01:35<00:54, 316.04 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29198/47780 [01:35<00:59, 311.14 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19583/47780 [01:35<01:45, 266.34 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28677/47780 [01:35<01:13, 258.25 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28208/47780 [01:35<01:05, 298.18 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28037/47780 [01:35<01:19, 246.98 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28506/47780 [01:35<01:09, 275.95 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29726/47780 [01:35<01:12, 250.24 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29230/47780 [01:35<00:59, 313.48 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30455/47780 [01:35<00:57, 303.22 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19613/47780 [01:35<01:44, 269.81 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28704/47780 [01:35<01:13, 261.18 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28239/47780 [01:35<01:09, 282.69 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28064/47780 [01:35<01:19, 247.67 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29760/47780 [01:35<01:07, 265.13 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28534/47780 [01:35<01:15, 254.45 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30490/47780 [01:35<00:55, 312.85 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29265/47780 [01:35<00:58, 314.48 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28731/47780 [01:35<01:12, 261.05 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19641/47780 [01:35<01:47, 261.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28268/47780 [01:35<01:10, 275.62 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29789/47780 [01:35<01:07, 266.09 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28089/47780 [01:35<01:26, 228.36 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30533/47780 [01:35<00:49, 346.15 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29303/47780 [01:35<00:55, 332.63 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28565/47780 [01:35<01:14, 258.59 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28760/47780 [01:35<01:13, 260.37 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████      | 19668/47780 [01:35<01:52, 250.09 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28296/47780 [01:35<01:12, 268.02 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28124/47780 [01:35<01:15, 260.68 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29825/47780 [01:35<01:03, 281.12 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29337/47780 [01:35<00:55, 330.15 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28593/47780 [01:35<01:13, 261.16 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30568/47780 [01:35<00:54, 317.97 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28787/47780 [01:35<01:13, 257.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19694/47780 [01:35<01:53, 247.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28324/47780 [01:35<01:13, 264.72 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28153/47780 [01:35<01:13, 265.81 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28624/47780 [01:35<01:10, 271.61 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29854/47780 [01:35<01:06, 270.00 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28814/47780 [01:35<01:14, 255.14 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29371/47780 [01:35<01:01, 301.53 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19720/47780 [01:35<01:53, 248.21 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30601/47780 [01:35<00:58, 295.39 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28351/47780 [01:35<01:13, 263.93 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28656/47780 [01:35<01:09, 275.83 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29882/47780 [01:35<01:09, 258.75 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28181/47780 [01:35<01:20, 242.27 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28852/47780 [01:35<01:05, 290.48 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29402/47780 [01:35<01:01, 297.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19751/47780 [01:35<01:46, 262.51 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28386/47780 [01:35<01:08, 285.10 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30635/47780 [01:35<00:57, 297.52 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28684/47780 [01:36<01:09, 276.35 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29914/47780 [01:36<01:04, 275.00 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28896/47780 [01:36<00:57, 329.94 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28208/47780 [01:36<01:22, 237.84 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19784/47780 [01:36<01:40, 278.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29433/47780 [01:36<01:02, 291.58 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30666/47780 [01:36<00:58, 294.64 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28415/47780 [01:36<01:15, 256.47 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28712/47780 [01:36<01:10, 268.84 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29946/47780 [01:36<01:03, 281.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28237/47780 [01:36<01:18, 248.49 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29467/47780 [01:36<01:02, 291.23 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28930/47780 [01:36<01:02, 302.07 examples/s]
Tokenizing train dataset (num_proc=32):  41%|████▏     | 19813/47780 [01:36<01:46, 263.64 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30696/47780 [01:36<01:00, 283.42 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28442/47780 [01:36<01:16, 252.03 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28741/47780 [01:36<01:10, 271.80 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29975/47780 [01:36<01:08, 260.65 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28263/47780 [01:36<01:21, 238.68 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29505/47780 [01:36<00:58, 314.97 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19840/47780 [01:36<01:46, 262.33 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28973/47780 [01:36<00:57, 325.62 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30729/47780 [01:36<00:58, 293.26 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28776/47780 [01:36<01:04, 292.53 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28468/47780 [01:36<01:23, 232.17 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30006/47780 [01:36<01:04, 273.80 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28297/47780 [01:36<01:15, 257.75 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29537/47780 [01:36<00:58, 310.39 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19868/47780 [01:36<01:46, 261.59 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29006/47780 [01:36<00:59, 313.51 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30768/47780 [01:36<00:54, 313.04 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28806/47780 [01:36<01:08, 277.02 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28492/47780 [01:36<01:24, 229.51 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30039/47780 [01:36<01:01, 289.34 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28324/47780 [01:36<01:15, 258.22 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19901/47780 [01:36<01:39, 280.62 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29569/47780 [01:36<01:00, 303.09 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30806/47780 [01:36<00:52, 324.58 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29038/47780 [01:36<01:01, 304.95 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28835/47780 [01:36<01:08, 277.64 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28516/47780 [01:36<01:24, 227.31 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30069/47780 [01:36<01:00, 291.96 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28353/47780 [01:36<01:13, 264.06 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19944/47780 [01:36<01:26, 320.08 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29602/47780 [01:36<00:59, 307.44 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30844/47780 [01:36<00:50, 336.33 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29070/47780 [01:36<01:01, 306.33 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28865/47780 [01:36<01:06, 283.79 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30099/47780 [01:36<01:00, 294.20 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28548/47780 [01:36<01:21, 237.19 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28380/47780 [01:36<01:15, 256.74 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 19977/47780 [01:36<01:33, 298.79 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29633/47780 [01:36<01:03, 285.38 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30878/47780 [01:36<00:52, 322.31 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29101/47780 [01:36<01:04, 290.23 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28899/47780 [01:36<01:03, 296.46 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30129/47780 [01:36<01:02, 283.48 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28582/47780 [01:36<01:12, 264.62 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28406/47780 [01:36<01:18, 246.86 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20008/47780 [01:36<01:32, 301.75 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29673/47780 [01:36<00:58, 309.88 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29131/47780 [01:36<01:05, 286.66 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30911/47780 [01:36<00:55, 304.08 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30165/47780 [01:36<00:58, 299.73 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28929/47780 [01:36<01:08, 275.97 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28611/47780 [01:36<01:11, 268.69 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28437/47780 [01:36<01:13, 261.53 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20040/47780 [01:36<01:32, 300.39 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29713/47780 [01:36<00:54, 331.24 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30944/47780 [01:36<00:54, 308.34 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29160/47780 [01:37<01:08, 272.49 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30196/47780 [01:37<00:59, 294.23 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28959/47780 [01:37<01:10, 267.25 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20077/47780 [01:37<01:26, 319.98 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28639/47780 [01:37<01:15, 252.07 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28465/47780 [01:37<01:17, 249.48 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29747/47780 [01:37<00:56, 319.04 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30976/47780 [01:37<00:54, 308.08 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29192/47780 [01:37<01:07, 273.73 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30232/47780 [01:37<00:56, 309.50 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28987/47780 [01:37<01:09, 270.37 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20115/47780 [01:37<01:22, 337.22 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28491/47780 [01:37<01:17, 248.68 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31008/47780 [01:37<00:53, 311.33 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29780/47780 [01:37<00:58, 308.47 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28665/47780 [01:37<01:25, 222.86 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29224/47780 [01:37<01:04, 286.22 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30266/47780 [01:37<00:55, 314.55 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29020/47780 [01:37<01:07, 277.98 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20149/47780 [01:37<01:22, 334.23 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29815/47780 [01:37<00:56, 316.67 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28517/47780 [01:37<01:21, 236.99 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31040/47780 [01:37<00:57, 290.50 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28689/47780 [01:37<01:27, 218.37 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30298/47780 [01:37<00:55, 313.02 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29253/47780 [01:37<01:09, 266.60 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29055/47780 [01:37<01:03, 294.83 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20183/47780 [01:37<01:23, 330.36 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28547/47780 [01:37<01:16, 250.39 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29847/47780 [01:37<00:59, 301.69 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28718/47780 [01:37<01:21, 234.86 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31070/47780 [01:37<00:58, 286.62 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29286/47780 [01:37<01:05, 280.63 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30330/47780 [01:37<00:58, 297.39 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29085/47780 [01:37<01:04, 289.70 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20218/47780 [01:37<01:27, 315.36 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28573/47780 [01:37<01:18, 246.24 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28744/47780 [01:37<01:18, 241.13 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29878/47780 [01:37<01:01, 293.11 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31103/47780 [01:37<00:57, 292.50 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29315/47780 [01:37<01:08, 271.03 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30366/47780 [01:37<00:56, 308.10 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29115/47780 [01:37<01:06, 282.64 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20250/47780 [01:37<01:30, 303.35 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28598/47780 [01:37<01:18, 244.23 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28773/47780 [01:37<01:14, 254.52 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29909/47780 [01:37<01:00, 294.77 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31133/47780 [01:37<01:01, 272.01 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29356/47780 [01:37<01:02, 296.20 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30397/47780 [01:37<00:58, 298.52 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29144/47780 [01:37<01:06, 281.58 examples/s]
Tokenizing train dataset (num_proc=32):  42%|████▏     | 20285/47780 [01:37<01:26, 316.28 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29944/47780 [01:37<00:58, 303.43 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28623/47780 [01:37<01:23, 230.56 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28799/47780 [01:37<01:18, 242.40 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31163/47780 [01:37<00:59, 277.97 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29390/47780 [01:37<01:00, 305.70 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30427/47780 [01:37<00:58, 298.67 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29179/47780 [01:37<01:01, 300.08 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20317/47780 [01:37<01:27, 313.80 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28829/47780 [01:37<01:14, 255.45 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28647/47780 [01:37<01:23, 227.92 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29975/47780 [01:37<01:02, 285.30 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31199/47780 [01:37<00:55, 298.89 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29421/47780 [01:37<01:00, 302.80 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30457/47780 [01:37<01:00, 285.98 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20353/47780 [01:37<01:24, 323.30 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29210/47780 [01:37<01:08, 269.91 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28675/47780 [01:37<01:21, 233.25 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30005/47780 [01:37<01:01, 286.76 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31230/47780 [01:37<00:56, 293.64 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28856/47780 [01:37<01:19, 238.85 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29452/47780 [01:38<01:00, 300.85 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30489/47780 [01:38<00:59, 289.37 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20387/47780 [01:37<01:25, 320.70 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29245/47780 [01:38<01:03, 290.56 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28699/47780 [01:38<01:24, 225.93 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28881/47780 [01:38<01:20, 233.62 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31260/47780 [01:38<00:58, 282.48 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30042/47780 [01:38<01:01, 287.62 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29483/47780 [01:38<01:02, 290.80 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20420/47780 [01:38<01:25, 319.83 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29275/47780 [01:38<01:03, 290.89 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30519/47780 [01:38<01:07, 257.55 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28723/47780 [01:38<01:23, 228.00 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28905/47780 [01:38<01:20, 235.05 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30081/47780 [01:38<00:57, 306.09 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31289/47780 [01:38<01:00, 272.87 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29527/47780 [01:38<00:56, 325.36 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29305/47780 [01:38<01:05, 283.87 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30548/47780 [01:38<01:04, 265.97 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20453/47780 [01:38<01:31, 298.17 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28746/47780 [01:38<01:25, 223.50 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28930/47780 [01:38<01:19, 236.74 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29560/47780 [01:38<00:55, 326.18 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31317/47780 [01:38<01:00, 271.30 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30116/47780 [01:38<00:56, 310.48 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29351/47780 [01:38<00:55, 329.57 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20484/47780 [01:38<01:34, 289.06 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30576/47780 [01:38<01:07, 253.20 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28769/47780 [01:38<01:27, 218.05 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29593/47780 [01:38<00:56, 323.96 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28958/47780 [01:38<01:19, 235.78 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30149/47780 [01:38<00:56, 312.47 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31346/47780 [01:38<01:02, 262.73 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20519/47780 [01:38<01:29, 305.68 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29385/47780 [01:38<00:58, 314.50 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30603/47780 [01:38<01:07, 255.00 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28791/47780 [01:38<01:27, 215.99 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28993/47780 [01:38<01:10, 265.98 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30182/47780 [01:38<00:55, 317.08 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29626/47780 [01:38<00:57, 316.37 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31377/47780 [01:38<01:00, 272.27 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20552/47780 [01:38<01:27, 312.23 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28820/47780 [01:38<01:20, 234.54 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29417/47780 [01:38<01:05, 279.07 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30629/47780 [01:38<01:13, 233.39 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29661/47780 [01:38<00:55, 324.30 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30214/47780 [01:38<00:57, 307.66 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31406/47780 [01:38<00:59, 273.51 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29020/47780 [01:38<01:14, 250.67 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20590/47780 [01:38<01:22, 330.90 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30680/47780 [01:38<00:55, 306.09 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28849/47780 [01:38<01:15, 250.36 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29695/47780 [01:38<00:55, 325.30 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29446/47780 [01:38<01:09, 265.41 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30245/47780 [01:38<00:58, 301.23 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29064/47780 [01:38<01:03, 297.00 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31435/47780 [01:38<01:03, 255.42 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20628/47780 [01:38<01:21, 334.67 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30713/47780 [01:38<00:55, 309.23 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28876/47780 [01:38<01:18, 242.02 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29728/47780 [01:38<00:56, 319.09 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29474/47780 [01:38<01:09, 263.74 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30276/47780 [01:38<00:58, 300.58 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29095/47780 [01:38<01:04, 290.98 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31463/47780 [01:38<01:02, 259.48 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20662/47780 [01:38<01:21, 332.45 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28910/47780 [01:38<01:10, 266.67 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29762/47780 [01:38<00:55, 324.00 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30310/47780 [01:38<00:56, 308.39 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29506/47780 [01:38<01:06, 272.84 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30745/47780 [01:38<01:00, 281.00 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29126/47780 [01:38<01:06, 280.74 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31495/47780 [01:38<01:01, 264.49 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20698/47780 [01:38<01:23, 324.90 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28943/47780 [01:39<01:06, 284.62 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29536/47780 [01:39<01:05, 277.21 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30784/47780 [01:39<00:55, 306.38 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29795/47780 [01:39<00:59, 302.30 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30341/47780 [01:39<01:03, 276.70 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29155/47780 [01:39<01:07, 274.26 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31529/47780 [01:39<00:57, 282.18 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20731/47780 [01:39<01:30, 299.50 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28977/47780 [01:39<01:02, 300.57 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30826/47780 [01:39<00:50, 333.65 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29565/47780 [01:39<01:06, 273.18 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29826/47780 [01:39<01:02, 288.14 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29195/47780 [01:39<01:00, 305.37 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30371/47780 [01:39<01:02, 277.25 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31558/47780 [01:39<00:57, 283.90 examples/s]
Tokenizing train dataset (num_proc=32):  43%|████▎     | 20762/47780 [01:39<01:29, 300.69 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29012/47780 [01:39<01:00, 307.87 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30861/47780 [01:39<00:51, 327.31 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29593/47780 [01:39<01:08, 264.80 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29869/47780 [01:39<00:54, 326.92 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31598/47780 [01:39<00:52, 306.90 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29227/47780 [01:39<01:03, 290.00 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30400/47780 [01:39<01:08, 255.47 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20794/47780 [01:39<01:32, 291.73 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29043/47780 [01:39<01:02, 298.19 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29623/47780 [01:39<01:06, 274.52 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29913/47780 [01:39<00:49, 358.61 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30896/47780 [01:39<00:52, 323.25 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29257/47780 [01:39<01:03, 292.69 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31629/47780 [01:39<00:55, 291.06 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30432/47780 [01:39<01:03, 271.69 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20825/47780 [01:39<01:30, 296.73 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29074/47780 [01:39<01:03, 294.69 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29651/47780 [01:39<01:07, 267.11 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30929/47780 [01:39<00:53, 317.90 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29951/47780 [01:39<00:54, 328.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29287/47780 [01:39<01:04, 287.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31659/47780 [01:39<00:55, 289.10 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30461/47780 [01:39<01:03, 271.60 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20855/47780 [01:39<01:30, 297.35 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29104/47780 [01:39<01:03, 292.78 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29683/47780 [01:39<01:04, 281.88 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30963/47780 [01:39<00:52, 320.27 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29985/47780 [01:39<00:55, 323.51 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31692/47780 [01:39<00:53, 298.89 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30490/47780 [01:39<01:03, 270.72 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29316/47780 [01:39<01:07, 273.51 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▎     | 20885/47780 [01:39<01:33, 288.51 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29134/47780 [01:39<01:04, 288.44 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29717/47780 [01:39<01:01, 295.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30997/47780 [01:39<00:51, 325.79 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31724/47780 [01:39<00:53, 298.13 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30022/47780 [01:39<00:55, 322.11 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30520/47780 [01:39<01:02, 275.83 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29344/47780 [01:39<01:08, 269.42 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29166/47780 [01:39<01:03, 294.08 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20914/47780 [01:39<01:38, 273.43 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31034/47780 [01:39<00:50, 332.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29747/47780 [01:39<01:03, 282.59 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30055/47780 [01:39<00:54, 323.41 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30548/47780 [01:39<01:02, 276.99 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31758/47780 [01:39<00:52, 303.02 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29373/47780 [01:39<01:10, 261.59 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29196/47780 [01:39<01:03, 291.11 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20943/47780 [01:39<01:38, 272.00 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31076/47780 [01:39<00:48, 344.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29779/47780 [01:39<01:02, 287.61 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30582/47780 [01:39<00:58, 295.08 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31793/47780 [01:39<00:51, 312.96 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30095/47780 [01:39<00:52, 338.23 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29402/47780 [01:39<01:09, 262.59 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20971/47780 [01:39<01:41, 265.35 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29226/47780 [01:40<01:08, 269.67 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29809/47780 [01:39<01:01, 291.04 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31112/47780 [01:40<00:49, 333.57 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31827/47780 [01:40<00:49, 320.69 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30612/47780 [01:40<01:00, 283.35 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30130/47780 [01:40<00:53, 330.41 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29429/47780 [01:40<01:10, 261.82 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 20999/47780 [01:40<01:39, 269.31 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29255/47780 [01:40<01:07, 272.61 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29839/47780 [01:40<01:01, 293.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31146/47780 [01:40<00:50, 327.76 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30642/47780 [01:40<00:59, 287.64 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31860/47780 [01:40<00:51, 312.00 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30173/47780 [01:40<00:50, 350.41 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29456/47780 [01:40<01:11, 255.31 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21027/47780 [01:40<01:44, 254.95 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29878/47780 [01:40<00:56, 314.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29283/47780 [01:40<01:11, 259.46 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31180/47780 [01:40<00:52, 313.36 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30671/47780 [01:40<01:00, 282.24 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30209/47780 [01:40<00:51, 341.63 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31892/47780 [01:40<00:55, 287.07 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29490/47780 [01:40<01:08, 267.20 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21065/47780 [01:40<01:36, 277.38 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29910/47780 [01:40<00:58, 305.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29315/47780 [01:40<01:08, 270.13 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31212/47780 [01:40<00:56, 295.31 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30700/47780 [01:40<01:03, 269.09 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30247/47780 [01:40<00:52, 333.28 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29517/47780 [01:40<01:08, 264.89 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21093/47780 [01:40<01:36, 277.81 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31922/47780 [01:40<01:00, 260.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29941/47780 [01:40<01:00, 296.78 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29344/47780 [01:40<01:13, 251.34 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31242/47780 [01:40<00:56, 294.06 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30729/47780 [01:40<01:02, 274.87 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30288/47780 [01:40<00:50, 348.93 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29544/47780 [01:40<01:12, 252.24 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31960/47780 [01:40<00:54, 291.52 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29977/47780 [01:40<00:56, 314.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21121/47780 [01:40<01:41, 263.77 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29373/47780 [01:40<01:10, 261.54 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30757/47780 [01:40<01:01, 276.33 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31272/47780 [01:40<00:56, 292.37 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30330/47780 [01:40<00:48, 362.88 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31995/47780 [01:40<00:51, 303.96 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29571/47780 [01:40<01:12, 251.63 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30009/47780 [01:40<00:56, 316.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21153/47780 [01:40<01:37, 274.48 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29400/47780 [01:40<01:09, 263.80 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31302/47780 [01:40<00:56, 294.17 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30788/47780 [01:40<01:00, 282.75 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30367/47780 [01:40<00:52, 334.63 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29602/47780 [01:40<01:08, 264.92 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32032/47780 [01:40<00:49, 315.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21187/47780 [01:40<01:31, 291.46 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30043/47780 [01:40<00:58, 305.22 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29428/47780 [01:40<01:13, 248.60 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31332/47780 [01:40<00:58, 280.15 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30821/47780 [01:40<01:00, 280.19 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29629/47780 [01:40<01:09, 260.57 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32065/47780 [01:40<00:49, 314.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30401/47780 [01:40<00:53, 324.91 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21217/47780 [01:40<01:32, 287.32 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30080/47780 [01:40<00:55, 316.58 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29464/47780 [01:40<01:06, 276.03 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31374/47780 [01:40<00:51, 316.22 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30855/47780 [01:40<00:57, 293.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29657/47780 [01:40<01:08, 266.01 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32098/47780 [01:40<00:52, 296.63 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30112/47780 [01:40<00:58, 303.65 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30434/47780 [01:41<00:58, 298.41 examples/s]
Tokenizing train dataset (num_proc=32):  44%|████▍     | 21246/47780 [01:40<01:39, 266.86 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29493/47780 [01:41<01:06, 276.69 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30890/47780 [01:41<00:54, 309.09 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31406/47780 [01:41<00:55, 292.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29684/47780 [01:41<01:10, 257.93 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30471/47780 [01:41<00:54, 316.54 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30143/47780 [01:41<00:58, 302.27 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32135/47780 [01:41<00:52, 300.27 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29528/47780 [01:41<01:01, 296.06 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21274/47780 [01:41<01:42, 259.06 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30922/47780 [01:41<00:57, 293.89 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31436/47780 [01:41<00:57, 283.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29712/47780 [01:41<01:09, 258.68 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30505/47780 [01:41<00:54, 315.78 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30174/47780 [01:41<00:59, 297.24 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32166/47780 [01:41<00:52, 295.78 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29564/47780 [01:41<00:58, 312.28 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30952/47780 [01:41<00:57, 291.09 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21301/47780 [01:41<01:49, 240.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31471/47780 [01:41<00:54, 298.04 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29738/47780 [01:41<01:11, 253.04 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30545/47780 [01:41<00:51, 335.54 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30217/47780 [01:41<00:52, 331.43 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29596/47780 [01:41<00:57, 314.22 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32197/47780 [01:41<00:52, 295.49 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30984/47780 [01:41<00:56, 299.24 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21333/47780 [01:41<01:42, 259.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31504/47780 [01:41<00:53, 306.67 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29769/47780 [01:41<01:08, 263.25 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29629/47780 [01:41<00:57, 315.64 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30579/47780 [01:41<00:52, 325.52 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32227/47780 [01:41<00:53, 288.35 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30251/47780 [01:41<00:56, 312.61 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21361/47780 [01:41<01:39, 264.58 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31015/47780 [01:41<00:56, 295.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31535/47780 [01:41<00:53, 304.05 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29797/47780 [01:41<01:07, 267.94 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29668/47780 [01:41<00:53, 335.43 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30291/47780 [01:41<00:52, 333.08 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30612/47780 [01:41<00:55, 309.64 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32256/47780 [01:41<00:56, 277.01 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31045/47780 [01:41<00:56, 296.20 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31571/47780 [01:41<00:50, 319.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21388/47780 [01:41<01:45, 249.45 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29824/47780 [01:41<01:07, 264.59 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29704/47780 [01:41<00:54, 332.74 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30325/47780 [01:41<00:53, 327.68 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30664/47780 [01:41<00:47, 363.47 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32284/47780 [01:41<00:56, 274.35 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31082/47780 [01:41<00:54, 307.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31604/47780 [01:41<00:51, 315.61 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21419/47780 [01:41<01:44, 252.37 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29856/47780 [01:41<01:05, 272.34 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29738/47780 [01:41<00:54, 330.71 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32318/47780 [01:41<00:53, 289.92 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30701/47780 [01:41<00:48, 349.63 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30358/47780 [01:41<00:56, 310.72 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31122/47780 [01:41<00:50, 330.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31636/47780 [01:41<00:51, 313.25 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29886/47780 [01:41<01:04, 277.09 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21454/47780 [01:41<01:39, 265.30 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29772/47780 [01:41<00:56, 318.77 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30738/47780 [01:41<00:48, 351.41 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30390/47780 [01:41<00:57, 302.94 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32348/47780 [01:41<00:56, 271.36 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31156/47780 [01:41<00:52, 314.78 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31668/47780 [01:41<00:55, 291.91 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29929/47780 [01:41<00:56, 317.48 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▍     | 21481/47780 [01:41<01:38, 265.71 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30776/47780 [01:42<00:48, 351.56 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32391/47780 [01:41<00:48, 314.51 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29805/47780 [01:41<01:00, 298.24 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30427/47780 [01:41<00:55, 311.51 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31188/47780 [01:41<00:53, 309.43 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31707/47780 [01:42<00:50, 318.87 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29961/47780 [01:42<00:56, 318.18 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21509/47780 [01:41<01:38, 266.81 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30812/47780 [01:42<00:49, 346.18 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29836/47780 [01:42<01:00, 298.33 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30464/47780 [01:42<00:52, 327.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32425/47780 [01:42<00:50, 301.57 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31743/47780 [01:42<00:49, 326.00 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31221/47780 [01:42<00:54, 301.66 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21540/47780 [01:42<01:35, 275.69 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29993/47780 [01:42<00:57, 307.56 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30503/47780 [01:42<00:50, 341.42 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30847/47780 [01:42<00:51, 331.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32475/47780 [01:42<00:43, 355.65 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31260/47780 [01:42<00:50, 325.92 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29867/47780 [01:42<01:05, 274.09 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21569/47780 [01:42<01:35, 273.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31776/47780 [01:42<00:51, 310.09 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30024/47780 [01:42<01:00, 295.07 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30543/47780 [01:42<00:48, 354.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30886/47780 [01:42<00:49, 344.62 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31293/47780 [01:42<00:53, 309.67 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21597/47780 [01:42<01:36, 270.89 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32512/47780 [01:42<00:46, 326.29 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30054/47780 [01:42<00:59, 295.97 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29895/47780 [01:42<01:09, 256.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31811/47780 [01:42<00:52, 304.51 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30579/47780 [01:42<00:50, 339.35 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30921/47780 [01:42<00:52, 324.11 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21626/47780 [01:42<01:35, 274.72 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31325/47780 [01:42<00:53, 308.38 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29924/47780 [01:42<01:07, 265.19 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30085/47780 [01:42<01:00, 293.76 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32547/47780 [01:42<00:47, 322.09 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31842/47780 [01:42<00:52, 302.77 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30954/47780 [01:42<00:51, 325.04 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31357/47780 [01:42<00:53, 305.40 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29951/47780 [01:42<01:07, 264.17 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21654/47780 [01:42<01:37, 266.99 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31873/47780 [01:42<00:52, 304.76 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30614/47780 [01:42<00:56, 304.66 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30117/47780 [01:42<01:00, 291.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32581/47780 [01:42<00:48, 313.98 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30989/47780 [01:42<00:51, 327.48 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21691/47780 [01:42<01:29, 292.96 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31912/47780 [01:42<00:48, 325.46 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32618/47780 [01:42<00:46, 329.00 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31388/47780 [01:42<00:56, 290.33 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30653/47780 [01:42<00:54, 314.53 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30151/47780 [01:42<00:58, 301.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29978/47780 [01:42<01:15, 236.28 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31023/47780 [01:42<00:52, 321.54 examples/s]
Tokenizing train dataset (num_proc=32):  45%|████▌     | 21722/47780 [01:42<01:31, 284.87 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30690/47780 [01:42<00:52, 327.47 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31419/47780 [01:42<00:56, 289.51 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31945/47780 [01:42<00:52, 301.78 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30182/47780 [01:42<01:01, 284.50 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32652/47780 [01:42<00:49, 308.18 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30009/47780 [01:42<01:10, 250.57 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31061/47780 [01:42<00:49, 337.72 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21760/47780 [01:42<01:24, 308.01 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31453/47780 [01:42<00:54, 300.25 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30724/47780 [01:42<00:54, 310.13 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30039/47780 [01:42<01:08, 258.22 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30211/47780 [01:42<01:04, 270.91 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32684/47780 [01:42<00:51, 295.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31976/47780 [01:42<00:56, 280.02 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31095/47780 [01:42<00:52, 316.72 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31484/47780 [01:42<00:54, 296.34 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30756/47780 [01:42<00:55, 308.30 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30248/47780 [01:43<00:58, 297.80 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21791/47780 [01:42<01:33, 279.40 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30068/47780 [01:43<01:07, 261.33 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32720/47780 [01:43<00:48, 308.52 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32005/47780 [01:43<00:58, 271.13 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31130/47780 [01:43<00:51, 325.95 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31528/47780 [01:43<00:48, 333.25 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30789/47780 [01:43<00:55, 304.25 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30279/47780 [01:43<00:59, 294.74 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32752/47780 [01:43<00:49, 305.36 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30101/47780 [01:43<01:05, 271.17 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21820/47780 [01:43<01:37, 265.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32033/47780 [01:43<00:58, 267.45 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31164/47780 [01:43<00:50, 326.56 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31562/47780 [01:43<00:51, 313.67 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30313/47780 [01:43<00:56, 307.29 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32788/47780 [01:43<00:46, 319.24 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30131/47780 [01:43<01:03, 278.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21848/47780 [01:43<01:37, 266.66 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30820/47780 [01:43<01:01, 277.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32067/47780 [01:43<00:57, 275.55 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31199/47780 [01:43<00:49, 333.24 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31594/47780 [01:43<00:53, 299.91 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30346/47780 [01:43<00:58, 297.10 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21875/47780 [01:43<01:37, 264.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32821/47780 [01:43<00:48, 309.69 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30160/47780 [01:43<01:07, 261.68 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32098/47780 [01:43<00:55, 284.68 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30850/47780 [01:43<01:01, 275.18 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31235/47780 [01:43<00:49, 336.96 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30376/47780 [01:43<00:58, 297.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21902/47780 [01:43<01:39, 260.37 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30879/47780 [01:43<01:00, 279.11 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32138/47780 [01:43<00:50, 310.16 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30187/47780 [01:43<01:08, 257.88 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31625/47780 [01:43<00:58, 274.74 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31273/47780 [01:43<00:47, 345.57 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32853/47780 [01:43<00:55, 270.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30407/47780 [01:43<00:58, 297.95 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30908/47780 [01:43<01:00, 278.11 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21931/47780 [01:43<01:41, 254.39 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32170/47780 [01:43<00:51, 302.16 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31308/47780 [01:43<00:48, 339.03 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31653/47780 [01:43<01:00, 266.30 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32883/47780 [01:43<00:55, 269.85 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30214/47780 [01:43<01:16, 228.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30438/47780 [01:43<00:58, 297.96 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30940/47780 [01:43<00:58, 287.94 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21957/47780 [01:43<01:46, 242.62 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31342/47780 [01:43<00:49, 331.54 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32201/47780 [01:43<00:52, 294.97 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31686/47780 [01:43<00:58, 273.16 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32911/47780 [01:43<00:54, 272.32 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30266/47780 [01:43<00:58, 300.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30473/47780 [01:43<00:55, 312.75 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30969/47780 [01:43<00:59, 281.82 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 21985/47780 [01:43<01:42, 252.73 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32231/47780 [01:43<00:53, 293.07 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31718/47780 [01:43<00:56, 281.98 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31376/47780 [01:43<00:51, 315.85 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30514/47780 [01:43<00:51, 337.67 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32939/47780 [01:43<00:59, 247.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30298/47780 [01:43<01:02, 279.00 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31002/47780 [01:43<00:57, 292.56 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32262/47780 [01:43<00:53, 289.24 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31752/47780 [01:43<00:54, 295.31 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22011/47780 [01:43<01:49, 236.39 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31408/47780 [01:43<00:53, 306.87 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30550/47780 [01:43<00:50, 340.02 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30329/47780 [01:43<01:01, 284.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32965/47780 [01:43<01:01, 242.74 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31035/47780 [01:43<00:55, 299.70 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31784/47780 [01:44<00:53, 298.86 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32294/47780 [01:44<00:53, 290.27 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31450/47780 [01:44<00:48, 337.83 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22035/47780 [01:43<01:50, 232.31 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30595/47780 [01:44<00:46, 368.39 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32996/47780 [01:44<00:57, 258.31 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30359/47780 [01:44<01:02, 279.30 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31066/47780 [01:44<00:55, 299.36 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31820/47780 [01:44<00:50, 316.12 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32327/47780 [01:44<00:52, 291.63 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31486/47780 [01:44<00:49, 329.93 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30634/47780 [01:44<00:46, 366.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33023/47780 [01:44<00:57, 258.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30389/47780 [01:44<01:01, 284.60 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▌     | 22059/47780 [01:44<02:09, 199.10 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31097/47780 [01:44<00:56, 295.54 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31852/47780 [01:44<00:50, 313.67 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31523/47780 [01:44<00:47, 340.94 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32357/47780 [01:44<00:55, 278.34 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30674/47780 [01:44<00:46, 371.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33059/47780 [01:44<00:51, 286.67 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30419/47780 [01:44<01:01, 282.93 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31131/47780 [01:44<00:55, 301.42 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31884/47780 [01:44<00:50, 315.49 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22122/47780 [01:44<01:29, 287.12 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31561/47780 [01:44<00:46, 351.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32385/47780 [01:44<00:57, 269.63 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30448/47780 [01:44<01:00, 284.61 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33090/47780 [01:44<00:52, 280.41 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30712/47780 [01:44<00:48, 348.72 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31166/47780 [01:44<00:53, 311.64 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22152/47780 [01:44<01:28, 290.05 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31916/47780 [01:44<00:53, 298.88 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32415/47780 [01:44<00:55, 275.34 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31597/47780 [01:44<00:49, 328.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30482/47780 [01:44<00:57, 299.59 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33120/47780 [01:44<00:53, 273.97 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30754/47780 [01:44<00:47, 357.46 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31199/47780 [01:44<00:54, 306.51 examples/s]
Tokenizing train dataset (num_proc=32):  46%|████▋     | 22187/47780 [01:44<01:25, 299.75 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31948/47780 [01:44<00:53, 295.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32443/47780 [01:44<00:59, 259.74 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30515/47780 [01:44<00:57, 299.13 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33151/47780 [01:44<00:52, 277.71 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30790/47780 [01:44<00:48, 353.44 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31632/47780 [01:44<00:55, 291.31 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22218/47780 [01:44<01:26, 296.15 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31230/47780 [01:44<00:57, 289.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31978/47780 [01:44<00:53, 296.27 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32470/47780 [01:44<00:59, 256.08 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30548/47780 [01:44<00:56, 306.39 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31664/47780 [01:44<00:54, 293.08 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30826/47780 [01:44<00:51, 329.93 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22250/47780 [01:44<01:27, 293.00 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32008/47780 [01:44<00:54, 290.75 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33179/47780 [01:44<00:59, 245.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31260/47780 [01:44<01:01, 269.09 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30587/47780 [01:44<00:52, 328.60 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32507/47780 [01:44<00:53, 284.38 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31700/47780 [01:44<00:51, 310.32 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22285/47780 [01:44<01:23, 304.15 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33206/47780 [01:44<00:57, 251.67 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30860/47780 [01:44<00:54, 311.93 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32038/47780 [01:44<00:56, 280.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31288/47780 [01:44<01:01, 269.57 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30621/47780 [01:44<00:52, 325.53 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32536/47780 [01:44<00:56, 268.13 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31734/47780 [01:44<00:50, 316.37 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22316/47780 [01:44<01:26, 295.27 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33232/47780 [01:44<00:58, 248.86 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32069/47780 [01:44<00:54, 285.66 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31316/47780 [01:44<01:00, 271.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30892/47780 [01:44<00:58, 289.27 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30655/47780 [01:45<00:53, 317.34 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32564/47780 [01:45<00:56, 268.27 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31767/47780 [01:45<00:51, 308.65 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22355/47780 [01:45<01:20, 316.43 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33265/47780 [01:45<00:54, 265.26 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32104/47780 [01:45<00:51, 303.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31350/47780 [01:45<00:56, 288.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30927/47780 [01:45<00:56, 299.01 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30689/47780 [01:45<00:53, 320.31 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32593/47780 [01:45<00:57, 265.59 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31799/47780 [01:45<00:51, 308.18 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33293/47780 [01:45<00:54, 263.41 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31390/47780 [01:45<00:51, 317.23 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32138/47780 [01:45<00:52, 300.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22387/47780 [01:45<01:24, 300.47 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30965/47780 [01:45<00:53, 314.09 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30722/47780 [01:45<00:54, 315.86 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32620/47780 [01:45<00:57, 264.01 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31841/47780 [01:45<00:46, 339.69 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33320/47780 [01:45<00:55, 262.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22419/47780 [01:45<01:22, 305.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32183/47780 [01:45<00:47, 327.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30999/47780 [01:45<00:52, 320.94 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31422/47780 [01:45<00:55, 294.35 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30756/47780 [01:45<00:54, 314.00 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32647/47780 [01:45<00:57, 262.61 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31879/47780 [01:45<00:45, 348.61 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33357/47780 [01:45<00:49, 289.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32220/47780 [01:45<00:46, 335.97 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31455/47780 [01:45<00:54, 297.70 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22450/47780 [01:45<01:30, 278.54 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31032/47780 [01:45<00:55, 300.27 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30790/47780 [01:45<00:53, 319.35 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32676/47780 [01:45<00:59, 255.97 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33387/47780 [01:45<00:49, 288.66 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31915/47780 [01:45<00:51, 308.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32257/47780 [01:45<00:45, 341.75 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31489/47780 [01:45<00:52, 309.32 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22479/47780 [01:45<01:36, 262.26 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31063/47780 [01:45<00:59, 281.41 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32705/47780 [01:45<00:58, 259.70 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30822/47780 [01:45<00:59, 284.92 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31962/47780 [01:45<00:45, 344.10 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33417/47780 [01:45<00:50, 282.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32293/47780 [01:45<00:45, 343.80 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31521/47780 [01:45<00:57, 284.72 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22506/47780 [01:45<01:38, 255.63 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32748/47780 [01:45<00:48, 307.29 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31093/47780 [01:45<00:59, 280.47 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30852/47780 [01:45<01:00, 281.60 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32329/47780 [01:45<00:44, 347.66 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31998/47780 [01:45<00:47, 333.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33446/47780 [01:45<00:52, 272.44 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31551/47780 [01:45<00:56, 287.43 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31122/47780 [01:45<00:59, 280.11 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22537/47780 [01:45<01:37, 259.61 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30881/47780 [01:45<01:00, 281.01 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32780/47780 [01:45<00:53, 279.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32369/47780 [01:45<00:42, 362.88 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33474/47780 [01:45<00:55, 259.95 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32033/47780 [01:45<00:51, 305.26 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31582/47780 [01:45<00:58, 278.61 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31157/47780 [01:45<00:55, 299.31 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22569/47780 [01:45<01:32, 272.93 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30913/47780 [01:45<00:58, 286.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32406/47780 [01:45<00:42, 360.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32809/47780 [01:45<00:55, 270.37 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33501/47780 [01:45<00:55, 257.15 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32070/47780 [01:45<00:49, 319.91 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31616/47780 [01:45<00:54, 294.98 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31201/47780 [01:45<00:48, 338.70 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22605/47780 [01:45<01:25, 293.59 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30942/47780 [01:46<01:01, 274.10 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32443/47780 [01:46<00:43, 355.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32841/47780 [01:46<00:53, 280.56 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32104/47780 [01:46<00:48, 320.55 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33527/47780 [01:46<00:58, 244.51 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31646/47780 [01:46<00:56, 286.45 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31236/47780 [01:46<00:50, 327.30 examples/s]
Tokenizing train dataset (num_proc=32):  47%|████▋     | 22637/47780 [01:46<01:27, 288.07 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30976/47780 [01:46<00:57, 291.93 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32871/47780 [01:46<00:52, 285.61 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32480/47780 [01:46<00:45, 339.84 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33553/47780 [01:46<00:57, 246.09 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32142/47780 [01:46<00:47, 329.65 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31678/47780 [01:46<00:54, 292.88 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31270/47780 [01:46<00:50, 327.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22667/47780 [01:46<01:28, 285.12 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31006/47780 [01:46<01:00, 278.30 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32900/47780 [01:46<00:55, 266.16 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32515/47780 [01:46<00:47, 324.11 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33579/47780 [01:46<00:58, 244.64 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32177/47780 [01:46<00:47, 331.27 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31709/47780 [01:46<00:54, 294.07 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31307/47780 [01:46<00:49, 331.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22701/47780 [01:46<01:23, 300.34 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31038/47780 [01:46<00:59, 280.79 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32933/47780 [01:46<00:52, 280.53 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32550/47780 [01:46<00:46, 324.24 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33607/47780 [01:46<00:55, 254.38 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32211/47780 [01:46<00:47, 330.35 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31739/47780 [01:46<00:54, 292.30 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31342/47780 [01:46<00:49, 332.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22733/47780 [01:46<01:23, 298.76 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31080/47780 [01:46<00:52, 315.92 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32962/47780 [01:46<00:54, 270.74 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32583/47780 [01:46<00:48, 316.12 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33641/47780 [01:46<00:53, 266.67 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32245/47780 [01:46<00:48, 320.51 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31377/47780 [01:46<00:49, 334.35 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31773/47780 [01:46<00:54, 292.94 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22768/47780 [01:46<01:25, 293.81 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31112/47780 [01:46<00:56, 293.51 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32991/47780 [01:46<00:54, 272.19 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33676/47780 [01:46<00:48, 290.01 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32615/47780 [01:46<00:50, 302.95 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31804/47780 [01:46<00:53, 297.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32278/47780 [01:46<00:50, 304.20 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31412/47780 [01:46<00:54, 297.87 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31143/47780 [01:46<00:55, 297.97 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22798/47780 [01:46<01:36, 258.46 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33706/47780 [01:46<00:48, 289.70 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33020/47780 [01:46<00:56, 260.99 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32648/47780 [01:46<00:49, 303.87 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31834/47780 [01:46<00:54, 291.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32309/47780 [01:46<00:53, 286.91 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31443/47780 [01:46<00:54, 297.75 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31174/47780 [01:46<00:55, 298.43 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22852/47780 [01:46<01:15, 330.50 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32683/47780 [01:46<00:48, 313.11 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33049/47780 [01:46<00:56, 263.02 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33736/47780 [01:46<00:50, 276.75 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31868/47780 [01:46<00:52, 302.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32344/47780 [01:46<00:51, 300.54 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31474/47780 [01:46<00:57, 282.74 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31205/47780 [01:46<00:58, 285.49 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33766/47780 [01:46<00:49, 283.06 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32720/47780 [01:46<00:46, 325.30 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33083/47780 [01:46<00:52, 278.56 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31900/47780 [01:46<00:54, 293.76 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32382/47780 [01:46<00:47, 322.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22887/47780 [01:46<01:26, 288.76 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31503/47780 [01:46<00:57, 280.81 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31239/47780 [01:47<00:55, 297.20 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33795/47780 [01:47<00:49, 281.63 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33118/47780 [01:47<00:49, 294.72 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31937/47780 [01:47<00:50, 315.13 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32753/47780 [01:47<00:50, 297.92 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32419/47780 [01:47<00:46, 329.24 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22928/47780 [01:47<01:18, 316.30 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31534/47780 [01:47<00:56, 286.59 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31275/47780 [01:47<00:53, 308.05 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33824/47780 [01:47<00:49, 280.95 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33148/47780 [01:47<00:51, 283.28 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31969/47780 [01:47<00:51, 309.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32796/47780 [01:47<00:45, 331.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32453/47780 [01:47<00:47, 320.74 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22962/47780 [01:47<01:22, 300.59 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31563/47780 [01:47<00:58, 278.23 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31322/47780 [01:47<00:47, 349.74 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33862/47780 [01:47<00:45, 302.91 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32002/47780 [01:47<00:50, 315.29 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33183/47780 [01:47<00:50, 291.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32835/47780 [01:47<00:43, 344.25 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32490/47780 [01:47<00:46, 330.88 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 22996/47780 [01:47<01:20, 308.93 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31366/47780 [01:47<00:44, 371.19 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33900/47780 [01:47<00:42, 324.96 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31592/47780 [01:47<01:02, 258.36 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33225/47780 [01:47<00:45, 320.96 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32526/47780 [01:47<00:45, 335.69 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32035/47780 [01:47<00:52, 298.79 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32870/47780 [01:47<00:46, 322.90 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23028/47780 [01:47<01:19, 310.46 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31404/47780 [01:47<00:44, 365.46 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33933/47780 [01:47<00:43, 318.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31619/47780 [01:47<01:03, 255.87 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32066/47780 [01:47<00:53, 292.17 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33258/47780 [01:47<00:48, 301.07 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32903/47780 [01:47<00:46, 318.97 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32561/47780 [01:47<00:47, 320.70 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23061/47780 [01:47<01:20, 308.67 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31445/47780 [01:47<00:43, 378.18 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33970/47780 [01:47<00:41, 330.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31645/47780 [01:47<01:08, 237.11 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32104/47780 [01:47<00:50, 313.19 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33289/47780 [01:47<00:47, 301.98 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32940/47780 [01:47<00:45, 329.34 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32601/47780 [01:47<00:45, 336.99 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23093/47780 [01:47<01:21, 301.76 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31484/47780 [01:47<00:42, 380.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 34006/47780 [01:47<00:42, 323.63 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31673/47780 [01:47<01:05, 245.28 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32136/47780 [01:47<00:50, 311.60 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32979/47780 [01:47<00:42, 344.86 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33320/47780 [01:47<00:49, 295.10 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32638/47780 [01:47<00:43, 344.89 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23128/47780 [01:47<01:18, 315.04 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31528/47780 [01:47<00:41, 394.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 34039/47780 [01:47<00:44, 311.43 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31708/47780 [01:47<00:59, 270.72 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32168/47780 [01:47<00:50, 310.42 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33014/47780 [01:47<00:42, 343.85 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32674/47780 [01:47<00:45, 333.94 examples/s]
Tokenizing train dataset (num_proc=32):  48%|████▊     | 23163/47780 [01:47<01:17, 318.08 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33350/47780 [01:47<00:51, 277.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31568/47780 [01:47<00:42, 382.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34078/47780 [01:47<00:41, 329.58 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33050/47780 [01:47<00:42, 348.26 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32206/47780 [01:47<00:48, 323.29 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31736/47780 [01:47<01:03, 253.55 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32714/47780 [01:47<00:42, 352.22 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33386/47780 [01:47<00:48, 299.39 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23196/47780 [01:47<01:21, 300.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31610/47780 [01:47<00:42, 384.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34112/47780 [01:47<00:41, 328.45 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33085/47780 [01:48<00:42, 344.93 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32242/47780 [01:47<00:47, 329.13 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31768/47780 [01:48<01:01, 260.26 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32750/47780 [01:48<00:43, 342.63 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33417/47780 [01:48<00:48, 293.14 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▊     | 23227/47780 [01:48<01:21, 300.16 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31653/47780 [01:48<00:40, 397.36 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34145/47780 [01:48<00:41, 325.77 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33127/47780 [01:48<00:40, 362.86 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32277/47780 [01:48<00:47, 328.23 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31800/47780 [01:48<00:57, 276.12 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32785/47780 [01:48<00:45, 329.75 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33447/47780 [01:48<00:50, 282.77 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31699/47780 [01:48<00:38, 415.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23258/47780 [01:48<01:24, 289.74 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34178/47780 [01:48<00:43, 315.95 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33168/47780 [01:48<00:38, 376.34 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31829/47780 [01:48<00:59, 268.26 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32822/47780 [01:48<00:44, 337.47 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32310/47780 [01:48<00:51, 297.89 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33481/47780 [01:48<00:48, 294.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31741/47780 [01:48<00:42, 380.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23288/47780 [01:48<01:32, 266.17 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34210/47780 [01:48<00:43, 310.32 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33206/47780 [01:48<00:41, 349.00 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32856/47780 [01:48<00:45, 330.49 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31857/47780 [01:48<01:01, 260.07 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32341/47780 [01:48<00:52, 294.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33511/47780 [01:48<00:48, 291.96 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31780/47780 [01:48<00:43, 371.16 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23321/47780 [01:48<01:28, 277.24 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34242/47780 [01:48<00:46, 292.79 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33242/47780 [01:48<00:41, 348.13 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31884/47780 [01:48<01:00, 262.61 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32890/47780 [01:48<00:45, 325.72 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32372/47780 [01:48<00:52, 295.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33541/47780 [01:48<00:53, 267.99 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23353/47780 [01:48<01:25, 285.73 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31818/47780 [01:48<00:44, 357.85 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33279/47780 [01:48<00:41, 350.40 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34272/47780 [01:48<00:49, 273.81 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32404/47780 [01:48<00:51, 299.41 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32924/47780 [01:48<00:46, 322.84 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31911/47780 [01:48<01:03, 248.17 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33571/47780 [01:48<00:51, 276.60 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23382/47780 [01:48<01:27, 277.54 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34300/47780 [01:48<00:49, 272.54 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32959/47780 [01:48<00:45, 326.83 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32435/47780 [01:48<00:53, 289.28 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33315/47780 [01:48<00:46, 313.46 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31855/47780 [01:48<00:52, 304.49 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33609/47780 [01:48<00:46, 305.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31951/47780 [01:48<00:57, 274.52 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23410/47780 [01:48<01:28, 274.91 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34329/47780 [01:48<00:49, 274.21 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32993/47780 [01:48<00:45, 326.56 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33350/47780 [01:48<00:45, 316.68 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32465/47780 [01:48<00:54, 281.16 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31887/47780 [01:48<00:53, 296.36 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31986/47780 [01:48<00:53, 294.77 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33641/47780 [01:48<00:50, 280.39 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23438/47780 [01:48<01:31, 267.45 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34357/47780 [01:48<00:50, 266.72 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33026/47780 [01:48<00:46, 320.53 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33383/47780 [01:48<00:45, 316.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31919/47780 [01:48<00:52, 299.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32494/47780 [01:48<00:55, 273.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32016/47780 [01:48<00:54, 286.88 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33681/47780 [01:48<00:45, 309.76 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23468/47780 [01:48<01:28, 273.79 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33060/47780 [01:49<00:45, 322.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34384/47780 [01:48<00:51, 258.80 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33416/47780 [01:49<00:48, 297.49 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32525/47780 [01:49<00:56, 271.29 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31950/47780 [01:49<00:56, 281.40 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33713/47780 [01:49<00:46, 302.21 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32045/47780 [01:49<00:59, 263.90 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23497/47780 [01:49<01:31, 266.07 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33093/47780 [01:49<00:45, 320.94 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34414/47780 [01:49<00:49, 267.60 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32556/47780 [01:49<00:54, 278.88 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33447/47780 [01:49<00:49, 288.47 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31985/47780 [01:49<00:53, 293.28 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32072/47780 [01:49<01:01, 257.50 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23524/47780 [01:49<01:35, 253.02 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33744/47780 [01:49<00:49, 281.90 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34441/47780 [01:49<00:50, 262.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33126/47780 [01:49<00:47, 308.88 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32586/47780 [01:49<00:53, 281.70 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32023/47780 [01:49<00:50, 309.69 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33477/47780 [01:49<00:51, 279.33 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32107/47780 [01:49<00:56, 276.66 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33774/47780 [01:49<00:49, 284.70 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23560/47780 [01:49<01:28, 273.61 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34468/47780 [01:49<00:51, 258.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33158/47780 [01:49<00:47, 308.90 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32057/47780 [01:49<00:49, 314.59 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32615/47780 [01:49<00:55, 271.40 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33510/47780 [01:49<00:49, 286.95 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32137/47780 [01:49<00:55, 279.94 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23597/47780 [01:49<01:20, 299.22 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33808/47780 [01:49<00:48, 287.24 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33189/47780 [01:49<00:47, 309.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34494/47780 [01:49<00:53, 250.23 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32649/47780 [01:49<00:52, 287.55 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32089/47780 [01:49<00:51, 306.01 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33545/47780 [01:49<00:47, 300.94 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32170/47780 [01:49<00:53, 290.73 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33842/47780 [01:49<00:46, 298.55 examples/s]
Tokenizing train dataset (num_proc=32):  49%|████▉     | 23628/47780 [01:49<01:23, 290.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33220/47780 [01:49<00:47, 305.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34520/47780 [01:49<00:53, 247.77 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32679/47780 [01:49<00:52, 288.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32128/47780 [01:49<00:47, 329.13 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33576/47780 [01:49<00:48, 293.22 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32209/47780 [01:49<00:49, 311.64 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33878/47780 [01:49<00:44, 312.09 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23664/47780 [01:49<01:18, 306.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33252/47780 [01:49<00:47, 302.70 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34546/47780 [01:49<00:53, 248.22 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32708/47780 [01:49<00:52, 287.97 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32162/47780 [01:49<00:49, 317.70 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33611/47780 [01:49<00:46, 306.02 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32241/47780 [01:49<00:52, 296.84 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23698/47780 [01:49<01:17, 312.21 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33910/47780 [01:49<00:46, 300.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33289/47780 [01:49<00:45, 318.75 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34571/47780 [01:49<00:57, 227.81 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33642/47780 [01:49<00:47, 300.52 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32737/47780 [01:49<00:57, 263.52 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32195/47780 [01:49<00:51, 304.38 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32274/47780 [01:49<00:51, 303.14 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23737/47780 [01:49<01:11, 334.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33950/47780 [01:49<00:42, 324.73 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33325/47780 [01:49<00:44, 323.20 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34599/47780 [01:49<00:56, 234.55 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33676/47780 [01:49<00:45, 311.60 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32775/47780 [01:49<00:51, 293.21 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23771/47780 [01:49<01:13, 327.94 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33983/47780 [01:49<00:43, 319.84 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32227/47780 [01:49<00:54, 286.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33360/47780 [01:49<00:43, 330.73 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32305/47780 [01:49<00:57, 270.79 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34625/47780 [01:49<00:54, 241.43 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32805/47780 [01:49<00:51, 288.30 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33709/47780 [01:50<00:47, 296.42 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23807/47780 [01:49<01:12, 330.08 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34017/47780 [01:50<00:42, 324.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33396/47780 [01:50<00:42, 338.71 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32256/47780 [01:50<00:57, 270.33 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32333/47780 [01:50<00:57, 268.25 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34651/47780 [01:50<00:55, 236.20 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32835/47780 [01:50<00:53, 279.10 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33739/47780 [01:50<00:49, 284.84 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23842/47780 [01:50<01:12, 331.71 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33434/47780 [01:50<00:41, 343.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34050/47780 [01:50<00:44, 311.78 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32371/47780 [01:50<00:52, 292.09 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32285/47780 [01:50<00:58, 264.41 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34676/47780 [01:50<00:54, 239.92 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33773/47780 [01:50<00:47, 296.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32864/47780 [01:50<00:56, 262.11 examples/s]
Tokenizing train dataset (num_proc=32):  50%|████▉     | 23876/47780 [01:50<01:17, 309.20 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33469/47780 [01:50<00:43, 328.73 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34082/47780 [01:50<00:46, 294.04 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32404/47780 [01:50<00:51, 295.77 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34703/47780 [01:50<00:53, 246.15 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32312/47780 [01:50<01:03, 245.03 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33812/47780 [01:50<00:44, 315.87 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32897/47780 [01:50<00:53, 280.23 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23910/47780 [01:50<01:15, 314.44 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33503/47780 [01:50<00:43, 329.11 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32443/47780 [01:50<00:48, 315.14 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34112/47780 [01:50<00:48, 283.53 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32338/47780 [01:50<01:02, 248.82 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34730/47780 [01:50<00:52, 247.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33849/47780 [01:50<00:42, 327.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32929/47780 [01:50<00:52, 285.02 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23945/47780 [01:50<01:15, 317.23 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33537/47780 [01:50<00:44, 321.59 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32475/47780 [01:50<00:48, 316.40 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34143/47780 [01:50<00:46, 290.66 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32364/47780 [01:50<01:02, 246.15 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34756/47780 [01:50<00:52, 247.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32960/47780 [01:50<00:51, 288.84 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33882/47780 [01:50<00:44, 313.78 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 23978/47780 [01:50<01:15, 313.72 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33572/47780 [01:50<00:44, 322.36 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34173/47780 [01:50<00:47, 287.08 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32507/47780 [01:50<00:51, 293.90 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32392/47780 [01:50<01:00, 253.08 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34781/47780 [01:50<00:55, 234.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32990/47780 [01:50<00:51, 288.74 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33914/47780 [01:50<00:44, 310.44 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24010/47780 [01:50<01:15, 315.35 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33605/47780 [01:50<00:44, 316.18 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34203/47780 [01:50<00:47, 287.38 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32544/47780 [01:50<00:48, 314.54 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32421/47780 [01:50<00:58, 262.78 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34809/47780 [01:50<00:53, 242.47 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33023/47780 [01:50<00:49, 297.03 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24043/47780 [01:50<01:14, 319.49 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33646/47780 [01:50<00:42, 336.33 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34232/47780 [01:50<00:47, 284.35 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33946/47780 [01:50<00:49, 278.43 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32576/47780 [01:50<00:49, 309.47 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32448/47780 [01:50<01:02, 245.93 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34834/47780 [01:50<00:53, 241.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33057/47780 [01:50<00:47, 309.36 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24077/47780 [01:50<01:13, 322.01 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33681/47780 [01:50<00:41, 339.94 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34264/47780 [01:50<00:46, 289.58 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33977/47780 [01:50<00:48, 284.43 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32608/47780 [01:50<00:50, 301.84 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34864/47780 [01:50<00:50, 255.60 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32475/47780 [01:50<01:03, 240.66 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33089/47780 [01:50<00:47, 308.93 examples/s]
Tokenizing train dataset (num_proc=32):  50%|█████     | 24110/47780 [01:50<01:14, 317.13 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34295/47780 [01:51<00:45, 294.38 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33722/47780 [01:51<00:40, 348.36 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34006/47780 [01:51<00:48, 285.14 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32639/47780 [01:51<00:50, 300.91 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32514/47780 [01:51<00:54, 279.64 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34890/47780 [01:51<00:52, 245.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33125/47780 [01:51<00:45, 320.13 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34326/47780 [01:51<00:45, 298.90 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24142/47780 [01:51<01:18, 300.41 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33761/47780 [01:51<00:39, 356.25 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34037/47780 [01:51<00:47, 287.41 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32676/47780 [01:51<00:48, 310.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32546/47780 [01:51<00:53, 284.53 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33161/47780 [01:51<00:44, 327.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34915/47780 [01:51<00:54, 236.11 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24173/47780 [01:51<01:19, 298.43 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34068/47780 [01:51<00:48, 284.10 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33797/47780 [01:51<00:41, 334.31 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34356/47780 [01:51<00:49, 270.18 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32711/47780 [01:51<00:48, 307.58 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32575/47780 [01:51<00:53, 285.42 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33194/47780 [01:51<00:44, 328.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34943/47780 [01:51<00:52, 245.67 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24213/47780 [01:51<01:12, 323.91 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34097/47780 [01:51<00:50, 270.68 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34393/47780 [01:51<00:46, 288.63 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33831/47780 [01:51<00:43, 321.65 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32744/47780 [01:51<00:48, 310.26 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32604/47780 [01:51<00:53, 285.10 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33227/47780 [01:51<00:44, 325.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34970/47780 [01:51<00:51, 249.65 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24247/47780 [01:51<01:12, 325.92 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34127/47780 [01:51<00:49, 275.75 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33868/47780 [01:51<00:41, 334.86 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32777/47780 [01:51<00:47, 315.69 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34424/47780 [01:51<00:46, 285.11 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34998/47780 [01:51<00:49, 258.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33260/47780 [01:51<00:45, 322.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32634/47780 [01:51<00:56, 269.30 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24280/47780 [01:51<01:13, 319.17 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34157/47780 [01:51<00:48, 282.41 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33905/47780 [01:51<00:40, 340.83 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32810/47780 [01:51<00:46, 319.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34459/47780 [01:51<00:43, 302.85 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35025/47780 [01:51<00:50, 250.19 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33297/47780 [01:51<00:45, 321.72 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32663/47780 [01:51<00:56, 266.69 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24313/47780 [01:51<01:17, 301.97 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34186/47780 [01:51<00:48, 281.27 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32847/47780 [01:51<00:45, 330.84 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34494/47780 [01:51<00:42, 316.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33940/47780 [01:51<00:42, 328.51 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35054/47780 [01:51<00:49, 255.54 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33331/47780 [01:51<00:45, 316.14 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32690/47780 [01:51<00:58, 255.93 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24349/47780 [01:51<01:14, 314.57 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33974/47780 [01:51<00:41, 331.34 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34526/47780 [01:51<00:43, 303.51 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34215/47780 [01:51<00:51, 262.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32881/47780 [01:51<00:47, 311.42 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35085/47780 [01:51<00:46, 270.87 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33367/47780 [01:51<00:44, 324.80 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32728/47780 [01:51<00:52, 287.26 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34012/47780 [01:51<00:40, 341.87 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24381/47780 [01:51<01:21, 287.11 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34557/47780 [01:51<00:44, 295.33 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34243/47780 [01:51<00:51, 261.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32914/47780 [01:51<00:47, 313.34 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35121/47780 [01:51<00:43, 290.13 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33400/47780 [01:51<00:46, 310.45 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32758/47780 [01:51<00:53, 283.00 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34047/47780 [01:52<00:39, 343.69 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24411/47780 [01:51<01:23, 281.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34587/47780 [01:52<00:45, 289.35 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34270/47780 [01:52<00:53, 252.74 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32946/47780 [01:52<00:50, 294.69 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35151/47780 [01:52<00:44, 282.75 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32794/47780 [01:52<00:49, 303.91 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33436/47780 [01:52<00:44, 318.88 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34092/47780 [01:52<00:36, 371.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34618/47780 [01:52<00:44, 292.69 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24440/47780 [01:52<01:24, 277.80 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34296/47780 [01:52<00:53, 253.96 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32980/47780 [01:52<00:48, 306.14 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32829/47780 [01:52<00:47, 315.86 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35180/47780 [01:52<00:45, 274.64 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33476/47780 [01:52<00:42, 337.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34139/47780 [01:52<00:34, 394.98 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████     | 24469/47780 [01:52<01:23, 278.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34327/47780 [01:52<00:50, 267.65 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34648/47780 [01:52<00:47, 278.87 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33011/47780 [01:52<00:49, 295.46 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32868/47780 [01:52<00:44, 337.07 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33510/47780 [01:52<00:42, 334.41 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35208/47780 [01:52<00:47, 261.93 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34185/47780 [01:52<00:33, 406.80 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24501/47780 [01:52<01:21, 286.63 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34361/47780 [01:52<00:47, 285.04 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32904/47780 [01:52<00:44, 336.06 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33041/47780 [01:52<00:51, 287.07 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34677/47780 [01:52<00:49, 264.41 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33545/47780 [01:52<00:45, 314.03 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35235/47780 [01:52<00:51, 245.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34227/47780 [01:52<00:33, 399.01 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34392/47780 [01:52<00:45, 291.84 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24530/47780 [01:52<01:22, 281.21 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32938/47780 [01:52<00:44, 332.76 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33079/47780 [01:52<00:47, 309.43 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34714/47780 [01:52<00:45, 289.66 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35265/47780 [01:52<00:49, 254.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33577/47780 [01:52<00:48, 293.04 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34269/47780 [01:52<00:36, 370.07 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34422/47780 [01:52<00:47, 278.41 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24560/47780 [01:52<01:23, 277.09 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32972/47780 [01:52<00:45, 323.84 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33111/47780 [01:52<00:49, 299.15 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34744/47780 [01:52<00:46, 280.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35297/47780 [01:52<00:45, 272.45 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34453/47780 [01:52<00:46, 284.07 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33607/47780 [01:52<00:53, 266.17 examples/s]
Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24588/47780 [01:52<01:26, 268.83 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33142/47780 [01:52<00:49, 298.59 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34773/47780 [01:52<00:47, 276.36 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33005/47780 [01:52<00:48, 301.60 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34307/47780 [01:52<00:41, 320.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35325/47780 [01:52<00:46, 268.78 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33635/47780 [01:52<00:53, 264.59 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24620/47780 [01:52<01:22, 280.29 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34482/47780 [01:52<00:48, 276.39 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34805/47780 [01:52<00:45, 285.72 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33172/47780 [01:52<00:51, 283.15 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35354/47780 [01:52<00:47, 263.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34341/47780 [01:52<00:44, 304.43 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33036/47780 [01:52<00:56, 263.23 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33662/47780 [01:52<00:54, 260.51 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34510/47780 [01:52<00:48, 271.00 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24649/47780 [01:52<01:26, 267.33 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33203/47780 [01:52<00:50, 289.01 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34834/47780 [01:52<00:46, 277.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35382/47780 [01:52<00:47, 261.75 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34373/47780 [01:52<00:45, 293.54 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34538/47780 [01:52<00:49, 267.22 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33064/47780 [01:52<00:59, 247.71 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33689/47780 [01:52<00:55, 252.15 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24684/47780 [01:52<01:21, 284.21 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33247/47780 [01:53<00:44, 329.70 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34863/47780 [01:53<00:46, 277.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35413/47780 [01:53<00:44, 274.96 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34403/47780 [01:53<00:47, 280.85 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33720/47780 [01:53<00:53, 262.12 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24718/47780 [01:53<01:17, 298.51 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33090/47780 [01:53<01:00, 243.45 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34567/47780 [01:53<00:50, 262.18 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33281/47780 [01:53<00:44, 328.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34892/47780 [01:53<00:46, 278.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35441/47780 [01:53<00:46, 267.07 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34432/47780 [01:53<00:49, 272.12 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33751/47780 [01:53<00:51, 274.36 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33117/47780 [01:53<00:58, 250.13 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34602/47780 [01:53<00:46, 285.69 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24750/47780 [01:53<01:17, 295.91 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34927/47780 [01:53<00:43, 298.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33315/47780 [01:53<00:47, 306.82 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35468/47780 [01:53<00:50, 243.04 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34473/47780 [01:53<00:43, 308.03 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33780/47780 [01:53<00:50, 278.29 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34631/47780 [01:53<00:46, 282.82 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33143/47780 [01:53<00:59, 246.25 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24784/47780 [01:53<01:15, 304.96 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34958/47780 [01:53<00:43, 295.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33348/47780 [01:53<00:46, 309.84 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35495/47780 [01:53<00:49, 249.19 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34505/47780 [01:53<00:42, 311.02 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34661/47780 [01:53<00:46, 280.15 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33176/47780 [01:53<00:55, 264.85 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24821/47780 [01:53<01:12, 316.19 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33809/47780 [01:53<00:53, 261.51 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34989/47780 [01:53<00:43, 292.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33380/47780 [01:53<00:47, 300.84 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35521/47780 [01:53<00:48, 250.81 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34537/47780 [01:53<00:44, 300.11 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34691/47780 [01:53<00:46, 281.38 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24858/47780 [01:53<01:09, 327.75 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33841/47780 [01:53<00:51, 272.15 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35029/47780 [01:53<00:39, 323.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33203/47780 [01:53<00:58, 247.17 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33417/47780 [01:53<00:47, 305.29 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35549/47780 [01:53<00:48, 250.82 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24891/47780 [01:53<01:10, 324.76 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34573/47780 [01:53<00:44, 299.10 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35064/47780 [01:53<00:39, 323.63 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33231/47780 [01:53<00:56, 255.93 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34720/47780 [01:53<00:48, 266.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33869/47780 [01:53<00:54, 257.26 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33448/47780 [01:53<00:47, 303.06 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35575/47780 [01:53<00:49, 244.72 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24940/47780 [01:53<01:01, 371.37 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33267/47780 [01:53<00:51, 281.71 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33898/47780 [01:53<00:52, 266.09 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34604/47780 [01:53<00:46, 281.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34755/47780 [01:53<00:46, 277.48 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35097/47780 [01:53<00:43, 294.81 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33479/47780 [01:53<00:47, 298.56 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35600/47780 [01:53<00:51, 238.21 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33302/47780 [01:53<00:48, 297.54 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24978/47780 [01:53<01:05, 350.02 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33925/47780 [01:53<00:51, 267.13 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34640/47780 [01:53<00:44, 296.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34788/47780 [01:53<00:45, 282.60 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35129/47780 [01:53<00:43, 292.15 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33509/47780 [01:53<00:48, 292.32 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35626/47780 [01:53<00:50, 242.05 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33333/47780 [01:53<00:48, 298.97 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33957/47780 [01:53<00:49, 282.02 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34670/47780 [01:54<00:45, 291.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34821/47780 [01:53<00:44, 293.03 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25014/47780 [01:53<01:11, 317.53 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33541/47780 [01:53<00:47, 296.82 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35159/47780 [01:54<00:48, 262.78 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35651/47780 [01:54<00:51, 236.27 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33989/47780 [01:54<00:47, 289.80 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33364/47780 [01:54<00:49, 293.87 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34853/47780 [01:54<00:43, 296.74 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34700/47780 [01:54<00:47, 275.45 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25047/47780 [01:54<01:11, 317.51 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33571/47780 [01:54<00:50, 281.49 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35679/47780 [01:54<00:49, 245.78 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35191/47780 [01:54<00:47, 266.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 34019/47780 [01:54<00:47, 289.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33394/47780 [01:54<00:51, 279.50 examples/s]
Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25082/47780 [01:54<01:09, 326.36 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34731/47780 [01:54<00:45, 284.48 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34884/47780 [01:54<00:45, 283.88 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33601/47780 [01:54<00:51, 274.59 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35707/47780 [01:54<00:47, 255.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35220/47780 [01:54<00:48, 261.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33425/47780 [01:54<00:50, 285.15 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34049/47780 [01:54<00:51, 267.52 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34768/47780 [01:54<00:42, 308.22 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25116/47780 [01:54<01:10, 322.94 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34913/47780 [01:54<00:46, 279.17 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33629/47780 [01:54<00:52, 270.00 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35736/47780 [01:54<00:45, 262.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35247/47780 [01:54<00:47, 261.14 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34078/47780 [01:54<00:50, 270.92 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25149/47780 [01:54<01:09, 324.92 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34800/47780 [01:54<00:43, 300.94 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34942/47780 [01:54<00:46, 276.69 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33454/47780 [01:54<00:53, 265.37 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35767/47780 [01:54<00:44, 269.84 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35274/47780 [01:54<00:48, 257.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33657/47780 [01:54<00:57, 245.63 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34834/47780 [01:54<00:41, 308.90 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34107/47780 [01:54<00:51, 264.35 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25182/47780 [01:54<01:13, 308.35 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34970/47780 [01:54<00:47, 268.35 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33481/47780 [01:54<00:57, 247.94 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35306/47780 [01:54<00:45, 274.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33686/47780 [01:54<00:56, 249.36 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35795/47780 [01:54<00:49, 242.86 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34867/47780 [01:54<00:41, 311.41 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34134/47780 [01:54<00:51, 265.56 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25215/47780 [01:54<01:12, 311.37 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34997/47780 [01:54<00:48, 262.97 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33510/47780 [01:54<00:55, 258.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35336/47780 [01:54<00:46, 267.01 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35849/47780 [01:54<00:37, 321.66 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33714/47780 [01:54<00:55, 252.24 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34161/47780 [01:54<00:51, 264.24 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34902/47780 [01:54<00:40, 318.90 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25249/47780 [01:54<01:10, 319.38 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35029/47780 [01:54<00:45, 278.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33537/47780 [01:54<00:56, 253.52 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35368/47780 [01:54<00:45, 275.22 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33740/47780 [01:54<00:56, 250.08 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25282/47780 [01:54<01:09, 322.22 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34936/47780 [01:54<00:40, 313.89 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34188/47780 [01:54<00:53, 253.90 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35883/47780 [01:54<00:42, 282.13 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33563/47780 [01:54<00:56, 251.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35058/47780 [01:54<00:49, 258.62 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35396/47780 [01:54<00:48, 256.39 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34968/47780 [01:54<00:41, 305.32 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33766/47780 [01:54<01:01, 228.90 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34214/47780 [01:54<00:56, 242.25 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35921/47780 [01:54<00:38, 304.80 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33590/47780 [01:54<00:56, 252.53 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35087/47780 [01:54<00:47, 267.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25315/47780 [01:54<01:18, 284.83 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33790/47780 [01:55<01:00, 231.72 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35422/47780 [01:55<00:51, 239.81 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35001/47780 [01:55<00:42, 298.70 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34239/47780 [01:55<00:56, 241.32 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33621/47780 [01:55<00:52, 268.62 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35953/47780 [01:55<00:39, 302.81 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35118/47780 [01:55<00:45, 276.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25345/47780 [01:55<01:18, 285.81 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34276/47780 [01:55<00:49, 271.82 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33650/47780 [01:55<00:52, 271.58 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35148/47780 [01:55<00:45, 279.80 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25376/47780 [01:55<01:16, 292.18 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33814/47780 [01:55<01:06, 211.12 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35031/47780 [01:55<00:45, 277.33 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35447/47780 [01:55<00:55, 223.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35985/47780 [01:55<00:41, 285.50 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33678/47780 [01:55<00:52, 268.04 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34304/47780 [01:55<00:50, 264.90 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35177/47780 [01:55<00:45, 279.14 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25406/47780 [01:55<01:16, 291.02 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33851/47780 [01:55<00:55, 249.79 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35063/47780 [01:55<00:44, 283.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35470/47780 [01:55<00:55, 223.04 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36015/47780 [01:55<00:45, 261.26 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33713/47780 [01:55<00:48, 288.25 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25440/47780 [01:55<01:13, 301.91 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34335/47780 [01:55<00:49, 271.67 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33890/47780 [01:55<00:48, 287.50 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35092/47780 [01:55<00:44, 284.95 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35206/47780 [01:55<00:46, 267.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35494/47780 [01:55<00:54, 225.16 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36043/47780 [01:55<00:45, 255.97 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33742/47780 [01:55<00:48, 288.25 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33926/47780 [01:55<00:45, 307.46 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25471/47780 [01:55<01:15, 294.21 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34363/47780 [01:55<00:51, 259.48 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35527/47780 [01:55<00:49, 248.48 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35122/47780 [01:55<00:45, 277.34 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35233/47780 [01:55<00:49, 252.97 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36082/47780 [01:55<00:40, 290.50 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33777/47780 [01:55<00:46, 299.81 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25503/47780 [01:55<01:15, 294.69 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34390/47780 [01:55<00:52, 256.49 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33959/47780 [01:55<00:47, 290.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35259/47780 [01:55<00:49, 252.81 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35554/47780 [01:55<00:50, 240.63 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35150/47780 [01:55<00:48, 260.13 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36115/47780 [01:55<00:39, 298.18 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33811/47780 [01:55<00:45, 308.01 examples/s]
Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25540/47780 [01:55<01:11, 312.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34420/47780 [01:55<00:50, 265.86 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35290/47780 [01:55<00:47, 262.94 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35597/47780 [01:55<00:42, 289.58 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35182/47780 [01:55<00:45, 276.34 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33989/47780 [01:55<00:49, 280.93 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36148/47780 [01:55<00:39, 295.90 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33842/47780 [01:55<00:47, 296.25 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34452/47780 [01:55<00:47, 280.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25572/47780 [01:55<01:13, 303.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35318/47780 [01:55<00:46, 267.70 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34022/47780 [01:55<00:47, 288.35 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35212/47780 [01:55<00:45, 276.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35627/47780 [01:55<00:44, 274.11 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36181/47780 [01:55<00:38, 303.18 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34481/47780 [01:55<00:47, 280.54 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33872/47780 [01:55<00:48, 285.83 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25603/47780 [01:55<01:14, 298.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35348/47780 [01:55<00:45, 273.85 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34054/47780 [01:55<00:47, 290.78 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35241/47780 [01:55<00:46, 271.34 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35655/47780 [01:55<00:43, 275.68 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36212/47780 [01:55<00:37, 304.77 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34510/47780 [01:56<00:47, 279.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33903/47780 [01:56<00:48, 286.34 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25634/47780 [01:56<01:15, 292.41 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35269/47780 [01:56<00:45, 273.55 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35376/47780 [01:56<00:48, 258.23 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34084/47780 [01:56<00:48, 283.48 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35683/47780 [01:56<00:46, 259.70 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36243/47780 [01:56<00:38, 299.34 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33939/47780 [01:56<00:45, 303.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34539/47780 [01:56<00:49, 267.56 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25664/47780 [01:56<01:17, 285.94 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35297/47780 [01:56<00:46, 269.53 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34117/47780 [01:56<00:46, 296.36 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35403/47780 [01:56<00:48, 252.60 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35710/47780 [01:56<00:46, 257.42 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36275/47780 [01:56<00:38, 299.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33975/47780 [01:56<00:44, 312.73 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25693/47780 [01:56<01:18, 282.59 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34567/47780 [01:56<00:50, 259.86 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35325/47780 [01:56<00:45, 272.49 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34149/47780 [01:56<00:45, 300.00 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35429/47780 [01:56<00:49, 251.90 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36307/47780 [01:56<00:37, 304.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35736/47780 [01:56<00:48, 249.00 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34007/47780 [01:56<00:46, 294.78 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34180/47780 [01:56<00:44, 302.65 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25722/47780 [01:56<01:20, 272.61 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35353/47780 [01:56<00:46, 265.40 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35455/47780 [01:56<00:51, 240.50 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36348/47780 [01:56<00:34, 327.49 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35766/47780 [01:56<00:46, 260.47 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34594/47780 [01:56<01:01, 215.52 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25752/47780 [01:56<01:18, 280.04 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35380/47780 [01:56<00:47, 263.70 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34038/47780 [01:56<00:48, 283.32 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34211/47780 [01:56<00:47, 285.60 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35480/47780 [01:56<00:50, 242.98 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35799/47780 [01:56<00:43, 276.92 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36381/47780 [01:56<00:35, 317.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34623/47780 [01:56<00:56, 232.67 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34240/47780 [01:56<00:47, 286.37 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34072/47780 [01:56<00:46, 295.47 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35407/47780 [01:56<00:49, 251.09 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25781/47780 [01:56<01:24, 259.24 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35834/47780 [01:56<00:40, 294.26 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36416/47780 [01:56<00:35, 322.81 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35506/47780 [01:56<00:54, 225.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34654/47780 [01:56<00:52, 250.00 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34111/47780 [01:56<00:42, 321.49 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34269/47780 [01:56<00:49, 271.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35866/47780 [01:56<00:40, 295.80 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35439/47780 [01:56<00:48, 255.94 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36452/47780 [01:56<00:35, 318.89 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35538/47780 [01:56<00:50, 242.87 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25808/47780 [01:56<01:32, 238.81 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34681/47780 [01:56<00:59, 219.88 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34152/47780 [01:56<00:41, 329.71 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35465/47780 [01:56<00:48, 253.81 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34298/47780 [01:56<00:51, 262.35 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35896/47780 [01:56<00:41, 285.92 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35564/47780 [01:56<00:49, 247.42 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25845/47780 [01:56<01:20, 273.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36484/47780 [01:56<00:38, 295.62 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34203/47780 [01:56<00:35, 378.15 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34705/47780 [01:56<01:00, 216.49 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35925/47780 [01:56<00:42, 278.06 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34325/47780 [01:56<00:53, 251.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35491/47780 [01:56<00:52, 235.12 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25874/47780 [01:56<01:24, 260.70 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36514/47780 [01:56<00:38, 290.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35589/47780 [01:56<00:52, 232.34 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34733/47780 [01:57<00:57, 227.93 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35958/47780 [01:57<00:40, 292.65 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34242/47780 [01:57<00:39, 342.79 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34351/47780 [01:57<00:53, 253.00 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35524/47780 [01:57<00:47, 260.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25907/47780 [01:57<01:19, 276.39 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36544/47780 [01:57<00:39, 286.80 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35623/47780 [01:57<00:47, 253.45 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34761/47780 [01:57<00:56, 231.86 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34377/47780 [01:57<00:52, 254.87 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35988/47780 [01:57<00:43, 270.06 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25942/47780 [01:57<01:15, 288.22 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35650/47780 [01:57<00:47, 255.44 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34278/47780 [01:57<00:42, 316.89 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35551/47780 [01:57<00:50, 241.43 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36573/47780 [01:57<00:40, 275.77 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34791/47780 [01:57<00:52, 247.44 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34404/47780 [01:57<00:52, 253.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36027/47780 [01:57<00:38, 302.59 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35676/47780 [01:57<00:47, 253.80 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25974/47780 [01:57<01:15, 289.49 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35581/47780 [01:57<00:48, 252.77 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34311/47780 [01:57<00:43, 311.99 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36601/47780 [01:57<00:43, 257.63 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34824/47780 [01:57<00:48, 269.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34437/47780 [01:57<00:49, 272.21 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35703/47780 [01:57<00:47, 255.32 examples/s]
Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26014/47780 [01:57<01:08, 316.68 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36058/47780 [01:57<00:40, 287.72 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34343/47780 [01:57<00:43, 309.34 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35607/47780 [01:57<00:50, 241.27 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36634/47780 [01:57<00:40, 273.13 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34852/47780 [01:57<00:47, 269.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34466/47780 [01:57<00:48, 277.27 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35732/47780 [01:57<00:45, 262.26 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26057/47780 [01:57<01:03, 344.73 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36092/47780 [01:57<00:40, 290.20 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35632/47780 [01:57<00:51, 237.90 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36665/47780 [01:57<00:39, 280.55 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34375/47780 [01:57<00:45, 293.14 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34889/47780 [01:57<00:45, 284.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34501/47780 [01:57<00:47, 282.05 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26092/47780 [01:57<01:03, 342.09 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35761/47780 [01:57<00:46, 261.25 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34406/47780 [01:57<00:44, 297.42 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36122/47780 [01:57<00:41, 277.71 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35657/47780 [01:57<00:51, 234.76 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36695/47780 [01:57<00:40, 276.69 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34923/47780 [01:57<00:44, 290.96 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34531/47780 [01:57<00:46, 283.78 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35788/47780 [01:57<00:45, 263.62 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26127/47780 [01:57<01:05, 333.09 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34442/47780 [01:57<00:42, 314.63 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36151/47780 [01:57<00:41, 280.91 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35684/47780 [01:57<00:50, 239.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36725/47780 [01:57<00:39, 280.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34953/47780 [01:57<00:45, 283.49 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34564/47780 [01:57<00:46, 284.11 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35816/47780 [01:57<00:45, 262.75 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36180/47780 [01:57<00:40, 283.07 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26161/47780 [01:57<01:09, 313.08 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34474/47780 [01:57<00:43, 302.79 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35713/47780 [01:57<00:48, 249.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36754/47780 [01:57<00:39, 279.27 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34593/47780 [01:57<00:48, 273.47 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35843/47780 [01:57<00:46, 255.75 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34982/47780 [01:57<00:49, 259.75 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36214/47780 [01:57<00:39, 296.41 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26194/47780 [01:57<01:10, 308.23 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34506/47780 [01:57<00:44, 300.90 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35743/47780 [01:57<00:46, 260.60 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36783/47780 [01:57<00:39, 276.32 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34624/47780 [01:58<00:46, 283.47 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36251/47780 [01:58<00:36, 313.99 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35869/47780 [01:58<00:48, 245.02 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35777/47780 [01:58<00:42, 283.05 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34542/47780 [01:58<00:42, 313.93 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35009/47780 [01:58<00:52, 244.34 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36811/47780 [01:58<00:41, 265.06 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26226/47780 [01:58<01:19, 269.88 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36288/47780 [01:58<00:35, 326.33 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34653/47780 [01:58<00:50, 257.59 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34583/47780 [01:58<00:39, 334.97 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35894/47780 [01:58<00:51, 231.61 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35806/47780 [01:58<00:44, 269.45 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36839/47780 [01:58<00:41, 266.21 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35037/47780 [01:58<00:52, 240.97 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26265/47780 [01:58<01:12, 297.31 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36326/47780 [01:58<00:33, 341.86 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34680/47780 [01:58<00:50, 256.96 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34619/47780 [01:58<00:39, 337.00 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35924/47780 [01:58<00:48, 244.94 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36866/47780 [01:58<00:41, 262.99 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35063/47780 [01:58<00:52, 243.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35840/47780 [01:58<00:43, 277.12 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26305/47780 [01:58<01:07, 320.38 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36361/47780 [01:58<00:34, 328.32 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35949/47780 [01:58<00:48, 245.28 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36899/47780 [01:58<00:38, 279.05 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34708/47780 [01:58<00:52, 247.02 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35875/47780 [01:58<00:40, 297.24 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35088/47780 [01:58<00:52, 240.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34653/47780 [01:58<00:41, 315.94 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26340/47780 [01:58<01:07, 315.30 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36395/47780 [01:58<00:36, 310.91 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36927/47780 [01:58<00:39, 277.30 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35113/47780 [01:58<00:52, 242.79 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34739/47780 [01:58<00:51, 255.66 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35975/47780 [01:58<00:50, 234.39 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35905/47780 [01:58<00:41, 285.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34685/47780 [01:58<00:42, 306.72 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26375/47780 [01:58<01:05, 324.41 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36429/47780 [01:58<00:35, 315.43 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35141/47780 [01:58<00:51, 247.35 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36001/47780 [01:58<00:48, 241.24 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36965/47780 [01:58<00:36, 293.91 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34765/47780 [01:58<00:51, 250.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35934/47780 [01:58<00:42, 279.98 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26408/47780 [01:58<01:08, 312.47 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34716/47780 [01:58<00:49, 266.55 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36461/47780 [01:58<00:37, 303.07 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36995/47780 [01:58<00:36, 292.26 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36029/47780 [01:58<00:47, 245.04 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35168/47780 [01:58<00:51, 245.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34803/47780 [01:58<00:45, 283.85 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35963/47780 [01:58<00:45, 261.68 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26440/47780 [01:58<01:10, 304.28 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34746/47780 [01:58<00:47, 272.35 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36494/47780 [01:58<00:36, 310.32 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37029/47780 [01:58<00:35, 302.39 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34836/47780 [01:58<00:43, 296.66 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36054/47780 [01:58<00:47, 245.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35196/47780 [01:58<00:49, 252.48 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35990/47780 [01:58<00:45, 258.82 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34774/47780 [01:58<00:48, 265.61 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26471/47780 [01:58<01:14, 286.95 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37064/47780 [01:58<00:34, 312.50 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34870/47780 [01:58<00:42, 302.23 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35225/47780 [01:58<00:48, 260.20 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36079/47780 [01:58<00:48, 241.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36527/47780 [01:58<00:37, 298.96 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36017/47780 [01:59<00:48, 244.73 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34802/47780 [01:58<00:50, 258.48 examples/s]
Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26501/47780 [01:58<01:17, 275.92 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35252/47780 [01:59<00:48, 260.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34901/47780 [01:59<00:42, 300.73 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36104/47780 [01:59<00:49, 233.84 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37096/47780 [01:59<00:36, 294.23 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36558/47780 [01:59<00:40, 280.45 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36046/47780 [01:59<00:46, 252.67 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34833/47780 [01:59<00:48, 266.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26529/47780 [01:59<01:19, 268.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34932/47780 [01:59<00:43, 295.08 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37128/47780 [01:59<00:35, 298.16 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36128/47780 [01:59<00:51, 227.30 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36588/47780 [01:59<00:39, 285.61 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35279/47780 [01:59<00:53, 233.37 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36072/47780 [01:59<00:47, 249.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34861/47780 [01:59<00:48, 267.42 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36151/47780 [01:59<00:51, 227.70 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34962/47780 [01:59<00:45, 282.81 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26556/47780 [01:59<01:26, 244.28 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36617/47780 [01:59<00:40, 277.65 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35303/47780 [01:59<00:56, 220.59 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37158/47780 [01:59<00:40, 260.48 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36108/47780 [01:59<00:42, 272.47 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34888/47780 [01:59<00:48, 267.65 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26583/47780 [01:59<01:25, 248.90 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34991/47780 [01:59<00:46, 277.96 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36655/47780 [01:59<00:36, 305.81 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36174/47780 [01:59<00:56, 205.96 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37188/47780 [01:59<00:39, 270.68 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35331/47780 [01:59<00:52, 235.07 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36154/47780 [01:59<00:37, 312.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34918/47780 [01:59<00:47, 271.19 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26612/47780 [01:59<01:22, 257.17 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36689/47780 [01:59<00:35, 310.45 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35019/47780 [01:59<00:47, 266.44 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36195/47780 [01:59<00:56, 204.28 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35355/47780 [01:59<00:53, 231.24 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34952/47780 [01:59<00:44, 290.77 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36195/47780 [01:59<00:34, 335.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37216/47780 [01:59<00:40, 258.89 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26639/47780 [01:59<01:25, 246.82 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36721/47780 [01:59<00:36, 304.18 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35049/47780 [01:59<00:47, 270.02 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36217/47780 [01:59<00:56, 206.25 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35381/47780 [01:59<00:52, 238.42 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34991/47780 [01:59<00:40, 315.90 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36236/47780 [01:59<00:33, 348.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37246/47780 [01:59<00:39, 264.44 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36752/47780 [01:59<00:36, 302.83 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35077/47780 [01:59<00:46, 272.51 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26666/47780 [01:59<01:24, 248.68 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36241/47780 [01:59<00:54, 211.80 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35406/47780 [01:59<00:52, 233.73 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37275/47780 [01:59<00:39, 265.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35023/47780 [01:59<00:42, 302.71 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36271/47780 [01:59<00:35, 322.11 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35105/47780 [01:59<00:46, 271.61 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26692/47780 [01:59<01:25, 245.64 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36263/47780 [01:59<00:55, 208.81 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36784/47780 [01:59<00:38, 284.67 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35430/47780 [01:59<00:53, 230.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37307/47780 [01:59<00:37, 278.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35054/47780 [01:59<00:44, 285.36 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36306/47780 [01:59<00:35, 320.65 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35144/47780 [01:59<00:41, 305.59 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26717/47780 [01:59<01:27, 241.32 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36294/47780 [01:59<00:49, 234.40 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36817/47780 [01:59<00:37, 290.97 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35464/47780 [01:59<00:47, 258.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37340/47780 [01:59<00:36, 285.78 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35083/47780 [01:59<00:45, 280.54 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36339/47780 [02:00<00:37, 303.46 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26749/47780 [01:59<01:19, 263.23 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35175/47780 [02:00<00:43, 286.62 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36847/47780 [02:00<00:37, 293.01 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36320/47780 [02:00<00:47, 238.90 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37373/47780 [02:00<00:34, 298.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35491/47780 [02:00<00:49, 247.49 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35118/47780 [02:00<00:42, 296.72 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36374/47780 [02:00<00:37, 302.82 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26776/47780 [02:00<01:20, 262.52 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36356/47780 [02:00<00:41, 273.51 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36878/47780 [02:00<00:36, 294.97 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35206/47780 [02:00<00:45, 274.70 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37407/47780 [02:00<00:33, 309.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35521/47780 [02:00<00:47, 259.30 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35148/47780 [02:00<00:45, 278.89 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36409/47780 [02:00<00:36, 315.31 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26803/47780 [02:00<01:21, 258.70 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36389/47780 [02:00<00:39, 286.77 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36910/47780 [02:00<00:36, 298.63 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37440/47780 [02:00<00:33, 312.53 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35234/47780 [02:00<00:47, 262.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35549/47780 [02:00<00:46, 262.06 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35178/47780 [02:00<00:44, 284.62 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36442/47780 [02:00<00:36, 308.79 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36420/47780 [02:00<00:39, 287.66 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36940/47780 [02:00<00:37, 289.10 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26829/47780 [02:00<01:27, 239.68 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35263/47780 [02:00<00:46, 269.42 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35578/47780 [02:00<00:45, 266.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37472/47780 [02:00<00:34, 300.16 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35207/47780 [02:00<00:44, 282.80 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36478/47780 [02:00<00:36, 313.02 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36970/47780 [02:00<00:37, 288.75 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26858/47780 [02:00<01:23, 250.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36449/47780 [02:00<00:42, 268.86 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37509/47780 [02:00<00:33, 310.13 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35605/47780 [02:00<00:48, 253.26 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35291/47780 [02:00<00:49, 253.02 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35237/47780 [02:00<00:43, 287.55 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36511/47780 [02:00<00:35, 317.40 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26886/47780 [02:00<01:21, 256.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36480/47780 [02:00<00:40, 277.11 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37541/47780 [02:00<00:33, 305.54 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35321/47780 [02:00<00:47, 264.10 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35273/47780 [02:00<00:40, 305.22 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35631/47780 [02:00<00:53, 225.11 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36999/47780 [02:00<00:47, 224.89 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36543/47780 [02:00<00:37, 301.12 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26912/47780 [02:00<01:22, 251.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36514/47780 [02:00<00:38, 291.70 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35350/47780 [02:00<00:46, 269.91 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37573/47780 [02:00<00:34, 299.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35662/47780 [02:00<00:49, 244.76 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35304/47780 [02:00<00:44, 277.76 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37026/47780 [02:00<00:45, 235.74 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36574/47780 [02:00<00:38, 294.20 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26938/47780 [02:00<01:22, 253.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36544/47780 [02:00<00:39, 281.28 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37616/47780 [02:00<00:30, 336.00 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35385/47780 [02:00<00:43, 282.88 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35335/47780 [02:00<00:43, 283.46 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35693/47780 [02:00<00:47, 255.45 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26964/47780 [02:00<01:23, 249.91 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37052/47780 [02:00<00:47, 227.62 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36604/47780 [02:00<00:39, 285.91 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36574/47780 [02:00<00:39, 281.95 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37657/47780 [02:00<00:28, 355.36 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35416/47780 [02:00<00:42, 290.07 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35723/47780 [02:00<00:45, 265.89 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35364/47780 [02:00<00:45, 275.84 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37079/47780 [02:01<00:44, 238.46 examples/s]
Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26990/47780 [02:00<01:24, 247.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36633/47780 [02:01<00:39, 281.14 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36603/47780 [02:00<00:40, 272.90 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35446/47780 [02:01<00:43, 280.53 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37694/47780 [02:01<00:31, 324.13 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35751/47780 [02:01<00:46, 260.58 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35393/47780 [02:01<00:45, 273.91 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27016/47780 [02:01<01:22, 250.90 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37104/47780 [02:01<00:46, 231.96 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36666/47780 [02:01<00:38, 290.88 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36632/47780 [02:01<00:40, 274.99 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35476/47780 [02:01<00:43, 285.88 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37729/47780 [02:01<00:32, 307.80 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35781/47780 [02:01<00:45, 266.23 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27044/47780 [02:01<01:20, 258.36 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36697/47780 [02:01<00:37, 293.65 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35421/47780 [02:01<00:48, 255.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37134/47780 [02:01<00:43, 242.36 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36661/47780 [02:01<00:40, 275.99 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35505/47780 [02:01<00:45, 268.49 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35810/47780 [02:01<00:44, 266.95 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27074/47780 [02:01<01:17, 268.22 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37761/47780 [02:01<00:34, 286.58 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35447/47780 [02:01<00:49, 251.29 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37171/47780 [02:01<00:38, 274.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36727/47780 [02:01<00:38, 285.07 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36690/47780 [02:01<00:40, 276.90 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35535/47780 [02:01<00:45, 271.42 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35842/47780 [02:01<00:42, 278.70 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27105/47780 [02:01<01:13, 280.32 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35479/47780 [02:01<00:46, 267.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37200/47780 [02:01<00:38, 275.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37791/47780 [02:01<00:35, 281.52 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36756/47780 [02:01<00:41, 268.38 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36718/47780 [02:01<00:42, 259.66 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35563/47780 [02:01<00:44, 273.67 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27135/47780 [02:01<01:12, 286.09 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35874/47780 [02:01<00:42, 280.89 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35514/47780 [02:01<00:42, 290.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37231/47780 [02:01<00:37, 282.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37820/47780 [02:01<00:35, 277.55 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36788/47780 [02:01<00:39, 279.97 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36753/47780 [02:01<00:39, 278.75 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35595/47780 [02:01<00:42, 286.72 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35909/47780 [02:01<00:39, 297.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27173/47780 [02:01<01:08, 299.98 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37260/47780 [02:01<00:38, 271.88 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37848/47780 [02:01<00:36, 272.69 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35544/47780 [02:01<00:45, 270.66 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36782/47780 [02:01<00:39, 278.43 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36818/47780 [02:01<00:40, 267.61 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35624/47780 [02:01<00:43, 281.39 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35939/47780 [02:01<00:40, 294.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27203/47780 [02:01<01:10, 293.29 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37292/47780 [02:01<00:37, 281.18 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37878/47780 [02:01<00:35, 275.31 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35578/47780 [02:01<00:43, 278.34 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36856/47780 [02:01<00:37, 295.04 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36810/47780 [02:01<00:40, 270.12 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35653/47780 [02:01<00:44, 275.29 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35970/47780 [02:01<00:40, 292.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27237/47780 [02:01<01:06, 306.68 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37322/47780 [02:01<00:36, 284.31 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37906/47780 [02:01<00:37, 266.38 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35682/47780 [02:01<00:43, 275.24 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36843/47780 [02:01<00:39, 275.21 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35607/47780 [02:01<00:47, 256.05 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36886/47780 [02:01<00:40, 272.24 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27268/47780 [02:01<01:07, 304.12 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36000/47780 [02:01<00:43, 272.45 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37359/47780 [02:01<00:34, 305.34 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37934/47780 [02:01<00:37, 261.51 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35712/47780 [02:01<00:43, 279.39 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36878/47780 [02:01<00:36, 295.27 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35639/47780 [02:01<00:44, 271.73 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36919/47780 [02:02<00:37, 286.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27300/47780 [02:01<01:07, 301.64 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36030/47780 [02:02<00:42, 275.84 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37961/47780 [02:02<00:38, 258.14 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37406/47780 [02:02<00:32, 319.61 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35741/47780 [02:02<00:43, 279.22 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36909/47780 [02:02<00:37, 292.42 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36953/47780 [02:02<00:36, 295.81 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35667/47780 [02:02<00:48, 250.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27331/47780 [02:02<01:08, 297.86 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36058/47780 [02:02<00:44, 263.65 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37995/47780 [02:02<00:34, 280.87 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37445/47780 [02:02<00:30, 338.47 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35773/47780 [02:02<00:41, 290.93 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36987/47780 [02:02<00:35, 308.08 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36939/47780 [02:02<00:38, 279.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35693/47780 [02:02<00:47, 253.12 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27361/47780 [02:02<01:13, 278.67 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35807/47780 [02:02<00:39, 305.13 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36085/47780 [02:02<00:49, 237.86 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38024/47780 [02:02<00:37, 257.44 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37479/47780 [02:02<00:32, 314.14 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36969/47780 [02:02<00:38, 283.51 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35721/47780 [02:02<00:46, 257.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37019/47780 [02:02<00:37, 288.00 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27390/47780 [02:02<01:14, 272.71 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35838/47780 [02:02<00:40, 295.79 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38068/47780 [02:02<00:32, 303.40 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37511/47780 [02:02<00:32, 312.37 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36999/47780 [02:02<00:37, 286.41 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36110/47780 [02:02<00:49, 233.96 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35752/47780 [02:02<00:44, 272.08 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37049/47780 [02:02<00:39, 273.56 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27418/47780 [02:02<01:18, 260.28 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35872/47780 [02:02<00:38, 305.79 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36142/47780 [02:02<00:46, 252.54 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37543/47780 [02:02<00:33, 301.26 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35781/47780 [02:02<00:45, 262.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37028/47780 [02:02<00:40, 263.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38100/47780 [02:02<00:35, 274.20 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37083/47780 [02:02<00:37, 282.53 examples/s]
Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27445/47780 [02:02<01:21, 248.81 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35903/47780 [02:02<00:39, 299.65 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36170/47780 [02:02<00:45, 257.23 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37057/47780 [02:02<00:39, 270.35 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37574/47780 [02:02<00:35, 284.82 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35809/47780 [02:02<00:45, 261.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38132/47780 [02:02<00:34, 283.51 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37115/47780 [02:02<00:36, 292.68 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27477/47780 [02:02<01:16, 265.73 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35934/47780 [02:02<00:40, 292.68 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36203/47780 [02:02<00:43, 268.44 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37605/47780 [02:02<00:35, 288.85 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35837/47780 [02:02<00:45, 263.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37085/47780 [02:02<00:40, 261.64 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37152/47780 [02:02<00:33, 313.40 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38162/47780 [02:02<00:35, 271.52 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27512/47780 [02:02<01:10, 285.84 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36234/47780 [02:02<00:42, 273.41 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35964/47780 [02:02<00:43, 272.79 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35867/47780 [02:02<00:43, 273.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37636/47780 [02:02<00:35, 288.32 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37114/47780 [02:02<00:40, 260.77 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37185/47780 [02:02<00:35, 298.57 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38190/47780 [02:02<00:35, 266.59 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27544/47780 [02:02<01:08, 295.24 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35996/47780 [02:02<00:41, 282.89 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37665/47780 [02:02<00:35, 285.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35895/47780 [02:02<00:44, 269.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36262/47780 [02:02<00:44, 258.43 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37142/47780 [02:02<00:42, 249.57 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37217/47780 [02:03<00:35, 297.95 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38218/47780 [02:03<00:37, 253.79 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27574/47780 [02:02<01:12, 277.51 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36025/47780 [02:03<00:42, 275.29 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37701/47780 [02:03<00:33, 303.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35929/47780 [02:03<00:41, 283.06 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36289/47780 [02:03<00:45, 253.36 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37248/47780 [02:03<00:35, 298.21 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37168/47780 [02:03<00:42, 247.04 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38251/47780 [02:03<00:35, 268.70 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27603/47780 [02:03<01:14, 271.66 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37741/47780 [02:03<00:30, 330.55 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35960/47780 [02:03<00:42, 280.98 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36056/47780 [02:03<00:44, 264.58 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36315/47780 [02:03<00:47, 243.72 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37281/47780 [02:03<00:35, 296.88 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37193/47780 [02:03<00:44, 239.76 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38279/47780 [02:03<00:37, 252.23 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27631/47780 [02:03<01:15, 265.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37778/47780 [02:03<00:29, 338.31 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35994/47780 [02:03<00:40, 291.41 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36340/47780 [02:03<00:46, 244.37 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36092/47780 [02:03<00:41, 284.21 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37222/47780 [02:03<00:41, 252.67 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37311/47780 [02:03<00:36, 287.88 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38310/47780 [02:03<00:36, 259.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27658/47780 [02:03<01:18, 255.32 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37813/47780 [02:03<00:30, 322.92 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36365/47780 [02:03<00:46, 245.45 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36024/47780 [02:03<00:41, 282.10 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36121/47780 [02:03<00:42, 276.35 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37248/47780 [02:03<00:42, 250.12 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37342/47780 [02:03<00:37, 281.48 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38338/47780 [02:03<00:36, 256.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27688/47780 [02:03<01:15, 264.88 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37851/47780 [02:03<00:29, 338.80 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36390/47780 [02:03<00:46, 246.39 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37274/47780 [02:03<00:42, 247.42 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36149/47780 [02:03<00:44, 263.29 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37377/47780 [02:03<00:34, 300.26 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36053/47780 [02:03<00:45, 257.45 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38366/47780 [02:03<00:35, 263.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27721/47780 [02:03<01:10, 282.90 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36419/47780 [02:03<00:44, 253.02 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37886/47780 [02:03<00:31, 316.78 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37307/47780 [02:03<00:39, 267.77 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36182/47780 [02:03<00:41, 278.30 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37410/47780 [02:03<00:33, 305.59 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36080/47780 [02:03<00:46, 252.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38393/47780 [02:03<00:35, 262.19 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27750/47780 [02:03<01:15, 264.12 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37919/47780 [02:03<00:30, 318.16 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36445/47780 [02:03<00:47, 238.36 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37336/47780 [02:03<00:38, 268.00 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36211/47780 [02:03<00:42, 274.93 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36106/47780 [02:03<00:47, 246.34 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37441/47780 [02:03<00:36, 283.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38420/47780 [02:03<00:36, 255.61 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27780/47780 [02:03<01:13, 270.89 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36470/47780 [02:03<00:47, 236.35 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37952/47780 [02:03<00:32, 303.05 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36239/47780 [02:03<00:43, 267.96 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37368/47780 [02:03<00:38, 273.47 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36132/47780 [02:03<00:47, 245.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37470/47780 [02:03<00:37, 276.75 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38446/47780 [02:03<00:37, 245.83 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27810/47780 [02:03<01:13, 269.99 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36494/47780 [02:03<00:48, 230.91 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37396/47780 [02:03<00:38, 269.18 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36266/47780 [02:03<00:43, 262.15 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37983/47780 [02:03<00:33, 288.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37503/47780 [02:04<00:35, 291.21 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36158/47780 [02:03<00:49, 233.84 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38475/47780 [02:03<00:36, 255.33 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27838/47780 [02:03<01:13, 269.78 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36518/47780 [02:04<00:48, 232.33 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37426/47780 [02:04<00:38, 271.78 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38015/47780 [02:04<00:33, 291.25 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36293/47780 [02:04<00:44, 259.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37533/47780 [02:04<00:36, 284.27 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38502/47780 [02:04<00:35, 259.24 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36182/47780 [02:04<00:51, 223.53 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27871/47780 [02:04<01:10, 283.46 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36548/47780 [02:04<00:46, 243.36 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36330/47780 [02:04<00:40, 279.72 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37454/47780 [02:04<00:39, 261.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37564/47780 [02:04<00:35, 291.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38045/47780 [02:04<00:36, 269.98 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38531/47780 [02:04<00:34, 265.15 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36214/47780 [02:04<00:46, 246.70 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27909/47780 [02:04<01:03, 310.88 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36581/47780 [02:04<00:42, 264.88 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36365/47780 [02:04<00:38, 297.26 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37494/47780 [02:04<00:34, 298.51 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37595/47780 [02:04<00:34, 293.44 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38563/47780 [02:04<00:32, 280.53 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38073/47780 [02:04<00:36, 264.36 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36242/47780 [02:04<00:45, 252.90 examples/s]
Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27941/47780 [02:04<01:09, 286.97 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36396/47780 [02:04<00:38, 297.39 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36608/47780 [02:04<00:45, 244.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37627/47780 [02:04<00:33, 300.19 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37525/47780 [02:04<00:36, 284.06 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38595/47780 [02:04<00:31, 289.09 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38101/47780 [02:04<00:36, 267.55 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36270/47780 [02:04<00:45, 254.85 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27971/47780 [02:04<01:08, 287.59 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36426/47780 [02:04<00:38, 298.01 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37659/47780 [02:04<00:33, 299.84 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36633/47780 [02:04<00:47, 235.28 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38633/47780 [02:04<00:28, 315.47 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37554/47780 [02:04<00:36, 277.42 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38128/47780 [02:04<00:37, 255.15 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36296/47780 [02:04<00:49, 232.72 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28001/47780 [02:04<01:10, 281.15 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36462/47780 [02:04<00:35, 314.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37691/47780 [02:04<00:33, 305.66 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37597/47780 [02:04<00:31, 319.38 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36658/47780 [02:04<00:47, 232.32 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38665/47780 [02:04<00:30, 298.88 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38155/47780 [02:04<00:37, 253.76 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28030/47780 [02:04<01:10, 280.94 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36323/47780 [02:04<00:49, 230.35 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36494/47780 [02:04<00:36, 310.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37725/47780 [02:04<00:32, 308.46 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36684/47780 [02:04<00:47, 234.12 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38188/47780 [02:04<00:35, 271.63 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37630/47780 [02:04<00:33, 298.61 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38696/47780 [02:04<00:32, 277.19 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28059/47780 [02:04<01:09, 283.26 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36348/47780 [02:04<00:48, 234.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36526/47780 [02:04<00:38, 295.72 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37757/47780 [02:04<00:33, 301.20 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36710/47780 [02:04<00:46, 238.79 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37661/47780 [02:04<00:34, 294.82 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38725/47780 [02:04<00:33, 272.03 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38216/47780 [02:04<00:38, 246.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36372/47780 [02:04<00:50, 224.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28088/47780 [02:04<01:16, 256.09 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36558/47780 [02:04<00:37, 296.37 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37794/47780 [02:04<00:31, 320.82 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36739/47780 [02:04<00:44, 250.49 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37691/47780 [02:04<00:35, 285.89 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38757/47780 [02:04<00:32, 278.97 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38261/47780 [02:05<00:32, 297.32 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36401/47780 [02:05<00:47, 237.33 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28120/47780 [02:04<01:12, 271.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36592/47780 [02:05<00:36, 308.68 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37831/47780 [02:05<00:30, 327.71 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36772/47780 [02:05<00:40, 272.90 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37725/47780 [02:05<00:34, 295.72 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38788/47780 [02:05<00:31, 287.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38292/47780 [02:05<00:32, 294.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36624/47780 [02:05<00:36, 308.13 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36425/47780 [02:05<00:49, 227.98 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28148/47780 [02:05<01:14, 262.41 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37878/47780 [02:05<00:27, 360.42 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36800/47780 [02:05<00:40, 268.53 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38817/47780 [02:05<00:31, 286.42 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37755/47780 [02:05<00:36, 275.51 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38323/47780 [02:05<00:32, 291.73 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36655/47780 [02:05<00:37, 298.41 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28184/47780 [02:05<01:08, 284.54 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37922/47780 [02:05<00:26, 378.89 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36449/47780 [02:05<00:51, 221.60 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36828/47780 [02:05<00:41, 265.81 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38846/47780 [02:05<00:32, 276.39 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37787/47780 [02:05<00:34, 287.51 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38354/47780 [02:05<00:32, 290.31 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36477/47780 [02:05<00:48, 234.87 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37961/47780 [02:05<00:26, 371.51 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36685/47780 [02:05<00:39, 279.85 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36855/47780 [02:05<00:41, 261.14 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28213/47780 [02:05<01:13, 265.32 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37817/47780 [02:05<00:34, 287.65 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38384/47780 [02:05<00:32, 290.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38874/47780 [02:05<00:34, 257.25 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36506/47780 [02:05<00:45, 247.53 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38007/47780 [02:05<00:25, 390.02 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36714/47780 [02:05<00:39, 279.31 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28243/47780 [02:05<01:11, 271.79 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36882/47780 [02:05<00:45, 238.76 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37848/47780 [02:05<00:34, 290.58 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38425/47780 [02:05<00:29, 317.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38902/47780 [02:05<00:34, 260.55 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36534/47780 [02:05<00:44, 253.89 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36743/47780 [02:05<00:40, 270.45 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38047/47780 [02:05<00:26, 367.07 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28271/47780 [02:05<01:13, 265.33 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37883/47780 [02:05<00:33, 297.47 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36907/47780 [02:05<00:48, 222.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38937/47780 [02:05<00:31, 279.25 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38457/47780 [02:05<00:31, 297.72 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36565/47780 [02:05<00:42, 266.70 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36775/47780 [02:05<00:39, 281.56 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28298/47780 [02:05<01:17, 249.98 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38084/47780 [02:05<00:28, 338.51 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37915/47780 [02:05<00:32, 300.42 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36938/47780 [02:05<00:45, 240.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38966/47780 [02:05<00:31, 281.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38498/47780 [02:05<00:28, 328.53 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36594/47780 [02:05<00:41, 270.35 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36804/47780 [02:05<00:39, 280.18 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38121/47780 [02:05<00:27, 346.80 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28326/47780 [02:05<01:19, 244.52 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36963/47780 [02:05<00:44, 240.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37946/47780 [02:05<00:34, 286.83 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38534/47780 [02:05<00:27, 333.70 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38995/47780 [02:05<00:31, 275.24 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36622/47780 [02:05<00:42, 264.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36833/47780 [02:05<00:39, 276.63 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28356/47780 [02:05<01:16, 254.30 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38158/47780 [02:05<00:29, 324.22 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39024/47780 [02:05<00:31, 276.21 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38570/47780 [02:05<00:27, 333.57 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36988/47780 [02:05<00:46, 232.70 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37975/47780 [02:05<00:37, 261.51 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36649/47780 [02:05<00:42, 259.81 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36863/47780 [02:05<00:38, 280.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38608/47780 [02:06<00:26, 346.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38191/47780 [02:06<00:30, 311.75 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39052/47780 [02:06<00:32, 268.31 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37021/47780 [02:06<00:42, 254.01 examples/s]
Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28382/47780 [02:06<01:21, 237.51 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38006/47780 [02:06<00:35, 274.17 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36679/47780 [02:06<00:41, 268.15 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36895/47780 [02:06<00:37, 288.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28407/47780 [02:06<01:20, 240.49 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39079/47780 [02:06<00:32, 265.61 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38643/47780 [02:06<00:27, 332.94 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38223/47780 [02:06<00:31, 305.07 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37047/47780 [02:06<00:43, 247.13 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38039/47780 [02:06<00:34, 283.51 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36706/47780 [02:06<00:42, 262.57 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36930/47780 [02:06<00:35, 302.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28434/47780 [02:06<01:18, 246.50 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38678/47780 [02:06<00:26, 337.20 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39106/47780 [02:06<00:32, 263.78 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38268/47780 [02:06<00:27, 340.83 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37078/47780 [02:06<00:40, 264.48 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38073/47780 [02:06<00:32, 296.00 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36740/47780 [02:06<00:39, 278.56 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36963/47780 [02:06<00:34, 310.09 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28463/47780 [02:06<01:14, 258.65 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38303/47780 [02:06<00:27, 339.39 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38712/47780 [02:06<00:28, 321.86 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39133/47780 [02:06<00:34, 250.87 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38103/47780 [02:06<00:33, 290.02 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37105/47780 [02:06<00:42, 248.73 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36768/47780 [02:06<00:40, 271.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37001/47780 [02:06<00:33, 323.31 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39166/47780 [02:06<00:31, 270.36 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28491/47780 [02:06<01:19, 242.64 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38133/47780 [02:06<00:34, 283.69 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38745/47780 [02:06<00:29, 304.73 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37131/47780 [02:06<00:43, 244.16 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36802/47780 [02:06<00:38, 288.74 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37034/47780 [02:06<00:33, 317.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38338/47780 [02:06<00:31, 295.90 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39196/47780 [02:06<00:30, 278.74 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28520/47780 [02:06<01:16, 252.68 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38776/47780 [02:06<00:29, 306.14 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36831/47780 [02:06<00:37, 288.72 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38169/47780 [02:06<00:31, 300.86 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37066/47780 [02:06<00:34, 311.47 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37156/47780 [02:06<00:46, 228.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38370/47780 [02:06<00:31, 299.11 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39225/47780 [02:06<00:30, 278.76 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38807/47780 [02:06<00:29, 306.77 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28546/47780 [02:06<01:18, 244.68 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38200/47780 [02:06<00:34, 281.69 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36860/47780 [02:06<00:40, 267.75 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37185/47780 [02:06<00:44, 239.88 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38401/47780 [02:06<00:32, 289.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37098/47780 [02:06<00:36, 290.50 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39254/47780 [02:06<00:30, 278.69 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38843/47780 [02:06<00:28, 318.87 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28571/47780 [02:06<01:18, 245.17 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37213/47780 [02:06<00:42, 248.18 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38229/47780 [02:06<00:34, 275.29 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38434/47780 [02:06<00:31, 294.32 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37130/47780 [02:06<00:36, 290.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36888/47780 [02:06<00:43, 249.12 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39282/47780 [02:06<00:30, 278.57 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38876/47780 [02:06<00:28, 307.66 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28596/47780 [02:06<01:24, 226.29 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37239/47780 [02:06<00:42, 245.93 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38262/47780 [02:06<00:33, 284.04 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38470/47780 [02:07<00:30, 308.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36923/47780 [02:06<00:39, 272.94 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37161/47780 [02:06<00:38, 273.41 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39310/47780 [02:07<00:31, 267.32 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37270/47780 [02:07<00:39, 263.68 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28624/47780 [02:07<01:22, 233.29 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38907/47780 [02:07<00:31, 282.54 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38293/47780 [02:07<00:33, 284.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38506/47780 [02:07<00:29, 316.01 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36951/47780 [02:07<00:42, 255.35 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39344/47780 [02:07<00:29, 287.91 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37189/47780 [02:07<00:42, 248.32 examples/s]
Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28648/47780 [02:07<01:22, 232.51 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37298/47780 [02:07<00:40, 261.22 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38322/47780 [02:07<00:33, 286.13 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38936/47780 [02:07<00:32, 275.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38542/47780 [02:07<00:28, 324.77 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36980/47780 [02:07<00:40, 264.56 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39378/47780 [02:07<00:28, 296.18 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37215/47780 [02:07<00:45, 234.04 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37326/47780 [02:07<00:39, 264.82 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38357/47780 [02:07<00:31, 301.58 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38965/47780 [02:07<00:31, 276.66 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38583/47780 [02:07<00:26, 345.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28672/47780 [02:07<01:25, 224.46 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37007/47780 [02:07<00:41, 259.00 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39408/47780 [02:07<00:28, 293.24 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37239/47780 [02:07<00:45, 233.88 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37353/47780 [02:07<00:40, 260.12 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38996/47780 [02:07<00:31, 283.14 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38388/47780 [02:07<00:31, 296.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28696/47780 [02:07<01:24, 226.20 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38618/47780 [02:07<00:28, 323.85 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37034/47780 [02:07<00:41, 257.77 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39438/47780 [02:07<00:29, 282.65 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37266/47780 [02:07<00:44, 238.48 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37383/47780 [02:07<00:38, 268.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38421/47780 [02:07<00:31, 297.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39029/47780 [02:07<00:31, 280.42 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38654/47780 [02:07<00:27, 333.83 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28720/47780 [02:07<01:29, 213.53 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37060/47780 [02:07<00:43, 244.58 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39469/47780 [02:07<00:29, 283.92 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37292/47780 [02:07<00:42, 244.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38452/47780 [02:07<00:31, 296.44 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37417/47780 [02:07<00:38, 270.52 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39058/47780 [02:07<00:31, 280.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38692/47780 [02:07<00:26, 343.04 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28746/47780 [02:07<01:26, 219.28 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39502/47780 [02:07<00:28, 294.29 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37086/47780 [02:07<00:44, 238.20 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37317/47780 [02:07<00:43, 242.91 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39089/47780 [02:07<00:30, 288.41 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38728/47780 [02:07<00:26, 347.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37447/47780 [02:07<00:37, 275.61 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28772/47780 [02:07<01:22, 230.10 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38482/47780 [02:07<00:34, 272.44 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37118/47780 [02:07<00:41, 257.96 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39532/47780 [02:07<00:28, 288.31 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37343/47780 [02:07<00:42, 247.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39121/47780 [02:07<00:29, 297.26 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37483/47780 [02:07<00:35, 292.89 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28801/47780 [02:07<01:17, 244.21 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38763/47780 [02:07<00:27, 327.55 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38521/47780 [02:07<00:30, 301.20 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37146/47780 [02:07<00:40, 261.20 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39566/47780 [02:07<00:27, 300.07 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37373/47780 [02:07<00:41, 251.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39152/47780 [02:07<00:29, 294.29 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37513/47780 [02:07<00:35, 290.70 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28826/47780 [02:07<01:18, 240.99 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38552/47780 [02:07<00:30, 300.03 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38797/47780 [02:07<00:27, 322.19 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39597/47780 [02:07<00:27, 299.54 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37173/47780 [02:07<00:43, 246.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39187/47780 [02:08<00:28, 306.88 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37399/47780 [02:08<00:43, 237.72 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37543/47780 [02:08<00:35, 287.71 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28855/47780 [02:08<01:15, 249.83 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38583/47780 [02:08<00:31, 296.11 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38830/47780 [02:08<00:27, 320.35 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39628/47780 [02:08<00:27, 292.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37198/47780 [02:08<00:43, 245.18 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37424/47780 [02:08<00:43, 238.36 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39218/47780 [02:08<00:29, 294.21 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37578/47780 [02:08<00:34, 298.66 examples/s]
Tokenizing train dataset (num_proc=32):  60%|██████    | 28888/47780 [02:08<01:09, 271.19 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38620/47780 [02:08<00:29, 313.73 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38864/47780 [02:08<00:27, 319.04 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37223/47780 [02:08<00:44, 238.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39658/47780 [02:08<00:29, 272.55 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37450/47780 [02:08<00:42, 243.60 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39252/47780 [02:08<00:28, 303.73 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38652/47780 [02:08<00:28, 315.07 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37608/47780 [02:08<00:35, 285.51 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38900/47780 [02:08<00:27, 326.97 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28916/47780 [02:08<01:16, 247.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37249/47780 [02:08<00:44, 239.21 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37480/47780 [02:08<00:40, 257.43 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39287/47780 [02:08<00:27, 309.93 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38934/47780 [02:08<00:26, 330.38 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39686/47780 [02:08<00:33, 242.97 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37637/47780 [02:08<00:36, 277.89 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28947/47780 [02:08<01:11, 262.07 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38684/47780 [02:08<00:32, 284.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37279/47780 [02:08<00:40, 256.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37510/47780 [02:08<00:38, 266.89 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39319/47780 [02:08<00:27, 302.33 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39713/47780 [02:08<00:32, 247.45 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37668/47780 [02:08<00:35, 286.78 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38972/47780 [02:08<00:26, 333.49 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 28977/47780 [02:08<01:09, 269.64 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38718/47780 [02:08<00:30, 299.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37310/47780 [02:08<00:38, 271.40 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37546/47780 [02:08<00:35, 290.31 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39353/47780 [02:08<00:27, 306.06 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37705/47780 [02:08<00:32, 307.14 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39010/47780 [02:08<00:25, 346.42 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39739/47780 [02:08<00:33, 239.94 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29008/47780 [02:08<01:07, 277.79 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38749/47780 [02:08<00:31, 285.94 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37344/47780 [02:08<00:36, 284.77 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37576/47780 [02:08<00:37, 271.20 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39387/47780 [02:08<00:26, 312.16 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39050/47780 [02:08<00:24, 358.23 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37745/47780 [02:08<00:30, 329.84 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39773/47780 [02:08<00:30, 264.39 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29037/47780 [02:08<01:11, 263.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38779/47780 [02:08<00:32, 280.56 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37373/47780 [02:08<00:39, 264.65 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37604/47780 [02:08<00:37, 270.23 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37779/47780 [02:08<00:30, 328.89 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39429/47780 [02:08<00:25, 331.59 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39086/47780 [02:08<00:25, 346.08 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39812/47780 [02:08<00:26, 296.36 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29064/47780 [02:08<01:10, 264.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38808/47780 [02:08<00:32, 277.03 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37407/47780 [02:08<00:37, 276.58 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37632/47780 [02:08<00:38, 264.39 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39467/47780 [02:08<00:24, 341.51 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37812/47780 [02:08<00:32, 311.01 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39843/47780 [02:08<00:27, 289.66 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39121/47780 [02:08<00:26, 328.96 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29094/47780 [02:08<01:08, 272.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38837/47780 [02:08<00:32, 271.97 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37439/47780 [02:08<00:35, 288.49 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37661/47780 [02:08<00:37, 271.50 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37844/47780 [02:08<00:32, 310.21 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39502/47780 [02:09<00:25, 321.85 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39873/47780 [02:09<00:27, 283.28 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39169/47780 [02:09<00:23, 362.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29122/47780 [02:08<01:08, 270.46 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38865/47780 [02:09<00:34, 259.75 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37469/47780 [02:09<00:36, 285.38 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37689/47780 [02:09<00:36, 273.09 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37879/47780 [02:09<00:31, 318.11 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39903/47780 [02:09<00:27, 287.78 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39537/47780 [02:09<00:26, 315.74 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29151/47780 [02:09<01:08, 273.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39206/47780 [02:09<00:25, 340.33 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38893/47780 [02:09<00:34, 254.07 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37500/47780 [02:09<00:36, 279.78 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37720/47780 [02:09<00:36, 278.31 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37911/47780 [02:09<00:31, 314.69 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39935/47780 [02:09<00:26, 293.53 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39579/47780 [02:09<00:23, 344.20 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29183/47780 [02:09<01:06, 278.21 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39241/47780 [02:09<00:25, 336.99 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38919/47780 [02:09<00:34, 255.62 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37750/47780 [02:09<00:35, 282.72 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37536/47780 [02:09<00:35, 292.37 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37944/47780 [02:09<00:31, 315.50 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39968/47780 [02:09<00:25, 300.55 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████    | 29211/47780 [02:09<01:07, 274.96 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39275/47780 [02:09<00:25, 330.34 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38945/47780 [02:09<00:34, 253.94 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39614/47780 [02:09<00:28, 285.00 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37779/47780 [02:09<00:37, 268.07 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37980/47780 [02:09<00:30, 321.36 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40003/47780 [02:09<00:24, 311.18 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37566/47780 [02:09<00:38, 267.66 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29243/47780 [02:09<01:05, 284.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39309/47780 [02:09<00:25, 326.25 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38973/47780 [02:09<00:33, 261.19 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39659/47780 [02:09<00:24, 325.97 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37809/47780 [02:09<00:36, 270.86 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40035/47780 [02:09<00:25, 308.16 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38013/47780 [02:09<00:31, 309.58 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37600/47780 [02:09<00:35, 283.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29272/47780 [02:09<01:06, 279.49 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39342/47780 [02:09<00:26, 316.62 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39000/47780 [02:09<00:34, 255.35 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39695/47780 [02:09<00:24, 324.66 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40073/47780 [02:09<00:23, 327.37 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37638/47780 [02:09<00:32, 308.08 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38045/47780 [02:09<00:31, 304.78 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37837/47780 [02:09<00:39, 253.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29303/47780 [02:09<01:05, 283.32 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39374/47780 [02:09<00:26, 314.08 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39030/47780 [02:09<00:32, 268.04 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39735/47780 [02:09<00:23, 341.10 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37670/47780 [02:09<00:33, 299.93 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37867/47780 [02:09<00:38, 260.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38076/47780 [02:09<00:32, 296.52 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29332/47780 [02:09<01:07, 273.73 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40106/47780 [02:09<00:26, 284.54 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39406/47780 [02:09<00:27, 305.01 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39783/47780 [02:09<00:21, 371.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39057/47780 [02:09<00:36, 240.75 examples/s]
Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29362/47780 [02:09<01:06, 278.77 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37701/47780 [02:09<00:35, 281.02 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37905/47780 [02:09<00:36, 272.51 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38106/47780 [02:09<00:35, 276.18 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39437/47780 [02:09<00:27, 306.13 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40136/47780 [02:09<00:26, 283.11 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39822/47780 [02:09<00:22, 360.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39082/47780 [02:09<00:37, 233.23 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37736/47780 [02:09<00:33, 299.53 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29396/47780 [02:09<01:02, 292.92 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37942/47780 [02:09<00:33, 295.85 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39470/47780 [02:10<00:26, 311.30 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38136/47780 [02:09<00:34, 276.80 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40167/47780 [02:10<00:26, 284.25 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39107/47780 [02:10<00:36, 237.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39859/47780 [02:10<00:23, 332.82 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39506/47780 [02:10<00:25, 324.07 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29426/47780 [02:10<01:06, 275.93 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38170/47780 [02:10<00:33, 284.62 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40196/47780 [02:10<00:27, 273.76 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37972/47780 [02:10<00:35, 272.53 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37770/47780 [02:10<00:35, 279.70 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39132/47780 [02:10<00:37, 233.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39894/47780 [02:10<00:23, 334.72 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38201/47780 [02:10<00:33, 288.40 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29454/47780 [02:10<01:07, 270.36 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40234/47780 [02:10<00:25, 299.62 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38000/47780 [02:10<00:36, 270.96 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39539/47780 [02:10<00:28, 291.71 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37801/47780 [02:10<00:35, 278.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39159/47780 [02:10<00:35, 240.77 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39930/47780 [02:10<00:24, 317.30 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38238/47780 [02:10<00:30, 310.84 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40267/47780 [02:10<00:24, 304.56 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29482/47780 [02:10<01:09, 262.10 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38035/47780 [02:10<00:33, 286.92 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37834/47780 [02:10<00:34, 289.47 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39575/47780 [02:10<00:26, 306.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39185/47780 [02:10<00:35, 240.84 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39980/47780 [02:10<00:21, 365.36 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38276/47780 [02:10<00:29, 327.50 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40304/47780 [02:10<00:23, 322.86 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29511/47780 [02:10<01:07, 269.77 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38068/47780 [02:10<00:32, 298.54 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37868/47780 [02:10<00:33, 299.71 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39607/47780 [02:10<00:27, 294.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39215/47780 [02:10<00:33, 257.51 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40018/47780 [02:10<00:21, 357.33 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38311/47780 [02:10<00:29, 326.44 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37906/47780 [02:10<00:30, 319.02 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38099/47780 [02:10<00:33, 285.51 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29539/47780 [02:10<01:11, 255.27 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39642/47780 [02:10<00:26, 306.23 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39241/47780 [02:10<00:33, 252.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40337/47780 [02:10<00:27, 274.64 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38345/47780 [02:10<00:28, 330.11 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40055/47780 [02:10<00:21, 357.40 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29565/47780 [02:10<01:11, 253.51 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38128/47780 [02:10<00:34, 280.67 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37939/47780 [02:10<00:32, 304.75 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39674/47780 [02:10<00:26, 303.33 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39267/47780 [02:10<00:33, 251.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40366/47780 [02:10<00:26, 275.85 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40092/47780 [02:10<00:22, 334.98 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38160/47780 [02:10<00:33, 286.60 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39710/47780 [02:10<00:25, 312.28 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38379/47780 [02:10<00:33, 283.09 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39296/47780 [02:10<00:32, 262.58 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37971/47780 [02:10<00:33, 292.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29593/47780 [02:10<01:16, 236.88 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40395/47780 [02:10<00:29, 251.99 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39743/47780 [02:10<00:25, 317.24 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40127/47780 [02:10<00:24, 315.14 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38439/47780 [02:10<00:25, 362.85 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38004/47780 [02:10<00:32, 299.66 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38189/47780 [02:10<00:36, 265.67 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39323/47780 [02:10<00:33, 255.76 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29625/47780 [02:10<01:10, 256.74 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40440/47780 [02:10<00:24, 297.24 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39775/47780 [02:11<00:25, 318.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38036/47780 [02:10<00:32, 298.24 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38217/47780 [02:10<00:35, 268.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29652/47780 [02:10<01:09, 259.42 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39349/47780 [02:11<00:33, 251.22 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40160/47780 [02:11<00:26, 288.48 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38480/47780 [02:11<00:27, 338.74 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40471/47780 [02:11<00:25, 291.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39808/47780 [02:11<00:25, 317.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29681/47780 [02:11<01:08, 266.04 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39375/47780 [02:11<00:33, 248.14 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38245/47780 [02:11<00:36, 260.90 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38066/47780 [02:11<00:33, 286.09 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40191/47780 [02:11<00:25, 293.67 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38519/47780 [02:11<00:26, 350.16 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40503/47780 [02:11<00:25, 280.93 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39849/47780 [02:11<00:23, 342.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29711/47780 [02:11<01:06, 272.59 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38276/47780 [02:11<00:34, 272.87 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38102/47780 [02:11<00:31, 303.38 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40221/47780 [02:11<00:26, 289.23 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39400/47780 [02:11<00:34, 240.20 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38556/47780 [02:11<00:27, 335.92 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40539/47780 [02:11<00:24, 298.76 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39890/47780 [02:11<00:21, 360.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29739/47780 [02:11<01:05, 274.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38304/47780 [02:11<00:34, 273.54 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38134/47780 [02:11<00:31, 304.33 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40252/47780 [02:11<00:25, 292.05 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39434/47780 [02:11<00:32, 257.11 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40570/47780 [02:11<00:23, 301.45 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38591/47780 [02:11<00:29, 312.28 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39931/47780 [02:11<00:21, 370.52 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29771/47780 [02:11<01:03, 285.13 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38332/47780 [02:11<00:34, 275.08 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38168/47780 [02:11<00:31, 306.92 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39468/47780 [02:11<00:29, 277.22 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40282/47780 [02:11<00:27, 270.22 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38628/47780 [02:11<00:28, 321.36 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39971/47780 [02:11<00:20, 374.82 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40601/47780 [02:11<00:24, 288.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29800/47780 [02:11<01:03, 283.34 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38203/47780 [02:11<00:30, 313.00 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38360/47780 [02:11<00:36, 255.80 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39496/47780 [02:11<00:30, 274.77 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40311/47780 [02:11<00:27, 272.27 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38661/47780 [02:11<00:28, 316.86 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40009/47780 [02:11<00:21, 367.19 examples/s]
Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29836/47780 [02:11<01:00, 298.10 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40631/47780 [02:11<00:26, 270.55 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38242/47780 [02:11<00:29, 327.44 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38389/47780 [02:11<00:35, 262.69 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39532/47780 [02:11<00:27, 299.05 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40339/47780 [02:11<00:27, 268.77 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38694/47780 [02:11<00:28, 316.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40051/47780 [02:11<00:20, 378.68 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29868/47780 [02:11<01:00, 297.61 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38277/47780 [02:11<00:28, 330.76 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38430/47780 [02:11<00:31, 297.38 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40659/47780 [02:11<00:28, 253.87 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39564/47780 [02:11<00:28, 292.63 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40381/47780 [02:11<00:24, 307.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40089/47780 [02:11<00:20, 374.26 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38727/47780 [02:11<00:30, 294.22 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38466/47780 [02:11<00:29, 311.38 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38313/47780 [02:11<00:29, 325.71 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40685/47780 [02:11<00:28, 250.77 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29898/47780 [02:11<01:06, 270.34 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39594/47780 [02:11<00:28, 287.06 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40413/47780 [02:11<00:25, 286.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40127/47780 [02:11<00:21, 359.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38758/47780 [02:11<00:30, 295.65 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38513/47780 [02:11<00:26, 348.61 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39625/47780 [02:11<00:27, 293.48 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29926/47780 [02:11<01:06, 267.19 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38346/47780 [02:11<00:30, 314.34 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40711/47780 [02:11<00:29, 240.45 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40444/47780 [02:12<00:25, 282.36 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38790/47780 [02:12<00:29, 301.28 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40164/47780 [02:12<00:24, 315.54 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39660/47780 [02:12<00:26, 304.07 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38548/47780 [02:12<00:27, 337.61 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38379/47780 [02:12<00:30, 305.17 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40737/47780 [02:12<00:29, 240.09 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29954/47780 [02:12<01:10, 253.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40475/47780 [02:12<00:25, 286.84 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38821/47780 [02:12<00:30, 294.90 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40763/47780 [02:12<00:28, 245.48 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38413/47780 [02:12<00:29, 314.65 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38583/47780 [02:12<00:28, 324.67 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40197/47780 [02:12<00:25, 301.76 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29982/47780 [02:12<01:08, 258.15 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39691/47780 [02:12<00:29, 273.39 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40504/47780 [02:12<00:26, 276.99 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38851/47780 [02:12<00:31, 283.54 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38446/47780 [02:12<00:29, 318.98 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40792/47780 [02:12<00:27, 255.15 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40233/47780 [02:12<00:23, 315.85 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38618/47780 [02:12<00:27, 329.84 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30012/47780 [02:12<01:08, 261.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39720/47780 [02:12<00:29, 277.73 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40536/47780 [02:12<00:25, 281.38 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38882/47780 [02:12<00:30, 287.72 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38483/47780 [02:12<00:28, 329.85 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40818/47780 [02:12<00:28, 247.86 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40266/47780 [02:12<00:24, 312.66 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38652/47780 [02:12<00:28, 318.04 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30040/47780 [02:12<01:08, 259.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39754/47780 [02:12<00:27, 288.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40566/47780 [02:12<00:25, 279.16 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38918/47780 [02:12<00:28, 308.04 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40303/47780 [02:12<00:22, 325.09 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38518/47780 [02:12<00:29, 310.48 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38684/47780 [02:12<00:29, 305.11 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40843/47780 [02:12<00:29, 231.25 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30074/47780 [02:12<01:05, 270.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39784/47780 [02:12<00:29, 273.14 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40598/47780 [02:12<00:25, 285.11 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38957/47780 [02:12<00:26, 327.76 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30105/47780 [02:12<01:03, 278.75 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38715/47780 [02:12<00:30, 296.57 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40869/47780 [02:12<00:29, 230.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40338/47780 [02:12<00:24, 298.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38550/47780 [02:12<00:32, 284.50 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40629/47780 [02:12<00:24, 288.92 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39812/47780 [02:12<00:30, 263.76 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38990/47780 [02:12<00:26, 328.39 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38745/47780 [02:12<00:31, 291.37 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40379/47780 [02:12<00:22, 328.04 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30134/47780 [02:12<01:04, 272.69 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40893/47780 [02:12<00:30, 223.40 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39024/47780 [02:12<00:26, 327.92 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38579/47780 [02:12<00:33, 277.17 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40658/47780 [02:12<00:26, 265.18 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39839/47780 [02:12<00:32, 242.06 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40424/47780 [02:12<00:20, 361.24 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30180/47780 [02:12<00:54, 325.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40930/47780 [02:12<00:26, 263.18 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38776/47780 [02:12<00:31, 283.89 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39057/47780 [02:12<00:26, 324.19 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39882/47780 [02:12<00:27, 288.07 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40686/47780 [02:12<00:27, 257.73 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38608/47780 [02:12<00:39, 229.41 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40974/47780 [02:12<00:21, 312.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38811/47780 [02:12<00:30, 298.79 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30218/47780 [02:12<00:54, 322.28 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40462/47780 [02:13<00:21, 333.14 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39090/47780 [02:12<00:28, 305.08 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39921/47780 [02:13<00:24, 315.38 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40751/47780 [02:13<00:19, 360.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38645/47780 [02:13<00:35, 260.32 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41010/47780 [02:13<00:21, 312.82 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38842/47780 [02:13<00:30, 295.33 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30251/47780 [02:13<00:55, 317.08 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40497/47780 [02:13<00:21, 337.50 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39122/47780 [02:13<00:28, 302.54 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39955/47780 [02:13<00:24, 315.35 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40789/47780 [02:13<00:19, 349.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38673/47780 [02:13<00:35, 259.81 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41050/47780 [02:13<00:20, 335.91 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38873/47780 [02:13<00:30, 295.57 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30284/47780 [02:13<00:55, 317.41 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40532/47780 [02:13<00:21, 330.06 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39161/47780 [02:13<00:26, 324.67 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39993/47780 [02:13<00:23, 333.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40826/47780 [02:13<00:20, 340.56 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41089/47780 [02:13<00:19, 344.18 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38903/47780 [02:13<00:31, 284.41 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38701/47780 [02:13<00:37, 244.58 examples/s]
Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30316/47780 [02:13<00:58, 297.93 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40566/47780 [02:13<00:23, 312.07 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40036/47780 [02:13<00:21, 353.04 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39195/47780 [02:13<00:28, 300.55 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38727/47780 [02:13<00:36, 246.36 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41127/47780 [02:13<00:19, 335.04 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38932/47780 [02:13<00:32, 273.69 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30347/47780 [02:13<00:58, 297.80 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40605/47780 [02:13<00:22, 326.07 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40072/47780 [02:13<00:22, 343.09 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40861/47780 [02:13<00:24, 276.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39226/47780 [02:13<00:28, 303.10 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38756/47780 [02:13<00:34, 257.85 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41161/47780 [02:13<00:19, 333.01 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30378/47780 [02:13<00:58, 298.02 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38961/47780 [02:13<00:32, 275.12 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40107/47780 [02:13<00:22, 341.03 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40639/47780 [02:13<00:22, 319.52 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40904/47780 [02:13<00:22, 310.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39262/47780 [02:13<00:26, 315.55 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38785/47780 [02:13<00:34, 263.87 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30409/47780 [02:13<00:59, 291.65 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41195/47780 [02:13<00:21, 310.38 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40675/47780 [02:13<00:21, 330.25 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40142/47780 [02:13<00:22, 339.73 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39295/47780 [02:13<00:26, 319.56 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38989/47780 [02:13<00:35, 251.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40940/47780 [02:13<00:21, 311.57 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30445/47780 [02:13<00:55, 310.79 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41227/47780 [02:13<00:21, 305.20 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40177/47780 [02:13<00:22, 335.87 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40987/47780 [02:13<00:19, 351.26 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39330/47780 [02:13<00:26, 317.36 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39015/47780 [02:13<00:35, 248.18 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40709/47780 [02:13<00:22, 308.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38812/47780 [02:13<00:40, 223.19 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30478/47780 [02:13<00:56, 307.67 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41028/47780 [02:13<00:18, 363.04 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41258/47780 [02:13<00:22, 293.58 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39041/47780 [02:13<00:35, 248.29 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39362/47780 [02:13<00:27, 307.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38860/47780 [02:13<00:31, 284.78 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40741/47780 [02:13<00:24, 284.08 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40211/47780 [02:13<00:26, 289.83 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30509/47780 [02:13<00:58, 293.14 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41070/47780 [02:14<00:17, 374.66 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39067/47780 [02:13<00:35, 246.04 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38895/47780 [02:13<00:29, 298.82 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41288/47780 [02:13<00:23, 275.41 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39393/47780 [02:13<00:28, 291.45 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40257/47780 [02:14<00:22, 330.92 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40770/47780 [02:14<00:25, 274.19 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30541/47780 [02:14<00:58, 294.00 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39092/47780 [02:14<00:35, 242.16 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38930/47780 [02:14<00:28, 312.51 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41109/47780 [02:14<00:19, 347.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39425/47780 [02:14<00:28, 293.17 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41316/47780 [02:14<00:24, 262.53 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40292/47780 [02:14<00:23, 325.37 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40798/47780 [02:14<00:27, 253.95 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30572/47780 [02:14<00:58, 295.24 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39121/47780 [02:14<00:34, 252.91 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39459/47780 [02:14<00:27, 305.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38963/47780 [02:14<00:29, 297.64 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41343/47780 [02:14<00:25, 256.42 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41146/47780 [02:14<00:20, 322.32 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40326/47780 [02:14<00:24, 305.94 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40835/47780 [02:14<00:24, 278.47 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30603/47780 [02:14<00:58, 296.09 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39153/47780 [02:14<00:31, 271.94 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39490/47780 [02:14<00:27, 296.94 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38994/47780 [02:14<00:30, 288.53 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41377/47780 [02:14<00:23, 275.83 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41183/47780 [02:14<00:20, 324.86 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40365/47780 [02:14<00:22, 323.82 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40864/47780 [02:14<00:25, 272.82 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39184/47780 [02:14<00:30, 282.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30633/47780 [02:14<00:59, 286.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39526/47780 [02:14<00:26, 312.90 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41414/47780 [02:14<00:21, 300.96 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39024/47780 [02:14<00:31, 276.32 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41217/47780 [02:14<00:20, 315.52 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40906/47780 [02:14<00:22, 307.60 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40399/47780 [02:14<00:24, 303.08 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39220/47780 [02:14<00:28, 301.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30662/47780 [02:14<01:00, 281.89 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39559/47780 [02:14<00:27, 299.37 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39062/47780 [02:14<00:29, 298.04 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41445/47780 [02:14<00:22, 279.16 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41251/47780 [02:14<00:21, 308.91 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40938/47780 [02:14<00:22, 309.17 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40430/47780 [02:14<00:25, 289.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39251/47780 [02:14<00:29, 290.66 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30691/47780 [02:14<01:04, 263.03 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39601/47780 [02:14<00:24, 329.24 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39096/47780 [02:14<00:28, 309.48 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41474/47780 [02:14<00:22, 275.73 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41283/47780 [02:14<00:21, 308.00 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40970/47780 [02:14<00:23, 292.54 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39281/47780 [02:14<00:29, 286.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40460/47780 [02:14<00:25, 283.23 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30718/47780 [02:14<01:07, 254.10 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39640/47780 [02:14<00:23, 342.55 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39129/47780 [02:14<00:29, 292.31 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41316/47780 [02:14<00:21, 307.46 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41502/47780 [02:14<00:24, 254.96 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41000/47780 [02:14<00:23, 290.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39320/47780 [02:14<00:26, 316.21 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40489/47780 [02:14<00:26, 276.42 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30755/47780 [02:14<01:00, 282.51 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39679/47780 [02:14<00:23, 344.24 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39168/47780 [02:14<00:27, 308.66 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41529/47780 [02:14<00:24, 257.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41347/47780 [02:14<00:22, 288.92 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41031/47780 [02:14<00:24, 281.12 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40517/47780 [02:14<00:27, 268.56 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39352/47780 [02:14<00:28, 293.44 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30784/47780 [02:14<01:01, 275.47 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39715/47780 [02:14<00:23, 340.85 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39201/47780 [02:14<00:27, 307.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41390/47780 [02:15<00:19, 324.08 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41556/47780 [02:15<00:25, 241.21 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41061/47780 [02:15<00:23, 286.23 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40554/47780 [02:15<00:24, 293.04 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39387/47780 [02:15<00:28, 299.13 examples/s]
Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30818/47780 [02:15<00:58, 290.02 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39750/47780 [02:15<00:23, 336.06 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41424/47780 [02:15<00:19, 328.47 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39233/47780 [02:15<00:29, 291.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41582/47780 [02:15<00:25, 246.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41094/47780 [02:15<00:22, 295.34 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40585/47780 [02:15<00:24, 297.73 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30851/47780 [02:15<00:56, 298.03 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39418/47780 [02:15<00:29, 286.24 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39784/47780 [02:15<00:25, 319.07 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39264/47780 [02:15<00:28, 293.75 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41129/47780 [02:15<00:21, 310.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41464/47780 [02:15<00:19, 332.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41610/47780 [02:15<00:24, 247.32 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40628/47780 [02:15<00:21, 335.18 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30882/47780 [02:15<00:56, 298.14 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39461/47780 [02:15<00:25, 322.07 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39817/47780 [02:15<00:25, 314.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41501/47780 [02:15<00:18, 337.60 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39295/47780 [02:15<00:30, 282.44 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41161/47780 [02:15<00:22, 293.10 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41635/47780 [02:15<00:25, 237.15 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40662/47780 [02:15<00:22, 318.40 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30912/47780 [02:15<00:57, 295.23 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39494/47780 [02:15<00:26, 308.56 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39849/47780 [02:15<00:25, 309.69 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41542/47780 [02:15<00:17, 357.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39336/47780 [02:15<00:26, 313.78 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40700/47780 [02:15<00:21, 335.63 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41192/47780 [02:15<00:22, 288.17 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30942/47780 [02:15<00:58, 289.88 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41659/47780 [02:15<00:27, 223.68 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39526/47780 [02:15<00:27, 296.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39881/47780 [02:15<00:26, 302.35 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39373/47780 [02:15<00:26, 322.22 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41578/47780 [02:15<00:18, 341.85 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30972/47780 [02:15<00:58, 286.58 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41692/47780 [02:15<00:24, 249.59 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40734/47780 [02:15<00:22, 318.69 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41222/47780 [02:15<00:23, 278.74 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39918/47780 [02:15<00:24, 321.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39557/47780 [02:15<00:28, 291.22 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39407/47780 [02:15<00:26, 320.03 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41616/47780 [02:15<00:18, 341.40 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31001/47780 [02:15<00:58, 287.04 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40767/47780 [02:15<00:22, 318.08 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41251/47780 [02:15<00:23, 276.21 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41718/47780 [02:15<00:25, 241.79 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39952/47780 [02:15<00:24, 322.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39587/47780 [02:15<00:28, 287.58 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39448/47780 [02:15<00:24, 345.13 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41659/47780 [02:15<00:17, 358.19 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31030/47780 [02:15<00:58, 287.80 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41280/47780 [02:15<00:23, 279.97 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40808/47780 [02:15<00:20, 332.96 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41753/47780 [02:15<00:22, 265.58 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39985/47780 [02:15<00:24, 317.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39616/47780 [02:15<00:28, 285.75 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39483/47780 [02:15<00:25, 331.59 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41697/47780 [02:15<00:17, 352.88 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31069/47780 [02:15<00:55, 303.73 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41309/47780 [02:15<00:23, 273.51 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40842/47780 [02:15<00:21, 324.10 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41780/47780 [02:15<00:22, 260.98 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39645/47780 [02:15<00:28, 285.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40028/47780 [02:15<00:22, 341.81 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39524/47780 [02:15<00:23, 349.71 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41742/47780 [02:16<00:16, 375.36 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31105/47780 [02:15<00:52, 314.94 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41820/47780 [02:16<00:20, 296.61 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41337/47780 [02:16<00:24, 263.44 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39677/47780 [02:16<00:27, 292.66 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40063/47780 [02:16<00:23, 325.84 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40875/47780 [02:16<00:24, 281.69 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39560/47780 [02:16<00:24, 341.00 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41783/47780 [02:16<00:16, 372.68 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31138/47780 [02:16<00:52, 316.96 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41365/47780 [02:16<00:23, 267.99 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41850/47780 [02:16<00:20, 287.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39707/47780 [02:16<00:28, 278.65 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40096/47780 [02:16<00:25, 305.97 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39596/47780 [02:16<00:24, 338.23 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41821/47780 [02:16<00:16, 362.41 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41400/47780 [02:16<00:21, 291.12 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31170/47780 [02:16<00:55, 300.38 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40905/47780 [02:16<00:28, 239.20 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41889/47780 [02:16<00:19, 302.86 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39740/47780 [02:16<00:27, 289.91 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40130/47780 [02:16<00:24, 313.48 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39631/47780 [02:16<00:24, 334.55 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41433/47780 [02:16<00:20, 302.30 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31207/47780 [02:16<00:52, 313.24 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41858/47780 [02:16<00:17, 341.38 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40958/47780 [02:16<00:22, 305.08 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41920/47780 [02:16<00:19, 293.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39770/47780 [02:16<00:28, 285.74 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40162/47780 [02:16<00:24, 307.38 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39668/47780 [02:16<00:23, 338.61 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41464/47780 [02:16<00:21, 297.86 examples/s]
Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31239/47780 [02:16<00:53, 307.94 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41893/47780 [02:16<00:18, 319.32 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39799/47780 [02:16<00:28, 284.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41950/47780 [02:16<00:20, 284.04 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40992/47780 [02:16<00:23, 290.52 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40194/47780 [02:16<00:25, 294.01 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41502/47780 [02:16<00:19, 321.50 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39702/47780 [02:16<00:25, 322.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31270/47780 [02:16<00:53, 308.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41926/47780 [02:16<00:18, 312.08 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39829/47780 [02:16<00:28, 282.31 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41979/47780 [02:16<00:20, 279.74 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41023/47780 [02:16<00:23, 291.19 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40227/47780 [02:16<00:25, 298.14 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39735/47780 [02:16<00:26, 304.17 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41535/47780 [02:16<00:21, 296.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31301/47780 [02:16<00:57, 285.94 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39860/47780 [02:16<00:27, 290.05 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41057/47780 [02:16<00:22, 302.04 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42008/47780 [02:16<00:21, 267.70 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41958/47780 [02:16<00:20, 286.28 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40257/47780 [02:16<00:26, 281.95 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41567/47780 [02:16<00:20, 296.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31330/47780 [02:16<00:57, 283.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39766/47780 [02:16<00:28, 283.79 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41093/47780 [02:16<00:21, 314.34 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39890/47780 [02:16<00:28, 277.11 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42041/47780 [02:16<00:20, 281.73 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41988/47780 [02:16<00:20, 283.95 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40288/47780 [02:16<00:27, 275.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31360/47780 [02:16<00:57, 285.28 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39795/47780 [02:16<00:28, 283.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41127/47780 [02:16<00:20, 321.39 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41599/47780 [02:16<00:22, 280.88 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39918/47780 [02:16<00:28, 277.43 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42070/47780 [02:16<00:20, 277.87 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42026/47780 [02:16<00:19, 297.37 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40316/47780 [02:16<00:27, 267.72 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39831/47780 [02:16<00:26, 303.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31389/47780 [02:16<00:59, 276.90 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41160/47780 [02:17<00:20, 316.38 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41628/47780 [02:17<00:22, 277.47 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39946/47780 [02:17<00:28, 277.78 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42100/47780 [02:17<00:19, 284.03 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42073/47780 [02:17<00:16, 339.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40343/47780 [02:17<00:27, 268.20 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31425/47780 [02:17<00:56, 290.74 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39982/47780 [02:17<00:26, 295.64 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41658/47780 [02:17<00:22, 274.68 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41193/47780 [02:17<00:21, 303.41 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42129/47780 [02:17<00:20, 279.34 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39862/47780 [02:17<00:28, 277.53 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42116/47780 [02:17<00:16, 353.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40371/47780 [02:17<00:27, 265.85 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31455/47780 [02:17<00:56, 289.11 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41690/47780 [02:17<00:21, 284.01 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39893/47780 [02:17<00:27, 286.05 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41225/47780 [02:17<00:22, 297.79 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40012/47780 [02:17<00:28, 276.87 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42160/47780 [02:17<00:20, 277.38 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42152/47780 [02:17<00:15, 355.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40400/47780 [02:17<00:27, 263.84 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31494/47780 [02:17<00:51, 315.21 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41728/47780 [02:17<00:19, 304.10 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41256/47780 [02:17<00:22, 295.05 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39923/47780 [02:17<00:28, 277.84 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42188/47780 [02:17<00:20, 267.02 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40040/47780 [02:17<00:30, 250.50 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40443/47780 [02:17<00:23, 310.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42189/47780 [02:17<00:17, 316.49 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31526/47780 [02:17<00:52, 309.09 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41764/47780 [02:17<00:18, 319.72 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41290/47780 [02:17<00:21, 304.09 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39952/47780 [02:17<00:28, 272.24 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42216/47780 [02:17<00:21, 264.91 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40072/47780 [02:17<00:28, 266.20 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42222/47780 [02:17<00:17, 319.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40475/47780 [02:17<00:23, 305.66 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31558/47780 [02:17<00:52, 307.99 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41327/47780 [02:17<00:19, 322.69 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41797/47780 [02:17<00:19, 302.98 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39986/47780 [02:17<00:26, 290.78 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42243/47780 [02:17<00:20, 266.00 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40506/47780 [02:17<00:24, 300.54 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42255/47780 [02:17<00:17, 315.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40100/47780 [02:17<00:30, 248.05 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31591/47780 [02:17<00:51, 311.84 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41828/47780 [02:17<00:19, 303.99 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41368/47780 [02:17<00:18, 340.01 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40022/47780 [02:17<00:25, 307.05 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42270/47780 [02:17<00:21, 258.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40537/47780 [02:17<00:23, 303.04 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40132/47780 [02:17<00:28, 264.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42290/47780 [02:17<00:17, 318.26 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31627/47780 [02:17<00:50, 322.05 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41403/47780 [02:17<00:19, 334.88 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41859/47780 [02:17<00:19, 298.55 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42296/47780 [02:17<00:21, 250.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40066/47780 [02:17<00:23, 323.06 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40168/47780 [02:17<00:27, 281.26 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42323/47780 [02:17<00:17, 313.13 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31660/47780 [02:17<00:49, 324.35 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40568/47780 [02:17<00:25, 288.09 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41447/47780 [02:17<00:17, 362.94 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41890/47780 [02:17<00:20, 288.70 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40100/47780 [02:17<00:23, 327.39 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42328/47780 [02:17<00:20, 267.15 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31703/47780 [02:17<00:45, 351.16 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40598/47780 [02:17<00:24, 287.88 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40197/47780 [02:17<00:28, 266.11 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41484/47780 [02:17<00:17, 357.61 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42355/47780 [02:18<00:19, 276.25 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40134/47780 [02:17<00:23, 330.69 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41920/47780 [02:18<00:20, 279.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42355/47780 [02:18<00:21, 249.24 examples/s]
Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31740/47780 [02:18<00:44, 356.65 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40230/47780 [02:18<00:26, 282.97 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40632/47780 [02:18<00:24, 286.87 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41956/47780 [02:18<00:19, 298.61 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40168/47780 [02:18<00:23, 318.93 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42381/47780 [02:18<00:21, 248.68 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41520/47780 [02:18<00:20, 300.40 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42384/47780 [02:18<00:22, 239.98 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40259/47780 [02:18<00:26, 282.09 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40661/47780 [02:18<00:25, 278.72 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31780/47780 [02:18<00:47, 336.22 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41987/47780 [02:18<00:19, 301.80 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40202/47780 [02:18<00:23, 321.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42411/47780 [02:18<00:20, 259.74 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41563/47780 [02:18<00:18, 330.49 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42414/47780 [02:18<00:22, 242.74 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40288/47780 [02:18<00:27, 275.97 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31819/47780 [02:18<00:45, 348.67 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42021/47780 [02:18<00:18, 309.14 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40236/47780 [02:18<00:23, 326.53 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40689/47780 [02:18<00:29, 241.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42443/47780 [02:18<00:19, 273.75 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41598/47780 [02:18<00:19, 318.51 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40316/47780 [02:18<00:27, 272.82 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31858/47780 [02:18<00:44, 356.40 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42440/47780 [02:18<00:22, 237.66 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42053/47780 [02:18<00:18, 308.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40269/47780 [02:18<00:24, 312.47 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42475/47780 [02:18<00:18, 280.16 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40714/47780 [02:18<00:31, 222.43 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41635/47780 [02:18<00:18, 328.97 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31894/47780 [02:18<00:44, 356.92 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40347/47780 [02:18<00:26, 277.54 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42465/47780 [02:18<00:22, 232.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42097/47780 [02:18<00:16, 338.84 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42506/47780 [02:18<00:18, 285.79 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40301/47780 [02:18<00:25, 291.30 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40751/47780 [02:18<00:27, 257.58 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41677/47780 [02:18<00:17, 339.07 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40377/47780 [02:18<00:26, 283.79 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31932/47780 [02:18<00:45, 347.34 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42134/47780 [02:18<00:16, 336.18 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42489/47780 [02:18<00:24, 213.29 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40334/47780 [02:18<00:25, 296.20 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42535/47780 [02:18<00:19, 268.42 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40780/47780 [02:18<00:26, 263.32 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40406/47780 [02:18<00:26, 279.16 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41712/47780 [02:18<00:18, 327.79 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31970/47780 [02:18<00:44, 353.20 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42514/47780 [02:18<00:23, 220.52 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42168/47780 [02:18<00:17, 322.62 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40364/47780 [02:18<00:25, 292.09 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40816/47780 [02:18<00:24, 289.38 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42567/47780 [02:18<00:19, 270.44 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41767/47780 [02:18<00:15, 388.02 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40436/47780 [02:18<00:26, 277.13 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32006/47780 [02:18<00:45, 343.40 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42205/47780 [02:18<00:16, 335.84 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42543/47780 [02:18<00:22, 233.78 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40410/47780 [02:18<00:22, 333.66 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40846/47780 [02:18<00:25, 274.10 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42607/47780 [02:18<00:17, 295.65 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40464/47780 [02:18<00:26, 271.47 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32044/47780 [02:18<00:44, 353.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41819/47780 [02:18<00:14, 406.62 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42239/47780 [02:19<00:17, 314.91 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40453/47780 [02:18<00:20, 356.78 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42567/47780 [02:19<00:24, 208.61 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42639/47780 [02:19<00:17, 299.90 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32080/47780 [02:18<00:44, 351.55 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40497/47780 [02:19<00:25, 280.49 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40875/47780 [02:19<00:27, 250.67 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41861/47780 [02:19<00:16, 368.41 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40489/47780 [02:19<00:21, 346.74 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42589/47780 [02:19<00:24, 211.21 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42271/47780 [02:19<00:18, 291.15 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40527/47780 [02:19<00:25, 282.83 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32116/47780 [02:19<00:45, 341.73 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40902/47780 [02:19<00:27, 253.58 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42670/47780 [02:19<00:19, 263.34 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41936/47780 [02:19<00:12, 463.43 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42613/47780 [02:19<00:23, 217.83 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42306/47780 [02:19<00:18, 303.68 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40524/47780 [02:19<00:21, 332.02 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40556/47780 [02:19<00:25, 281.71 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40930/47780 [02:19<00:26, 258.24 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32156/47780 [02:19<00:47, 332.05 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42715/47780 [02:19<00:16, 306.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41985/47780 [02:19<00:12, 467.04 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42342/47780 [02:19<00:17, 315.63 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42636/47780 [02:19<00:24, 210.84 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40585/47780 [02:19<00:25, 284.04 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40558/47780 [02:19<00:23, 303.70 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40960/47780 [02:19<00:25, 269.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32203/47780 [02:19<00:42, 368.11 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42033/47780 [02:19<00:13, 436.90 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42374/47780 [02:19<00:17, 313.23 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42747/47780 [02:19<00:18, 269.28 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42665/47780 [02:19<00:22, 227.61 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40619/47780 [02:19<00:24, 293.50 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40992/47780 [02:19<00:24, 280.50 examples/s]
Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32241/47780 [02:19<00:42, 366.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40590/47780 [02:19<00:25, 286.46 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42083/47780 [02:19<00:12, 448.91 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42406/47780 [02:19<00:17, 311.08 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42690/47780 [02:19<00:22, 231.02 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42783/47780 [02:19<00:18, 273.28 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40649/47780 [02:19<00:24, 288.63 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41022/47780 [02:19<00:24, 279.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32279/47780 [02:19<00:42, 364.69 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40623/47780 [02:19<00:24, 291.85 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42134/47780 [02:19<00:12, 455.65 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40680/47780 [02:19<00:24, 294.62 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42438/47780 [02:19<00:18, 287.94 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41058/47780 [02:19<00:22, 302.59 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42812/47780 [02:19<00:18, 269.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32316/47780 [02:19<00:43, 358.07 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40653/47780 [02:19<00:24, 291.05 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42714/47780 [02:19<00:25, 198.12 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42181/47780 [02:19<00:13, 430.61 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42473/47780 [02:19<00:17, 301.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40710/47780 [02:19<00:24, 283.18 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32355/47780 [02:19<00:42, 363.21 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41089/47780 [02:19<00:23, 284.51 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42840/47780 [02:19<00:19, 249.22 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42768/47780 [02:19<00:17, 284.69 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40683/47780 [02:19<00:25, 275.15 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42227/47780 [02:19<00:12, 429.60 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42514/47780 [02:19<00:15, 331.62 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40739/47780 [02:19<00:24, 282.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41121/47780 [02:19<00:22, 293.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32401/47780 [02:19<00:39, 386.44 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42866/47780 [02:19<00:19, 249.34 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40712/47780 [02:19<00:25, 277.82 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42800/47780 [02:19<00:17, 281.78 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42271/47780 [02:19<00:13, 418.69 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40774/47780 [02:19<00:23, 301.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41158/47780 [02:19<00:21, 313.17 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42548/47780 [02:20<00:17, 298.23 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32440/47780 [02:19<00:41, 370.16 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42892/47780 [02:20<00:19, 246.65 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42832/47780 [02:20<00:17, 289.04 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40740/47780 [02:20<00:25, 270.87 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40805/47780 [02:20<00:23, 300.45 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42315/47780 [02:20<00:13, 397.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41191/47780 [02:20<00:20, 314.49 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42927/47780 [02:20<00:17, 270.59 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32478/47780 [02:20<00:43, 349.18 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40768/47780 [02:20<00:26, 267.33 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42579/47780 [02:20<00:18, 273.96 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42863/47780 [02:20<00:17, 279.57 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40838/47780 [02:20<00:22, 309.01 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41226/47780 [02:20<00:20, 324.67 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42356/47780 [02:20<00:14, 365.76 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40797/47780 [02:20<00:26, 264.95 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42608/47780 [02:20<00:19, 272.20 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32515/47780 [02:20<00:45, 336.45 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42955/47780 [02:20<00:20, 239.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40874/47780 [02:20<00:21, 316.66 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41259/47780 [02:20<00:21, 299.56 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42892/47780 [02:20<00:22, 219.66 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42639/47780 [02:20<00:18, 280.20 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42395/47780 [02:20<00:15, 340.17 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32549/47780 [02:20<00:46, 330.47 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 43000/47780 [02:20<00:16, 291.04 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40824/47780 [02:20<00:27, 249.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40914/47780 [02:20<00:20, 336.91 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41293/47780 [02:20<00:21, 306.03 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42970/47780 [02:20<00:13, 347.34 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42669/47780 [02:20<00:17, 284.80 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42432/47780 [02:20<00:15, 344.52 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32587/47780 [02:20<00:44, 341.50 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43036/47780 [02:20<00:15, 309.35 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40859/47780 [02:20<00:25, 274.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40948/47780 [02:20<00:20, 333.48 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41326/47780 [02:20<00:21, 301.80 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42701/47780 [02:20<00:17, 294.63 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42473/47780 [02:20<00:14, 354.31 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32622/47780 [02:20<00:44, 342.71 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43076/47780 [02:20<00:14, 330.72 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43010/47780 [02:20<00:14, 337.02 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40887/47780 [02:20<00:26, 258.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40986/47780 [02:20<00:20, 339.36 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41362/47780 [02:20<00:20, 315.44 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42740/47780 [02:20<00:16, 311.20 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32660/47780 [02:20<00:42, 353.10 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42509/47780 [02:20<00:15, 344.70 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43049/47780 [02:20<00:13, 343.36 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41028/47780 [02:20<00:18, 360.49 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40918/47780 [02:20<00:25, 266.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43110/47780 [02:20<00:15, 299.36 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41397/47780 [02:20<00:19, 325.00 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42774/47780 [02:20<00:15, 319.33 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42552/47780 [02:20<00:14, 367.64 examples/s]
Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32703/47780 [02:20<00:42, 358.83 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43096/47780 [02:20<00:12, 368.43 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40946/47780 [02:20<00:26, 261.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41065/47780 [02:20<00:19, 345.00 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43143/47780 [02:20<00:16, 278.43 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41431/47780 [02:20<00:20, 315.05 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32747/47780 [02:20<00:40, 373.63 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43143/47780 [02:20<00:11, 387.17 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42590/47780 [02:20<00:15, 344.15 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42807/47780 [02:20<00:17, 286.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40977/47780 [02:20<00:24, 275.02 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41100/47780 [02:20<00:19, 335.23 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43185/47780 [02:20<00:14, 308.17 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41463/47780 [02:20<00:20, 313.05 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43185/47780 [02:21<00:11, 391.77 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32785/47780 [02:20<00:42, 353.10 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42627/47780 [02:21<00:14, 343.94 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42846/47780 [02:21<00:15, 310.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41006/47780 [02:21<00:24, 279.12 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41135/47780 [02:21<00:20, 325.04 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41495/47780 [02:21<00:19, 314.58 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43217/47780 [02:21<00:15, 298.69 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32824/47780 [02:21<00:41, 361.62 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42663/47780 [02:21<00:15, 340.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41035/47780 [02:21<00:24, 272.69 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43226/47780 [02:21<00:12, 364.23 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41168/47780 [02:21<00:20, 325.89 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42878/47780 [02:21<00:17, 281.96 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41527/47780 [02:21<00:20, 309.29 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43253/47780 [02:21<00:14, 308.42 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32877/47780 [02:21<00:36, 409.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42704/47780 [02:21<00:14, 359.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41070/47780 [02:21<00:23, 290.39 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43264/47780 [02:21<00:12, 361.11 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42928/47780 [02:21<00:14, 338.05 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41201/47780 [02:21<00:21, 304.26 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43285/47780 [02:21<00:14, 301.48 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41562/47780 [02:21<00:21, 290.53 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32919/47780 [02:21<00:37, 397.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42755/47780 [02:21<00:12, 393.63 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43301/47780 [02:21<00:13, 339.68 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41100/47780 [02:21<00:25, 266.80 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42964/47780 [02:21<00:14, 324.11 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41232/47780 [02:21<00:22, 289.10 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43316/47780 [02:21<00:15, 297.58 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41599/47780 [02:21<00:20, 305.84 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32972/47780 [02:21<00:34, 431.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42806/47780 [02:21<00:11, 421.95 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41134/47780 [02:21<00:23, 280.62 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43005/47780 [02:21<00:13, 343.30 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43336/47780 [02:21<00:13, 320.11 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41266/47780 [02:21<00:21, 302.73 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43347/47780 [02:21<00:15, 290.88 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42852/47780 [02:21<00:11, 432.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33017/47780 [02:21<00:34, 428.76 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41630/47780 [02:21<00:23, 266.09 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43047/47780 [02:21<00:13, 360.35 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41163/47780 [02:21<00:24, 270.74 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43369/47780 [02:21<00:14, 309.72 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43379/47780 [02:21<00:15, 286.74 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41297/47780 [02:21<00:23, 271.74 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42899/47780 [02:21<00:11, 433.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33061/47780 [02:21<00:35, 420.04 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41664/47780 [02:21<00:21, 284.86 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41196/47780 [02:21<00:23, 284.35 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43401/47780 [02:21<00:14, 296.74 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43084/47780 [02:21<00:14, 317.00 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41328/47780 [02:21<00:23, 278.83 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42950/47780 [02:21<00:10, 450.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33104/47780 [02:21<00:35, 418.30 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43408/47780 [02:21<00:17, 246.72 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41225/47780 [02:21<00:23, 282.78 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41694/47780 [02:21<00:24, 253.20 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43121/47780 [02:21<00:14, 325.40 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41362/47780 [02:21<00:21, 295.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 43000/47780 [02:21<00:10, 459.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43431/47780 [02:21<00:15, 281.82 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33146/47780 [02:21<00:37, 391.81 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43440/47780 [02:21<00:16, 260.20 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41257/47780 [02:21<00:22, 288.16 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41756/47780 [02:21<00:17, 338.70 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43159/47780 [02:21<00:13, 339.57 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41398/47780 [02:21<00:20, 309.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43047/47780 [02:21<00:10, 452.31 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43461/47780 [02:22<00:15, 278.65 examples/s]
Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33186/47780 [02:21<00:38, 381.26 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43469/47780 [02:22<00:16, 264.93 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41288/47780 [02:22<00:22, 283.47 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41434/47780 [02:22<00:19, 318.08 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43194/47780 [02:22<00:13, 330.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43096/47780 [02:22<00:10, 461.68 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43496/47780 [02:22<00:14, 288.52 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41792/47780 [02:22<00:19, 310.11 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33225/47780 [02:22<00:40, 363.53 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41330/47780 [02:22<00:20, 321.78 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43497/47780 [02:22<00:17, 240.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43143/47780 [02:22<00:10, 460.20 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43229/47780 [02:22<00:14, 325.05 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43525/47780 [02:22<00:14, 288.60 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41467/47780 [02:22<00:21, 299.60 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41825/47780 [02:22<00:19, 304.58 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41363/47780 [02:22<00:20, 320.49 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33262/47780 [02:22<00:41, 346.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43524/47780 [02:22<00:17, 243.37 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43191/47780 [02:22<00:10, 445.22 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43275/47780 [02:22<00:12, 350.65 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43556/47780 [02:22<00:14, 288.50 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41498/47780 [02:22<00:22, 283.99 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41857/47780 [02:22<00:20, 287.70 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41403/47780 [02:22<00:19, 331.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43550/47780 [02:22<00:17, 247.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33297/47780 [02:22<00:47, 304.92 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43587/47780 [02:22<00:14, 294.23 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43312/47780 [02:22<00:12, 348.31 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43237/47780 [02:22<00:10, 416.20 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41536/47780 [02:22<00:20, 309.33 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41437/47780 [02:22<00:19, 323.15 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41887/47780 [02:22<00:22, 266.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43584/47780 [02:22<00:15, 272.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33331/47780 [02:22<00:46, 313.61 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43352/47780 [02:22<00:12, 356.82 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43617/47780 [02:22<00:14, 283.20 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43280/47780 [02:22<00:11, 406.38 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41568/47780 [02:22<00:20, 301.11 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41473/47780 [02:22<00:19, 329.84 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41918/47780 [02:22<00:21, 274.95 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43618/47780 [02:22<00:14, 290.92 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43390/47780 [02:22<00:12, 361.25 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43651/47780 [02:22<00:14, 289.43 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33364/47780 [02:22<00:50, 284.48 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41602/47780 [02:22<00:20, 306.77 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43321/47780 [02:22<00:11, 390.51 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41507/47780 [02:22<00:19, 325.28 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41949/47780 [02:22<00:20, 281.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43648/47780 [02:22<00:14, 290.47 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33406/47780 [02:22<00:45, 315.96 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43681/47780 [02:22<00:14, 276.90 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41640/47780 [02:22<00:19, 320.08 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43370/47780 [02:22<00:10, 417.27 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43427/47780 [02:22<00:13, 329.54 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43687/47780 [02:22<00:12, 316.16 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41981/47780 [02:22<00:20, 285.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41540/47780 [02:22<00:19, 312.33 examples/s]
Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33440/47780 [02:22<00:45, 312.16 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41674/47780 [02:22<00:19, 318.57 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43467/47780 [02:22<00:12, 337.90 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43413/47780 [02:22<00:10, 407.46 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43709/47780 [02:22<00:15, 258.01 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42011/47780 [02:22<00:20, 286.26 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43724/47780 [02:22<00:12, 324.17 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41575/47780 [02:22<00:19, 322.78 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33472/47780 [02:22<00:45, 311.27 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43512/47780 [02:22<00:11, 368.24 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41710/47780 [02:22<00:18, 319.51 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43753/47780 [02:22<00:13, 306.52 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43455/47780 [02:22<00:11, 388.70 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41608/47780 [02:22<00:19, 313.91 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42040/47780 [02:22<00:21, 272.22 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43757/47780 [02:23<00:13, 289.35 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33506/47780 [02:23<00:44, 319.09 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43561/47780 [02:23<00:10, 400.02 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43786/47780 [02:23<00:12, 312.99 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43495/47780 [02:23<00:11, 388.16 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41749/47780 [02:23<00:18, 321.17 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41641/47780 [02:23<00:19, 315.29 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43787/47780 [02:23<00:13, 286.70 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42068/47780 [02:23<00:24, 235.21 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33539/47780 [02:23<00:46, 305.10 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43818/47780 [02:23<00:12, 311.15 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43535/47780 [02:23<00:10, 386.93 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43603/47780 [02:23<00:11, 377.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41783/47780 [02:23<00:18, 322.86 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41673/47780 [02:23<00:20, 302.86 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43821/47780 [02:23<00:13, 299.62 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42109/47780 [02:23<00:20, 276.74 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43580/47780 [02:23<00:10, 400.55 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43647/47780 [02:23<00:10, 380.99 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43851/47780 [02:23<00:13, 293.33 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33580/47780 [02:23<00:46, 303.51 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41816/47780 [02:23<00:19, 304.38 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41708/47780 [02:23<00:19, 308.90 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43853/47780 [02:23<00:13, 280.95 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43653/47780 [02:23<00:08, 488.83 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42139/47780 [02:23<00:21, 266.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33630/47780 [02:23<00:40, 348.27 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43686/47780 [02:23<00:11, 365.34 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41853/47780 [02:23<00:19, 311.92 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43881/47780 [02:23<00:14, 277.03 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41739/47780 [02:23<00:20, 298.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43882/47780 [02:23<00:14, 274.26 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43703/47780 [02:23<00:08, 460.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42167/47780 [02:23<00:21, 256.35 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43728/47780 [02:23<00:10, 375.91 examples/s]
Tokenizing train dataset (num_proc=32):  70%|███████   | 33666/47780 [02:23<00:41, 336.99 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43911/47780 [02:23<00:13, 279.96 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41885/47780 [02:23<00:19, 304.28 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41772/47780 [02:23<00:19, 304.57 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43915/47780 [02:23<00:13, 280.66 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42196/47780 [02:23<00:21, 263.55 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43766/47780 [02:23<00:10, 372.64 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43940/47780 [02:23<00:13, 276.78 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33701/47780 [02:23<00:42, 329.82 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41916/47780 [02:23<00:19, 296.07 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41803/47780 [02:23<00:20, 289.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43750/47780 [02:23<00:09, 404.28 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42223/47780 [02:23<00:21, 261.30 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43978/47780 [02:23<00:12, 305.26 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43804/47780 [02:23<00:11, 350.54 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43944/47780 [02:23<00:15, 241.11 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41953/47780 [02:23<00:19, 300.04 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33735/47780 [02:23<00:44, 312.27 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41838/47780 [02:23<00:19, 303.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43797/47780 [02:23<00:10, 395.00 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42251/47780 [02:23<00:21, 260.57 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44009/47780 [02:23<00:12, 301.27 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33781/47780 [02:23<00:39, 351.67 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43970/47780 [02:23<00:15, 240.95 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43840/47780 [02:23<00:11, 331.97 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41882/47780 [02:23<00:17, 337.70 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41984/47780 [02:23<00:20, 281.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43838/47780 [02:23<00:10, 380.97 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42278/47780 [02:23<00:21, 260.32 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44045/47780 [02:23<00:11, 313.09 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33827/47780 [02:23<00:36, 377.35 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43998/47780 [02:23<00:15, 243.45 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41919/47780 [02:23<00:17, 335.51 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43874/47780 [02:24<00:12, 317.18 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42018/47780 [02:23<00:19, 296.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43884/47780 [02:24<00:09, 397.85 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42306/47780 [02:24<00:21, 257.01 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44082/47780 [02:24<00:11, 325.75 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44024/47780 [02:24<00:15, 246.14 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41961/47780 [02:24<00:16, 359.27 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43906/47780 [02:24<00:12, 317.48 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42050/47780 [02:24<00:19, 296.64 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33867/47780 [02:24<00:39, 351.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43930/47780 [02:24<00:09, 410.08 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42335/47780 [02:24<00:21, 257.87 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44115/47780 [02:24<00:11, 310.70 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43941/47780 [02:24<00:11, 323.24 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41998/47780 [02:24<00:16, 346.52 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33905/47780 [02:24<00:38, 356.05 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44050/47780 [02:24<00:15, 233.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43977/47780 [02:24<00:09, 417.32 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42080/47780 [02:24<00:21, 260.16 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42367/47780 [02:24<00:19, 273.03 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44147/47780 [02:24<00:12, 294.88 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43974/47780 [02:24<00:11, 321.23 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42047/47780 [02:24<00:14, 386.72 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44082/47780 [02:24<00:14, 254.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44022/47780 [02:24<00:09, 417.24 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33944/47780 [02:24<00:42, 328.04 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42107/47780 [02:24<00:21, 259.55 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42395/47780 [02:24<00:20, 267.54 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44007/47780 [02:24<00:12, 309.97 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44108/47780 [02:24<00:14, 252.99 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42087/47780 [02:24<00:15, 365.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44177/47780 [02:24<00:13, 272.16 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44065/47780 [02:24<00:09, 411.53 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42134/47780 [02:24<00:21, 257.89 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42425/47780 [02:24<00:19, 274.20 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 33978/47780 [02:24<00:44, 309.43 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44136/47780 [02:24<00:14, 260.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44041/47780 [02:24<00:11, 314.86 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44205/47780 [02:24<00:13, 258.30 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44109/47780 [02:24<00:08, 410.02 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42125/47780 [02:24<00:16, 339.49 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42165/47780 [02:24<00:20, 271.33 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████   | 34015/47780 [02:24<00:42, 321.88 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42454/47780 [02:24<00:20, 257.27 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44073/47780 [02:24<00:11, 313.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44166/47780 [02:24<00:13, 265.83 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44151/47780 [02:24<00:08, 408.49 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42163/47780 [02:24<00:16, 346.52 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44232/47780 [02:24<00:14, 250.58 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42203/47780 [02:24<00:18, 298.33 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34051/47780 [02:24<00:41, 328.50 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42494/47780 [02:24<00:17, 294.08 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44109/47780 [02:24<00:11, 321.67 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44200/47780 [02:24<00:13, 271.57 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44193/47780 [02:24<00:08, 407.18 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42234/47780 [02:24<00:18, 295.00 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42199/47780 [02:24<00:17, 328.20 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34085/47780 [02:24<00:43, 317.53 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42533/47780 [02:24<00:16, 317.43 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44144/47780 [02:24<00:11, 323.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44258/47780 [02:24<00:16, 209.14 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44240/47780 [02:24<00:12, 294.09 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42269/47780 [02:24<00:17, 307.11 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44234/47780 [02:24<00:09, 369.39 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42233/47780 [02:24<00:17, 311.65 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34118/47780 [02:24<00:44, 310.50 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42566/47780 [02:24<00:16, 313.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44303/47780 [02:24<00:13, 266.32 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44274/47780 [02:24<00:11, 306.69 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42307/47780 [02:24<00:16, 327.79 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44178/47780 [02:25<00:12, 284.89 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42272/47780 [02:24<00:16, 325.66 examples/s]
Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34152/47780 [02:24<00:43, 312.23 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42598/47780 [02:24<00:16, 308.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44272/47780 [02:25<00:10, 336.24 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44336/47780 [02:25<00:12, 273.64 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44309/47780 [02:25<00:11, 315.37 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44208/47780 [02:25<00:12, 283.47 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42341/47780 [02:25<00:17, 318.42 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42305/47780 [02:25<00:16, 324.68 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34184/47780 [02:25<00:44, 307.55 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42630/47780 [02:25<00:17, 301.52 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44309/47780 [02:25<00:10, 337.47 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44373/47780 [02:25<00:11, 296.24 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44343/47780 [02:25<00:10, 322.23 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42375/47780 [02:25<00:16, 321.67 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34228/47780 [02:25<00:39, 340.80 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44348/47780 [02:25<00:09, 351.03 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44237/47780 [02:25<00:14, 245.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42661/47780 [02:25<00:17, 292.48 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44407/47780 [02:25<00:10, 307.94 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42338/47780 [02:25<00:18, 288.30 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44376/47780 [02:25<00:11, 306.31 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42412/47780 [02:25<00:16, 331.19 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34266/47780 [02:25<00:38, 347.91 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44384/47780 [02:25<00:10, 335.73 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42691/47780 [02:25<00:17, 283.53 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42369/47780 [02:25<00:18, 289.45 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44443/47780 [02:25<00:10, 312.01 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44263/47780 [02:25<00:15, 232.82 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44407/47780 [02:25<00:10, 306.82 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42448/47780 [02:25<00:15, 337.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34302/47780 [02:25<00:39, 343.51 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44419/47780 [02:25<00:10, 329.64 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42415/47780 [02:25<00:16, 331.50 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42720/47780 [02:25<00:18, 276.01 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44477/47780 [02:25<00:10, 309.16 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44439/47780 [02:25<00:10, 304.78 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44290/47780 [02:25<00:14, 233.03 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34338/47780 [02:25<00:39, 343.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42482/47780 [02:25<00:18, 290.99 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42452/47780 [02:25<00:15, 338.21 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42752/47780 [02:25<00:17, 285.25 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44472/47780 [02:25<00:10, 308.43 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44316/47780 [02:25<00:14, 238.62 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44453/47780 [02:25<00:10, 308.36 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44515/47780 [02:25<00:10, 315.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42522/47780 [02:25<00:16, 319.61 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34373/47780 [02:25<00:41, 320.21 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42495/47780 [02:25<00:14, 363.66 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42781/47780 [02:25<00:17, 282.56 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44507/47780 [02:25<00:10, 320.23 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44346/47780 [02:25<00:13, 253.70 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44486/47780 [02:25<00:10, 311.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44548/47780 [02:25<00:10, 308.75 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34406/47780 [02:25<00:43, 309.34 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42827/47780 [02:25<00:15, 330.03 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42556/47780 [02:25<00:17, 296.03 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42544/47780 [02:25<00:13, 374.38 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44372/47780 [02:25<00:13, 252.25 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44541/47780 [02:25<00:10, 314.65 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44518/47780 [02:25<00:10, 303.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44580/47780 [02:25<00:10, 297.03 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42863/47780 [02:25<00:14, 334.86 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34438/47780 [02:25<00:44, 302.44 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42582/47780 [02:25<00:13, 375.83 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44399/47780 [02:25<00:13, 251.79 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44577/47780 [02:25<00:10, 317.27 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42587/47780 [02:25<00:18, 276.50 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44611/47780 [02:25<00:10, 299.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44549/47780 [02:25<00:11, 269.71 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42900/47780 [02:25<00:14, 336.29 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34483/47780 [02:25<00:39, 339.22 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44425/47780 [02:26<00:13, 251.22 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42620/47780 [02:26<00:14, 352.97 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42616/47780 [02:26<00:18, 279.77 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44643/47780 [02:26<00:10, 302.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44608/47780 [02:26<00:09, 348.37 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44611/47780 [02:26<00:12, 263.94 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42940/47780 [02:26<00:13, 350.92 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34518/47780 [02:26<00:39, 334.70 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44459/47780 [02:26<00:12, 276.30 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42656/47780 [02:26<00:15, 336.03 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44674/47780 [02:26<00:11, 281.26 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42645/47780 [02:26<00:20, 252.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44645/47780 [02:26<00:09, 346.51 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34552/47780 [02:26<00:40, 328.84 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42976/47780 [02:26<00:14, 338.34 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44487/47780 [02:26<00:12, 265.62 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42700/47780 [02:26<00:14, 349.39 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44639/47780 [02:26<00:13, 228.97 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44709/47780 [02:26<00:10, 290.65 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42674/47780 [02:26<00:19, 259.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44682/47780 [02:26<00:08, 348.73 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34586/47780 [02:26<00:39, 331.11 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43010/47780 [02:26<00:14, 330.83 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44527/47780 [02:26<00:10, 300.12 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44699/47780 [02:26<00:09, 310.03 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42736/47780 [02:26<00:14, 341.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42705/47780 [02:26<00:18, 269.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44739/47780 [02:26<00:10, 283.28 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44718/47780 [02:26<00:09, 333.73 examples/s]
Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34624/47780 [02:26<00:38, 338.29 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43044/47780 [02:26<00:14, 330.12 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44558/47780 [02:26<00:11, 292.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42772/47780 [02:26<00:14, 342.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42733/47780 [02:26<00:19, 264.51 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44773/47780 [02:26<00:10, 293.07 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44733/47780 [02:26<00:10, 294.02 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44752/47780 [02:26<00:09, 332.09 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34666/47780 [02:26<00:37, 353.44 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43078/47780 [02:26<00:14, 322.07 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44589/47780 [02:26<00:11, 284.92 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42811/47780 [02:26<00:14, 351.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42766/47780 [02:26<00:17, 282.38 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44809/47780 [02:26<00:09, 306.68 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44790/47780 [02:26<00:08, 337.98 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44765/47780 [02:26<00:10, 283.58 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34702/47780 [02:26<00:39, 328.89 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43112/47780 [02:26<00:15, 304.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44618/47780 [02:26<00:11, 276.72 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42803/47780 [02:26<00:16, 297.03 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44828/47780 [02:26<00:08, 349.68 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44845/47780 [02:26<00:09, 312.75 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42847/47780 [02:26<00:15, 317.81 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44795/47780 [02:26<00:10, 271.51 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34737/47780 [02:26<00:39, 331.41 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43146/47780 [02:26<00:14, 313.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44646/47780 [02:26<00:11, 269.11 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42834/47780 [02:26<00:16, 297.40 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44878/47780 [02:26<00:09, 303.96 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44871/47780 [02:26<00:08, 352.05 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42887/47780 [02:26<00:14, 329.68 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44824/47780 [02:26<00:11, 262.96 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34771/47780 [02:26<00:39, 326.36 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43178/47780 [02:26<00:14, 307.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44677/47780 [02:26<00:11, 277.37 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42868/47780 [02:26<00:16, 305.76 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42921/47780 [02:26<00:14, 325.36 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44907/47780 [02:26<00:08, 342.49 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44909/47780 [02:26<00:10, 275.06 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34812/47780 [02:26<00:37, 346.02 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44855/47780 [02:26<00:10, 266.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44711/47780 [02:27<00:10, 291.65 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43209/47780 [02:26<00:16, 280.04 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42899/47780 [02:27<00:17, 279.59 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42954/47780 [02:27<00:15, 316.31 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44942/47780 [02:27<00:08, 330.23 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34847/47780 [02:27<00:38, 339.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44949/47780 [02:27<00:09, 289.69 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44883/47780 [02:27<00:11, 243.77 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44741/47780 [02:27<00:11, 266.78 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43239/47780 [02:27<00:17, 262.62 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42989/47780 [02:27<00:14, 323.00 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42928/47780 [02:27<00:18, 262.65 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34882/47780 [02:27<00:38, 334.90 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44981/47780 [02:27<00:09, 291.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44977/47780 [02:27<00:09, 302.31 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44783/47780 [02:27<00:09, 304.78 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44908/47780 [02:27<00:12, 236.79 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43267/47780 [02:27<00:17, 264.77 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43026/47780 [02:27<00:14, 327.78 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42957/47780 [02:27<00:18, 265.80 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34918/47780 [02:27<00:38, 338.17 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45011/47780 [02:27<00:09, 292.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45009/47780 [02:27<00:09, 300.98 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44933/47780 [02:27<00:12, 228.38 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43299/47780 [02:27<00:16, 270.49 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44815/47780 [02:27<00:10, 283.93 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43059/47780 [02:27<00:14, 322.38 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45044/47780 [02:27<00:08, 314.04 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34953/47780 [02:27<00:38, 330.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42984/47780 [02:27<00:19, 242.86 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45041/47780 [02:27<00:10, 273.76 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44962/47780 [02:27<00:11, 244.18 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44856/47780 [02:27<00:09, 314.12 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43336/47780 [02:27<00:15, 291.34 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43095/47780 [02:27<00:14, 320.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34995/47780 [02:27<00:36, 353.50 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45078/47780 [02:27<00:08, 304.62 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43009/47780 [02:27<00:20, 235.28 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45072/47780 [02:27<00:09, 275.47 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44991/47780 [02:27<00:11, 248.65 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44890/47780 [02:27<00:09, 317.22 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43132/47780 [02:27<00:13, 334.41 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43366/47780 [02:27<00:15, 281.31 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45117/47780 [02:27<00:08, 327.10 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43035/47780 [02:27<00:19, 239.23 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35031/47780 [02:27<00:38, 334.27 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45106/47780 [02:27<00:09, 292.87 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43173/47780 [02:27<00:12, 355.76 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45017/47780 [02:27<00:11, 241.25 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44923/47780 [02:27<00:09, 304.21 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43399/47780 [02:27<00:15, 285.32 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43060/47780 [02:27<00:19, 241.37 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45139/47780 [02:27<00:08, 300.07 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35066/47780 [02:27<00:38, 331.22 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45151/47780 [02:27<00:08, 292.20 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43209/47780 [02:27<00:12, 352.67 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45043/47780 [02:27<00:11, 238.54 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44958/47780 [02:27<00:09, 309.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43434/47780 [02:27<00:14, 299.86 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43088/47780 [02:27<00:18, 250.27 examples/s]
Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35102/47780 [02:27<00:37, 334.94 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45170/47780 [02:27<00:08, 296.11 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43248/47780 [02:27<00:12, 360.17 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43475/47780 [02:27<00:13, 330.61 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45183/47780 [02:27<00:09, 276.36 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44996/47780 [02:27<00:08, 322.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45067/47780 [02:27<00:11, 226.60 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43117/47780 [02:27<00:18, 258.66 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45201/47780 [02:27<00:08, 293.43 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35136/47780 [02:27<00:39, 318.50 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43285/47780 [02:27<00:12, 358.57 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45234/47780 [02:28<00:07, 332.64 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43509/47780 [02:27<00:13, 322.24 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45100/47780 [02:28<00:10, 251.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45029/47780 [02:28<00:08, 313.46 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43147/47780 [02:28<00:17, 261.24 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35173/47780 [02:28<00:38, 329.51 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45231/47780 [02:28<00:09, 279.55 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45269/47780 [02:28<00:07, 333.49 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43545/47780 [02:28<00:12, 329.21 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43321/47780 [02:28<00:13, 335.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45068/47780 [02:28<00:08, 327.86 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43176/47780 [02:28<00:17, 263.69 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45266/47780 [02:28<00:08, 298.99 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35207/47780 [02:28<00:38, 325.16 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45126/47780 [02:28<00:12, 211.67 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45304/47780 [02:28<00:07, 334.62 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43357/47780 [02:28<00:13, 338.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43581/47780 [02:28<00:12, 333.96 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45101/47780 [02:28<00:08, 320.20 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43209/47780 [02:28<00:16, 273.09 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35244/47780 [02:28<00:37, 337.73 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45302/47780 [02:28<00:07, 311.81 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45161/47780 [02:28<00:10, 241.39 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45343/47780 [02:28<00:07, 346.18 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43392/47780 [02:28<00:12, 341.95 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45136/47780 [02:28<00:08, 322.43 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43615/47780 [02:28<00:13, 304.38 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35279/47780 [02:28<00:37, 337.09 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43237/47780 [02:28<00:17, 266.49 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45334/47780 [02:28<00:08, 298.00 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45187/47780 [02:28<00:11, 231.90 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43428/47780 [02:28<00:12, 343.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45379/47780 [02:28<00:07, 331.37 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45177/47780 [02:28<00:07, 343.34 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43659/47780 [02:28<00:12, 337.70 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43264/47780 [02:28<00:17, 263.87 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35313/47780 [02:28<00:38, 323.55 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45365/47780 [02:28<00:08, 298.02 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43463/47780 [02:28<00:12, 342.92 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45424/47780 [02:28<00:06, 364.00 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45220/47780 [02:28<00:10, 237.52 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45215/47780 [02:28<00:07, 340.19 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43694/47780 [02:28<00:12, 330.11 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35346/47780 [02:28<00:38, 321.40 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45395/47780 [02:28<00:08, 292.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43291/47780 [02:28<00:19, 231.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45462/47780 [02:28<00:06, 360.55 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45248/47780 [02:28<00:10, 247.97 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45256/47780 [02:28<00:07, 357.86 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43499/47780 [02:28<00:14, 303.97 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43728/47780 [02:28<00:12, 325.45 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35384/47780 [02:28<00:37, 334.68 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45425/47780 [02:28<00:08, 281.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43317/47780 [02:28<00:18, 236.66 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45499/47780 [02:28<00:06, 355.19 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45295/47780 [02:28<00:06, 362.93 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43531/47780 [02:28<00:14, 301.30 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43761/47780 [02:28<00:12, 311.93 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45274/47780 [02:28<00:11, 225.67 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35418/47780 [02:28<00:37, 328.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45462/47780 [02:28<00:07, 302.79 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45540/47780 [02:28<00:06, 366.51 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43342/47780 [02:28<00:19, 227.93 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45337/47780 [02:28<00:06, 373.90 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43563/47780 [02:28<00:13, 303.00 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35454/47780 [02:28<00:36, 337.58 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45298/47780 [02:28<00:11, 217.78 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43793/47780 [02:28<00:13, 295.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45495/47780 [02:28<00:07, 309.80 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45580/47780 [02:28<00:06, 363.05 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43375/47780 [02:28<00:18, 242.23 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45383/47780 [02:29<00:06, 382.12 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43600/47780 [02:28<00:13, 318.54 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45321/47780 [02:29<00:11, 216.29 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45527/47780 [02:29<00:07, 309.85 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35488/47780 [02:28<00:38, 316.34 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43823/47780 [02:29<00:14, 267.80 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45619/47780 [02:29<00:05, 369.28 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45423/47780 [02:29<00:06, 374.89 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43634/47780 [02:29<00:13, 313.80 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43403/47780 [02:29<00:18, 234.93 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45346/47780 [02:29<00:10, 224.38 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35536/47780 [02:29<00:33, 362.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45559/47780 [02:29<00:07, 298.64 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43851/47780 [02:29<00:15, 259.89 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45657/47780 [02:29<00:05, 362.32 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43669/47780 [02:29<00:12, 323.84 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43431/47780 [02:29<00:18, 241.56 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45372/47780 [02:29<00:10, 232.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45461/47780 [02:29<00:06, 333.77 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45590/47780 [02:29<00:07, 280.07 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43878/47780 [02:29<00:15, 257.12 examples/s]
Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35573/47780 [02:29<00:38, 317.31 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43458/47780 [02:29<00:17, 249.17 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43702/47780 [02:29<00:13, 305.08 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45694/47780 [02:29<00:06, 321.24 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45396/47780 [02:29<00:10, 227.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45497/47780 [02:29<00:06, 334.53 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35627/47780 [02:29<00:32, 375.52 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43911/47780 [02:29<00:14, 274.08 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45619/47780 [02:29<00:07, 274.62 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43492/47780 [02:29<00:15, 271.39 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43736/47780 [02:29<00:12, 314.67 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45741/47780 [02:29<00:05, 355.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45427/47780 [02:29<00:09, 244.68 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45531/47780 [02:29<00:07, 316.56 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43949/47780 [02:29<00:12, 303.09 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45647/47780 [02:29<00:08, 260.85 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43530/47780 [02:29<00:14, 298.52 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35667/47780 [02:29<00:35, 341.41 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43775/47780 [02:29<00:12, 332.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45778/47780 [02:29<00:05, 340.57 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45565/47780 [02:29<00:06, 318.47 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45452/47780 [02:29<00:10, 223.59 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43982/47780 [02:29<00:12, 297.33 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45682/47780 [02:29<00:07, 284.75 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35706/47780 [02:29<00:34, 353.80 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43562/47780 [02:29<00:14, 294.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45823/47780 [02:29<00:05, 359.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43811/47780 [02:29<00:13, 305.30 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45598/47780 [02:29<00:07, 308.09 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44018/47780 [02:29<00:12, 311.30 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45476/47780 [02:29<00:10, 216.08 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45711/47780 [02:29<00:07, 271.48 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43592/47780 [02:29<00:14, 295.68 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35743/47780 [02:29<00:35, 343.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45860/47780 [02:29<00:05, 358.06 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43847/47780 [02:29<00:12, 309.68 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45632/47780 [02:29<00:06, 313.34 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44051/47780 [02:29<00:12, 309.71 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45498/47780 [02:29<00:10, 213.02 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45744/47780 [02:29<00:07, 286.89 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43622/47780 [02:29<00:14, 284.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35779/47780 [02:29<00:35, 336.87 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45897/47780 [02:29<00:05, 346.02 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45665/47780 [02:29<00:06, 304.72 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43880/47780 [02:29<00:13, 293.08 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44086/47780 [02:29<00:11, 313.95 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45520/47780 [02:29<00:10, 208.11 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45776/47780 [02:29<00:07, 273.97 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43651/47780 [02:29<00:14, 281.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35815/47780 [02:29<00:35, 339.70 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45935/47780 [02:29<00:05, 351.58 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45696/47780 [02:30<00:06, 302.58 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43910/47780 [02:30<00:13, 288.48 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44125/47780 [02:30<00:10, 335.42 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45542/47780 [02:30<00:11, 196.42 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45805/47780 [02:30<00:07, 264.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43681/47780 [02:30<00:14, 274.35 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45973/47780 [02:30<00:05, 359.43 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35850/47780 [02:30<00:39, 302.32 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45735/47780 [02:30<00:06, 326.84 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44159/47780 [02:30<00:10, 335.57 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43940/47780 [02:30<00:13, 280.02 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45564/47780 [02:30<00:11, 200.54 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43709/47780 [02:30<00:15, 271.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45835/47780 [02:30<00:07, 271.35 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46011/47780 [02:30<00:05, 341.82 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45769/47780 [02:30<00:06, 323.12 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44193/47780 [02:30<00:10, 329.28 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35882/47780 [02:30<00:41, 288.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43970/47780 [02:30<00:14, 270.49 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45586/47780 [02:30<00:11, 187.37 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43737/47780 [02:30<00:15, 261.58 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45863/47780 [02:30<00:07, 254.33 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45802/47780 [02:30<00:06, 321.71 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35962/47780 [02:30<00:28, 413.74 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44240/47780 [02:30<00:09, 358.68 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46048/47780 [02:30<00:05, 320.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43998/47780 [02:30<00:14, 256.80 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43764/47780 [02:30<00:16, 247.60 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45606/47780 [02:30<00:12, 175.92 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45889/47780 [02:30<00:07, 242.83 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44283/47780 [02:30<00:09, 378.81 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45836/47780 [02:30<00:06, 302.24 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46082/47780 [02:30<00:05, 306.82 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36006/47780 [02:30<00:30, 383.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44032/47780 [02:30<00:13, 275.87 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45630/47780 [02:30<00:11, 192.36 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43789/47780 [02:30<00:16, 237.99 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45918/47780 [02:30<00:07, 250.05 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44329/47780 [02:30<00:08, 393.47 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46121/47780 [02:30<00:05, 321.93 examples/s]
Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36055/47780 [02:30<00:28, 406.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44065/47780 [02:30<00:13, 284.56 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45867/47780 [02:30<00:07, 269.21 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45652/47780 [02:30<00:10, 197.78 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43824/47780 [02:30<00:14, 265.45 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45944/47780 [02:30<00:07, 242.19 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44373/47780 [02:30<00:09, 376.51 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46156/47780 [02:30<00:04, 326.06 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36098/47780 [02:30<00:29, 395.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44103/47780 [02:30<00:12, 304.02 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45906/47780 [02:30<00:06, 294.90 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45673/47780 [02:30<00:10, 198.91 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43854/47780 [02:30<00:14, 273.16 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45969/47780 [02:30<00:07, 229.35 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44415/47780 [02:30<00:08, 381.37 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46189/47780 [02:30<00:05, 312.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44135/47780 [02:30<00:12, 301.76 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45939/47780 [02:30<00:06, 297.37 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36139/47780 [02:30<00:31, 367.79 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43892/47780 [02:30<00:12, 300.70 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45694/47780 [02:30<00:10, 191.84 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45994/47780 [02:30<00:07, 227.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44454/47780 [02:30<00:08, 372.87 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44168/47780 [02:30<00:11, 306.36 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36178/47780 [02:30<00:31, 365.96 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46222/47780 [02:30<00:05, 285.21 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45970/47780 [02:30<00:06, 285.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45715/47780 [02:30<00:10, 196.35 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43934/47780 [02:30<00:11, 328.61 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44493/47780 [02:30<00:08, 375.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46022/47780 [02:31<00:07, 236.71 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44199/47780 [02:31<00:12, 297.19 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46004/47780 [02:31<00:05, 299.90 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36217/47780 [02:31<00:31, 364.85 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43975/47780 [02:31<00:10, 351.67 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45737/47780 [02:31<00:10, 200.63 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46058/47780 [02:31<00:06, 269.44 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46252/47780 [02:31<00:06, 240.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44531/47780 [02:31<00:09, 355.91 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44233/47780 [02:31<00:11, 302.50 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46035/47780 [02:31<00:05, 291.89 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45759/47780 [02:31<00:09, 204.51 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36255/47780 [02:31<00:34, 335.77 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44011/47780 [02:31<00:11, 325.18 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44568/47780 [02:31<00:08, 359.60 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46086/47780 [02:31<00:06, 258.49 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44266/47780 [02:31<00:11, 309.87 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46279/47780 [02:31<00:06, 234.34 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46066/47780 [02:31<00:05, 294.72 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45780/47780 [02:31<00:10, 193.94 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36293/47780 [02:31<00:33, 344.10 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44045/47780 [02:31<00:11, 327.98 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44607/47780 [02:31<00:08, 364.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46115/47780 [02:31<00:06, 261.82 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44302/47780 [02:31<00:11, 313.80 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46304/47780 [02:31<00:06, 224.82 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46101/47780 [02:31<00:05, 300.15 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45804/47780 [02:31<00:09, 204.97 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44079/47780 [02:31<00:11, 317.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36328/47780 [02:31<00:36, 315.04 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44658/47780 [02:31<00:07, 395.76 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44337/47780 [02:31<00:10, 320.55 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46142/47780 [02:31<00:06, 249.30 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46328/47780 [02:31<00:06, 217.80 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45826/47780 [02:31<00:09, 209.13 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46132/47780 [02:31<00:05, 278.11 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44112/47780 [02:31<00:12, 304.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36366/47780 [02:31<00:34, 331.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44704/47780 [02:31<00:07, 410.40 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44370/47780 [02:31<00:10, 313.26 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46168/47780 [02:31<00:06, 234.89 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46351/47780 [02:31<00:06, 218.49 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46161/47780 [02:31<00:05, 270.65 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44143/47780 [02:31<00:12, 302.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45848/47780 [02:31<00:10, 186.48 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36400/47780 [02:31<00:35, 316.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44750/47780 [02:31<00:07, 415.26 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44406/47780 [02:31<00:10, 322.41 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46193/47780 [02:31<00:06, 236.34 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46379/47780 [02:31<00:06, 230.00 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44180/47780 [02:31<00:11, 320.99 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46189/47780 [02:31<00:06, 255.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44797/47780 [02:31<00:06, 426.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36436/47780 [02:31<00:34, 325.16 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45868/47780 [02:31<00:11, 173.52 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46221/47780 [02:31<00:06, 243.75 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44439/47780 [02:31<00:11, 299.74 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46403/47780 [02:31<00:06, 216.43 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44215/47780 [02:31<00:10, 329.14 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36471/47780 [02:31<00:34, 328.52 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46216/47780 [02:31<00:06, 253.78 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44840/47780 [02:31<00:07, 396.66 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45886/47780 [02:31<00:11, 169.93 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44476/47780 [02:31<00:10, 312.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46247/47780 [02:31<00:06, 220.96 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44249/47780 [02:31<00:11, 307.62 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36505/47780 [02:31<00:35, 317.35 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46425/47780 [02:31<00:06, 193.58 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46243/47780 [02:32<00:06, 243.02 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44881/47780 [02:31<00:07, 394.12 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45908/47780 [02:31<00:10, 181.16 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44508/47780 [02:31<00:10, 311.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46272/47780 [02:32<00:06, 228.46 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44284/47780 [02:32<00:11, 315.79 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46446/47780 [02:32<00:06, 197.09 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46271/47780 [02:32<00:06, 247.45 examples/s]
Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36538/47780 [02:32<00:36, 307.24 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45927/47780 [02:32<00:10, 174.16 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44540/47780 [02:32<00:10, 310.30 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44921/47780 [02:32<00:08, 337.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46296/47780 [02:32<00:06, 222.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44318/47780 [02:32<00:10, 319.25 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46468/47780 [02:32<00:06, 198.31 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36570/47780 [02:32<00:36, 306.81 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46307/47780 [02:32<00:05, 267.68 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44573/47780 [02:32<00:10, 314.22 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45947/47780 [02:32<00:10, 175.47 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44958/47780 [02:32<00:08, 344.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46322/47780 [02:32<00:06, 227.28 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44352/47780 [02:32<00:10, 315.75 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36609/47780 [02:32<00:34, 327.04 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46489/47780 [02:32<00:06, 195.48 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46345/47780 [02:32<00:04, 289.04 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44605/47780 [02:32<00:10, 310.30 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46346/47780 [02:32<00:06, 225.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45965/47780 [02:32<00:11, 157.84 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44994/47780 [02:32<00:08, 321.12 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44385/47780 [02:32<00:10, 318.25 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36646/47780 [02:32<00:33, 331.70 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46509/47780 [02:32<00:06, 192.81 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46375/47780 [02:32<00:04, 289.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44637/47780 [02:32<00:10, 298.60 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45030/47780 [02:32<00:08, 327.90 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45982/47780 [02:32<00:11, 153.00 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46369/47780 [02:32<00:06, 208.27 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36680/47780 [02:32<00:33, 330.42 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44417/47780 [02:32<00:11, 292.00 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46533/47780 [02:32<00:06, 201.30 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46409/47780 [02:32<00:04, 301.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44676/47780 [02:32<00:09, 321.52 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46000/47780 [02:32<00:11, 158.81 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45064/47780 [02:32<00:08, 315.81 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36731/47780 [02:32<00:28, 381.75 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44450/47780 [02:32<00:11, 301.91 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46555/47780 [02:32<00:06, 202.10 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46391/47780 [02:32<00:07, 196.90 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46440/47780 [02:32<00:04, 292.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44712/47780 [02:32<00:09, 328.87 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46023/47780 [02:32<00:10, 170.24 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36786/47780 [02:32<00:25, 425.53 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45097/47780 [02:32<00:08, 310.93 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44483/47780 [02:32<00:10, 303.38 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46576/47780 [02:32<00:05, 202.75 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46411/47780 [02:32<00:07, 193.17 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46470/47780 [02:32<00:04, 283.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44746/47780 [02:32<00:09, 328.03 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45133/47780 [02:32<00:08, 321.09 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36830/47780 [02:32<00:25, 424.74 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46045/47780 [02:32<00:09, 179.58 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44515/47780 [02:32<00:11, 291.82 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46598/47780 [02:32<00:05, 198.93 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46442/47780 [02:32<00:06, 215.98 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44780/47780 [02:32<00:09, 323.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46506/47780 [02:32<00:04, 283.46 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45169/47780 [02:32<00:08, 324.58 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46068/47780 [02:32<00:09, 187.33 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36873/47780 [02:32<00:27, 393.55 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46618/47780 [02:32<00:05, 195.84 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44545/47780 [02:32<00:11, 284.26 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46464/47780 [02:32<00:06, 215.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44818/47780 [02:32<00:08, 332.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46535/47780 [02:33<00:04, 271.23 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46090/47780 [02:33<00:08, 196.14 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45203/47780 [02:33<00:08, 314.83 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36914/47780 [02:33<00:27, 394.56 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44578/47780 [02:33<00:10, 293.98 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46638/47780 [02:33<00:06, 185.91 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44852/47780 [02:33<00:09, 323.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46487/47780 [02:33<00:06, 198.40 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46565/47780 [02:33<00:04, 268.34 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46111/47780 [02:33<00:08, 193.74 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45246/47780 [02:33<00:07, 340.63 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36963/47780 [02:33<00:25, 419.42 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44620/47780 [02:33<00:09, 329.32 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46657/47780 [02:33<00:06, 185.61 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44891/47780 [02:33<00:08, 341.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46509/47780 [02:33<00:06, 203.50 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46593/47780 [02:33<00:04, 255.11 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46131/47780 [02:33<00:08, 189.14 examples/s]
Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37010/47780 [02:33<00:25, 426.24 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44655/47780 [02:33<00:09, 335.24 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46679/47780 [02:33<00:05, 193.34 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45281/47780 [02:33<00:08, 304.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44926/47780 [02:33<00:08, 329.54 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46533/47780 [02:33<00:06, 205.44 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46619/47780 [02:33<00:04, 251.02 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37056/47780 [02:33<00:24, 435.75 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44696/47780 [02:33<00:08, 348.83 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46153/47780 [02:33<00:08, 190.76 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46700/47780 [02:33<00:05, 197.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45321/47780 [02:33<00:07, 329.53 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46557/47780 [02:33<00:05, 214.69 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44961/47780 [02:33<00:08, 317.05 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46647/47780 [02:33<00:04, 246.52 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37103/47780 [02:33<00:24, 440.50 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44732/47780 [02:33<00:08, 344.47 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46179/47780 [02:33<00:07, 206.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46723/47780 [02:33<00:05, 203.66 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46579/47780 [02:33<00:05, 213.99 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45355/47780 [02:33<00:07, 313.69 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44996/47780 [02:33<00:08, 320.79 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37153/47780 [02:33<00:23, 452.66 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46672/47780 [02:33<00:04, 229.28 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46201/47780 [02:33<00:07, 200.84 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46744/47780 [02:33<00:05, 200.04 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44767/47780 [02:33<00:09, 326.73 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46601/47780 [02:33<00:05, 206.31 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45029/47780 [02:33<00:09, 301.90 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45388/47780 [02:33<00:08, 291.32 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37199/47780 [02:33<00:24, 434.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44803/47780 [02:33<00:09, 328.89 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46222/47780 [02:33<00:08, 188.75 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46765/47780 [02:33<00:05, 185.86 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46696/47780 [02:33<00:05, 205.97 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46631/47780 [02:33<00:05, 224.85 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45421/47780 [02:33<00:07, 298.22 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45060/47780 [02:33<00:09, 283.64 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37252/47780 [02:33<00:22, 461.41 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44839/47780 [02:33<00:08, 337.62 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46244/47780 [02:33<00:08, 191.09 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46790/47780 [02:33<00:04, 201.03 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46657/47780 [02:33<00:04, 232.12 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45452/47780 [02:33<00:08, 288.52 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45096/47780 [02:33<00:08, 302.79 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46719/47780 [02:33<00:05, 190.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37300/47780 [02:33<00:22, 461.90 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44891/47780 [02:33<00:07, 363.87 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46266/47780 [02:33<00:07, 197.11 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46811/47780 [02:33<00:04, 197.02 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46682/47780 [02:34<00:05, 215.33 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37351/47780 [02:33<00:21, 475.73 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45127/47780 [02:33<00:09, 292.05 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45482/47780 [02:33<00:08, 274.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46739/47780 [02:34<00:05, 182.81 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44932/47780 [02:34<00:07, 373.50 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46286/47780 [02:34<00:07, 194.53 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46831/47780 [02:34<00:04, 191.53 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37404/47780 [02:34<00:21, 488.44 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46704/47780 [02:34<00:05, 212.02 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45182/47780 [02:34<00:07, 358.44 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45510/47780 [02:34<00:08, 270.21 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46758/47780 [02:34<00:05, 180.90 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46315/47780 [02:34<00:06, 219.78 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44970/47780 [02:34<00:07, 359.20 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46851/47780 [02:34<00:05, 179.83 examples/s]
Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37466/47780 [02:34<00:19, 518.20 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46730/47780 [02:34<00:04, 222.39 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45219/47780 [02:34<00:07, 346.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45538/47780 [02:34<00:08, 251.17 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46777/47780 [02:34<00:05, 171.00 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45006/47780 [02:34<00:07, 347.46 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46338/47780 [02:34<00:07, 193.84 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37519/47780 [02:34<00:20, 512.63 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46754/47780 [02:34<00:04, 217.97 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45257/47780 [02:34<00:07, 351.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46873/47780 [02:34<00:05, 170.38 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45564/47780 [02:34<00:08, 247.21 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46795/47780 [02:34<00:05, 172.20 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45048/47780 [02:34<00:07, 366.30 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46359/47780 [02:34<00:07, 188.36 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46777/47780 [02:34<00:04, 216.40 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45297/47780 [02:34<00:06, 360.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37571/47780 [02:34<00:21, 467.77 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45595/47780 [02:34<00:08, 262.44 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46816/47780 [02:34<00:05, 175.19 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45097/47780 [02:34<00:06, 399.31 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46892/47780 [02:34<00:05, 159.03 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46382/47780 [02:34<00:07, 195.52 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45334/47780 [02:34<00:06, 352.28 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37647/47780 [02:34<00:18, 546.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46799/47780 [02:34<00:04, 204.72 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45140/47780 [02:34<00:06, 405.10 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45624/47780 [02:34<00:08, 255.90 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46835/47780 [02:34<00:05, 171.90 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46909/47780 [02:34<00:05, 156.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46403/47780 [02:34<00:07, 188.60 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37703/47780 [02:34<00:18, 534.65 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45370/47780 [02:34<00:07, 334.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46820/47780 [02:34<00:04, 195.03 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45656/47780 [02:34<00:07, 273.31 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45182/47780 [02:34<00:06, 405.03 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46854/47780 [02:34<00:05, 171.97 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46925/47780 [02:34<00:05, 154.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46425/47780 [02:34<00:06, 196.11 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37759/47780 [02:34<00:18, 535.02 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45684/47780 [02:34<00:07, 272.96 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45225/47780 [02:34<00:06, 409.70 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45404/47780 [02:34<00:07, 315.81 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46841/47780 [02:34<00:05, 187.12 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46875/47780 [02:34<00:04, 181.02 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46941/47780 [02:34<00:05, 151.33 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46446/47780 [02:34<00:06, 199.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37825/47780 [02:34<00:17, 567.86 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45718/47780 [02:34<00:07, 290.98 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46861/47780 [02:34<00:04, 188.43 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45444/47780 [02:34<00:07, 324.87 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46897/47780 [02:34<00:04, 189.61 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45270/47780 [02:34<00:06, 381.41 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46959/47780 [02:34<00:05, 155.42 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46467/47780 [02:34<00:06, 194.01 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37883/47780 [02:34<00:17, 552.38 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45753/47780 [02:34<00:06, 296.32 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46886/47780 [02:35<00:04, 203.20 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45478/47780 [02:34<00:07, 324.78 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46919/47780 [02:35<00:04, 196.79 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46982/47780 [02:34<00:04, 174.87 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45309/47780 [02:35<00:06, 353.68 examples/s]
Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37940/47780 [02:35<00:17, 557.31 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46908/47780 [02:35<00:04, 207.80 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46487/47780 [02:35<00:07, 178.60 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45783/47780 [02:35<00:06, 287.16 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45511/47780 [02:35<00:07, 324.11 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46941/47780 [02:35<00:04, 201.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47002/47780 [02:35<00:04, 178.88 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37999/47780 [02:35<00:17, 565.68 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45346/47780 [02:35<00:07, 315.93 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46932/47780 [02:35<00:03, 213.15 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45544/47780 [02:35<00:06, 322.11 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46507/47780 [02:35<00:07, 178.07 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45812/47780 [02:35<00:07, 278.43 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46962/47780 [02:35<00:04, 189.94 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47021/47780 [02:35<00:04, 170.72 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38056/47780 [02:35<00:17, 551.41 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45379/47780 [02:35<00:07, 306.39 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45840/47780 [02:35<00:07, 274.18 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46954/47780 [02:35<00:04, 205.48 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45578/47780 [02:35<00:07, 313.70 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46527/47780 [02:35<00:07, 176.24 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46983/47780 [02:35<00:04, 192.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47039/47780 [02:35<00:04, 166.48 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38114/47780 [02:35<00:17, 554.51 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45870/47780 [02:35<00:06, 278.62 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45614/47780 [02:35<00:06, 323.53 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46975/47780 [02:35<00:03, 202.24 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45411/47780 [02:35<00:08, 292.35 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47003/47780 [02:35<00:03, 194.63 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46552/47780 [02:35<00:06, 186.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47056/47780 [02:35<00:04, 162.37 examples/s]
Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38171/47780 [02:35<00:17, 541.90 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45648/47780 [02:35<00:06, 323.95 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46997/47780 [02:35<00:03, 206.17 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47027/47780 [02:35<00:03, 205.19 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45898/47780 [02:35<00:07, 262.16 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45441/47780 [02:35<00:08, 280.67 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46571/47780 [02:35<00:06, 182.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47078/47780 [02:35<00:03, 176.56 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38227/47780 [02:35<00:17, 543.57 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47018/47780 [02:35<00:03, 200.30 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45935/47780 [02:35<00:06, 288.87 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45681/47780 [02:35<00:06, 305.20 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45472/47780 [02:35<00:08, 280.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47048/47780 [02:35<00:03, 191.73 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46590/47780 [02:35<00:07, 167.27 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47099/47780 [02:35<00:03, 174.08 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38282/47780 [02:35<00:19, 498.22 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47040/47780 [02:35<00:03, 200.19 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45965/47780 [02:35<00:06, 279.62 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45501/47780 [02:35<00:08, 280.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45712/47780 [02:35<00:07, 290.61 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47118/47780 [02:35<00:03, 177.22 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46612/47780 [02:35<00:06, 168.59 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47069/47780 [02:35<00:04, 168.38 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38333/47780 [02:35<00:19, 487.14 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47061/47780 [02:35<00:03, 192.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45530/47780 [02:35<00:08, 275.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45996/47780 [02:35<00:06, 273.47 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45742/47780 [02:35<00:07, 279.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46630/47780 [02:35<00:06, 170.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47136/47780 [02:35<00:03, 163.75 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38384/47780 [02:35<00:19, 489.25 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47087/47780 [02:35<00:04, 164.76 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45558/47780 [02:35<00:08, 274.46 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47081/47780 [02:36<00:03, 190.32 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45777/47780 [02:35<00:06, 298.55 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46024/47780 [02:35<00:06, 261.26 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47159/47780 [02:36<00:03, 180.42 examples/s]
Tokenizing train dataset (num_proc=32):  80%|████████  | 38447/47780 [02:35<00:17, 527.24 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46648/47780 [02:36<00:06, 162.50 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47104/47780 [02:36<00:04, 153.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45586/47780 [02:36<00:08, 268.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45818/47780 [02:36<00:05, 328.52 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46051/47780 [02:36<00:06, 252.15 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38513/47780 [02:36<00:16, 560.62 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47101/47780 [02:36<00:04, 160.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47178/47780 [02:36<00:03, 170.53 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45619/47780 [02:36<00:07, 279.73 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45852/47780 [02:36<00:05, 325.63 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47121/47780 [02:36<00:04, 144.78 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46666/47780 [02:36<00:07, 144.72 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46077/47780 [02:36<00:06, 250.88 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38570/47780 [02:36<00:16, 562.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47119/47780 [02:36<00:04, 162.97 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45651/47780 [02:36<00:07, 284.59 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46685/47780 [02:36<00:07, 155.40 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47196/47780 [02:36<00:03, 151.95 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46103/47780 [02:36<00:06, 249.70 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45885/47780 [02:36<00:06, 297.70 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38633/47780 [02:36<00:15, 574.15 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47137/47780 [02:36<00:04, 134.41 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47136/47780 [02:36<00:03, 163.23 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45682/47780 [02:36<00:07, 285.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47213/47780 [02:36<00:03, 149.08 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46144/47780 [02:36<00:05, 286.40 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46702/47780 [02:36<00:07, 146.23 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45917/47780 [02:36<00:06, 289.02 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38705/47780 [02:36<00:14, 606.84 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47153/47780 [02:36<00:04, 137.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47154/47780 [02:36<00:04, 149.02 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45712/47780 [02:36<00:07, 289.22 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47229/47780 [02:36<00:03, 145.58 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46719/47780 [02:36<00:07, 150.82 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████  | 38770/47780 [02:36<00:14, 614.12 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45954/47780 [02:36<00:06, 302.74 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47174/47780 [02:36<00:03, 155.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46176/47780 [02:36<00:05, 273.36 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45741/47780 [02:36<00:07, 275.00 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47170/47780 [02:36<00:04, 134.15 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38833/47780 [02:36<00:14, 615.80 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45989/47780 [02:36<00:05, 312.43 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46735/47780 [02:36<00:07, 147.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47244/47780 [02:36<00:03, 137.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46204/47780 [02:36<00:06, 260.91 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45776/47780 [02:36<00:06, 295.32 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47192/47780 [02:36<00:04, 135.60 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46021/47780 [02:36<00:05, 312.69 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47185/47780 [02:36<00:04, 134.73 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47258/47780 [02:36<00:03, 137.82 examples/s]
Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38895/47780 [02:36<00:15, 590.88 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46752/47780 [02:36<00:07, 142.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46231/47780 [02:36<00:06, 257.44 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45806/47780 [02:36<00:06, 282.18 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47207/47780 [02:36<00:04, 131.02 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38962/47780 [02:36<00:14, 605.94 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47272/47780 [02:36<00:03, 135.82 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46054/47780 [02:36<00:05, 293.82 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46262/47780 [02:36<00:05, 270.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46770/47780 [02:36<00:06, 145.86 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47200/47780 [02:36<00:04, 123.49 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45840/47780 [02:36<00:06, 294.81 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47226/47780 [02:36<00:03, 145.34 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39024/47780 [02:36<00:14, 609.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47287/47780 [02:36<00:03, 134.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46291/47780 [02:36<00:05, 273.41 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46788/47780 [02:37<00:06, 150.20 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46084/47780 [02:37<00:06, 274.16 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47213/47780 [02:37<00:04, 118.61 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45876/47780 [02:37<00:06, 310.38 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47247/47780 [02:37<00:03, 155.68 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39086/47780 [02:37<00:14, 601.95 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47301/47780 [02:37<00:03, 134.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46320/47780 [02:37<00:05, 276.52 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46805/47780 [02:37<00:06, 152.32 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46116/47780 [02:37<00:05, 280.94 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47230/47780 [02:37<00:04, 128.05 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45911/47780 [02:37<00:05, 317.69 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39148/47780 [02:37<00:14, 603.31 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47266/47780 [02:37<00:03, 156.77 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46350/47780 [02:37<00:05, 269.90 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47315/47780 [02:37<00:03, 127.83 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46152/47780 [02:37<00:05, 301.19 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46821/47780 [02:37<00:06, 150.56 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47244/47780 [02:37<00:04, 130.91 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45943/47780 [02:37<00:05, 311.45 examples/s]
Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39211/47780 [02:37<00:14, 610.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47284/47780 [02:37<00:03, 158.56 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47330/47780 [02:37<00:03, 131.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46837/47780 [02:37<00:06, 150.48 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46184/47780 [02:37<00:05, 294.20 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46378/47780 [02:37<00:05, 255.00 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47258/47780 [02:37<00:04, 126.93 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45975/47780 [02:37<00:06, 298.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39273/47780 [02:37<00:14, 604.13 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47303/47780 [02:37<00:03, 149.93 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46222/47780 [02:37<00:04, 315.70 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46855/47780 [02:37<00:05, 155.74 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47344/47780 [02:37<00:03, 123.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47274/47780 [02:37<00:03, 132.14 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46404/47780 [02:37<00:05, 231.16 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46010/47780 [02:37<00:05, 307.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39334/47780 [02:37<00:14, 572.11 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46257/47780 [02:37<00:04, 318.51 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46875/47780 [02:37<00:05, 163.73 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47319/47780 [02:37<00:03, 145.85 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47288/47780 [02:37<00:03, 131.28 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46047/47780 [02:37<00:05, 321.72 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46428/47780 [02:37<00:06, 221.92 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47357/47780 [02:37<00:03, 109.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39396/47780 [02:37<00:14, 572.22 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46290/47780 [02:37<00:04, 319.25 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47334/47780 [02:37<00:03, 144.76 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46892/47780 [02:37<00:05, 157.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47305/47780 [02:37<00:03, 133.72 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46454/47780 [02:37<00:05, 226.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46082/47780 [02:37<00:05, 309.75 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39455/47780 [02:37<00:15, 552.94 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47371/47780 [02:37<00:03, 106.01 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46323/47780 [02:37<00:04, 312.00 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47349/47780 [02:37<00:03, 139.18 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46909/47780 [02:37<00:06, 144.42 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47319/47780 [02:37<00:03, 131.94 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46115/47780 [02:37<00:05, 312.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46477/47780 [02:37<00:05, 219.87 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39513/47780 [02:37<00:15, 545.02 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47382/47780 [02:37<00:03, 104.54 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46356/47780 [02:37<00:04, 288.78 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46924/47780 [02:37<00:05, 144.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47333/47780 [02:37<00:03, 130.59 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39571/47780 [02:37<00:14, 553.90 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47364/47780 [02:37<00:03, 122.52 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46500/47780 [02:37<00:06, 210.01 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47393/47780 [02:37<00:03, 104.13 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46147/47780 [02:37<00:05, 273.60 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46387/47780 [02:37<00:04, 286.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46940/47780 [02:38<00:05, 148.43 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39628/47780 [02:37<00:14, 554.26 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47352/47780 [02:38<00:03, 134.31 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46522/47780 [02:38<00:06, 205.04 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47407/47780 [02:38<00:03, 111.63 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46177/47780 [02:38<00:06, 265.08 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47378/47780 [02:38<00:03, 109.78 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46422/47780 [02:38<00:04, 291.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46955/47780 [02:38<00:05, 142.79 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39698/47780 [02:38<00:13, 594.40 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46549/47780 [02:38<00:05, 219.42 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47369/47780 [02:38<00:02, 140.40 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47419/47780 [02:38<00:03, 112.95 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46206/47780 [02:38<00:05, 268.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47392/47780 [02:38<00:03, 115.04 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46972/47780 [02:38<00:05, 149.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46452/47780 [02:38<00:04, 285.74 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39759/47780 [02:38<00:13, 590.89 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46574/47780 [02:38<00:05, 223.19 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47384/47780 [02:38<00:02, 136.20 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47432/47780 [02:38<00:03, 107.90 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46237/47780 [02:38<00:05, 270.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47404/47780 [02:38<00:03, 112.18 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46988/47780 [02:38<00:05, 143.24 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39820/47780 [02:38<00:13, 581.95 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46481/47780 [02:38<00:04, 265.23 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46599/47780 [02:38<00:05, 228.95 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47401/47780 [02:38<00:02, 144.52 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47448/47780 [02:38<00:02, 117.37 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46266/47780 [02:38<00:05, 266.39 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47416/47780 [02:38<00:03, 105.87 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47003/47780 [02:38<00:05, 143.38 examples/s]
Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39880/47780 [02:38<00:13, 566.41 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46628/47780 [02:38<00:04, 241.77 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46508/47780 [02:38<00:05, 241.39 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47465/47780 [02:38<00:02, 131.25 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46293/47780 [02:38<00:05, 266.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47417/47780 [02:38<00:02, 132.81 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39951/47780 [02:38<00:12, 606.88 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47023/47780 [02:38<00:05, 150.87 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47427/47780 [02:38<00:03, 97.46 examples/s] 
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46653/47780 [02:38<00:04, 231.04 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46534/47780 [02:38<00:05, 234.59 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47479/47780 [02:38<00:02, 132.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47439/47780 [02:38<00:02, 149.37 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46320/47780 [02:38<00:06, 234.67 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40021/47780 [02:38<00:12, 623.90 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47039/47780 [02:38<00:04, 152.35 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46686/47780 [02:38<00:04, 255.73 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46571/47780 [02:38<00:04, 245.21 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47460/47780 [02:38<00:02, 157.60 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47437/47780 [02:38<00:04, 81.79 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40090/47780 [02:38<00:12, 638.88 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46349/47780 [02:38<00:05, 242.86 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47055/47780 [02:38<00:04, 148.33 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46713/47780 [02:38<00:04, 251.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47494/47780 [02:38<00:02, 105.15 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46596/47780 [02:38<00:04, 246.14 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47476/47780 [02:38<00:01, 157.10 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40160/47780 [02:38<00:11, 653.33 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47446/47780 [02:38<00:04, 77.17 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47070/47780 [02:38<00:04, 142.04 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46374/47780 [02:38<00:06, 219.79 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46739/47780 [02:38<00:04, 245.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47509/47780 [02:38<00:02, 113.40 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46627/47780 [02:38<00:04, 259.38 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40242/47780 [02:38<00:10, 695.17 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47495/47780 [02:39<00:01, 158.49 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47086/47780 [02:39<00:04, 146.29 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46397/47780 [02:39<00:06, 218.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46764/47780 [02:39<00:04, 230.01 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46654/47780 [02:39<00:04, 259.97 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47456/47780 [02:39<00:04, 70.48 examples/s]
Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40312/47780 [02:39<00:11, 676.11 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47522/47780 [02:39<00:02, 101.28 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47105/47780 [02:39<00:04, 151.67 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47511/47780 [02:39<00:01, 139.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46431/47780 [02:39<00:05, 247.32 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46682/47780 [02:39<00:04, 264.41 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46790/47780 [02:39<00:04, 221.70 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40380/47780 [02:39<00:11, 670.20 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47121/47780 [02:39<00:04, 153.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47534/47780 [02:39<00:02, 98.54 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47464/47780 [02:39<00:05, 61.80 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47526/47780 [02:39<00:01, 131.21 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46457/47780 [02:39<00:05, 221.95 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46711/47780 [02:39<00:04, 259.32 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46813/47780 [02:39<00:04, 219.16 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40448/47780 [02:39<00:11, 655.87 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47138/47780 [02:39<00:04, 151.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47546/47780 [02:39<00:02, 98.20 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47540/47780 [02:39<00:01, 129.70 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46486/47780 [02:39<00:05, 239.11 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46840/47780 [02:39<00:04, 232.63 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46738/47780 [02:39<00:03, 261.00 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47473/47780 [02:39<00:04, 63.81 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40516/47780 [02:39<00:10, 662.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47154/47780 [02:39<00:04, 149.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47563/47780 [02:39<00:01, 111.60 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46511/47780 [02:39<00:05, 227.86 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46766/47780 [02:39<00:04, 251.90 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40587/47780 [02:39<00:10, 658.11 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47481/47780 [02:39<00:04, 64.14 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46864/47780 [02:39<00:04, 209.65 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47554/47780 [02:39<00:02, 110.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47169/47780 [02:39<00:04, 146.37 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46536/47780 [02:39<00:05, 231.47 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40653/47780 [02:39<00:11, 645.52 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47576/47780 [02:39<00:01, 103.00 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47492/47780 [02:39<00:03, 72.76 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46792/47780 [02:39<00:04, 239.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46886/47780 [02:39<00:04, 201.63 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47185/47780 [02:39<00:04, 145.28 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47567/47780 [02:39<00:01, 107.37 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40725/47780 [02:39<00:10, 661.14 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46560/47780 [02:39<00:05, 223.75 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46817/47780 [02:39<00:04, 240.24 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47502/47780 [02:39<00:03, 75.36 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46907/47780 [02:39<00:04, 203.47 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47588/47780 [02:39<00:01, 97.56 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47582/47780 [02:39<00:01, 115.97 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47201/47780 [02:39<00:04, 137.71 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46843/47780 [02:39<00:03, 245.17 examples/s]
Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40792/47780 [02:39<00:11, 626.30 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46588/47780 [02:39<00:05, 226.65 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47513/47780 [02:39<00:03, 82.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46928/47780 [02:39<00:04, 198.20 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47599/47780 [02:39<00:01, 94.27 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47596/47780 [02:39<00:01, 109.26 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40855/47780 [02:39<00:11, 597.35 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47215/47780 [02:39<00:04, 118.41 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46958/47780 [02:39<00:03, 221.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46868/47780 [02:39<00:04, 219.79 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46618/47780 [02:39<00:05, 224.01 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47522/47780 [02:40<00:03, 77.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47609/47780 [02:40<00:01, 90.60 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40925/47780 [02:40<00:11, 611.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47608/47780 [02:40<00:01, 103.12 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46642/47780 [02:40<00:05, 227.40 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47231/47780 [02:40<00:04, 124.28 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46982/47780 [02:40<00:03, 212.34 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46891/47780 [02:40<00:04, 206.14 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47530/47780 [02:40<00:03, 74.73 examples/s]
Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40987/47780 [02:40<00:11, 607.27 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47620/47780 [02:40<00:01, 82.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47620/47780 [02:40<00:01, 104.76 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47245/47780 [02:40<00:04, 127.97 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46665/47780 [02:40<00:05, 222.01 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47004/47780 [02:40<00:03, 200.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47541/47780 [02:40<00:03, 79.11 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46913/47780 [02:40<00:04, 181.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41048/47780 [02:40<00:11, 605.73 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47262/47780 [02:40<00:03, 137.69 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46690/47780 [02:40<00:04, 218.00 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47026/47780 [02:40<00:03, 198.89 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47554/47780 [02:40<00:02, 90.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47631/47780 [02:40<00:01, 91.62 examples/s] 
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46934/47780 [02:40<00:04, 187.76 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47630/47780 [02:40<00:02, 71.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41110/47780 [02:40<00:11, 598.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47278/47780 [02:40<00:03, 143.23 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46718/47780 [02:40<00:04, 225.91 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47564/47780 [02:40<00:02, 91.26 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47047/47780 [02:40<00:03, 189.69 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46956/47780 [02:40<00:04, 193.92 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47638/47780 [02:40<00:01, 71.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41174/47780 [02:40<00:10, 605.25 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47293/47780 [02:40<00:03, 136.08 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47642/47780 [02:40<00:01, 81.35 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46742/47780 [02:40<00:04, 226.77 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47067/47780 [02:40<00:03, 187.16 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47575/47780 [02:40<00:02, 88.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41238/47780 [02:40<00:10, 600.55 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46978/47780 [02:40<00:04, 187.14 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47646/47780 [02:40<00:01, 68.42 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46765/47780 [02:40<00:04, 226.85 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47653/47780 [02:40<00:01, 83.71 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47310/47780 [02:40<00:03, 133.47 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47089/47780 [02:40<00:03, 184.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41303/47780 [02:40<00:10, 606.64 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47585/47780 [02:40<00:02, 86.44 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46998/47780 [02:40<00:04, 175.05 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46795/47780 [02:40<00:04, 244.28 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47328/47780 [02:40<00:03, 144.63 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47662/47780 [02:40<00:01, 81.18 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47653/47780 [02:40<00:02, 60.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47113/47780 [02:40<00:03, 196.66 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41364/47780 [02:40<00:10, 599.70 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46824/47780 [02:40<00:03, 256.10 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47595/47780 [02:40<00:02, 81.72 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47345/47780 [02:40<00:02, 150.79 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47674/47780 [02:40<00:01, 85.93 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47018/47780 [02:40<00:04, 159.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41431/47780 [02:40<00:10, 618.72 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47662/47780 [02:40<00:01, 61.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47134/47780 [02:40<00:03, 183.16 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46857/47780 [02:40<00:03, 274.59 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47361/47780 [02:40<00:02, 150.35 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47605/47780 [02:41<00:02, 79.39 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47037/47780 [02:40<00:04, 165.51 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47689/47780 [02:41<00:00, 96.45 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41496/47780 [02:40<00:10, 619.77 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47669/47780 [02:41<00:01, 60.02 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47153/47780 [02:41<00:03, 180.60 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46886/47780 [02:41<00:03, 269.03 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47380/47780 [02:41<00:02, 159.84 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47054/47780 [02:41<00:04, 160.00 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47172/47780 [02:41<00:03, 182.86 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41560/47780 [02:41<00:11, 565.25 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47615/47780 [02:41<00:02, 69.38 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47700/47780 [02:41<00:00, 84.72 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47397/47780 [02:41<00:02, 147.78 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46914/47780 [02:41<00:03, 240.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47072/47780 [02:41<00:04, 163.00 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47202/47780 [02:41<00:02, 212.37 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41641/47780 [02:41<00:09, 623.74 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47676/47780 [02:41<00:02, 48.71 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47624/47780 [02:41<00:02, 69.29 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46939/47780 [02:41<00:03, 239.22 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47414/47780 [02:41<00:02, 137.37 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41706/47780 [02:41<00:10, 598.84 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47225/47780 [02:41<00:02, 203.17 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47090/47780 [02:41<00:04, 143.41 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47632/47780 [02:41<00:02, 68.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47710/47780 [02:41<00:01, 64.40 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46964/47780 [02:41<00:03, 207.25 examples/s]
Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41768/47780 [02:41<00:10, 598.25 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47429/47780 [02:41<00:02, 123.87 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47105/47780 [02:41<00:05, 133.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47247/47780 [02:41<00:02, 183.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47641/47780 [02:41<00:01, 70.53 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47683/47780 [02:41<00:02, 37.05 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41831/47780 [02:41<00:09, 601.09 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46990/47780 [02:41<00:03, 217.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47447/47780 [02:41<00:02, 135.70 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47270/47780 [02:41<00:02, 191.53 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47121/47780 [02:41<00:04, 133.16 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47653/47780 [02:41<00:01, 81.13 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47719/47780 [02:41<00:01, 55.30 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41893/47780 [02:41<00:09, 604.45 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47014/47780 [02:41<00:03, 221.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47688/47780 [02:41<00:02, 37.30 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47136/47780 [02:41<00:04, 136.70 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47462/47780 [02:41<00:02, 123.59 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47290/47780 [02:41<00:02, 169.94 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47664/47780 [02:41<00:01, 80.26 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41954/47780 [02:41<00:09, 586.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47037/47780 [02:41<00:03, 211.46 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47476/47780 [02:41<00:02, 125.73 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47728/47780 [02:41<00:00, 52.84 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47694/47780 [02:41<00:02, 36.50 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47150/47780 [02:41<00:05, 125.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47311/47780 [02:41<00:02, 178.09 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42013/47780 [02:41<00:10, 575.50 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47064/47780 [02:41<00:03, 224.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47675/47780 [02:41<00:01, 78.45 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47489/47780 [02:41<00:02, 117.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47331/47780 [02:41<00:02, 180.01 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47165/47780 [02:41<00:04, 123.66 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47700/47780 [02:42<00:02, 38.05 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42091/47780 [02:41<00:09, 609.60 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47087/47780 [02:42<00:03, 214.65 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47685/47780 [02:42<00:01, 75.22 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47351/47780 [02:42<00:02, 185.28 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47180/47780 [02:42<00:04, 129.45 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47735/47780 [02:42<00:01, 44.55 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47504/47780 [02:42<00:02, 120.12 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42170/47780 [02:42<00:08, 657.48 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47113/47780 [02:42<00:02, 226.44 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47706/47780 [02:42<00:01, 38.82 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47194/47780 [02:42<00:04, 130.75 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47372/47780 [02:42<00:02, 186.50 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47695/47780 [02:42<00:01, 75.54 examples/s]
Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42256/47780 [02:42<00:07, 711.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47523/47780 [02:42<00:01, 129.11 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47138/47780 [02:42<00:02, 220.08 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47711/47780 [02:42<00:01, 39.86 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47209/47780 [02:42<00:04, 132.00 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47391/47780 [02:42<00:02, 181.51 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47703/47780 [02:42<00:01, 74.31 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42339/47780 [02:42<00:07, 733.85 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47164/47780 [02:42<00:02, 225.65 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47741/47780 [02:42<00:01, 37.20 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47537/47780 [02:42<00:02, 110.87 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47224/47780 [02:42<00:04, 135.29 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47410/47780 [02:42<00:02, 167.60 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42414/47780 [02:42<00:07, 677.60 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47712/47780 [02:42<00:00, 70.87 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47717/47780 [02:42<00:01, 36.93 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47187/47780 [02:42<00:02, 220.03 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47549/47780 [02:42<00:02, 106.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47239/47780 [02:42<00:04, 133.11 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42489/47780 [02:42<00:07, 694.10 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47721/47780 [02:42<00:00, 73.66 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47211/47780 [02:42<00:02, 216.91 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47428/47780 [02:42<00:02, 156.25 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47722/47780 [02:42<00:01, 37.06 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47747/47780 [02:42<00:01, 32.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47255/47780 [02:42<00:03, 140.43 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42560/47780 [02:42<00:07, 698.22 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47447/47780 [02:42<00:02, 162.56 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47560/47780 [02:42<00:02, 93.83 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47233/47780 [02:42<00:02, 210.04 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47730/47780 [02:42<00:00, 70.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47729/47780 [02:42<00:01, 40.51 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47270/47780 [02:42<00:03, 136.35 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42637/47780 [02:42<00:07, 717.99 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47751/47780 [02:42<00:00, 31.74 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47256/47780 [02:42<00:02, 205.83 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47571/47780 [02:42<00:02, 89.86 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47465/47780 [02:42<00:02, 147.83 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47734/47780 [02:42<00:01, 40.64 examples/s]
Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42710/47780 [02:42<00:07, 696.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47292/47780 [02:42<00:03, 147.35 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47755/47780 [02:42<00:00, 30.85 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47280/47780 [02:42<00:02, 213.51 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47483/47780 [02:42<00:01, 153.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47584/47780 [02:42<00:02, 95.05 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42782/47780 [02:42<00:07, 696.42 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47739/47780 [02:43<00:00, 53.25 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47307/47780 [02:42<00:03, 139.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47759/47780 [02:43<00:00, 31.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47302/47780 [02:43<00:02, 200.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47600/47780 [02:43<00:01, 104.84 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42856/47780 [02:43<00:07, 695.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47499/47780 [02:43<00:01, 143.50 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47740/47780 [02:43<00:01, 34.41 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47324/47780 [02:43<00:03, 147.44 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47763/47780 [02:43<00:00, 30.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47612/47780 [02:43<00:01, 106.80 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47323/47780 [02:43<00:02, 181.90 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42926/47780 [02:43<00:07, 674.13 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47515/47780 [02:43<00:01, 138.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47348/47780 [02:43<00:02, 165.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47744/47780 [02:43<00:01, 31.12 examples/s]
Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42994/47780 [02:43<00:07, 664.55 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47349/47780 [02:43<00:02, 196.12 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [02:43<00:00, 30.30 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47747/47780 [02:43<00:00, 39.39 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47624/47780 [02:43<00:01, 99.01 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47367/47780 [02:43<00:02, 163.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47530/47780 [02:43<00:01, 127.40 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47371/47780 [02:43<00:02, 199.25 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43061/47780 [02:43<00:07, 631.40 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47635/47780 [02:43<00:01, 96.87 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47385/47780 [02:43<00:02, 154.18 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47544/47780 [02:43<00:01, 119.00 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47749/47780 [02:43<00:01, 27.33 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43126/47780 [02:43<00:07, 627.46 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47392/47780 [02:43<00:02, 188.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47648/47780 [02:43<00:01, 100.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47753/47780 [02:43<00:00, 34.56 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47409/47780 [02:43<00:02, 165.02 examples/s]
Tokenizing train dataset (num_proc=32):  90%|█████████ | 43190/47780 [02:43<00:07, 614.93 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47753/47780 [02:43<00:00, 27.39 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47413/47780 [02:43<00:02, 178.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47557/47780 [02:43<00:02, 102.45 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47661/47780 [02:43<00:01, 99.05 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47427/47780 [02:43<00:02, 161.78 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43272/47780 [02:43<00:06, 667.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47759/47780 [02:43<00:00, 32.56 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47437/47780 [02:43<00:01, 182.21 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47569/47780 [02:43<00:02, 99.99 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47757/47780 [02:43<00:00, 26.64 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43346/47780 [02:43<00:06, 679.64 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47444/47780 [02:43<00:02, 156.69 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47763/47780 [02:43<00:00, 32.57 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47459/47780 [02:43<00:01, 172.90 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43422/47780 [02:43<00:06, 698.99 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47761/47780 [02:43<00:00, 27.60 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47673/47780 [02:43<00:01, 76.44 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47461/47780 [02:43<00:02, 149.14 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47580/47780 [02:43<00:02, 78.97 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [02:44<00:00, 32.38 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43493/47780 [02:44<00:06, 666.00 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47765/47780 [02:44<00:00, 28.99 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47479/47780 [02:44<00:01, 155.21 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47478/47780 [02:44<00:01, 161.42 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47685/47780 [02:44<00:01, 80.65 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47589/47780 [02:44<00:02, 75.93 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████ | 43561/47780 [02:44<00:06, 649.92 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47771/47780 [02:44<00:00, 31.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47769/47780 [02:44<00:00, 28.67 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47495/47780 [02:44<00:02, 131.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47695/47780 [02:44<00:01, 70.33 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47495/47780 [02:44<00:02, 132.09 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43630/47780 [02:44<00:06, 654.43 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47598/47780 [02:44<00:02, 73.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47775/47780 [02:44<00:00, 31.05 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47773/47780 [02:44<00:00, 28.59 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47510/47780 [02:44<00:02, 124.01 examples/s]
Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43705/47780 [02:44<00:06, 664.75 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47511/47780 [02:44<00:02, 125.26 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47607/47780 [02:44<00:02, 67.87 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47703/47780 [02:44<00:01, 60.46 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43773/47780 [02:44<00:06, 652.15 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47524/47780 [02:44<00:02, 120.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47526/47780 [02:44<00:01, 127.36 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47711/47780 [02:44<00:01, 61.52 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47617/47780 [02:44<00:02, 68.98 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43840/47780 [02:44<00:06, 646.74 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47539/47780 [02:44<00:01, 126.37 examples/s]
Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47541/47780 [02:44<00:01, 126.31 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43908/47780 [02:44<00:05, 650.82 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47627/47780 [02:44<00:02, 74.52 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47723/47780 [02:44<00:00, 71.87 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47555/47780 [02:44<00:01, 132.32 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47555/47780 [02:44<00:01, 125.49 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43987/47780 [02:44<00:05, 686.03 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47732/47780 [02:44<00:00, 73.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47635/47780 [02:44<00:02, 69.48 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47570/47780 [02:44<00:01, 123.18 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44057/47780 [02:44<00:05, 690.01 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47568/47780 [02:44<00:01, 113.62 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47740/47780 [02:44<00:00, 68.76 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47584/47780 [02:44<00:01, 119.05 examples/s]
Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44128/47780 [02:44<00:05, 690.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47581/47780 [02:45<00:01, 113.66 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44199/47780 [02:45<00:05, 689.57 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47643/47780 [02:45<00:02, 49.82 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47597/47780 [02:45<00:01, 106.46 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47593/47780 [02:45<00:01, 98.91 examples/s] 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44278/47780 [02:45<00:04, 716.26 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47609/47780 [02:45<00:01, 103.10 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47650/47780 [02:45<00:02, 45.63 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44352/47780 [02:45<00:04, 703.38 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47604/47780 [02:45<00:01, 91.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44424/47780 [02:45<00:04, 701.86 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47614/47780 [02:45<00:01, 85.55 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47749/47780 [02:45<00:00, 36.31 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47621/47780 [02:45<00:02, 78.63 examples/s] 
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44496/47780 [02:45<00:04, 668.72 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47656/47780 [02:45<00:03, 38.94 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47626/47780 [02:45<00:01, 90.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44564/47780 [02:45<00:04, 643.76 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47632/47780 [02:45<00:01, 74.15 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47755/47780 [02:45<00:00, 33.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47636/47780 [02:45<00:01, 83.89 examples/s]
Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44629/47780 [02:45<00:04, 631.30 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47661/47780 [02:45<00:03, 33.57 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47642/47780 [02:45<00:01, 78.82 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44698/47780 [02:45<00:04, 643.84 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47665/47780 [02:45<00:03, 31.66 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47652/47780 [02:45<00:01, 75.26 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47761/47780 [02:45<00:00, 31.35 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47645/47780 [02:45<00:02, 65.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44763/47780 [02:45<00:04, 634.43 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44835/47780 [02:46<00:04, 649.30 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47654/47780 [02:46<00:01, 66.48 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [02:46<00:00, 31.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47670/47780 [02:46<00:03, 28.69 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47660/47780 [02:46<00:02, 59.76 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44901/47780 [02:46<00:04, 639.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47663/47780 [02:46<00:01, 67.06 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44966/47780 [02:46<00:04, 641.14 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47771/47780 [02:46<00:00, 30.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47674/47780 [02:46<00:03, 27.06 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47671/47780 [02:46<00:01, 64.65 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45034/47780 [02:46<00:04, 648.25 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47775/47780 [02:46<00:00, 29.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47679/47780 [02:46<00:01, 66.16 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47678/47780 [02:46<00:03, 26.19 examples/s]
Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45100/47780 [02:46<00:04, 619.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47668/47780 [02:46<00:02, 40.94 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47687/47780 [02:46<00:01, 68.37 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45165/47780 [02:46<00:04, 584.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47682/47780 [02:46<00:03, 25.68 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47695/47780 [02:46<00:01, 66.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45225/47780 [02:46<00:04, 566.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47687/47780 [02:46<00:03, 27.83 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47705/47780 [02:46<00:01, 72.45 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45283/47780 [02:46<00:04, 562.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47675/47780 [02:46<00:03, 34.31 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47692/47780 [02:46<00:02, 30.54 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47717/47780 [02:46<00:00, 80.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45343/47780 [02:46<00:04, 568.82 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45402/47780 [02:47<00:04, 545.04 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47698/47780 [02:47<00:02, 33.48 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47727/47780 [02:47<00:00, 75.27 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47681/47780 [02:47<00:03, 31.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45476/47780 [02:47<00:03, 593.65 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47703/47780 [02:47<00:02, 34.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47685/47780 [02:47<00:03, 30.39 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45538/47780 [02:47<00:03, 565.12 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47707/47780 [02:47<00:02, 34.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47736/47780 [02:47<00:00, 58.81 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47691/47780 [02:47<00:02, 32.84 examples/s]
Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45596/47780 [02:47<00:04, 537.58 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47712/47780 [02:47<00:01, 35.77 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45652/47780 [02:47<00:04, 519.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47697/47780 [02:47<00:02, 35.21 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47771/47780 [02:47<00:02,  3.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47717/47780 [02:47<00:01, 38.66 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47744/47780 [02:47<00:00, 44.24 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47702/47780 [02:47<00:02, 37.40 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45706/47780 [02:47<00:04, 493.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47722/47780 [02:47<00:01, 38.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45757/47780 [02:47<00:04, 480.33 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47727/47780 [02:47<00:01, 37.89 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47750/47780 [02:47<00:00, 40.05 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47709/47780 [02:47<00:01, 36.04 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45806/47780 [02:47<00:04, 467.32 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47733/47780 [02:47<00:01, 40.31 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47755/47780 [02:47<00:00, 39.77 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45853/47780 [02:47<00:04, 463.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47715/47780 [02:47<00:01, 38.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45900/47780 [02:48<00:04, 450.15 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47721/47780 [02:48<00:01, 41.24 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47739/47780 [02:48<00:01, 36.74 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47761/47780 [02:48<00:00, 36.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45961/47780 [02:48<00:03, 492.86 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47726/47780 [02:48<00:01, 40.79 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46012/47780 [02:48<00:03, 477.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47743/47780 [02:48<00:01, 31.32 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47731/47780 [02:48<00:01, 37.54 examples/s]
Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46064/47780 [02:48<00:03, 468.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47747/47780 [02:48<00:01, 29.40 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46113/47780 [02:48<00:03, 460.18 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47735/47780 [02:48<00:01, 33.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47751/47780 [02:48<00:00, 29.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46163/47780 [02:48<00:03, 454.57 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47740/47780 [02:48<00:01, 31.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47755/47780 [02:48<00:00, 29.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46210/47780 [02:48<00:03, 431.02 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46259/47780 [02:48<00:03, 439.59 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47759/47780 [02:48<00:00, 30.50 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47744/47780 [02:48<00:01, 29.66 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46304/47780 [02:48<00:03, 432.39 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47748/47780 [02:49<00:01, 29.73 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47763/47780 [02:49<00:00, 29.79 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46350/47780 [02:49<00:03, 433.26 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [02:49<00:00, 30.19 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47752/47780 [02:49<00:00, 29.46 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46396/47780 [02:49<00:03, 413.65 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [02:49<00:00, 30.54 examples/s]
Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46439/47780 [02:49<00:03, 380.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47760/47780 [02:49<00:00, 30.39 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46480/47780 [02:49<00:03, 376.46 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47764/47780 [02:49<00:00, 30.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46530/47780 [02:49<00:03, 403.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46572/47780 [02:49<00:03, 395.97 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46612/47780 [02:49<00:03, 380.69 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46654/47780 [02:49<00:02, 383.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46693/47780 [02:49<00:02, 367.17 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46730/47780 [02:50<00:02, 352.21 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46776/47780 [02:50<00:02, 372.03 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [02:50<00:02,  2.22 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46815/47780 [02:50<00:02, 366.52 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47766/47780 [02:50<00:01,  7.83 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46852/47780 [02:50<00:02, 348.90 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46890/47780 [02:50<00:02, 347.96 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46926/47780 [02:50<00:02, 303.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46961/47780 [02:50<00:02, 299.58 examples/s]
Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46995/47780 [02:50<00:02, 301.13 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47768/47780 [02:51<00:01,  7.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47027/47780 [02:51<00:02, 288.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47057/47780 [02:51<00:02, 288.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47088/47780 [02:51<00:02, 275.87 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47777/47780 [02:51<00:01,  1.86 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47119/47780 [02:51<00:02, 281.12 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47151/47780 [02:51<00:02, 281.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47185/47780 [02:51<00:02, 293.23 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47216/47780 [02:51<00:01, 282.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47247/47780 [02:51<00:01, 279.18 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47277/47780 [02:51<00:01, 264.56 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47305/47780 [02:52<00:01, 250.04 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47332/47780 [02:52<00:01, 246.25 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47359/47780 [02:52<00:01, 248.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47385/47780 [02:52<00:01, 222.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47409/47780 [02:52<00:01, 195.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47431/47780 [02:52<00:02, 159.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47449/47780 [02:52<00:02, 159.08 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47468/47780 [02:53<00:02, 118.31 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47483/47780 [02:53<00:02, 122.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47497/47780 [02:53<00:02, 105.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47509/47780 [02:53<00:03, 88.36 examples/s] 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47519/47780 [02:53<00:03, 84.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47530/47780 [02:54<00:03, 79.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47543/47780 [02:54<00:02, 85.19 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47554/47780 [02:54<00:02, 86.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47564/47780 [02:54<00:02, 83.26 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47769/47780 [02:54<00:03,  2.96 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47575/47780 [02:54<00:02, 72.87 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [02:54<00:00, 31.05 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47584/47780 [02:54<00:02, 73.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47593/47780 [02:54<00:02, 68.91 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47602/47780 [02:55<00:02, 69.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47610/47780 [02:55<00:02, 65.67 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47618/47780 [02:55<00:02, 63.68 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47771/47780 [02:55<00:04,  2.08 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47626/47780 [02:55<00:02, 62.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [02:55<00:01,  1.42 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47771/47780 [02:55<00:04,  2.15 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47634/47780 [02:55<00:02, 60.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47642/47780 [02:55<00:02, 60.57 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [02:55<00:00,  1.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47649/47780 [02:55<00:02, 59.78 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47661/47780 [02:55<00:01, 68.11 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47670/47780 [02:56<00:01, 70.41 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [02:56<00:00, 271.09 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47682/47780 [02:56<00:01, 79.47 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47692/47780 [02:56<00:01, 77.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47701/47780 [02:56<00:01, 76.81 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47711/47780 [02:56<00:00, 81.11 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47721/47780 [02:56<00:01, 57.67 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:29, 1592.57 examples/s]
Truncating train dataset (num_proc=32):  29%|██▉       | 14000/47780 [00:00<00:01, 25133.30 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47728/47780 [02:57<00:01, 43.86 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  82%|████████▏ | 39399/47780 [00:00<00:00, 71385.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47734/47780 [02:57<00:01, 38.13 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47775/47780 [02:57<00:02,  2.00 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47740/47780 [02:57<00:01, 35.67 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47746/47780 [02:57<00:00, 36.13 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47752/47780 [02:57<00:00, 34.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47772/47780 [02:57<00:03,  2.01 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [02:58<00:03,  1.80 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [02:58<00:00, 34.28 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [02:58<00:00,  1.07 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [02:58<00:02,  2.19 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47760/47780 [02:59<00:01, 10.41 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [03:00<00:01,  1.88 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [03:00<00:00,  1.87 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:01<00:00, 263.71 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47765/47780 [03:01<00:02,  5.54 examples/s]
Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:01<00:00,  1.14s/ examples]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:01<00:00, 262.76 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47777/47780 [03:01<00:01,  1.60 examples/s]
Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:24, 1924.56 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:01<00:00,  1.25s/ examples]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:01<00:00,  2.12 examples/s]
Truncating train dataset (num_proc=32):  13%|█▎        | 6000/47780 [00:00<00:03, 12238.63 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  36%|███▌      | 16988/47780 [00:00<00:00, 34922.86 examples/s]
Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [03:02<00:00, 29.20 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  77%|███████▋  | 36934/47780 [00:00<00:00, 71352.76 examples/s]
Truncating train dataset (num_proc=32):  99%|█████████▉| 47287/47780 [00:00<00:00, 71745.42 examples/s]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:02<00:00, 261.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:02<00:00, 261.89 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:35, 1306.28 examples/s]
Truncating train dataset (num_proc=32):   8%|▊         | 4000/47780 [00:00<00:07, 5673.47 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [03:02<00:03,  3.77 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  63%|██████▎   | 29987/47780 [00:00<00:00, 51144.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  94%|█████████▍| 44822/47780 [00:01<00:00, 70660.36 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:31, 1496.27 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):   8%|▊         | 4000/47780 [00:00<00:06, 6488.99 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  46%|████▌     | 21988/47780 [00:00<00:00, 40935.42 examples/s]
Truncating train dataset (num_proc=32):  76%|███████▋  | 36440/47780 [00:01<00:00, 55794.10 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:01<00:53, 875.00 examples/s]
Truncating train dataset (num_proc=32):  95%|█████████▍| 45315/47780 [00:01<00:00, 61746.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  40%|███▉      | 19000/47780 [00:01<00:01, 20775.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  82%|████████▏ | 39398/47780 [00:01<00:00, 45852.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00,  1.07s/ examples]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00, 257.55 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):   9%|▉         | 4479/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  11%|█▏        | 5479/47780 [00:00<00:24, 1740.02 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  26%|██▌       | 12479/47780 [00:00<00:02, 15321.17 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  78%|███████▊  | 37426/47780 [00:00<00:00, 66112.64 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47770/47780 [03:08<00:06,  1.53 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:09<00:00,  1.31s/ examples]
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:09<00:00, 251.98 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Truncating train dataset (num_proc=32):  34%|███▍      | 16424/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [03:09<00:03,  1.84 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:15<00:00, 71385.49 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:15<00:00, 2130.62 examples/s] 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:11<00:00, 71745.42 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:11<00:00, 70660.36 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:11<00:00, 45852.43 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  36%|███▋      | 17424/47780 [00:05<02:37, 192.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  39%|███▊      | 18424/47780 [00:06<01:23, 351.06 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:14<00:00, 61746.44 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  41%|████      | 19410/47780 [00:07<00:59, 474.16 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  53%|█████▎    | 25410/47780 [00:07<00:09, 2255.59 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47777/47780 [03:17<00:03,  1.07s/ examples]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  61%|██████▏   | 29370/47780 [00:10<00:09, 1921.70 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  74%|███████▍  | 35357/47780 [00:10<00:03, 3592.85 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [03:21<00:02,  1.32s/ examples]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:16<00:00, 66112.64 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:26<00:00, 2130.62 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  80%|████████  | 38329/47780 [00:14<00:05, 1888.95 examples/s]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:23<00:00, 1009.61 examples/s] 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  86%|████████▋ | 41316/47780 [00:16<00:03, 1620.27 examples/s]
Truncating train dataset (num_proc=32):  91%|█████████ | 43302/47780 [00:16<00:02, 1981.54 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:24<00:00, 1362.15 examples/s] 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32):  95%|█████████▍| 45302/47780 [00:17<00:01, 1932.61 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32): 47781 examples [00:17, 2614.49 examples/s]                    
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:31<00:00,  2.19s/ examples]
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:35<00:00, 1353.79 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:31<00:00, 740.89 examples/s]  
Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:33<00:00, 224.22 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:32<00:00, 873.29 examples/s]  [2025-08-02 07:41:09,252] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:31<00:00, 1516.73 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m [2025-08-02 07:41:09,280] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:28<00:00, 1119.70 examples/s] backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m [2025-08-02 07:41:10,280] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m df: /home/sky/.triton/autotune: No such file or directory
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:33<00:00, 1444.93 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m [2025-08-02 07:41:11,751] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:31<00:00, 1381.01 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m [2025-08-02 07:41:13,181] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:36<00:00, 1324.34 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m [2025-08-02 07:41:14,307] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:37<00:00, 1262.93 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
Truncating train dataset (num_proc=32): 47781 examples [00:29, 1057.39 examples/s]
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m [2025-08-02 07:41:15,050] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m [2025-08-02 07:41:15,050] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m [2025-08-02 07:41:15,051] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m [2025-08-02 07:41:15,051] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m [2025-08-02 07:41:15,051] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m [2025-08-02 07:41:15,398] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m [2025-08-02 07:41:15,530] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m [2025-08-02 07:41:15,780] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m [2025-08-02 07:41:16,615] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m [2025-08-02 07:41:17,035] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   0%|          | 0/10 [00:00<?, ?it/s]
[36m(head, rank=0, pid=2319)[0m  10%|█         | 1/10 [06:02<54:21, 362.37s/it]
[36m(head, rank=0, pid=2319)[0m  20%|██        | 2/10 [12:03<48:13, 361.74s/it]
[36m(head, rank=0, pid=2319)[0m  30%|███       | 3/10 [17:52<41:31, 355.94s/it]
[36m(head, rank=0, pid=2319)[0m  40%|████      | 4/10 [23:55<35:52, 358.74s/it]
[36m(head, rank=0, pid=2319)[0m  50%|█████     | 5/10 [30:03<30:09, 361.90s/it]
[36m(head, rank=0, pid=2319)[0m  60%|██████    | 6/10 [36:10<24:15, 363.80s/it]
[36m(head, rank=0, pid=2319)[0m  70%|███████   | 7/10 [42:20<18:17, 365.85s/it]
[36m(head, rank=0, pid=2319)[0m  80%|████████  | 8/10 [48:10<12:01, 360.81s/it]
[36m(head, rank=0, pid=2319)[0m  90%|█████████ | 9/10 [54:25<06:05, 365.02s/it]
100%|██████████| 10/10 [1:00:27<00:00, 364.36s/it]
                                                  
{'loss': 124.359, 'grad_norm': 28.74504280090332, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=2319)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m TRAINING TIME STATISTICS
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Total training steps: 80
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Total training time: 3172.97 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Average time per step: 39.662 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Fastest step: 34.976 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Slowest step: 52.806 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Time variance: 17.830 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Step time distribution:
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 1: 46.360s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 2: 37.813s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 3: 38.378s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 4: 38.006s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 5: 42.173s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m TRAINING TIME STATISTICS  Step 6: 38.899s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 7: 39.051s============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 8: 37.859s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Total training steps: 80  Step 9: 39.862s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 10: 37.780s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 11: 38.577s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 12: 38.250s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 13: 39.123s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 14: 38.146s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 15: 40.121sTotal training time: 3170.90 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 16: 45.668s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 17: 37.148s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Average time per step: 39.636 seconds  Step 18: 36.969s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Fastest step: 34.606 seconds  Step 19: 38.682s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 20: 37.309sSlowest step: 52.210 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 21: 42.087s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Time variance: 17.604 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 22: 38.222s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Step time distribution:
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 23: 36.210s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 24: 39.737s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 25: 44.309s  Step 1: 47.514s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 26: 39.314s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 2: 37.798s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 27: 41.793s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 3: 38.364s  Step 28: 38.024s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 4: 38.003s  Step 29: 38.655s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 5: 42.195s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 30: 39.960s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 6: 38.859s  Step 31: 38.243s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 7: 39.037s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 32: 37.824s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 8: 37.862s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 33: 52.806s  Step 9: 39.935s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 34: 38.822s  Step 10: 37.753s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 35: 39.780s  Step 11: 38.557s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 36: 39.201s  Step 12: 38.240s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 37: 38.746s  Step 13: 39.106s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 38: 40.141s  Step 14: 38.137s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 39: 37.473s  Step 15: 40.095s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 40: 35.288s  Step 16: 41.515s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 41: 37.578s  Step 17: 37.147s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 42: 39.142s  Step 18: 36.964s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 43: 38.816s  Step 19: 38.712s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 44: 39.530s  Step 20: 37.302s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 45: 46.585s  Step 21: 41.394s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 46: 39.081s  Step 22: 38.199s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 47: 39.602s  Step 23: 36.193s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 48: 40.480s  Step 24: 39.717s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 49: 38.956s  Step 25: 49.041s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 50: 39.609s  Step 26: 39.232s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 51: 37.206s  Step 27: 41.787s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 52: 41.728s  Step 28: 37.966s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 53: 39.738s  Step 29: 39.126s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 54: 41.837s  Step 30: 39.205s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 55: 45.730s  Step 31: 37.703s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 56: 37.812s  Step 32: 37.781s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 57: 34.976s  Step 33: 52.210s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 58: 38.465s  Step 34: 38.814s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 59: 40.938s  Step 35: 39.757s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 60: 39.372s  Step 36: 38.640s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 61: 36.344s  Step 37: 38.739s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 62: 37.514s  Step 38: 40.149s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 63: 37.569s  Step 39: 37.460s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 64: 37.951s  Step 40: 34.606s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 65: 39.186s  Step 41: 37.594s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 66: 39.603s  Step 42: 39.073s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 67: 37.386s  Step 43: 38.773s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 68: 36.916s  Step 44: 39.511s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 69: 49.256s  Step 45: 46.546s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 70: 40.326s  Step 46: 39.049s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 71: 46.096s  Step 47: 39.342s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 72: 38.115s  Step 48: 40.472s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 73: 38.873s  Step 49: 38.932s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 74: 37.486s  Step 50: 39.617s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 75: 39.889s  Step 51: 37.711s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 76: 38.219s  Step 52: 41.576s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 77: 40.398s  Step 53: 39.735s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 78: 38.282s  Step 54: 41.871s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 79: 42.649s  Step 55: 45.695s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 80: 40.925s  Step 56: 37.800s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================  Step 57: 34.967s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 58: 38.455s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 59: 40.927s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 60: 39.400s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 61: 37.084s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 62: 37.487s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 63: 37.557s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 64: 38.517s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 65: 39.184s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 66: 39.655s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 67: 37.355s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 68: 36.870s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 69: 49.263s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 70: 40.308s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 71: 45.539s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 72: 38.081s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 73: 38.820s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 74: 36.880s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 75: 40.280s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 76: 38.212s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 77: 40.936s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 78: 38.273s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 79: 42.626s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 80: 40.107s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m TRAINING TIME STATISTICS
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Total training steps: 80
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Total training time: 3172.95 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Average time per step: 39.662 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Fastest step: 34.972 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Slowest step: 52.796 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Time variance: 17.824 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Step time distribution:
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 1: 47.476s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 2: 37.761s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 3: 38.370s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 4: 37.958s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 5: 42.207s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 6: 38.882s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 7: 39.043s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 8: 37.859s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 9: 39.952s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 10: 37.764s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 11: 43.314s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 12: 38.245s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 13: 38.603s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 14: 38.109s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 15: 40.063s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 16: 41.519s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 17: 37.184s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 18: 36.968s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 19: 38.686s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 20: 37.305s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 21: 42.079s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 22: 38.220s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 23: 36.196s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 24: 39.679s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 25: 44.304s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 26: 39.234s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 27: 41.789s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 28: 38.008s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 29: 39.127s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 30: 39.939s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 31: 38.247s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 32: 37.820s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 33: 52.796s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 34: 38.821s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 35: 39.770s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 36: 38.640s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 37: 38.739s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m TRAINING TIME STATISTICS
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 38: 40.170s============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 39: 37.470s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 40: 35.243sTotal training steps: 80
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 41: 37.603s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 42: 39.129s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 43: 38.810s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 44: 39.533s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 45: 46.598s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 46: 39.064s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 47: 38.784s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 48: 40.468s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Total training time: 3174.72 seconds  Step 49: 38.940s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 50: 39.608s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 51: 37.180sAverage time per step: 39.684 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 52: 41.581s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Fastest step: 34.923 seconds  Step 53: 39.689s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 54: 41.875sSlowest step: 52.803 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 55: 45.705s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Time variance: 17.880 seconds  Step 56: 37.801s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Step time distribution:  Step 57: 34.972s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 58: 38.463s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 59: 40.893s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 1: 47.547s  Step 60: 39.404s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 2: 37.819s  Step 61: 37.094s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 3: 38.378s  Step 62: 36.931s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 4: 38.007s  Step 63: 37.566s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 5: 42.164s  Step 64: 38.524s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 6: 38.892s  Step 65: 39.138s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 7: 39.050s  Step 66: 39.040s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 67: 37.365s  Step 8: 37.862s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 68: 36.884s  Step 9: 44.686s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 69: 49.257s  Step 10: 37.773s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 70: 40.311s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 11: 38.572s  Step 71: 46.081s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 12: 38.241s  Step 72: 37.502s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 13: 39.119s  Step 73: 38.862s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 14: 38.146s  Step 74: 37.472s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 15: 40.124s  Step 75: 40.288s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 16: 41.519s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================  Step 76: 38.213s  Step 17: 37.165s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 77: 40.942s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 18: 36.972sTRAINING TIME STATISTICS
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 78: 38.276s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 19: 38.726s  Step 79: 42.624s============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 20: 37.263s  Step 80: 40.917sTotal training steps: 80
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 21: 42.083s============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 22: 38.220s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 23: 36.208s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================  Step 24: 39.721s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Total training time: 3170.41 seconds  Step 25: 44.269s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m TRAINING TIME STATISTICS  Step 26: 39.310s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Average time per step: 39.630 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 27: 41.237s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Fastest step: 34.980 seconds  Step 28: 37.973s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Total training steps: 80
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Slowest step: 52.756 seconds  Step 29: 39.094s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 30: 39.942s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Time variance: 17.776 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 31: 38.287s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Step time distribution:
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Total training time: 3174.17 seconds  Step 32: 37.827s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 33: 52.803s  Step 1: 47.557s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Average time per step: 39.677 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 34: 38.825s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 2: 37.798s  Step 35: 39.778sFastest step: 34.983 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 3: 38.319s  Step 36: 39.189sSlowest step: 52.750 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 4: 38.000sTime variance: 17.768 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 37: 37.989s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Step time distribution:  Step 5: 42.125s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 38: 40.177s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 6: 38.380s  Step 1: 47.500s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 39: 37.471s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 7: 38.986s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 40: 35.286s  Step 2: 37.807s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 8: 37.825s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 41: 37.612s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 3: 38.205s  Step 9: 39.935s  Step 42: 39.133s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 4: 37.997s  Step 10: 37.735s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 43: 38.816s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 5: 42.101s  Step 11: 38.532s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 12: 38.239s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 13: 39.092s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 14: 38.131s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 15: 40.079s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 16: 41.536s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 17: 37.168s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 44: 39.488s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 6: 38.872s  Step 18: 36.955s  Step 45: 46.597s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 46: 38.517s  Step 7: 39.014s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 19: 38.736s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 47: 39.600s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 8: 37.768s  Step 20: 37.074s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 48: 40.471s  Step 9: 39.988s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 21: 42.104s  Step 49: 38.955s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 10: 37.744s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 22: 38.199s  Step 50: 39.613s  Step 11: 38.511s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 23: 36.181s  Step 12: 38.230s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 51: 37.656s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 24: 39.711s  Step 13: 39.101s  Step 52: 41.729s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 25: 44.264s  Step 53: 39.733s  Step 14: 38.174s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 26: 39.273s  Step 54: 41.829s  Step 15: 40.064s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 27: 41.801s  Step 16: 41.518s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 55: 45.717s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 17: 37.170s  Step 28: 38.013s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 56: 37.802s  Step 18: 37.090s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 29: 39.131s  Step 57: 34.923s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 19: 38.732s  Step 30: 39.980s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 58: 38.467s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 20: 37.054s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 31: 38.285s  Step 59: 40.940s  Step 21: 42.093s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 22: 43.212s  Step 60: 39.410s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 32: 37.815s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 23: 36.174s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 61: 37.053s  Step 33: 52.756s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 24: 39.711s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 62: 37.512s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 34: 43.315s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 25: 44.312s  Step 63: 37.568s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 26: 39.276s  Step 35: 39.172s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 64: 38.479s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 27: 41.794s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 36: 39.183s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 65: 39.189s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 28: 38.020s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 37: 38.021s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 66: 39.038s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 29: 39.135s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 38: 40.140s  Step 67: 37.376s  Step 30: 40.005s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 68: 36.883s  Step 39: 37.455s  Step 31: 37.729s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 69: 49.253s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 32: 37.822s  Step 40: 35.266s  Step 70: 40.327s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 33: 52.750s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 71: 46.081s  Step 41: 37.601s  Step 34: 38.690s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 72: 38.116s  Step 35: 39.716s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 42: 38.514s  Step 73: 38.865s  Step 36: 39.194s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 37: 38.746s  Step 74: 37.479s  Step 43: 38.808s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 38: 40.078s  Step 75: 40.290s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 44: 39.497s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 39: 37.450s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 76: 37.753s  Step 40: 35.258s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 45: 46.567s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 77: 40.907s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 41: 37.061s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 78: 38.278s  Step 46: 38.994s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 42: 39.062s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 79: 42.626s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 47: 39.388s  Step 80: 40.924s  Step 43: 38.673s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================  Step 44: 39.410s  Step 48: 40.489s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 49: 38.409s  Step 45: 46.565s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 46: 38.944s  Step 50: 39.109s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 47: 39.397s  Step 51: 37.720s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 48: 40.519s  Step 52: 41.574s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================  Step 49: 38.919s  Step 53: 39.750s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 50: 39.784s  Step 54: 41.893sTRAINING TIME STATISTICS
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 55: 45.683s============================================================  Step 51: 37.731s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 56: 37.768sTotal training steps: 80
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 52: 41.100s  Step 57: 34.980s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 53: 39.772s  Step 58: 38.444s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 54: 41.931s  Step 59: 40.915s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Total training time: 3168.73 seconds  Step 55: 45.645s  Step 60: 38.915s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 56: 37.812sAverage time per step: 39.609 seconds  Step 61: 37.053s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 62: 36.909sFastest step: 34.989 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 57: 34.983s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 63: 37.548sSlowest step: 52.186 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 58: 38.311s  Step 64: 38.476s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Time variance: 17.197 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 59: 40.979s  Step 65: 39.186s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Step time distribution:
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 60: 39.497s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 66: 39.066s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 61: 36.919s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 67: 37.355s  Step 1: 47.520s  Step 62: 37.432s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 68: 36.922s  Step 2: 37.805s  Step 63: 37.544s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 69: 49.271s  Step 64: 38.510s  Step 3: 37.678s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 70: 40.251s  Step 65: 39.191s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 4: 37.394s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 71: 46.086s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 66: 39.680s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 5: 41.528s  Step 72: 38.077s  Step 67: 37.366s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 6: 38.389s  Step 73: 38.842s  Step 68: 36.866s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 7: 39.005s  Step 74: 36.857s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 69: 49.242s  Step 8: 37.765s  Step 75: 40.257s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 70: 40.206s  Step 9: 39.797s  Step 76: 38.213s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 71: 46.116s  Step 77: 40.916s  Step 10: 37.872s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 72: 38.064s  Step 11: 38.501s  Step 78: 38.278s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 73: 38.965s  Step 79: 42.662s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 12: 38.226s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 74: 37.400s  Step 13: 39.115s  Step 80: 40.902s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 75: 39.825s============================================================  Step 14: 38.173s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m TRAINING TIME STATISTICS
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 76: 38.204s  Step 15: 40.012s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 77: 40.881s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 16: 40.959sTotal training steps: 80  Step 78: 38.292s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 17: 37.175s  Step 79: 42.624s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 18: 37.093s  Step 80: 40.944s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 19: 38.728s============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Total training time: 3172.73 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 20: 37.044s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Average time per step: 39.659 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 21: 42.048s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Fastest step: 34.981 seconds  Step 22: 38.206s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Slowest step: 52.789 seconds
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 23: 36.126s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Time variance: 17.808 seconds  Step 24: 43.753s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m Step time distribution:
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 25: 44.303s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 26: 39.272s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 27: 41.860s  Step 1: 47.526s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 28: 38.021s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 2: 37.794s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 29: 39.137s  Step 3: 38.361s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 30: 40.012s  Step 4: 37.997s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 5: 42.162s  Step 31: 38.289s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 6: 38.869s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 32: 37.875s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 7: 39.026s  Step 33: 52.186s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 8: 37.826s  Step 34: 38.661s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 9: 40.010s  Step 35: 39.704s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 10: 42.597s  Step 36: 39.196s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 11: 38.526s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 37: 38.051s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 12: 38.191s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 38: 40.120s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 13: 39.097s  Step 39: 37.445s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 14: 37.439s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 40: 35.257s  Step 15: 40.073s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 41: 37.601s  Step 16: 41.478s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 42: 39.043s  Step 17: 37.175s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 43: 38.705s  Step 18: 36.972s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 44: 39.440s  Step 19: 38.731s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 45: 46.278s  Step 20: 37.025s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 46: 38.976s  Step 21: 42.101s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 47: 39.399s  Step 22: 38.199s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 23: 36.177s  Step 48: 39.833s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 24: 39.177s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 49: 38.959s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 25: 43.430s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 50: 39.751s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 26: 39.270s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 51: 37.840s  Step 27: 41.224s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 52: 41.572s  Step 28: 38.014s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 53: 39.777s  Step 29: 39.129s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 54: 41.950s  Step 30: 39.992s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 55: 45.620s  Step 31: 37.736s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 32: 37.830s  Step 56: 37.178s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 33: 52.789s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 57: 34.989s  Step 34: 38.786s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 58: 38.311s  Step 35: 39.723s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 59: 40.944s  Step 36: 39.187s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 60: 39.531s  Step 37: 38.739s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 61: 36.869s  Step 38: 40.136s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 62: 37.410s  Step 39: 37.454s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 40: 35.265s  Step 63: 37.094s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 41: 37.603s  Step 64: 38.506s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 42: 39.075s  Step 65: 39.186s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 43: 38.721s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 66: 39.688s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 44: 39.448s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 67: 37.372s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 45: 46.560s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 68: 36.916s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 46: 38.967s  Step 69: 49.242s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 47: 39.390s  Step 70: 40.244s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 48: 39.829s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 71: 46.239s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 49: 38.947s  Step 72: 37.994s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 50: 39.785s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 73: 38.357s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 51: 37.726s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 74: 37.376s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 52: 41.569s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 75: 40.221s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 53: 39.763s  Step 76: 38.205s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 54: 41.917s  Step 77: 40.865s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 55: 45.666s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 78: 38.301s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 56: 37.814s  Step 79: 42.702s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 57: 34.981s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 80: 40.948s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 58: 38.444s============================================================
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m 
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 59: 40.975s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 60: 39.533s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 61: 37.051s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 62: 37.453s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 63: 37.540s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 64: 38.512s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 65: 39.190s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 66: 39.675s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 67: 37.365s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 68: 36.915s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 69: 49.235s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 70: 40.268s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 71: 46.098s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 72: 38.070s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 73: 38.825s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 74: 37.420s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 75: 40.203s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 76: 38.208s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 77: 40.862s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 78: 38.289s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 79: 42.661s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m   Step 80: 40.945s
[36m(worker1, rank=1, pid=1615, ip=10.113.50.240)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m 100%|██████████| 10/10 [1:00:27<00:00, 364.36s/it]
                                                  
{'train_runtime': 4043.1533, 'train_samples_per_second': 0.317, 'train_steps_per_second': 0.002, 'train_loss': 124.358984375, 'epoch': 0.03}
[36m(head, rank=0, pid=2319)[0m 
100%|██████████| 10/10 [1:07:23<00:00, 364.36s/it]
100%|██████████| 10/10 [1:07:23<00:00, 404.32s/it]
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m TRAINING TIME STATISTICS
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m Total training steps: 80
[36m(head, rank=0, pid=2319)[0m Total training time: 3174.12 seconds
[36m(head, rank=0, pid=2319)[0m Average time per step: 39.677 seconds
[36m(head, rank=0, pid=2319)[0m Fastest step: 34.987 seconds
[36m(head, rank=0, pid=2319)[0m Slowest step: 52.734 seconds
[36m(head, rank=0, pid=2319)[0m Time variance: 17.747 seconds
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Step time distribution:
[36m(head, rank=0, pid=2319)[0m   Step 1: 46.370s
[36m(head, rank=0, pid=2319)[0m   Step 2: 42.493s
[36m(head, rank=0, pid=2319)[0m   Step 3: 38.256s
[36m(head, rank=0, pid=2319)[0m   Step 4: 37.994s
[36m(head, rank=0, pid=2319)[0m   Step 5: 42.203s
[36m(head, rank=0, pid=2319)[0m   Step 6: 39.017s
[36m(head, rank=0, pid=2319)[0m   Step 7: 38.095s
[36m(head, rank=0, pid=2319)[0m   Step 8: 37.776s
[36m(head, rank=0, pid=2319)[0m   Step 9: 39.894s
[36m(head, rank=0, pid=2319)[0m   Step 10: 37.879s
[36m(head, rank=0, pid=2319)[0m   Step 11: 38.480s
[36m(head, rank=0, pid=2319)[0m   Step 12: 38.226s
[36m(head, rank=0, pid=2319)[0m   Step 13: 39.513s
[36m(head, rank=0, pid=2319)[0m   Step 14: 38.130s
[36m(head, rank=0, pid=2319)[0m   Step 15: 40.040s
[36m(head, rank=0, pid=2319)[0m   Step 16: 41.514s
[36m(head, rank=0, pid=2319)[0m   Step 17: 37.211s
[36m(head, rank=0, pid=2319)[0m   Step 18: 37.127s
[36m(head, rank=0, pid=2319)[0m   Step 19: 38.230s
[36m(head, rank=0, pid=2319)[0m   Step 20: 37.021s
[36m(head, rank=0, pid=2319)[0m   Step 21: 42.129s
[36m(head, rank=0, pid=2319)[0m   Step 22: 38.210s
[36m(head, rank=0, pid=2319)[0m   Step 23: 36.260s
[36m(head, rank=0, pid=2319)[0m   Step 24: 39.730s
[36m(head, rank=0, pid=2319)[0m   Step 25: 44.320s
[36m(head, rank=0, pid=2319)[0m   Step 26: 39.231s
[36m(head, rank=0, pid=2319)[0m   Step 27: 41.930s
[36m(head, rank=0, pid=2319)[0m   Step 28: 38.037s
[36m(head, rank=0, pid=2319)[0m   Step 29: 39.150s
[36m(head, rank=0, pid=2319)[0m   Step 30: 40.045s
[36m(head, rank=0, pid=2319)[0m   Step 31: 38.304s
[36m(head, rank=0, pid=2319)[0m   Step 32: 37.923s
[36m(head, rank=0, pid=2319)[0m   Step 33: 52.734s
[36m(head, rank=0, pid=2319)[0m   Step 34: 38.744s
[36m(head, rank=0, pid=2319)[0m   Step 35: 39.748s
[36m(head, rank=0, pid=2319)[0m   Step 36: 39.225s
[36m(head, rank=0, pid=2319)[0m   Step 37: 38.766s
[36m(head, rank=0, pid=2319)[0m   Step 38: 40.159s
[36m(head, rank=0, pid=2319)[0m   Step 39: 37.440s
[36m(head, rank=0, pid=2319)[0m   Step 40: 35.247s
[36m(head, rank=0, pid=2319)[0m   Step 41: 37.617s
[36m(head, rank=0, pid=2319)[0m   Step 42: 38.482s
[36m(head, rank=0, pid=2319)[0m   Step 43: 38.699s
[36m(head, rank=0, pid=2319)[0m   Step 44: 39.441s
[36m(head, rank=0, pid=2319)[0m   Step 45: 46.249s
[36m(head, rank=0, pid=2319)[0m   Step 46: 38.971s
[36m(head, rank=0, pid=2319)[0m   Step 47: 39.412s
[36m(head, rank=0, pid=2319)[0m   Step 48: 40.577s
[36m(head, rank=0, pid=2319)[0m   Step 49: 39.007s
[36m(head, rank=0, pid=2319)[0m   Step 50: 39.821s
[36m(head, rank=0, pid=2319)[0m   Step 51: 37.881s
[36m(head, rank=0, pid=2319)[0m   Step 52: 41.613s
[36m(head, rank=0, pid=2319)[0m   Step 53: 39.815s
[36m(head, rank=0, pid=2319)[0m   Step 54: 42.004s
[36m(head, rank=0, pid=2319)[0m   Step 55: 45.556s
[36m(head, rank=0, pid=2319)[0m   Step 56: 37.849s
[36m(head, rank=0, pid=2319)[0m   Step 57: 34.987s
[36m(head, rank=0, pid=2319)[0m   Step 58: 38.530s
[36m(head, rank=0, pid=2319)[0m   Step 59: 41.046s
[36m(head, rank=0, pid=2319)[0m   Step 60: 39.542s
[36m(head, rank=0, pid=2319)[0m   Step 61: 36.946s
[36m(head, rank=0, pid=2319)[0m   Step 62: 37.399s
[36m(head, rank=0, pid=2319)[0m   Step 63: 37.693s
[36m(head, rank=0, pid=2319)[0m   Step 64: 38.520s
[36m(head, rank=0, pid=2319)[0m   Step 65: 39.203s
[36m(head, rank=0, pid=2319)[0m   Step 66: 39.700s
[36m(head, rank=0, pid=2319)[0m   Step 67: 37.396s
[36m(head, rank=0, pid=2319)[0m   Step 68: 36.334s
[36m(head, rank=0, pid=2319)[0m   Step 69: 49.296s
[36m(head, rank=0, pid=2319)[0m   Step 70: 40.303s
[36m(head, rank=0, pid=2319)[0m   Step 71: 46.287s
[36m(head, rank=0, pid=2319)[0m   Step 72: 38.024s
[36m(head, rank=0, pid=2319)[0m   Step 73: 38.382s
[36m(head, rank=0, pid=2319)[0m   Step 74: 37.434s
[36m(head, rank=0, pid=2319)[0m   Step 75: 40.205s
[36m(head, rank=0, pid=2319)[0m   Step 76: 38.200s
[36m(head, rank=0, pid=2319)[0m   Step 77: 40.844s
[36m(head, rank=0, pid=2319)[0m   Step 78: 38.341s
[36m(head, rank=0, pid=2319)[0m   Step 79: 42.728s
[36m(head, rank=0, pid=2319)[0m   Step 80: 40.984s
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m TRAINING TIME STATISTICS
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m Total training steps: 80
[36m(head, rank=0, pid=2319)[0m Total training time: 3174.14 seconds
[36m(head, rank=0, pid=2319)[0m Average time per step: 39.677 seconds
[36m(head, rank=0, pid=2319)[0m Fastest step: 34.951 seconds
[36m(head, rank=0, pid=2319)[0m Slowest step: 52.768 seconds
[36m(head, rank=0, pid=2319)[0m Time variance: 17.817 seconds
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Step time distribution:
[36m(head, rank=0, pid=2319)[0m   Step 1: 47.976s
[36m(head, rank=0, pid=2319)[0m   Step 2: 42.481s
[36m(head, rank=0, pid=2319)[0m   Step 3: 38.239s
[36m(head, rank=0, pid=2319)[0m   Step 4: 37.990s
[36m(head, rank=0, pid=2319)[0m   Step 5: 42.179s
[36m(head, rank=0, pid=2319)[0m   Step 6: 39.015s
[36m(head, rank=0, pid=2319)[0m   Step 7: 38.089s
[36m(head, rank=0, pid=2319)[0m   Step 8: 37.768s
[36m(head, rank=0, pid=2319)[0m   Step 9: 39.938s
[36m(head, rank=0, pid=2319)[0m   Step 10: 37.895s
[36m(head, rank=0, pid=2319)[0m   Step 11: 38.469s
[36m(head, rank=0, pid=2319)[0m   Step 12: 38.223s
[36m(head, rank=0, pid=2319)[0m   Step 13: 39.138s
[36m(head, rank=0, pid=2319)[0m   Step 14: 38.117s
[36m(head, rank=0, pid=2319)[0m   Step 15: 40.042s
[36m(head, rank=0, pid=2319)[0m   Step 16: 41.514s
[36m(head, rank=0, pid=2319)[0m   Step 17: 37.194s
[36m(head, rank=0, pid=2319)[0m   Step 18: 37.102s
[36m(head, rank=0, pid=2319)[0m   Step 19: 38.734s
[36m(head, rank=0, pid=2319)[0m   Step 20: 37.020s
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m   Step 21: 42.104s
[36m(head, rank=0, pid=2319)[0m   Step 22: 38.169s
[36m(head, rank=0, pid=2319)[0m   Step 23: 35.580s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 24: 39.714sTRAINING TIME STATISTICS
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 25: 44.308s============================================================
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 26: 39.273s
[36m(head, rank=0, pid=2319)[0m Total training steps: 80  Step 27: 41.892s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 28: 38.027s
[36m(head, rank=0, pid=2319)[0m   Step 29: 39.108s
[36m(head, rank=0, pid=2319)[0m   Step 30: 40.020s
[36m(head, rank=0, pid=2319)[0m   Step 31: 37.751s
[36m(head, rank=0, pid=2319)[0m   Step 32: 37.890s
[36m(head, rank=0, pid=2319)[0m   Step 33: 52.768s
[36m(head, rank=0, pid=2319)[0m   Step 34: 38.720sTotal training time: 3171.50 seconds
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 35: 39.724s
[36m(head, rank=0, pid=2319)[0m   Step 36: 39.204sAverage time per step: 39.644 seconds
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 37: 38.756s
[36m(head, rank=0, pid=2319)[0m Fastest step: 34.999 seconds
[36m(head, rank=0, pid=2319)[0m   Step 38: 40.133s
[36m(head, rank=0, pid=2319)[0m Slowest step: 52.777 seconds  Step 39: 37.439s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Time variance: 17.777 seconds  Step 40: 35.247s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Step time distribution:  Step 41: 37.606s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 42: 39.012s
[36m(head, rank=0, pid=2319)[0m   Step 1: 47.970s
[36m(head, rank=0, pid=2319)[0m   Step 2: 37.811s
[36m(head, rank=0, pid=2319)[0m   Step 3: 38.249s
[36m(head, rank=0, pid=2319)[0m   Step 4: 37.997s
[36m(head, rank=0, pid=2319)[0m   Step 43: 38.661s  Step 5: 42.205s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 44: 39.435s  Step 6: 39.016s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 45: 46.243s
[36m(head, rank=0, pid=2319)[0m   Step 7: 38.810s
[36m(head, rank=0, pid=2319)[0m ============================================================  Step 46: 38.966s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 8: 42.701s  Step 47: 39.405s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 9: 40.018s  Step 48: 40.518sTRAINING TIME STATISTICS
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 49: 38.995s
[36m(head, rank=0, pid=2319)[0m ============================================================  Step 10: 37.150s  Step 50: 39.809s
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 51: 37.847sTotal training steps: 80  Step 11: 38.452s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 52: 41.086sTRAINING TIME STATISTICS  Step 12: 37.694s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m ============================================================  Step 53: 39.768s  Step 13: 39.517s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Total training time: 3170.26 secondsTotal training steps: 80  Step 54: 41.969s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 14: 38.128s
[36m(head, rank=0, pid=2319)[0m   Step 55: 45.593s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 15: 40.038s  Step 56: 37.833sAverage time per step: 39.628 seconds
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Total training time: 3174.54 seconds  Step 57: 34.951s  Step 16: 41.470sFastest step: 34.984 seconds
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 58: 38.332sAverage time per step: 39.682 seconds  Step 17: 37.205s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Slowest step: 52.734 seconds  Step 59: 41.012s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Fastest step: 34.940 seconds  Step 18: 37.084s  Step 60: 39.565sTime variance: 17.750 seconds
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Slowest step: 52.783 seconds  Step 19: 38.739s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Step time distribution:  Step 61: 36.935s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Time variance: 17.843 seconds
[36m(head, rank=0, pid=2319)[0m   Step 20: 37.000s
[36m(head, rank=0, pid=2319)[0m   Step 62: 37.398s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Step time distribution:
[36m(head, rank=0, pid=2319)[0m   Step 1: 47.961s
[36m(head, rank=0, pid=2319)[0m   Step 21: 42.115s
[36m(head, rank=0, pid=2319)[0m   Step 63: 37.680s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 2: 37.813s  Step 1: 47.958s  Step 22: 38.207s
[36m(head, rank=0, pid=2319)[0m   Step 64: 38.500s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 3: 38.223s
[36m(head, rank=0, pid=2319)[0m   Step 23: 36.256s  Step 2: 37.809s  Step 65: 39.188s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 4: 37.997s  Step 24: 39.715s
[36m(head, rank=0, pid=2319)[0m   Step 25: 44.314s
[36m(head, rank=0, pid=2319)[0m   Step 26: 39.277s
[36m(head, rank=0, pid=2319)[0m   Step 27: 41.227s
[36m(head, rank=0, pid=2319)[0m   Step 28: 37.240s
[36m(head, rank=0, pid=2319)[0m   Step 29: 39.159s
[36m(head, rank=0, pid=2319)[0m   Step 30: 40.037s
[36m(head, rank=0, pid=2319)[0m   Step 31: 38.307s  Step 66: 39.696s
[36m(head, rank=0, pid=2319)[0m   Step 3: 38.212s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 32: 37.918s  Step 5: 42.157s  Step 67: 37.386s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 4: 37.998s
[36m(head, rank=0, pid=2319)[0m   Step 33: 52.777s
[36m(head, rank=0, pid=2319)[0m   Step 6: 38.877s  Step 68: 36.919s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 7: 38.819s
[36m(head, rank=0, pid=2319)[0m   Step 5: 42.148s  Step 69: 49.254s
[36m(head, rank=0, pid=2319)[0m   Step 34: 38.740s
[36m(head, rank=0, pid=2319)[0m   Step 8: 37.297s
[36m(head, rank=0, pid=2319)[0m   Step 70: 40.276s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 6: 38.871s
[36m(head, rank=0, pid=2319)[0m   Step 35: 39.045s
[36m(head, rank=0, pid=2319)[0m   Step 9: 39.945s
[36m(head, rank=0, pid=2319)[0m   Step 71: 46.258s
[36m(head, rank=0, pid=2319)[0m   Step 7: 39.009s
[36m(head, rank=0, pid=2319)[0m   Step 36: 39.215s  Step 10: 42.527s
[36m(head, rank=0, pid=2319)[0m   Step 72: 38.012s
[36m(head, rank=0, pid=2319)[0m   Step 8: 37.768s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 11: 38.448s
[36m(head, rank=0, pid=2319)[0m   Step 37: 38.117s  Step 73: 38.971s  Step 9: 39.943s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 38: 40.154s  Step 12: 37.481s  Step 74: 36.892s  Step 10: 37.869s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 39: 37.438s  Step 11: 38.510s  Step 13: 39.117s  Step 75: 40.206s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 12: 38.229s
[36m(head, rank=0, pid=2319)[0m   Step 40: 35.244s
[36m(head, rank=0, pid=2319)[0m   Step 14: 38.170s  Step 76: 38.196s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 13: 39.109s  Step 15: 40.050s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 77: 40.836s  Step 16: 41.520s  Step 41: 37.608s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 17: 37.174s  Step 14: 38.127s  Step 42: 39.007s  Step 78: 38.309s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 18: 37.095s  Step 15: 40.061s  Step 43: 38.696s  Step 79: 42.717s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 19: 38.730s
[36m(head, rank=0, pid=2319)[0m   Step 16: 41.518s  Step 44: 39.404s  Step 80: 40.955s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 20: 37.032s  Step 17: 37.169s============================================================  Step 45: 46.236s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 21: 42.091s  Step 18: 37.092s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 46: 38.968s  Step 22: 37.593s  Step 19: 38.731s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 23: 36.226s  Step 47: 39.370s  Step 20: 37.051s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 24: 39.713s  Step 48: 40.531s
[36m(head, rank=0, pid=2319)[0m   Step 21: 42.090s
[36m(head, rank=0, pid=2319)[0m   Step 25: 44.311s
[36m(head, rank=0, pid=2319)[0m   Step 49: 38.967s
[36m(head, rank=0, pid=2319)[0m   Step 22: 38.202s
[36m(head, rank=0, pid=2319)[0m   Step 26: 39.272s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 50: 39.820s  Step 23: 36.135s  Step 27: 41.871s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 51: 37.882s  Step 24: 39.195s  Step 28: 38.026s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 52: 41.120s  Step 29: 39.144s  Step 25: 44.301s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 53: 39.820s  Step 30: 40.016s  Step 26: 39.273s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 54: 41.955s  Step 31: 37.749s  Step 27: 41.809s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 55: 45.598s  Step 32: 37.881s  Step 28: 38.019s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 56: 37.842s  Step 33: 52.734s  Step 29: 39.138s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 34: 38.711s
[36m(head, rank=0, pid=2319)[0m   Step 57: 34.999s  Step 30: 39.970s  Step 35: 39.706s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 58: 38.335s  Step 31: 38.288s  Step 36: 39.200s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 59: 41.036s  Step 32: 37.336s  Step 37: 38.080s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 33: 52.783s  Step 60: 39.579s  Step 38: 40.115s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 34: 38.691s  Step 61: 36.941s
[36m(head, rank=0, pid=2319)[0m   Step 39: 37.442s
[36m(head, rank=0, pid=2319)[0m   Step 35: 39.714s
[36m(head, rank=0, pid=2319)[0m   Step 62: 37.378s
[36m(head, rank=0, pid=2319)[0m   Step 40: 35.254s
[36m(head, rank=0, pid=2319)[0m   Step 36: 39.150s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 63: 37.692s  Step 41: 37.603s
[36m(head, rank=0, pid=2319)[0m   Step 37: 38.745s
[36m(head, rank=0, pid=2319)[0m   Step 64: 37.968s  Step 42: 38.983s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 38: 40.084s  Step 43: 38.703s
[36m(head, rank=0, pid=2319)[0m   Step 65: 39.195s
[36m(head, rank=0, pid=2319)[0m   Step 39: 37.445s  Step 44: 39.437s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 40: 35.257s  Step 66: 39.697s  Step 45: 46.280s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 41: 37.606s  Step 46: 38.977s
[36m(head, rank=0, pid=2319)[0m   Step 67: 36.849s
[36m(head, rank=0, pid=2319)[0m   Step 42: 39.057s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 47: 39.399s  Step 68: 36.922s
[36m(head, rank=0, pid=2319)[0m   Step 43: 38.671s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 48: 40.532s  Step 69: 49.297s
[36m(head, rank=0, pid=2319)[0m   Step 44: 38.802s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 49: 38.978s  Step 70: 40.298s  Step 45: 46.243s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 50: 39.787s  Step 71: 46.283s
[36m(head, rank=0, pid=2319)[0m   Step 46: 38.989s
[36m(head, rank=0, pid=2319)[0m   Step 51: 37.843s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 72: 38.004s  Step 47: 39.399s  Step 52: 41.082s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 73: 38.978s
[36m(head, rank=0, pid=2319)[0m   Step 48: 40.485s  Step 53: 39.338s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 74: 37.469s  Step 49: 38.959s  Step 54: 41.954s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 75: 40.207s  Step 55: 45.608s  Step 50: 39.785s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 76: 38.199s  Step 51: 37.734s  Step 56: 37.830s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 77: 40.846s  Step 57: 34.984s  Step 52: 41.561s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 78: 37.750s  Step 58: 38.317s  Step 53: 39.773s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 79: 42.728s  Step 54: 41.939s  Step 59: 41.001s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 80: 40.265s  Step 55: 52.054s  Step 60: 39.551s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m ============================================================  Step 61: 36.918s  Step 56: 37.823s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 62: 37.407s
[36m(head, rank=0, pid=2319)[0m   Step 57: 34.940s  Step 63: 37.680s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 58: 37.696s  Step 64: 38.499s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 59: 40.455s  Step 65: 39.194s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 60: 39.543s  Step 66: 39.075s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 61: 36.917s  Step 67: 37.376s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 62: 37.428s  Step 68: 36.916s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 69: 49.288s  Step 63: 37.545s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 70: 39.647s  Step 64: 38.495s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 71: 46.244s  Step 65: 39.193s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 72: 37.468s  Step 66: 39.678s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 73: 38.927s  Step 67: 36.820s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 74: 37.420s  Step 68: 36.865s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 75: 40.172s  Step 69: 49.280s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 76: 38.160s  Step 70: 40.242s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 77: 40.856s  Step 71: 46.125s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 78: 38.301s  Step 72: 38.013s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 79: 42.703s  Step 73: 38.968s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 80: 40.258s  Step 74: 37.407s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m ============================================================  Step 75: 40.229s
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m   Step 76: 38.205s
[36m(head, rank=0, pid=2319)[0m   Step 77: 40.873s
[36m(head, rank=0, pid=2319)[0m   Step 78: 38.292s
[36m(head, rank=0, pid=2319)[0m   Step 79: 42.696s
[36m(head, rank=0, pid=2319)[0m   Step 80: 40.945s
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m TRAINING TIME STATISTICS
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m Total training steps: 80
[36m(head, rank=0, pid=2319)[0m Total training time: 3172.01 seconds
[36m(head, rank=0, pid=2319)[0m Average time per step: 39.650 seconds
[36m(head, rank=0, pid=2319)[0m Fastest step: 34.944 seconds
[36m(head, rank=0, pid=2319)[0m Slowest step: 52.763 seconds
[36m(head, rank=0, pid=2319)[0m Time variance: 17.819 seconds
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Step time distribution:
[36m(head, rank=0, pid=2319)[0m   Step 1: 47.983s
[36m(head, rank=0, pid=2319)[0m   Step 2: 37.677s
[36m(head, rank=0, pid=2319)[0m   Step 3: 38.246s
[36m(head, rank=0, pid=2319)[0m   Step 4: 37.947s
[36m(head, rank=0, pid=2319)[0m   Step 5: 42.196s
[36m(head, rank=0, pid=2319)[0m   Step 6: 39.018s
[36m(head, rank=0, pid=2319)[0m   Step 7: 38.121s
[36m(head, rank=0, pid=2319)[0m   Step 8: 37.680s
[36m(head, rank=0, pid=2319)[0m   Step 9: 39.949s
[36m(head, rank=0, pid=2319)[0m   Step 10: 37.907s
[36m(head, rank=0, pid=2319)[0m   Step 11: 38.450s
[36m(head, rank=0, pid=2319)[0m   Step 12: 37.549s
[36m(head, rank=0, pid=2319)[0m   Step 13: 39.517s
[36m(head, rank=0, pid=2319)[0m   Step 14: 38.084s
[36m(head, rank=0, pid=2319)[0m   Step 15: 40.031s
[36m(head, rank=0, pid=2319)[0m   Step 16: 41.511s
[36m(head, rank=0, pid=2319)[0m   Step 17: 37.202s
[36m(head, rank=0, pid=2319)[0m   Step 18: 37.112s
[36m(head, rank=0, pid=2319)[0m   Step 19: 38.730s
[36m(head, rank=0, pid=2319)[0m   Step 20: 36.997s
[36m(head, rank=0, pid=2319)[0m   Step 21: 42.075s
[36m(head, rank=0, pid=2319)[0m   Step 22: 38.206s
[36m(head, rank=0, pid=2319)[0m   Step 23: 36.253s
[36m(head, rank=0, pid=2319)[0m   Step 24: 39.715s
[36m(head, rank=0, pid=2319)[0m   Step 25: 44.303s
[36m(head, rank=0, pid=2319)[0m   Step 26: 39.271s
[36m(head, rank=0, pid=2319)[0m   Step 27: 41.911s
[36m(head, rank=0, pid=2319)[0m   Step 28: 38.029s
[36m(head, rank=0, pid=2319)[0m   Step 29: 43.216s
[36m(head, rank=0, pid=2319)[0m   Step 30: 40.033s
[36m(head, rank=0, pid=2319)[0m   Step 31: 38.303s
[36m(head, rank=0, pid=2319)[0m   Step 32: 37.351s
[36m(head, rank=0, pid=2319)[0m   Step 33: 52.763s
[36m(head, rank=0, pid=2319)[0m   Step 34: 38.731s
[36m(head, rank=0, pid=2319)[0m   Step 35: 39.746s
[36m(head, rank=0, pid=2319)[0m   Step 36: 39.170s
[36m(head, rank=0, pid=2319)[0m   Step 37: 38.759s
[36m(head, rank=0, pid=2319)[0m   Step 38: 40.145s
[36m(head, rank=0, pid=2319)[0m   Step 39: 37.434s
[36m(head, rank=0, pid=2319)[0m   Step 40: 35.246s
[36m(head, rank=0, pid=2319)[0m   Step 41: 37.606s
[36m(head, rank=0, pid=2319)[0m   Step 42: 39.010s
[36m(head, rank=0, pid=2319)[0m   Step 43: 38.700s
[36m(head, rank=0, pid=2319)[0m   Step 44: 39.409s
[36m(head, rank=0, pid=2319)[0m   Step 45: 46.282s
[36m(head, rank=0, pid=2319)[0m   Step 46: 38.968s
[36m(head, rank=0, pid=2319)[0m   Step 47: 39.412s
[36m(head, rank=0, pid=2319)[0m   Step 48: 40.572s
[36m(head, rank=0, pid=2319)[0m   Step 49: 38.359s
[36m(head, rank=0, pid=2319)[0m   Step 50: 39.774s
[36m(head, rank=0, pid=2319)[0m   Step 51: 37.873s
[36m(head, rank=0, pid=2319)[0m   Step 52: 41.603s
[36m(head, rank=0, pid=2319)[0m   Step 53: 39.817s
[36m(head, rank=0, pid=2319)[0m   Step 54: 41.994s
[36m(head, rank=0, pid=2319)[0m   Step 55: 45.596s
[36m(head, rank=0, pid=2319)[0m   Step 56: 37.843s
[36m(head, rank=0, pid=2319)[0m   Step 57: 34.944s
[36m(head, rank=0, pid=2319)[0m   Step 58: 37.710s
[36m(head, rank=0, pid=2319)[0m   Step 59: 41.029s
[36m(head, rank=0, pid=2319)[0m   Step 60: 38.926s
[36m(head, rank=0, pid=2319)[0m   Step 61: 36.941s
[36m(head, rank=0, pid=2319)[0m   Step 62: 37.373s
[36m(head, rank=0, pid=2319)[0m   Step 63: 37.683s
[36m(head, rank=0, pid=2319)[0m   Step 64: 37.978s
[36m(head, rank=0, pid=2319)[0m   Step 65: 39.194s
[36m(head, rank=0, pid=2319)[0m   Step 66: 39.696s
[36m(head, rank=0, pid=2319)[0m   Step 67: 37.351s
[36m(head, rank=0, pid=2319)[0m   Step 68: 36.923s
[36m(head, rank=0, pid=2319)[0m   Step 69: 49.298s
[36m(head, rank=0, pid=2319)[0m   Step 70: 40.286s
[36m(head, rank=0, pid=2319)[0m   Step 71: 46.276s
[36m(head, rank=0, pid=2319)[0m   Step 72: 37.958s
[36m(head, rank=0, pid=2319)[0m   Step 73: 38.985s
[36m(head, rank=0, pid=2319)[0m   Step 74: 37.460s
[36m(head, rank=0, pid=2319)[0m   Step 75: 40.183s
[36m(head, rank=0, pid=2319)[0m   Step 76: 38.196s
[36m(head, rank=0, pid=2319)[0m   Step 77: 40.840s
[36m(head, rank=0, pid=2319)[0m   Step 78: 37.738s
[36m(head, rank=0, pid=2319)[0m   Step 79: 42.730s
[36m(head, rank=0, pid=2319)[0m   Step 80: 40.924s
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m TRAINING TIME STATISTICS
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m Total training steps: 80
[36m(head, rank=0, pid=2319)[0m Total training time: 3167.20 seconds
[36m(head, rank=0, pid=2319)[0m Average time per step: 39.590 seconds
[36m(head, rank=0, pid=2319)[0m Fastest step: 34.987 seconds
[36m(head, rank=0, pid=2319)[0m Slowest step: 52.180 seconds
[36m(head, rank=0, pid=2319)[0m Time variance: 17.193 seconds
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Step time distribution:
[36m(head, rank=0, pid=2319)[0m   Step 1: 47.971s
[36m(head, rank=0, pid=2319)[0m   Step 2: 37.798s
[36m(head, rank=0, pid=2319)[0m   Step 3: 38.363s
[36m(head, rank=0, pid=2319)[0m   Step 4: 37.999s
[36m(head, rank=0, pid=2319)[0m   Step 5: 42.158s
[36m(head, rank=0, pid=2319)[0m   Step 6: 38.871s
[36m(head, rank=0, pid=2319)[0m   Step 7: 39.019s
[36m(head, rank=0, pid=2319)[0m   Step 8: 37.306s
[36m(head, rank=0, pid=2319)[0m   Step 9: 39.930s
[36m(head, rank=0, pid=2319)[0m   Step 10: 37.737s
[36m(head, rank=0, pid=2319)[0m   Step 11: 38.523s
[36m(head, rank=0, pid=2319)[0m   Step 12: 38.232s
[36m(head, rank=0, pid=2319)[0m   Step 13: 39.099s
[36m(head, rank=0, pid=2319)[0m   Step 14: 38.129s
[36m(head, rank=0, pid=2319)[0m   Step 15: 40.016s
[36m(head, rank=0, pid=2319)[0m   Step 16: 41.520s
[36m(head, rank=0, pid=2319)[0m   Step 17: 37.173s
[36m(head, rank=0, pid=2319)[0m   Step 18: 37.085s
[36m(head, rank=0, pid=2319)[0m   Step 19: 43.151s
[36m(head, rank=0, pid=2319)[0m   Step 20: 37.063s
[36m(head, rank=0, pid=2319)[0m   Step 21: 41.390s
[36m(head, rank=0, pid=2319)[0m   Step 22: 38.205s
[36m(head, rank=0, pid=2319)[0m   Step 23: 36.136s
[36m(head, rank=0, pid=2319)[0m   Step 24: 39.678s
[36m(head, rank=0, pid=2319)[0m   Step 25: 44.268s
[36m(head, rank=0, pid=2319)[0m   Step 26: 38.574s
[36m(head, rank=0, pid=2319)[0m   Step 27: 41.827s
[36m(head, rank=0, pid=2319)[0m   Step 28: 37.983s
[36m(head, rank=0, pid=2319)[0m   Step 29: 39.131s
[36m(head, rank=0, pid=2319)[0m   Step 30: 39.995s
[36m(head, rank=0, pid=2319)[0m   Step 31: 38.290s
[36m(head, rank=0, pid=2319)[0m   Step 32: 37.831s
[36m(head, rank=0, pid=2319)[0m   Step 33: 52.180s
[36m(head, rank=0, pid=2319)[0m   Step 34: 38.779s
[36m(head, rank=0, pid=2319)[0m   Step 35: 39.723s
[36m(head, rank=0, pid=2319)[0m   Step 36: 39.190s
[36m(head, rank=0, pid=2319)[0m   Step 37: 38.701s
[36m(head, rank=0, pid=2319)[0m   Step 38: 40.133s
[36m(head, rank=0, pid=2319)[0m   Step 39: 37.452s
[36m(head, rank=0, pid=2319)[0m   Step 40: 35.260s
[36m(head, rank=0, pid=2319)[0m   Step 41: 37.602s
[36m(head, rank=0, pid=2319)[0m   Step 42: 39.071s
[36m(head, rank=0, pid=2319)[0m   Step 43: 38.721s
[36m(head, rank=0, pid=2319)[0m   Step 44: 39.448s
[36m(head, rank=0, pid=2319)[0m   Step 45: 45.635s
[36m(head, rank=0, pid=2319)[0m   Step 46: 39.008s
[36m(head, rank=0, pid=2319)[0m   Step 47: 39.395s
[36m(head, rank=0, pid=2319)[0m   Step 48: 40.513s
[36m(head, rank=0, pid=2319)[0m   Step 49: 38.915s
[36m(head, rank=0, pid=2319)[0m   Step 50: 39.142s
[36m(head, rank=0, pid=2319)[0m   Step 51: 37.728s
[36m(head, rank=0, pid=2319)[0m   Step 52: 41.569s
[36m(head, rank=0, pid=2319)[0m   Step 53: 39.311s
[36m(head, rank=0, pid=2319)[0m   Step 54: 41.324s
[36m(head, rank=0, pid=2319)[0m   Step 55: 45.657s
[36m(head, rank=0, pid=2319)[0m   Step 56: 37.818s
[36m(head, rank=0, pid=2319)[0m   Step 57: 34.987s
[36m(head, rank=0, pid=2319)[0m   Step 58: 37.672s
[36m(head, rank=0, pid=2319)[0m   Step 59: 40.940s
[36m(head, rank=0, pid=2319)[0m   Step 60: 38.950s
[36m(head, rank=0, pid=2319)[0m   Step 61: 37.047s
[36m(head, rank=0, pid=2319)[0m   Step 62: 36.907s
[36m(head, rank=0, pid=2319)[0m   Step 63: 37.541s
[36m(head, rank=0, pid=2319)[0m   Step 64: 37.968s
[36m(head, rank=0, pid=2319)[0m   Step 65: 39.192s
[36m(head, rank=0, pid=2319)[0m   Step 66: 39.066s
[36m(head, rank=0, pid=2319)[0m   Step 67: 37.365s
[36m(head, rank=0, pid=2319)[0m   Step 68: 36.303s
[36m(head, rank=0, pid=2319)[0m   Step 69: 49.279s
[36m(head, rank=0, pid=2319)[0m   Step 70: 40.254s
[36m(head, rank=0, pid=2319)[0m   Step 71: 46.068s
[36m(head, rank=0, pid=2319)[0m   Step 72: 37.453s
[36m(head, rank=0, pid=2319)[0m   Step 73: 38.823s
[36m(head, rank=0, pid=2319)[0m   Step 74: 37.415s
[36m(head, rank=0, pid=2319)[0m   Step 75: 40.242s
[36m(head, rank=0, pid=2319)[0m   Step 76: 38.212s
[36m(head, rank=0, pid=2319)[0m   Step 77: 40.897s
[36m(head, rank=0, pid=2319)[0m   Step 78: 38.288s
[36m(head, rank=0, pid=2319)[0m   Step 79: 42.668s
[36m(head, rank=0, pid=2319)[0m   Step 80: 40.943s
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m TRAINING TIME STATISTICS
[36m(head, rank=0, pid=2319)[0m ============================================================
[36m(head, rank=0, pid=2319)[0m Total training steps: 80
[36m(head, rank=0, pid=2319)[0m Total training time: 3170.00 seconds
[36m(head, rank=0, pid=2319)[0m Average time per step: 39.625 seconds
[36m(head, rank=0, pid=2319)[0m Fastest step: 34.978 seconds
[36m(head, rank=0, pid=2319)[0m Slowest step: 52.793 seconds
[36m(head, rank=0, pid=2319)[0m Time variance: 17.815 seconds
[36m(head, rank=0, pid=2319)[0m 
[36m(head, rank=0, pid=2319)[0m Step time distribution:
[36m(head, rank=0, pid=2319)[0m   Step 1: 47.909s
[36m(head, rank=0, pid=2319)[0m   Step 2: 37.763s
[36m(head, rank=0, pid=2319)[0m   Step 3: 38.361s
[36m(head, rank=0, pid=2319)[0m   Step 4: 38.000s
[36m(head, rank=0, pid=2319)[0m   Step 5: 42.169s
[36m(head, rank=0, pid=2319)[0m   Step 6: 38.862s
[36m(head, rank=0, pid=2319)[0m   Step 7: 39.023s
[36m(head, rank=0, pid=2319)[0m   Step 8: 37.826s
[36m(head, rank=0, pid=2319)[0m   Step 9: 39.864s
[36m(head, rank=0, pid=2319)[0m   Step 10: 37.722s
[36m(head, rank=0, pid=2319)[0m   Step 11: 38.529s
[36m(head, rank=0, pid=2319)[0m   Step 12: 38.192s
[36m(head, rank=0, pid=2319)[0m   Step 13: 39.092s
[36m(head, rank=0, pid=2319)[0m   Step 14: 38.131s
[36m(head, rank=0, pid=2319)[0m   Step 15: 40.026s
[36m(head, rank=0, pid=2319)[0m   Step 16: 41.520s
[36m(head, rank=0, pid=2319)[0m   Step 17: 37.178s
[36m(head, rank=0, pid=2319)[0m   Step 18: 40.633s
[36m(head, rank=0, pid=2319)[0m   Step 19: 38.732s
[36m(head, rank=0, pid=2319)[0m   Step 20: 37.072s
[36m(head, rank=0, pid=2319)[0m   Step 21: 41.382s
[36m(head, rank=0, pid=2319)[0m   Step 22: 38.205s
[36m(head, rank=0, pid=2319)[0m   Step 23: 35.518s
[36m(head, rank=0, pid=2319)[0m   Step 24: 39.715s
[36m(head, rank=0, pid=2319)[0m   Step 25: 44.308s
[36m(head, rank=0, pid=2319)[0m   Step 26: 38.584s
[36m(head, rank=0, pid=2319)[0m   Step 27: 41.809s
[36m(head, rank=0, pid=2319)[0m   Step 28: 38.013s
[36m(head, rank=0, pid=2319)[0m   Step 29: 39.132s
[36m(head, rank=0, pid=2319)[0m   Step 30: 39.982s
[36m(head, rank=0, pid=2319)[0m   Step 31: 38.289s
[36m(head, rank=0, pid=2319)[0m   Step 32: 37.872s
[36m(head, rank=0, pid=2319)[0m   Step 33: 52.793s
[36m(head, rank=0, pid=2319)[0m   Step 34: 38.423s
[36m(head, rank=0, pid=2319)[0m   Step 35: 39.729s
[36m(head, rank=0, pid=2319)[0m   Step 36: 39.188s
[36m(head, rank=0, pid=2319)[0m   Step 37: 38.741s
[36m(head, rank=0, pid=2319)[0m   Step 38: 39.523s
[36m(head, rank=0, pid=2319)[0m   Step 39: 37.451s
[36m(head, rank=0, pid=2319)[0m   Step 40: 35.268s
[36m(head, rank=0, pid=2319)[0m   Step 41: 37.604s
[36m(head, rank=0, pid=2319)[0m   Step 42: 38.516s
[36m(head, rank=0, pid=2319)[0m   Step 43: 38.687s
[36m(head, rank=0, pid=2319)[0m   Step 44: 38.814s
[36m(head, rank=0, pid=2319)[0m   Step 45: 46.564s
[36m(head, rank=0, pid=2319)[0m   Step 46: 39.022s
[36m(head, rank=0, pid=2319)[0m   Step 47: 39.392s
[36m(head, rank=0, pid=2319)[0m   Step 48: 40.496s
[36m(head, rank=0, pid=2319)[0m   Step 49: 38.937s
[36m(head, rank=0, pid=2319)[0m   Step 50: 39.640s
[36m(head, rank=0, pid=2319)[0m   Step 51: 37.715s
[36m(head, rank=0, pid=2319)[0m   Step 52: 41.568s
[36m(head, rank=0, pid=2319)[0m   Step 53: 39.754s
[36m(head, rank=0, pid=2319)[0m   Step 54: 41.888s
[36m(head, rank=0, pid=2319)[0m   Step 55: 45.673s
[36m(head, rank=0, pid=2319)[0m   Step 56: 37.169s
[36m(head, rank=0, pid=2319)[0m   Step 57: 34.978s
[36m(head, rank=0, pid=2319)[0m   Step 58: 38.400s
[36m(head, rank=0, pid=2319)[0m   Step 59: 40.962s
[36m(head, rank=0, pid=2319)[0m   Step 60: 39.532s
[36m(head, rank=0, pid=2319)[0m   Step 61: 37.050s
[36m(head, rank=0, pid=2319)[0m   Step 62: 37.420s
[36m(head, rank=0, pid=2319)[0m   Step 63: 37.540s
[36m(head, rank=0, pid=2319)[0m   Step 64: 38.513s
[36m(head, rank=0, pid=2319)[0m   Step 65: 39.181s
[36m(head, rank=0, pid=2319)[0m   Step 66: 39.669s
[36m(head, rank=0, pid=2319)[0m   Step 67: 37.358s
[36m(head, rank=0, pid=2319)[0m   Step 68: 36.917s
[36m(head, rank=0, pid=2319)[0m   Step 69: 49.274s
[36m(head, rank=0, pid=2319)[0m   Step 70: 40.236s
[36m(head, rank=0, pid=2319)[0m   Step 71: 46.094s
[36m(head, rank=0, pid=2319)[0m   Step 72: 37.478s
[36m(head, rank=0, pid=2319)[0m   Step 73: 38.832s
[36m(head, rank=0, pid=2319)[0m   Step 74: 37.429s
[36m(head, rank=0, pid=2319)[0m   Step 75: 40.205s
[36m(head, rank=0, pid=2319)[0m   Step 76: 38.209s
[36m(head, rank=0, pid=2319)[0m   Step 77: 40.905s
[36m(head, rank=0, pid=2319)[0m   Step 78: 38.281s
[36m(head, rank=0, pid=2319)[0m   Step 79: 42.660s
[36m(head, rank=0, pid=2319)[0m   Step 80: 40.901s
[36m(head, rank=0, pid=2319)[0m ============================================================
[0m[32m✓ Job finished (status: SUCCEEDED).[0m[0m
